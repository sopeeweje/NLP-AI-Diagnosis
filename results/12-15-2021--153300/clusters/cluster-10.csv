text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among         these are the development of highly sensitive and accurate automated             sequencing techniques, the development of optimal strategies for gene            recognition in sequence data, and an improved understanding of gene              function and regulation.  My intent in this Special Emphasis Research            Career Award project is to address these and other related problems              within the context of state-of-the-art genome research.  I believe that          my background in theoretical and experimental particle physics provides          me with a unique set of skills relevant to the solution of these and             other problems.  The goals of this training program are to: 1) obtain a          firm grounding in modern molecular biology and genetics with                     specialization in genome research, 2) develop a set of skills in                 laboratory-based genome research through a first year project in                 physical mapping and DNA sequencing, and 3) develop a long term project          focusing on DNA sequence acquisition and analysis which will utilize the         analytical, computational and model building skills which I have                 developed as a physicist.  In particular, I would hope to develop                optimum protocols for gene mapping and sequence assembly applicable to           large scale genome analysis and to develop new and more efficient                algorithms for gene sequence identification and interpretation.  In              addition, I intend to pursue the development of advanced automated               sequencing technology based on highly sensitive detectors and techniques         developed for particle physics.  Achievement of either or both of these          goals will greatly facilitate the formidable task faced by the                   researchers involved in the Human Genome Project in accumulating and             analyzing vast amounts of genomic DNA sequence.  This project will begin         by immersion in the work currently being done on the physical mapping of         human chromosome 11, and the sequencing of selected reference markers            and cDNA clones, as part of the Salk Institute large scale physical              mapping project.  The formal training I will receive during the tenure           of the NCHGR/SERCA provides an ideal environment in which I can gain the         necessary grounding in current techniques so that I can effectively work         on the development of new techniques and strategies and contribute to            the genome research of the future.                                                n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,2440343,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' nucleic acid sequence', ' technology /technique development', ' training']",NHGRI,INSTITUTE FOR GENOMIC RESEARCH,K01,1996,78818,-0.002404329474151946
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among  these are the development of highly sensitive and accurate automated  sequencing techniques, the development of optimal strategies for gene  recognition in sequence data, and an improved understanding of gene  function and regulation.  My intent in this Special Emphasis Research  Career Award project is to address these and other related problems  within the context of state-of-the-art genome research.  I believe that  my background in theoretical and experimental particle physics provides  me with a unique set of skills relevant to the solution of these and  other problems.  The goals of this training program are to: 1) obtain a  firm grounding in modern molecular biology and genetics with  specialization in genome research, 2) develop a set of skills in  laboratory-based genome research through a first year project in  physical mapping and DNA sequencing, and 3) develop a long term project  focusing on DNA sequence acquisition and analysis which will utilize the  analytical, computational and model building skills which I have  developed as a physicist.  In particular, I would hope to develop  optimum protocols for gene mapping and sequence assembly applicable to  large scale genome analysis and to develop new and more efficient  algorithms for gene sequence identification and interpretation.  In  addition, I intend to pursue the development of advanced automated  sequencing technology based on highly sensitive detectors and techniques  developed for particle physics.  Achievement of either or both of these  goals will greatly facilitate the formidable task faced by the  researchers involved in the Human Genome Project in accumulating and  analyzing vast amounts of genomic DNA sequence.  This project will begin  by immersion in the work currently being done on the physical mapping of  human chromosome 11, and the sequencing of selected reference markers  and cDNA clones, as part of the Salk Institute large scale physical  mapping project.  The formal training I will receive during the tenure  of the NCHGR/SERCA provides an ideal environment in which I can gain the  necessary grounding in current techniques so that I can effectively work  on the development of new techniques and strategies and contribute to  the genome research of the future.  n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,2208285,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' nucleic acid sequence', ' technology /technique development', ' training']",NHGRI,STANFORD UNIVERSITY,K01,1995,79392,-0.002404329474151946
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among these are the development of highly sensitive and accurate automated sequencing techniques, the development of optimal strategies for gene recognition in sequence data, and an improved understanding of gene function and regulation.  My intent in this Special Emphasis Research Career Award project is to address these and other related problems within the context of state-of-the-art genome research.  I believe that my background in theoretical and experimental particle physics provides me with a unique set of skills relevant to the solution of these and other problems.  The goals of this training program are to: 1) obtain a firm grounding in modern molecular biology and genetics with specialization in genome research, 2) develop a set of skills in laboratory-based genome research through a first year project in physical mapping and DNA sequencing, and 3) develop a long term project focusing on DNA sequence acquisition and analysis which will utilize the analytical, computational and model building skills which I have developed as a physicist.  In particular, I would hope to develop optimum protocols for gene mapping and sequence assembly applicable to large scale genome analysis and to develop new and more efficient algorithms for gene sequence identification and interpretation.  In addition, I intend to pursue the development of advanced automated sequencing technology based on highly sensitive detectors and techniques developed for particle physics.  Achievement of either or both of these goals will greatly facilitate the formidable task faced by the researchers involved in the Human Genome Project in accumulating and analyzing vast amounts of genomic DNA sequence.  This project will begin by immersion in the work currently being done on the physical mapping of human chromosome 11, and the sequencing of selected reference markers and cDNA clones, as part of the Salk Institute large scale physical mapping project.  The formal training I will receive during the tenure of the NCHGR/SERCA provides an ideal environment in which I can gain the necessary grounding in current techniques so that I can effectively work on the development of new techniques and strategies and contribute to the genome research of the future.  n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,2208284,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' nucleic acid sequence', ' technology /technique development', ' training']",NHGRI,STANFORD UNIVERSITY,K01,1994,81199,-0.002404329474151946
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among these are the development of highly sensitive and accurate automated sequencing techniques, the development of optimal strategies for gene recognition in sequence data, and an improved understanding of gene function and regulation.  My intent in this Special Emphasis Research Career Award project is to address these and other related problems within the context of state-of-the-art genome research.  I believe that my background in theoretical and experimental particle physics provides me with a unique set of skills relevant to the solution of these and other problems.  The goals of this training program are to: 1) obtain a firm grounding in modern molecular biology and genetics with specialization in genome research, 2) develop a set of skills in laboratory-based genome research through a first year project in physical mapping and DNA sequencing, and 3) develop a long term project focusing on DNA sequence acquisition and analysis which will utilize the analytical, computational and model building skills which I have developed as a physicist.  In particular, I would hope to develop optimum protocols for gene mapping and sequence assembly applicable to large scale genome analysis and to develop new and more efficient algorithms for gene sequence identification and interpretation.  In addition, I intend to pursue the development of advanced automated sequencing technology based on highly sensitive detectors and techniques developed for particle physics.  Achievement of either or both of these goals will greatly facilitate the formidable task faced by the researchers involved in the Human Genome Project in accumulating and analyzing vast amounts of genomic DNA sequence.  This project will begin by immersion in the work currently being done on the physical mapping of human chromosome 11, and the sequencing of selected reference markers and cDNA clones, as part of the Salk Institute large scale physical mapping project.  The formal training I will receive during the tenure of the NCHGR/SERCA provides an ideal environment in which I can gain the necessary grounding in current techniques so that I can effectively work on the development of new techniques and strategies and contribute to the genome research of the future.  n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,3068602,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' nucleic acid sequence', ' technology /technique development', ' training']",NHGRI,SALK INSTITUTE FOR BIOLOGICAL STUDIES,K01,1993,89532,-0.002404329474151946
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among these are the development of highly sensitive and accurate automated sequencing techniques, the development of optimal strategies for gene recognition in sequence data, and an improved understanding of gene function and regulation.  My intent in this Special Emphasis Research Career Award project is to address these and other related problems within the context of state-of-the-art genome research.  I believe that my background in theoretical and experimental particle physics provides me with a unique set of skills relevant to the solution of these and other problems.  The goals of this training program are to: 1) obtain a firm grounding in modern molecular biology and genetics with specialization in genome research, 2) develop a set of skills in laboratory-based genome research through a first year project in physical mapping and DNA sequencing, and 3) develop a long term project focusing on DNA sequence acquisition and analysis which will utilize the analytical, computational and model building skills which I have developed as a physicist.  In particular, I would hope to develop optimum protocols for gene mapping and sequence assembly applicable to large scale genome analysis and to develop new and more efficient algorithms for gene sequence identification and interpretation.  In addition, I intend to pursue the development of advanced automated sequencing technology based on highly sensitive detectors and techniques developed for particle physics.  Achievement of either or both of these goals will greatly facilitate the formidable task faced by the researchers involved in the Human Genome Project in accumulating and analyzing vast amounts of genomic DNA sequence.  This project will begin by immersion in the work currently being done on the physical mapping of human chromosome 11, and the sequencing of selected reference markers and cDNA clones, as part of the Salk Institute large scale physical mapping project.  The formal training I will receive during the tenure of the NCHGR/SERCA provides an ideal environment in which I can gain the necessary grounding in current techniques so that I can effectively work on the development of new techniques and strategies and contribute to the genome research of the future.  n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,3068600,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' technology /technique development', ' training']",NHGRI,SALK INSTITUTE FOR BIOLOGICAL STUDIES,K01,1992,80784,-0.002404329474151946
"ADVANCED ALGORITHMS AND TOOLS FOR CONTIG BUILDING This is an application for an NCHGR/SERCA grant (K01) to support                 interdisciplinary research in genomic science.  The immediate objective of       this research project is to develop a fully automated/robust algorithm for       computer assembly of high density cosmid contigs to serve as templates for       large-scale sequence-based mapping.  This includes integrating the cosmid        contigs with chromosome-wide YAC based maps and incorporating diverse            sources of data (e.g., DNA sequence from cosmid ends, STSs and other             markers, or results of specific gap-filling efforts) to resolve                  ambiguities and verify self-consistency.  Initial efforts will be focused        on the high resolution mapping and sampled sequencing of human chromosome        11.  The mapping strategy employs high density cosmid contig assembly over       individual 200 kb to 1 Mb regions of the chromosome coupled with DNA             sequencing of the cosmid ends.  The relative order and spacing of the            sequence fragments is determined from the template contig resulting in a         physical map of 1 to 5 kb resolution which contains up to 40% of the             entire sequence at one-pass accuracy.  A simple restriction-site based           approach to cosmid fingerprinting will be effective, provided that the           contig-building algorithm correlates fragment data from multiple                 restriction digests and includes labeled vector/insert end fragments to          determine the orientation of individual cosmids, i.e., the orientation of        the genomic insert relative to the cloning vector.                                                                                                                The candidate is a physicist with nearly a ten year record of achievement        and publication in the field of plasma fusion energy--theory/computation.        The research advisor, Prof. Glen Evans, is the Principal Investigator of         the Genome Science and Technology Center (GESTEC) at the University of           Texas Southwestern Medical Center at Dallas, one of the top academic             medical centers in the nation and the performance site of this grant.            Prof. Evans is an accomplished biologist with an established record of           coordinating multi-disciplinary research to develop informatics and              automation for the Human Genome Project (HGP).  The candidate's skills           also compliment those of Prof. Harold Garner, physicist and co-Principal         Investigator of GESTEC.  The candidate will receive explicit training            through an intensive 18 months program that includes formal course-work in       the Division of Cell and Molecular Biology (at UT Southwestern), and             laboratory rotations in the mapping, sequencing, and informatics units of        GESTEC.                                                                           n/a",ADVANCED ALGORITHMS AND TOOLS FOR CONTIG BUILDING,2430543,K01HG000018,"['DNA', ' artificial chromosomes', ' artificial intelligence', ' chemical fingerprinting', ' chromosomes', ' computer assisted sequence analysis', ' computer program /software', ' genetic mapping', ' human genetic material tag', ' molecular cloning', ' nucleic acid sequence', ' plasmids', ' restriction fragment length polymorphism']",NHGRI,UNIVERSITY OF TEXAS SW MED CTR/DALLAS,K01,1997,97527,0.027269707907860354
"ADVANCED ALGORITHMS AND TOOLS FOR CONTIG BUILDING This is an application for an NCHGR/SERCA grant (K01) to support  interdisciplinary research in genomic science.  The immediate objective of  this research project is to develop a fully automated/robust algorithm for  computer assembly of high density cosmid contigs to serve as templates for  large-scale sequence-based mapping.  This includes integrating the cosmid  contigs with chromosome-wide YAC based maps and incorporating diverse  sources of data (e.g., DNA sequence from cosmid ends, STSs and other  markers, or results of specific gap-filling efforts) to resolve  ambiguities and verify self-consistency.  Initial efforts will be focused  on the high resolution mapping and sampled sequencing of human chromosome  11.  The mapping strategy employs high density cosmid contig assembly over  individual 200 kb to 1 Mb regions of the chromosome coupled with DNA  sequencing of the cosmid ends.  The relative order and spacing of the  sequence fragments is determined from the template contig resulting in a  physical map of 1 to 5 kb resolution which contains up to 40% of the  entire sequence at one-pass accuracy.  A simple restriction-site based  approach to cosmid fingerprinting will be effective, provided that the  contig-building algorithm correlates fragment data from multiple  restriction digests and includes labeled vector/insert end fragments to  determine the orientation of individual cosmids, i.e., the orientation of  the genomic insert relative to the cloning vector.    The candidate is a physicist with nearly a ten year record of achievement  and publication in the field of plasma fusion energy--theory/computation.  The research advisor, Prof. Glen Evans, is the Principal Investigator of  the Genome Science and Technology Center (GESTEC) at the University of  Texas Southwestern Medical Center at Dallas, one of the top academic  medical centers in the nation and the performance site of this grant.  Prof. Evans is an accomplished biologist with an established record of  coordinating multi-disciplinary research to develop informatics and  automation for the Human Genome Project (HGP).  The candidate's skills  also compliment those of Prof. Harold Garner, physicist and co-Principal  Investigator of GESTEC.  The candidate will receive explicit training  through an intensive 18 months program that includes formal course-work in  the Division of Cell and Molecular Biology (at UT Southwestern), and  laboratory rotations in the mapping, sequencing, and informatics units of  GESTEC.  n/a",ADVANCED ALGORITHMS AND TOOLS FOR CONTIG BUILDING,2208336,K01HG000018,"['DNA', ' artificial chromosomes', ' artificial intelligence', ' chemical fingerprinting', ' chromosomes', ' computer assisted sequence analysis', ' computer program /software', ' genetic mapping', ' human genetic material tag', ' molecular cloning', ' nucleic acid sequence', ' plasmids', ' restriction fragment length polymorphism']",NHGRI,UNIVERSITY OF TEXAS SW MED CTR/DALLAS,K01,1995,81100,0.027269707907860354
"GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS In this proposal we present a systematic approach to gene mapping and genotyping based on the simultaneous analysis of multiple Amplified Sequence Polymorphisms (ASPs).  The proposal has three broad features: the development of a technology suitable for the automation of gene mapping and genotyping, the application of this technology to the development of markers for the X chromosome and then for the entire genome, and the development of a computer tool for the management of gene mapping experiments. The main concept associated with ASP technology is that a DNA segment containing the sequence variation of a polymorphic locus can be amplified in such a way that it has a unique physical property.  This unique property will allow individual loci to be distinguished from one another such that multiple loci can be analyzed simultaneously.  In this application, we are proposing to use the length of the DNA segment as this distinguishing physical property and the polymerase chain reaction (PCR) as the method of amplification.  Two alternative approaches for the generation of ASP markers are to be explored.  The first is allele specific PCR (AS-PCR) in which the length of the PCR amplified fragment is different for different loci producing the marker directly.  The second is allele specific primer extension (AS-PE) in which the PCR products are analyzed with oligonucleotide primers which produce allele specific fragments of different lengths for different loci.  Specifically we plan to 1) refine ASP technology, 2) develop ASPs for the X chromosome and the genome and 3) create appropriate software for aiding the scientist in concerning ASP based mapping experiments, including an expert system.  n/a",GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS,3333120,R01HG000099,"['alleles', ' biological polymorphism', ' chromosomes', ' computer assisted sequence analysis', ' gel electrophoresis', ' genetic mapping', ' genetic markers', ' genetic regulatory element', ' genome', ' genotype', ' molecular cloning', ' natural gene amplification', ' oligonucleotides', ' polymerase chain reaction', ' restriction fragment length polymorphism']",NHGRI,CITY OF HOPE/BECKMAN RESEARCH INSTITUTE,R01,1992,294334,0.03103245278011108
"GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS In this proposal we present a systematic approach to gene mapping and genotyping based on the simultaneous analysis of multiple Amplified Sequence Polymorphisms (ASPs).  The proposal has three broad features: the development of a technology suitable for the automation of gene mapping and genotyping, the application of this technology to the development of markers for the X chromosome and then for the entire genome, and the development of a computer tool for the management of gene mapping experiments. The main concept associated with ASP technology is that a DNA segment containing the sequence variation of a polymorphic locus can be amplified in such a way that it has a unique physical property.  This unique property will allow individual loci to be distinguished from one another such that multiple loci can be analyzed simultaneously.  In this application, we are proposing to use the length of the DNA segment as this distinguishing physical property and the polymerase chain reaction (PCR) as the method of amplification.  Two alternative approaches for the generation of ASP markers are to be explored.  The first is allele specific PCR (AS-PCR) in which the length of the PCR amplified fragment is different for different loci producing the marker directly.  The second is allele specific primer extension (AS-PE) in which the PCR products are analyzed with oligonucleotide primers which produce allele specific fragments of different lengths for different loci.  Specifically we plan to 1) refine ASP technology, 2) develop ASPs for the X chromosome and the genome and 3) create appropriate software for aiding the scientist in concerning ASP based mapping experiments, including an expert system.  n/a",GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS,3333119,R01HG000099,"['alleles', ' biological polymorphism', ' chromosomes', ' computer assisted sequence analysis', ' gel electrophoresis', ' genetic mapping', ' genetic markers', ' genetic regulatory element', ' genome', ' genotype', ' molecular cloning', ' natural gene amplification', ' oligonucleotides', ' polymerase chain reaction', ' restriction fragment length polymorphism']",NHGRI,CITY OF HOPE/BECKMAN RESEARCH INSTITUTE,R01,1991,282985,0.03103245278011108
"GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS In this proposal we present a systematic approach to gene mapping and genotyping based on the simultaneous analysis of multiple Amplified Sequence Polymorphisms (ASPs).  The proposal has three broad features: the development of a technology suitable for the automation of gene mapping and genotyping, the application of this technology to the development of markers for the X chromosome and then for the entire genome, and the development of a computer tool for the management of gene mapping experiments. The main concept associated with ASP technology is that a DNA segment containing the sequence variation of a polymorphic locus can be amplified in such a way that it has a unique physical property.  This unique property will allow individual loci to be distinguished from one another such that multiple loci can be analyzed simultaneously.  In this application, we are proposing to use the length of the DNA segment as this distinguishing physical property and the polymerase chain reaction (PCR) as the method of amplification.  Two alternative approaches for the generation of ASP markers are to be explored.  The first is allele specific PCR (AS-PCR) in which the length of the PCR amplified fragment is different for different loci producing the marker directly.  The second is allele specific primer extension (AS-PE) in which the PCR products are analyzed with oligonucleotide primers which produce allele specific fragments of different lengths for different loci.  Specifically we plan to 1) refine ASP technology, 2) develop ASPs for the X chromosome and the genome and 3) create appropriate software for aiding the scientist in concerning ASP based mapping experiments, including an expert system.  n/a",GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS,3333118,R01HG000099,"['alleles', ' biological polymorphism', ' chromosomes', ' computer assisted sequence analysis', ' gel electrophoresis', ' genetic mapping', ' genetic markers', ' genetic regulatory element', ' genome', ' genotype', ' molecular cloning', ' natural gene amplification', ' oligonucleotides', ' polymerase chain reaction', ' restriction fragment length polymorphism']",NHGRI,BECKMAN RES INST OF THE CITY OF HOPE,R01,1990,283176,0.03103245278011108
"REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA We proposed to develop a database for storage, retrieval, and graphical display of physical mapping data being produced by several laboratories at the Yale Departments of Human Genetics and Biology.  In the near future, large amounts of physical mapping data describing the human genome will be produced at Yale and elsewhere, and will need to be stored in an organized fashion so it can be retrieved and displayed easily.  Many different types of data are being produced which characterize the genome at different levels of detail.  This information is typically uncertain and incomplete, and data at one level may interact with (reinforce, complement or contradict) data at another level.  The routines that retrieve this data should adapt intelligently to the uncertainty, incompleteness and interdependencies of the data.  Representation of Physical Mapping Data.  The laboratories of Drs. Kenneth Kidd, David Ward, Sherman Weissman, Frank Ruddle, Stephen Reeders, and Allen Bale are currently producing large quantities of physical mapping data, including large scale restriction maps, sets of overlapping cosmids, mapping of yeast artificial chromosomes, and in situ hybridization data. We will develop and refine an appropriate representation for this data.  We will focus particularly on how best to represent the inherent uncertainties and interdependencies in the data, and consensus conclusions based on the data.  Intelligent Retrieval and Concise Display of the Data.  We will develop routines that incorporate several types of knowledge to allow intelligent retrieval of the data.  We will also develop routines to display the data graphically at different levels of detail, including the construction of gene maps.  Although the data in the database itself will be complex and interrelated, the display routines will be designed to present the data clearly, at an appropriate level of detail.  For example, a map of a chromosome or of a large or small chromosomal region will be concise and easily understood.  n/a",REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA,2208596,R01HG000175,"['artificial chromosomes', ' artificial intelligence', ' automated data processing', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' genetic polymorphism', ' hybrid cells', ' information display', ' information retrieval', ' information system analysis', ' information systems', ' linkage mapping', ' nucleic acid sequence', ' restriction mapping']",NHGRI,YALE UNIVERSITY,R01,1993,313085,0.04227576571668396
"REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA We proposed to develop a database for storage, retrieval, and graphical display of physical mapping data being produced by several laboratories at the Yale Departments of Human Genetics and Biology.  In the near future, large amounts of physical mapping data describing the human genome will be produced at Yale and elsewhere, and will need to be stored in an organized fashion so it can be retrieved and displayed easily.  Many different types of data are being produced which characterize the genome at different levels of detail.  This information is typically uncertain and incomplete, and data at one level may interact with (reinforce, complement or contradict) data at another level.  The routines that retrieve this data should adapt intelligently to the uncertainty, incompleteness and interdependencies of the data.  Representation of Physical Mapping Data.  The laboratories of Drs. Kenneth Kidd, David Ward, Sherman Weissman, Frank Ruddle, Stephen Reeders, and Allen Bale are currently producing large quantities of physical mapping data, including large scale restriction maps, sets of overlapping cosmids, mapping of yeast artificial chromosomes, and in situ hybridization data. We will develop and refine an appropriate representation for this data.  We will focus particularly on how best to represent the inherent uncertainties and interdependencies in the data, and consensus conclusions based on the data.  Intelligent Retrieval and Concise Display of the Data.  We will develop routines that incorporate several types of knowledge to allow intelligent retrieval of the data.  We will also develop routines to display the data graphically at different levels of detail, including the construction of gene maps.  Although the data in the database itself will be complex and interrelated, the display routines will be designed to present the data clearly, at an appropriate level of detail.  For example, a map of a chromosome or of a large or small chromosomal region will be concise and easily understood.  n/a",REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA,3333224,R01HG000175,"['artificial chromosomes', ' artificial intelligence', ' automated data processing', ' computer graphics /printing', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' genetic polymorphism', ' hybrid cells', ' information display', ' information retrieval', ' information system analysis', ' information systems', ' linkage mapping', ' nucleic acid sequence', ' restriction mapping']",NHGRI,YALE UNIVERSITY,R01,1992,308409,0.04227576571668396
"REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA We proposed to develop a database for storage, retrieval, and graphical display of physical mapping data being produced by several laboratories at the Yale Departments of Human Genetics and Biology.  In the near future, large amounts of physical mapping data describing the human genome will be produced at Yale and elsewhere, and will need to be stored in an organized fashion so it can be retrieved and displayed easily.  Many different types of data are being produced which characterize the genome at different levels of detail.  This information is typically uncertain and incomplete, and data at one level may interact with (reinforce, complement or contradict) data at another level.  The routines that retrieve this data should adapt intelligently to the uncertainty, incompleteness and interdependencies of the data.  Representation of Physical Mapping Data.  The laboratories of Drs. Kenneth Kidd, David Ward, Sherman Weissman, Frank Ruddle, Stephen Reeders, and Allen Bale are currently producing large quantities of physical mapping data, including large scale restriction maps, sets of overlapping cosmids, mapping of yeast artificial chromosomes, and in situ hybridization data. We will develop and refine an appropriate representation for this data.  We will focus particularly on how best to represent the inherent uncertainties and interdependencies in the data, and consensus conclusions based on the data.  Intelligent Retrieval and Concise Display of the Data.  We will develop routines that incorporate several types of knowledge to allow intelligent retrieval of the data.  We will also develop routines to display the data graphically at different levels of detail, including the construction of gene maps.  Although the data in the database itself will be complex and interrelated, the display routines will be designed to present the data clearly, at an appropriate level of detail.  For example, a map of a chromosome or of a large or small chromosomal region will be concise and easily understood.  n/a",REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA,3333222,R01HG000175,"['artificial intelligence', ' automated data processing', ' computer graphics /printing', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' genetic polymorphism', ' hybrid cells', ' information display', ' information retrieval', ' information system analysis', ' information systems', ' linkage mapping', ' nucleic acid sequence', ' restriction mapping']",NHGRI,YALE UNIVERSITY,R01,1991,309867,0.04227576571668396
"Spectromicroscopy for biochemical analysis of sperm   Description (provided by applicant): We propose to develop the capabilities of       x-ray spectromicroscopy to allow it to be applied to biochemical imaging of          normal and abnormal sperm. This will be done by focusing ""soft"" X rays (in this      case, x rays with a photon energy of 200-800 eV) to the smallest far-field           focus of electromagnetic radiation of any wavelength, and scanning a dry or          frozen hydrated specimen through that focal spot to form an image. Images at a       series of photon energies will then be combined to deliver                           chemical-state-sensitive x-ray absorption spectra from an entire sperm at            better than 50 nm spatial resolution. From this data, major biochemical              constituents in individual sperm will be determined by fitting to reference          spectra of isolated compounds; furthermore, expected and possibly unexpected         spatial correlations between components will be studied using principal              component analysis methods. This work will be carried out using x-ray                microscopes developed by our group at Stony Brook which operate at a soft x-ray      undulator beamline at the National Synchrotron Light Source at Brookhaven            National Laboratory. The microscopes will be improved by the addition of better      order sorting optics for quatitative spectroscopy, and by equipping a cryo           microscope with a more accurate piezo stage and a higher efficiency detector         for studies of frozen hydrated specimens without excessive radiation damage.         These instrumentation developments will be guided by our goal of studying the        correlation between morphological and biochemical variations in sperm, in order      to better understand the causes of male infertility. By obtaining x-ray              spectromicroscopic data on different sperm morphologies in infertile males, we       hope to guide the in vitro fertilization (IVP) clinician in the choice of sperm      use for intracytoplasmic sperm injection (ICSI) so as to improve the success         rate of the procedure. Spectromicroscopic data anaysis software will be made         available for free downloading by other researchers as it is developed.                                                                                                   n/a",Spectromicroscopy for biochemical analysis of sperm,6732037,R01EB000479,"['X ray microscopy', 'X ray spectrometry', 'biochemistry', 'bioimaging /biomedical imaging', 'computer program /software', 'computer system design /evaluation', 'cryoscopy', 'fertility', 'human tissue', 'male', 'morphometry', 'sperm', 'technology /technique development']",NIBIB,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2004,241938,0.005177268718145208
"Spectromicroscopy for biochemical analysis of sperm   Description (provided by applicant): We propose to develop the capabilities of       x-ray spectromicroscopy to allow it to be applied to biochemical imaging of          normal and abnormal sperm. This will be done by focusing ""soft"" X rays (in this      case, x rays with a photon energy of 200-800 eV) to the smallest far-field           focus of electromagnetic radiation of any wavelength, and scanning a dry or          frozen hydrated specimen through that focal spot to form an image. Images at a       series of photon energies will then be combined to deliver                           chemical-state-sensitive x-ray absorption spectra from an entire sperm at            better than 50 nm spatial resolution. From this data, major biochemical              constituents in individual sperm will be determined by fitting to reference          spectra of isolated compounds; furthermore, expected and possibly unexpected         spatial correlations between components will be studied using principal              component analysis methods. This work will be carried out using x-ray                microscopes developed by our group at Stony Brook which operate at a soft x-ray      undulator beamline at the National Synchrotron Light Source at Brookhaven            National Laboratory. The microscopes will be improved by the addition of better      order sorting optics for quatitative spectroscopy, and by equipping a cryo           microscope with a more accurate piezo stage and a higher efficiency detector         for studies of frozen hydrated specimens without excessive radiation damage.         These instrumentation developments will be guided by our goal of studying the        correlation between morphological and biochemical variations in sperm, in order      to better understand the causes of male infertility. By obtaining x-ray              spectromicroscopic data on different sperm morphologies in infertile males, we       hope to guide the in vitro fertilization (IVP) clinician in the choice of sperm      use for intracytoplasmic sperm injection (ICSI) so as to improve the success         rate of the procedure. Spectromicroscopic data anaysis software will be made         available for free downloading by other researchers as it is developed.                                                                                                   n/a",Spectromicroscopy for biochemical analysis of sperm,6624086,R01EB000479,"['X ray microscopy', ' X ray spectrometry', ' biochemistry', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' cryoscopy', ' fertility', ' human tissue', ' male', ' morphometry', ' sperm', ' technology /technique development']",NIBIB,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2003,241938,0.005177268718145208
"Spectromicroscopy for biochemical analysis of sperm   Description (provided by applicant): We propose to develop the capabilities of       x-ray spectromicroscopy to allow it to be applied to biochemical imaging of          normal and abnormal sperm. This will be done by focusing ""soft"" X rays (in this      case, x rays with a photon energy of 200-800 eV) to the smallest far-field           focus of electromagnetic radiation of any wavelength, and scanning a dry or          frozen hydrated specimen through that focal spot to form an image. Images at a       series of photon energies will then be combined to deliver                           chemical-state-sensitive x-ray absorption spectra from an entire sperm at            better than 50 nm spatial resolution. From this data, major biochemical              constituents in individual sperm will be determined by fitting to reference          spectra of isolated compounds; furthermore, expected and possibly unexpected         spatial correlations between components will be studied using principal              component analysis methods. This work will be carried out using x-ray                microscopes developed by our group at Stony Brook which operate at a soft x-ray      undulator beamline at the National Synchrotron Light Source at Brookhaven            National Laboratory. The microscopes will be improved by the addition of better      order sorting optics for quatitative spectroscopy, and by equipping a cryo           microscope with a more accurate piezo stage and a higher efficiency detector         for studies of frozen hydrated specimens without excessive radiation damage.         These instrumentation developments will be guided by our goal of studying the        correlation between morphological and biochemical variations in sperm, in order      to better understand the causes of male infertility. By obtaining x-ray              spectromicroscopic data on different sperm morphologies in infertile males, we       hope to guide the in vitro fertilization (IVP) clinician in the choice of sperm      use for intracytoplasmic sperm injection (ICSI) so as to improve the success         rate of the procedure. Spectromicroscopic data anaysis software will be made         available for free downloading by other researchers as it is developed.                                                                                                   n/a",Spectromicroscopy for biochemical analysis of sperm,6472301,R01EB000479,"['X ray microscopy', ' X ray spectrometry', ' biochemistry', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' cryoscopy', ' fertility', ' human tissue', ' male', ' morphometry', ' sperm', ' technology /technique development']",NIBIB,STATE UNIVERSITY NEW YORK STONY BROOK,R01,2002,241938,0.005177268718145208
"MicroSeer, Analysis software for microscopy imagery  DESCRIPTION (provided by applicant): This project will create new pattern recognition software to improve the analysis and interpretation of in vivo  biomedical imagery. Currently, researchers can get remarkably detailed images of living cells and their  constituent proteins using molecular genetic and microscopy-based approaches in conjunction with  sophisticated microscopy hardware. Available image analysis techniques and software, however, lag behind  the power of this new imaging equipment to visualize the microscopic world.  This phase I SBIR project will apply existing technology in spatial analysis of satellite image data to microscopy data, create new statistical techniques specific to the study of spatial association of proteins in  cells, and create software that implements these statistics for use in the analysis of spatial association timeslice in vivo biomedical imagery.   n/a","MicroSeer, Analysis software for microscopy imagery",6581125,R43EB000575,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' image processing', ' statistics /biometry', ' structural biology']",NIBIB,BIOMEDWARE,R43,2003,177261,0.024820595433396198
"INTELLIGENT AUTOMATED RESTRICTION MAPPING TOOL DESCRIPTION (Adapted from the Investigator's Abstract):  Numerous  restriction mapping programs have been devised since 1978, but none of them  is as precise as manual map construction using digest gel photos, pencil,  and graph paper.  Given realistic data, programs usually find hundreds or  even thousands of solutions, only one of which can be correct.  Because of  this, slow and demanding manual techniques are still in common use.  The  researchers propose to develop public domain software implementing a  complete restriction mapping environment which will be far more powerful  and useful than current restriction mapping software.  This system will:  1) find solutions more quickly than any existing software; 2) find far  fewer false maps than any existing software; 3) allow the user to ""steer""  the entire mapping process (if desired); and 4) guide the user with  detailed, expert advice on handling specific mapping problems as they  arise.  In addition, the system will have:  5) built-in extensibility, so  that simple modifications will also allow other genetic marker mapping  problems to be solved by the same program and 6) the ability to record all  user activity transparently, providing quantitative data on successful  mapping strategies.    The system will be based on extant restriction mapping programs, but it  will overcome their limitations by including the following additional  capabilities:  1) All known heuristics will be implemented.  (Heuristics  are logical rules of thumb which guide the search towards a true solution.)  Existing programs use only a small subset of the known heuristics.  Every  added heuristic will speed up the search and reduce the set of possible  solutions to a problem.  2) Hand mapping will be simulated on-screen via a  ""what you see is what you get"" graphical user interface, with users  choosing fully automatic mapping (the default), fully manual mapping (with  simulated pencils and log paper), or various in-between levels of  semi-automatic assisted mapping.  This will allow users to control or  adjust any part of the mapping process if they so desire.  3) An expert  system (a program which can answer queries and make decisions by consulting  a knowledge database) will guide users through the mapping process.  It  will assist the process of data acquisition, help the user solve  difficulties, and tutor inexperienced users.    Considerable preliminary design work has already taken place, so  implementation can begin almost at once.  Software will be developed and  tested iteratively (""rapid prototyping"") to assure end-user satisfaction.  To insure portability at the source code level, the two major modules of  the system (fragment length derivation and mapping) will be coded in C++  using Boochs' object-oriented design methodology, and the user interface  will be designed using a portable interface-building tool that works on a  variety of computing platforms (including DOS machines, and the Macintosh).  The expert system will be implemented using CLIPS, a portable C-based  public domain expert system shell.  n/a",INTELLIGENT AUTOMATED RESTRICTION MAPPING TOOL,2209202,R01HG000972,"['artificial intelligence', ' automated data processing', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' restriction fragment length polymorphism', ' restriction mapping']",NHGRI,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,1995,134128,0.056227206195092104
"INTELLIGENT AUTOMATED RESTRICTION MAPPING TOOL DESCRIPTION (Adapted from the Investigator's Abstract):  Numerous restriction mapping programs have been devised since 1978, but none of them is as precise as manual map construction using digest gel photos, pencil, and graph paper.  Given realistic data, programs usually find hundreds or even thousands of solutions, only one of which can be correct.  Because of this, slow and demanding manual techniques are still in common use.  The researchers propose to develop public domain software implementing a complete restriction mapping environment which will be far more powerful and useful than current restriction mapping software.  This system will: 1) find solutions more quickly than any existing software; 2) find far fewer false maps than any existing software; 3) allow the user to ""steer"" the entire mapping process (if desired); and 4) guide the user with detailed, expert advice on handling specific mapping problems as they arise.  In addition, the system will have:  5) built-in extensibility, so that simple modifications will also allow other genetic marker mapping problems to be solved by the same program and 6) the ability to record all user activity transparently, providing quantitative data on successful mapping strategies.  The system will be based on extant restriction mapping programs, but it will overcome their limitations by including the following additional capabilities:  1) All known heuristics will be implemented.  (Heuristics are logical rules of thumb which guide the search towards a true solution.) Existing programs use only a small subset of the known heuristics.  Every added heuristic will speed up the search and reduce the set of possible solutions to a problem.  2) Hand mapping will be simulated on-screen via a ""what you see is what you get"" graphical user interface, with users choosing fully automatic mapping (the default), fully manual mapping (with simulated pencils and log paper), or various in-between levels of semi-automatic assisted mapping.  This will allow users to control or adjust any part of the mapping process if they so desire.  3) An expert system (a program which can answer queries and make decisions by consulting a knowledge database) will guide users through the mapping process.  It will assist the process of data acquisition, help the user solve difficulties, and tutor inexperienced users.  Considerable preliminary design work has already taken place, so implementation can begin almost at once.  Software will be developed and tested iteratively (""rapid prototyping"") to assure end-user satisfaction. To insure portability at the source code level, the two major modules of the system (fragment length derivation and mapping) will be coded in C++ using Boochs' object-oriented design methodology, and the user interface will be designed using a portable interface-building tool that works on a variety of computing platforms (including DOS machines, and the Macintosh). The expert system will be implemented using CLIPS, a portable C-based public domain expert system shell.  n/a",INTELLIGENT AUTOMATED RESTRICTION MAPPING TOOL,2209201,R01HG000972,"['artificial intelligence', ' automated data processing', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' restriction fragment length polymorphism', ' restriction mapping']",NHGRI,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,1994,138701,0.056227206195092104
"Maternal Morbidity and Mortality: Risk Factors, Early Detection and Personalized Intervention PROJECT ABSTRACT  In the U.S., from 2011 to 2014, 7,208 maternal fatalities, with the trend worsening year-on-year (CDC, 2016). In addition to the 700+ fatalities, at least 50,000 woman experienced life-threatening complications, annually. According to CDC (2019) for every fatality, 70 more women suffer avoidable, traumatic complications as a result of pregnancy.  Medstar Health Research Institute and Invaryant, Inc, propose the evaluation of a cardiac risk assessment tool for pregnant and postpartum women; this tool updates automatically directly from patient medical records; wearable devices; and patient surveys. Success implies disruptive improvement in women's health. Proposed research involves three key elements: technology, data, and social determinants of health (SDOH) using geospatial mapping of patient locations. Technology: Study technology shall be based on the Invaryant Health Platform (IHP), a technology that automatically ingests data, from medical records, wearable devices, and other sources using proprietary AI based interoperability technology called Mesh-Complex Method Exchange (Mesh-CMX). We propose using the IHP in conjunction with novel prototype-level technology, namely Healthy Outcomes for all Pregnancy Experiences-Cardiovascular-risk Assessment Technology (HOPE-CAT) and the Invaryant machine learning technologies to monitor the patient, based on signals, out-of-range “trip-wires”, and trends in the mother's health data that merit medical intervention. By extending the proof of concept into an early commercial version of the software, and integrating it to the IHP which will automatically update changes in the patient's medical record, we will provide an “early warning” system for mothers and their providers. Data: The study will be tested on patients' medical records using the MedStar's Analytics Platform (MAP), a registry of over 5 Million unique patients. The tool will subsequently have the potential to be leveraged to over 90 million medical records for the MedStar and Cerner hospital systems, distilled down to meet specific eligibility criteria including, gender, age, race, pregnancy and medical outcomes. A second phase of this project would take the findings from the retrospective study (this grant request) and use the technology within the Medstar hospital system, to validate the efficacy of the findings in a “real-world setting”. Using our proprietary AI technology, we will compare each mother's progress against a cohort of retrospective data to enhance diagnostics and provide real-time feedback to caregivers and patients. Geospatial mapping: Mapping the patient medical record and the health information to their social setting is vital for understanding the underlying social constructs that affect the health of mothers in different regions. PROJECT NARRATIVE Medstar Health Research Institute and Invaryant, Inc. propose the evaluation of a cardiovascular risk assessment tool (HOPE-CAT) for pregnant and postpartum women utilizing technology, data, and social determinants of health (SDoH) with geospatial mapping. HOPE- CAT, in conjunction with Invaryant's health platform and machine learning technologies, will monitor the patient based on signals, out-of-range ""trip-wires"", and trends in health data. HOPE-CAT will be validated on patient medical records using MedStar's Analytics Platform (MAP), a registry of over 5 million unique patients.","Maternal Morbidity and Mortality: Risk Factors, Early Detection and Personalized Intervention",10200448,UL1TR001409,"['Affect', 'Age', 'Assessment tool', 'Behavioral', 'California', 'Cardiac', 'Cardiomyopathies', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Centers for Disease Control and Prevention (U.S.)', 'Complex', 'Computer software', 'Data', 'Database Management Systems', 'Diagnostic', 'Discipline of obstetrics', 'Early Diagnosis', 'Eclampsia', 'Elements', 'Eligibility Determination', 'Epidemiology', 'Evaluation', 'Feedback', 'Gender', 'Grant', 'Health', 'Healthcare Systems', 'Hemorrhage', 'Hospitals', 'Individual', 'Intervention', 'Life Experience', 'Location', 'Machine Learning', 'Maternal Mortality', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Mothers', 'Outcome', 'Patient Monitoring', 'Patients', 'Phase', 'Postpartum Women', 'Pre-Eclampsia', 'Pregnancy', 'Pregnant Women', 'Provider', 'Race', 'Registries', 'Research', 'Research Institute', 'Retrospective Studies', 'Retrospective cohort', 'Risk', 'Risk Assessment', 'Risk Factors', 'Sepsis', 'Signal Transduction', 'Socioeconomic Status', 'Source', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Update', 'Urban Population', 'Woman', 'Women&apos', 's Health', 'advanced analytics', 'base', 'cardiovascular disorder risk', 'cardiovascular risk factor', 'data ingestion', 'ethnic diversity', 'experience', 'health data', 'health of the mother', 'high risk', 'indexing', 'interoperability', 'maternal morbidity', 'maternal risk', 'mortality', 'mortality risk', 'novel', 'patient health information', 'personalized intervention', 'prototype', 'screening', 'social', 'social health determinants', 'sociodemographics', 'socioeconomics', 'success', 'tool', 'trend', 'venous thromboembolism', 'wearable device']",NCATS,GEORGETOWN UNIVERSITY,UL1,2020,146537,0.005177437748175453
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,8309492,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Cations', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Inbreeding', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Normalcy', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2012,333078,0.01757910715616764
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,8119139,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Cations', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Inbreeding', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Normalcy', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2011,333078,0.01757910715616764
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,7902299,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Anus', 'Cations', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Hand', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2010,336442,0.01757910715616764
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,7681324,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Anus', 'Cations', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Hand', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2009,339841,0.01757910715616764
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,7464116,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Anus', 'Cations', 'Class', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Hand', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Range', 'Rate', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Score', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Standards of Weights and Measures', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2008,339841,0.01757910715616764
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7682282,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Other Genetics', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'flexibility', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'non-genetic', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2009,291480,-0.046241122270437106
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7488003,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Disease regression', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Numbers', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Rate', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2008,291480,-0.046241122270437106
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7930715,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Other Genetics', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'flexibility', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'non-genetic', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2010,288566,-0.046241122270437106
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7292731,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Disease regression', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Numbers', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Rate', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2007,297126,-0.046241122270437106
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7146455,R01HG003618,"['clinical research', 'genes', 'genetics', 'human', 'model']",NHGRI,EMORY UNIVERSITY,R01,2006,306000,-0.046241122270437106
"Pathway Commons: Research Resource for Biological Pathways    DESCRIPTION (provided by applicant): Biological pathways represent knowledge about molecules, processes and their interactions, the cellular wiring diagram. Researchers use pathway maps to design and analyze experiments and to make predictions about the behavior of biological systems. Pathway information is, unfortunately, extremely difficult for biologists to use in its current fragmented and incomplete state. We plan to overcome this roadblock to biological research by developing the Pathway Commons Research Resource.      Pathway Commons benefits researchers as a convenient single point of access to diverse biological pathway information translated to a common data language (www.pathwaycommons.org). To provide this service, we will aggregate datasets from many existing pathway databases; translate, store, validate, index, integrate, hyperlink and maintain the information for maximum quality access; freely distribute pathway information to the scientific public, both academic and commercial; and, provide open-source end user software for pathway browsing and analysis. Pathway Commons promotes and supports convergence, by the community, to a truly integrated representation of cellular biological processes.      Using Pathway Commons, biology research groups will be able to quickly find and analyze information about cellular biological processes. Primary database 'groups will be able to share their pathway data, thus increase access, reduce software development and curation costs and avoid duplication of effort. Bioinformatics software developers will be able to increase efficiency by sharing open-source software components.      The completion of the human genome sequence and advances in molecular technologies are driving biology towards increased use of computational tools. Pathway Commons will make biological knowledge available for computational processing and help create predictive computational models of biological processes, which will revolutionize many areas of biology, including health research.              n/a",Pathway Commons: Research Resource for Biological Pathways,8332918,P41HG004118,"['Area', 'Automobile Driving', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cells', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Set', 'Databases', 'Development', 'Future', 'Generations', 'Growth', 'Health', 'Human', 'Human Genome', 'Information Resources', 'Journals', 'Knowledge', 'Language', 'Link', 'Maps', 'Molecular', 'Pathway interactions', 'Process', 'Provider', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Services', 'Source', 'Speed', 'Staging', 'Technology', 'Time', 'Training', 'Translating', 'Vision', 'Work', 'biological research', 'biological systems', 'computerized tools', 'cost', 'data exchange', 'design', 'flexibility', 'genome sequencing', 'indexing', 'information organization', 'open source', 'research study', 'software development']",NHGRI,SLOAN-KETTERING INST CAN RESEARCH,P41,2011,681000,0.009838508144490337
"Pathway Commons: Research Resource for Biological Pathways    DESCRIPTION (provided by applicant): Biological pathways represent knowledge about molecules, processes and their interactions, the cellular wiring diagram. Researchers use pathway maps to design and analyze experiments and to make predictions about the behavior of biological systems. Pathway information is, unfortunately, extremely difficult for biologists to use in its current fragmented and incomplete state. We plan to overcome this roadblock to biological research by developing the Pathway Commons Research Resource.      Pathway Commons benefits researchers as a convenient single point of access to diverse biological pathway information translated to a common data language (www.pathwaycommons.org). To provide this service, we will aggregate datasets from many existing pathway databases; translate, store, validate, index, integrate, hyperlink and maintain the information for maximum quality access; freely distribute pathway information to the scientific public, both academic and commercial; and, provide open-source end user software for pathway browsing and analysis. Pathway Commons promotes and supports convergence, by the community, to a truly integrated representation of cellular biological processes.      Using Pathway Commons, biology research groups will be able to quickly find and analyze information about cellular biological processes. Primary database 'groups will be able to share their pathway data, thus increase access, reduce software development and curation costs and avoid duplication of effort. Bioinformatics software developers will be able to increase efficiency by sharing open-source software components.      The completion of the human genome sequence and advances in molecular technologies are driving biology towards increased use of computational tools. Pathway Commons will make biological knowledge available for computational processing and help create predictive computational models of biological processes, which will revolutionize many areas of biology, including health research.              n/a",Pathway Commons: Research Resource for Biological Pathways,7880780,P41HG004118,"['Area', 'Automobile Driving', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cells', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Set', 'Databases', 'Development', 'Future', 'Generations', 'Growth', 'Health', 'Human', 'Human Genome', 'Information Resources', 'Journals', 'Knowledge', 'Language', 'Link', 'Maps', 'Molecular', 'Pathway interactions', 'Process', 'Provider', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Services', 'Source', 'Speed', 'Staging', 'Technology', 'Time', 'Training', 'Translating', 'Vision', 'Work', 'biological research', 'biological systems', 'computerized tools', 'cost', 'data exchange', 'design', 'flexibility', 'genome sequencing', 'indexing', 'information organization', 'open source', 'research study', 'software development']",NHGRI,SLOAN-KETTERING INST CAN RESEARCH,P41,2010,1050291,0.009838508144490337
"Pathway Commons: Research Resource for Biological Pathways    DESCRIPTION (provided by applicant): Biological pathways represent knowledge about molecules, processes and their interactions, the cellular wiring diagram. Researchers use pathway maps to design and analyze experiments and to make predictions about the behavior of biological systems. Pathway information is, unfortunately, extremely difficult for biologists to use in its current fragmented and incomplete state. We plan to overcome this roadblock to biological research by developing the Pathway Commons Research Resource.      Pathway Commons benefits researchers as a convenient single point of access to diverse biological pathway information translated to a common data language (www.pathwaycommons.org). To provide this service, we will aggregate datasets from many existing pathway databases; translate, store, validate, index, integrate, hyperlink and maintain the information for maximum quality access; freely distribute pathway information to the scientific public, both academic and commercial; and, provide open-source end user software for pathway browsing and analysis. Pathway Commons promotes and supports convergence, by the community, to a truly integrated representation of cellular biological processes.      Using Pathway Commons, biology research groups will be able to quickly find and analyze information about cellular biological processes. Primary database 'groups will be able to share their pathway data, thus increase access, reduce software development and curation costs and avoid duplication of effort. Bioinformatics software developers will be able to increase efficiency by sharing open-source software components.      The completion of the human genome sequence and advances in molecular technologies are driving biology towards increased use of computational tools. Pathway Commons will make biological knowledge available for computational processing and help create predictive computational models of biological processes, which will revolutionize many areas of biology, including health research.              n/a",Pathway Commons: Research Resource for Biological Pathways,7620460,P41HG004118,"['Area', 'Automobile Driving', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cells', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Set', 'Databases', 'Development', 'Future', 'Generations', 'Growth', 'Health', 'Human', 'Human Genome', 'Information Resources', 'Journals', 'Knowledge', 'Language', 'Link', 'Maps', 'Molecular', 'Pathway interactions', 'Process', 'Provider', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Services', 'Source', 'Speed', 'Staging', 'Technology', 'Time', 'Training', 'Translating', 'Vision', 'Work', 'biological research', 'biological systems', 'computerized tools', 'cost', 'data exchange', 'design', 'flexibility', 'genome sequencing', 'indexing', 'information organization', 'open source', 'research study', 'software development']",NHGRI,SLOAN-KETTERING INST CAN RESEARCH,P41,2009,1030000,0.009838508144490337
"Pathway Commons: Research Resource for Biological Pathways    DESCRIPTION (provided by applicant): Biological pathways represent knowledge about molecules, processes and their interactions, the cellular wiring diagram. Researchers use pathway maps to design and analyze experiments and to make predictions about the behavior of biological systems. Pathway information is, unfortunately, extremely difficult for biologists to use in its current fragmented and incomplete state. We plan to overcome this roadblock to biological research by developing the Pathway Commons Research Resource.      Pathway Commons benefits researchers as a convenient single point of access to diverse biological pathway information translated to a common data language (www.pathwaycommons.org). To provide this service, we will aggregate datasets from many existing pathway databases; translate, store, validate, index, integrate, hyperlink and maintain the information for maximum quality access; freely distribute pathway information to the scientific public, both academic and commercial; and, provide open-source end user software for pathway browsing and analysis. Pathway Commons promotes and supports convergence, by the community, to a truly integrated representation of cellular biological processes.      Using Pathway Commons, biology research groups will be able to quickly find and analyze information about cellular biological processes. Primary database 'groups will be able to share their pathway data, thus increase access, reduce software development and curation costs and avoid duplication of effort. Bioinformatics software developers will be able to increase efficiency by sharing open-source software components.      The completion of the human genome sequence and advances in molecular technologies are driving biology towards increased use of computational tools. Pathway Commons will make biological knowledge available for computational processing and help create predictive computational models of biological processes, which will revolutionize many areas of biology, including health research.              n/a",Pathway Commons: Research Resource for Biological Pathways,7301357,P41HG004118,"['Area', 'Automobile Driving', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cells', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Set', 'Databases', 'Development', 'Future', 'Generations', 'Growth', 'Health', 'Human', 'Information Resources', 'Journals', 'Knowledge', 'Language', 'Link', 'Maps', 'Molecular', 'Pathway interactions', 'Process', 'Provider', 'Representations, Knowledge (Computer)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Services', 'Source', 'Speed', 'Staging', 'Standards of Weights and Measures', 'System', 'Technology', 'Time', 'Training', 'Translating', 'Vision', 'Work', 'biological research', 'computerized tools', 'cost', 'design', 'genome sequencing', 'indexing', 'information organization', 'open source', 'research study', 'software development']",NHGRI,SLOAN-KETTERING INST CAN RESEARCH,P41,2008,1000000,0.009838508144490337
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,8323569,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human Gene Mapping', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Play', 'Population', 'Procedures', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2012,380794,0.01604386112793587
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,8147862,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human Gene Mapping', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Play', 'Population', 'Procedures', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2011,380638,0.01604386112793587
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,7903895,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Arts', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human Gene Mapping', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Play', 'Population', 'Procedures', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2010,384328,0.01604386112793587
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,7688619,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Arts', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human Gene Mapping', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Play', 'Population', 'Procedures', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2009,389374,0.01604386112793587
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,7528283,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Arts', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human', 'Human Gene Mapping', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Numbers', 'Play', 'Population', 'Procedures', 'Range', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2008,402542,0.01604386112793587
"A Comprehensive catalog of human DNasel hypersensitive sites The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNasel hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNasel hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5). n/a",A Comprehensive catalog of human DNasel hypersensitive sites,8321717,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Insulator Elements', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Molecular', 'Noise', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Predictive Value', 'Preparation', 'Production', 'Public Domains', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'cost effective', 'density', 'design', 'digital', 'experience', 'functional genomics', 'genome-wide', 'high standard', 'high throughput screening', 'histone modification', 'human tissue', 'in vivo', 'insight', 'meetings', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2011,342218,0.01099744099359495
"A Comprehensive catalog of human DNasel hypersensitive sites The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNasel hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNasel hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5). n/a",A Comprehensive catalog of human DNasel hypersensitive sites,8320051,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Insulator Elements', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Molecular', 'Noise', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Predictive Value', 'Preparation', 'Production', 'Public Domains', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'cost effective', 'density', 'design', 'digital', 'experience', 'functional genomics', 'genome-wide', 'high standard', 'high throughput screening', 'histone modification', 'human tissue', 'in vivo', 'insight', 'meetings', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2011,2615448,0.01099744099359495
"A Comprehensive catalog of human DNasel hypersensitive sites    DESCRIPTION (provided by applicant):   The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNaseI hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNaseI hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5).           n/a",A Comprehensive catalog of human DNasel hypersensitive sites,7410206,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Class', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonuclease I', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Histones', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Modification', 'Molecular', 'Noise', 'Numbers', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Preparation', 'Production', 'Public Domains', 'Range', 'Rate', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Score', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Standards of Weights and Measures', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'density', 'design', 'digital', 'experience', 'functional genomics', 'high throughput screening', 'human tissue', 'in vivo', 'insight', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2007,3114596,0.01099744099359495
"THE ROLE OF THE HAPTIC SYSTEM IN COMMUNICATION The major research effort in this project is directed at the fundamental problem of the processing of complex tactile stimulus patterns in real-time for use as correlates of environmental information by handicapped or normal persons working under a sensory overload. To determine what characteristics of patterns provide reliable and rapidly processed units of information, a computer-controlled vibrotactile matrix has been constructed to permit presentation of a wide variety of frequencies, amplitudes, and time relations of tactile stimuli over a spatial display of 64 independently controlled vibrators.  Present explorations of promising pattern dimensions involve serial presentations of patterns for discrimination and identification, but future work will involve pattern production and modification in dynamic simulated environmental representations.  A variety of basic problems that have appeared as by-products of the main effort also receive attention, viz., threshold and ""loudness"" summation in the presence of multiple contactors, spatial mislocalizations as space-time trade-offs, judgments of texture and distance on the skin, and the influence of mechanical skin characteristics on basic psychophysical functions.   n/a",THE ROLE OF THE HAPTIC SYSTEM IN COMMUNICATION,3393333,R01NS004755,"['artificial intelligence', ' communication disorder aid', ' cutaneous sensory nerve', ' electrophysiology', ' human subject', ' neural information processing', ' paralinguistic behavior', ' person with disability', ' psychophysics', ' sensory thresholds', ' sequential perception', ' somesthesis', ' space perception', ' time perception', ' touch', ' vibration perception']",NINDS,PRINCETON UNIVERSITY,R01,1985,184951,-0.026822123710763705
"EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES We propose to design efficient computer algorithms providing novel and/or        improved methods and software for a number of computational problems in          molecular biology.  The proposal and the principal investigator's current        research efforts are divided into three projects, as follows.                                                                                                     The first project centers on computational problems in the sequencing of         DNA and physical mapping of genomes.  We propose to continue refining our        algorithms and software library for the fragment assembly problem, i.e.,         determining the most likely complete DNA sequence consistent with                electrophoresis data gathered from cloned fragments.  The refinements            consist of improved algorithms for all phases of the computation: ultra-         rapid overlap detection, assembly in the presence of constraints modeling        additional experimental information, a formulation of the problem that           correctly handles repetitive sequence, and a multi-alignment component           that accommodates base-calling quality figures.  We also propose work on         ordered shotgun sequencing (OSS) and a cDNA database for the data being          generated at Washington University under contract to Merck.  Lastly, there       is much similarity between fragment assembly and physical mapping, save          that the relative level of experimental error is higher.  We propose an          algorithm for STS content mapping based on rules-of-inference that are           true with very high probability.                                                                                                                                  The second project is to design better algorithms for a number of                computational problems arising in molecular biology.  Progress in this           arena tends to be inspired rather than calculated.  We demonstrate our           track record of producing interesting results and then describe the              following problems for which we have a number of ideas and preliminary           results: sublinear Smith-Waterman database searches, determining                 restriction maps from digest data, grammar-based pattern matching,               selecting PCR primers, predicting RNA secondary structure, and docking           rigid molecules (3D matching).                                                                                                                                    The final project involves the introduction into our funded research             activities of a new area, molecular graphics.  Earlier, we developed             MacMolecule 1.7 which rendered space-filling, ball-and-stock, and wire-          frame views of molecules.  We estimate 10,000 copies are currently in use        around the world.  Our aim is high-speed, high-quality graphics, on low-         end machines achieved by virtue of very efficient rendering algorithms.          We have begun to develop a new version of MacMolecule, called Linus 2.0,         which will deliver superior performance and visualizations along with            greater capabilities, including ribbon renderings of protein secondary           structure, zoom, hi-lighting, picking, and additional visualization modes.       We further propose to build a helper application supporting ""Linus""              content files so that Linus may be used with the World-Wide Web.  In             further years, we will support molecular animation, construction, and            possibly dynamics.                                                                n/a",EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES,2635404,R01LM004960,"['Internet', ' artificial intelligence', ' computer assisted sequence analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' nucleic acid sequence', ' protein sequence']",NLM,UNIVERSITY OF ARIZONA,R01,1998,157399,0.000847919682127408
"EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES We propose to design efficient computer algorithms providing novel and/or        improved methods and software for a number of computational problems in          molecular biology.  The proposal and the principal investigator's current        research efforts are divided into three projects, as follows.                                                                                                     The first project centers on computational problems in the sequencing of         DNA and physical mapping of genomes.  We propose to continue refining our        algorithms and software library for the fragment assembly problem, i.e.,         determining the most likely complete DNA sequence consistent with                electrophoresis data gathered from cloned fragments.  The refinements            consist of improved algorithms for all phases of the computation: ultra-         rapid overlap detection, assembly in the presence of constraints modeling        additional experimental information, a formulation of the problem that           correctly handles repetitive sequence, and a multi-alignment component           that accommodates base-calling quality figures.  We also propose work on         ordered shotgun sequencing (OSS) and a cDNA database for the data being          generated at Washington University under contract to Merck.  Lastly, there       is much similarity between fragment assembly and physical mapping, save          that the relative level of experimental error is higher.  We propose an          algorithm for STS content mapping based on rules-of-inference that are           true with very high probability.                                                                                                                                  The second project is to design better algorithms for a number of                computational problems arising in molecular biology.  Progress in this           arena tends to be inspired rather than calculated.  We demonstrate our           track record of producing interesting results and then describe the              following problems for which we have a number of ideas and preliminary           results: sublinear Smith-Waterman database searches, determining                 restriction maps from digest data, grammar-based pattern matching,               selecting PCR primers, predicting RNA secondary structure, and docking           rigid molecules (3D matching).                                                                                                                                    The final project involves the introduction into our funded research             activities of a new area, molecular graphics.  Earlier, we developed             MacMolecule 1.7 which rendered space-filling, ball-and-stock, and wire-          frame views of molecules.  We estimate 10,000 copies are currently in use        around the world.  Our aim is high-speed, high-quality graphics, on low-         end machines achieved by virtue of very efficient rendering algorithms.          We have begun to develop a new version of MacMolecule, called Linus 2.0,         which will deliver superior performance and visualizations along with            greater capabilities, including ribbon renderings of protein secondary           structure, zoom, hi-lighting, picking, and additional visualization modes.       We further propose to build a helper application supporting ""Linus""              content files so that Linus may be used with the World-Wide Web.  In             further years, we will support molecular animation, construction, and            possibly dynamics.                                                                n/a",EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES,2032335,R01LM004960,"['Internet', ' artificial intelligence', ' computer assisted sequence analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' nucleic acid sequence', ' protein sequence']",NLM,UNIVERSITY OF ARIZONA,R01,1997,157056,0.000847919682127408
"EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES We propose to design efficient computer algorithms providing novel and/or  improved methods and software for a number of computational problems in  molecular biology.  the emphasis will b eon blending theoretical results  with practical concerns.  All software emerging from the project will be  made available free of charge.  The proposal and the principal  investigator's current research efforts are divided into three projects.    The first project centers on computational problems in the physical mapping  and sequencing of DNA.  We propose to continue refining a software system  for the fragment assembly problem, i.e., determine the most likely complete  DNA sequence consistent with electrophoresis data gathered from cloned  fragments.  The refinements consist of improved algorithms for a number of  the phases of the computation, expanding the functionality to support user-  interaction, and developing a complete environment to support megabase  sequencing projects.  The methods we developed for fragment assembly also  apply in large part to the problem of determining physical maps via various  fingerprinting techniques.  We have formulated a generalized assembly  problem and plan to build a system that is capable of solving such problems  for any combination of restriction map, digest, and hybridization  information about the clones.    The second project is to design algorithms for a number of computational  problems arising in molecular biology.  Progress in this arena tends to be  inspired rather than calculated.  We demonstrate our track record of  producing interesting results and then describe the following problems for  which we have a number of ideas and preliminary results:  sublinear  similarity searches, restriction map comparison, super pattern matching  (gene recognition), determining restriction maps from digest data,  designing oligonucleotide probes, and RNA secondary structure prediction.    The objective of the last project is to develop a pattern matching system  permitting the expression of complex patterns and their reduction to  efficient search strategies.  The pattern specification language is simple  yet powerful enough to succinctly express the most complex patterns of  biological interest.  An ""expert system"" compiler for the language will  examine a pattern and will choose a search strategy or combination of  strategies from a built-in library of basic search techniques.  The build-  in library will contain implementations of the best available search  algorithms for exact and approximate matches to keywords, repeats, and  regular expressions.  Using a dynamic-programming style calculation the  expert compiler chooses the optimal backtracking strategy over the basic  library searches.  We have proven the efficacy of this approach on a small  prototype for a subset of the language that is useful for specifying  protein motifs.  We now propose to embark upon the construction of a  complete system.  n/a",EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES,2237672,R01LM004960,"['artificial intelligence', ' computer assisted sequence analysis', ' computer data analysis', ' computer program /software', ' information retrieval', ' nucleic acid sequence']",NLM,UNIVERSITY OF ARIZONA,R01,1995,143074,0.00713030670310931
"EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES We propose to design efficient computer algorithms providing novel and/or improved methods and software for a number of computational problems in molecular biology.  the emphasis will b eon blending theoretical results with practical concerns.  All software emerging from the project will be made available free of charge.  The proposal and the principal investigator's current research efforts are divided into three projects.  The first project centers on computational problems in the physical mapping and sequencing of DNA.  We propose to continue refining a software system for the fragment assembly problem, i.e., determine the most likely complete DNA sequence consistent with electrophoresis data gathered from cloned fragments.  The refinements consist of improved algorithms for a number of the phases of the computation, expanding the functionality to support user- interaction, and developing a complete environment to support megabase sequencing projects.  The methods we developed for fragment assembly also apply in large part to the problem of determining physical maps via various fingerprinting techniques.  We have formulated a generalized assembly problem and plan to build a system that is capable of solving such problems for any combination of restriction map, digest, and hybridization information about the clones.  The second project is to design algorithms for a number of computational problems arising in molecular biology.  Progress in this arena tends to be inspired rather than calculated.  We demonstrate our track record of producing interesting results and then describe the following problems for which we have a number of ideas and preliminary results:  sublinear similarity searches, restriction map comparison, super pattern matching (gene recognition), determining restriction maps from digest data, designing oligonucleotide probes, and RNA secondary structure prediction.  The objective of the last project is to develop a pattern matching system permitting the expression of complex patterns and their reduction to efficient search strategies.  The pattern specification language is simple yet powerful enough to succinctly express the most complex patterns of biological interest.  An ""expert system"" compiler for the language will examine a pattern and will choose a search strategy or combination of strategies from a built-in library of basic search techniques.  The build- in library will contain implementations of the best available search algorithms for exact and approximate matches to keywords, repeats, and regular expressions.  Using a dynamic-programming style calculation the expert compiler chooses the optimal backtracking strategy over the basic library searches.  We have proven the efficacy of this approach on a small prototype for a subset of the language that is useful for specifying protein motifs.  We now propose to embark upon the construction of a complete system.  n/a",EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES,2237671,R01LM004960,"['artificial intelligence', ' computer assisted sequence analysis', ' computer data analysis', ' computer program /software', ' information retrieval', ' nucleic acid sequence']",NLM,UNIVERSITY OF ARIZONA,R01,1994,140854,0.00713030670310931
"EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES We propose to design efficient computer algorithms providing novel and/or improved methods and software for a number of computational problems in molecular biology.  the emphasis will b eon blending theoretical results with practical concerns.  All software emerging from the project will be made available free of charge.  The proposal and the principal investigator's current research efforts are divided into three projects.  The first project centers on computational problems in the physical mapping and sequencing of DNA.  We propose to continue refining a software system for the fragment assembly problem, i.e., determine the most likely complete DNA sequence consistent with electrophoresis data gathered from cloned fragments.  The refinements consist of improved algorithms for a number of the phases of the computation, expanding the functionality to support user- interaction, and developing a complete environment to support megabase sequencing projects.  The methods we developed for fragment assembly also apply in large part to the problem of determining physical maps via various fingerprinting techniques.  We have formulated a generalized assembly problem and plan to build a system that is capable of solving such problems for any combination of restriction map, digest, and hybridization information about the clones.  The second project is to design algorithms for a number of computational problems arising in molecular biology.  Progress in this arena tends to be inspired rather than calculated.  We demonstrate our track record of producing interesting results and then describe the following problems for which we have a number of ideas and preliminary results:  sublinear similarity searches, restriction map comparison, super pattern matching (gene recognition), determining restriction maps from digest data, designing oligonucleotide probes, and RNA secondary structure prediction.  The objective of the last project is to develop a pattern matching system permitting the expression of complex patterns and their reduction to efficient search strategies.  The pattern specification language is simple yet powerful enough to succinctly express the most complex patterns of biological interest.  An ""expert system"" compiler for the language will examine a pattern and will choose a search strategy or combination of strategies from a built-in library of basic search techniques.  The build- in library will contain implementations of the best available search algorithms for exact and approximate matches to keywords, repeats, and regular expressions.  Using a dynamic-programming style calculation the expert compiler chooses the optimal backtracking strategy over the basic library searches.  We have proven the efficacy of this approach on a small prototype for a subset of the language that is useful for specifying protein motifs.  We now propose to embark upon the construction of a complete system.  n/a",EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES,3374075,R01LM004960,"['artificial intelligence', ' computer assisted sequence analysis', ' computer data analysis', ' computer program /software', ' information retrieval', ' nucleic acid sequence']",NLM,UNIVERSITY OF ARIZONA,R01,1993,135752,0.00713030670310931
"EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES We propose to design efficient computer algorithms providing novel and/or improved methods and software for a number of computational problems in molecular biology.  the emphasis will b eon blending theoretical results with practical concerns.  All software emerging from the project will be made available free of charge.  The proposal and the principal investigator's current research efforts are divided into three projects.  The first project centers on computational problems in the physical mapping and sequencing of DNA.  We propose to continue refining a software system for the fragment assembly problem, i.e., determine the most likely complete DNA sequence consistent with electrophoresis data gathered from cloned fragments.  The refinements consist of improved algorithms for a number of the phases of the computation, expanding the functionality to support user- interaction, and developing a complete environment to support megabase sequencing projects.  The methods we developed for fragment assembly also apply in large part to the problem of determining physical maps via various fingerprinting techniques.  We have formulated a generalized assembly problem and plan to build a system that is capable of solving such problems for any combination of restriction map, digest, and hybridization information about the clones.  The second project is to design algorithms for a number of computational problems arising in molecular biology.  Progress in this arena tends to be inspired rather than calculated.  We demonstrate our track record of producing interesting results and then describe the following problems for which we have a number of ideas and preliminary results:  sublinear similarity searches, restriction map comparison, super pattern matching (gene recognition), determining restriction maps from digest data, designing oligonucleotide probes, and RNA secondary structure prediction.  The objective of the last project is to develop a pattern matching system permitting the expression of complex patterns and their reduction to efficient search strategies.  The pattern specification language is simple yet powerful enough to succinctly express the most complex patterns of biological interest.  An ""expert system"" compiler for the language will examine a pattern and will choose a search strategy or combination of strategies from a built-in library of basic search techniques.  The build- in library will contain implementations of the best available search algorithms for exact and approximate matches to keywords, repeats, and regular expressions.  Using a dynamic-programming style calculation the expert compiler chooses the optimal backtracking strategy over the basic library searches.  We have proven the efficacy of this approach on a small prototype for a subset of the language that is useful for specifying protein motifs.  We now propose to embark upon the construction of a complete system.  n/a",EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES,3374072,R01LM004960,"['artificial intelligence', ' computer assisted sequence analysis', ' computer data analysis', ' computer program /software', ' information retrieval']",NLM,UNIVERSITY OF ARIZONA,R01,1992,130435,0.00713030670310931
"Statistical methods for assessing copy number variation in SNP arrays Copy number variants (CNV) are common and can be measured on a genomic scale using high throughput  genotyping platforms. However, copy number estimates from existing algorithms are often inaccurate and  imprecise. During the mentored phase of this Award, first generation algorithms for the locus-level estimation  of copy number and hidden Markov models to identify regions of copy number gain and loss were  developed. During the ROO phase these algorithms will be further improved by generalizations that broaden  the scope of the problems and final versions of open source software.  Specific methodologic areas areas that will be targeted during the ROO phase of this Award include improved  estimates of uncertainty that distinguish between outliers and CNV and statistical models that 'borrowstrength'  across loci and across samples. In parallel with the development of these methods, we will explore  new approaches for CNV-phenotype inference that accommodate features of the study design (e.g.,  unrelated subjects versus case-parent trios) and biological characteristics of the disease. For instance, we  expect that extensions of segmentation methods and principal component analysis will benefit the study of  cancer genomes.  Activities during the K99 phase of this Award will be helpful for achieving these goals. First, 1 successfully  identified a tenure-track faculty position at the rank of Assistant Professor. Faculty in the Department of  Oncology are supportive of the development of these methods. Secondly, I developed new collaborations  during the K99 phase that will spur the development of statistical methods in the above areas. Finally, I  participated in workshops, statistical conferences, and completed coursework in subject-relevant areas that  will be helpful as I transition to the independent phase. I look forward to competing for R01 funding  opportunities as new technologies and applications for genomic research emerge. Approximately 10% of the genome is thought to be variable in copy number. Statistical approaches to  measure this variation on a genomic scale and assess its contribution to physical traits are needed.",Statistical methods for assessing copy number variation in SNP arrays,8258323,R00HG005015,"['Algorithms', 'Area', 'Award', 'Biologic Characteristic', 'Chromosome abnormality', 'Chromosomes', 'Collaborations', 'Computer software', 'Copy Number Polymorphism', 'DNA', 'Development', 'Disease', 'Educational workshop', 'Environment', 'Faculty', 'Family', 'Funding Opportunities', 'Generations', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Individual', 'Link', 'Measures', 'Mentors', 'Methods', 'Parents', 'Phase', 'Phenotype', 'Positioning Attribute', 'Principal Component Analysis', 'Research', 'Research Design', 'Sampling', 'Single Nucleotide Polymorphism', 'Somatic Cell', 'Statistical Methods', 'Statistical Models', 'Uncertainty', 'Variant', 'Weight', 'cancer genome', 'density', 'dosage', 'improved', 'markov model', 'method development', 'new technology', 'novel', 'novel strategies', 'oncology', 'open source', 'professor', 'symposium', 'tool', 'trait']",NHGRI,JOHNS HOPKINS UNIVERSITY,R00,2012,242663,-0.05347602252705973
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,8280356,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2012,218662,-0.06687040894518433
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,8133157,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2011,218724,-0.06687040894518433
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,7887777,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2010,273884,-0.06687040894518433
"FAST BROWSING OF PACS IMAGE ARCHIVE VIA NETWORK THIS IS A SHANNON AWARD PROVIDING PARTIAL SUPPORT FOR THE RESEARCH               PROJECTS THAT FALL SHORT OF THE ASSIGNED INSTITUTE'S FUNDING RANGE BUT           ARE IN THE MARGIN OF EXCELLENCE. THE SHANNON AWARD IS INTENDED TO PROVIDE        SUPPORT TO TEST THE FEASIBILITY OF THE APPROACH; DEVELOP FURTHER TESTS           AND REFINE RESEARCH TECHNIQUES; PERFORM SECONDARY ANALYSIS OR AVAILABLE          DATA SETS; OR CONDUCT DISCRETE PROJECTS THAT CAN DEMONSTRATE THE PI'S            RESEARCH CAPABILITIES OR LEND ADDITIONAL WEIGHT TO AN ALREADY MERITORIOUS        APPLICATION. THE ABSTRACT BELOW IS TAKEN FROM THE ORIGINAL DOCUMENT              SUBMITTED BY THE PRINCIPAL INVESTIGATOR.                                                                                                                          DESCRIPTION:  (adapted from the application abstract)  The advent of             large  picture archiving and communication systems (PACS) will likely            result in a  conversion of clinical radiology to become nearly completely        digital. Improved methods for access to a large collection of on-line            image data can  improve medical research and education.  Although the            techniques for fast text  search are well established, similar tool              development for rapidly searching  through years of digitally archived           images is still in its infancy. Development of a fast browsing technology        for retrieving archived images over  a network, both local and remote            (international) accesses is proposed.                                                                                                                             In this project, three key technologies will be merged:  smart query,            hierarchical archive, and photo indexing using embedded  zerotree wavelet        transform (EZTWT) code.  The first two technologies provides query               constraint  and automatic image migration management, and are supported          in other PACS- related projects at UCLA.  The third and newest component,        EZTWT, is an  encoding method designed for maximum network utility,              providing the receiver  highest image quality for a given transmission           time.  The implications for  high-performance teleradiology under                bandwidth limitations are significant.  Diagnostic viewing can start             before transmission of an image in full resolution and quality is                complete.  This encoding scheme will be modified to  allow variable size         iconic representation of the original, achieving minimum  network delay          and fast reconstruction, thus making browsing through a larger  selection        of images convenient and manageable.                                                                                                                              In addition, the modified EZTWT can achieve high efficiency for images           with  clearly separated anatomical and background regions.  The space            saving in very  high resolution radiographs, such as mammograms, can be          typically 7MB per  4Kx4K image (44%) without loss in anatomical                  information.  This coding  technique will be tested in conjunction with          new pattern recognition techniques to achieve efficient mammogram storage        and telecommunication.                                                            n/a",FAST BROWSING OF PACS IMAGE ARCHIVE VIA NETWORK,2329566,R55LM005712,"['abstracting', ' archives', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer assisted instruction', ' computer graphics /printing', ' digital imaging', ' informatics', ' online computer', ' radiology', ' telemedicine']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R55,1996,100000,0.010860945199645478
"LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE The long-term objective of our research group is to facilitate automatic         or semi-automatic classification and retrieval of natural language texts,        in support of reducing the cost and improving the quality of computerized        medical information. This proposal develops further and applies a novel          approach, the Linear Least Squares Fit (LLSF) mapping, to document               indexing and document retrieval of the MEDLINE database. LLSF mapping is         a statistical method developed by the PI for learning human knowledge            about matching queries, documents, and canonical concepts. The goal is to        improve the quality (recall and precision) of automatic document indexing        and retrieval, which cannot be achieved by surface-based matching without        using human knowledge or thesaurus-based matching dependent on manually          developed synonyms. This project applies LLSF to MEDLINE, the world's            largest and most frequently used on-line database, to evaluate the               effectiveness of this method and to explore the practical potential on           large scale databases. The specific aims and methods are:                                                                                                         l. To collect data needed for the training and evaluation of the LLSF            method. A collaboration with another research institute is planned for           utilizing and refining a large collection of MEDLINE retrieval data. A           sampling of MEDLINE searches at the Mayo Clinic will be employed for             obtaining additional tasks.                                                                                                                                       2. To develop automatic noise reduction techniques for improving both the        accuracy of the LLSF mapping and the efficiency of the computation. A            multi-step noise reduction in the training process of LLSF will be               investigated, including a statistical term weighting for the removal of          non-informative terms, a truncated singular value decomposition (SVD) for        reducing the noise at the semantic structure level, and the truncation of        insignificant elements in the LLSF solution matrix for noise-reduction at        the level of term-to-concept mapping.                                                                                                                             3. To scale-up the training capacity for enabling the LLSF to accommodate        the large size of MEDLINE data. A split-merge approach decomposes a large        training sample into tractable subsets, computes an LLSF mapping function        for each subset, and then merges the lcal mapping functions into a global        one.                                                                                                                                                              4. To improve the computational efficiency by employing algorithms               optimized for sparse matrices and for noise reduction. The potential             solutions include the Block Lanczos truncated SVD algorithm which can            reduce the cubic time complexity of standard SVD (on dense matrices) to a        quadratic complexity, a QR decomposition which solves the LLSF without           SVD, a sparse matrix algorithm which has shown a speed-up in matrix              multiplication and cosine computation by a factor of l to 4 magnitudes,          and parallel computing.                                                                                                                                           5. To evaluate the effectiveness of LLSF on large MEDLINE document sets          and compare with the performance of alternate indexing/retrieval systems.         n/a",LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE,2897374,R29LM005714,"['computer program /software', ' data collection methodology /evaluation', ' indexing', ' information retrieval', ' information systems', ' semantics', ' statistics /biometry', ' vocabulary development for information system']",NLM,CARNEGIE-MELLON UNIVERSITY,R29,1999,103033,0.04325780874934245
"LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE The long-term objective of our research group is to facilitate automatic         or semi-automatic classification and retrieval of natural language texts,        in support of reducing the cost and improving the quality of computerized        medical information. This proposal develops further and applies a novel          approach, the Linear Least Squares Fit (LLSF) mapping, to document               indexing and document retrieval of the MEDLINE database. LLSF mapping is         a statistical method developed by the PI for learning human knowledge            about matching queries, documents, and canonical concepts. The goal is to        improve the quality (recall and precision) of automatic document indexing        and retrieval, which cannot be achieved by surface-based matching without        using human knowledge or thesaurus-based matching dependent on manually          developed synonyms. This project applies LLSF to MEDLINE, the world's            largest and most frequently used on-line database, to evaluate the               effectiveness of this method and to explore the practical potential on           large scale databases. The specific aims and methods are:                                                                                                         l. To collect data needed for the training and evaluation of the LLSF            method. A collaboration with another research institute is planned for           utilizing and refining a large collection of MEDLINE retrieval data. A           sampling of MEDLINE searches at the Mayo Clinic will be employed for             obtaining additional tasks.                                                                                                                                       2. To develop automatic noise reduction techniques for improving both the        accuracy of the LLSF mapping and the efficiency of the computation. A            multi-step noise reduction in the training process of LLSF will be               investigated, including a statistical term weighting for the removal of          non-informative terms, a truncated singular value decomposition (SVD) for        reducing the noise at the semantic structure level, and the truncation of        insignificant elements in the LLSF solution matrix for noise-reduction at        the level of term-to-concept mapping.                                                                                                                             3. To scale-up the training capacity for enabling the LLSF to accommodate        the large size of MEDLINE data. A split-merge approach decomposes a large        training sample into tractable subsets, computes an LLSF mapping function        for each subset, and then merges the lcal mapping functions into a global        one.                                                                                                                                                              4. To improve the computational efficiency by employing algorithms               optimized for sparse matrices and for noise reduction. The potential             solutions include the Block Lanczos truncated SVD algorithm which can            reduce the cubic time complexity of standard SVD (on dense matrices) to a        quadratic complexity, a QR decomposition which solves the LLSF without           SVD, a sparse matrix algorithm which has shown a speed-up in matrix              multiplication and cosine computation by a factor of l to 4 magnitudes,          and parallel computing.                                                                                                                                           5. To evaluate the effectiveness of LLSF on large MEDLINE document sets          and compare with the performance of alternate indexing/retrieval systems.         n/a",LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE,2685564,R29LM005714,"['computer program /software', ' data collection methodology /evaluation', ' indexing', ' information retrieval', ' information systems', ' semantics', ' statistics /biometry', ' vocabulary development for information system']",NLM,CARNEGIE-MELLON UNIVERSITY,R29,1998,99071,0.04325780874934245
"LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE The long-term objective of our research group is to facilitate automatic         or semi-automatic classification and retrieval of natural language texts,        in support of reducing the cost and improving the quality of computerized        medical information. This proposal develops further and applies a novel          approach, the Linear Least Squares Fit (LLSF) mapping, to document               indexing and document retrieval of the MEDLINE database. LLSF mapping is         a statistical method developed by the PI for learning human knowledge            about matching queries, documents, and canonical concepts. The goal is to        improve the quality (recall and precision) of automatic document indexing        and retrieval, which cannot be achieved by surface-based matching without        using human knowledge or thesaurus-based matching dependent on manually          developed synonyms. This project applies LLSF to MEDLINE, the world's            largest and most frequently used on-line database, to evaluate the               effectiveness of this method and to explore the practical potential on           large scale databases. The specific aims and methods are:                                                                                                         l. To collect data needed for the training and evaluation of the LLSF            method. A collaboration with another research institute is planned for           utilizing and refining a large collection of MEDLINE retrieval data. A           sampling of MEDLINE searches at the Mayo Clinic will be employed for             obtaining additional tasks.                                                                                                                                       2. To develop automatic noise reduction techniques for improving both the        accuracy of the LLSF mapping and the efficiency of the computation. A            multi-step noise reduction in the training process of LLSF will be               investigated, including a statistical term weighting for the removal of          non-informative terms, a truncated singular value decomposition (SVD) for        reducing the noise at the semantic structure level, and the truncation of        insignificant elements in the LLSF solution matrix for noise-reduction at        the level of term-to-concept mapping.                                                                                                                             3. To scale-up the training capacity for enabling the LLSF to accommodate        the large size of MEDLINE data. A split-merge approach decomposes a large        training sample into tractable subsets, computes an LLSF mapping function        for each subset, and then merges the lcal mapping functions into a global        one.                                                                                                                                                              4. To improve the computational efficiency by employing algorithms               optimized for sparse matrices and for noise reduction. The potential             solutions include the Block Lanczos truncated SVD algorithm which can            reduce the cubic time complexity of standard SVD (on dense matrices) to a        quadratic complexity, a QR decomposition which solves the LLSF without           SVD, a sparse matrix algorithm which has shown a speed-up in matrix              multiplication and cosine computation by a factor of l to 4 magnitudes,          and parallel computing.                                                                                                                                           5. To evaluate the effectiveness of LLSF on large MEDLINE document sets          and compare with the performance of alternate indexing/retrieval systems.         n/a",LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE,2392815,R29LM005714,"['computer program /software', ' data collection methodology /evaluation', ' indexing', ' information retrieval', ' information systems', ' semantics', ' statistics /biometry', ' vocabulary development for information system']",NLM,CARNEGIE-MELLON UNIVERSITY,R29,1997,95259,0.04325780874934245
"LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE The long-term objective of our research group is to facilitate automatic  or semi-automatic classification and retrieval of natural language texts,  in support of reducing the cost and improving the quality of computerized  medical information. This proposal develops further and applies a novel  approach, the Linear Least Squares Fit (LLSF) mapping, to document  indexing and document retrieval of the MEDLINE database. LLSF mapping is  a statistical method developed by the PI for learning human knowledge  about matching queries, documents, and canonical concepts. The goal is to  improve the quality (recall and precision) of automatic document indexing  and retrieval, which cannot be achieved by surface-based matching without  using human knowledge or thesaurus-based matching dependent on manually  developed synonyms. This project applies LLSF to MEDLINE, the world's  largest and most frequently used on-line database, to evaluate the  effectiveness of this method and to explore the practical potential on  large scale databases. The specific aims and methods are:    l. To collect data needed for the training and evaluation of the LLSF  method. A collaboration with another research institute is planned for  utilizing and refining a large collection of MEDLINE retrieval data. A  sampling of MEDLINE searches at the Mayo Clinic will be employed for  obtaining additional tasks.    2. To develop automatic noise reduction techniques for improving both the  accuracy of the LLSF mapping and the efficiency of the computation. A  multi-step noise reduction in the training process of LLSF will be  investigated, including a statistical term weighting for the removal of  non-informative terms, a truncated singular value decomposition (SVD) for  reducing the noise at the semantic structure level, and the truncation of  insignificant elements in the LLSF solution matrix for noise-reduction at  the level of term-to-concept mapping.    3. To scale-up the training capacity for enabling the LLSF to accommodate  the large size of MEDLINE data. A split-merge approach decomposes a large  training sample into tractable subsets, computes an LLSF mapping function  for each subset, and then merges the lcal mapping functions into a global  one.    4. To improve the computational efficiency by employing algorithms  optimized for sparse matrices and for noise reduction. The potential  solutions include the Block Lanczos truncated SVD algorithm which can  reduce the cubic time complexity of standard SVD (on dense matrices) to a  quadratic complexity, a QR decomposition which solves the LLSF without  SVD, a sparse matrix algorithm which has shown a speed-up in matrix  multiplication and cosine computation by a factor of l to 4 magnitudes,  and parallel computing.    5. To evaluate the effectiveness of LLSF on large MEDLINE document sets  and compare with the performance of alternate indexing/retrieval systems.  n/a",LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE,2238093,R29LM005714,"['computer program /software', ' data collection methodology /evaluation', ' indexing', ' information retrieval', ' information systems', ' semantics', ' statistics /biometry', ' vocabulary development for information system']",NLM,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R29,1995,120129,0.04325780874934245
"STRUCTURE BASED VISUAL ACCESS TO BIOMEDICAL INFORMATION DESCRIPTION (Taken from application abstract):  The long term goal of the        work described in this proposal is to develop on-line combined spatial and       symbolic methods for representing, storing, retrieving and visualizing           anatomical information, both as a means for understanding human biological       structure, and as a visual gateway into the rapidly increasing array of          on-line text-based information sources in biomedicine.  In this proposal we      will address some of the fundamental problems involved in combining spatial      and symbolic anatomic information, and will test solutions to these problems     in a World Wide Web based 3-D anatomy information system for the thoracic        viscera.  Clinicians, researchers and students will be able to use this          system to retrieve specific anatomic knowledge, in the form of                   dynamically-generated interactive 3-D scenes and corresponding symbolic          information, without the need to consult hard copy atlases or to navigate        through irrelevant computer-based images before finding the needed               information.  In order to build this system we will need to address              fundamental problems in spatial modeling, organization of these models in a      knowledge based spatial database system, and access to the models via an         on-line user interface and spatial query processor.  The specific aims for       this proposal are:  1) develop a knowledge base that organizes and               integrates spatial and symbolic models of anatomy, 2) implement an anatomy       information system that combines knowledge-based spatial and symbolic            retrieval with dynamically generated 3-D scenes, 3) develop methods for          smoothly rendering and interacting with the scene in real-time, and 4)           evaluate the system by integrating other spatial data and by providing it to     anatomy medical students and radiation treatment planners.  Accomplishment       of these aims will lead to a useful information system for the anatomy of        the thoracic viscera that can be enhanced with new technology such as high       performance graphics and virtual reality.  Moreover, the information             framework and methods we establish in this project will be generalizable not     only to gross anatomy in different regions of the body and to different          anatomical databases, but also to the management of structural information       pertaining to cellular and molecular biology, as well as developmental and       neurobiology.                                                                     n/a",STRUCTURE BASED VISUAL ACCESS TO BIOMEDICAL INFORMATION,2897386,R01LM006316,"['DVD /CD ROM', ' anatomy', ' artificial intelligence', ' computer human interaction', ' computer system design /evaluation', ' information retrieval', ' information systems']",NLM,UNIVERSITY OF WASHINGTON,R01,1999,296940,0.020480588488132723
"STRUCTURE BASED VISUAL ACCESS TO BIOMEDICAL INFORMATION DESCRIPTION (Taken from application abstract):  The long term goal of the        work described in this proposal is to develop on-line combined spatial and       symbolic methods for representing, storing, retrieving and visualizing           anatomical information, both as a means for understanding human biological       structure, and as a visual gateway into the rapidly increasing array of          on-line text-based information sources in biomedicine.  In this proposal we      will address some of the fundamental problems involved in combining spatial      and symbolic anatomic information, and will test solutions to these problems     in a World Wide Web based 3-D anatomy information system for the thoracic        viscera.  Clinicians, researchers and students will be able to use this          system to retrieve specific anatomic knowledge, in the form of                   dynamically-generated interactive 3-D scenes and corresponding symbolic          information, without the need to consult hard copy atlases or to navigate        through irrelevant computer-based images before finding the needed               information.  In order to build this system we will need to address              fundamental problems in spatial modeling, organization of these models in a      knowledge based spatial database system, and access to the models via an         on-line user interface and spatial query processor.  The specific aims for       this proposal are:  1) develop a knowledge base that organizes and               integrates spatial and symbolic models of anatomy, 2) implement an anatomy       information system that combines knowledge-based spatial and symbolic            retrieval with dynamically generated 3-D scenes, 3) develop methods for          smoothly rendering and interacting with the scene in real-time, and 4)           evaluate the system by integrating other spatial data and by providing it to     anatomy medical students and radiation treatment planners.  Accomplishment       of these aims will lead to a useful information system for the anatomy of        the thoracic viscera that can be enhanced with new technology such as high       performance graphics and virtual reality.  Moreover, the information             framework and methods we establish in this project will be generalizable not     only to gross anatomy in different regions of the body and to different          anatomical databases, but also to the management of structural information       pertaining to cellular and molecular biology, as well as developmental and       neurobiology.                                                                     n/a",STRUCTURE BASED VISUAL ACCESS TO BIOMEDICAL INFORMATION,2702873,R01LM006316,"['DVD /CD ROM', ' anatomy', ' artificial intelligence', ' computer human interaction', ' computer system design /evaluation', ' information retrieval', ' information systems']",NLM,UNIVERSITY OF WASHINGTON,R01,1998,296107,0.020480588488132723
"STRUCTURE BASED VISUAL ACCESS TO BIOMEDICAL INFORMATION DESCRIPTION (Taken from application abstract):  The long term goal of the        work described in this proposal is to develop on-line combined spatial and       symbolic methods for representing, storing, retrieving and visualizing           anatomical information, both as a means for understanding human biological       structure, and as a visual gateway into the rapidly increasing array of          on-line text-based information sources in biomedicine.  In this proposal we      will address some of the fundamental problems involved in combining spatial      and symbolic anatomic information, and will test solutions to these problems     in a World Wide Web based 3-D anatomy information system for the thoracic        viscera.  Clinicians, researchers and students will be able to use this          system to retrieve specific anatomic knowledge, in the form of                   dynamically-generated interactive 3-D scenes and corresponding symbolic          information, without the need to consult hard copy atlases or to navigate        through irrelevant computer-based images before finding the needed               information.  In order to build this system we will need to address              fundamental problems in spatial modeling, organization of these models in a      knowledge based spatial database system, and access to the models via an         on-line user interface and spatial query processor.  The specific aims for       this proposal are:  1) develop a knowledge base that organizes and               integrates spatial and symbolic models of anatomy, 2) implement an anatomy       information system that combines knowledge-based spatial and symbolic            retrieval with dynamically generated 3-D scenes, 3) develop methods for          smoothly rendering and interacting with the scene in real-time, and 4)           evaluate the system by integrating other spatial data and by providing it to     anatomy medical students and radiation treatment planners.  Accomplishment       of these aims will lead to a useful information system for the anatomy of        the thoracic viscera that can be enhanced with new technology such as high       performance graphics and virtual reality.  Moreover, the information             framework and methods we establish in this project will be generalizable not     only to gross anatomy in different regions of the body and to different          anatomical databases, but also to the management of structural information       pertaining to cellular and molecular biology, as well as developmental and       neurobiology.                                                                     n/a",STRUCTURE BASED VISUAL ACCESS TO BIOMEDICAL INFORMATION,2032431,R01LM006316,"['DVD /CD ROM', ' anatomy', ' artificial intelligence', ' computer human interaction', ' computer system design /evaluation', ' information retrieval', ' information systems']",NLM,UNIVERSITY OF WASHINGTON,R01,1997,298924,0.020480588488132723
"THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES DESCRIPTION (Taken from application abstract):  Recent advances in               understanding neuronal functions have led to an expanded scientific interest     in defining the organization of the nervous system so the spatial correlates     of these functions can be identified.  This interest has been formalized as      the Human Brain Project, an ambitious multi disciplinary effort to map the       nervous system from the organismal to the macromolecular levels.  One of the     greatest challenges of this effort is to preserve the complex                    three-dimensional relationships that occur between neuronal structures.          This problem will require new methods for data acquisition as well as data       visualization.                                                                                                                                                    The project described here is an interdisciplinary effort to derive              three-dimensional reconstructions of synaptic architecture from stereo           electron micrographs acquired from multiple viewpoints.  The collaboration       combines advanced ultrastructural visualization techniques with massively        parallel computational methods and an innovative set of pattern recognition,     stereo correspondence and depth mapping algorithms.  Our goal is to              integrate structural information from numerous images into a single,             high-accuracy three-dimensional reconstruction of the synaptic cytoskeleton.     The immediate result of this collaboration will be an improved understanding     of the spatial relationships between synaptic macromolecules.  More              importantly, the project will produce a set of computational tools that can      be applied to stereo image data sets of various areas of the nervous system,     from the macroscopic to the molecular level.  Finally, our studies will          advance the state-of-the-art of parallel computation and interactive             reconstruction methods that can provide novel solutions to difficult             problems of neuroscience visualization.                                           n/a",THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES,6185220,R01LM006326,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain mapping', ' cell cell interaction', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' cytoskeleton', ' data collection', ' electron microscopy', ' image processing', ' imaging /visualization /scanning', ' macromolecule', ' method development', ' nerve endings', ' neurons', ' parallel processing', ' stereophotography', ' structural biology', ' synapses']",NLM,UNIVERSITY OF MARYLAND BALTIMORE,R01,2000,117821,0.024553580743423488
"THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES DESCRIPTION (Taken from application abstract):  Recent advances in               understanding neuronal functions have led to an expanded scientific interest     in defining the organization of the nervous system so the spatial correlates     of these functions can be identified.  This interest has been formalized as      the Human Brain Project, an ambitious multi disciplinary effort to map the       nervous system from the organismal to the macromolecular levels.  One of the     greatest challenges of this effort is to preserve the complex                    three-dimensional relationships that occur between neuronal structures.          This problem will require new methods for data acquisition as well as data       visualization.                                                                                                                                                    The project described here is an interdisciplinary effort to derive              three-dimensional reconstructions of synaptic architecture from stereo           electron micrographs acquired from multiple viewpoints.  The collaboration       combines advanced ultrastructural visualization techniques with massively        parallel computational methods and an innovative set of pattern recognition,     stereo correspondence and depth mapping algorithms.  Our goal is to              integrate structural information from numerous images into a single,             high-accuracy three-dimensional reconstruction of the synaptic cytoskeleton.     The immediate result of this collaboration will be an improved understanding     of the spatial relationships between synaptic macromolecules.  More              importantly, the project will produce a set of computational tools that can      be applied to stereo image data sets of various areas of the nervous system,     from the macroscopic to the molecular level.  Finally, our studies will          advance the state-of-the-art of parallel computation and interactive             reconstruction methods that can provide novel solutions to difficult             problems of neuroscience visualization.                                           n/a",THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES,2897389,R01LM006326,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain mapping', ' cell cell interaction', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' cytoskeleton', ' data collection', ' electron microscopy', ' image processing', ' imaging /visualization /scanning', ' macromolecule', ' method development', ' nerve endings', ' neurons', ' parallel processing', ' stereophotography', ' structural biology', ' synapses']",NLM,UNIVERSITY OF MARYLAND BALTIMORE,R01,1999,107225,0.024553580743423488
"THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES DESCRIPTION (Taken from application abstract):  Recent advances in               understanding neuronal functions have led to an expanded scientific interest     in defining the organization of the nervous system so the spatial correlates     of these functions can be identified.  This interest has been formalized as      the Human Brain Project, an ambitious multi disciplinary effort to map the       nervous system from the organismal to the macromolecular levels.  One of the     greatest challenges of this effort is to preserve the complex                    three-dimensional relationships that occur between neuronal structures.          This problem will require new methods for data acquisition as well as data       visualization.                                                                                                                                                    The project described here is an interdisciplinary effort to derive              three-dimensional reconstructions of synaptic architecture from stereo           electron micrographs acquired from multiple viewpoints.  The collaboration       combines advanced ultrastructural visualization techniques with massively        parallel computational methods and an innovative set of pattern recognition,     stereo correspondence and depth mapping algorithms.  Our goal is to              integrate structural information from numerous images into a single,             high-accuracy three-dimensional reconstruction of the synaptic cytoskeleton.     The immediate result of this collaboration will be an improved understanding     of the spatial relationships between synaptic macromolecules.  More              importantly, the project will produce a set of computational tools that can      be applied to stereo image data sets of various areas of the nervous system,     from the macroscopic to the molecular level.  Finally, our studies will          advance the state-of-the-art of parallel computation and interactive             reconstruction methods that can provide novel solutions to difficult             problems of neuroscience visualization.                                           n/a",THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES,2771703,R01LM006326,"['artificial intelligence', ' brain mapping', ' cell cell interaction', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' cytoskeleton', ' data collection', ' electron microscopy', ' image processing', ' imaging /visualization /scanning', ' macromolecule', ' method development', ' nerve endings', ' neurons', ' parallel processing', ' stereophotography', ' structural biology', ' synapses']",NLM,UNIVERSITY OF MARYLAND BALTIMORE,R01,1998,118988,0.024553580743423488
"THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES DESCRIPTION (Taken from application abstract):  Recent advances in               understanding neuronal functions have led to an expanded scientific interest     in defining the organization of the nervous system so the spatial correlates     of these functions can be identified.  This interest has been formalized as      the Human Brain Project, an ambitious multi disciplinary effort to map the       nervous system from the organismal to the macromolecular levels.  One of the     greatest challenges of this effort is to preserve the complex                    three-dimensional relationships that occur between neuronal structures.          This problem will require new methods for data acquisition as well as data       visualization.                                                                                                                                                    The project described here is an interdisciplinary effort to derive              three-dimensional reconstructions of synaptic architecture from stereo           electron micrographs acquired from multiple viewpoints.  The collaboration       combines advanced ultrastructural visualization techniques with massively        parallel computational methods and an innovative set of pattern recognition,     stereo correspondence and depth mapping algorithms.  Our goal is to              integrate structural information from numerous images into a single,             high-accuracy three-dimensional reconstruction of the synaptic cytoskeleton.     The immediate result of this collaboration will be an improved understanding     of the spatial relationships between synaptic macromolecules.  More              importantly, the project will produce a set of computational tools that can      be applied to stereo image data sets of various areas of the nervous system,     from the macroscopic to the molecular level.  Finally, our studies will          advance the state-of-the-art of parallel computation and interactive             reconstruction methods that can provide novel solutions to difficult             problems of neuroscience visualization.                                           n/a",THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES,2453331,R01LM006326,"['artificial intelligence', ' brain mapping', ' cell cell interaction', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' cytoskeleton', ' data collection', ' electron microscopy', ' image processing', ' imaging /visualization /scanning', ' macromolecule', ' method development', ' nerve endings', ' neurons', ' parallel processing', ' stereophotography', ' structural biology', ' synapses']",NLM,UNIVERSITY OF MARYLAND BALTIMORE,R01,1997,128043,0.024553580743423488
"Models and Methods for Population Genomics     DESCRIPTION (provided by applicant): Significant improvements in the cost and ability to obtain genome-wide genotypes, even entire genome sequencing, of individuals provides an opportunity to understand genetic variation among humans and its relationship to complex trait variation at an unprecedented level of resolution. During this time, it has been discovered that human population genetic structure is more of a continuous phenomenon rather than being manifested as a set of well-defined discrete subpopulations. However, classical population genetic theory and methods for population structure are largely based on the assumption of non-overlapping, discretely structured populations. For example, Wright's F-statistics and association testing have mostly been studied in the context of K distinct populations. A number of innovative algorithms for analyzing structured populations with dense genotyping have recently been proposed. However, there has yet to be a firm statistical foundation developed for this setting. We propose to tackle a number of open problems in such a way that a coherent theoretical framework and set of statistical methodologies will emerge. We will perform extensive data analyses based on these methods on existing data sets, including the Human Genome Diversity Project, the 1000 Genomes Project, and GWAS studies involving structured populations.          Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.            ",Models and Methods for Population Genomics,8688050,R01HG006448,"['Accounting', 'Algorithms', 'Bioinformatics', 'Biological', 'Characteristics', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Equilibrium', 'Foundations', 'General Population', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome Diversity Project', 'Individual', 'Linear Models', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Pattern', 'Population', 'Population Genetics', 'Principal Component Analysis', 'Programming Languages', 'Research', 'Resolution', 'Role', 'Simulate', 'Source Code', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'Trust', 'Update', 'Variant', 'Writing', 'base', 'case control', 'cost', 'database of Genotypes and Phenotypes', 'genome sequencing', 'genome wide association study', 'genome-wide', 'human disease', 'human population genetics', 'innovation', 'interest', 'population genetic structure', 'programs', 'statistics', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2014,294003,-0.015629256541959825
"Models and Methods for Population Genomics     DESCRIPTION (provided by applicant): Significant improvements in the cost and ability to obtain genome-wide genotypes, even entire genome sequencing, of individuals provides an opportunity to understand genetic variation among humans and its relationship to complex trait variation at an unprecedented level of resolution. During this time, it has been discovered that human population genetic structure is more of a continuous phenomenon rather than being manifested as a set of well-defined discrete subpopulations. However, classical population genetic theory and methods for population structure are largely based on the assumption of non-overlapping, discretely structured populations. For example, Wright's F-statistics and association testing have mostly been studied in the context of K distinct populations. A number of innovative algorithms for analyzing structured populations with dense genotyping have recently been proposed. However, there has yet to be a firm statistical foundation developed for this setting. We propose to tackle a number of open problems in such a way that a coherent theoretical framework and set of statistical methodologies will emerge. We will perform extensive data analyses based on these methods on existing data sets, including the Human Genome Diversity Project, the 1000 Genomes Project, and GWAS studies involving structured populations.          Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.            ",Models and Methods for Population Genomics,8536347,R01HG006448,"['Accounting', 'Algorithms', 'Bioinformatics', 'Biological', 'Characteristics', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Equilibrium', 'Foundations', 'General Population', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome Diversity Project', 'Individual', 'Linear Models', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Pattern', 'Population', 'Population Genetics', 'Principal Component Analysis', 'Programming Languages', 'Research', 'Resolution', 'Role', 'Simulate', 'Source Code', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'Trust', 'Update', 'Variant', 'Writing', 'base', 'case control', 'cost', 'database of Genotypes and Phenotypes', 'genome sequencing', 'genome wide association study', 'genome-wide', 'human disease', 'human population genetics', 'innovation', 'interest', 'population genetic structure', 'programs', 'statistics', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2013,286504,-0.015629256541959825
"Models and Methods for Population Genomics     DESCRIPTION (provided by applicant): Significant improvements in the cost and ability to obtain genome-wide genotypes, even entire genome sequencing, of individuals provides an opportunity to understand genetic variation among humans and its relationship to complex trait variation at an unprecedented level of resolution. During this time, it has been discovered that human population genetic structure is more of a continuous phenomenon rather than being manifested as a set of well-defined discrete subpopulations. However, classical population genetic theory and methods for population structure are largely based on the assumption of non-overlapping, discretely structured populations. For example, Wright's F-statistics and association testing have mostly been studied in the context of K distinct populations. A number of innovative algorithms for analyzing structured populations with dense genotyping have recently been proposed. However, there has yet to be a firm statistical foundation developed for this setting. We propose to tackle a number of open problems in such a way that a coherent theoretical framework and set of statistical methodologies will emerge. We will perform extensive data analyses based on these methods on existing data sets, including the Human Genome Diversity Project, the 1000 Genomes Project, and GWAS studies involving structured populations.        PUBLIC HEALTH RELEVANCE: Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.              Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.            ",Models and Methods for Population Genomics,8296777,R01HG006448,"['Accounting', 'Algorithms', 'Bioinformatics', 'Biological', 'Characteristics', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Equilibrium', 'Foundations', 'General Population', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome Diversity Project', 'Individual', 'Linear Models', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Pattern', 'Population', 'Population Genetics', 'Principal Component Analysis', 'Programming Languages', 'Research', 'Resolution', 'Role', 'Simulate', 'Source Code', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'Trust', 'Update', 'Variant', 'Writing', 'base', 'case control', 'cost', 'database of Genotypes and Phenotypes', 'genome sequencing', 'genome wide association study', 'genome-wide', 'human disease', 'human population genetics', 'innovation', 'interest', 'population genetic structure', 'programs', 'statistics', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2012,300004,-0.0193389447271364
"Models and Methods for Population Genomics Project Summary Title: Models and Methods for Population Genomics Abstract: Understanding genome-wide genetic variation and its role in health-related complex traits in humans is one of the most important goals of modern biomedical research. There continues to be a substantial need for new statistical models and methods that can be applied in these studies, particularly as study designs become more ambitious and sample sizes increase. The overall goal of the proposed research is to develop statistical methods and software useful in understanding population genomics studies that involve genome-wide genotyping, many simultaneously measured traits, and very large sample sizes. Our focus is on flexible modeling that adapts to systematic variation and robustly models data encountered in these modern studies. The specific aims involve (1) developing tests of association immune to arbitrary population structure that work for general distributions of traits, many simultaneous traits, or extreme large sample sizes; (2) introducing new models and estimates of kinship and FST in generalized settings, which will lead to improved quantitative genetic modeling of complex traits; (3) introducing new estimation and testing frameworks for population structure that show superior performance to existing approaches; (4) developing and distributing software; and (5) analyzing important data sets to discover new biology and validate our methods and software. Project Narrative Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.",Models and Methods for Population Genomics,9482429,R01HG006448,"['Admixture', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Complex', 'Computer software', 'Data', 'Data Set', 'Disease', 'Equilibrium', 'Family', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Human', 'Immune', 'Individual', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Procedures', 'Programming Languages', 'Quantitative Genetics', 'Research', 'Research Design', 'Role', 'Sample Size', 'Seminal', 'Source Code', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Testing', 'Update', 'Variant', 'Work', 'Writing', 'data modeling', 'flexibility', 'genetic association', 'genome-wide', 'human disease', 'improved', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2018,356951,-0.0066658460758988874
"Models and Methods for Population Genomics Project Summary Title: Models and Methods for Population Genomics Abstract: Understanding genome-wide genetic variation and its role in health-related complex traits in humans is one of the most important goals of modern biomedical research. There continues to be a substantial need for new statistical models and methods that can be applied in these studies, particularly as study designs become more ambitious and sample sizes increase. The overall goal of the proposed research is to develop statistical methods and software useful in understanding population genomics studies that involve genome-wide genotyping, many simultaneously measured traits, and very large sample sizes. Our focus is on flexible modeling that adapts to systematic variation and robustly models data encountered in these modern studies. The specific aims involve (1) developing tests of association immune to arbitrary population structure that work for general distributions of traits, many simultaneous traits, or extreme large sample sizes; (2) introducing new models and estimates of kinship and FST in generalized settings, which will lead to improved quantitative genetic modeling of complex traits; (3) introducing new estimation and testing frameworks for population structure that show superior performance to existing approaches; (4) developing and distributing software; and (5) analyzing important data sets to discover new biology and validate our methods and software. Project Narrative Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.",Models and Methods for Population Genomics,9308564,R01HG006448,"['Admixture', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Complex', 'Computer software', 'Data', 'Data Set', 'Disease', 'Equilibrium', 'Family', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Human', 'Immune', 'Individual', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Procedures', 'Programming Languages', 'Quantitative Genetics', 'Research', 'Research Design', 'Role', 'Sample Size', 'Seminal', 'Source Code', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Testing', 'Update', 'Variant', 'Work', 'Writing', 'data modeling', 'flexibility', 'genetic association', 'genome-wide', 'human disease', 'improved', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2017,356951,-0.0066658460758988874
"Models and Methods for Population Genomics Project Summary Title: Models and Methods for Population Genomics Abstract: Understanding genome-wide genetic variation and its role in health-related complex traits in humans is one of the most important goals of modern biomedical research. There continues to be a substantial need for new statistical models and methods that can be applied in these studies, particularly as study designs become more ambitious and sample sizes increase. The overall goal of the proposed research is to develop statistical methods and software useful in understanding population genomics studies that involve genome-wide genotyping, many simultaneously measured traits, and very large sample sizes. Our focus is on flexible modeling that adapts to systematic variation and robustly models data encountered in these modern studies. The specific aims involve (1) developing tests of association immune to arbitrary population structure that work for general distributions of traits, many simultaneous traits, or extreme large sample sizes; (2) introducing new models and estimates of kinship and FST in generalized settings, which will lead to improved quantitative genetic modeling of complex traits; (3) introducing new estimation and testing frameworks for population structure that show superior performance to existing approaches; (4) developing and distributing software; and (5) analyzing important data sets to discover new biology and validate our methods and software. Project Narrative Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.",Models and Methods for Population Genomics,9893014,R01HG006448,"['Admixture', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Complex', 'Computer software', 'Data', 'Data Set', 'Disease', 'Equilibrium', 'Family', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Human', 'Immune', 'Individual', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Procedures', 'Programming Languages', 'Quantitative Genetics', 'R programming language ', 'Research', 'Research Design', 'Role', 'Sample Size', 'Seminal', 'Source Code', 'Statistical Methods', 'Statistical Models', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Update', 'Variant', 'Work', 'Writing', 'data modeling', 'flexibility', 'genetic association', 'genome-wide', 'human disease', 'improved', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2020,356951,-0.0066658460758988874
"Models and Methods for Population Genomics Project Summary Title: Models and Methods for Population Genomics Abstract: Understanding genome-wide genetic variation and its role in health-related complex traits in humans is one of the most important goals of modern biomedical research. There continues to be a substantial need for new statistical models and methods that can be applied in these studies, particularly as study designs become more ambitious and sample sizes increase. The overall goal of the proposed research is to develop statistical methods and software useful in understanding population genomics studies that involve genome-wide genotyping, many simultaneously measured traits, and very large sample sizes. Our focus is on flexible modeling that adapts to systematic variation and robustly models data encountered in these modern studies. The specific aims involve (1) developing tests of association immune to arbitrary population structure that work for general distributions of traits, many simultaneous traits, or extreme large sample sizes; (2) introducing new models and estimates of kinship and FST in generalized settings, which will lead to improved quantitative genetic modeling of complex traits; (3) introducing new estimation and testing frameworks for population structure that show superior performance to existing approaches; (4) developing and distributing software; and (5) analyzing important data sets to discover new biology and validate our methods and software. Project Narrative Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.",Models and Methods for Population Genomics,9666919,R01HG006448,"['Admixture', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Complex', 'Computer software', 'Data', 'Data Set', 'Disease', 'Equilibrium', 'Family', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Human', 'Immune', 'Individual', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Procedures', 'Programming Languages', 'Quantitative Genetics', 'R programming language\xa0', 'Research', 'Research Design', 'Role', 'Sample Size', 'Seminal', 'Source Code', 'Statistical Methods', 'Statistical Models', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Update', 'Variant', 'Work', 'Writing', 'data modeling', 'flexibility', 'genetic association', 'genome-wide', 'human disease', 'improved', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2019,356951,-0.0066658460758988874
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,7068069,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2006,19532,-0.008046319129828066
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,6937143,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2005,20000,-0.008046319129828066
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,6803809,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2004,242276,-0.008046319129828066
"Pathway Commons: A Public Library of Biological Pathways    DESCRIPTION (provided by applicant): Biological pathways represent knowledge about molecules, processes and their interactions. Maps of such  pathways are used to design and analyze experiments, and for predicting the behavior of biological systems.  Pathway information is extremely difficult for biologists to use in its current fragmented and incomplete state,  involving a large amount of time and effort to wade through, piece together and analyze. The Pathway  Commons research resource is being developed to overcome this roadblock by providing researchers with a  convenient single point of access to diverse biological pathway information translated to a common data  language. This project is an important step towards the development of a complete and integrated  computable map of the cell across all species and developmental stages.  Pathway Commons promotes and supports convergence, by the community, to a truly integrated computable  and searchable representation of cellular biological processes. Pathway Commons does not compete with or  duplicate efforts of pathway databases or softward tool providers. Existing database groups provide pathway  curation, while Pathway Commons provides mechanims and technology for adding value, disseminating, and  reducing duplication of effort. Collaboration with user and database groups is a central component, driven by  the desire for maximum synergy and efficiency.  The Pathway Commons resource will aggregate datasets from multiple major pathway databases; translate,  store, validate, index, integrate, hyperlink and maintain the information for maximum quality access; freely  deliver pathway information to the scientific public, both academic and commercial, using advanced internet  technology; and, provide open-source end user software for pathway browsing and analysis. User support  and training for Pathway Commons and related resources will be freely available to the scientific community.       PUBLIC HEALTH RELEVANCE:  The completion of the human genome sequence and advances in molecular technologies has led to an  explosion of biological data, which is driving biology towards increased use of computational tools. Pathway  Commons is making biological knowledge available for computational processing, and is helping create  predictive models of biological processes. These models will revolutionize biology and health research.         ",Pathway Commons: A Public Library of Biological Pathways,8698796,U41HG006623,"['Animal Model', 'Automobile Driving', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cells', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Evolution', 'Explosion', 'Genome', 'Genomics', 'Health', 'Human Genome', 'Information Services', 'Internet', 'Knowledge', 'Language', 'Libraries', 'Link', 'Maps', 'Modeling', 'Molecular', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Phase', 'Policies', 'Process', 'Provider', 'Reading', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Services', 'Source', 'Speed', 'Staging', 'Standardization', 'Technology', 'Time', 'Training', 'Training Support', 'Translating', 'Vision', 'Work', 'Writing', 'analog', 'biological systems', 'computerized tools', 'cost', 'data exchange', 'design', 'flexibility', 'functional genomics', 'genome sequencing', 'improved', 'indexing', 'information organization', 'innovation', 'news', 'next generation', 'open source', 'predictive modeling', 'public health relevance', 'research study', 'tool', 'usability', 'web services']",NHGRI,SLOAN-KETTERING INST CAN RESEARCH,U41,2014,980001,0.012278885662491613
"Pathway Commons: A Public Library of Biological Pathways    DESCRIPTION (provided by applicant): Biological pathways represent knowledge about molecules, processes and their interactions. Maps of such  pathways are used to design and analyze experiments, and for predicting the behavior of biological systems.  Pathway information is extremely difficult for biologists to use in its current fragmented and incomplete state,  involving a large amount of time and effort to wade through, piece together and analyze. The Pathway  Commons research resource is being developed to overcome this roadblock by providing researchers with a  convenient single point of access to diverse biological pathway information translated to a common data  language. This project is an important step towards the development of a complete and integrated  computable map of the cell across all species and developmental stages.  Pathway Commons promotes and supports convergence, by the community, to a truly integrated computable  and searchable representation of cellular biological processes. Pathway Commons does not compete with or  duplicate efforts of pathway databases or softward tool providers. Existing database groups provide pathway  curation, while Pathway Commons provides mechanims and technology for adding value, disseminating, and  reducing duplication of effort. Collaboration with user and database groups is a central component, driven by  the desire for maximum synergy and efficiency.  The Pathway Commons resource will aggregate datasets from multiple major pathway databases; translate,  store, validate, index, integrate, hyperlink and maintain the information for maximum quality access; freely  deliver pathway information to the scientific public, both academic and commercial, using advanced internet  technology; and, provide open-source end user software for pathway browsing and analysis. User support  and training for Pathway Commons and related resources will be freely available to the scientific community.       PUBLIC HEALTH RELEVANCE:  The completion of the human genome sequence and advances in molecular technologies has led to an  explosion of biological data, which is driving biology towards increased use of computational tools. Pathway  Commons is making biological knowledge available for computational processing, and is helping create  predictive models of biological processes. These models will revolutionize biology and health research.         ",Pathway Commons: A Public Library of Biological Pathways,8549293,U41HG006623,"['Animal Model', 'Automobile Driving', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cells', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Evolution', 'Explosion', 'Genome', 'Genomics', 'Health', 'Human Genome', 'Information Services', 'Internet', 'Knowledge', 'Language', 'Libraries', 'Link', 'Maps', 'Modeling', 'Molecular', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Phase', 'Policies', 'Process', 'Provider', 'Reading', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Services', 'Source', 'Speed', 'Staging', 'Standardization', 'Technology', 'Time', 'Training', 'Training Support', 'Translating', 'Vision', 'Work', 'Writing', 'analog', 'biological systems', 'computerized tools', 'cost', 'data exchange', 'design', 'flexibility', 'functional genomics', 'genome sequencing', 'improved', 'indexing', 'information organization', 'innovation', 'news', 'next generation', 'open source', 'predictive modeling', 'public health relevance', 'research study', 'tool', 'usability', 'web services']",NHGRI,SLOAN-KETTERING INST CAN RESEARCH,U41,2013,954999,0.012278885662491613
"Pathway Commons: A Public Library of Biological Pathways    DESCRIPTION (provided by applicant): Biological pathways represent knowledge about molecules, processes and their interactions. Maps of such  pathways are used to design and analyze experiments, and for predicting the behavior of biological systems.  Pathway information is extremely difficult for biologists to use in its current fragmented and incomplete state,  involving a large amount of time and effort to wade through, piece together and analyze. The Pathway  Commons research resource is being developed to overcome this roadblock by providing researchers with a  convenient single point of access to diverse biological pathway information translated to a common data  language. This project is an important step towards the development of a complete and integrated  computable map of the cell across all species and developmental stages.  Pathway Commons promotes and supports convergence, by the community, to a truly integrated computable  and searchable representation of cellular biological processes. Pathway Commons does not compete with or  duplicate efforts of pathway databases or softward tool providers. Existing database groups provide pathway  curation, while Pathway Commons provides mechanims and technology for adding value, disseminating, and  reducing duplication of effort. Collaboration with user and database groups is a central component, driven by  the desire for maximum synergy and efficiency.  The Pathway Commons resource will aggregate datasets from multiple major pathway databases; translate,  store, validate, index, integrate, hyperlink and maintain the information for maximum quality access; freely  deliver pathway information to the scientific public, both academic and commercial, using advanced internet  technology; and, provide open-source end user software for pathway browsing and analysis. User support  and training for Pathway Commons and related resources will be freely available to the scientific community.      PUBLIC HEALTH RELEVANCE:  The completion of the human genome sequence and advances in molecular technologies has led to an  explosion of biological data, which is driving biology towards increased use of computational tools. Pathway  Commons is making biological knowledge available for computational processing, and is helping create  predictive models of biological processes. These models will revolutionize biology and health research.            The completion of the human genome sequence and advances in molecular technologies has led to an  explosion of biological data, which is driving biology towards increased use of computational tools. Pathway  Commons is making biological knowledge available for computational processing, and is helping create  predictive models of biological processes. These models will revolutionize biology and health research.         ",Pathway Commons: A Public Library of Biological Pathways,8243036,U41HG006623,"['Animal Model', 'Automobile Driving', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cells', 'Collaborations', 'Communication', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Evolution', 'Explosion', 'Genome', 'Genomics', 'Health', 'Human Genome', 'Information Services', 'Internet', 'Knowledge', 'Language', 'Libraries', 'Link', 'Maps', 'Modeling', 'Molecular', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Phase', 'Policies', 'Process', 'Provider', 'Reading', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Services', 'Source', 'Speed', 'Staging', 'Standardization', 'Technology', 'Time', 'Training', 'Training Support', 'Translating', 'Vision', 'Work', 'Writing', 'analog', 'biological systems', 'computerized tools', 'cost', 'data exchange', 'design', 'flexibility', 'functional genomics', 'genome sequencing', 'improved', 'indexing', 'information organization', 'innovation', 'news', 'next generation', 'open source', 'predictive modeling', 'research study', 'tool', 'usability', 'web services']",NHGRI,SLOAN-KETTERING INST CAN RESEARCH,U41,2012,1000000,0.009840810685557784
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8683213,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2014,221252,-0.01368804040519315
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8518436,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2013,220626,-0.01368804040519315
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.        PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.              DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8350385,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Base Sequence', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'RNA', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'tool', 'transcription factor', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2012,220000,-0.02180644550451421
"Knowledge Mapping Across Disparate Patient Care Datasets DESCRIPTION: (provided by applicant) Health informatics can yield computational insight in assimilating knowledge from large clinical datasets for both research and policy discussion. The adoption of computerized patient records (CPR) by healthcare organizations promises to expand the sources potential research data to include clinical patient data. Applications of health informatics can enhance health services and clinical research, as well as improve healthcare quality. A primary goal of this traineeship in health informatics is to gain expertise in the modeling of clinical knowledge and the mapping of this knowledge to alternative taxonomies and meta-languages. A computational approach to this knowledge modeling and mapping will enable the creation of methodologies for aggregating clinical data from disparate data storage systems for large analyses. The proposed research is a first step in creating a regional health data repository. Broadly, this research will explore how various health data systems created by the private sector to facilitate healthcare delivery will support the secondary analysis of healthcare information for both health services and clinical research. Specifically, this research will examine the attributes and knowledge representation of multiple patient care data sources, and map the knowledge relevant to vancomycin-resistant nosocomial infections indexed to a common Unified Medical Language System (UMLS) integrated knowledge base for combined outcomes analyses. n/a",Knowledge Mapping Across Disparate Patient Care Datasets,6622211,F38LM007187,"['data collection methodology /evaluation', ' drug resistance', ' human data', ' indexing', ' informatics', ' information systems', ' information theory', ' medical records', ' nosocomial infections', ' patient care management', ' predoctoral investigator', ' vancomycin']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2003,58483,-0.0009400565399889355
"Knowledge Mapping Across Disparate Patient Care Datasets DESCRIPTION: (provided by applicant) Health informatics can yield computational insight in assimilating knowledge from large clinical datasets for both research and policy discussion. The adoption of computerized patient records (CPR) by healthcare organizations promises to expand the sources potential research data to include clinical patient data. Applications of health informatics can enhance health services and clinical research, as well as improve healthcare quality. A primary goal of this traineeship in health informatics is to gain expertise in the modeling of clinical knowledge and the mapping of this knowledge to alternative taxonomies and meta-languages. A computational approach to this knowledge modeling and mapping will enable the creation of methodologies for aggregating clinical data from disparate data storage systems for large analyses. The proposed research is a first step in creating a regional health data repository. Broadly, this research will explore how various health data systems created by the private sector to facilitate healthcare delivery will support the secondary analysis of healthcare information for both health services and clinical research. Specifically, this research will examine the attributes and knowledge representation of multiple patient care data sources, and map the knowledge relevant to vancomycin-resistant nosocomial infections indexed to a common Unified Medical Language System (UMLS) integrated knowledge base for combined outcomes analyses. n/a",Knowledge Mapping Across Disparate Patient Care Datasets,6442837,F38LM007187,"['data collection methodology /evaluation', ' drug resistance', ' human data', ' indexing', ' informatics', ' information systems', ' information theory', ' medical records', ' nosocomial infections', ' patient care management', ' predoctoral investigator', ' vancomycin']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2002,57671,-0.0009400565399889355
"Medical Vocabulary Support for Patients DESCRIPTION (provided by applicant): Consumers and patients are confronted with a plethora of health and health care information, especially through the proliferation of web content resources. Democratization of the web is an important milestone for patients and consumers since it helps to empower them, make them better advocates on their own behalf and foster better, more informed decisions about their health. Nonetheless, they have difficulties in identifying and accessing information that answers their specific questions, through standard information retrieval (IR) and text-based search techniques. This is partly due to vocabulary mismatches between lay terminology and the concepts that underlie medical/technical content. In addition, mental models of patients may not match the conceptual models of content developers, or of content indexers. Although a rich array of tools and vocabularies exists, current term mapping methods and tools for medical professionals are not sufficient to meet patients' needs. The goal of this project is to develop an improved means for patients to search for information resources relating to questions they may have about their health. We will define the characteristics of patient terminology in the context of carrying out web-based IR tasks, and develop a new scalable and flexible patient term mapping and linking method by combining knowledge-based and data-driven approaches. The proposed method uses a semantic network with weighted relations among concepts where the weights signify the semantic closeness between the concepts. The weights and relations can be updated based on prior successful retrievals and can be adapted to specific application contexts. A patient-oriented medical vocabulary tool will be developed that will assist patients in formulating queries for retrieving resources from the Internet. The project will build on existing tools and vocabularies for health information indexing and retrieval, and enhance these resources by incorporating tools and methods that map patient-oriented concepts and mental models to them. The method and the tools developed will be evaluated for their impact on patient IR in a randomized controlled study. Subjects in the study will attempt to retrieve healthcare information pertaining to specific scenarios that they will be provided. We will measure IR precision and recall, discriminating ability, self-perceived success (by subjects), and user-satisfaction with and without the vocabulary support.  n/a",Medical Vocabulary Support for Patients,6699042,R01LM007222,"['Internet', 'abstracting', 'biotechnology', 'clinical research', 'educational resource design /development', 'health education', 'human subject', 'informatics', 'information retrieval', 'information system analysis', 'interview', 'library', 'vocabulary', 'vocabulary development for information system']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2004,238740,0.0077287876415683176
"Medical Vocabulary Support for Patients DESCRIPTION (provided by applicant): Consumers and patients are confronted with a plethora of health and health care information, especially through the proliferation of web content resources. Democratization of the web is an important milestone for patients and consumers since it helps to empower them, make them better advocates on their own behalf and foster better, more informed decisions about their health. Nonetheless, they have difficulties in identifying and accessing information that answers their specific questions, through standard information retrieval (IR) and text-based search techniques. This is partly due to vocabulary mismatches between lay terminology and the concepts that underlie medical/technical content. In addition, mental models of patients may not match the conceptual models of content developers, or of content indexers. Although a rich array of tools and vocabularies exists, current term mapping methods and tools for medical professionals are not sufficient to meet patients' needs. The goal of this project is to develop an improved means for patients to search for information resources relating to questions they may have about their health. We will define the characteristics of patient terminology in the context of carrying out web-based IR tasks, and develop a new scalable and flexible patient term mapping and linking method by combining knowledge-based and data-driven approaches. The proposed method uses a semantic network with weighted relations among concepts where the weights signify the semantic closeness between the concepts. The weights and relations can be updated based on prior successful retrievals and can be adapted to specific application contexts. A patient-oriented medical vocabulary tool will be developed that will assist patients in formulating queries for retrieving resources from the Internet. The project will build on existing tools and vocabularies for health information indexing and retrieval, and enhance these resources by incorporating tools and methods that map patient-oriented concepts and mental models to them. The method and the tools developed will be evaluated for their impact on patient IR in a randomized controlled study. Subjects in the study will attempt to retrieve healthcare information pertaining to specific scenarios that they will be provided. We will measure IR precision and recall, discriminating ability, self-perceived success (by subjects), and user-satisfaction with and without the vocabulary support.  n/a",Medical Vocabulary Support for Patients,6620110,R01LM007222,"['Internet', ' abstracting', ' biotechnology', ' clinical research', ' educational resource design /development', ' health education', ' human subject', ' informatics', ' information retrieval', ' information system analysis', ' interview', ' library', ' vocabulary', ' vocabulary development for information system']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2003,238740,0.0077287876415683176
"Medical Vocabulary Support for Patients DESCRIPTION (provided by applicant): Consumers and patients are confronted with a plethora of health and health care information, especially through the proliferation of web content resources. Democratization of the web is an important milestone for patients and consumers since it helps to empower them, make them better advocates on their own behalf and foster better, more informed decisions about their health. Nonetheless, they have difficulties in identifying and accessing information that answers their specific questions, through standard information retrieval (IR) and text-based search techniques. This is partly due to vocabulary mismatches between lay terminology and the concepts that underlie medical/technical content. In addition, mental models of patients may not match the conceptual models of content developers, or of content indexers. Although a rich array of tools and vocabularies exists, current term mapping methods and tools for medical professionals are not sufficient to meet patients' needs. The goal of this project is to develop an improved means for patients to search for information resources relating to questions they may have about their health. We will define the characteristics of patient terminology in the context of carrying out web-based IR tasks, and develop a new scalable and flexible patient term mapping and linking method by combining knowledge-based and data-driven approaches. The proposed method uses a semantic network with weighted relations among concepts where the weights signify the semantic closeness between the concepts. The weights and relations can be updated based on prior successful retrievals and can be adapted to specific application contexts. A patient-oriented medical vocabulary tool will be developed that will assist patients in formulating queries for retrieving resources from the Internet. The project will build on existing tools and vocabularies for health information indexing and retrieval, and enhance these resources by incorporating tools and methods that map patient-oriented concepts and mental models to them. The method and the tools developed will be evaluated for their impact on patient IR in a randomized controlled study. Subjects in the study will attempt to retrieve healthcare information pertaining to specific scenarios that they will be provided. We will measure IR precision and recall, discriminating ability, self-perceived success (by subjects), and user-satisfaction with and without the vocabulary support.  n/a",Medical Vocabulary Support for Patients,6368778,R01LM007222,"['Internet', ' abstracting', ' biotechnology', ' clinical research', ' educational resource design /development', ' health education', ' human subject', ' informatics', ' information retrieval', ' information system analysis', ' interview', ' library', ' vocabulary', ' vocabulary development for information system']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2002,235899,0.0077287876415683176
"GeneScene: a toolkit for gene pathway analysis   DESCRIPTION (provided by applicant): The recent explosion of information in the      biomedical field has provided a greater opportunity to address significant           problems related to human disease than at any time in the past. Biomedical           researchers studying such processes as growth, differentiation, and cell death       have defined a large number of genetic and biochemical pathways that regulate        these processes, and have determined that disruption of these pathways are           known to occur in most disease states. It is widely believed that elucidation        of the genes and proteins that compose these biochemical pathways will define        the molecular targets for future drug therapies. Increasingly, it is recognized      that the various biochemical pathways that have been defined by researchers are      cross connected and form an exceedingly complex network involving hundreds of        genes and proteins. Therefore, before the promise of pathway mechanism based         drug therapies can be realized, the nature of the effect that manipulating any       one pathway might have on another must be understood.                                                                                                                     GeneScene is designed to utilize information derived from Medline, the primary       repository of the abstracts of biomedical research reports, to help suggest          possible interactions between genetic and biochemical pathways. It will assist       in reviewing existing literature, identifying gaps in existing knowledge,            comparing and integrating knowledge and data from different fields, and as such      help lead the way to new and interesting hypotheses and field research. There        are four parts to this goal: GeneScene will integrate the knowledge related to       gene pathway analysis contained in several journals, allow researchers to            browse and search the information and our knowledge representation, integrate        text based knowledge regarding gene pathway analysis with gene array data, and       allow personalization and collaboration by researchers.                                                                                                                   Our first objective is the extraction of gene pathway knowledge from text-based      sources. Our second objective is to let researchers browse and search the            knowledge map. Our third objective is to provide researchers the opportunity to      cooperate and to integrate gene array data into the knowledge map.                                                                                                        n/a",GeneScene: a toolkit for gene pathway analysis,6916279,R33LM007299,"['Internet', 'abstracting', 'clinical research', 'computer data analysis', 'computer program /software', 'genetic mapping', 'health science research analysis /evaluation', 'human subject', 'interview', 'journals', 'literature survey', 'microarray technology', 'molecular biology information system']",NLM,UNIVERSITY OF ARIZONA,R33,2005,453468,-0.006044441559685185
"GeneScene: a toolkit for gene pathway analysis   DESCRIPTION (provided by applicant): The recent explosion of information in the      biomedical field has provided a greater opportunity to address significant           problems related to human disease than at any time in the past. Biomedical           researchers studying such processes as growth, differentiation, and cell death       have defined a large number of genetic and biochemical pathways that regulate        these processes, and have determined that disruption of these pathways are           known to occur in most disease states. It is widely believed that elucidation        of the genes and proteins that compose these biochemical pathways will define        the molecular targets for future drug therapies. Increasingly, it is recognized      that the various biochemical pathways that have been defined by researchers are      cross connected and form an exceedingly complex network involving hundreds of        genes and proteins. Therefore, before the promise of pathway mechanism based         drug therapies can be realized, the nature of the effect that manipulating any       one pathway might have on another must be understood.                                                                                                                     GeneScene is designed to utilize information derived from Medline, the primary       repository of the abstracts of biomedical research reports, to help suggest          possible interactions between genetic and biochemical pathways. It will assist       in reviewing existing literature, identifying gaps in existing knowledge,            comparing and integrating knowledge and data from different fields, and as such      help lead the way to new and interesting hypotheses and field research. There        are four parts to this goal: GeneScene will integrate the knowledge related to       gene pathway analysis contained in several journals, allow researchers to            browse and search the information and our knowledge representation, integrate        text based knowledge regarding gene pathway analysis with gene array data, and       allow personalization and collaboration by researchers.                                                                                                                   Our first objective is the extraction of gene pathway knowledge from text-based      sources. Our second objective is to let researchers browse and search the            knowledge map. Our third objective is to provide researchers the opportunity to      cooperate and to integrate gene array data into the knowledge map.                                                                                                        n/a",GeneScene: a toolkit for gene pathway analysis,6622199,R33LM007299,"['Internet', 'abstracting', 'clinical research', 'computer data analysis', 'computer program /software', 'genetic mapping', 'health science research analysis /evaluation', 'human subject', 'interview', 'journals', 'literature survey', 'microarray technology', 'molecular biology information system']",NLM,UNIVERSITY OF ARIZONA,R33,2004,440259,-0.006044441559685185
"GeneScene: a toolkit for gene pathway analysis   DESCRIPTION (provided by applicant): The recent explosion of information in the      biomedical field has provided a greater opportunity to address significant           problems related to human disease than at any time in the past. Biomedical           researchers studying such processes as growth, differentiation, and cell death       have defined a large number of genetic and biochemical pathways that regulate        these processes, and have determined that disruption of these pathways are           known to occur in most disease states. It is widely believed that elucidation        of the genes and proteins that compose these biochemical pathways will define        the molecular targets for future drug therapies. Increasingly, it is recognized      that the various biochemical pathways that have been defined by researchers are      cross connected and form an exceedingly complex network involving hundreds of        genes and proteins. Therefore, before the promise of pathway mechanism based         drug therapies can be realized, the nature of the effect that manipulating any       one pathway might have on another must be understood.                                                                                                                     GeneScene is designed to utilize information derived from Medline, the primary       repository of the abstracts of biomedical research reports, to help suggest          possible interactions between genetic and biochemical pathways. It will assist       in reviewing existing literature, identifying gaps in existing knowledge,            comparing and integrating knowledge and data from different fields, and as such      help lead the way to new and interesting hypotheses and field research. There        are four parts to this goal: GeneScene will integrate the knowledge related to       gene pathway analysis contained in several journals, allow researchers to            browse and search the information and our knowledge representation, integrate        text based knowledge regarding gene pathway analysis with gene array data, and       allow personalization and collaboration by researchers.                                                                                                                   Our first objective is the extraction of gene pathway knowledge from text-based      sources. Our second objective is to let researchers browse and search the            knowledge map. Our third objective is to provide researchers the opportunity to      cooperate and to integrate gene array data into the knowledge map.                                                                                                        n/a",GeneScene: a toolkit for gene pathway analysis,6442174,R33LM007299,"['Internet', ' abstracting', ' clinical research', ' computer data analysis', ' computer program /software', ' genetic mapping', ' health science research analysis /evaluation', ' human subject', ' interview', ' journals', ' literature survey', ' microarray technology', ' molecular biology information system']",NLM,UNIVERSITY OF ARIZONA,R33,2002,427435,-0.006044441559685185
"Enhanced Gene Identification in Complex Traits Using Kernel Machines DESCRIPTION (provided by applicant):     Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5). PUBLIC HEALTH RELEVANCE:     Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8894057,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'methylation pattern', 'next generation sequencing', 'novel', 'open source', 'population based', 'predictive modeling', 'rare variant', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2015,341249,-0.0012535460841032054
"Enhanced Gene Identification in Complex Traits Using Kernel Machines     DESCRIPTION (provided by applicant):     Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5).         PUBLIC HEALTH RELEVANCE:     Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.            ",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8729618,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Pattern', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Simulate', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'next generation sequencing', 'novel', 'open source', 'population based', 'public health relevance', 'rare variant', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2014,343000,-0.0012535460841032054
"Enhanced Gene Identification in Complex Traits Using Kernel Machines DESCRIPTION (provided by applicant):  Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5). PUBLIC HEALTH RELEVANCE:  Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8598704,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Pattern', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Simulate', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'next generation sequencing', 'novel', 'open source', 'population based', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2013,350000,-0.0012535460841032054
"In-vivo optical molecular imaging with Dynamic Contrast Enhancement (DyCE)    DESCRIPTION (provided by applicant): Fluorescence-based molecular Imaging in small animals is having a major impact on drug development and disease research. However, a significant challenge to imaging targeted fluorescent markers in vivo remains: unless the labeled regions are located superficially; localization, quantitation and host organ identification are impeded by the effects of light scattering and absorption. Orthotopic tumor and disease models are increasingly preferred over less biologically relevant subcutaneous xenografts. In such studies, substantial difficulties are encountered in longitudinal studies where animals are growing and are positioned differently for each measurement. We believe that a single imaging advance could address many of these issues, and advance the utility of in-vivo molecular imaging: an exact anatomical co-registration technique that does not rely on multimodal techniques. This proposal describes dynamic molecular imaging (DMI), an approach that can provide co-registered anatomical information by exploiting in-vivo pharmacokinetics of dyes in small animals in a simple and inexpensive way. We demonstrate that by acquiring a time-series of optical images during injection of an inert dye, we can repeatably and accurately delineate the major internal organs of mice using optical imaging alone. This is possible because each major organ is ""illuminated"" by the kinetics of dye passing through it in such a manner as to make it distinguishable from other structures. Spatiotemporal analysis can exploit these characteristic time courses to allow the body-surface representation of each organ to be visualized. These in- vivo anatomical maps can be overlaid onto simultaneously acquired images of a targeted molecular probe (detected and distinguished from the mapping dye via multispectral imaging techniques, if necessary) to significantly aid in identification of the probe's anatomical and physical location. Using CRi's existing and prototype 2D, ""2.5D"" and true 3D multispectral mouse imaging systems, we propose to test and refine a DMI approach. Based on our findings to date, we will examine and exploit in-vivo pharmacokinetics of the near-infrared dye, indocyanine green, to generate delineated surface projections of individual organs. Co-registering this surface map with surface projections of detected targeted labels will allow the targeted probe's 3D spatial location to be inferred. This information can further be used to improve quantitative accuracy in longitudinal molecular imaging studies of deep targets.           n/a",In-vivo optical molecular imaging with Dynamic Contrast Enhancement (DyCE),7485551,R43EB008627,"['Address', 'Adoption', 'Algorithms', 'Anatomy', 'Animals', 'Automatic Data Processing', 'Back', 'Basic Science', 'Body Surface', 'Bolus Infusion', 'Characteristics', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Contrast Media', 'Data', 'Data Display', 'Depth', 'Detection', 'Development', 'Disease', 'Disease model', 'Drug Kinetics', 'Dyes', 'Fluorescence', 'General Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Indocyanine Green', 'Injection of therapeutic agent', 'Kinetics', 'Label', 'Legal patent', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Maps', 'Massachusetts', 'Measurement', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Molecular Probes', 'Mus', 'Nature', 'Optics', 'Organ', 'Paper', 'Performance', 'Physiological', 'Positioning Attribute', 'Protocols documentation', 'Purpose', 'Range', 'Research', 'Research Personnel', 'Retrieval', 'Series', 'Signal Transduction', 'Small Animal Imaging Systems', 'Software Tools', 'Solutions', 'Source', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'Tissues', 'Validation', 'Variant', 'Virginia', 'Visualization software', 'X-Ray Computed Tomography', 'Xenograft procedure', 'absorption', 'base', 'blind', 'data acquisition', 'drug development', 'drug discovery', 'experience', 'hemodynamics', 'image reconstruction', 'improved', 'in vivo', 'instrumentation', 'light scattering', 'longitudinal animal study', 'millimeter', 'molecular imaging', 'novel strategies', 'optical imaging', 'photonics', 'prototype', 'response', 'spatiotemporal', 'subcutaneous', 'tumor']",NIBIB,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R43,2008,167462,-0.02038263214330967
"Machine Learning and Visualization in Structural Biology    DESCRIPTION:       This project's main objective is to develop computerized tools that assist x-ray crystallographers in rapidly determining the three-dimensional structure of a protein. More specifically, this project addresses the following task: given a 3D electron-density map from crystallography and the sequence of the protein, find the most likely layout (i.e. ""trace"") of the protein sequence in 3D. The project will create both automated methods based on statistical machine-learning and computer-vision techniques, as well as visualization tools that support humans doing this layout. These two approaches complement each other and are synergistic.      This project's first specific aim is to develop and empirically evaluate algorithms that interpret crystallographic electron-density maps. The second specific aim is to incorporate structural-biology domain knowledge (secondary-structure prediction and potential-energy calculations) into the project's algorithms for interpreting density maps. The third specific aim is to tightly integrate partial model-construction with phase estimation updates to improve the recognition of 3D protein structures in x-ray reflection data; crystallographers will be able to intervene whenever they desire to help ""steer"" this iterative process. The final specific aim is to develop intuitive and effective modalities - including virtual reality and the use of speech/audio - for the efficient use of crystallographer's time in manual model fitting and validation.      Structural biology has wide relevance to biomedicine, since protein function generally follows from protein form (i.e., its structure). This project's techniques will speed-up the process of determining protein 3D structures, especially from low-quality (i.e., low-resolution) x-ray data, and will be applicable to other structural-biology tasks. Being able to accurately interpret low-resolution data promises to allow higher through put structure determination. The broader impact will include a better understanding of the power of modern theories and algorithms in machine learning and visualization in solving biological problems.         n/a",Machine Learning and Visualization in Structural Biology,7599114,R01LM008796,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Arts', 'Biological', 'Complement', 'Complex', 'Computer Vision Systems', 'Coupling', 'Crystallography', 'Data', 'Devices', 'Engineering', 'Error Sources', 'Evaluation', 'Freedom', 'Human', 'Image', 'Imagery', 'Knowledge', 'Left', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Modality', 'Modeling', 'Nature', 'Peptide Sequence Determination', 'Phase', 'Potential Energy', 'Process', 'Proteins', 'Research Personnel', 'Resolution', 'Right-On', 'Shapes', 'Speech', 'Speed', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Update', 'Validation', 'Vertebral column', 'Work', 'base', 'computerized tools', 'cost', 'data format', 'density', 'design', 'electron density', 'improved', 'method development', 'open source', 'programs', 'protein function', 'protein structure', 'structural biology', 'theories', 'three dimensional structure', 'tool', 'usability', 'virtual reality']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2009,306728,0.03646699914130366
"Machine Learning and Visualization in Structural Biology    DESCRIPTION:       This project's main objective is to develop computerized tools that assist x-ray crystallographers in rapidly determining the three-dimensional structure of a protein. More specifically, this project addresses the following task: given a 3D electron-density map from crystallography and the sequence of the protein, find the most likely layout (i.e. ""trace"") of the protein sequence in 3D. The project will create both automated methods based on statistical machine-learning and computer-vision techniques, as well as visualization tools that support humans doing this layout. These two approaches complement each other and are synergistic.      This project's first specific aim is to develop and empirically evaluate algorithms that interpret crystallographic electron-density maps. The second specific aim is to incorporate structural-biology domain knowledge (secondary-structure prediction and potential-energy calculations) into the project's algorithms for interpreting density maps. The third specific aim is to tightly integrate partial model-construction with phase estimation updates to improve the recognition of 3D protein structures in x-ray reflection data; crystallographers will be able to intervene whenever they desire to help ""steer"" this iterative process. The final specific aim is to develop intuitive and effective modalities - including virtual reality and the use of speech/audio - for the efficient use of crystallographer's time in manual model fitting and validation.      Structural biology has wide relevance to biomedicine, since protein function generally follows from protein form (i.e., its structure). This project's techniques will speed-up the process of determining protein 3D structures, especially from low-quality (i.e., low-resolution) x-ray data, and will be applicable to other structural-biology tasks. Being able to accurately interpret low-resolution data promises to allow higher through put structure determination. The broader impact will include a better understanding of the power of modern theories and algorithms in machine learning and visualization in solving biological problems.         n/a",Machine Learning and Visualization in Structural Biology,7391736,R01LM008796,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Arts', 'Biological', 'Complement', 'Complex', 'Computer Vision Systems', 'Condition', 'Coupling', 'Crystallography', 'Data', 'Devices', 'Engineering', 'Error Sources', 'Evaluation', 'Facility Construction Funding Category', 'Freedom', 'Human', 'Image', 'Imagery', 'Knowledge', 'Left', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Modality', 'Modeling', 'Nature', 'Object Attachment', 'Peptide Sequence Determination', 'Phase', 'Potential Energy', 'Process', 'Proteins', 'Research Personnel', 'Resolution', 'Right-On', 'Shapes', 'Speech', 'Speed', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Update', 'Validation', 'Vertebral column', 'Work', 'base', 'computerized tools', 'cost', 'density', 'design', 'desire', 'electron density', 'improved', 'method development', 'open source', 'programs', 'protein function', 'protein structure', 'structural biology', 'theories', 'three dimensional structure', 'tool', 'usability', 'virtual reality']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2008,306970,0.03646699914130366
"Machine Learning and Visualization in Structural Biology    DESCRIPTION:       This project's main objective is to develop computerized tools that assist x-ray crystallographers in rapidly determining the three-dimensional structure of a protein. More specifically, this project addresses the following task: given a 3D electron-density map from crystallography and the sequence of the protein, find the most likely layout (i.e. ""trace"") of the protein sequence in 3D. The project will create both automated methods based on statistical machine-learning and computer-vision techniques, as well as visualization tools that support humans doing this layout. These two approaches complement each other and are synergistic.      This project's first specific aim is to develop and empirically evaluate algorithms that interpret crystallographic electron-density maps. The second specific aim is to incorporate structural-biology domain knowledge (secondary-structure prediction and potential-energy calculations) into the project's algorithms for interpreting density maps. The third specific aim is to tightly integrate partial model-construction with phase estimation updates to improve the recognition of 3D protein structures in x-ray reflection data; crystallographers will be able to intervene whenever they desire to help ""steer"" this iterative process. The final specific aim is to develop intuitive and effective modalities - including virtual reality and the use of speech/audio - for the efficient use of crystallographer's time in manual model fitting and validation.      Structural biology has wide relevance to biomedicine, since protein function generally follows from protein form (i.e., its structure). This project's techniques will speed-up the process of determining protein 3D structures, especially from low-quality (i.e., low-resolution) x-ray data, and will be applicable to other structural-biology tasks. Being able to accurately interpret low-resolution data promises to allow higher through put structure determination. The broader impact will include a better understanding of the power of modern theories and algorithms in machine learning and visualization in solving biological problems.         n/a",Machine Learning and Visualization in Structural Biology,7216865,R01LM008796,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Arts', 'Biological', 'Complement', 'Complex', 'Computer Vision Systems', 'Condition', 'Coupling', 'Crystallography', 'Data', 'Devices', 'Engineering', 'Error Sources', 'Evaluation', 'Facility Construction Funding Category', 'Freedom', 'Human', 'Image', 'Imagery', 'Knowledge', 'Left', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Modality', 'Modeling', 'Nature', 'Object Attachment', 'Peptide Sequence Determination', 'Phase', 'Potential Energy', 'Process', 'Proteins', 'Research Personnel', 'Resolution', 'Right-On', 'Shapes', 'Speech', 'Speed', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Update', 'Validation', 'Vertebral column', 'Work', 'base', 'computerized tools', 'cost', 'density', 'design', 'desire', 'electron density', 'improved', 'method development', 'open source', 'programs', 'protein function', 'protein structure', 'structural biology', 'theories', 'three dimensional structure', 'tool', 'usability', 'virtual reality']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2007,313156,0.03646699914130366
"Machine Learning and Visualization in Structural Biology    DESCRIPTION:       This project's main objective is to develop computerized tools that assist x-ray crystallographers in rapidly determining the three-dimensional structure of a protein. More specifically, this project addresses the following task: given a 3D electron-density map from crystallography and the sequence of the protein, find the most likely layout (i.e. ""trace"") of the protein sequence in 3D. The project will create both automated methods based on statistical machine-learning and computer-vision techniques, as well as visualization tools that support humans doing this layout. These two approaches complement each other and are synergistic.      This project's first specific aim is to develop and empirically evaluate algorithms that interpret crystallographic electron-density maps. The second specific aim is to incorporate structural-biology domain knowledge (secondary-structure prediction and potential-energy calculations) into the project's algorithms for interpreting density maps. The third specific aim is to tightly integrate partial model-construction with phase estimation updates to improve the recognition of 3D protein structures in x-ray reflection data; crystallographers will be able to intervene whenever they desire to help ""steer"" this iterative process. The final specific aim is to develop intuitive and effective modalities - including virtual reality and the use of speech/audio - for the efficient use of crystallographer's time in manual model fitting and validation.      Structural biology has wide relevance to biomedicine, since protein function generally follows from protein form (i.e., its structure). This project's techniques will speed-up the process of determining protein 3D structures, especially from low-quality (i.e., low-resolution) x-ray data, and will be applicable to other structural-biology tasks. Being able to accurately interpret low-resolution data promises to allow higher through put structure determination. The broader impact will include a better understanding of the power of modern theories and algorithms in machine learning and visualization in solving biological problems.         n/a",Machine Learning and Visualization in Structural Biology,6958317,R01LM008796,"['computer human interaction', 'computer simulation', 'computers', 'density', 'electron density', 'human', 'learning', 'model', 'protein sequence', 'protein structure', 'proteins', 'structural biology', 'vision']",NLM,UNIVERSITY OF WISCONSIN MADISON,R01,2006,322749,0.03646699914130366
"Multi-point and multi-locus analysis of genomic association data    DESCRIPTION (provided by applicant):       Genome-wide association studies (GWAS) provide a new and powerful approach to investigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learning approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases.            Principal Investigator/Program Director: Li, Jing Title: Multi-point and multi-locus analysis of genomic association data Abstract: Genome-wide association studies (GWAS) provide a new and powerful approach to inves- tigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learn- ing approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases. PHS 398 Page 1",Multi-point and multi-locus analysis of genomic association data,7897811,R01LM008991,"['Address', 'Advanced Development', 'Affect', 'Algorithms', 'Alleles', 'Architecture', 'Cataloging', 'Catalogs', 'Chromosomes', 'Classification', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Decision Trees', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Environment', 'Environmental Risk Factor', 'Etiology', 'Evaluation', 'Freedom', 'Frequencies', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Recombination', 'Genetic Risk', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Grouping', 'Haplotypes', 'Heart Diseases', 'Heterogeneity', 'Imagery', 'Inherited', 'Intelligence', 'Internet', 'Joints', 'Learning', 'Licensing', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Markov Chains', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Phenocopy', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Procedures', 'Rare Diseases', 'Research Project Grants', 'Risk', 'Role', 'Sampling', 'Scientist', 'Simulate', 'Single Nucleotide Polymorphism', 'Staging', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Trust', 'Uncertainty', 'Weight', 'Work', 'abstracting', 'base', 'case control', 'database of Genotypes and Phenotypes', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genome wide association study', 'genotyping technology', 'hydroxy-aluminum polymer', 'improved', 'markov model', 'neglect', 'novel', 'programs', 'research study', 'software systems', 'tool', 'trait']",NLM,CASE WESTERN RESERVE UNIVERSITY,R01,2010,930276,-0.015952346901914747
"Multi-point and multi-locus analysis of genomic association data    DESCRIPTION (provided by applicant):       Genome-wide association studies (GWAS) provide a new and powerful approach to investigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learning approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases.            Principal Investigator/Program Director: Li, Jing Title: Multi-point and multi-locus analysis of genomic association data Abstract: Genome-wide association studies (GWAS) provide a new and powerful approach to inves- tigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learn- ing approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases. PHS 398 Page 1",Multi-point and multi-locus analysis of genomic association data,7652746,R01LM008991,"['Address', 'Advanced Development', 'Affect', 'Algorithms', 'Alleles', 'Architecture', 'Cataloging', 'Catalogs', 'Chromosomes', 'Classification', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Decision Trees', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Environment', 'Environmental Risk Factor', 'Etiology', 'Evaluation', 'Freedom', 'Frequencies', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Recombination', 'Genetic Risk', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Grouping', 'Haplotypes', 'Heart Diseases', 'Heterogeneity', 'Imagery', 'Inherited', 'Intelligence', 'Internet', 'Joints', 'Learning', 'Licensing', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Markov Chains', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Phenocopy', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Procedures', 'Rare Diseases', 'Research Project Grants', 'Risk', 'Role', 'Sampling', 'Scientist', 'Simulate', 'Single Nucleotide Polymorphism', 'Staging', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Trust', 'Uncertainty', 'Weight', 'Work', 'abstracting', 'base', 'case control', 'database of Genotypes and Phenotypes', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genome wide association study', 'genotyping technology', 'hydroxy-aluminum polymer', 'improved', 'markov model', 'neglect', 'novel', 'programs', 'research study', 'software systems', 'tool', 'trait']",NLM,CASE WESTERN RESERVE UNIVERSITY,R01,2009,951009,-0.015952346901914747
"Estimating disease risk using genetic data Project Summary In the past 10 years, over 21,000 genetic variants have been linked to complex human traits through genome-wide association studies (GWAS). However, the predictive power of many of these variants remains limited, and it is still unclear how best to use the wealth of information generated by GWAS to impact personal health and clinical practice. For nearly 10 years, 23andMe has been not only a driving force in direct-to-consumer genetic testing but also has established an innovative crowd-sourced genetics research platform. This platform has yielded a compelling data resource and many genetic discoveries. In this proposal, we will address the next phase of 23andMe human genetics research: the development of highly scalable and accurate disease risk estimation. Two of the key challenges in human genetics research are (1) to determine how to use results of GWAS to paint an accurate picture of an individual's disease risk, and (2) to determine how these estimates can provide information of personal and clinical utility. These challenges are difficult due to many factors including the wide spectrum of disease classes, the paucity of genetic and phenotypic data and significant methodological and computational challenges. In this proposal, we present a plan to utilize the genetic and phenotypic data stores at 23andMe to ​develop validated risk estimation algorithms​. In Phase I, we will build a computational pipeline that will be used to develop predictive algorithms for estimating disease risk (Aim #1) and use this pipeline to evaluate predictive ability of different estimation approaches in a broad class of human complex traits (Aim #2). In Phase II, we will validate these algorithms in external cohorts and build customer-facing reports that we will test for user comprehension. We believe that the development of accurate risk estimation capability will have a major impact on both consumer genetics and clinical genetics markets.      Project Narrative   The promise of genetics-based estimation of disease risk has yet to be realized. In this project, 23andMe will use its database of genetic and phenotypic information from over 1,000,000 research participants who have contributed more than 285,000,000 phenotypic data points on a wide spectrum of disease to build risk estimation algorithms. This project will enable 23andMe to produce the first validated risk estimation algorithms that provide both personal and clinical utility.    ",Estimating disease risk using genetic data,9255753,R43HG009089,"['Address', 'Algorithms', 'Applications Grants', 'Catalogs', 'Clinical', 'Communities', 'Complement', 'Complex', 'Comprehension', 'Data', 'Data Reporting', 'Databases', 'Development', 'Disease', 'Environmental Risk Factor', 'Foundations', 'Frequencies', 'Genetic', 'Genetic Databases', 'Genetic Markers', 'Genetic Models', 'Genetic Research', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genotype', 'Goals', 'Grant', 'Health', 'Human', 'Human Genetics', 'Individual', 'Industry Collaboration', 'Knowledge', 'Link', 'Logistics', 'Machine Learning', 'Medical Genetics', 'Mendelian disorder', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Myopia', 'National Human Genome Research Institute', 'Online Systems', 'Paint', 'Participant', 'Patient Self-Report', 'Peer Review', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Prevention', 'Public Health', 'Publications', 'Reporting', 'Research', 'Risk', 'Role', 'Services', 'Small Business Innovation Research Grant', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'clinical practice', 'clinically relevant', 'cohort', 'crowdsourcing', 'data resource', 'disorder risk', 'driving force', 'drug development', 'flexibility', 'genetic predictors', 'genetic variant', 'genome wide association study', 'health practice', 'human disease', 'improved', 'innovation', 'learning strategy', 'lifestyle factors', 'new therapeutic target', 'non-genetic', 'personalized medicine', 'phenotypic data', 'prediction algorithm', 'research and development', 'risk variant', 'trait']",NHGRI,"23ANDME, INC.",R43,2017,241905,-0.055883082152351535
"Predicting gene regulation across populations to understand mechanisms underlying complex traits Project Summary Deeper understanding of the degree of transferability of genetic association results and implicated biological mechanisms across populations is essential for equitable precision medicine implementation and can only be accomplished by studying the genetic architecture of complex traits in diverse populations. In our initial project period, we have shown that genetic correlation of gene expression depends on shared ancestry proportions in African American, Hispanic, and European populations. We identified a subset of genes that are well-predicted in one population, but poorly predicted in another and showed these differences are due to allele frequency differences between populations. Our results demonstrate that when comparing predicted expression levels to the observed, a balance of the training population with ancestry similar to the test population and total sample size leads to optimal predicted gene expression. Our studies of lipid traits in Yoruba, Filipino and Hispanic populations uncovered key genes likely regulated by variants that are monomorphic or rare in European populations, demonstrating why studies in diverse populations are crucial. We have optimized genetic prediction models of gene expression levels in diverse populations and thus have broadened the scope of PrediXcan. In this proposal, we seek to (1) optimize global and local ancestry-aware omics trait prediction models within and across diverse populations and (2) predict the intermediate omics traits and perform poly- omic PrediXcan analyses of complex traits in GWAS cohorts from diverse populations. We have gathered data of multiple omics traits from diverse populations for this project (genome-wide genotype, RNA-Seq, methylomics, metabolomics, and microbiome). We will use machine learning to optimize genotypic prediction models of gene expression levels, splicing ratios, methylation, metabolite levels, and microbial diversity. We expect a range of predictive power will be observed across omics traits dependent on the heritability of each trait and differences in allele frequencies and effect sizes among populations. We will integrate regulatory data and previous results from larger European populations when appropriate to prioritize functional variants in our prediction models. For each omics trait, we will survey its genetic architecture to inform the best prediction models. Our models will account for global and local ancestry and we will quantify the ancestry specific components of each omics trait. We will test the predicted omics traits for association with phenotypes of interest using either raw genotypes or summary statistics. We will use colocalization methods to determine if the SNPs driving each omics trait prediction model are also those most associated with the phenotype and thus most likely to be causal. We will combine predicted omics traits in poly-omic models to determine which genes and biological pathways are implicated for a particular phenotype. Our team is well positioned to perform novel PrediXcan-based analyses of omics traits in diverse populations and promises to maximize impact by making our scripts, models, and results publicly available. Project Narrative Differences in DNA sequence among individuals can lead to differences in omics traits like gene expression, splicing, methylation, metabolite levels, and microbial diversity, which in turn can lead to trait differences. We have developed a method that harnesses DNA differences to predict omics traits, which are then tested for association with a disease or other trait of interest. Our project will lead to a better understanding of the degree of transferability of genetic association results across populations, which has the potential to improve the implementation of precision medicine among diverse populations and reduce health disparities.",Predicting gene regulation across populations to understand mechanisms underlying complex traits,9880471,R15HG009569,"['Adopted', 'African American', 'Authorship', 'Automobile Driving', 'Awareness', 'Balance training', 'Biological', 'Bipolar Disorder', 'Catalogs', 'Cohort Studies', 'Communities', 'Complex', 'Complex Genetic Trait', 'DNA', 'DNA Sequence', 'Data', 'Disease', 'European', 'Filipino', 'Gene Expression', 'Gene Expression Regulation', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic study', 'Genotype', 'Heritability', 'Hispanics', 'Individual', 'Knowledge', 'Lead', 'Lipids', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuscripts', 'Methods', 'Methylation', 'Mission', 'Modeling', 'Multiomic Data', 'Pathway interactions', 'Performance', 'Phenotype', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Publishing', 'RNA Splicing', 'Sample Size', 'Schizophrenia', 'Surveys', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'Variant', 'base', 'cohort', 'database of Genotypes and Phenotypes', 'epidemiological model', 'epigenomics', 'genetic architecture', 'genetic association', 'genetic predictors', 'genome wide association study', 'genome-wide', 'health disparity', 'improved', 'interest', 'metabolomics', 'methylomics', 'microbial', 'microbiome', 'microbiota', 'novel', 'precision medicine', 'predictive modeling', 'predictive test', 'statistics', 'trait', 'transcriptome', 'transcriptome sequencing', 'undergraduate student']",NHGRI,LOYOLA UNIVERSITY OF CHICAGO,R15,2020,436000,-0.01377433484172148
"HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence    DESCRIPTION (provided by applicant):      Even as many developed countries strengthen their traditional clinically-based surveillance capacity, a basic level of health information infrastructure is still lacking in many parts of the developing world, including areas that are most vulnerable to emerging health threats. To help fill this gap, electronic news outlets, disease reporting networks, discussion sites, and blogs are proving to be invaluable data sources for a new generation of public health surveillance systems that operate across international borders- almost all major outbreaks investigated by WHO, including SARS, are first identified by these informal online sources. These data sources provide local and timely information about disease outbreaks and related events around the world, including areas relatively invisible to day-to-day global public health efforts due to lack of infrastructure or political suppression of information. However, since this information is dispersed and largely unstructured, there is lack of organization and integration between sources, precluding a global view of all ongoing disease threats. In order to construct such an integrated view of current emerging infections, we deployed an early prototype called Health Map, a freely available multi-stream real-time knowledge management system that aggregates and maps health alerts across numerous key data sources, including WHO alerts, newswires, mailing lists. Leveraging our previous National Library of Medicine funded work in real-time health monitoring; we propose extensive development of this new digital resource to address technological and methodological barriers to achieving a synthesized, comprehensive, and customized view of global health. The principal objective of Health Map development is to provide access to the greatest amount of possibly useful information across the widest variety of geographical areas and disease agents, without overwhelming the user with an excess of information, or obscuring important and urgent elements. We will specifically address the challenge of providing structure to unstructured data while still enabling the astute user to notice the subtle pattern that could be an early indication of a significant outbreak. Development of Health Map will proceed along the four key components of surveillance: (1) data acquisition (evaluation and integration of multiple electronic sources) (2) information characterization (disease and location categorization and severity rating of unstructured data), (3) signal interpretation (multi-stream signal detection, spatiotemporal modeling and risk assessment) and (4) knowledge dissemination (tiered dissemination of global infectious disease alerts and flexible data visualization tools). In each area, we will make critical enhancements to the existing prototype. We plan rigorous evaluation to ensure that Health Map successfully leverages electronic sources for surveillance, communication, and intervention. We will also conduct comprehensive user testing, usability studies, user behavior analysis as part of our effort. Our goal is to make Health Map a vital knowledge resource tailored for both the general public and public health decision-makers.        Although an enormous amount of information about current infectious disease outbreaks is found in Web- accessible information sources, this information is dispersed and not well-organized, making it almost impossible for public health officials and concerned citizens to know about all ongoing emerging disease threats. Through rigorous development of our online HealthMap system, we plan to provide a synthesized, timely and comprehensive view of current global infectious disease outbreaks by acquiring, integrating and disseminating a wide variety of Internet-based information sources. Our goal is to make HealthMap a vital knowledge resource tailored for both the general public and public health decision-makers.",HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence,8138357,G08LM009776,"['Accounting', 'Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Characteristics', 'Code', 'Communicable Diseases', 'Communication', 'Complement', 'Data', 'Data Quality', 'Data Sources', 'Decision Making', 'Detection', 'Developed Countries', 'Development', 'Dictionary', 'Disease', 'Disease Outbreaks', 'Electronics', 'Elements', 'Emerging Communicable Diseases', 'Ensure', 'Evaluation', 'Event', 'Funding', 'General Population', 'Generations', 'Geographic Locations', 'Goals', 'Health', 'Health Professional', 'Health Status', 'Imagery', 'Infection', 'Information Resources', 'Information Resources Management', 'Information Retrieval', 'Intelligence', 'International', 'Internet', 'Intervention', 'Knowledge', 'Language', 'Location', 'Mails', 'Maps', 'Medical', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Operating System', 'Pattern', 'Population', 'Population Surveillance', 'Populations at Risk', 'Process', 'Public Health', 'Reporting', 'Research Infrastructure', 'Resources', 'Risk Assessment', 'Risk Estimate', 'Sampling', 'Severe Acute Respiratory Syndrome', 'Severities', 'Signal Transduction', 'Site', 'Source', 'Statistical Models', 'Stream', 'Structure', 'System', 'Systems Development', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trees', 'United States National Library of Medicine', 'Update', 'Work', 'base', 'data acquisition', 'demographics', 'digital', 'experience', 'flexibility', 'global health', 'improved', 'interest', 'mortality', 'news', 'prototype', 'spatiotemporal', 'syndromic surveillance', 'tool', 'usability', 'web-accessible']",NLM,BOSTON CHILDREN'S HOSPITAL,G08,2011,128304,0.005485008350427314
"HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence    DESCRIPTION (provided by applicant):      Even as many developed countries strengthen their traditional clinically-based surveillance capacity, a basic level of health information infrastructure is still lacking in many parts of the developing world, including areas that are most vulnerable to emerging health threats. To help fill this gap, electronic news outlets, disease reporting networks, discussion sites, and blogs are proving to be invaluable data sources for a new generation of public health surveillance systems that operate across international borders- almost all major outbreaks investigated by WHO, including SARS, are first identified by these informal online sources. These data sources provide local and timely information about disease outbreaks and related events around the world, including areas relatively invisible to day-to-day global public health efforts due to lack of infrastructure or political suppression of information. However, since this information is dispersed and largely unstructured, there is lack of organization and integration between sources, precluding a global view of all ongoing disease threats. In order to construct such an integrated view of current emerging infections, we deployed an early prototype called Health Map, a freely available multi-stream real-time knowledge management system that aggregates and maps health alerts across numerous key data sources, including WHO alerts, newswires, mailing lists. Leveraging our previous National Library of Medicine funded work in real-time health monitoring; we propose extensive development of this new digital resource to address technological and methodological barriers to achieving a synthesized, comprehensive, and customized view of global health. The principal objective of Health Map development is to provide access to the greatest amount of possibly useful information across the widest variety of geographical areas and disease agents, without overwhelming the user with an excess of information, or obscuring important and urgent elements. We will specifically address the challenge of providing structure to unstructured data while still enabling the astute user to notice the subtle pattern that could be an early indication of a significant outbreak. Development of Health Map will proceed along the four key components of surveillance: (1) data acquisition (evaluation and integration of multiple electronic sources) (2) information characterization (disease and location categorization and severity rating of unstructured data), (3) signal interpretation (multi-stream signal detection, spatiotemporal modeling and risk assessment) and (4) knowledge dissemination (tiered dissemination of global infectious disease alerts and flexible data visualization tools). In each area, we will make critical enhancements to the existing prototype. We plan rigorous evaluation to ensure that Health Map successfully leverages electronic sources for surveillance, communication, and intervention. We will also conduct comprehensive user testing, usability studies, user behavior analysis as part of our effort. Our goal is to make Health Map a vital knowledge resource tailored for both the general public and public health decision-makers.        Although an enormous amount of information about current infectious disease outbreaks is found in Web- accessible information sources, this information is dispersed and not well-organized, making it almost impossible for public health officials and concerned citizens to know about all ongoing emerging disease threats. Through rigorous development of our online HealthMap system, we plan to provide a synthesized, timely and comprehensive view of current global infectious disease outbreaks by acquiring, integrating and disseminating a wide variety of Internet-based information sources. Our goal is to make HealthMap a vital knowledge resource tailored for both the general public and public health decision-makers.",HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence,8325815,G08LM009776,"['Accounting', 'Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Characteristics', 'Code', 'Communicable Diseases', 'Communication', 'Complement', 'Data', 'Data Quality', 'Data Sources', 'Decision Making', 'Detection', 'Developed Countries', 'Development', 'Dictionary', 'Disease', 'Disease Outbreaks', 'Electronics', 'Elements', 'Emerging Communicable Diseases', 'Ensure', 'Evaluation', 'Event', 'Funding', 'General Population', 'Generations', 'Geographic Locations', 'Goals', 'Health', 'Health Professional', 'Health Status', 'Imagery', 'Infection', 'Information Resources', 'Information Resources Management', 'Information Retrieval', 'Intelligence', 'International', 'Internet', 'Intervention', 'Knowledge', 'Language', 'Location', 'Mails', 'Maps', 'Medical', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Operating System', 'Pattern', 'Population', 'Population Surveillance', 'Populations at Risk', 'Process', 'Public Health', 'Reporting', 'Research Infrastructure', 'Resources', 'Risk Assessment', 'Risk Estimate', 'Sampling', 'Severe Acute Respiratory Syndrome', 'Severities', 'Signal Transduction', 'Site', 'Source', 'Statistical Models', 'Stream', 'Structure', 'System', 'Systems Development', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trees', 'United States National Library of Medicine', 'Update', 'Work', 'base', 'data acquisition', 'demographics', 'digital', 'experience', 'flexibility', 'global health', 'improved', 'interest', 'mortality', 'news', 'prototype', 'spatiotemporal', 'syndromic surveillance', 'tool', 'usability', 'web-accessible']",NLM,BOSTON CHILDREN'S HOSPITAL,G08,2011,100000,0.005485008350427314
"HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence    DESCRIPTION (provided by applicant):      Even as many developed countries strengthen their traditional clinically-based surveillance capacity, a basic level of health information infrastructure is still lacking in many parts of the developing world, including areas that are most vulnerable to emerging health threats. To help fill this gap, electronic news outlets, disease reporting networks, discussion sites, and blogs are proving to be invaluable data sources for a new generation of public health surveillance systems that operate across international borders- almost all major outbreaks investigated by WHO, including SARS, are first identified by these informal online sources. These data sources provide local and timely information about disease outbreaks and related events around the world, including areas relatively invisible to day-to-day global public health efforts due to lack of infrastructure or political suppression of information. However, since this information is dispersed and largely unstructured, there is lack of organization and integration between sources, precluding a global view of all ongoing disease threats. In order to construct such an integrated view of current emerging infections, we deployed an early prototype called Health Map, a freely available multi-stream real-time knowledge management system that aggregates and maps health alerts across numerous key data sources, including WHO alerts, newswires, mailing lists. Leveraging our previous National Library of Medicine funded work in real-time health monitoring; we propose extensive development of this new digital resource to address technological and methodological barriers to achieving a synthesized, comprehensive, and customized view of global health. The principal objective of Health Map development is to provide access to the greatest amount of possibly useful information across the widest variety of geographical areas and disease agents, without overwhelming the user with an excess of information, or obscuring important and urgent elements. We will specifically address the challenge of providing structure to unstructured data while still enabling the astute user to notice the subtle pattern that could be an early indication of a significant outbreak. Development of Health Map will proceed along the four key components of surveillance: (1) data acquisition (evaluation and integration of multiple electronic sources) (2) information characterization (disease and location categorization and severity rating of unstructured data), (3) signal interpretation (multi-stream signal detection, spatiotemporal modeling and risk assessment) and (4) knowledge dissemination (tiered dissemination of global infectious disease alerts and flexible data visualization tools). In each area, we will make critical enhancements to the existing prototype. We plan rigorous evaluation to ensure that Health Map successfully leverages electronic sources for surveillance, communication, and intervention. We will also conduct comprehensive user testing, usability studies, user behavior analysis as part of our effort. Our goal is to make Health Map a vital knowledge resource tailored for both the general public and public health decision-makers.        Although an enormous amount of information about current infectious disease outbreaks is found in Web- accessible information sources, this information is dispersed and not well-organized, making it almost impossible for public health officials and concerned citizens to know about all ongoing emerging disease threats. Through rigorous development of our online HealthMap system, we plan to provide a synthesized, timely and comprehensive view of current global infectious disease outbreaks by acquiring, integrating and disseminating a wide variety of Internet-based information sources. Our goal is to make HealthMap a vital knowledge resource tailored for both the general public and public health decision-makers.",HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence,7921043,G08LM009776,"['Accounting', 'Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Characteristics', 'Code', 'Communicable Diseases', 'Communication', 'Complement', 'Computer Systems Development', 'Data', 'Data Quality', 'Data Sources', 'Decision Making', 'Detection', 'Developed Countries', 'Development', 'Dictionary', 'Disease', 'Disease Outbreaks', 'Electronics', 'Elements', 'Emerging Communicable Diseases', 'Ensure', 'Evaluation', 'Event', 'Funding', 'General Population', 'Generations', 'Geographic Locations', 'Goals', 'Health', 'Health Professional', 'Health Status', 'Imagery', 'Infection', 'Information Resources', 'Information Resources Management', 'Information Retrieval', 'Intelligence', 'International', 'Internet', 'Intervention', 'Knowledge', 'Language', 'Location', 'Mails', 'Maps', 'Medical', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Network-based', 'Operating System', 'Pattern', 'Population', 'Population Surveillance', 'Populations at Risk', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk Assessment', 'Risk Estimate', 'Sampling', 'Severe Acute Respiratory Syndrome', 'Severities', 'Signal Transduction', 'Site', 'Source', 'Statistical Models', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trees', 'United States National Library of Medicine', 'Update', 'Work', 'base', 'data acquisition', 'demographics', 'digital', 'experience', 'flexibility', 'global health', 'improved', 'interest', 'mortality', 'news', 'prototype', 'spatiotemporal', 'syndromic surveillance', 'tool', 'usability', 'web-accessible']",NLM,BOSTON CHILDREN'S HOSPITAL,G08,2010,133651,0.005485008350427314
"HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence    DESCRIPTION (provided by applicant):      Even as many developed countries strengthen their traditional clinically-based surveillance capacity, a basic level of health information infrastructure is still lacking in many parts of the developing world, including areas that are most vulnerable to emerging health threats. To help fill this gap, electronic news outlets, disease reporting networks, discussion sites, and blogs are proving to be invaluable data sources for a new generation of public health surveillance systems that operate across international borders- almost all major outbreaks investigated by WHO, including SARS, are first identified by these informal online sources. These data sources provide local and timely information about disease outbreaks and related events around the world, including areas relatively invisible to day-to-day global public health efforts due to lack of infrastructure or political suppression of information. However, since this information is dispersed and largely unstructured, there is lack of organization and integration between sources, precluding a global view of all ongoing disease threats. In order to construct such an integrated view of current emerging infections, we deployed an early prototype called Health Map, a freely available multi-stream real-time knowledge management system that aggregates and maps health alerts across numerous key data sources, including WHO alerts, newswires, mailing lists. Leveraging our previous National Library of Medicine funded work in real-time health monitoring; we propose extensive development of this new digital resource to address technological and methodological barriers to achieving a synthesized, comprehensive, and customized view of global health. The principal objective of Health Map development is to provide access to the greatest amount of possibly useful information across the widest variety of geographical areas and disease agents, without overwhelming the user with an excess of information, or obscuring important and urgent elements. We will specifically address the challenge of providing structure to unstructured data while still enabling the astute user to notice the subtle pattern that could be an early indication of a significant outbreak. Development of Health Map will proceed along the four key components of surveillance: (1) data acquisition (evaluation and integration of multiple electronic sources) (2) information characterization (disease and location categorization and severity rating of unstructured data), (3) signal interpretation (multi-stream signal detection, spatiotemporal modeling and risk assessment) and (4) knowledge dissemination (tiered dissemination of global infectious disease alerts and flexible data visualization tools). In each area, we will make critical enhancements to the existing prototype. We plan rigorous evaluation to ensure that Health Map successfully leverages electronic sources for surveillance, communication, and intervention. We will also conduct comprehensive user testing, usability studies, user behavior analysis as part of our effort. Our goal is to make Health Map a vital knowledge resource tailored for both the general public and public health decision-makers.        Although an enormous amount of information about current infectious disease outbreaks is found in Web- accessible information sources, this information is dispersed and not well-organized, making it almost impossible for public health officials and concerned citizens to know about all ongoing emerging disease threats. Through rigorous development of our online HealthMap system, we plan to provide a synthesized, timely and comprehensive view of current global infectious disease outbreaks by acquiring, integrating and disseminating a wide variety of Internet-based information sources. Our goal is to make HealthMap a vital knowledge resource tailored for both the general public and public health decision-makers.",HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence,7692401,G08LM009776,"['Accounting', 'Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Characteristics', 'Code', 'Communicable Diseases', 'Communication', 'Complement', 'Computer Systems Development', 'Data', 'Data Quality', 'Data Sources', 'Decision Making', 'Detection', 'Developed Countries', 'Developing Countries', 'Development', 'Dictionary', 'Disease', 'Disease Outbreaks', 'Electronics', 'Elements', 'Emerging Communicable Diseases', 'Ensure', 'Evaluation', 'Event', 'Funding', 'General Population', 'Generations', 'Geographic Locations', 'Goals', 'Health', 'Health Professional', 'Health Status', 'Imagery', 'Infection', 'Information Resources', 'Information Resources Management', 'Information Retrieval', 'Intelligence', 'International', 'Internet', 'Intervention', 'Knowledge', 'Language', 'Location', 'Mails', 'Maps', 'Medical', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Network-based', 'Operating System', 'Pattern', 'Population', 'Population Surveillance', 'Populations at Risk', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk Assessment', 'Risk Estimate', 'Sampling', 'Severe Acute Respiratory Syndrome', 'Severities', 'Signal Transduction', 'Site', 'Source', 'Statistical Models', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trees', 'United States National Library of Medicine', 'Update', 'Work', 'base', 'data acquisition', 'demographics', 'digital', 'experience', 'flexibility', 'improved', 'interest', 'mortality', 'news', 'prototype', 'spatiotemporal', 'syndromic surveillance', 'tool', 'usability', 'web-accessible']",NLM,BOSTON CHILDREN'S HOSPITAL,G08,2009,135000,0.005485008350427314
"HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence    DESCRIPTION (provided by applicant):      Even as many developed countries strengthen their traditional clinically-based surveillance capacity, a basic level of health information infrastructure is still lacking in many parts of the developing world, including areas that are most vulnerable to emerging health threats. To help fill this gap, electronic news outlets, disease reporting networks, discussion sites, and blogs are proving to be invaluable data sources for a new generation of public health surveillance systems that operate across international borders- almost all major outbreaks investigated by WHO, including SARS, are first identified by these informal online sources. These data sources provide local and timely information about disease outbreaks and related events around the world, including areas relatively invisible to day-to-day global public health efforts due to lack of infrastructure or political suppression of information. However, since this information is dispersed and largely unstructured, there is lack of organization and integration between sources, precluding a global view of all ongoing disease threats. In order to construct such an integrated view of current emerging infections, we deployed an early prototype called Health Map, a freely available multi-stream real-time knowledge management system that aggregates and maps health alerts across numerous key data sources, including WHO alerts, newswires, mailing lists. Leveraging our previous National Library of Medicine funded work in real-time health monitoring; we propose extensive development of this new digital resource to address technological and methodological barriers to achieving a synthesized, comprehensive, and customized view of global health. The principal objective of Health Map development is to provide access to the greatest amount of possibly useful information across the widest variety of geographical areas and disease agents, without overwhelming the user with an excess of information, or obscuring important and urgent elements. We will specifically address the challenge of providing structure to unstructured data while still enabling the astute user to notice the subtle pattern that could be an early indication of a significant outbreak. Development of Health Map will proceed along the four key components of surveillance: (1) data acquisition (evaluation and integration of multiple electronic sources) (2) information characterization (disease and location categorization and severity rating of unstructured data), (3) signal interpretation (multi-stream signal detection, spatiotemporal modeling and risk assessment) and (4) knowledge dissemination (tiered dissemination of global infectious disease alerts and flexible data visualization tools). In each area, we will make critical enhancements to the existing prototype. We plan rigorous evaluation to ensure that Health Map successfully leverages electronic sources for surveillance, communication, and intervention. We will also conduct comprehensive user testing, usability studies, user behavior analysis as part of our effort. Our goal is to make Health Map a vital knowledge resource tailored for both the general public and public health decision-makers.        Although an enormous amount of information about current infectious disease outbreaks is found in Web- accessible information sources, this information is dispersed and not well-organized, making it almost impossible for public health officials and concerned citizens to know about all ongoing emerging disease threats. Through rigorous development of our online HealthMap system, we plan to provide a synthesized, timely and comprehensive view of current global infectious disease outbreaks by acquiring, integrating and disseminating a wide variety of Internet-based information sources. Our goal is to make HealthMap a vital knowledge resource tailored for both the general public and public health decision-makers.",HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence,8496251,G08LM009776,"['Accounting', 'Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Characteristics', 'Code', 'Communicable Diseases', 'Communication', 'Complement', 'Data', 'Data Quality', 'Data Sources', 'Decision Making', 'Detection', 'Developed Countries', 'Development', 'Dictionary', 'Disease', 'Disease Outbreaks', 'Electronics', 'Elements', 'Emerging Communicable Diseases', 'Ensure', 'Evaluation', 'Event', 'Funding', 'General Population', 'Generations', 'Geographic Locations', 'Goals', 'Health', 'Health Professional', 'Health Status', 'Imagery', 'Infection', 'Information Resources', 'Information Resources Management', 'Information Retrieval', 'Intelligence', 'International', 'Internet', 'Intervention', 'Knowledge', 'Language', 'Location', 'Mails', 'Maps', 'Medical', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Operating System', 'Pattern', 'Population', 'Population Surveillance', 'Populations at Risk', 'Process', 'Public Health', 'Reporting', 'Research Infrastructure', 'Resources', 'Risk Assessment', 'Risk Estimate', 'Sampling', 'Severe Acute Respiratory Syndrome', 'Severities', 'Signal Transduction', 'Site', 'Source', 'Statistical Models', 'Stream', 'Structure', 'System', 'Systems Development', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trees', 'United States National Library of Medicine', 'Update', 'Work', 'base', 'data acquisition', 'demographics', 'digital', 'experience', 'flexibility', 'global health', 'improved', 'interest', 'mortality', 'news', 'prototype', 'spatiotemporal', 'syndromic surveillance', 'tool', 'usability', 'web-accessible']",NLM,BOSTON CHILDREN'S HOSPITAL,G08,2012,40000,0.005485008350427314
"HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence    DESCRIPTION (provided by applicant):      Even as many developed countries strengthen their traditional clinically-based surveillance capacity, a basic level of health information infrastructure is still lacking in many parts of the developing world, including areas that are most vulnerable to emerging health threats. To help fill this gap, electronic news outlets, disease reporting networks, discussion sites, and blogs are proving to be invaluable data sources for a new generation of public health surveillance systems that operate across international borders- almost all major outbreaks investigated by WHO, including SARS, are first identified by these informal online sources. These data sources provide local and timely information about disease outbreaks and related events around the world, including areas relatively invisible to day-to-day global public health efforts due to lack of infrastructure or political suppression of information. However, since this information is dispersed and largely unstructured, there is lack of organization and integration between sources, precluding a global view of all ongoing disease threats. In order to construct such an integrated view of current emerging infections, we deployed an early prototype called Health Map, a freely available multi-stream real-time knowledge management system that aggregates and maps health alerts across numerous key data sources, including WHO alerts, newswires, mailing lists. Leveraging our previous National Library of Medicine funded work in real-time health monitoring; we propose extensive development of this new digital resource to address technological and methodological barriers to achieving a synthesized, comprehensive, and customized view of global health. The principal objective of Health Map development is to provide access to the greatest amount of possibly useful information across the widest variety of geographical areas and disease agents, without overwhelming the user with an excess of information, or obscuring important and urgent elements. We will specifically address the challenge of providing structure to unstructured data while still enabling the astute user to notice the subtle pattern that could be an early indication of a significant outbreak. Development of Health Map will proceed along the four key components of surveillance: (1) data acquisition (evaluation and integration of multiple electronic sources) (2) information characterization (disease and location categorization and severity rating of unstructured data), (3) signal interpretation (multi-stream signal detection, spatiotemporal modeling and risk assessment) and (4) knowledge dissemination (tiered dissemination of global infectious disease alerts and flexible data visualization tools). In each area, we will make critical enhancements to the existing prototype. We plan rigorous evaluation to ensure that Health Map successfully leverages electronic sources for surveillance, communication, and intervention. We will also conduct comprehensive user testing, usability studies, user behavior analysis as part of our effort. Our goal is to make Health Map a vital knowledge resource tailored for both the general public and public health decision-makers.        Although an enormous amount of information about current infectious disease outbreaks is found in Web- accessible information sources, this information is dispersed and not well-organized, making it almost impossible for public health officials and concerned citizens to know about all ongoing emerging disease threats. Through rigorous development of our online HealthMap system, we plan to provide a synthesized, timely and comprehensive view of current global infectious disease outbreaks by acquiring, integrating and disseminating a wide variety of Internet-based information sources. Our goal is to make HealthMap a vital knowledge resource tailored for both the general public and public health decision-makers.",HealthMap: Knowledge Management for Emerging Infectious Disease Intelligence,7928674,G08LM009776,"['Accounting', 'Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Characteristics', 'Code', 'Communicable Diseases', 'Communication', 'Complement', 'Computer Systems Development', 'Data', 'Data Quality', 'Data Sources', 'Decision Making', 'Detection', 'Developed Countries', 'Developing Countries', 'Development', 'Dictionary', 'Disease', 'Disease Outbreaks', 'Electronics', 'Elements', 'Emerging Communicable Diseases', 'Ensure', 'Evaluation', 'Event', 'Funding', 'General Population', 'Generations', 'Geographic Locations', 'Goals', 'Health', 'Health Professional', 'Health Status', 'Imagery', 'Infection', 'Information Resources', 'Information Resources Management', 'Information Retrieval', 'Intelligence', 'International', 'Internet', 'Intervention', 'Knowledge', 'Language', 'Location', 'Mails', 'Maps', 'Medical', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Network-based', 'Operating System', 'Pattern', 'Population', 'Population Surveillance', 'Populations at Risk', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk Assessment', 'Risk Estimate', 'Sampling', 'Severe Acute Respiratory Syndrome', 'Severities', 'Signal Transduction', 'Site', 'Source', 'Statistical Models', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trees', 'United States National Library of Medicine', 'Update', 'Work', 'base', 'data acquisition', 'demographics', 'digital', 'experience', 'flexibility', 'improved', 'interest', 'mortality', 'news', 'prototype', 'spatiotemporal', 'syndromic surveillance', 'tool', 'usability', 'web-accessible']",NLM,BOSTON CHILDREN'S HOSPITAL,G08,2009,55179,0.005485008350427314
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7845601,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,TULANE UNIVERSITY OF LOUISIANA,R21,2010,186306,0.017499226250352412
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7641582,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Classification', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,UNIVERSITY OF MISSOURI KANSAS CITY,R21,2009,219972,0.017499226250352412
"Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity Project Summary Antimicrobial resistance is an increasing problem, and current drug pipelines are not keeping pace with the rise of antimicrobial resistance. An alternative strategy is to boost host immunity. An often overlooked side-effect of the vitamin and mineral supplementation projects of the 1940s is that these supplements greatly reduced infectious disease burden. Recent work has shown that further gains may be possible, especially in adding phytochemicals back to highly processed diets typically consumed in the United States. However, we lack a fundamental understanding of how these components are processed by the microbiome, and how diet-derived molecules, microbiome and host immune system work together to resist infectious disease. A key barrier preventing us from making these discoveries is that each individual assay (microbiome, host gene expression metabolome, dietary compounds) is expensive and highly multivariate. Three key insights that enable the current project are the miniaturization of DNA and RNA sequencing assays on advanced nanoliter- scale liquid handling robots, greatly reducing the cost, the combination of untargeted and targeted mass spectrometry on the same samples in high throughput to enable discovery of a much greater chemical space, and the ability to use explicitly spatial maps on multiple scales to integrate the dataset throughout the body and enable both visual analytics and deep learning approaches based on spatial data. These breakthroughs will provide a fundamentally new understanding of how dietary metabolites promote disease resistance, and will allow us to develop a new infrastructure to integrate results from many investigators in different laboratories studying various aspects of these systems. Additionally, the results will allow us to choose biomaterials and biomarkers in human subjects that provide maximum information about internal nutritional and immune status. Results will be tested against the NHANES and American Gut cohorts. The results of this project will therefore be: 3D maps of mouse models showing how the microbiome, diet, and host gene expression produce immunity; an infrastructure for creating and sharing these maps; and a preliminary test of whether the results extend to large human populations. Project Narrative The public health relevance of this proposal is that it will provide an infrastructure for analyzing impacts of dietary components and microbiomes throughout the body. The analysis of these maps will help us identify dietary components that improve resistance to infectious disease.",Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity,10015205,DP1AT010885,"['3-Dimensional', 'American', 'Antimicrobial Resistance', 'Back', 'Biocompatible Materials', 'Biological Assay', 'Biological Markers', 'Chemicals', 'Communicable Diseases', 'Consumption', 'DNA sequencing', 'Data', 'Data Set', 'Diet', 'Dietary Component', 'Disease Resistance', 'Enhancers', 'Gene Expression', 'Human', 'Immune system', 'Immunity', 'Individual', 'Infrastructure', 'Laboratory Study', 'Liquid substance', 'Maps', 'Mass Spectrum Analysis', 'Metabolite Interaction', 'Microbe', 'Minerals', 'Miniaturization', 'National Health and Nutrition Examination Survey', 'Nutritional status', 'Pharmaceutical Preparations', 'Phytochemical', 'Population', 'Process', 'Research Personnel', 'Resistance', 'Robot', 'Sampling', 'Supplementation', 'System', 'Testing', 'United States', 'Visual', 'Vitamins', 'Work', 'base', 'burden of illness', 'cohort', 'cost', 'deep learning', 'human subject', 'immunological status', 'improved', 'insight', 'metabolome', 'microbiome', 'mouse model', 'nanolitre scale', 'prevent', 'public health relevance', 'side effect', 'transcriptome sequencing']",NCCIH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",DP1,2020,885000,-0.014481691250842586
"Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity Project Summary Antimicrobial resistance is an increasing problem, and current drug pipelines are not keeping pace with the rise of antimicrobial resistance. An alternative strategy is to boost host immunity. An often overlooked side-effect of the vitamin and mineral supplementation projects of the 1940s is that these supplements greatly reduced infectious disease burden. Recent work has shown that further gains may be possible, especially in adding phytochemicals back to highly processed diets typically consumed in the United States. However, we lack a fundamental understanding of how these components are processed by the microbiome, and how diet-derived molecules, microbiome and host immune system work together to resist infectious disease. A key barrier preventing us from making these discoveries is that each individual assay (microbiome, host gene expression metabolome, dietary compounds) is expensive and highly multivariate. Three key insights that enable the current project are the miniaturization of DNA and RNA sequencing assays on advanced nanoliter- scale liquid handling robots, greatly reducing the cost, the combination of untargeted and targeted mass spectrometry on the same samples in high throughput to enable discovery of a much greater chemical space, and the ability to use explicitly spatial maps on multiple scales to integrate the dataset throughout the body and enable both visual analytics and deep learning approaches based on spatial data. These breakthroughs will provide a fundamentally new understanding of how dietary metabolites promote disease resistance, and will allow us to develop a new infrastructure to integrate results from many investigators in different laboratories studying various aspects of these systems. Additionally, the results will allow us to choose biomaterials and biomarkers in human subjects that provide maximum information about internal nutritional and immune status. Results will be tested against the NHANES and American Gut cohorts. The results of this project will therefore be: 3D maps of mouse models showing how the microbiome, diet, and host gene expression produce immunity; an infrastructure for creating and sharing these maps; and a preliminary test of whether the results extend to large human populations. Project Narrative The public health relevance of this proposal is that it will provide an infrastructure for analyzing impacts of dietary components and microbiomes throughout the body. The analysis of these maps will help us identify dietary components that improve resistance to infectious disease.",Mapping host-microbe-metabolite interactions in 3D to find diet-derived enhancers of immunity,9785812,DP1AT010885,"['3-Dimensional', 'American', 'Antimicrobial Resistance', 'Back', 'Biocompatible Materials', 'Biological Assay', 'Biological Markers', 'Chemicals', 'Communicable Diseases', 'Consumption', 'DNA sequencing', 'Data', 'Data Set', 'Diet', 'Dietary Component', 'Disease Resistance', 'Enhancers', 'Gene Expression', 'Human', 'Immune system', 'Immunity', 'Individual', 'Infrastructure', 'Laboratory Study', 'Liquid substance', 'Maps', 'Mass Spectrum Analysis', 'Metabolite Interaction', 'Microbe', 'Minerals', 'Miniaturization', 'National Health and Nutrition Examination Survey', 'Nutritional status', 'Pharmaceutical Preparations', 'Phytochemical', 'Population', 'Process', 'Research Personnel', 'Resistance', 'Robot', 'Sampling', 'Supplementation', 'System', 'Testing', 'United States', 'Visual', 'Vitamins', 'Work', 'base', 'burden of illness', 'cohort', 'cost', 'deep learning', 'human subject', 'immunological status', 'improved', 'insight', 'metabolome', 'microbiome', 'mouse model', 'nanolitre scale', 'prevent', 'public health relevance', 'side effect', 'transcriptome sequencing']",NCCIH,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",DP1,2019,1085000,-0.014481691250842586
"Computational tools for regulome mapping using single-cell genomic data Project Summary Understanding how genes' activities are controlled is crucial for elucidating the basic operating rules of biology and molecular mechanisms of diseases. Recent innovations in single-cell genomic technologies have opened the door to analyzing a variety of functional genomic features in individual cells. These technologies enable scientists to systematically discover unknown cell subpopulations in complex tissue and disease samples, and allow them to reconstruct a sample's gene regulatory landscape at an unprecedented cellular resolution. Despite these promising developments, many challenges still exist and must be overcome before one can fully decode gene regulation at the single-cell resolution. In particular, current technologies lack the ability to accurately measure the activity of each individual cis-regulatory element (CRE) in a single cell. They also cannot measure all functional genomic data types in the same cell. Moreover, the prevalent technical biases and noises in single-cell genomic data make computational analysis non-trivial. With rapid growth of data, lack of computational tools for data analysis has become a rate-limiting factor for effective applications of single-cell genomic technologies.  The objective of this proposal is to develop computational and statistical methods and software tools for mapping and analyzing gene regulatory landscape using single-cell genomic data. Our Aim 1 addresses the challenge of accurately measuring CRE activities in single cells using single-cell regulome data. Regulome, deﬁned as the activities of all cis-regulatory elements in a genome, contains crucial information for understanding gene regulation. The state-of-the-art technologies for mapping regulome in a single cell produce sparse data that cannot accurately measure activities of individual CREs. We will develop a new computational framework to allow more accurate analysis of individual CREs' activities in single cells using sparse data. Our Aim 2 addresses the challenge of collecting multiple functional genomic data types in the same cell. We will develop a method that uses single-cell RNA sequencing (scRNA-seq), the most widely used single-cell functional genomic technology, to predict cells' regulatory landscape. Since most scRNA-seq datasets do not have accompanying single-cell data for other -omics data types, our method will also signiﬁcantly expand the utility and increase the value of scRNA- seq experiments. Our Aim 3 addresses the challenge of integrating different data types generated by different single-cell genomic technologies from different cells. We will develop a method to align single-cell RNA-seq and single-cell regulome data to generate an integrated map of transcriptome and regulome.  Upon completion of this proposal, we will deliver our methods through open-source software tools. These tools will be widely useful for analyzing and integrating single-cell regulome and transcriptome data. By addressing several major challenges in single-cell genomics, our new methods and tools will help unleash the full potential of single-cell genomic technologies for studying gene regulation. As such, they can have a major impact on advancing our understanding of both basic biology and human diseases. Project Narrative Understanding how genes' activities are controlled at single-cell resolution is crucial for studying human diseases. This proposal will develop a coordinated set of computational and statistical methods and software tools for mapping and analyzing gene regulatory programs using single-cell genomic data. These methods and tools will allow scientists to more accurately and comprehensively reconstruct gene regulatory landscape of individual cells in complex tissue and disease samples, and they can have a major impact on advancing our understanding of both basic biology and human diseases.",Computational tools for regulome mapping using single-cell genomic data,10001077,R01HG010889,"['Address', 'Atlases', 'Behavior', 'Biological', 'Biology', 'Biomedical Research', 'Brain', 'Cells', 'Cellular Assay', 'Chromatin', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Emerging Technologies', 'Foundations', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genomics', 'Human', 'Immune system', 'Individual', 'Knowledge', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Modality', 'Molecular', 'Multiomic Data', 'Noise', 'Organ', 'Phase', 'Population', 'Regulator Genes', 'Regulatory Element', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Software Tools', 'Statistical Methods', 'Stem Cell Development', 'System', 'Technology', 'Therapeutic', 'Tissues', 'Training', 'Transposase', 'base', 'computer framework', 'computerized tools', 'epigenome', 'experimental study', 'functional genomics', 'genomic data', 'histone modification', 'human disease', 'innovation', 'multiple data types', 'multiple omics', 'novel strategies', 'open source', 'predictive modeling', 'programs', 'rapid growth', 'single cell analysis', 'single cell technology', 'single-cell RNA sequencing', 'supervised learning', 'tool', 'transcriptome', 'transcriptome sequencing', 'user-friendly']",NHGRI,JOHNS HOPKINS UNIVERSITY,R01,2020,409375,-0.007706102282278429
"Computational tools for regulome mapping using single-cell genomic data Project Summary Understanding how genes' activities are controlled is crucial for elucidating the basic operating rules of biology and molecular mechanisms of diseases. Recent innovations in single-cell genomic technologies have opened the door to analyzing a variety of functional genomic features in individual cells. These technologies enable scientists to systematically discover unknown cell subpopulations in complex tissue and disease samples, and allow them to reconstruct a sample's gene regulatory landscape at an unprecedented cellular resolution. Despite these promising developments, many challenges still exist and must be overcome before one can fully decode gene regulation at the single-cell resolution. In particular, current technologies lack the ability to accurately measure the activity of each individual cis-regulatory element (CRE) in a single cell. They also cannot measure all functional genomic data types in the same cell. Moreover, the prevalent technical biases and noises in single-cell genomic data make computational analysis non-trivial. With rapid growth of data, lack of computational tools for data analysis has become a rate-limiting factor for effective applications of single-cell genomic technologies.  The objective of this proposal is to develop computational and statistical methods and software tools for mapping and analyzing gene regulatory landscape using single-cell genomic data. Our Aim 1 addresses the challenge of accurately measuring CRE activities in single cells using single-cell regulome data. Regulome, deﬁned as the activities of all cis-regulatory elements in a genome, contains crucial information for understanding gene regulation. The state-of-the-art technologies for mapping regulome in a single cell produce sparse data that cannot accurately measure activities of individual CREs. We will develop a new computational framework to allow more accurate analysis of individual CREs' activities in single cells using sparse data. Our Aim 2 addresses the challenge of collecting multiple functional genomic data types in the same cell. We will develop a method that uses single-cell RNA sequencing (scRNA-seq), the most widely used single-cell functional genomic technology, to predict cells' regulatory landscape. Since most scRNA-seq datasets do not have accompanying single-cell data for other -omics data types, our method will also signiﬁcantly expand the utility and increase the value of scRNA- seq experiments. Our Aim 3 addresses the challenge of integrating different data types generated by different single-cell genomic technologies from different cells. We will develop a method to align single-cell RNA-seq and single-cell regulome data to generate an integrated map of transcriptome and regulome.  Upon completion of this proposal, we will deliver our methods through open-source software tools. These tools will be widely useful for analyzing and integrating single-cell regulome and transcriptome data. By addressing several major challenges in single-cell genomics, our new methods and tools will help unleash the full potential of single-cell genomic technologies for studying gene regulation. As such, they can have a major impact on advancing our understanding of both basic biology and human diseases. Project Narrative Understanding how genes' activities are controlled at single-cell resolution is crucial for studying human diseases. This proposal will develop a coordinated set of computational and statistical methods and software tools for mapping and analyzing gene regulatory programs using single-cell genomic data. These methods and tools will allow scientists to more accurately and comprehensively reconstruct gene regulatory landscape of individual cells in complex tissue and disease samples, and they can have a major impact on advancing our understanding of both basic biology and human diseases.",Computational tools for regulome mapping using single-cell genomic data,9649896,R01HG010889,"['Address', 'Atlases', 'Behavior', 'Biological', 'Biology', 'Biomedical Research', 'Brain', 'Cells', 'Cellular Assay', 'Chromatin', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Emerging Technologies', 'Foundations', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genomics', 'Human', 'Immune system', 'Individual', 'Knowledge', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Modality', 'Molecular', 'Multiomic Data', 'Noise', 'Organ', 'Phase', 'Population', 'Regulator Genes', 'Regulatory Element', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Software Tools', 'Statistical Methods', 'Stem Cell Development', 'System', 'Technology', 'Therapeutic', 'Tissues', 'Training', 'Transposase', 'base', 'computer framework', 'computerized tools', 'epigenome', 'experimental study', 'functional genomics', 'genomic data', 'histone modification', 'human disease', 'innovation', 'multiple omics', 'novel strategies', 'open source', 'predictive modeling', 'programs', 'rapid growth', 'single cell analysis', 'single cell technology', 'single-cell RNA sequencing', 'supervised learning', 'tool', 'transcriptome', 'transcriptome sequencing', 'user-friendly']",NHGRI,JOHNS HOPKINS UNIVERSITY,R01,2019,409375,-0.007706102282278429
"Center for Integrated Cellular Analysis Abstract While rapid advances in single-cell RNA-sequencing are yielding comprehensive taxonomies of cell states in the human body, understanding the complex molecular and environmental factors that regulate cell behavior remains a central challenge. New methods for simultaneous measurement of multiple molecular modalities, spatial context, and lineage relationships are needed to address this goal, but are currently outside the scope of present technologies which largely focus on a single data type. We propose to create a Center for Integrated Cellular Analysis, with a mission to develop a comprehensive suite of technologies and analytical methods to measure and integrate the molecular and environmental determinants of cellular identity. To achieve these goals, we propose the following series of synergistic Aims that will be developed in parallel: 1) Develop massively- parallel assays to simultaneously profile multiple molecular components across millions of cells; 2) Identify the spatial and environmental determinants of cellular state in complex interacting populations; 3) Develop scalable platforms to profile inherited molecular components, and determine the role of cell lineage in establishing molecular and phenotypic differences across cells; and 4) Develop methods to harmonize single- cell profiles across distinct modalities, enabling the inference of cellular identity. Our Center will address critical challenges in data integration, and produce software and protocols that will be applicable to diverse biological systems. We will share these resources broadly with the community, alongside a broader educational focus to encourage New York City students from under-represented backgrounds to pursue academic training in Genomics and Systems Biology. Project Narrative Understanding how the molecular components, inherited lineage, and spatial milieu of single cells dictate function in health and disease remains a key outstanding challenge in genomics. The overarching goal of our Center for Integrated Cellular Analysis is to develop methods to simultaneously assess these multimodal cellular properties, develop tools to harmonize them to allow inferential assessment of cell identity based on partial phenotyping, and share these developments with the broad scientific community while encouraging community engagement through education and outreach. Success in our strategy will facilitate deep, multi-omic phenotyping of single cells for basic research and clinical applications.",Center for Integrated Cellular Analysis,9932724,RM1HG011014,"['Academic Training', 'Address', 'Anatomy', 'Atlases', 'Awareness', 'Basic Science', 'Biological', 'Biological Assay', 'Cell Communication', 'Cell Lineage', 'Cells', 'Chromatin', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Methylation', 'Data', 'Data Set', 'Development', 'Disease', 'Education and Outreach', 'Ensure', 'Environmental Risk Factor', 'Epitopes', 'Genes', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Health', 'Heritability', 'Human body', 'Immunofluorescence Immunologic', 'In Situ', 'Individual', 'Inherited', 'Joints', 'Learning', 'Measurement', 'Measures', 'Membrane Proteins', 'Messenger RNA', 'Methods', 'Mission', 'Modality', 'Molecular', 'New York City', 'Output', 'Phenotype', 'Play', 'Population', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Proteome', 'Protocols documentation', 'Recording of previous events', 'Resolution', 'Resource Sharing', 'Role', 'Series', 'Signal Transduction', 'Source', 'Systems Biology', 'Taxonomy', 'Technology', 'Time', 'Underrepresented Students', 'Variant', 'analytical method', 'base', 'biological systems', 'cell behavior', 'clinical application', 'combinatorial', 'cost', 'data integration', 'deep learning', 'epigenome', 'experimental study', 'extracellular', 'indexing', 'innovation', 'insight', 'molecular phenotype', 'multimodality', 'multiple omics', 'novel strategies', 'outreach', 'reconstruction', 'single cell sequencing', 'single-cell RNA sequencing', 'success', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,RM1,2020,2000000,-0.005666912818311993
"A next-generation morbid map of the human genome PROJECT SUMMARY/ABSTRACT The impact of next-generation sequencing (NGS) on gene discovery and molecular diagnostics for Mendelian conditions (MCs) is hard to overstate. However, to provide affected individuals with precise natural history, recurrence risk, and prognosis in clinical settings, identification of pathogenic variant(s)/genotypes alone is often insufficient. This is a challenge most notably for genes that cause more than one MC or ~25% of all genes that underlie MCs. In such an instance, even with a known genotype a patient's phenotype has to be compared to that of all MCs caused by variants in a gene to determine which MC, if any, is the likely diagnosis or whether patient instead has a novel condition. This comparison is increasingly difficult because delineation of the ~5,100 MCs currently known has typically been based on subjective grouping of affected individuals by phenotypic similarity. We propose to develop a quantitative framework for assessing overlap among the distributions of phenotypes due to pathogenic genotypes the same gene and apply this framework genome-wide. NGS has enabled identification of causal genotypes in hundreds of thousands of individuals with MCs, providing a sufficiently large dataset that it is now feasible to use machine learning to quantitatively and systematically identify “clusters” of co-occurring genotypes and phenotypic features for each known gene. We will refine and validate our approach by comparing differences between conventionally-delineated and quantitatively-delineated MCs and by assessing the similarity of individuals with well-studied atypical phenotypes/genotypes to quantitatively-delineated MCs. We will then apply the optimal strategy across the genome to generate a “next- generation morbid map” based on quantitatively-delineated MCs. We will also apply machine learning approaches to identify genomic properties associated with the propensity for each gene to underlie multiple MCs (i.e., the numeric contribution of each gene to the morbid map or phenotropy). This will enable a more precise and complete understanding of the genotypic and phenotypic spectrum of each MC, enable more objective diagnosis of individuals with atypical phenotypes, and more robustly identify the existence of multiple MCs among individuals with non-specific “class” phenotypes (e.g., developmental delay, autism, hearing impairment). We will make all newly developed methods publicly available via interactive and programmatic web-based tools to facilitate extension of this work to other human and model organism datasets. PROJECT NARRATIVE The major goals of this project are to develop a quantitative framework that enables objective delineation of Mendelian conditions, apply the framework to systematically delineate conditions across all genes known to underlie a Mendelian condition, and predict the number of conditions due to each gene. This framework will provide a fuller, unbiased characterization of the genotypic/phenotypic spectrum for all Mendelian conditions, enable more precise diagnoses and counseling of individuals with difficult to diagnose phenotypes, and accelerate the detection of new Mendelian conditions.",A next-generation morbid map of the human genome,10047366,R35HG011297,"['Affect', 'Animal Model', 'Clinical', 'Counseling', 'Data Set', 'Detection', 'Developmental Delay Disorders', 'Diagnosis', 'Genes', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Grouping', 'Human', 'Human Genome', 'Individual', 'Machine Learning', 'Maps', 'Methods', 'Natural History', 'Pathogenicity', 'Patients', 'Phenotype', 'Property', 'Recurrence', 'Risk', 'Variant', 'Work', 'autism spectrum disorder', 'base', 'gene discovery', 'genome-wide', 'hearing impairment', 'large datasets', 'molecular diagnostics', 'next generation', 'next generation sequencing', 'novel', 'outcome forecast', 'web-based tool']",NHGRI,UNIVERSITY OF WASHINGTON,R35,2020,466172,-0.06224529480278157
"Bioinformatics Strategies for Multidimensional Brain Imaging Genetics DESCRIPTION (provided by applicant):         Today's generation of multi-modal imaging systems produces massive high dimensional data sets, which when coupled with high throughput genotyping data such as single nucleotide polymorphisms (SNPs), provide exciting opportunities to enhance our understanding of phenotypic characteristics and the genetic architecture of human diseases. However, the unprecedented scale and complexity of these data sets have presented critical computational bottlenecks requiring new concepts and enabling tools. To address these challenges, using the study of Alzheimer's disease (AD) as a test bed, this project will develop and validate novel bioinformatics strategies for multidimensional brain imaging genetics. Aim 1 is to develop a novel bi- multivariate analysis strategy, S3K-CCA, for studying imaging genetic associations. Existing imaging genetics methods are typically designed to discover single-SNP-single-QT, single-SNP-multi-QT or multi-SNP-single- QT associations, and have limited power in revealing complex relationships between interlinked genetic markers and correlated brain phenotypes. To overcome this limitation, S3K-CCA is designed to be a sparse bi- multivariate learning model that simultaneously uses multiple response variables with multiple predictors for analyzing large-scale multi-modal neurogenomic data. Aim 2 is to develop HD-BIG, a visualization and systems biology framework for integrative analysis of High-Dimensional Brain Imaging Genetics data. Machine learning strategies to seamlessly incorporate valuable domain knowledge to produce biologically meaningful results is still an under-explored area in imaging genetics. In this aim, we will develop a user-friendly heat map interface to visualize high-dimensional results, adjust learning parameters and strategies, interact with existing bioinformatics resources and tools, and facilitate visual exploratory and systems biology analysis. A novel imaging genetic enrichment analysis (IGEA) method will be developed to identify relevant genetic pathways and associated brain circuits, and to reveal complex relationships among them. Aim 3 is to evaluate the proposed S3K-CCA and IGEA methods and the HD-BIG framework using both simulated and real imaging genetics data. This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale heterogeneous imaging genetics data. The availability of these powerful methods is critical to the success of many imaging genetics initiatives. In addition, they can also help enable new computational applications in other areas of biomedical research where systematic and integrative analysis of large-scale multi-modal data is critical. Using AD as an exemplar, the proposed methods will demonstrate the potential for enhancing mechanistic understanding of complex disorders, which can benefit public health outcomes by facilitating diagnostic and therapeutic progress. Public Health Relevance (Narrative) Recent advances in multi-modal imaging and high throughput genotyping techniques provide exciting opportunities to enhance our understanding of phenotypic characteristics and underlying genetic mechanisms associated with human diseases. This proposal seeks to develop new bi-multivariate machine learning models and novel enrichment analysis methods, coupled with a visualization and systems biology framework, for integrative analysis of high-dimensional brain imaging genetics data. The methods and tools are developed and evaluated in an imaging genetic study of Alzheimer's disease, and can also be applied to many other disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Bioinformatics Strategies for Multidimensional Brain Imaging Genetics,8913771,R01LM011360,"['Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Atlases', 'Beds', 'Biochemical Pathway', 'Bioinformatics', 'Biological Markers', 'Biomedical Research', 'Brain', 'Brain imaging', 'Characteristics', 'Clinical', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Epidemiology', 'Evaluation', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Genetic study', 'Genomics', 'Genotype', 'Heart', 'Heating', 'Human', 'Image', 'Imagery', 'Investigation', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Multivariate Analysis', 'Ontology', 'Outcome', 'Participant', 'Pathway interactions', 'Phenotype', 'Positron-Emission Tomography', 'Public Health', 'Research', 'Resources', 'Single Nucleotide Polymorphism', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Visual', 'base', 'cohort', 'density', 'design', 'genetic association', 'genome wide association study', 'genome-wide', 'human disease', 'imaging system', 'improved', 'interest', 'mild cognitive impairment', 'neuroimaging', 'neuropsychological', 'novel', 'novel strategies', 'public health relevance', 'public-private partnership', 'response', 'simulation', 'success', 'tool', 'trait', 'user-friendly']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2015,330386,-0.06404864995188832
"Bioinformatics Strategies for Multidimensional Brain Imaging Genetics     DESCRIPTION (provided by applicant):         Today's generation of multi-modal imaging systems produces massive high dimensional data sets, which when coupled with high throughput genotyping data such as single nucleotide polymorphisms (SNPs), provide exciting opportunities to enhance our understanding of phenotypic characteristics and the genetic architecture of human diseases. However, the unprecedented scale and complexity of these data sets have presented critical computational bottlenecks requiring new concepts and enabling tools. To address these challenges, using the study of Alzheimer's disease (AD) as a test bed, this project will develop and validate novel bioinformatics strategies for multidimensional brain imaging genetics. Aim 1 is to develop a novel bi- multivariate analysis strategy, S3K-CCA, for studying imaging genetic associations. Existing imaging genetics methods are typically designed to discover single-SNP-single-QT, single-SNP-multi-QT or multi-SNP-single- QT associations, and have limited power in revealing complex relationships between interlinked genetic markers and correlated brain phenotypes. To overcome this limitation, S3K-CCA is designed to be a sparse bi- multivariate learning model that simultaneously uses multiple response variables with multiple predictors for analyzing large-scale multi-modal neurogenomic data. Aim 2 is to develop HD-BIG, a visualization and systems biology framework for integrative analysis of High-Dimensional Brain Imaging Genetics data. Machine learning strategies to seamlessly incorporate valuable domain knowledge to produce biologically meaningful results is still an under-explored area in imaging genetics. In this aim, we will develop a user-friendly heat map interface to visualize high-dimensional results, adjust learning parameters and strategies, interact with existing bioinformatics resources and tools, and facilitate visual exploratory and systems biology analysis. A novel imaging genetic enrichment analysis (IGEA) method will be developed to identify relevant genetic pathways and associated brain circuits, and to reveal complex relationships among them. Aim 3 is to evaluate the proposed S3K-CCA and IGEA methods and the HD-BIG framework using both simulated and real imaging genetics data. This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale heterogeneous imaging genetics data. The availability of these powerful methods is critical to the success of many imaging genetics initiatives. In addition, they can also help enable new computational applications in other areas of biomedical research where systematic and integrative analysis of large-scale multi-modal data is critical. Using AD as an exemplar, the proposed methods will demonstrate the potential for enhancing mechanistic understanding of complex disorders, which can benefit public health outcomes by facilitating diagnostic and therapeutic progress.             Public Health Relevance (Narrative) Recent advances in multi-modal imaging and high throughput genotyping techniques provide exciting opportunities to enhance our understanding of phenotypic characteristics and underlying genetic mechanisms associated with human diseases. This proposal seeks to develop new bi-multivariate machine learning models and novel enrichment analysis methods, coupled with a visualization and systems biology framework, for integrative analysis of high-dimensional brain imaging genetics data. The methods and tools are developed and evaluated in an imaging genetic study of Alzheimer's disease, and can also be applied to many other disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Bioinformatics Strategies for Multidimensional Brain Imaging Genetics,8714056,R01LM011360,"['Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Atlases', 'Beds', 'Biochemical Pathway', 'Bioinformatics', 'Biological Markers', 'Biomedical Research', 'Brain', 'Brain imaging', 'Characteristics', 'Clinical', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Epidemiology', 'Evaluation', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Genomics', 'Genotype', 'Heart', 'Heating', 'Human', 'Image', 'Imagery', 'Investigation', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Multivariate Analysis', 'Ontology', 'Outcome', 'Participant', 'Pathway interactions', 'Phenotype', 'Positron-Emission Tomography', 'Public Health', 'Research', 'Resources', 'Simulate', 'Single Nucleotide Polymorphism', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Visual', 'base', 'cohort', 'density', 'design', 'genetic association', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'interest', 'mild cognitive impairment', 'neuroimaging', 'neuropsychological', 'novel', 'novel strategies', 'public health relevance', 'public-private partnership', 'response', 'simulation', 'success', 'tool', 'trait', 'user-friendly']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2014,330386,-0.06404864995188832
"Bioinformatics Strategies for Multidimensional Brain Imaging Genetics     DESCRIPTION (provided by applicant):         Today's generation of multi-modal imaging systems produces massive high dimensional data sets, which when coupled with high throughput genotyping data such as single nucleotide polymorphisms (SNPs), provide exciting opportunities to enhance our understanding of phenotypic characteristics and the genetic architecture of human diseases. However, the unprecedented scale and complexity of these data sets have presented critical computational bottlenecks requiring new concepts and enabling tools. To address these challenges, using the study of Alzheimer's disease (AD) as a test bed, this project will develop and validate novel bioinformatics strategies for multidimensional brain imaging genetics. Aim 1 is to develop a novel bi- multivariate analysis strategy, S3K-CCA, for studying imaging genetic associations. Existing imaging genetics methods are typically designed to discover single-SNP-single-QT, single-SNP-multi-QT or multi-SNP-single- QT associations, and have limited power in revealing complex relationships between interlinked genetic markers and correlated brain phenotypes. To overcome this limitation, S3K-CCA is designed to be a sparse bi- multivariate learning model that simultaneously uses multiple response variables with multiple predictors for analyzing large-scale multi-modal neurogenomic data. Aim 2 is to develop HD-BIG, a visualization and systems biology framework for integrative analysis of High-Dimensional Brain Imaging Genetics data. Machine learning strategies to seamlessly incorporate valuable domain knowledge to produce biologically meaningful results is still an under-explored area in imaging genetics. In this aim, we will develop a user-friendly heat map interface to visualize high-dimensional results, adjust learning parameters and strategies, interact with existing bioinformatics resources and tools, and facilitate visual exploratory and systems biology analysis. A novel imaging genetic enrichment analysis (IGEA) method will be developed to identify relevant genetic pathways and associated brain circuits, and to reveal complex relationships among them. Aim 3 is to evaluate the proposed S3K-CCA and IGEA methods and the HD-BIG framework using both simulated and real imaging genetics data. This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale heterogeneous imaging genetics data. The availability of these powerful methods is critical to the success of many imaging genetics initiatives. In addition, they can also help enable new computational applications in other areas of biomedical research where systematic and integrative analysis of large-scale multi-modal data is critical. Using AD as an exemplar, the proposed methods will demonstrate the potential for enhancing mechanistic understanding of complex disorders, which can benefit public health outcomes by facilitating diagnostic and therapeutic progress.              Public Health Relevance (Narrative) Recent advances in multi-modal imaging and high throughput genotyping techniques provide exciting opportunities to enhance our understanding of phenotypic characteristics and underlying genetic mechanisms associated with human diseases. This proposal seeks to develop new bi-multivariate machine learning models and novel enrichment analysis methods, coupled with a visualization and systems biology framework, for integrative analysis of high-dimensional brain imaging genetics data. The methods and tools are developed and evaluated in an imaging genetic study of Alzheimer's disease, and can also be applied to many other disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Bioinformatics Strategies for Multidimensional Brain Imaging Genetics,8538499,R01LM011360,"['Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Atlases', 'Beds', 'Biochemical Pathway', 'Bioinformatics', 'Biological Markers', 'Biomedical Research', 'Brain', 'Brain imaging', 'Characteristics', 'Clinical', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Epidemiology', 'Evaluation', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Genomics', 'Genotype', 'Heart', 'Heating', 'Human', 'Image', 'Imagery', 'Investigation', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Multivariate Analysis', 'Ontology', 'Outcome', 'Participant', 'Pathway interactions', 'Phenotype', 'Positron-Emission Tomography', 'Public Health', 'Research', 'Resources', 'Simulate', 'Single Nucleotide Polymorphism', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Visual', 'base', 'cohort', 'density', 'design', 'genetic association', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'interest', 'mild cognitive impairment', 'neuroimaging', 'neuropsychological', 'novel', 'novel strategies', 'public health relevance', 'public-private partnership', 'response', 'simulation', 'success', 'tool', 'trait', 'user-friendly']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2013,313357,-0.06404864995188832
"Bioinformatics Strategies for Multidimensional Brain Imaging Genetics     DESCRIPTION (provided by applicant):         Today's generation of multi-modal imaging systems produces massive high dimensional data sets, which when coupled with high throughput genotyping data such as single nucleotide polymorphisms (SNPs), provide exciting opportunities to enhance our understanding of phenotypic characteristics and the genetic architecture of human diseases. However, the unprecedented scale and complexity of these data sets have presented critical computational bottlenecks requiring new concepts and enabling tools. To address these challenges, using the study of Alzheimer's disease (AD) as a test bed, this project will develop and validate novel bioinformatics strategies for multidimensional brain imaging genetics. Aim 1 is to develop a novel bi- multivariate analysis strategy, S3K-CCA, for studying imaging genetic associations. Existing imaging genetics methods are typically designed to discover single-SNP-single-QT, single-SNP-multi-QT or multi-SNP-single- QT associations, and have limited power in revealing complex relationships between interlinked genetic markers and correlated brain phenotypes. To overcome this limitation, S3K-CCA is designed to be a sparse bi- multivariate learning model that simultaneously uses multiple response variables with multiple predictors for analyzing large-scale multi-modal neurogenomic data. Aim 2 is to develop HD-BIG, a visualization and systems biology framework for integrative analysis of High-Dimensional Brain Imaging Genetics data. Machine learning strategies to seamlessly incorporate valuable domain knowledge to produce biologically meaningful results is still an under-explored area in imaging genetics. In this aim, we will develop a user-friendly heat map interface to visualize high-dimensional results, adjust learning parameters and strategies, interact with existing bioinformatics resources and tools, and facilitate visual exploratory and systems biology analysis. A novel imaging genetic enrichment analysis (IGEA) method will be developed to identify relevant genetic pathways and associated brain circuits, and to reveal complex relationships among them. Aim 3 is to evaluate the proposed S3K-CCA and IGEA methods and the HD-BIG framework using both simulated and real imaging genetics data. This project is expected to produce novel bioinformatics algorithms and tools for comprehensive joint analysis of large scale heterogeneous imaging genetics data. The availability of these powerful methods is critical to the success of many imaging genetics initiatives. In addition, they can also help enable new computational applications in other areas of biomedical research where systematic and integrative analysis of large-scale multi-modal data is critical. Using AD as an exemplar, the proposed methods will demonstrate the potential for enhancing mechanistic understanding of complex disorders, which can benefit public health outcomes by facilitating diagnostic and therapeutic progress.              Public Health Relevance (Narrative) Recent advances in multi-modal imaging and high throughput genotyping techniques provide exciting opportunities to enhance our understanding of phenotypic characteristics and underlying genetic mechanisms associated with human diseases. This proposal seeks to develop new bi-multivariate machine learning models and novel enrichment analysis methods, coupled with a visualization and systems biology framework, for integrative analysis of high-dimensional brain imaging genetics data. The methods and tools are developed and evaluated in an imaging genetic study of Alzheimer's disease, and can also be applied to many other disorders to improve public health outcomes by facilitating diagnostic and therapeutic progress.",Bioinformatics Strategies for Multidimensional Brain Imaging Genetics,8342777,R01LM011360,"['Address', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Atlases', 'Beds', 'Biochemical Pathway', 'Bioinformatics', 'Biological Markers', 'Biomedical Research', 'Brain', 'Brain imaging', 'Characteristics', 'Clinical', 'Complex', 'Coupled', 'Data', 'Data Set', 'Diagnostic', 'Disease', 'Epidemiology', 'Evaluation', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Genomics', 'Genotype', 'Heart', 'Heating', 'Human', 'Image', 'Imagery', 'Investigation', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Multivariate Analysis', 'Ontology', 'Outcome', 'Participant', 'Pathway interactions', 'Phenotype', 'Positron-Emission Tomography', 'Public Health', 'Research', 'Resources', 'Simulate', 'Single Nucleotide Polymorphism', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Visual', 'base', 'cohort', 'density', 'design', 'genetic association', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'interest', 'mild neurocognitive impairment', 'neuroimaging', 'neuropsychological', 'novel', 'novel strategies', 'public health relevance', 'public-private partnership', 'response', 'simulation', 'success', 'tool', 'trait', 'user-friendly']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2012,405500,-0.06404864995188832
"Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular DESCRIPTION (provided by applicant): A career development plan is proposed for Dr. David Mayerich, a computer scientist who is committed to developing an interdisciplinary career in biomedical engineering, with a focus on the collection and analysis of large-scale data sets at sub-micrometer resolution. His graduate research was in the areas of computer visualization and optical imaging, where his work lead to the development of the prototype Knife-Edge Scanning Microscope (KESM). This is the first instrument capable of imaging three-dimensional macro-scale tissue volumes at sub-micrometer resolution while providing a data rate approaching the transfer speed of most modern computer systems.         Since receiving his Ph.D., Dr. Mayerich worked as a postdoctoral fellow at the Beckman Institute for Advanced Science and Technology at the University of Illinois at Urbana-Champaign, where he has worked with biologists and biomedical engineers to develop tools for the segmentation and classification of large data sets. This provided experience in addressing the needs and limitations of the computational tools available to the interdisciplinary community.        The goal of the mentored phase of this proposal is to provide Dr. Mayerich with the opportunity to work as a developer for the FARSIGHT Toolkit. The FARSIGHT Toolkit is an open-source segmentation toolkit that focuses on developing computer vision algorithms specifically tailored to deal with the unique structures found in microscopy data sets. This project is directed by Prof. Badrinath Roysam at the University of Houston, and was awarded first-place in the NIH-sponsored DIADEM Challenge in neuron segmentation. Dr. Mayerich will use his previous experience in biomedical segmentation, GPU-based computing, and efficient data structures to help make the FARSIGHT Toolkit scalable to the terabyte-scale data sets produced using next-generation high-throughput imaging techniques. Dr. Mayerich will receive mentoring in the algorithms and techniques used in the FARSIGHT Toolkit, as well as valuable experience working on a collaborative software development project.         The goal of the independent phase is to use recently developed imaging techniques, along with scalable segmentation algorithms, to construct complete microvascular models of mouse organs. Recent advances in KESM demonstrate that sub-micrometer images of 1cm3 tissue samples can be collected in less than 50 hours. These images have the resolution and quality necessary for (a) complete reconstruction of microvascular networks in whole organs, and (b) the geometric distribution of cell soma in relation to this network. Models describing cellular and microvascular relationships have implications in several diseases, including neurodegenerative disease and tumor growth, as well as clinical applications in tissue engineering and the quantitative analysis of angiogenic drugs and therapies. PROJECT NARRATIVE The goal of this work is to produce high-resolution microvascular models from mouse brain tissue, as well as create algorithms for querying, distributing, and building models from next-generation high-throughput microscopy data sets. These techniques will allow researchers to create large-scale blood flow simulations, simulate the extent of tissue damage due to stroke or aneurism, and explore the relationships between cells and microvessels on a tissue-wide scale. Clinical applications include the quantification of angiogenesis in tumors and tissue implants, and the quantification of neurovascular effects in neurodegenerative disease models.",Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular,9117645,R00LM011390,"['Active Learning', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood Vessels', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Doctor of Philosophy', 'Funding', 'Future', 'Goals', 'Hour', 'Illinois', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Institutes', 'Lead', 'Learning', 'Machine Learning', 'Memory', 'Mentors', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Mus', 'Neurodegenerative Disorders', 'Neurons', 'Online Systems', 'Organ', 'Pharmacotherapy', 'Phase', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Speed', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Engineering', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'Transgenic Organisms', 'Tumor Angiogenesis', 'Tumor Tissue', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'angiogenesis', 'base', 'brain tissue', 'career', 'career development', 'clinical application', 'computerized tools', 'design', 'experience', 'imaging Segmentation', 'improved', 'instrument', 'learning strategy', 'memory process', 'model building', 'mouse model', 'neuronal cell body', 'neurovascular', 'next generation', 'open source', 'optical imaging', 'programs', 'prototype', 'reconstruction', 'research study', 'simulation', 'software development', 'success', 'terabyte', 'tool', 'tumor growth']",NLM,UNIVERSITY OF HOUSTON,R00,2016,244245,-0.02168955972769288
"Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular DESCRIPTION (provided by applicant): A career development plan is proposed for Dr. David Mayerich, a computer scientist who is committed to developing an interdisciplinary career in biomedical engineering, with a focus on the collection and analysis of large-scale data sets at sub-micrometer resolution. His graduate research was in the areas of computer visualization and optical imaging, where his work lead to the development of the prototype Knife-Edge Scanning Microscope (KESM). This is the first instrument capable of imaging three-dimensional macro-scale tissue volumes at sub-micrometer resolution while providing a data rate approaching the transfer speed of most modern computer systems.         Since receiving his Ph.D., Dr. Mayerich worked as a postdoctoral fellow at the Beckman Institute for Advanced Science and Technology at the University of Illinois at Urbana-Champaign, where he has worked with biologists and biomedical engineers to develop tools for the segmentation and classification of large data sets. This provided experience in addressing the needs and limitations of the computational tools available to the interdisciplinary community.        The goal of the mentored phase of this proposal is to provide Dr. Mayerich with the opportunity to work as a developer for the FARSIGHT Toolkit. The FARSIGHT Toolkit is an open-source segmentation toolkit that focuses on developing computer vision algorithms specifically tailored to deal with the unique structures found in microscopy data sets. This project is directed by Prof. Badrinath Roysam at the University of Houston, and was awarded first-place in the NIH-sponsored DIADEM Challenge in neuron segmentation. Dr. Mayerich will use his previous experience in biomedical segmentation, GPU-based computing, and efficient data structures to help make the FARSIGHT Toolkit scalable to the terabyte-scale data sets produced using next-generation high-throughput imaging techniques. Dr. Mayerich will receive mentoring in the algorithms and techniques used in the FARSIGHT Toolkit, as well as valuable experience working on a collaborative software development project.         The goal of the independent phase is to use recently developed imaging techniques, along with scalable segmentation algorithms, to construct complete microvascular models of mouse organs. Recent advances in KESM demonstrate that sub-micrometer images of 1cm3 tissue samples can be collected in less than 50 hours. These images have the resolution and quality necessary for (a) complete reconstruction of microvascular networks in whole organs, and (b) the geometric distribution of cell soma in relation to this network. Models describing cellular and microvascular relationships have implications in several diseases, including neurodegenerative disease and tumor growth, as well as clinical applications in tissue engineering and the quantitative analysis of angiogenic drugs and therapies. PROJECT NARRATIVE The goal of this work is to produce high-resolution microvascular models from mouse brain tissue, as well as create algorithms for querying, distributing, and building models from next-generation high-throughput microscopy data sets. These techniques will allow researchers to create large-scale blood flow simulations, simulate the extent of tissue damage due to stroke or aneurism, and explore the relationships between cells and microvessels on a tissue-wide scale. Clinical applications include the quantification of angiogenesis in tumors and tissue implants, and the quantification of neurovascular effects in neurodegenerative disease models.",Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular,8920669,R00LM011390,"['Active Learning', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood Vessels', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Doctor of Philosophy', 'Funding', 'Future', 'Goals', 'Hour', 'Illinois', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Institutes', 'Lead', 'Learning', 'Machine Learning', 'Memory', 'Mentors', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Mus', 'Neurodegenerative Disorders', 'Neurons', 'Online Systems', 'Organ', 'Pharmacotherapy', 'Phase', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Speed', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Engineering', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'Transgenic Organisms', 'Tumor Angiogenesis', 'Tumor Tissue', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'angiogenesis', 'base', 'brain tissue', 'career', 'career development', 'clinical application', 'computerized tools', 'design', 'experience', 'imaging Segmentation', 'improved', 'instrument', 'memory process', 'model building', 'mouse model', 'neuronal cell body', 'next generation', 'open source', 'optical imaging', 'programs', 'prototype', 'reconstruction', 'research study', 'simulation', 'software development', 'success', 'tool', 'tumor growth']",NLM,UNIVERSITY OF HOUSTON,R00,2015,239130,-0.02168955972769288
"Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular DESCRIPTION (provided by applicant): A career development plan is proposed for Dr. David Mayerich, a computer scientist who is committed to developing an interdisciplinary career in biomedical engineering, with a focus on the collection and analysis of large-scale data sets at sub-micrometer resolution. His graduate research was in the areas of computer visualization and optical imaging, where his work lead to the development of the prototype Knife-Edge Scanning Microscope (KESM). This is the first instrument capable of imaging three-dimensional macro-scale tissue volumes at sub-micrometer resolution while providing a data rate approaching the transfer speed of most modern computer systems.         Since receiving his Ph.D., Dr. Mayerich worked as a postdoctoral fellow at the Beckman Institute for Advanced Science and Technology at the University of Illinois at Urbana-Champaign, where he has worked with biologists and biomedical engineers to develop tools for the segmentation and classification of large data sets. This provided experience in addressing the needs and limitations of the computational tools available to the interdisciplinary community.        The goal of the mentored phase of this proposal is to provide Dr. Mayerich with the opportunity to work as a developer for the FARSIGHT Toolkit. The FARSIGHT Toolkit is an open-source segmentation toolkit that focuses on developing computer vision algorithms specifically tailored to deal with the unique structures found in microscopy data sets. This project is directed by Prof. Badrinath Roysam at the University of Houston, and was awarded first-place in the NIH-sponsored DIADEM Challenge in neuron segmentation. Dr. Mayerich will use his previous experience in biomedical segmentation, GPU-based computing, and efficient data structures to help make the FARSIGHT Toolkit scalable to the terabyte-scale data sets produced using next-generation high-throughput imaging techniques. Dr. Mayerich will receive mentoring in the algorithms and techniques used in the FARSIGHT Toolkit, as well as valuable experience working on a collaborative software development project.         The goal of the independent phase is to use recently developed imaging techniques, along with scalable segmentation algorithms, to construct complete microvascular models of mouse organs. Recent advances in KESM demonstrate that sub-micrometer images of 1cm3 tissue samples can be collected in less than 50 hours. These images have the resolution and quality necessary for (a) complete reconstruction of microvascular networks in whole organs, and (b) the geometric distribution of cell soma in relation to this network. Models describing cellular and microvascular relationships have implications in several diseases, including neurodegenerative disease and tumor growth, as well as clinical applications in tissue engineering and the quantitative analysis of angiogenic drugs and therapies. PROJECT NARRATIVE The goal of this work is to produce high-resolution microvascular models from mouse brain tissue, as well as create algorithms for querying, distributing, and building models from next-generation high-throughput microscopy data sets. These techniques will allow researchers to create large-scale blood flow simulations, simulate the extent of tissue damage due to stroke or aneurism, and explore the relationships between cells and microvessels on a tissue-wide scale. Clinical applications include the quantification of angiogenesis in tumors and tissue implants, and the quantification of neurovascular effects in neurodegenerative disease models.",Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular,8916335,R00LM011390,"['Active Learning', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood Vessels', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical Research', 'Collection', 'Commit', 'Communities', 'Complex', 'Computer Systems', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Doctor of Philosophy', 'Funding', 'Future', 'Goals', 'Hour', 'Illinois', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Institutes', 'Lead', 'Learning', 'Machine Learning', 'Memory', 'Mentors', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Mus', 'Neurodegenerative Disorders', 'Neurons', 'Online Systems', 'Organ', 'Pharmacotherapy', 'Phase', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Simulate', 'Speed', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Engineering', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'Transgenic Organisms', 'Tumor Angiogenesis', 'Tumor Tissue', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'angiogenesis', 'base', 'brain tissue', 'career', 'career development', 'clinical application', 'computerized tools', 'design', 'experience', 'imaging Segmentation', 'improved', 'instrument', 'memory process', 'mouse model', 'neuronal cell body', 'next generation', 'open source', 'optical imaging', 'programs', 'prototype', 'reconstruction', 'research study', 'simulation', 'software development', 'success', 'tool', 'tumor growth']",NLM,UNIVERSITY OF HOUSTON,R00,2014,246867,-0.02168955972769288
"Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular     DESCRIPTION (provided by applicant): A career development plan is proposed for Dr. David Mayerich, a computer scientist who is committed to developing an interdisciplinary career in biomedical engineering, with a focus on the collection and analysis of large-scale data sets at sub-micrometer resolution. His graduate research was in the areas of computer visualization and optical imaging, where his work lead to the development of the prototype Knife-Edge Scanning Microscope (KESM). This is the first instrument capable of imaging three-dimensional macro-scale tissue volumes at sub-micrometer resolution while providing a data rate approaching the transfer speed of most modern computer systems.         Since receiving his Ph.D., Dr. Mayerich worked as a postdoctoral fellow at the Beckman Institute for Advanced Science and Technology at the University of Illinois at Urbana-Champaign, where he has worked with biologists and biomedical engineers to develop tools for the segmentation and classification of large data sets. This provided experience in addressing the needs and limitations of the computational tools available to the interdisciplinary community.        The goal of the mentored phase of this proposal is to provide Dr. Mayerich with the opportunity to work as a developer for the FARSIGHT Toolkit. The FARSIGHT Toolkit is an open-source segmentation toolkit that focuses on developing computer vision algorithms specifically tailored to deal with the unique structures found in microscopy data sets. This project is directed by Prof. Badrinath Roysam at the University of Houston, and was awarded first-place in the NIH-sponsored DIADEM Challenge in neuron segmentation. Dr. Mayerich will use his previous experience in biomedical segmentation, GPU-based computing, and efficient data structures to help make the FARSIGHT Toolkit scalable to the terabyte-scale data sets produced using next-generation high-throughput imaging techniques. Dr. Mayerich will receive mentoring in the algorithms and techniques used in the FARSIGHT Toolkit, as well as valuable experience working on a collaborative software development project.         The goal of the independent phase is to use recently developed imaging techniques, along with scalable segmentation algorithms, to construct complete microvascular models of mouse organs. Recent advances in KESM demonstrate that sub-micrometer images of 1cm3 tissue samples can be collected in less than 50 hours. These images have the resolution and quality necessary for (a) complete reconstruction of microvascular networks in whole organs, and (b) the geometric distribution of cell soma in relation to this network. Models describing cellular and microvascular relationships have implications in several diseases, including neurodegenerative disease and tumor growth, as well as clinical applications in tissue engineering and the quantitative analysis of angiogenic drugs and therapies.                  PROJECT NARRATIVE The goal of this work is to produce high-resolution microvascular models from mouse brain tissue, as well as create algorithms for querying, distributing, and building models from next-generation high-throughput microscopy data sets. These techniques will allow researchers to create large-scale blood flow simulations, simulate the extent of tissue damage due to stroke or aneurism, and explore the relationships between cells and microvessels on a tissue-wide scale. Clinical applications include the quantification of angiogenesis in tumors and tissue implants, and the quantification of neurovascular effects in neurodegenerative disease models.",Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular,8508596,K99LM011390,"['Active Learning', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood Vessels', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical Research', 'Collection', 'Commit', 'Communities', 'Complex', 'Computer Systems', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Doctor of Philosophy', 'Funding', 'Future', 'Goals', 'Hour', 'Illinois', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Institutes', 'Lead', 'Learning', 'Machine Learning', 'Memory', 'Mentors', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Mus', 'Neurodegenerative Disorders', 'Neurons', 'Online Systems', 'Organ', 'Pharmacotherapy', 'Phase', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Simulate', 'Speed', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Engineering', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'Transgenic Organisms', 'Tumor Angiogenesis', 'Tumor Tissue', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'angiogenesis', 'base', 'brain tissue', 'career', 'career development', 'clinical application', 'computerized tools', 'design', 'experience', 'imaging Segmentation', 'improved', 'instrument', 'memory process', 'mouse model', 'neuronal cell body', 'next generation', 'open source', 'optical imaging', 'programs', 'prototype', 'reconstruction', 'research study', 'simulation', 'software development', 'success', 'tool', 'tumor growth']",NLM,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,K99,2013,87300,-0.02168955972769288
"Multiscale Framework for Molecular Heterogeneity Analysis DESCRIPTION (provided by applicant): Genomic profiling has become a routine practice in selecting treatments for many diseases, enabling the classification of patients into categories that associate with improved outcomes for specific treatments. One potential detractor to this approach is the tremendous heterogeneity in tissues used for profiling. Genomic classifications, obtained from a relatively small biopsy, are subject to influence from broad, regional variations in the affected tissue. Heterogeneity on a cellular scale can also obscure the target of treatment, as cells with distinct molecular profiles are homogenized in genomic profiling. Realizing better therapies will depend greatly on the ability to understand molecular heterogeneity within an individual, a challenge that necessitates new approaches to organize, analyze and integrate data from multiple spatial and molecular scales. This proposal describes an informatics framework to characterizing heterogeneity for tissue based studies. The framework will combine imaging informatics with genomics to describe molecular heterogeneity at multiple spatial and molecular scales. The imaging component will leverage a novel quantum dot technology that enables detailed mapping of multiple protein expression pathways within a single sample. Fluorescence in situ hybridization imaging will be used to measure DNA content. Whole-slide digitization will enable computer algorithms to capture molecular profiles of hundreds of millions of cells, calculating quantitative features to describe their expression patterns and DNA content. Biologically meaningful descriptions of each cell will be generated using a novel active machine learning classifier to annotate cells with an ontology describing molecular biology and cell anatomy, enabling slides to be analyzed in a biological context. Cell boundaries, features, and annotations will be integrated through the Pathology Analytic Imaging Standards (PAIS) database to provide support for data mining analysis. Mining methods will be developed to find the enrichment of cellular phenotypes, and to analyze the spatial layout of cells with respect to structures like blood vessels to discover the influence of the tissue microenvironment on key expression pathways in surrounding cells. These tools will be applied to studies of glioblastoma brain tumors, but are relevant for studies of other solid tissue diseases. The scientific study wil use tissues resected in a novel clinical trial that accurately defines the invading tumor margin, bulk and necrosis-rich core. Tissues will be analyzed for gene expression and imaging to generate a paired genomic-imaging profile for each region. Mining the imaging and gene expression profiles of these regions will identify intra-tumoral differences in cellular phenotypes and illustrate the extent of variation in genomic classifications. The paired imaging and gene expression profiles will also be mined to determine relationships between specific expression classes and the imaging observations to illustrate a complete picture of heterogeneity. A project repository will be deployed to disseminate images, analysis pipelines and analytic results. This repository will provide a public resource for brain tumor research and access to open source tools. PROJECT NARRATIVE Developing effective treatments for disease requires an understanding of their molecular mechanisms. The software tools created by this research will enable researchers to better identify variations in the mechanisms of disease within an individual, and to develop and apply more effective therapies to improve patient outcomes.",Multiscale Framework for Molecular Heterogeneity Analysis,8897444,K22LM011576,"['Active Learning', 'Address', 'Affect', 'Algorithms', 'Animal Model', 'Biological', 'Biopsy', 'Blood Vessels', 'Brain Neoplasms', 'Categories', 'Cells', 'Classification', 'Clinical Trials', 'Complex', 'Computational algorithm', 'Conduct Clinical Trials', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Diffuse', 'Disease', 'Environment', 'Event', 'Fluorescent in Situ Hybridization', 'Gene Expression', 'Genetic', 'Genomics', 'Glioblastoma', 'Glioma', 'Goals', 'Heterogeneity', 'Hypoxia', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Individual', 'Informatics', 'Invaded', 'Label', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Microscopy', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Necrosis', 'Ontology', 'Operative Surgical Procedures', 'Outcome', 'Oxygen', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Ploidies', 'Process', 'Property', 'Protocols documentation', 'Quantum Dots', 'Research', 'Research Personnel', 'Resected', 'Resolution', 'Resources', 'Sampling', 'Signaling Molecule', 'Slide', 'Software Tools', 'Solid', 'Structure', 'Subcellular Anatomy', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Variant', 'analytical method', 'base', 'comparative', 'data mining', 'effective therapy', 'exome', 'human tissue', 'imaging informatics', 'improved', 'molecular scale', 'novel', 'novel strategies', 'open source', 'personalized medicine', 'protein expression', 'repository', 'routine practice', 'small molecule', 'tissue processing', 'tool', 'tumor']",NLM,EMORY UNIVERSITY,K22,2015,160696,-0.04335183686300989
"Multiscale Framework for Molecular Heterogeneity Analysis     DESCRIPTION (provided by applicant): Genomic profiling has become a routine practice in selecting treatments for many diseases, enabling the classification of patients into categories that associate with improved outcomes for specific treatments. One potential detractor to this approach is the tremendous heterogeneity in tissues used for profiling. Genomic classifications, obtained from a relatively small biopsy, are subject to influence from broad, regional variations in the affected tissue. Heterogeneity on a cellular scale can also obscure the target of treatment, as cells with distinct molecular profiles are homogenized in genomic profiling. Realizing better therapies will depend greatly on the ability to understand molecular heterogeneity within an individual, a challenge that necessitates new approaches to organize, analyze and integrate data from multiple spatial and molecular scales. This proposal describes an informatics framework to characterizing heterogeneity for tissue based studies. The framework will combine imaging informatics with genomics to describe molecular heterogeneity at multiple spatial and molecular scales. The imaging component will leverage a novel quantum dot technology that enables detailed mapping of multiple protein expression pathways within a single sample. Fluorescence in situ hybridization imaging will be used to measure DNA content. Whole-slide digitization will enable computer algorithms to capture molecular profiles of hundreds of millions of cells, calculating quantitative features to describe their expression patterns and DNA content. Biologically meaningful descriptions of each cell will be generated using a novel active machine learning classifier to annotate cells with an ontology describing molecular biology and cell anatomy, enabling slides to be analyzed in a biological context. Cell boundaries, features, and annotations will be integrated through the Pathology Analytic Imaging Standards (PAIS) database to provide support for data mining analysis. Mining methods will be developed to find the enrichment of cellular phenotypes, and to analyze the spatial layout of cells with respect to structures like blood vessels to discover the influence of the tissue microenvironment on key expression pathways in surrounding cells. These tools will be applied to studies of glioblastoma brain tumors, but are relevant for studies of other solid tissue diseases. The scientific study wil use tissues resected in a novel clinical trial that accurately defines the invading tumor margin, bulk and necrosis-rich core. Tissues will be analyzed for gene expression and imaging to generate a paired genomic-imaging profile for each region. Mining the imaging and gene expression profiles of these regions will identify intra-tumoral differences in cellular phenotypes and illustrate the extent of variation in genomic classifications. The paired imaging and gene expression profiles will also be mined to determine relationships between specific expression classes and the imaging observations to illustrate a complete picture of heterogeneity. A project repository will be deployed to disseminate images, analysis pipelines and analytic results. This repository will provide a public resource for brain tumor research and access to open source tools.                 PROJECT NARRATIVE Developing effective treatments for disease requires an understanding of their molecular mechanisms. The software tools created by this research will enable researchers to better identify variations in the mechanisms of disease within an individual, and to develop and apply more effective therapies to improve patient outcomes.",Multiscale Framework for Molecular Heterogeneity Analysis,8710341,K22LM011576,"['Active Learning', 'Address', 'Affect', 'Algorithms', 'Animal Model', 'Biological', 'Biopsy', 'Blood Vessels', 'Brain Neoplasms', 'Categories', 'Cells', 'Classification', 'Clinical Trials', 'Complex', 'Computational algorithm', 'Conduct Clinical Trials', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Diffuse', 'Disease', 'Environment', 'Event', 'Fluorescent in Situ Hybridization', 'Gene Expression', 'Genetic', 'Genomics', 'Glioblastoma', 'Glioma', 'Goals', 'Heterogeneity', 'Hypoxia', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Individual', 'Informatics', 'Invaded', 'Label', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Microscopy', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Necrosis', 'Ontology', 'Operative Surgical Procedures', 'Outcome', 'Oxygen', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Ploidies', 'Process', 'Property', 'Protocols documentation', 'Quantum Dots', 'Research', 'Research Personnel', 'Resected', 'Resolution', 'Resources', 'Sampling', 'Signaling Molecule', 'Simulate', 'Slide', 'Software Tools', 'Solid', 'Structure', 'Subcellular Anatomy', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Variant', 'analytical method', 'base', 'comparative', 'data mining', 'effective therapy', 'exome', 'human tissue', 'imaging informatics', 'improved', 'molecular scale', 'novel', 'novel strategies', 'open source', 'protein expression', 'repository', 'routine practice', 'small molecule', 'tissue processing', 'tool', 'tumor']",NLM,EMORY UNIVERSITY,K22,2014,162303,-0.04335183686300989
"Multiscale Framework for Molecular Heterogeneity Analysis     DESCRIPTION (provided by applicant): Genomic profiling has become a routine practice in selecting treatments for many diseases, enabling the classification of patients into categories that associate with improved outcomes for specific treatments. One potential detractor to this approach is the tremendous heterogeneity in tissues used for profiling. Genomic classifications, obtained from a relatively small biopsy, are subject to influence from broad, regional variations in the affected tissue. Heterogeneity on a cellular scale can also obscure the target of treatment, as cells with distinct molecular profiles are homogenized in genomic profiling. Realizing better therapies will depend greatly on the ability to understand molecular heterogeneity within an individual, a challenge that necessitates new approaches to organize, analyze and integrate data from multiple spatial and molecular scales. This proposal describes an informatics framework to characterizing heterogeneity for tissue based studies. The framework will combine imaging informatics with genomics to describe molecular heterogeneity at multiple spatial and molecular scales. The imaging component will leverage a novel quantum dot technology that enables detailed mapping of multiple protein expression pathways within a single sample. Fluorescence in situ hybridization imaging will be used to measure DNA content. Whole-slide digitization will enable computer algorithms to capture molecular profiles of hundreds of millions of cells, calculating quantitative features to describe their expression patterns and DNA content. Biologically meaningful descriptions of each cell will be generated using a novel active machine learning classifier to annotate cells with an ontology describing molecular biology and cell anatomy, enabling slides to be analyzed in a biological context. Cell boundaries, features, and annotations will be integrated through the Pathology Analytic Imaging Standards (PAIS) database to provide support for data mining analysis. Mining methods will be developed to find the enrichment of cellular phenotypes, and to analyze the spatial layout of cells with respect to structures like blood vessels to discover the influence of the tissue microenvironment on key expression pathways in surrounding cells. These tools will be applied to studies of glioblastoma brain tumors, but are relevant for studies of other solid tissue diseases. The scientific study wil use tissues resected in a novel clinical trial that accurately defines the invading tumor margin, bulk and necrosis-rich core. Tissues will be analyzed for gene expression and imaging to generate a paired genomic-imaging profile for each region. Mining the imaging and gene expression profiles of these regions will identify intra-tumoral differences in cellular phenotypes and illustrate the extent of variation in genomic classifications. The paired imaging and gene expression profiles will also be mined to determine relationships between specific expression classes and the imaging observations to illustrate a complete picture of heterogeneity. A project repository will be deployed to disseminate images, analysis pipelines and analytic results. This repository will provide a public resource for brain tumor research and access to open source tools.                  PROJECT NARRATIVE Developing effective treatments for disease requires an understanding of their molecular mechanisms. The software tools created by this research will enable researchers to better identify variations in the mechanisms of disease within an individual, and to develop and apply more effective therapies to improve patient outcomes.",Multiscale Framework for Molecular Heterogeneity Analysis,8488045,K22LM011576,"['Active Learning', 'Address', 'Affect', 'Algorithms', 'Animal Model', 'Biological', 'Biopsy', 'Blood Vessels', 'Brain Neoplasms', 'Categories', 'Cells', 'Classification', 'Clinical Trials', 'Complex', 'Computational algorithm', 'Conduct Clinical Trials', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Diffuse', 'Disease', 'Environment', 'Event', 'Fluorescent in Situ Hybridization', 'Gene Expression', 'Genetic', 'Genomics', 'Glioblastoma', 'Glioma', 'Goals', 'Heterogeneity', 'Hypoxia', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Individual', 'Informatics', 'Invaded', 'Label', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Microscopy', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Profiling', 'Necrosis', 'Ontology', 'Operative Surgical Procedures', 'Outcome', 'Oxygen', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Ploidies', 'Process', 'Property', 'Protocols documentation', 'Quantum Dots', 'Research', 'Research Personnel', 'Resected', 'Resolution', 'Resources', 'Sampling', 'Signaling Molecule', 'Simulate', 'Slide', 'Software Tools', 'Solid', 'Structure', 'Subcellular Anatomy', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Variant', 'analytical method', 'base', 'comparative', 'data mining', 'effective therapy', 'exome', 'human tissue', 'imaging informatics', 'improved', 'molecular scale', 'novel', 'novel strategies', 'open source', 'protein expression', 'repository', 'routine practice', 'small molecule', 'tissue processing', 'tool', 'tumor']",NLM,EMORY UNIVERSITY,K22,2013,162319,-0.04335183686300989
"UW 4-Dimensional Genomic Organization of Mammalian Embryogenesis Center Project Summary / Abstract A major shortcoming of most efforts to understand the 4D nucleome is that they have mainly focused on in vitro cell lines, rather than on dynamic, in vivo systems. Arguably, the most important in vivo system, which also happens to be the most dynamic, is development itself, wherein the nucleome both shapes and is shaped by the initial emergence of the myriad mammalian cell types. While these in vivo dynamics are presently poorly documented and understood, recently emerged technologies offer a path forward. Here we propose to establish the University of Washington 4-Dimensional Genomic Nuclear Organization of Mammalian Embryogenesis Center (UW 4D GENOME Center), which will address these massive gaps in our understanding by generating systematic datasets on nuclear morphology and associated molecular measurements in mammalian tissues and cell types. These datasets will be generated in the context of the leading model organism for mammalian development, the mouse. Our approach focuses on following nuclear structure, chromatin and gene expression changes at a “whole organism” scale, using a combination of scalable single cell profiling and “visual cell sorting” (VCS) methods, all well-established and mostly developed in our own labs. Our goal is to generate a high- resolution 4DN atlas of mouse embryogenesis for the community. The different types of data will be integrated, including cross-species imputation to integrate with human data, as well as models and navigable maps applied to pathways relevant to mammalian development. Project Narrative The UW 4D Genome Organization of Mammalian Embryogenesis Center (UW 4D GENOME) aims to elucidate chromatin dynamics during the early stages of mammalian development. Accordingly, the proposed center will carry out systematic generation of sequencing and imaging data during mouse embryogenesis, summarizing and visualizing the resulting data using machine learning models. These approaches will also be applied to investigate nuclear architecture in mouse models with mutations in genes relevant to nuclear structure, which will help advance our understanding of diseases such as laminopathy and cancer.",UW 4-Dimensional Genomic Organization of Mammalian Embryogenesis Center,10151918,UM1HG011586,"['3-Dimensional', 'ATAC-seq', 'Address', 'Alleles', 'Animal Model', 'Antibodies', 'Architecture', 'Atlases', 'Biological Assay', 'C57BL/6 Mouse', 'Cell Line', 'Cell Nucleolus', 'Cell Nucleus', 'Cell Separation', 'Cells', 'Chromatin', 'Chromatin Structure', 'Chromosomes', 'Communities', 'DNA', 'Data', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Embryo', 'Embryonic Development', 'Four-dimensional', 'Gene Expression', 'Gene Mutation', 'Generations', 'Genes', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Heterochromatin', 'Hour', 'Human', 'Hybrids', 'Image', 'In Vitro', 'Lamin Type A', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Profiling', 'Morphology', 'Mus', 'Mutation', 'Nuclear', 'Nuclear Structure', 'Pathway interactions', 'Phenotype', 'Positioning Attribute', 'RNA', 'Resolution', 'Series', 'Shapes', 'Sorting - Cell Movement', 'Stains', 'Statistical Methods', 'System', 'Technology', 'Time', 'Tissues', 'Universities', 'Visual', 'Visualization', 'Washington', 'Whole Organism', 'X Inactivation', 'base', 'cell type', 'human data', 'human disease', 'imprint', 'in vivo', 'knowledge translation', 'lamin B receptor', 'molecular phenotype', 'mouse development', 'mouse model', 'mutant', 'novel', 'nucleophosmin', 'transcriptome sequencing', 'web portal']",NHGRI,UNIVERSITY OF WASHINGTON,UM1,2020,2031051,-0.020870480761723712
"Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration PROJECT SUMMARY The cell nucleus is a heterogeneous organelle that consists of nuclear bodies such as nuclear lamina, speckles, nucleoli and PML bodies. These structures continuously tether and tug chromatin at the small and large scales to synergistically orchestrate dynamic functions in distinct spatio-temporal compartments. A major obstacle to the production of navigable 4D reference maps and relating structure to function in the nucleus remains understanding how these different scales of organization influence each other. In particular, we have a poor understanding of the large-scale genome organization. Growing evidence suggests that such nuclear compartmentalization is causally connected with vital genome functions in human health and disease. However, the principles of this nuclear compartmentalization, its dynamics during changes in cell conditions, and its functional relevance are poorly understood. One lesson from Phase 1 4DN was the huge gap in throughput between imaging methods, that directly measure large-scale multi-landmark relationships, and genomic methods, that aim for whole genome high-resolution maps but are indirect measurements and provide limited information about large-scale compartments. For this 4DN UM1 Center application, we propose to meet these needs through the following Aims: (1) Generate multi-modal imaging and genomic datasets to reveal the structure, dynamics, and function of nuclear compartmentalization; (2) Develop and apply computational tools for data-driven genome structure modeling and integrative analysis of nuclear compartmentalization; (3) Develop an integrative analysis and visualization platform with navigable 4D reference maps of nuclear organization. The combined datasets and results of our proposed approaches will advance our understanding of nuclear compartmentalization, the interwoven connections among different nuclear components, and their functional significance. Our new integrative analysis tools and data-driven predictive models will produce more complete nuclear organization reference maps that integrate large-scale chromosome structure data from live and super-resolution microscopy with multi-modal genomic data including smaller scale chromatin interaction maps and predict functional relationships and dynamic responses. Our navigable reference maps will be publicly accessible through an analysis platform that provides interactive visualization of multiple data types, thus enabling investigators with diverse expertise to simultaneously explore their own data and related datasets/tools and promoting collaborations that will open new horizons into the role of the 4D nucleome in human health and disease. PROJECT NARRATIVE The proposed research is relevant to public health because it will enhance our understanding of nuclear genome organization and functions that are increasingly being linked to health and disease. Because we develop tools to disseminate this information and enable others to work with our data and their own data, we will also bring nuclear architecture to bear on a broad range of ongoing health related research. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Multiscale Analyses of 4D Nucleome Structure and Function by Comprehensive Multimodal Data Integration,10156141,UM1HG011593,"['Address', 'Architecture', 'Atlases', 'Binding', 'Biochemical', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Chromatin', 'Chromatin Loop', 'Chromatin Structure', 'Chromosome Structures', 'Chromosomes', 'Collaborations', 'Communities', 'Complement', 'Computing Methodologies', 'Cytology', 'DNA Replication Timing', 'Data', 'Data Set', 'Development', 'Disease', 'Formulation', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Interphase Chromosome', 'Intuition', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Methods', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nuclear', 'Nuclear Lamina', 'Nuclear Structure', 'Organelles', 'Outcome', 'Output', 'Phase', 'Population', 'Production', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Structural Models', 'Structure', 'Technology', 'Three-Dimensional Imaging', 'United States National Institutes of Health', 'Ursidae Family', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'cell cycle genetics', 'cell type', 'computer framework', 'computerized tools', 'data exploration', 'data integration', 'data tools', 'experimental study', 'genome-wide', 'genomic data', 'histone modification', 'imaging modality', 'improved', 'insight', 'machine learning algorithm', 'mental function', 'multimodal data', 'multimodality', 'multiple data types', 'multiscale data', 'predictive modeling', 'response', 'spatiotemporal', 'structured data', 'tool', 'transcription factor', 'transcriptome sequencing', 'user-friendly', 'whole genome']",NHGRI,CARNEGIE-MELLON UNIVERSITY,UM1,2020,2075409,0.032527860072834286
"MULTISPECTRAL FUNDUS IMAGING SYSTEM Recent advances in sensor technology for a broad class of applications           have resulted in the evolution of sophisticated hardware for high                resolution multispectral imaging.  Multispectral imaging and associated          cutting edge multispectral image and data fusion processing software             have led to the realization of techniques which add significantly to the         ability of identifying and characterizing the nature of scenes on the            earth from space, or the identification of other objects from their              multispectral and spatial signatures.                                                                                                                             A multispectral image fusion system is proposed which will present               additional diagnostic information to a clinical or research                      ophthalmologist.  Using state-of-the-art multispectral image capture             system, advanced multispectral image fusion techniques inspired by               the human vision system, and neural network feature classification               algorithms, a Multispectral Image fusion System for detection and                identification of ocular pathological features is described.                      n/a",MULTISPECTRAL FUNDUS IMAGING SYSTEM,2606924,R43EY011675,"['artificial intelligence', ' biomedical equipment development', ' charge coupled device camera', ' clinical biomedical equipment', ' computational neuroscience', ' diagnosis design /evaluation', ' eye disorder diagnosis', ' eye fundus photography', ' fundus oculi', ' hemoglobin', ' image processing']",NEI,KESTREL CORPORATION,R43,1997,99944,0.012220501908559252
"CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI DESCRIPTION (Adapted from the Investigator's Abstract): Bold steps must be       taken to advance our understanding of the genetic and associated co-             variates affecting the inheritance of complex diseases. To that end, this        proposal will develop improved quantitative methods to detect genetic            factors contributing to increased susceptibility to complex disorders and        implement these methods in software for distribution to the research             community.                                                                                                                                                        The methods will concentrate on the use of classification techniques             applied to allele sharing data and other risk factors which affect the           trait. Allele sharing methods for mapping genes will be extended to              include the classification methods known as latent class models, cluster         analysis, and artificial neural networks, as well as a novel use of              logistic regression Co-variates such as gender, parental diagnosis, or           other concomitant factors will be systematically studied through                 applications to both stimulated and existing data sets. An additional goal       is to determine the optimal distribution of relative pairs (e.g. siblings,       first cousins) for these methods. Of great importance to this proposal is        the development of well-documented, user-friendly software and                   documentation which will be distributed to the scientific community via          the Internet. Existing software developed by the PI will be extensively          expanded for latent class models. Existing cluster analysis software will        be modified and combined for ease of use.                                                                                                                         This proposal consists of theoretical exploration, computer simulation,          data analysis, and software development. First, solutions of theoretical         questions relating to classification techniques will be pursued; second,         adaptation of computer programs to implement the analytic methods, and           investigation into alternative research strategies will be accomplished.         The new strategies will be applied to stimulated data, and finally, to           existing data sets of pedigrees in which a complex trait has been                diagnosed. Findings from this research may contribute to the ability to          locate susceptibility loci in complex traits and to the clarification of         those etiological mechanisms responsible for susceptibility.                      n/a",CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI,6168495,R01AA012239,"['alleles', ' analytical method', ' artificial intelligence', ' biomedical resource', ' computer program /software', ' computer simulation', ' data collection methodology /evaluation', ' disease /disorder classification', ' disease /disorder etiology', ' family genetics', ' gene environment interaction', ' gene expression', ' genetic disorder', ' genetic disorder diagnosis', ' genetic mapping', ' genetic markers', ' genetic susceptibility', ' human data', ' mathematical model', ' model design /development', ' quantitative trait loci', ' statistics /biometry']",NIAAA,WASHINGTON UNIVERSITY,R01,2000,180260,0.010202989095733734
"CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI DESCRIPTION (Adapted from the Investigator's Abstract): Bold steps must be       taken to advance our understanding of the genetic and associated co-             variates affecting the inheritance of complex diseases. To that end, this        proposal will develop improved quantitative methods to detect genetic            factors contributing to increased susceptibility to complex disorders and        implement these methods in software for distribution to the research             community.                                                                                                                                                        The methods will concentrate on the use of classification techniques             applied to allele sharing data and other risk factors which affect the           trait. Allele sharing methods for mapping genes will be extended to              include the classification methods known as latent class models, cluster         analysis, and artificial neural networks, as well as a novel use of              logistic regression Co-variates such as gender, parental diagnosis, or           other concomitant factors will be systematically studied through                 applications to both stimulated and existing data sets. An additional goal       is to determine the optimal distribution of relative pairs (e.g. siblings,       first cousins) for these methods. Of great importance to this proposal is        the development of well-documented, user-friendly software and                   documentation which will be distributed to the scientific community via          the Internet. Existing software developed by the PI will be extensively          expanded for latent class models. Existing cluster analysis software will        be modified and combined for ease of use.                                                                                                                         This proposal consists of theoretical exploration, computer simulation,          data analysis, and software development. First, solutions of theoretical         questions relating to classification techniques will be pursued; second,         adaptation of computer programs to implement the analytic methods, and           investigation into alternative research strategies will be accomplished.         The new strategies will be applied to stimulated data, and finally, to           existing data sets of pedigrees in which a complex trait has been                diagnosed. Findings from this research may contribute to the ability to          locate susceptibility loci in complex traits and to the clarification of         those etiological mechanisms responsible for susceptibility.                      n/a",CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI,2894288,R01AA012239,"['alleles', ' analytical method', ' artificial intelligence', ' biomedical resource', ' computer program /software', ' computer simulation', ' data collection methodology /evaluation', ' disease /disorder classification', ' disease /disorder etiology', ' family genetics', ' gene environment interaction', ' gene expression', ' genetic disorder', ' genetic disorder diagnosis', ' genetic mapping', ' genetic markers', ' genetic susceptibility', ' human data', ' mathematical model', ' model design /development', ' quantitative trait loci', ' statistics /biometry']",NIAAA,WASHINGTON UNIVERSITY,R01,1999,175004,0.010202989095733734
"CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI DESCRIPTION (Adapted from the Investigator's Abstract): Bold steps must be       taken to advance our understanding of the genetic and associated co-             variates affecting the inheritance of complex diseases. To that end, this        proposal will develop improved quantitative methods to detect genetic            factors contributing to increased susceptibility to complex disorders and        implement these methods in software for distribution to the research             community.                                                                                                                                                        The methods will concentrate on the use of classification techniques             applied to allele sharing data and other risk factors which affect the           trait. Allele sharing methods for mapping genes will be extended to              include the classification methods known as latent class models, cluster         analysis, and artificial neural networks, as well as a novel use of              logistic regression Co-variates such as gender, parental diagnosis, or           other concomitant factors will be systematically studied through                 applications to both stimulated and existing data sets. An additional goal       is to determine the optimal distribution of relative pairs (e.g. siblings,       first cousins) for these methods. Of great importance to this proposal is        the development of well-documented, user-friendly software and                   documentation which will be distributed to the scientific community via          the Internet. Existing software developed by the PI will be extensively          expanded for latent class models. Existing cluster analysis software will        be modified and combined for ease of use.                                                                                                                         This proposal consists of theoretical exploration, computer simulation,          data analysis, and software development. First, solutions of theoretical         questions relating to classification techniques will be pursued; second,         adaptation of computer programs to implement the analytic methods, and           investigation into alternative research strategies will be accomplished.         The new strategies will be applied to stimulated data, and finally, to           existing data sets of pedigrees in which a complex trait has been                diagnosed. Findings from this research may contribute to the ability to          locate susceptibility loci in complex traits and to the clarification of         those etiological mechanisms responsible for susceptibility.                      n/a",CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI,2865173,R01AA012239,"['alleles', ' analytical method', ' artificial intelligence', ' biomedical resource', ' computer program /software', ' computer simulation', ' data collection methodology /evaluation', ' disease /disorder classification', ' disease /disorder etiology', ' family genetics', ' gene environment interaction', ' gene expression', ' genetic disorder', ' genetic disorder diagnosis', ' genetic mapping', ' genetic markers', ' genetic susceptibility', ' human data', ' mathematical model', ' model design /development', ' quantitative trait loci', ' statistics /biometry']",NIAAA,WASHINGTON UNIVERSITY,R01,1998,162275,0.010202989095733734
"InCell 6000 High Content Instrument for Cellular Systems Biology Program     DESCRIPTION: The General Electric Healthcare, InCell 6000 High Content Analysis (HCA) instrument is being requested to allow investigators from the University of Pittsburgh, the University of Pittsburgh Medical Center and Carnegie Mellon University to analyze complex cellular processes in both fixed and living cells, multicellular model systems and research organisms (Zebra Fish and C. elegans). This high instrument combines a high scan-rate confocal imaging device, an environmental chamber, 4-channel fluorescence, transmitted light and on-board fluid addition in a microplate-based system. The InCell 6000 permits automated, high throughput and high temporal and spatial resolution of subcelluar structures and biochemical reactions that are the basis of all cellular and tissue functions. The long-term objective is to extend our present capabilities in acquiring high temporal, spatial and spectral images from a small sample size to the acquisition of large data sets from populations of cells on a cell-by-cell basis, tissue models and experimental animals. This new capability will permit the application of computational and systems biology tools to understand the complexities of life processes based on statistical significance not possible before. The integration of the best biological experimental systems, fluorescence-based reagents and high throughput, automated imaging will enable large, combinatorial treatments of samples to allow the exploration of statistically relevant mechanisms of action in a variety of therapeutic areas. The NIH funded projects that will use this instrument include investigations on human adipocyte differentiation in cancer, the physiology of stem cell derived cardiomyocytes, the heterogeneity of drug responses in head and neck cancer models, the role of the immune response in cancer therapies, live, 3D breast cancer models with the analysis of pathways, cell migration in tumor models, modulation of Huntington's Disease progression in model systems, protein misfolding disease model of alpha 1- antitrypsin deficiency (ATD), and necrotizing enterocolitis (NEC) models in C. elgans. In addition, a kidney regeneration model in Zebra fish to identify small molecules that stimulate stem cell proliferation, as well as the application of a new generation of genetically encoded biosensors, standards for imaging and flow cytometry and the further application of active machine learning optimization of experimental strategies. The application of this platform to fundamental biomedical research and translational research programs will ultimately lead to better success in drug discovery and development, while helping to define the mechanisms of normal and disease processes.              n/a",InCell 6000 High Content Instrument for Cellular Systems Biology Program,8332956,S10OD012269,"['Animals', 'Area', 'Biochemical Reaction', 'Biological', 'Biological Models', 'Biomedical Research', 'Biosensor', 'Breast Cancer Model', 'Caenorhabditis elegans', 'Cancer Model', 'Cardiac Myocytes', 'Cell Migration Pathway', 'Cell Proliferation', 'Cell physiology', 'Cells', 'Complex', 'Data Set', 'Disease', 'Disease Progression', 'Disease model', 'Flow Cytometry', 'Fluorescence', 'Funding', 'Generations', 'Head and Neck Cancer', 'Healthcare', 'Heterogeneity', 'Human', 'Huntington Disease', 'Image', 'Image Cytometry', 'Imaging Device', 'Immune response', 'Investigation', 'Kidney', 'Lead', 'Life', 'Light', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Medical center', 'Modeling', 'Natural regeneration', 'Necrotizing Enterocolitis', 'Organism', 'Pharmaceutical Preparations', 'Physiology', 'Population', 'Process', 'Reagent', 'Research Personnel', 'Resolution', 'Role', 'Sample Size', 'Sampling', 'Scanning', 'Stem cells', 'Structure', 'System', 'Systems Biology', 'Therapeutic', 'Tissue Model', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Zebrafish', 'adipocyte differentiation', 'alpha 1-Antitrypsin Deficiency', 'base', 'cancer therapy', 'combinatorial', 'drug development', 'drug discovery', 'instrument', 'programs', 'protein misfolding', 'response', 'small molecule', 'success', 'systems research', 'tool', 'tumor']",OD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,S10,2013,502020,-0.03251090600457141
"DEVELOPMENT OF SPATIAL SOFTWARER This SBIR project will develop software for identifying and correcting spatial patterns in data for a wide range of alcohol-related phenomenon including alcohol consumption, problematic outcomes, and treatment modalities. Identifying and correcting statistical relationships in spatially configured data sets would be invaluable to alcohol-related research, the overall health community, and even to most social scientists (and biomedical researchers). Ecological models or models with locational components that provide unbiased estimates and increased predictive performance enhance the researcher' ability to identify new patterns within alcohol-related phenomenon. While spatial analysis has been widely researched and is a proven statistical technique, commercially available software with reasonable diagnostics and commonly used regression techniques does not yet exist. This phase I project addresses this need and will pursue three objectives: (1) Research and increase the capabilities of the current software package, (2) Design interfaces easily useable (friendly) for alcohol researchers, and (3) Improve the speed and efficiency of the core code. The proposed software development will provide powerful diagnostic and corrective tool in the analysis of mapped data describing relationships between space and alcohol- related phenomenon. PROPOSED COMMERCIAL APPLICATIONS: The need for identifying and adjusting for spatial autocorrelation in alcohol- related data sets is huge (see page 21) and so there is a large market for the proposed statistical software. The proposed package is expected to provide an easy to use, speedy, and comprehensive tool relative to current packages.  n/a",DEVELOPMENT OF SPATIAL SOFTWARER,6073824,R43AA012373,"['alcoholism /alcohol abuse', ' artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' mathematics', ' statistics /biometry']",NIAAA,S-THREE DEVELOPMENT,R43,2000,129935,-0.021565711349967185
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety  Of functions involved in the immune response, and influence  susceptibility to over 40 diseases.  Our understanding of the structure  and function of the HLA genes, their disease associations, and the  evolutionary features of this multigene family has benefitted from recent  advances in molecular biology, immunology, disease modelling and  population genetics.  Theoretical studies in the development of models to  determine the modes of inheritance of the HLA associated diseases have  led to a better understanding of the inheritance patterns in insulin  dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,  ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It  is now clear that many of the HLA associated diseases involve  heterogeneity in their HLA components, as well as non-HLA genetic  components.    The specific aims of our research are to study the genetic components in  the etiology of the HLA associated diseases, and population genetic  features of the HLA system.  A variety of methods to test modes of  inheritance of diseases using marker allele information, will be  developed.  Methods appropriate for the analysis of marker systems which  are not highly polymorphic, to both detect linkage and determine modes of  inheritance, will be investigated.  The information content of particular  pedigree types for LOD score analysis will be investigated.  Two methods  using patterns of linkage disequilibrium will be investigated to  determine their usefulness in mapping disease predisposing genes.  A  number of large collaborative data sets of HLA associated diseases will  be analyzed.  A framework for genetic counselling of HLA associated, and  other complex diseases, will be developed.  The results of our studies  are generally applicable to the mapping and characterization of complex  human genetic traits.  n/a",MODELS IN POPULATION GENETICS,2196932,R01HD012731,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage mapping', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1995,203332,0.02029287059876889
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety Of functions involved in the immune response, and influence susceptibility to over 40 diseases.  Our understanding of the structure and function of the HLA genes, their disease associations, and the evolutionary features of this multigene family has benefitted from recent advances in molecular biology, immunology, disease modelling and population genetics.  Theoretical studies in the development of models to determine the modes of inheritance of the HLA associated diseases have led to a better understanding of the inheritance patterns in insulin dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis, ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It is now clear that many of the HLA associated diseases involve heterogeneity in their HLA components, as well as non-HLA genetic components.  The specific aims of our research are to study the genetic components in the etiology of the HLA associated diseases, and population genetic features of the HLA system.  A variety of methods to test modes of inheritance of diseases using marker allele information, will be developed.  Methods appropriate for the analysis of marker systems which are not highly polymorphic, to both detect linkage and determine modes of inheritance, will be investigated.  The information content of particular pedigree types for LOD score analysis will be investigated.  Two methods using patterns of linkage disequilibrium will be investigated to determine their usefulness in mapping disease predisposing genes.  A number of large collaborative data sets of HLA associated diseases will be analyzed.  A framework for genetic counselling of HLA associated, and other complex diseases, will be developed.  The results of our studies are generally applicable to the mapping and characterization of complex human genetic traits.  n/a",MODELS IN POPULATION GENETICS,2196931,R01HD012731,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage mapping', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1994,170968,0.02029287059876889
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety Of functions involved in the immune response, and influence susceptibility to over 40 diseases.  Our understanding of the structure and function of the HLA genes, their disease associations, and the evolutionary features of this multigene family has benefitted from recent advances in molecular biology, immunology, disease modelling and population genetics.  Theoretical studies in the development of models to determine the modes of inheritance of the HLA associated diseases have led to a better understanding of the inheritance patterns in insulin dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis, ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It is now clear that many of the HLA associated diseases involve heterogeneity in their HLA components, as well as non-HLA genetic components.  The specific aims of our research are to study the genetic components in the etiology of the HLA associated diseases, and population genetic features of the HLA system.  A variety of methods to test modes of inheritance of diseases using marker allele information, will be developed.  Methods appropriate for the analysis of marker systems which are not highly polymorphic, to both detect linkage and determine modes of inheritance, will be investigated.  The information content of particular pedigree types for LOD score analysis will be investigated.  Two methods using patterns of linkage disequilibrium will be investigated to determine their usefulness in mapping disease predisposing genes.  A number of large collaborative data sets of HLA associated diseases will be analyzed.  A framework for genetic counselling of HLA associated, and other complex diseases, will be developed.  The results of our studies are generally applicable to the mapping and characterization of complex human genetic traits.  n/a",MODELS IN POPULATION GENETICS,3311999,R01HD012731,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage mapping', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1993,154095,0.02029287059876889
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety Of functions involved in the immune response, and influence susceptibility to over 40 diseases.  Our understanding of the structure and function of the HLA genes, their disease associations, and the evolutionary features of this multigene family has benefitted from recent advances in molecular biology, immunology, disease modelling and population genetics.  Theoretical studies in the development of models to determine the modes of inheritance of the HLA associated diseases have led to a better understanding of the inheritance patterns in insulin dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis, ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It is now clear that many of the HLA associated diseases involve heterogeneity in their HLA components, as well as non-HLA genetic components.  The specific aims of our research are to study the genetic components in the etiology of the HLA associated diseases, and population genetic features of the HLA system.  A variety of methods to test modes of inheritance of diseases using marker allele information, will be developed.  Methods appropriate for the analysis of marker systems which are not highly polymorphic, to both detect linkage and determine modes of inheritance, will be investigated.  The information content of particular pedigree types for LOD score analysis will be investigated.  Two methods using patterns of linkage disequilibrium will be investigated to determine their usefulness in mapping disease predisposing genes.  A number of large collaborative data sets of HLA associated diseases will be analyzed.  A framework for genetic counselling of HLA associated, and other complex diseases, will be developed.  The results of our studies are generally applicable to the mapping and characterization of complex human genetic traits.  n/a",MODELS IN POPULATION GENETICS,3311992,R01HD012731,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage mapping', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1992,148906,0.02029287059876889
"Shearography for Non-Invasive Dental Health Evaluation   DESCRIPTION: Optical holography has been applied to non-invasive clinical            diagnosis and monitoring of Dental and oral/facial pathology, but has been           sharply limited in its usefulness by its requirements of high laser coherence.       absolute stability of setup. and wet processing of holograms. Physical Optics        Corporation (POC) proposes to develop a shearographic micro-optic camera as a        novel means of non-invasive Dental evaluation and characterization based on          shearing speckle interferometry, miniature camera imaging, and proprietary           neural network image processing. The innovation in this concept is the use of        shearography to avoid the need for high stability, high temporal coherence, and      wet processing. Nearfield shearography will have high spatial resolution, and        the neural network will perform real-time data processing and display.                                                                                                    The unique high resolution. real-time operation. low cost. and miniaturization       will make this device attractive to a large commercial market in Dental and          clinical applications.                                                                                                                                                    In Phase 1. POC will develop a miniature shearographic micro-optic camera            (SMOC) with fiber light delivery. a micro-CCD imaging component. and neural          network. It will be capable of distinguishing among tooth enamel, cementum,           dentine, pulp, and soft tissue.                                                      PROPOSED COMMERCIAL APPLICATION:  This compact, low-cost, high resolution non-invasive shearography device will represent a  technological breakthrough not only for oral diagnostics but also for biomedical imaging in  general.  Because of its high resolution, real-time operation, and immunity to vibration, it will  also have wide applications beyond the medical field, particularly for industrial diagnostics.  High-strength aerospace composite material evaluation and testing as well as weld and pipe  defect inspection are areas where it will be particularly welcome.                                                                                     n/a",Shearography for Non-Invasive Dental Health Evaluation,6404393,R43DE014307,"['artificial intelligence', ' bioimaging /biomedical imaging', ' dental disorder diagnosis', ' diagnosis design /evaluation', ' fiber optics', ' image processing', ' interferometry', ' lasers', ' noninvasive diagnosis', ' oral health', ' video recording system']",NIDCR,PHYSICAL OPTICS CORPORATION,R43,2001,100000,0.03599665850798079
"Integrating Multimodal Brain Imaging Data to Assess Subtle Cognitive Impairment    DESCRIPTION (provided by applicant): Functional neuroimaging studies of the human brain have become increasingly important in the understanding of normal and pathological processes of cognition. Sophisticated statistical analytic frameworks have been developed to locate signal change and define brain networks involved in various tasks. However, in subtle cognitive impairment-e.g., exposure-related illness, early stages of degenerative diseases, injury, secondary illness following adjuvant therapy for cancer-these methods tend to have low sensitivity for detecting small changes in brain states resulting from mild brain dysfunction. An understanding of disease mechanism or progression of subtle cognitive dysfunction requires a novel statistical analytic framework with improved sensitivity to measure small changes in brain states. We have developed an innovative methodology that we successfully applied in measures of regional cerebral blood flow experiments. These methods use well established spatial modeling procedures, new to the functional brain imaging field, to derive statistically optimal spatial summaries within effective resolution groups or ""kriging"", shown by preliminary studies to improve signal detection sensitivity and mitigate the multiple testing burden. Within this new spatial modeling framework, we propose to extend the kriging methodology to fMRI and EEG, modify existing techniques for characterizing brain networks of connectivity (e.g., kriging-based independent components analysis), and integrate the imaging modalities using a statistical classifier based on derived inputs of data driven effective resolution groups. Our primary goal is to develop this analysis framework to provide insight into the neurophysiological mechanisms of mild cognitive dysfunction. Achieving this goal may suggest treatments to alleviate symptoms, prevent progression, or at minimum, provide an informed clinical management of cognitively impaired patients.        Cognitive impairment is a major health concern, affecting people of all ages. Causes range from traumatic injury to toxin exposures, including chemotherapy for cancer treatment, to degenerative diseases. Mechanisms of damage or disease remain difficult to establish using current methods in functional brain imaging studies due to an inability to measure very small changes in brain states. We propose a new analytic framework using existing technology to improve the ability to measure subtle changes important in the understanding of disease pathology of impaired cognition and to greatly facilitate the integration of information from several imaging modalities with potential implications for clinical management and treatment.            ",Integrating Multimodal Brain Imaging Data to Assess Subtle Cognitive Impairment,8445205,R21EB014563,"['Adjuvant Therapy', 'Affect', 'Age', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain region', 'Cerebrovascular Circulation', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Treatment', 'Cognition', 'Data', 'Databases', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Injury', 'Ions', 'Lead', 'Linear Models', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Neurocognitive', 'Neurotoxins', 'Outcome', 'Output', 'Pathologic Processes', 'Pathology', 'Patients', 'Procedures', 'Process', 'Property', 'Reliance', 'Research Personnel', 'Resolution', 'Sampling', 'Secondary to', 'Semantic memory', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Spin Labels', 'Staging', 'Statistical Methods', 'Symptoms', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Weight', 'Work', 'base', 'behavior measurement', 'behavior test', 'cancer therapy', 'case-based', 'chemobrain', 'chemotherapy', 'data reduction', 'executive function', 'image registration', 'imaging modality', 'improved', 'independent component analysis', 'innovation', 'insight', 'mild cognitive impairment', 'neurocognitive test', 'neuroimaging', 'neurophysiology', 'novel', 'prevent', 'research study', 'single photon emission computed tomography', 'tool', 'treatment strategy']",NIBIB,UNIVERSITY OF TEXAS DALLAS,R21,2013,184069,-0.004584370880544208
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,7051948,K01DA015129,"['artificial intelligence', 'behavioral /social science research tag', 'behavioral genetics', 'clinical research', 'computer simulation', 'data collection methodology /evaluation', 'drug addiction', 'family genetics', 'genetic susceptibility', 'human data', 'linkage mapping', 'mathematical model', 'nicotine', 'pharmacogenetics', 'smoking', 'tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2006,133928,0.0148482460241152
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,6864825,K01DA015129,"['artificial intelligence', 'behavioral /social science research tag', 'behavioral genetics', 'clinical research', 'computer simulation', 'data collection methodology /evaluation', 'drug addiction', 'family genetics', 'genetic susceptibility', 'human data', 'linkage mapping', 'mathematical model', 'nicotine', 'pharmacogenetics', 'smoking', 'tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2005,129738,0.0148482460241152
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,6745564,K01DA015129,"['artificial intelligence', 'behavioral /social science research tag', 'behavioral genetics', 'clinical research', 'computer simulation', 'data collection methodology /evaluation', 'drug addiction', 'family genetics', 'genetic susceptibility', 'human data', 'linkage mapping', 'mathematical model', 'nicotine', 'pharmacogenetics', 'smoking', 'tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2004,103831,0.0148482460241152
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,6623318,K01DA015129,"['artificial intelligence', ' behavioral /social science research tag', ' behavioral genetics', ' clinical research', ' computer simulation', ' data collection methodology /evaluation', ' drug addiction', ' family genetics', ' genetic susceptibility', ' human data', ' linkage mapping', ' mathematical model', ' nicotine', ' pharmacogenetics', ' smoking', ' tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2003,102301,0.0148482460241152
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,6464747,K01DA015129,"['artificial intelligence', ' behavioral /social science research tag', ' behavioral genetics', ' clinical research', ' computer simulation', ' data collection methodology /evaluation', ' drug addiction', ' family genetics', ' genetic susceptibility', ' human data', ' linkage mapping', ' mathematical model', ' nicotine', ' pharmacogenetics', ' smoking', ' tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2002,97825,0.0148482460241152
"Voxelation: a new method for 3D gene expression analysis   DESCRIPTION (provided by applicant): A major opportunity for the post-genomic        world will be to understand how the genome constructs the brain, and how this        process goes awry in disease. The approach we are taking combines the                computational procedures of biomedical imaging technologies, such as CT and          PET, with high throughput methods to acquire 3D gene expression patterns in the      brain. This new technology is called voxelation, and gets its name from the          term ""voxel,"" which refers to a cubic 3D image volume element. The voxel is the      3D analog of the familiar 2D image element, the pixel. Voxelation entails the        direct creation of voxels (cubes) in spatial register with the brain, and            application of high throughput gene expression analytic techniques to RNA            extracted from the voxels. Imaging algorithms are then employed to reconstruct       spatial information in high throughput. Using microarrays, we have obtained low      resolution (40 voxel) images of the normal mouse brain for 9,000 genes, giving       novel insights into the construction of the brain by the genome. Also using          microarrays, we have acquired 2,000 gene, 24 voxel images of coronal                 hemisections of both normal and Alzheimer's disease human brains at the level        of the hippocampus. Our analysis has revealed a common network of co-regulated       genes, and allowed identification of putative control regions. In addition, a        number of intriguing candidate genes have been found whose level of expression       is significantly different between the Alzheimer's and normal hemisections.          Finally, singular value decomposition (SVD), a mathematical technique used to        provide parsimonious explanations of complex data sets, produced images that         distinguished between brain structures, including cortex, caudate and                hippocampus. Building on the foundations provided by these studies, voxelation       will be employed in two Specific Aims using the mouse. (1.) Using microarrays,       low resolution (40 voxel) high throughput (9,000) gene images of the brain will      be acquired in four mouse models of human neuropsychiatric disorders:                Parkinson's disease, drug addiction, schizophrenia, and dopamine D3 receptor         deficiency. (2.) To extend the technology of voxelation, high resolution (300        voxel) moderate throughput (hundreds of gene) images of the mouse brain will be      obtained using real-time quantitative RT-PCR. An instrument, the voxelator, has      been constructed for semiautomated miniaturized harvesting of the voxels.            Images from both Specific Aims 1 and 2 will be validated using classical             techniques, such as in situ hybridization. This research promises important new      insights into the nexus of genome and brain, in health and disease, and may          also provide novel avenues to therapy.                                               n/a",Voxelation: a new method for 3D gene expression analysis,7281080,R01DA015802,"['Parkinson&apos', 's disease', 'bioimaging /biomedical imaging', 'brain mapping', 'computer data analysis', 'disease /disorder model', 'drug abuse', 'functional /structural genomics', 'gene expression', 'genetic models', 'high throughput technology', 'image processing', 'in situ hybridization', 'informatics', 'laboratory mouse', 'mathematics', 'method development', 'microarray technology', 'model design /development', 'neurogenetics', 'neurophysiology', 'polymerase chain reaction', 'schizophrenia', 'three dimensional imaging /topography']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,6156,0.01449472397612656
"Voxelation: a new method for 3D gene expression analysis   DESCRIPTION (provided by applicant): A major opportunity for the post-genomic        world will be to understand how the genome constructs the brain, and how this        process goes awry in disease. The approach we are taking combines the                computational procedures of biomedical imaging technologies, such as CT and          PET, with high throughput methods to acquire 3D gene expression patterns in the      brain. This new technology is called voxelation, and gets its name from the          term ""voxel,"" which refers to a cubic 3D image volume element. The voxel is the      3D analog of the familiar 2D image element, the pixel. Voxelation entails the        direct creation of voxels (cubes) in spatial register with the brain, and            application of high throughput gene expression analytic techniques to RNA            extracted from the voxels. Imaging algorithms are then employed to reconstruct       spatial information in high throughput. Using microarrays, we have obtained low      resolution (40 voxel) images of the normal mouse brain for 9,000 genes, giving       novel insights into the construction of the brain by the genome. Also using          microarrays, we have acquired 2,000 gene, 24 voxel images of coronal                 hemisections of both normal and Alzheimer's disease human brains at the level        of the hippocampus. Our analysis has revealed a common network of co-regulated       genes, and allowed identification of putative control regions. In addition, a        number of intriguing candidate genes have been found whose level of expression       is significantly different between the Alzheimer's and normal hemisections.          Finally, singular value decomposition (SVD), a mathematical technique used to        provide parsimonious explanations of complex data sets, produced images that         distinguished between brain structures, including cortex, caudate and                hippocampus. Building on the foundations provided by these studies, voxelation       will be employed in two Specific Aims using the mouse. (1.) Using microarrays,       low resolution (40 voxel) high throughput (9,000) gene images of the brain will      be acquired in four mouse models of human neuropsychiatric disorders:                Parkinson's disease, drug addiction, schizophrenia, and dopamine D3 receptor         deficiency. (2.) To extend the technology of voxelation, high resolution (300        voxel) moderate throughput (hundreds of gene) images of the mouse brain will be      obtained using real-time quantitative RT-PCR. An instrument, the voxelator, has      been constructed for semiautomated miniaturized harvesting of the voxels.            Images from both Specific Aims 1 and 2 will be validated using classical             techniques, such as in situ hybridization. This research promises important new      insights into the nexus of genome and brain, in health and disease, and may          also provide novel avenues to therapy.                                               n/a",Voxelation: a new method for 3D gene expression analysis,7033037,R01DA015802,"['Parkinson&apos', 's disease', 'bioimaging /biomedical imaging', 'brain mapping', 'computer data analysis', 'disease /disorder model', 'drug abuse', 'functional /structural genomics', 'gene expression', 'genetic models', 'high throughput technology', 'image processing', 'in situ hybridization', 'informatics', 'laboratory mouse', 'mathematics', 'method development', 'microarray technology', 'model design /development', 'neurogenetics', 'neurophysiology', 'polymerase chain reaction', 'schizophrenia', 'three dimensional imaging /topography']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,297833,0.01449472397612656
"Voxelation: a new method for 3D gene expression analysis   DESCRIPTION (provided by applicant): A major opportunity for the post-genomic        world will be to understand how the genome constructs the brain, and how this        process goes awry in disease. The approach we are taking combines the                computational procedures of biomedical imaging technologies, such as CT and          PET, with high throughput methods to acquire 3D gene expression patterns in the      brain. This new technology is called voxelation, and gets its name from the          term ""voxel,"" which refers to a cubic 3D image volume element. The voxel is the      3D analog of the familiar 2D image element, the pixel. Voxelation entails the        direct creation of voxels (cubes) in spatial register with the brain, and            application of high throughput gene expression analytic techniques to RNA            extracted from the voxels. Imaging algorithms are then employed to reconstruct       spatial information in high throughput. Using microarrays, we have obtained low      resolution (40 voxel) images of the normal mouse brain for 9,000 genes, giving       novel insights into the construction of the brain by the genome. Also using          microarrays, we have acquired 2,000 gene, 24 voxel images of coronal                 hemisections of both normal and Alzheimer's disease human brains at the level        of the hippocampus. Our analysis has revealed a common network of co-regulated       genes, and allowed identification of putative control regions. In addition, a        number of intriguing candidate genes have been found whose level of expression       is significantly different between the Alzheimer's and normal hemisections.          Finally, singular value decomposition (SVD), a mathematical technique used to        provide parsimonious explanations of complex data sets, produced images that         distinguished between brain structures, including cortex, caudate and                hippocampus. Building on the foundations provided by these studies, voxelation       will be employed in two Specific Aims using the mouse. (1.) Using microarrays,       low resolution (40 voxel) high throughput (9,000) gene images of the brain will      be acquired in four mouse models of human neuropsychiatric disorders:                Parkinson's disease, drug addiction, schizophrenia, and dopamine D3 receptor         deficiency. (2.) To extend the technology of voxelation, high resolution (300        voxel) moderate throughput (hundreds of gene) images of the mouse brain will be      obtained using real-time quantitative RT-PCR. An instrument, the voxelator, has      been constructed for semiautomated miniaturized harvesting of the voxels.            Images from both Specific Aims 1 and 2 will be validated using classical             techniques, such as in situ hybridization. This research promises important new      insights into the nexus of genome and brain, in health and disease, and may          also provide novel avenues to therapy.                                               n/a",Voxelation: a new method for 3D gene expression analysis,6858750,R01DA015802,"['Parkinson&apos', 's disease', 'bioimaging /biomedical imaging', 'brain mapping', 'computer data analysis', 'disease /disorder model', 'drug abuse', 'functional /structural genomics', 'gene expression', 'genetic models', 'high throughput technology', 'image processing', 'in situ hybridization', 'informatics', 'laboratory mouse', 'mathematics', 'method development', 'microarray technology', 'model design /development', 'neurogenetics', 'neurophysiology', 'polymerase chain reaction', 'schizophrenia', 'three dimensional imaging /topography']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2005,305000,0.01449472397612656
"Voxelation: a new method for 3D gene expression analysis   DESCRIPTION (provided by applicant): A major opportunity for the post-genomic        world will be to understand how the genome constructs the brain, and how this        process goes awry in disease. The approach we are taking combines the                computational procedures of biomedical imaging technologies, such as CT and          PET, with high throughput methods to acquire 3D gene expression patterns in the      brain. This new technology is called voxelation, and gets its name from the          term ""voxel,"" which refers to a cubic 3D image volume element. The voxel is the      3D analog of the familiar 2D image element, the pixel. Voxelation entails the        direct creation of voxels (cubes) in spatial register with the brain, and            application of high throughput gene expression analytic techniques to RNA            extracted from the voxels. Imaging algorithms are then employed to reconstruct       spatial information in high throughput. Using microarrays, we have obtained low      resolution (40 voxel) images of the normal mouse brain for 9,000 genes, giving       novel insights into the construction of the brain by the genome. Also using          microarrays, we have acquired 2,000 gene, 24 voxel images of coronal                 hemisections of both normal and Alzheimer's disease human brains at the level        of the hippocampus. Our analysis has revealed a common network of co-regulated       genes, and allowed identification of putative control regions. In addition, a        number of intriguing candidate genes have been found whose level of expression       is significantly different between the Alzheimer's and normal hemisections.          Finally, singular value decomposition (SVD), a mathematical technique used to        provide parsimonious explanations of complex data sets, produced images that         distinguished between brain structures, including cortex, caudate and                hippocampus. Building on the foundations provided by these studies, voxelation       will be employed in two Specific Aims using the mouse. (1.) Using microarrays,       low resolution (40 voxel) high throughput (9,000) gene images of the brain will      be acquired in four mouse models of human neuropsychiatric disorders:                Parkinson's disease, drug addiction, schizophrenia, and dopamine D3 receptor         deficiency. (2.) To extend the technology of voxelation, high resolution (300        voxel) moderate throughput (hundreds of gene) images of the mouse brain will be      obtained using real-time quantitative RT-PCR. An instrument, the voxelator, has      been constructed for semiautomated miniaturized harvesting of the voxels.            Images from both Specific Aims 1 and 2 will be validated using classical             techniques, such as in situ hybridization. This research promises important new      insights into the nexus of genome and brain, in health and disease, and may          also provide novel avenues to therapy.                                               n/a",Voxelation: a new method for 3D gene expression analysis,6702555,R01DA015802,"['Parkinson&apos', 's disease', 'bioimaging /biomedical imaging', 'brain mapping', 'computer data analysis', 'disease /disorder model', 'drug abuse', 'functional /structural genomics', 'gene expression', 'genetic models', 'high throughput technology', 'image processing', 'in situ hybridization', 'informatics', 'laboratory mouse', 'mathematics', 'method development', 'microarray technology', 'model design /development', 'neurogenetics', 'neurophysiology', 'polymerase chain reaction', 'schizophrenia', 'three dimensional imaging /topography']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,305000,0.01449472397612656
"Voxelation: a new method for 3D gene expression analysis   DESCRIPTION (provided by applicant): A major opportunity for the post-genomic        world will be to understand how the genome constructs the brain, and how this        process goes awry in disease. The approach we are taking combines the                computational procedures of biomedical imaging technologies, such as CT and          PET, with high throughput methods to acquire 3D gene expression patterns in the      brain. This new technology is called voxelation, and gets its name from the          term ""voxel,"" which refers to a cubic 3D image volume element. The voxel is the      3D analog of the familiar 2D image element, the pixel. Voxelation entails the        direct creation of voxels (cubes) in spatial register with the brain, and            application of high throughput gene expression analytic techniques to RNA            extracted from the voxels. Imaging algorithms are then employed to reconstruct       spatial information in high throughput. Using microarrays, we have obtained low      resolution (40 voxel) images of the normal mouse brain for 9,000 genes, giving       novel insights into the construction of the brain by the genome. Also using          microarrays, we have acquired 2,000 gene, 24 voxel images of coronal                 hemisections of both normal and Alzheimer's disease human brains at the level        of the hippocampus. Our analysis has revealed a common network of co-regulated       genes, and allowed identification of putative control regions. In addition, a        number of intriguing candidate genes have been found whose level of expression       is significantly different between the Alzheimer's and normal hemisections.          Finally, singular value decomposition (SVD), a mathematical technique used to        provide parsimonious explanations of complex data sets, produced images that         distinguished between brain structures, including cortex, caudate and                hippocampus. Building on the foundations provided by these studies, voxelation       will be employed in two Specific Aims using the mouse. (1.) Using microarrays,       low resolution (40 voxel) high throughput (9,000) gene images of the brain will      be acquired in four mouse models of human neuropsychiatric disorders:                Parkinson's disease, drug addiction, schizophrenia, and dopamine D3 receptor         deficiency. (2.) To extend the technology of voxelation, high resolution (300        voxel) moderate throughput (hundreds of gene) images of the mouse brain will be      obtained using real-time quantitative RT-PCR. An instrument, the voxelator, has      been constructed for semiautomated miniaturized harvesting of the voxels.            Images from both Specific Aims 1 and 2 will be validated using classical             techniques, such as in situ hybridization. This research promises important new      insights into the nexus of genome and brain, in health and disease, and may          also provide novel avenues to therapy.                                               n/a",Voxelation: a new method for 3D gene expression analysis,6621936,R01DA015802,"[""Parkinson's disease"", ' bioimaging /biomedical imaging', ' brain mapping', ' computer data analysis', ' disease /disorder model', ' drug abuse', ' functional /structural genomics', ' gene expression', ' genetic models', ' high throughput technology', ' image processing', ' in situ hybridization', ' informatics', ' laboratory mouse', ' mathematics', ' method development', ' microarray technology', ' model design /development', ' neurogenetics', ' neurophysiology', ' polymerase chain reaction', ' schizophrenia', ' three dimensional imaging /topography']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2003,305000,0.01449472397612656
"Voxelation: a new method for 3D gene expression analysis   DESCRIPTION (provided by applicant): A major opportunity for the post-genomic        world will be to understand how the genome constructs the brain, and how this        process goes awry in disease. The approach we are taking combines the                computational procedures of biomedical imaging technologies, such as CT and          PET, with high throughput methods to acquire 3D gene expression patterns in the      brain. This new technology is called voxelation, and gets its name from the          term ""voxel,"" which refers to a cubic 3D image volume element. The voxel is the      3D analog of the familiar 2D image element, the pixel. Voxelation entails the        direct creation of voxels (cubes) in spatial register with the brain, and            application of high throughput gene expression analytic techniques to RNA            extracted from the voxels. Imaging algorithms are then employed to reconstruct       spatial information in high throughput. Using microarrays, we have obtained low      resolution (40 voxel) images of the normal mouse brain for 9,000 genes, giving       novel insights into the construction of the brain by the genome. Also using          microarrays, we have acquired 2,000 gene, 24 voxel images of coronal                 hemisections of both normal and Alzheimer's disease human brains at the level        of the hippocampus. Our analysis has revealed a common network of co-regulated       genes, and allowed identification of putative control regions. In addition, a        number of intriguing candidate genes have been found whose level of expression       is significantly different between the Alzheimer's and normal hemisections.          Finally, singular value decomposition (SVD), a mathematical technique used to        provide parsimonious explanations of complex data sets, produced images that         distinguished between brain structures, including cortex, caudate and                hippocampus. Building on the foundations provided by these studies, voxelation       will be employed in two Specific Aims using the mouse. (1.) Using microarrays,       low resolution (40 voxel) high throughput (9,000) gene images of the brain will      be acquired in four mouse models of human neuropsychiatric disorders:                Parkinson's disease, drug addiction, schizophrenia, and dopamine D3 receptor         deficiency. (2.) To extend the technology of voxelation, high resolution (300        voxel) moderate throughput (hundreds of gene) images of the mouse brain will be      obtained using real-time quantitative RT-PCR. An instrument, the voxelator, has      been constructed for semiautomated miniaturized harvesting of the voxels.            Images from both Specific Aims 1 and 2 will be validated using classical             techniques, such as in situ hybridization. This research promises important new      insights into the nexus of genome and brain, in health and disease, and may          also provide novel avenues to therapy.                                               n/a",Voxelation: a new method for 3D gene expression analysis,6437885,R01DA015802,"[""Parkinson's disease"", ' bioimaging /biomedical imaging', ' brain mapping', ' computer data analysis', ' disease /disorder model', ' drug abuse', ' functional /structural genomics', ' gene expression', ' genetic models', ' high throughput technology', ' image processing', ' in situ hybridization', ' informatics', ' laboratory mouse', ' mathematics', ' method development', ' microarray technology', ' model design /development', ' neurogenetics', ' neurophysiology', ' polymerase chain reaction', ' schizophrenia']",NIDA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2002,305250,0.01449472397612656
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9922272,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Database Management Systems', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Infrastructure', 'Ingestion', 'Investigation', 'Laboratory of Neuro Imaging Resource', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data curation', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'image archival system', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2020,1217435,0.015573036465725665
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9700661,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Database Management Systems', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Infrastructure', 'Ingestion', 'Investigation', 'Laboratories', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data archive', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'neuroimaging', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2019,1217435,0.015573036465725665
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9491555,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Autistic Disorder', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Investigation', 'Laboratories', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data archive', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'neuroimaging', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2018,1717236,0.015573036465725665
"Sub-millimeter Simultaneous SPECT-CT for Imaging    DESCRIPTION (provided by applicant):    We are proposing to develop a single, bench-top animal scanner that will acquire both functional SPECT images and anatomical CT images with sub-millimeter spatial resolution for both imaging modalities. The sub-mm SPECT-CT will provide a technique for noninvasive functional imaging in mice for a wide range of applications, including the development of new radio-pharmaceuticals, assessment of new therapeutic approaches, and investigation of fundamental biological processes in transgenic and knockout mice. This would allow investigators to perform serial imaging studies in the same animal at multiple time points to investigate tumor growth, tissue pathology, the effects of therapy, and the mechanism of action of new diagnostic agents. The system will have wide applicability and significant impact in research that uses small animals to advance our understanding of human disease processes. During phase I we successfully completed all proposed feasibility studies to demonstrate SPECT/CT with gamma performance of 1.3mm intrinsic spatial resolution, E range from 30keV to 350keV, and,deltaE/E=12% at 140keV and - 100mu m CT capability from a 50xS0mm CMOS based digital x-ray detector. In addition, we acquired outstanding dual SPECT-CT images of euthanized mice. During the phase II project we will complete the integration of the high-resolution SPECT and transmission CT subsystems and develop all necessary hardware and software. The result will be a fully functional dual-modality prototype scanner for anatomical and quantitative metabolic imaging of small animals.         n/a",Sub-millimeter Simultaneous SPECT-CT for Imaging,6773880,R44RR016393,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computed axial tomography', 'computer system design /evaluation', 'image processing', 'laboratory mouse', 'noninvasive diagnosis', 'single photon emission computed tomography', 'technology /technique development', 'whole body imaging /scanning']",NCRR,"PHOTON IMAGING, INC.",R44,2004,368960,-0.011830590847516762
"Sub-millimeter Simultaneous SPECT-CT for Imaging    DESCRIPTION (provided by applicant):    We are proposing to develop a single, bench-top animal scanner that will acquire both functional SPECT images and anatomical CT images with sub-millimeter spatial resolution for both imaging modalities. The sub-mm SPECT-CT will provide a technique for noninvasive functional imaging in mice for a wide range of applications, including the development of new radio-pharmaceuticals, assessment of new therapeutic approaches, and investigation of fundamental biological processes in transgenic and knockout mice. This would allow investigators to perform serial imaging studies in the same animal at multiple time points to investigate tumor growth, tissue pathology, the effects of therapy, and the mechanism of action of new diagnostic agents. The system will have wide applicability and significant impact in research that uses small animals to advance our understanding of human disease processes. During phase I we successfully completed all proposed feasibility studies to demonstrate SPECT/CT with gamma performance of 1.3mm intrinsic spatial resolution, E range from 30keV to 350keV, and,deltaE/E=12% at 140keV and - 100mu m CT capability from a 50xS0mm CMOS based digital x-ray detector. In addition, we acquired outstanding dual SPECT-CT images of euthanized mice. During the phase II project we will complete the integration of the high-resolution SPECT and transmission CT subsystems and develop all necessary hardware and software. The result will be a fully functional dual-modality prototype scanner for anatomical and quantitative metabolic imaging of small animals.         n/a",Sub-millimeter Simultaneous SPECT-CT for Imaging,6693866,R44RR016393,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computed axial tomography', ' computer system design /evaluation', ' image processing', ' laboratory mouse', ' noninvasive diagnosis', ' single photon emission computed tomography', ' technology /technique development', ' whole body imaging /scanning']",NCRR,"PHOTON IMAGING, INC.",R44,2003,379863,-0.011830590847516762
"Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T Project Summary The goal of this project is to develop a framework for high-performance parallel transmission (pTx) that is trans- ferable to a wide range of MRI scanners, and apply it to push the spatial encoding limits of echo planar imaging (EPI) at 7 Tesla. EPI is by far the most widely used pulse sequence for rapid functional, diffusion, and perfusion imaging, and has been the focus of considerable development in recent years to increase its speed and spatial resolution. Now there is a strong desire to push EPI's spatial resolution down to the micro scale. For functional MRI (fMRI), this would enable imaging of ﬁne structures (layers, columns, and nuclei) of cortical and subcortical architecture while better resolving the hemodynamic response. For diffusion MRI (dMRI), micro scale EPI would improve surface and laminar analysis of ﬁbers in the cortex, as well as brain parcelation using fractional anisotropy differences between gray matter regions, while broadly reducing partial volume effects. It would further enable EPI to be broadly applied to accelerate anatomic scans that are geometrically matched to fMRI and dMRI scans. However, increasing the resolution of single-shot EPI requires longer readouts which extend echo times and re- duce functional contrast in fMRI and signal-to-noise in dMRI at 7 Tesla, while increasing geometric distortions and blurring. Segmented or multishot EPI is a classic method to increase spatial resolution without increasing readout durations, but is underutilized, primarily due to its high sensitivity to motion and dynamic phase changes between shots which cause large image artifacts.  We propose to develop a new multishot EPI technique called shuttered EPI, which addresses the lim- itations of conventional multishot EPI by imaging a set of spatially disjoint shutters in each shot. The shutters are produced by a multidimensional excitation pulse and are spatially shifted between shots to cover an entire slice. However, with thin slices the length of the excitation pulses are impractical (20-100 ms). Many-coil pTx (> 8 coils) can shorten the length of these pulses to feasible durations, but current 7 Tesla scanners have only 8 transmit channels due to cost, footprint, cabling, and other constraints. In the ﬁrst project period we pioneered a technique called array-compressed pTx (acpTx) which overcomes this limitation. Using acpTx, 8 transmit chan- nels can control an arbitrarily large number of coils, where the channels and coils are connected via an array compression network that is optimized with RF pulses for speciﬁc excitations. In this project, we will develop and apply acpTx methods and hardware (a many-coil head transmit array and an 8 channel-to-many coil array com- pression network) to achieve feasible RF pulse durations when exciting the shutter patterns required for shuttered EPI. These developments will be implemented on two major 7T scanner platforms and evaluated in submillimeter (600 micron) fMRI and dMRI acquisitions. Overall, the project encompasses the synergistic design of RF pulses, hardware, acquisitions and reconstructions to achieve a major advance in spatial encoding. Project Narrative Diffusion and functional magnetic resonance imaging (MRI) at 7 Tesla ﬁeld strength using echo planar imaging (EPI) has the potential to deliver clear images of brain structure and function at the level of layers, columns, and nuclei. However, when existing EPI scans are pushed to the spatial resolutions required to resolve these structures, they become highly sensitive to off resonance-induced geometric distortions, relaxation-induced blur- ring, physiological noise and motion. To address this problem, in this project we will develop many-coil array- compressed parallel transmission and apply it to enable shuttered multishot EPI scans that are robust to these effects.",Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T,9850978,R01EB016695,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Anisotropy', 'Architecture', 'Biological', 'Brain', 'Brain imaging', 'Cell Nucleus', 'Data', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Echo-Planar Imaging', 'Elements', 'Fiber', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Head', 'Homebound Persons', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Length', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methods', 'Morphologic artifacts', 'Motion', 'Noise', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Physiological', 'Problem Formulations', 'Relaxation', 'Research Project Grants', 'Resolution', 'Scanning', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Structure', 'Surface', 'System', 'Techniques', 'Thinness', 'Time', 'base', 'blood oxygen level dependent', 'cost', 'design', 'gray matter', 'hemodynamics', 'image reconstruction', 'improved', 'magnetic field', 'motion sensitivity', 'neuroimaging', 'perfusion imaging', 'phase change', 'reconstruction', 'response', 'simulation', 'spectroscopic imaging', 'time use', 'transmission process', 'virtual']",NIBIB,VANDERBILT UNIVERSITY,R01,2020,569563,-0.0010795541099032897
"Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T Project Summary The goal of this project is to develop a framework for high-performance parallel transmission (pTx) that is trans- ferable to a wide range of MRI scanners, and apply it to push the spatial encoding limits of echo planar imaging (EPI) at 7 Tesla. EPI is by far the most widely used pulse sequence for rapid functional, diffusion, and perfusion imaging, and has been the focus of considerable development in recent years to increase its speed and spatial resolution. Now there is a strong desire to push EPI's spatial resolution down to the micro scale. For functional MRI (fMRI), this would enable imaging of ﬁne structures (layers, columns, and nuclei) of cortical and subcortical architecture while better resolving the hemodynamic response. For diffusion MRI (dMRI), micro scale EPI would improve surface and laminar analysis of ﬁbers in the cortex, as well as brain parcelation using fractional anisotropy differences between gray matter regions, while broadly reducing partial volume effects. It would further enable EPI to be broadly applied to accelerate anatomic scans that are geometrically matched to fMRI and dMRI scans. However, increasing the resolution of single-shot EPI requires longer readouts which extend echo times and re- duce functional contrast in fMRI and signal-to-noise in dMRI at 7 Tesla, while increasing geometric distortions and blurring. Segmented or multishot EPI is a classic method to increase spatial resolution without increasing readout durations, but is underutilized, primarily due to its high sensitivity to motion and dynamic phase changes between shots which cause large image artifacts.  We propose to develop a new multishot EPI technique called shuttered EPI, which addresses the lim- itations of conventional multishot EPI by imaging a set of spatially disjoint shutters in each shot. The shutters are produced by a multidimensional excitation pulse and are spatially shifted between shots to cover an entire slice. However, with thin slices the length of the excitation pulses are impractical (20-100 ms). Many-coil pTx (> 8 coils) can shorten the length of these pulses to feasible durations, but current 7 Tesla scanners have only 8 transmit channels due to cost, footprint, cabling, and other constraints. In the ﬁrst project period we pioneered a technique called array-compressed pTx (acpTx) which overcomes this limitation. Using acpTx, 8 transmit chan- nels can control an arbitrarily large number of coils, where the channels and coils are connected via an array compression network that is optimized with RF pulses for speciﬁc excitations. In this project, we will develop and apply acpTx methods and hardware (a many-coil head transmit array and an 8 channel-to-many coil array com- pression network) to achieve feasible RF pulse durations when exciting the shutter patterns required for shuttered EPI. These developments will be implemented on two major 7T scanner platforms and evaluated in submillimeter (600 micron) fMRI and dMRI acquisitions. Overall, the project encompasses the synergistic design of RF pulses, hardware, acquisitions and reconstructions to achieve a major advance in spatial encoding. Project Narrative Diffusion and functional magnetic resonance imaging (MRI) at 7 Tesla ﬁeld strength using echo planar imaging (EPI) has the potential to deliver clear images of brain structure and function at the level of layers, columns, and nuclei. However, when existing EPI scans are pushed to the spatial resolutions required to resolve these structures, they become highly sensitive to off resonance-induced geometric distortions, relaxation-induced blur- ring, physiological noise and motion. To address this problem, in this project we will develop many-coil array- compressed parallel transmission and apply it to enable shuttered multishot EPI scans that are robust to these effects.",Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T,9669022,R01EB016695,"['Address', 'Algorithms', 'Anatomy', 'Anisotropy', 'Architecture', 'Biological', 'Brain', 'Brain imaging', 'Cell Nucleus', 'Data', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Echo-Planar Imaging', 'Elements', 'Fiber', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Head', 'Homebound Persons', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Length', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methods', 'Morphologic artifacts', 'Motion', 'Noise', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Physiological', 'Problem Formulations', 'Relaxation', 'Research Project Grants', 'Resolution', 'Scanning', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Structure', 'Surface', 'System', 'Techniques', 'Thinness', 'Time', 'base', 'blood oxygen level dependent', 'cost', 'design', 'gray matter', 'hemodynamics', 'image reconstruction', 'improved', 'magnetic field', 'motion sensitivity', 'neuroimaging', 'perfusion imaging', 'phase change', 'reconstruction', 'response', 'simulation', 'spectroscopic imaging', 'time use', 'transmission process', 'virtual']",NIBIB,VANDERBILT UNIVERSITY,R01,2019,569563,-0.0010795541099032897
"Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T Project Summary The goal of this project is to develop a framework for high-performance parallel transmission (pTx) that is trans- ferable to a wide range of MRI scanners, and apply it to push the spatial encoding limits of echo planar imaging (EPI) at 7 Tesla. EPI is by far the most widely used pulse sequence for rapid functional, diffusion, and perfusion imaging, and has been the focus of considerable development in recent years to increase its speed and spatial resolution. Now there is a strong desire to push EPI's spatial resolution down to the micro scale. For functional MRI (fMRI), this would enable imaging of ﬁne structures (layers, columns, and nuclei) of cortical and subcortical architecture while better resolving the hemodynamic response. For diffusion MRI (dMRI), micro scale EPI would improve surface and laminar analysis of ﬁbers in the cortex, as well as brain parcelation using fractional anisotropy differences between gray matter regions, while broadly reducing partial volume effects. It would further enable EPI to be broadly applied to accelerate anatomic scans that are geometrically matched to fMRI and dMRI scans. However, increasing the resolution of single-shot EPI requires longer readouts which extend echo times and re- duce functional contrast in fMRI and signal-to-noise in dMRI at 7 Tesla, while increasing geometric distortions and blurring. Segmented or multishot EPI is a classic method to increase spatial resolution without increasing readout durations, but is underutilized, primarily due to its high sensitivity to motion and dynamic phase changes between shots which cause large image artifacts.  We propose to develop a new multishot EPI technique called shuttered EPI, which addresses the lim- itations of conventional multishot EPI by imaging a set of spatially disjoint shutters in each shot. The shutters are produced by a multidimensional excitation pulse and are spatially shifted between shots to cover an entire slice. However, with thin slices the length of the excitation pulses are impractical (20-100 ms). Many-coil pTx (> 8 coils) can shorten the length of these pulses to feasible durations, but current 7 Tesla scanners have only 8 transmit channels due to cost, footprint, cabling, and other constraints. In the ﬁrst project period we pioneered a technique called array-compressed pTx (acpTx) which overcomes this limitation. Using acpTx, 8 transmit chan- nels can control an arbitrarily large number of coils, where the channels and coils are connected via an array compression network that is optimized with RF pulses for speciﬁc excitations. In this project, we will develop and apply acpTx methods and hardware (a many-coil head transmit array and an 8 channel-to-many coil array com- pression network) to achieve feasible RF pulse durations when exciting the shutter patterns required for shuttered EPI. These developments will be implemented on two major 7T scanner platforms and evaluated in submillimeter (600 micron) fMRI and dMRI acquisitions. Overall, the project encompasses the synergistic design of RF pulses, hardware, acquisitions and reconstructions to achieve a major advance in spatial encoding. Project Narrative Diffusion and functional magnetic resonance imaging (MRI) at 7 Tesla ﬁeld strength using echo planar imaging (EPI) has the potential to deliver clear images of brain structure and function at the level of layers, columns, and nuclei. However, when existing EPI scans are pushed to the spatial resolutions required to resolve these structures, they become highly sensitive to off resonance-induced geometric distortions, relaxation-induced blur- ring, physiological noise and motion. To address this problem, in this project we will develop many-coil array- compressed parallel transmission and apply it to enable shuttered multishot EPI scans that are robust to these effects.",Array-Compressed Parallel Transmission for High Resolution Neuroimaging at 7T,9524416,R01EB016695,"['Address', 'Algorithms', 'Anatomy', 'Anisotropy', 'Architecture', 'Biological', 'Brain', 'Brain imaging', 'Cell Nucleus', 'Data', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Echo-Planar Imaging', 'Elements', 'Fiber', 'Functional Magnetic Resonance Imaging', 'Funding', 'Goals', 'Head', 'Homebound Persons', 'Image', 'Image Enhancement', 'Imaging Techniques', 'Length', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methods', 'Morphologic artifacts', 'Motion', 'Noise', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic pulse', 'Physiological', 'Problem Formulations', 'Relaxation', 'Research Project Grants', 'Resolution', 'Scanning', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Structure', 'Surface', 'System', 'Techniques', 'Thinness', 'Time', 'base', 'blood oxygen level dependent', 'cost', 'design', 'gray matter', 'hemodynamics', 'image reconstruction', 'improved', 'magnetic field', 'motion sensitivity', 'neuroimaging', 'perfusion imaging', 'phase change', 'reconstruction', 'response', 'simulation', 'spectroscopic imaging', 'time use', 'transmission process', 'virtual']",NIBIB,VANDERBILT UNIVERSITY,R01,2018,598063,-0.0010795541099032897
"Epidemiologic Study of Neural Reserve and Neurobiology of Aging PROJECT SUMMARY/ABSTRACT Extensive progress was made in the previous funding period of the Rush Memory and Aging Project (MAP). We 1) elucidated the neuropathologic basis of cognitive decline due to Alzheimer’s disease and related disorders (ADRD), 2) discovered genomic, experiential, psychological, and medical risk factors for ADRD clinical and pathologic traits including numerous risk factors for Alzheimer’s dementia with little to no relationship with ADRD brain pathologies, and 3) identified numerous potential novel therapeutic targets for cognitive decline, especially targets for cognitive decline not explained by common brain pathologies i.e., resilience. Here, the average person has average resilience and individuals can be more or less resilient. Resilience is a high value therapeutic target because if druggable it would offset the effects of any combination of brain pathologies. In this funding cycle, we propose to continue to follow MAP participants and conduct autopsies, and in this cycle, to obtain skin biopsies at autopsy to support a powerful new drug discovery program that integrates existing brain omics data with a new human cellular model of disease, i.e., skin derived fibroblast cultures induced into neuronal lines from persons with more or less resilience. We propose to: 1) define a robust and specific molecular signature of resilience in the human brain; 2) identify gene targets of resilience and establish human low-resilience cell models derived from MAP participants of known resilience; and 3) conduct drug discovery screens in the low-resilience models to identify compounds that increase resilience. These aims are supported by compelling preliminary work. An Exploratory Aim will continue to identify risk factors for ADRD clinical and pathologic traits leveraging the rich resource generated from the exposure data, repeated measures, and neuropathologic traits . All aims will examine sex as a biologic variable. A Secondary Aim will continue to share the unique and valuable resources generated by MAP including the to-be-generated fibroblast cell lines with the scientific community. Harnessing mechanisms of resilience to ADRD can slow down or prevent cognitive decline regardless of the presence and complexity of common brain pathologies. Therefore, the genes and compounds identified from our study will provide new therapeutic remedies to boost brain reserve in combating ADRD-related dementia. We believe that the proposed continuation will have a high and sustained impact on the field of aging and dementia research. POJECT NARRATIVE/PUBLIC HEALTH RELEVANCE The identification of novel therapeutics to prevent of cognitive decline, MCI and Alzheimer’s dementia is a major public health priority. Resilience is a high value therapeutic target with the potential to maintain cognition regardless of the type and number of brain pathologies. The proposed continuation of MAP will identify genes and compounds that affect a molecular signature of resilience in a novel human cell model of disease from autopsied MAP partic ipants .",Epidemiologic Study of Neural Reserve and Neurobiology of Aging,10018624,R01AG017917,"['Affect', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Autopsy', 'Biological', 'Biological Models', 'Biopsy', 'Brain', 'Brain Diseases', 'Brain Pathology', 'Cell Line', 'Cell model', 'Cells', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Cognition', 'Cognitive', 'Communities', 'Custom', 'Data', 'Data Sources', 'Dementia', 'Disease', 'Disease model', 'Drug Screening', 'Female', 'Fibroblasts', 'Funding', 'Gene Targeting', 'Genes', 'Genetic Screening', 'Genomics', 'Human', 'Impaired cognition', 'Individual', 'Libraries', 'Machine Learning', 'Measures', 'Medical', 'Memory', 'Modeling', 'Molecular', 'Molecular Profiling', 'Neurobiology', 'Neurons', 'Participant', 'Pathologic', 'Persons', 'Research', 'Resource Sharing', 'Resources', 'Risk Factors', 'Skin', 'Source', 'Work', 'apolipoprotein E-3', 'base', 'combat', 'data hub', 'drug discovery', 'epidemiology study', 'experimental study', 'genome wide association study', 'human model', 'in silico', 'induced pluripotent stem cell', 'innovation', 'neuropathology', 'new therapeutic target', 'novel', 'novel therapeutics', 'prevent', 'programs', 'prospective', 'psychologic', 'public health priorities', 'public health relevance', 'relating to nervous system', 'resilience', 'sex', 'therapeutic target', 'trait']",NIA,RUSH UNIVERSITY MEDICAL CENTER,R01,2020,3035766,-0.0336667120605475
"Epidemiologic Study of Neural Reserve and Neurobiology of Aging PROJECT SUMMARY/ABSTRACT Extensive progress was made in the previous funding period of the Rush Memory and Aging Project (MAP). We 1) elucidated the neuropathologic basis of cognitive decline due to Alzheimer’s disease and related disorders (ADRD), 2) discovered genomic, experiential, psychological, and medical risk factors for ADRD clinical and pathologic traits including numerous risk factors for Alzheimer’s dementia with little to no relationship with ADRD brain pathologies, and 3) identified numerous potential novel therapeutic targets for cognitive decline, especially targets for cognitive decline not explained by common brain pathologies i.e., resilience. Here, the average person has average resilience and individuals can be more or less resilient. Resilience is a high value therapeutic target because if druggable it would offset the effects of any combination of brain pathologies. In this funding cycle, we propose to continue to follow MAP participants and conduct autopsies, and in this cycle, to obtain skin biopsies at autopsy to support a powerful new drug discovery program that integrates existing brain omics data with a new human cellular model of disease, i.e., skin derived fibroblast cultures induced into neuronal lines from persons with more or less resilience. We propose to: 1) define a robust and specific molecular signature of resilience in the human brain; 2) identify gene targets of resilience and establish human low-resilience cell models derived from MAP participants of known resilience; and 3) conduct drug discovery screens in the low-resilience models to identify compounds that increase resilience. These aims are supported by compelling preliminary work. An Exploratory Aim will continue to identify risk factors for ADRD clinical and pathologic traits leveraging the rich resource generated from the exposure data, repeated measures, and neuropathologic traits . All aims will examine sex as a biologic variable. A Secondary Aim will continue to share the unique and valuable resources generated by MAP including the to-be-generated fibroblast cell lines with the scientific community. Harnessing mechanisms of resilience to ADRD can slow down or prevent cognitive decline regardless of the presence and complexity of common brain pathologies. Therefore, the genes and compounds identified from our study will provide new therapeutic remedies to boost brain reserve in combating ADRD-related dementia. We believe that the proposed continuation will have a high and sustained impact on the field of aging and dementia research. POJECT NARRATIVE/PUBLIC HEALTH RELEVANCE The identification of novel therapeutics to prevent of cognitive decline, MCI and Alzheimer’s dementia is a major public health priority. Resilience is a high value therapeutic target with the potential to maintain cognition regardless of the type and number of brain pathologies. The proposed continuation of MAP will identify genes and compounds that affect a molecular signature of resilience in a novel human cell model of disease from autopsied MAP partic ipants .",Epidemiologic Study of Neural Reserve and Neurobiology of Aging,9917201,R01AG017917,"['Affect', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Autopsy', 'Biological', 'Biological Models', 'Biopsy', 'Brain', 'Brain Diseases', 'Brain Pathology', 'Cell Line', 'Cell model', 'Cells', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Cognition', 'Cognitive', 'Communities', 'Computer Simulation', 'Custom', 'Data', 'Data Sources', 'Dementia', 'Disease', 'Disease model', 'Drug Screening', 'Female', 'Fibroblasts', 'Funding', 'Gene Targeting', 'Genes', 'Genetic Screening', 'Genomics', 'Human', 'Impaired cognition', 'Individual', 'Libraries', 'Machine Learning', 'Measures', 'Medical', 'Memory', 'Modeling', 'Molecular', 'Molecular Profiling', 'Neurobiology', 'Neurons', 'Participant', 'Pathologic', 'Persons', 'Research', 'Resource Sharing', 'Resources', 'Risk Factors', 'Skin', 'Source', 'Work', 'apolipoprotein E-3', 'base', 'combat', 'drug discovery', 'epidemiology study', 'experimental study', 'genome wide association study', 'human model', 'induced pluripotent stem cell', 'innovation', 'neuropathology', 'new therapeutic target', 'novel', 'novel therapeutics', 'prevent', 'programs', 'prospective', 'psychologic', 'public health priorities', 'public health relevance', 'relating to nervous system', 'resilience', 'sex', 'therapeutic target', 'trait']",NIA,RUSH UNIVERSITY MEDICAL CENTER,R01,2019,2825827,-0.0336667120605475
"Epidemiologic Study of Neural Reserve and Neurobiology of Aging DESCRIPTION (provided by applicant): The prevention of cognitive decline and dementia is a major public health priority. The Memory and Aging Project (MAP) has made considerable progress elucidating the complex relationships between risk factors, common neuropathologies and resilience markers that increase or decrease the rate of cognitive decline, and risk of dementia. In nearly 200 peer-reviewed manuscripts, we reported genetic, medical, experiential, and psychological factors associated with increased or decreased rates of cognitive decline and dementia risk. We reported that Alzheimer's, vascular, and Lewy body pathologies (AD, CVD, LBD) explain about 40% of the variation of cognitive decline, and that resilience markers (e.g., cortical presynaptic proteins and locus coeruleus neurons) were associated with a slower rate of decline accounting for 8% of the variation, and that many risk factors with little direct relation o pathologies or resilience markers accounted for >10% of the variation of decline, controlling for pathologies. Additional factors related to cognitive decline await discovery. The overall goal of the planned continuation of MAP is to discover additional proteins associated with the slope of cognitive decline, after accounting for the effects of common pathologies. We use the term ""residual cognitive decline"" to describe this innovative primary study outcome. Methods to interrogate the genome, and therefore, the proteome, have improved markedly over the past decade, making the discovery of proteins that underlie cognitive decline both timely and feasible. We plan to continue collecting clinical and post-mortem data on MAP participants. Aim 1, Discovery and Verification Phase, will combine ""omics-wide"" association studies with innovative integrative pathway analyses on genomic, epigenomic, and transcriptomic data from human brain from 500 MAP participants to discover proteins associated with residual cognitive decline; it will select 200 proteins for quantitation in human brain to verify that protein level i associated with residual cognitive decline. Aim 2, Validation Phase, will quantify the 200 proteins selected and verified in Aim 1 with a new sample of 350 brains from MAP participants that will accrue by the end the funding period, followed by a joint statistical analysis to increas power (n=850). Aim 3 will link the validated proteins to the wealth of available risk factor data t discover novel biologic pathways linking risk factors to cognitive decline and dementia. Our plan is supported by extensive and compelling new preliminary data that demonstrate its high likelihood of success and demonstrate that the study is innovative, high yield and low risk. The continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline. These proteins will represent either unknown pathologies that increase rates of cognitive decline or resilience markers that decrease rates of cognitive decline. Both sets of proteins will offer new therapeutic targets for the prevention and treatment of cognitive decline and dementia. Thus, the study has the potential to have a high and sustained impact on aging and dementia research. PUBLIC HEALTH RELEVANCE: The prevention of cognitive decline, MCI and dementia is a major public health priority. The proposed continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline, MCI and dementia. These proteins, representing unknown pathologies and resilience markers associated with faster and slower rates of cognitive decline, will offer new therapeutic targets for the prevention and treatment of cognitive decline, MCI and dementia.",Epidemiologic Study of Neural Reserve and Neurobiology of Aging,9462863,R01AG017917,"['Accounting', 'Aging', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Biological Assay', 'Biological Neural Networks', 'Blood Vessels', 'Brain', 'Cerebrovascular Disorders', 'Clinical', 'Cognition', 'Cognitive', 'Cohort Studies', 'Communities', 'Complex', 'Data', 'Dementia', 'Ensure', 'Funding', 'GSTP1 gene', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Human', 'Impaired cognition', 'Intervention', 'Joints', 'Lewy Bodies', 'Lewy Body Disease', 'Link', 'Manuscripts', 'Measurement', 'Medical', 'Memory', 'Methods', 'Monitor', 'Neurobiology', 'Neurons', 'Outcome Study', 'Parkinsonian Disorders', 'Participant', 'Pathology', 'Pathology Report', 'Pathway Analysis', 'Pathway interactions', 'Peer Review', 'Pharmacology', 'Phase', 'Phenotype', 'Prefrontal Cortex', 'Prevention', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Psychological Factors', 'Publications', 'Reaction', 'Reporting', 'Research', 'Residual state', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Set protein', 'Statistical Data Interpretation', 'Time', 'Validation', 'Variant', 'base', 'brain tissue', 'cognitive change', 'density', 'epidemiology study', 'epigenomics', 'frailty', 'gene discovery', 'hippocampal sclerosis', 'human data', 'improved', 'innovation', 'inter-individual variation', 'locus ceruleus structure', 'mild cognitive impairment', 'neocortical', 'neuropathology', 'new therapeutic target', 'novel', 'presynaptic', 'protein TDP-43', 'public health priorities', 'public health relevance', 'relating to nervous system', 'resilience', 'success', 'text searching', 'transcriptomics']",NIA,RUSH UNIVERSITY MEDICAL CENTER,R01,2018,1952898,-0.04513009151704523
"Epidemiologic Study of Neural Reserve and Neurobiology of Aging DESCRIPTION (provided by applicant): The prevention of cognitive decline and dementia is a major public health priority. The Memory and Aging Project (MAP) has made considerable progress elucidating the complex relationships between risk factors, common neuropathologies and resilience markers that increase or decrease the rate of cognitive decline, and risk of dementia. In nearly 200 peer-reviewed manuscripts, we reported genetic, medical, experiential, and psychological factors associated with increased or decreased rates of cognitive decline and dementia risk. We reported that Alzheimer's, vascular, and Lewy body pathologies (AD, CVD, LBD) explain about 40% of the variation of cognitive decline, and that resilience markers (e.g., cortical presynaptic proteins and locus coeruleus neurons) were associated with a slower rate of decline accounting for 8% of the variation, and that many risk factors with little direct relation o pathologies or resilience markers accounted for >10% of the variation of decline, controlling for pathologies. Additional factors related to cognitive decline await discovery. The overall goal of the planned continuation of MAP is to discover additional proteins associated with the slope of cognitive decline, after accounting for the effects of common pathologies. We use the term ""residual cognitive decline"" to describe this innovative primary study outcome. Methods to interrogate the genome, and therefore, the proteome, have improved markedly over the past decade, making the discovery of proteins that underlie cognitive decline both timely and feasible. We plan to continue collecting clinical and post-mortem data on MAP participants. Aim 1, Discovery and Verification Phase, will combine ""omics-wide"" association studies with innovative integrative pathway analyses on genomic, epigenomic, and transcriptomic data from human brain from 500 MAP participants to discover proteins associated with residual cognitive decline; it will select 200 proteins for quantitation in human brain to verify that protein level i associated with residual cognitive decline. Aim 2, Validation Phase, will quantify the 200 proteins selected and verified in Aim 1 with a new sample of 350 brains from MAP participants that will accrue by the end the funding period, followed by a joint statistical analysis to increas power (n=850). Aim 3 will link the validated proteins to the wealth of available risk factor data t discover novel biologic pathways linking risk factors to cognitive decline and dementia. Our plan is supported by extensive and compelling new preliminary data that demonstrate its high likelihood of success and demonstrate that the study is innovative, high yield and low risk. The continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline. These proteins will represent either unknown pathologies that increase rates of cognitive decline or resilience markers that decrease rates of cognitive decline. Both sets of proteins will offer new therapeutic targets for the prevention and treatment of cognitive decline and dementia. Thus, the study has the potential to have a high and sustained impact on aging and dementia research. PUBLIC HEALTH RELEVANCE: The prevention of cognitive decline, MCI and dementia is a major public health priority. The proposed continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline, MCI and dementia. These proteins, representing unknown pathologies and resilience markers associated with faster and slower rates of cognitive decline, will offer new therapeutic targets for the prevention and treatment of cognitive decline, MCI and dementia.",Epidemiologic Study of Neural Reserve and Neurobiology of Aging,9264466,R01AG017917,"['Accounting', 'Aging', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Biological Assay', 'Biological Neural Networks', 'Blood Vessels', 'Brain', 'Cerebrovascular Disorders', 'Clinical', 'Cognition', 'Cognitive', 'Cohort Studies', 'Communities', 'Complex', 'Data', 'Dementia', 'Ensure', 'Funding', 'GSTP1 gene', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Human', 'Impaired cognition', 'Intervention', 'Joints', 'Lewy Bodies', 'Lewy Body Disease', 'Link', 'Manuscripts', 'Measurement', 'Medical', 'Memory', 'Methods', 'Monitor', 'Neurobiology', 'Neurons', 'Outcome Study', 'Parkinsonian Disorders', 'Participant', 'Pathology', 'Pathology Report', 'Pathway Analysis', 'Pathway interactions', 'Peer Review', 'Pharmacology', 'Phase', 'Phenotype', 'Prefrontal Cortex', 'Prevention', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Psychological Factors', 'Publications', 'Reaction', 'Reporting', 'Research', 'Residual state', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Set protein', 'Statistical Data Interpretation', 'Time', 'Validation', 'Variant', 'base', 'brain tissue', 'cognitive change', 'density', 'epidemiology study', 'epigenomics', 'frailty', 'gene discovery', 'hippocampal sclerosis', 'human data', 'improved', 'innovation', 'inter-individual variation', 'locus ceruleus structure', 'mild cognitive impairment', 'neocortical', 'neuropathology', 'new therapeutic target', 'novel', 'presynaptic', 'protein TDP-43', 'public health priorities', 'public health relevance', 'relating to nervous system', 'resilience', 'success', 'text searching', 'transcriptomics']",NIA,RUSH UNIVERSITY MEDICAL CENTER,R01,2017,1959843,-0.04513009151704523
"Epidemiologic Study of Neural Reserve and Neurobiology of Aging DESCRIPTION (provided by applicant): The prevention of cognitive decline and dementia is a major public health priority. The Memory and Aging Project (MAP) has made considerable progress elucidating the complex relationships between risk factors, common neuropathologies and resilience markers that increase or decrease the rate of cognitive decline, and risk of dementia. In nearly 200 peer-reviewed manuscripts, we reported genetic, medical, experiential, and psychological factors associated with increased or decreased rates of cognitive decline and dementia risk. We reported that Alzheimer's, vascular, and Lewy body pathologies (AD, CVD, LBD) explain about 40% of the variation of cognitive decline, and that resilience markers (e.g., cortical presynaptic proteins and locus coeruleus neurons) were associated with a slower rate of decline accounting for 8% of the variation, and that many risk factors with little direct relation o pathologies or resilience markers accounted for >10% of the variation of decline, controlling for pathologies. Additional factors related to cognitive decline await discovery. The overall goal of the planned continuation of MAP is to discover additional proteins associated with the slope of cognitive decline, after accounting for the effects of common pathologies. We use the term ""residual cognitive decline"" to describe this innovative primary study outcome. Methods to interrogate the genome, and therefore, the proteome, have improved markedly over the past decade, making the discovery of proteins that underlie cognitive decline both timely and feasible. We plan to continue collecting clinical and post-mortem data on MAP participants. Aim 1, Discovery and Verification Phase, will combine ""omics-wide"" association studies with innovative integrative pathway analyses on genomic, epigenomic, and transcriptomic data from human brain from 500 MAP participants to discover proteins associated with residual cognitive decline; it will select 200 proteins for quantitation in human brain to verify that protein level i associated with residual cognitive decline. Aim 2, Validation Phase, will quantify the 200 proteins selected and verified in Aim 1 with a new sample of 350 brains from MAP participants that will accrue by the end the funding period, followed by a joint statistical analysis to increas power (n=850). Aim 3 will link the validated proteins to the wealth of available risk factor data t discover novel biologic pathways linking risk factors to cognitive decline and dementia. Our plan is supported by extensive and compelling new preliminary data that demonstrate its high likelihood of success and demonstrate that the study is innovative, high yield and low risk. The continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline. These proteins will represent either unknown pathologies that increase rates of cognitive decline or resilience markers that decrease rates of cognitive decline. Both sets of proteins will offer new therapeutic targets for the prevention and treatment of cognitive decline and dementia. Thus, the study has the potential to have a high and sustained impact on aging and dementia research. PUBLIC HEALTH RELEVANCE: The prevention of cognitive decline, MCI and dementia is a major public health priority. The proposed continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline, MCI and dementia. These proteins, representing unknown pathologies and resilience markers associated with faster and slower rates of cognitive decline, will offer new therapeutic targets for the prevention and treatment of cognitive decline, MCI and dementia.",Epidemiologic Study of Neural Reserve and Neurobiology of Aging,9041455,R01AG017917,"['Accounting', 'Aging', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Biological Assay', 'Biological Neural Networks', 'Blood Vessels', 'Brain', 'Cerebrovascular Disorders', 'Clinical', 'Cognition', 'Cognitive', 'Cohort Studies', 'Communities', 'Complex', 'Data', 'Dementia', 'Ensure', 'Epidemiologic Studies', 'Funding', 'GSTP1 gene', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Impaired cognition', 'Intervention', 'Joints', 'Lewy Bodies', 'Lewy Body Disease', 'Link', 'Manuscripts', 'Measurement', 'Medical Genetics', 'Memory', 'Methods', 'Monitor', 'Neurobiology', 'Neurons', 'Outcome Study', 'Parkinsonian Disorders', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Peer Review', 'Phase', 'Phenotype', 'Prefrontal Cortex', 'Prevention', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Psychological Factors', 'Publications', 'Reaction', 'Reporting', 'Research', 'Residual state', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Set protein', 'Statistical Data Interpretation', 'Validation', 'Variant', 'base', 'brain tissue', 'cognitive change', 'density', 'epigenomics', 'frailty', 'gene discovery', 'hippocampal sclerosis', 'human data', 'improved', 'innovation', 'inter-individual variation', 'locus ceruleus structure', 'mild cognitive impairment', 'neocortical', 'neuropathology', 'new therapeutic target', 'novel', 'presynaptic', 'protein TDP-43', 'public health priorities', 'relating to nervous system', 'resilience', 'success', 'text searching', 'transcriptomics']",NIA,RUSH UNIVERSITY MEDICAL CENTER,R01,2016,2096988,-0.04513009151704523
"Epidemiologic Study of Neural Reserve and Neurobiology of Aging DESCRIPTION (provided by applicant): The prevention of cognitive decline and dementia is a major public health priority. The Memory and Aging Project (MAP) has made considerable progress elucidating the complex relationships between risk factors, common neuropathologies and resilience markers that increase or decrease the rate of cognitive decline, and risk of dementia. In nearly 200 peer-reviewed manuscripts, we reported genetic, medical, experiential, and psychological factors associated with increased or decreased rates of cognitive decline and dementia risk. We reported that Alzheimer's, vascular, and Lewy body pathologies (AD, CVD, LBD) explain about 40% of the variation of cognitive decline, and that resilience markers (e.g., cortical presynaptic proteins and locus coeruleus neurons) were associated with a slower rate of decline accounting for 8% of the variation, and that many risk factors with little direct relation o pathologies or resilience markers accounted for >10% of the variation of decline, controlling for pathologies. Additional factors related to cognitive decline await discovery. The overall goal of the planned continuation of MAP is to discover additional proteins associated with the slope of cognitive decline, after accounting for the effects of common pathologies. We use the term ""residual cognitive decline"" to describe this innovative primary study outcome. Methods to interrogate the genome, and therefore, the proteome, have improved markedly over the past decade, making the discovery of proteins that underlie cognitive decline both timely and feasible. We plan to continue collecting clinical and post-mortem data on MAP participants. Aim 1, Discovery and Verification Phase, will combine ""omics-wide"" association studies with innovative integrative pathway analyses on genomic, epigenomic, and transcriptomic data from human brain from 500 MAP participants to discover proteins associated with residual cognitive decline; it will select 200 proteins for quantitation in human brain to verify that protein level i associated with residual cognitive decline. Aim 2, Validation Phase, will quantify the 200 proteins selected and verified in Aim 1 with a new sample of 350 brains from MAP participants that will accrue by the end the funding period, followed by a joint statistical analysis to increas power (n=850). Aim 3 will link the validated proteins to the wealth of available risk factor data t discover novel biologic pathways linking risk factors to cognitive decline and dementia. Our plan is supported by extensive and compelling new preliminary data that demonstrate its high likelihood of success and demonstrate that the study is innovative, high yield and low risk. The continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline. These proteins will represent either unknown pathologies that increase rates of cognitive decline or resilience markers that decrease rates of cognitive decline. Both sets of proteins will offer new therapeutic targets for the prevention and treatment of cognitive decline and dementia. Thus, the study has the potential to have a high and sustained impact on aging and dementia research. PUBLIC HEALTH RELEVANCE: The prevention of cognitive decline, MCI and dementia is a major public health priority. The proposed continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline, MCI and dementia. These proteins, representing unknown pathologies and resilience markers associated with faster and slower rates of cognitive decline, will offer new therapeutic targets for the prevention and treatment of cognitive decline, MCI and dementia.",Epidemiologic Study of Neural Reserve and Neurobiology of Aging,8874816,R01AG017917,"['Accounting', 'Aging', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Biological Assay', 'Biological Neural Networks', 'Blood Vessels', 'Brain', 'Cerebrovascular Disorders', 'Clinical', 'Cognition', 'Cognitive', 'Cohort Studies', 'Communities', 'Complex', 'Data', 'Dementia', 'Ensure', 'Epidemiologic Studies', 'Funding', 'GSTP1 gene', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Hippocampus (Brain)', 'Human', 'Impaired cognition', 'Individual', 'Intervention', 'Joints', 'Lewy Bodies', 'Lewy Body Disease', 'Link', 'Manuscripts', 'Measurement', 'Medical Genetics', 'Memory', 'Methods', 'Monitor', 'Neurobiology', 'Neurons', 'Outcome Study', 'Parkinsonian Disorders', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Peer Review', 'Phase', 'Phenotype', 'Prefrontal Cortex', 'Prevention', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Psychological Factors', 'Publications', 'Reaction', 'Reporting', 'Research', 'Residual state', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Sclerosis', 'Set protein', 'Validation', 'Variant', 'base', 'brain tissue', 'cognitive change', 'density', 'epigenomics', 'frailty', 'gene discovery', 'human data', 'improved', 'innovation', 'locus ceruleus structure', 'mild cognitive impairment', 'neocortical', 'neuropathology', 'new therapeutic target', 'novel', 'presynaptic', 'protein TDP-43', 'public health priorities', 'relating to nervous system', 'resilience', 'success', 'text searching', 'transcriptomics']",NIA,RUSH UNIVERSITY MEDICAL CENTER,R01,2015,1967107,-0.04513009151704523
"Epidemiologic Study of Neural Reserve and Neurobiology of Aging DESCRIPTION (provided by applicant): The prevention of cognitive decline and dementia is a major public health priority. The Memory and Aging Project (MAP) has made considerable progress elucidating the complex relationships between risk factors, common neuropathologies and resilience markers that increase or decrease the rate of cognitive decline, and risk of dementia. In nearly 200 peer-reviewed manuscripts, we reported genetic, medical, experiential, and psychological factors associated with increased or decreased rates of cognitive decline and dementia risk. We reported that Alzheimer's, vascular, and Lewy body pathologies (AD, CVD, LBD) explain about 40% of the variation of cognitive decline, and that resilience markers (e.g., cortical presynaptic proteins and locus coeruleus neurons) were associated with a slower rate of decline accounting for 8% of the variation, and that many risk factors with little direct relation o pathologies or resilience markers accounted for >10% of the variation of decline, controlling for pathologies. Additional factors related to cognitive decline await discovery. The overall goal of the planned continuation of MAP is to discover additional proteins associated with the slope of cognitive decline, after accounting for the effects of common pathologies. We use the term ""residual cognitive decline"" to describe this innovative primary study outcome. Methods to interrogate the genome, and therefore, the proteome, have improved markedly over the past decade, making the discovery of proteins that underlie cognitive decline both timely and feasible. We plan to continue collecting clinical and post-mortem data on MAP participants. Aim 1, Discovery and Verification Phase, will combine ""omics-wide"" association studies with innovative integrative pathway analyses on genomic, epigenomic, and transcriptomic data from human brain from 500 MAP participants to discover proteins associated with residual cognitive decline; it will select 200 proteins for quantitation in human brain to verify that protein level i associated with residual cognitive decline. Aim 2, Validation Phase, will quantify the 200 proteins selected and verified in Aim 1 with a new sample of 350 brains from MAP participants that will accrue by the end the funding period, followed by a joint statistical analysis to increas power (n=850). Aim 3 will link the validated proteins to the wealth of available risk factor data t discover novel biologic pathways linking risk factors to cognitive decline and dementia. Our plan is supported by extensive and compelling new preliminary data that demonstrate its high likelihood of success and demonstrate that the study is innovative, high yield and low risk. The continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline. These proteins will represent either unknown pathologies that increase rates of cognitive decline or resilience markers that decrease rates of cognitive decline. Both sets of proteins will offer new therapeutic targets for the prevention and treatment of cognitive decline and dementia. Thus, the study has the potential to have a high and sustained impact on aging and dementia research. PUBLIC HEALTH RELEVANCE: The prevention of cognitive decline, MCI and dementia is a major public health priority. The proposed continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline, MCI and dementia. These proteins, representing unknown pathologies and resilience markers associated with faster and slower rates of cognitive decline, will offer new therapeutic targets for the prevention and treatment of cognitive decline, MCI and dementia.",Epidemiologic Study of Neural Reserve and Neurobiology of Aging,8875101,R01AG017917,"['Accounting', 'Aging', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Biological Assay', 'Biological Neural Networks', 'Blood Vessels', 'Brain', 'Cerebrovascular Disorders', 'Clinical', 'Cognition', 'Cognitive', 'Cohort Studies', 'Communities', 'Complex', 'Data', 'Dementia', 'Ensure', 'Epidemiologic Studies', 'Funding', 'GSTP1 gene', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Hippocampus (Brain)', 'Human', 'Impaired cognition', 'Individual', 'Intervention', 'Joints', 'Lewy Bodies', 'Lewy Body Disease', 'Link', 'Manuscripts', 'Measurement', 'Medical Genetics', 'Memory', 'Methods', 'Monitor', 'Neurobiology', 'Neurons', 'Outcome Study', 'Parkinsonian Disorders', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Peer Review', 'Phase', 'Phenotype', 'Prefrontal Cortex', 'Prevention', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Psychological Factors', 'Publications', 'Reaction', 'Reporting', 'Research', 'Residual state', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Sclerosis', 'Set protein', 'Validation', 'Variant', 'base', 'brain tissue', 'cognitive change', 'density', 'epigenomics', 'frailty', 'gene discovery', 'human data', 'improved', 'innovation', 'locus ceruleus structure', 'mild cognitive impairment', 'neocortical', 'neuropathology', 'new therapeutic target', 'novel', 'presynaptic', 'protein TDP-43', 'public health priorities', 'relating to nervous system', 'resilience', 'success', 'text searching', 'transcriptomics']",NIA,RUSH UNIVERSITY MEDICAL CENTER,R01,2014,154995,-0.04513009151704523
"Epidemiologic Study of Neural Reserve and Neurobiology of Aging     DESCRIPTION (provided by applicant): The prevention of cognitive decline and dementia is a major public health priority. The Memory and Aging Project (MAP) has made considerable progress elucidating the complex relationships between risk factors, common neuropathologies and resilience markers that increase or decrease the rate of cognitive decline, and risk of dementia. In nearly 200 peer-reviewed manuscripts, we reported genetic, medical, experiential, and psychological factors associated with increased or decreased rates of cognitive decline and dementia risk. We reported that Alzheimer's, vascular, and Lewy body pathologies (AD, CVD, LBD) explain about 40% of the variation of cognitive decline, and that resilience markers (e.g., cortical presynaptic proteins and locus coeruleus neurons) were associated with a slower rate of decline accounting for 8% of the variation, and that many risk factors with little direct relation o pathologies or resilience markers accounted for >10% of the variation of decline, controlling for pathologies. Additional factors related to cognitive decline await discovery. The overall goal of the planned continuation of MAP is to discover additional proteins associated with the slope of cognitive decline, after accounting for the effects of common pathologies. We use the term ""residual cognitive decline"" to describe this innovative primary study outcome. Methods to interrogate the genome, and therefore, the proteome, have improved markedly over the past decade, making the discovery of proteins that underlie cognitive decline both timely and feasible. We plan to continue collecting clinical and post-mortem data on MAP participants. Aim 1, Discovery and Verification Phase, will combine ""omics-wide"" association studies with innovative integrative pathway analyses on genomic, epigenomic, and transcriptomic data from human brain from 500 MAP participants to discover proteins associated with residual cognitive decline; it will select 200 proteins for quantitation in human brain to verify that protein level i associated with residual cognitive decline. Aim 2, Validation Phase, will quantify the 200 proteins selected and verified in Aim 1 with a new sample of 350 brains from MAP participants that will accrue by the end the funding period, followed by a joint statistical analysis to increas power (n=850). Aim 3 will link the validated proteins to the wealth of available risk factor data t discover novel biologic pathways linking risk factors to cognitive decline and dementia. Our plan is supported by extensive and compelling new preliminary data that demonstrate its high likelihood of success and demonstrate that the study is innovative, high yield and low risk. The continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline. These proteins will represent either unknown pathologies that increase rates of cognitive decline or resilience markers that decrease rates of cognitive decline. Both sets of proteins will offer new therapeutic targets for the prevention and treatment of cognitive decline and dementia. Thus, the study has the potential to have a high and sustained impact on aging and dementia research.         PUBLIC HEALTH RELEVANCE: The prevention of cognitive decline, MCI and dementia is a major public health priority. The proposed continuation of MAP will discover additional proteins associated with cognitive decline and novel biologic pathways linking risk factors to cognitive decline, MCI and dementia. These proteins, representing unknown pathologies and resilience markers associated with faster and slower rates of cognitive decline, will offer new therapeutic targets for the prevention and treatment of cognitive decline, MCI and dementia.            ",Epidemiologic Study of Neural Reserve and Neurobiology of Aging,8693374,R01AG017917,"['Accounting', 'Aging', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Biological Assay', 'Biological Neural Networks', 'Blood Vessels', 'Brain', 'Cerebrovascular Disorders', 'Clinical', 'Cognition', 'Cognitive', 'Cohort Studies', 'Communities', 'Complex', 'Data', 'Dementia', 'Ensure', 'Epidemiologic Studies', 'Funding', 'GSTP1 gene', 'Genes', 'Genome', 'Genomics', 'Goals', 'Hippocampus (Brain)', 'Human', 'Impaired cognition', 'Individual', 'Intervention', 'Joints', 'Lewy Bodies', 'Lewy Body Disease', 'Link', 'Manuscripts', 'Measurement', 'Medical Genetics', 'Memory', 'Methods', 'Monitor', 'Neurobiology', 'Neurons', 'Outcome Study', 'Parkinsonian Disorders', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Peer Review', 'Phase', 'Phenotype', 'Prefrontal Cortex', 'Prevention', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Psychological Factors', 'Publications', 'Reaction', 'Reporting', 'Research', 'Residual state', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Sclerosis', 'Set protein', 'Validation', 'Variant', 'base', 'brain tissue', 'cognitive change', 'density', 'epigenomics', 'frailty', 'gene discovery', 'human data', 'improved', 'innovation', 'locus ceruleus structure', 'mild cognitive impairment', 'neocortical', 'neuropathology', 'new therapeutic target', 'novel', 'presynaptic', 'protein TDP-43', 'public health priorities', 'public health relevance', 'relating to nervous system', 'resilience', 'success', 'text searching', 'transcriptomics']",NIA,RUSH UNIVERSITY MEDICAL CENTER,R01,2014,2048949,-0.04513009151704523
"NORMALIZED BODY SURFACE POTENTIAL MAPS The research has been divided into the following four integrated components:  (1) Instrumentation - Completion of the development of ""State-of-the Art"" Instrumentation to rapidly obtain, on-line and stand-alone at all age groups, electrocardiographic low noise body surface potential color coded maps (BSPM) utilizing 180 passive electrodes with active cables.  Insuring optimal safety in obtaining BSPM simultaneous with indwelling cardiac electrode catheters.  (2) Clinical Studies - four major subprojects.  a) Correlations of simultaneously obtained BSPM with endocardial electrophysiological studies (EPS), with analysis of spread of activation from known positioned stimulated activation during catheterization; b) Correlations of simultaneously obtained BSPM with spread of activation from known positioned epicardial pacemakers; c) Continued development of a normal quantified data base for P, QRS, ST-T, as well as development of maximal knowledge of BSPM's on a large number of children with varying pathology.  Correlations with Frank VCG plus M Mode and 2D Echo; d) Correlation of quantified BSPM's in adults with remote myocardial infarction undergoing cardiac catheterization involving coronary angiography and ventriculography, plus 12 lead simultaneous standard ECG, Frank VCG, and Positron Emission Tomography (PET).  (3) Image Measurements - Investigation of optimal imaging and display of BSPM data including determination of the effects of artifacts and system bandwidth upon the measurements of map features.  Develop a systematic approach to automatic measurements of the map features which encode clinical information.  (4) Biophysical Studies - a) Inverse Electrocardiography Methods for reconstructing epicardial potentials from body surface potential distributions utilizing the multipole expansion approach will be developed and tested.  The reconstructed epicardial maps will aid in the interpretations of BSPM's; b) Forward Problem - An interactive computer model of the electrocardiographic forward problem for realistic heart and torso geometry is being developed.  The model will contain the specialized conduction tissue and will generate isochrones, epicardial potentials, and body surface potential maps (BSPM's).  This model will be used to simulate BSPM's in normal and abnormal conditions and will serve as an additional tool for the interpretation of the maps.  n/a",NORMALIZED BODY SURFACE POTENTIAL MAPS,3335500,R01HL017931,"['Wolff Parkinson White syndrome', ' aortic valve stenosis', ' artificial intelligence', ' biological models', ' biophysics', ' child (0-11)', ' clinical biomedical equipment', ' computer assisted diagnosis', ' computer simulation', ' congenital heart disorder', ' diagnosis quality /standard', ' echocardiography', ' electrical potential', ' electrocardiography', ' electrodes', ' electronic pacemaker', ' electrophysiology', ' epicardial mapping', ' heart catheterization', ' heart disorder diagnosis', ' hemodynamics', ' human subject', ' image processing', ' mathematical model', ' myocardial infarction', ' noninvasive diagnosis', ' ventricular hypertrophy']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,1987,208742,-0.00884975453188906
"NORMALIZED BODY SURFACE POTENTIAL MAPS The research has been divided into the following four integrated components:  (1) Instrumentation - Completion of the development of ""State-of-the Art"" Instrumentation to rapidly obtain, on-line and stand-alone at all age groups, electrocardiographic low noise body surface potential color coded maps (BSPM) utilizing 180 passive electrodes with active cables.  Insuring optimal safety in obtaining BSPM simultaneous with indwelling cardiac electrode catheters.  (2) Clinical Studies - four major subprojects.  a) Correlations of simultaneously obtained BSPM with endocardial electrophysiological studies (EPS), with analysis of spread of activation from known positioned stimulated activation during catheterization; b) Correlations of simultaneously obtained BSPM with spread of activation from known positioned epicardial pacemakers; c) Continued development of a normal quantified data base for P, QRS, ST-T, as well as development of maximal knowledge of BSPM's on a large number of children with varying pathology.  Correlations with Frank VCG plus M Mode and 2D Echo; d) Correlation of quantified BSPM's in adults with remote myocardial infarction undergoing cardiac catheterization involving coronary angiography and ventriculography, plus 12 lead simultaneous standard ECG, Frank VCG, and Positron Emission Tomography (PET).  (3) Image Measurements - Investigation of optimal imaging and display of BSPM data including determination of the effects of artifacts and system bandwidth upon the measurements of map features.  Develop a systematic approach to automatic measurements of the map features which encode clinical information.  (4) Biophysical Studies - a) Inverse Electrocardiography Methods for reconstructing epicardial potentials from body surface potential distributions utilizing the multipole expansion approach will be developed and tested.  The reconstructed epicardial maps will aid in the interpretations of BSPM's; b) Forward Problem - An interactive computer model of the electrocardiographic forward problem for realistic heart and torso geometry is being developed.  The model will contain the specialized conduction tissue and will generate isochrones, epicardial potentials, and body surface potential maps (BSPM's).  This model will be used to simulate BSPM's in normal and abnormal conditions and will serve as an additional tool for the interpretation of the maps.  n/a",NORMALIZED BODY SURFACE POTENTIAL MAPS,3335499,R01HL017931,"['Wolff Parkinson White syndrome', ' aortic valve stenosis', ' artificial intelligence', ' biological models', ' biophysics', ' child (0-11)', ' clinical biomedical equipment', ' computer assisted diagnosis', ' computer simulation', ' congenital heart disorder', ' diagnosis quality /standard', ' echocardiography', ' electrical potential', ' electrocardiography', ' electrodes', ' electronic pacemaker', ' electrophysiology', ' epicardial mapping', ' heart catheterization', ' heart disorder diagnosis', ' hemodynamics', ' human subject', ' image processing', ' mathematical model', ' myocardial infarction', ' noninvasive diagnosis', ' ventricular hypertrophy']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,1986,203786,-0.00884975453188906
"NORMALIZED BODY SURFACE POTENTIAL MAPS The research has been divided into the following four integrated components:  (1) Instrumentation - Completion of the development of ""State-of-the Art"" Instrumentation to rapidly obtain, on-line and stand-alone at all age groups, electrocardiographic low noise body surface potential color coded maps (BSPM) utilizing 180 passive electrodes with active cables.  Insuring optimal safety in obtaining BSPM simultaneous with indwelling cardiac electrode catheters.  (2) Clinical Studies - four major subprojects.  a) Correlations of simultaneously obtained BSPM with endocardial electrophysiological studies (EPS), with analysis of spread of activation from known positioned stimulated activation during catheterization; b) Correlations of simultaneously obtained BSPM with spread of activation from known positioned epicardial pacemakers; c) Continued development of a normal quantified data base for P, QRS, ST-T, as well as development of maximal knowledge of BSPM's on a large number of children with varying pathology.  Correlations with Frank VCG plus M Mode and 2D Echo; d) Correlation of quantified BSPM's in adults with remote myocardial infarction undergoing cardiac catheterization involving coronary angiography and ventriculography, plus 12 lead simultaneous standard ECG, Frank VCG, and Positron Emission Tomography (PET).  (3) Image Measurements - Investigation of optimal imaging and display of BSPM data including determination of the effects of artifacts and system bandwidth upon the measurements of map features.  Develop a systematic approach to automatic measurements of the map features which encode clinical information.  (4) Biophysical Studies - a) Inverse Electrocardiography Methods for reconstructing epicardial potentials from body surface potential distributions utilizing the multipole expansion approach will be developed and tested.  The reconstructed epicardial maps will aid in the interpretations of BSPM's; b) Forward Problem - An interactive computer model of the electrocardiographic forward problem for realistic heart and torso geometry is being developed.  The model will contain the specialized conduction tissue and will generate isochrones, epicardial potentials, and body surface potential maps (BSPM's).  This model will be used to simulate BSPM's in normal and abnormal conditions and will serve as an additional tool for the interpretation of the maps.  n/a",NORMALIZED BODY SURFACE POTENTIAL MAPS,3335494,R01HL017931,"['Wolff Parkinson White syndrome', ' aortic valve stenosis', ' artificial intelligence', ' biological models', ' biophysics', ' child (0-11)', ' clinical biomedical equipment', ' computer assisted diagnosis', ' computer simulation', ' congenital heart disorder', ' diagnosis quality /standard', ' echocardiography', ' electrical potential', ' electrocardiography', ' electrodes', ' electronic pacemaker', ' electrophysiology', ' epicardial mapping', ' heart catheterization', ' heart disorder diagnosis', ' hemodynamics', ' human subject', ' image processing', ' mathematical model', ' myocardial infarction', ' noninvasive diagnosis', ' ventricular hypertrophy']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,1985,193552,-0.00884975453188906
"Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate    DESCRIPTION (provided by applicant): Orofacial clefts, principally cleft lip (CL), cleft palate (CP), and cleft lip and palate (CLP), are among the most common major birth defects, occurring in ~1/700 to 1/1000 live births in various populations around the world, ~70% as a sporadic, isolated abnormality. Such ""non-syndromic"" orofacial clefts act as complex traits, involving multiple genes and environmental risk factors. To date traditional genetic mapping approaches have identified only a few major susceptibility genes for non-syndromic orofacial clefts with certainty. Therefore, new approaches are clearly required. There is considerable evidence that orofacial malformations can occur at the extremes of the normal ranges of phenotypic variation of midfacial size and shape. Here we propose a novel approach to identify genes that regulate midfacial shape in mouse and human. We hypothesize that genes that are major contributors to normal orofacial size and shape will also have important roles in the occurrence of orofacial clefts. To identify such genes, we will perform detailed morphometric analysis of midfacial shape differences in innovative mouse strains as well as in select human populations, combining these studies with genetic analyses to identify genes that control major determinants of midfacial morphometries. Our studies have shown that specific inbred strains of mice have heritable differences in measurable parameters of facial shape. We will take advantage of a valuable new resource we have developed, the mouse ""Collaborative Cross"" (CC), to correlate heritable differences in facial shape among the 8 founder strains of the CC, along with select Recombinant Inbred lines and Recombinant Intercross (RIX), with detailed genetic mapping data for these mice. This approach will enable identification of quantitative trait loci (QTLs) that underlie these morphometric differences. We will complement our mouse studies with a similar analysis of humans, studying specific populations with different susceptibilities to orofacial clefts. These comparative studies will allow us to identify genes that underlie midfacial shape in humans. Finally, we will perform functional studies to assess how the genes we have identified can influence facial shape. Together, these studies should provide a basis for understanding the relationship between human facial morphogenesis and susceptibility to orofacial clefts, and for initiating studies of the functions of these genes in animal models relevant to human orofacial development.        PUBLIC HEALTH RELEVANCE: This proposal is submitted in specific response to an RFA ""to develop projects to advance our understanding of normal craniofacial development and the genetic and environmental perturbations that lead to diseases and disorders."" This proposal will study the genetic determinants of normal orofacial development in mouse and human, with the specific intent of investigating relationship of these genes to human orofacial clefts.          ",Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate,8464054,U01DE020054,"['Affect', 'African', 'Age', 'Animal Model', 'Asians', 'Biological Models', 'Birth', 'Candidate Disease Gene', 'Caucasians', 'Caucasoid Race', 'Child', 'Chromosome Mapping', 'Cleaved cell', 'Cleft Lip', 'Cleft Palate', 'Comparative Study', 'Complement', 'Complex', 'Congenital Abnormality', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Embryonic Development', 'Environmental Risk Factor', 'Ethnic group', 'Face', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Growth and Development function', 'Heritability', 'Hispanics', 'Human', 'In Situ Hybridization', 'Inbred Strains Mice', 'Inbreeding', 'Latino', 'Lead', 'Light', 'Live Birth', 'Maps', 'Measurable', 'Morphogenesis', 'Morphology', 'Mouse Strains', 'Mus', 'Normal Range', 'Not Hispanic or Latino', 'Pattern', 'Phenotype', 'Population', 'Predisposition', 'Principal Component Analysis', 'Principal Investigator', 'Quantitative Trait Loci', 'Recombinants', 'Resources', 'Role', 'Sampling', 'Shapes', 'Susceptibility Gene', 'Testing', 'Variant', 'base', 'cleft lip and palate', 'cohort', 'craniofacial', 'gain of function', 'gene function', 'genetic analysis', 'genetic association', 'genome wide association study', 'innovation', 'knock-down', 'malformation', 'morphometry', 'novel strategies', 'orofacial', 'population based', 'public health relevance', 'research study', 'response', 'trait']",NIDCR,UNIVERSITY OF COLORADO DENVER,U01,2013,235664,0.0028277541243997392
"Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate    DESCRIPTION (provided by applicant): Orofacial clefts, principally cleft lip (CL), cleft palate (CP), and cleft lip and palate (CLP), are among the most common major birth defects, occurring in ~1/700 to 1/1000 live births in various populations around the world, ~70% as a sporadic, isolated abnormality. Such ""non-syndromic"" orofacial clefts act as complex traits, involving multiple genes and environmental risk factors. To date traditional genetic mapping approaches have identified only a few major susceptibility genes for non-syndromic orofacial clefts with certainty. Therefore, new approaches are clearly required. There is considerable evidence that orofacial malformations can occur at the extremes of the normal ranges of phenotypic variation of midfacial size and shape. Here we propose a novel approach to identify genes that regulate midfacial shape in mouse and human. We hypothesize that genes that are major contributors to normal orofacial size and shape will also have important roles in the occurrence of orofacial clefts. To identify such genes, we will perform detailed morphometric analysis of midfacial shape differences in innovative mouse strains as well as in select human populations, combining these studies with genetic analyses to identify genes that control major determinants of midfacial morphometries. Our studies have shown that specific inbred strains of mice have heritable differences in measurable parameters of facial shape. We will take advantage of a valuable new resource we have developed, the mouse ""Collaborative Cross"" (CC), to correlate heritable differences in facial shape among the 8 founder strains of the CC, along with select Recombinant Inbred lines and Recombinant Intercross (RIX), with detailed genetic mapping data for these mice. This approach will enable identification of quantitative trait loci (QTLs) that underlie these morphometric differences. We will complement our mouse studies with a similar analysis of humans, studying specific populations with different susceptibilities to orofacial clefts. These comparative studies will allow us to identify genes that underlie midfacial shape in humans. Finally, we will perform functional studies to assess how the genes we have identified can influence facial shape. Together, these studies should provide a basis for understanding the relationship between human facial morphogenesis and susceptibility to orofacial clefts, and for initiating studies of the functions of these genes in animal models relevant to human orofacial development.        PUBLIC HEALTH RELEVANCE: This proposal is submitted in specific response to an RFA ""to develop projects to advance our understanding of normal craniofacial development and the genetic and environmental perturbations that lead to diseases and disorders."" This proposal will study the genetic determinants of normal orofacial development in mouse and human, with the specific intent of investigating relationship of these genes to human orofacial clefts.          ",Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate,8729693,U01DE020054,"['Affect', 'African', 'Age', 'Animal Model', 'Asians', 'Biological Models', 'Birth', 'Candidate Disease Gene', 'Caucasians', 'Caucasoid Race', 'Child', 'Chromosome Mapping', 'Cleaved cell', 'Cleft Lip', 'Cleft Palate', 'Comparative Study', 'Complement', 'Complex', 'Congenital Abnormality', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Embryonic Development', 'Environmental Risk Factor', 'Ethnic group', 'Face', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Growth and Development function', 'Heritability', 'Hispanics', 'Human', 'In Situ Hybridization', 'Inbred Strains Mice', 'Inbreeding', 'Latino', 'Lead', 'Light', 'Live Birth', 'Maps', 'Measurable', 'Morphogenesis', 'Morphology', 'Mouse Strains', 'Mus', 'Normal Range', 'Not Hispanic or Latino', 'Pattern', 'Phenotype', 'Population', 'Predisposition', 'Principal Component Analysis', 'Principal Investigator', 'Quantitative Trait Loci', 'Recombinants', 'Resources', 'Role', 'Sampling', 'Shapes', 'Susceptibility Gene', 'Testing', 'Variant', 'base', 'cleft lip and palate', 'cohort', 'craniofacial', 'gain of function', 'gene function', 'genetic analysis', 'genetic association', 'genome wide association study', 'innovation', 'knock-down', 'malformation', 'morphometry', 'novel strategies', 'orofacial', 'population based', 'public health relevance', 'research study', 'response', 'trait']",NIDCR,UNIVERSITY OF COLORADO DENVER,U01,2014,28134,0.0028277541243997392
"Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate    DESCRIPTION (provided by applicant): Orofacial clefts, principally cleft lip (CL), cleft palate (CP), and cleft lip and palate (CLP), are among the most common major birth defects, occurring in ~1/700 to 1/1000 live births in various populations around the world, ~70% as a sporadic, isolated abnormality. Such ""non-syndromic"" orofacial clefts act as complex traits, involving multiple genes and environmental risk factors. To date traditional genetic mapping approaches have identified only a few major susceptibility genes for non-syndromic orofacial clefts with certainty. Therefore, new approaches are clearly required. There is considerable evidence that orofacial malformations can occur at the extremes of the normal ranges of phenotypic variation of midfacial size and shape. Here we propose a novel approach to identify genes that regulate midfacial shape in mouse and human. We hypothesize that genes that are major contributors to normal orofacial size and shape will also have important roles in the occurrence of orofacial clefts. To identify such genes, we will perform detailed morphometric analysis of midfacial shape differences in innovative mouse strains as well as in select human populations, combining these studies with genetic analyses to identify genes that control major determinants of midfacial morphometries. Our studies have shown that specific inbred strains of mice have heritable differences in measurable parameters of facial shape. We will take advantage of a valuable new resource we have developed, the mouse ""Collaborative Cross"" (CC), to correlate heritable differences in facial shape among the 8 founder strains of the CC, along with select Recombinant Inbred lines and Recombinant Intercross (RIX), with detailed genetic mapping data for these mice. This approach will enable identification of quantitative trait loci (QTLs) that underlie these morphometric differences. We will complement our mouse studies with a similar analysis of humans, studying specific populations with different susceptibilities to orofacial clefts. These comparative studies will allow us to identify genes that underlie midfacial shape in humans. Finally, we will perform functional studies to assess how the genes we have identified can influence facial shape. Together, these studies should provide a basis for understanding the relationship between human facial morphogenesis and susceptibility to orofacial clefts, and for initiating studies of the functions of these genes in animal models relevant to human orofacial development.       PUBLIC HEALTH RELEVANCE: This proposal is submitted in specific response to an RFA ""to develop projects to advance our understanding of normal craniofacial development and the genetic and environmental perturbations that lead to diseases and disorders."" This proposal will study the genetic determinants of normal orofacial development in mouse and human, with the specific intent of investigating relationship of these genes to human orofacial clefts.           n/a",Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate,8258355,U01DE020054,"['Affect', 'African', 'Age', 'Animal Model', 'Asians', 'Biological Models', 'Birth', 'Candidate Disease Gene', 'Caucasians', 'Caucasoid Race', 'Child', 'Chromosome Mapping', 'Cleaved cell', 'Cleft Lip', 'Cleft Palate', 'Comparative Study', 'Complement', 'Complex', 'Congenital Abnormality', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Embryonic Development', 'Environmental Risk Factor', 'Ethnic group', 'Face', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Growth and Development function', 'Heritability', 'Hispanics', 'Human', 'In Situ Hybridization', 'Inbred Strains Mice', 'Inbreeding', 'Latino', 'Lead', 'Light', 'Live Birth', 'Maps', 'Measurable', 'Morphogenesis', 'Morphology', 'Mouse Strains', 'Mus', 'Normal Range', 'Not Hispanic or Latino', 'Pattern', 'Phenotype', 'Population', 'Predisposition', 'Principal Component Analysis', 'Principal Investigator', 'Quantitative Trait Loci', 'Recombinants', 'Resources', 'Role', 'Sampling', 'Shapes', 'Susceptibility Gene', 'Testing', 'Variant', 'base', 'cleft lip and palate', 'cohort', 'craniofacial', 'gain of function', 'gene function', 'genetic analysis', 'genetic association', 'genome wide association study', 'innovation', 'knock-down', 'malformation', 'morphometry', 'novel strategies', 'orofacial', 'population based', 'public health relevance', 'research study', 'response', 'trait']",NIDCR,UNIVERSITY OF COLORADO DENVER,U01,2012,367740,0.0028277541243997392
"Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate    DESCRIPTION (provided by applicant): Orofacial clefts, principally cleft lip (CL), cleft palate (CP), and cleft lip and palate (CLP), are among the most common major birth defects, occurring in ~1/700 to 1/1000 live births in various populations around the world, ~70% as a sporadic, isolated abnormality. Such ""non-syndromic"" orofacial clefts act as complex traits, involving multiple genes and environmental risk factors. To date traditional genetic mapping approaches have identified only a few major susceptibility genes for non-syndromic orofacial clefts with certainty. Therefore, new approaches are clearly required. There is considerable evidence that orofacial malformations can occur at the extremes of the normal ranges of phenotypic variation of midfacial size and shape. Here we propose a novel approach to identify genes that regulate midfacial shape in mouse and human. We hypothesize that genes that are major contributors to normal orofacial size and shape will also have important roles in the occurrence of orofacial clefts. To identify such genes, we will perform detailed morphometric analysis of midfacial shape differences in innovative mouse strains as well as in select human populations, combining these studies with genetic analyses to identify genes that control major determinants of midfacial morphometries. Our studies have shown that specific inbred strains of mice have heritable differences in measurable parameters of facial shape. We will take advantage of a valuable new resource we have developed, the mouse ""Collaborative Cross"" (CC), to correlate heritable differences in facial shape among the 8 founder strains of the CC, along with select Recombinant Inbred lines and Recombinant Intercross (RIX), with detailed genetic mapping data for these mice. This approach will enable identification of quantitative trait loci (QTLs) that underlie these morphometric differences. We will complement our mouse studies with a similar analysis of humans, studying specific populations with different susceptibilities to orofacial clefts. These comparative studies will allow us to identify genes that underlie midfacial shape in humans. Finally, we will perform functional studies to assess how the genes we have identified can influence facial shape. Together, these studies should provide a basis for understanding the relationship between human facial morphogenesis and susceptibility to orofacial clefts, and for initiating studies of the functions of these genes in animal models relevant to human orofacial development.       PUBLIC HEALTH RELEVANCE: This proposal is submitted in specific response to an RFA ""to develop projects to advance our understanding of normal craniofacial development and the genetic and environmental perturbations that lead to diseases and disorders."" This proposal will study the genetic determinants of normal orofacial development in mouse and human, with the specific intent of investigating relationship of these genes to human orofacial clefts.           n/a",Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate,8062309,U01DE020054,"['Affect', 'African', 'Age', 'Animal Model', 'Asians', 'Biological Models', 'Birth', 'Candidate Disease Gene', 'Caucasians', 'Caucasoid Race', 'Child', 'Chromosome Mapping', 'Cleaved cell', 'Cleft Lip', 'Cleft Palate', 'Comparative Study', 'Complement', 'Complex', 'Congenital Abnormality', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Embryonic Development', 'Environmental Risk Factor', 'Ethnic group', 'Face', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Growth and Development function', 'Heritability', 'Hispanics', 'Human', 'In Situ Hybridization', 'Inbred Strains Mice', 'Inbreeding', 'Latino', 'Lead', 'Light', 'Live Birth', 'Maps', 'Measurable', 'Morphogenesis', 'Morphology', 'Mouse Strains', 'Mus', 'Normal Range', 'Not Hispanic or Latino', 'Pattern', 'Phenotype', 'Population', 'Predisposition', 'Principal Component Analysis', 'Principal Investigator', 'Quantitative Trait Loci', 'Recombinants', 'Resources', 'Role', 'Sampling', 'Shapes', 'Susceptibility Gene', 'Testing', 'Variant', 'base', 'cleft lip and palate', 'cohort', 'craniofacial', 'gain of function', 'gene function', 'genetic analysis', 'genetic association', 'genome wide association study', 'innovation', 'knock-down', 'malformation', 'morphometry', 'novel strategies', 'orofacial', 'population based', 'public health relevance', 'research study', 'response', 'trait']",NIDCR,UNIVERSITY OF COLORADO DENVER,U01,2011,565988,0.0028277541243997392
"Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate    DESCRIPTION (provided by applicant): Orofacial clefts, principally cleft lip (CL), cleft palate (CP), and cleft lip and palate (CLP), are among the most common major birth defects, occurring in ~1/700 to 1/1000 live births in various populations around the world, ~70% as a sporadic, isolated abnormality. Such ""non-syndromic"" orofacial clefts act as complex traits, involving multiple genes and environmental risk factors. To date traditional genetic mapping approaches have identified only a few major susceptibility genes for non-syndromic orofacial clefts with certainty. Therefore, new approaches are clearly required. There is considerable evidence that orofacial malformations can occur at the extremes of the normal ranges of phenotypic variation of midfacial size and shape. Here we propose a novel approach to identify genes that regulate midfacial shape in mouse and human. We hypothesize that genes that are major contributors to normal orofacial size and shape will also have important roles in the occurrence of orofacial clefts. To identify such genes, we will perform detailed morphometric analysis of midfacial shape differences in innovative mouse strains as well as in select human populations, combining these studies with genetic analyses to identify genes that control major determinants of midfacial morphometries. Our studies have shown that specific inbred strains of mice have heritable differences in measurable parameters of facial shape. We will take advantage of a valuable new resource we have developed, the mouse ""Collaborative Cross"" (CC), to correlate heritable differences in facial shape among the 8 founder strains of the CC, along with select Recombinant Inbred lines and Recombinant Intercross (RIX), with detailed genetic mapping data for these mice. This approach will enable identification of quantitative trait loci (QTLs) that underlie these morphometric differences. We will complement our mouse studies with a similar analysis of humans, studying specific populations with different susceptibilities to orofacial clefts. These comparative studies will allow us to identify genes that underlie midfacial shape in humans. Finally, we will perform functional studies to assess how the genes we have identified can influence facial shape. Together, these studies should provide a basis for understanding the relationship between human facial morphogenesis and susceptibility to orofacial clefts, and for initiating studies of the functions of these genes in animal models relevant to human orofacial development.       PUBLIC HEALTH RELEVANCE: This proposal is submitted in specific response to an RFA ""to develop projects to advance our understanding of normal craniofacial development and the genetic and environmental perturbations that lead to diseases and disorders."" This proposal will study the genetic determinants of normal orofacial development in mouse and human, with the specific intent of investigating relationship of these genes to human orofacial clefts.           n/a",Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate,7935373,U01DE020054,"['Affect', 'African', 'Age', 'Animal Model', 'Asians', 'Biological Models', 'Birth', 'Candidate Disease Gene', 'Caucasians', 'Caucasoid Race', 'Child', 'Chromosome Mapping', 'Cleaved cell', 'Cleft Lip', 'Cleft Palate', 'Comparative Study', 'Complement', 'Complex', 'Congenital Abnormality', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Embryonic Development', 'Environmental Risk Factor', 'Ethnic group', 'Face', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Growth and Development function', 'Heritability', 'Hispanics', 'Human', 'In Situ Hybridization', 'Inbred Strains Mice', 'Latino', 'Lead', 'Light', 'Live Birth', 'Maps', 'Measurable', 'Morphogenesis', 'Morphology', 'Mouse Strains', 'Mus', 'Normal Range', 'Not Hispanic or Latino', 'Pattern', 'Phenotype', 'Population', 'Predisposition', 'Principal Component Analysis', 'Principal Investigator', 'Quantitative Trait Loci', 'Recombinants', 'Resources', 'Role', 'Sampling', 'Shapes', 'Susceptibility Gene', 'Testing', 'Variant', 'base', 'cleft lip and palate', 'cohort', 'craniofacial', 'gain of function', 'gene function', 'genetic analysis', 'genetic association', 'genome wide association study', 'innovation', 'knock-down', 'malformation', 'morphometry', 'novel strategies', 'orofacial', 'population based', 'public health relevance', 'research study', 'response', 'trait']",NIDCR,UNIVERSITY OF COLORADO DENVER,U01,2010,550903,0.0028277541243997392
"Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate    DESCRIPTION (provided by applicant): Orofacial clefts, principally cleft lip (CL), cleft palate (CP), and cleft lip and palate (CLP), are among the most common major birth defects, occurring in ~1/700 to 1/1000 live births in various populations around the world, ~70% as a sporadic, isolated abnormality. Such ""non-syndromic"" orofacial clefts act as complex traits, involving multiple genes and environmental risk factors. To date traditional genetic mapping approaches have identified only a few major susceptibility genes for non-syndromic orofacial clefts with certainty. Therefore, new approaches are clearly required. There is considerable evidence that orofacial malformations can occur at the extremes of the normal ranges of phenotypic variation of midfacial size and shape. Here we propose a novel approach to identify genes that regulate midfacial shape in mouse and human. We hypothesize that genes that are major contributors to normal orofacial size and shape will also have important roles in the occurrence of orofacial clefts. To identify such genes, we will perform detailed morphometric analysis of midfacial shape differences in innovative mouse strains as well as in select human populations, combining these studies with genetic analyses to identify genes that control major determinants of midfacial morphometries. Our studies have shown that specific inbred strains of mice have heritable differences in measurable parameters of facial shape. We will take advantage of a valuable new resource we have developed, the mouse ""Collaborative Cross"" (CC), to correlate heritable differences in facial shape among the 8 founder strains of the CC, along with select Recombinant Inbred lines and Recombinant Intercross (RIX), with detailed genetic mapping data for these mice. This approach will enable identification of quantitative trait loci (QTLs) that underlie these morphometric differences. We will complement our mouse studies with a similar analysis of humans, studying specific populations with different susceptibilities to orofacial clefts. These comparative studies will allow us to identify genes that underlie midfacial shape in humans. Finally, we will perform functional studies to assess how the genes we have identified can influence facial shape. Together, these studies should provide a basis for understanding the relationship between human facial morphogenesis and susceptibility to orofacial clefts, and for initiating studies of the functions of these genes in animal models relevant to human orofacial development.       PUBLIC HEALTH RELEVANCE: This proposal is submitted in specific response to an RFA ""to develop projects to advance our understanding of normal craniofacial development and the genetic and environmental perturbations that lead to diseases and disorders."" This proposal will study the genetic determinants of normal orofacial development in mouse and human, with the specific intent of investigating relationship of these genes to human orofacial clefts.           n/a",Genetic Determinants of Orofacial Shape and Relationship to Cleft Lip/Palate,7767390,U01DE020054,"['Affect', 'African', 'Age', 'Animal Model', 'Asians', 'Biological Models', 'Birth', 'Candidate Disease Gene', 'Caucasians', 'Caucasoid Race', 'Child', 'Chromosome Mapping', 'Cleaved cell', 'Cleft Lip', 'Cleft Palate', 'Comparative Study', 'Complement', 'Complex', 'Congenital Abnormality', 'DNA', 'Data', 'Data Set', 'Development', 'Disease', 'Embryonic Development', 'Environmental Risk Factor', 'Ethnic group', 'Face', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Determinism', 'Growth and Development function', 'Heritability', 'Hispanics', 'Human', 'In Situ Hybridization', 'Inbred Strains Mice', 'Latino', 'Lead', 'Light', 'Live Birth', 'Maps', 'Measurable', 'Morphogenesis', 'Morphology', 'Mouse Strains', 'Mus', 'Normal Range', 'Not Hispanic or Latino', 'Pattern', 'Phenotype', 'Population', 'Predisposition', 'Principal Component Analysis', 'Principal Investigator', 'Quantitative Trait Loci', 'Recombinants', 'Resources', 'Role', 'Sampling', 'Shapes', 'Susceptibility Gene', 'Testing', 'Variant', 'base', 'cleft lip and palate', 'cohort', 'craniofacial', 'gain of function', 'gene function', 'genetic analysis', 'genetic association', 'genome wide association study', 'innovation', 'knock-down', 'malformation', 'morphometry', 'novel strategies', 'orofacial', 'population based', 'public health relevance', 'research study', 'response', 'trait']",NIDCR,UNIVERSITY OF COLORADO DENVER,U01,2009,603656,0.0028277541243997392
"Conflict Resolution    DESCRIPTION (provided by applicant): The purpose of this Small Business Innovation Research Phase I proposal is to develop Conflict Resolution for Recovery and Relapse Prevention, a 12-session, multimedia psychoeducational curriculum for adult substance abusers, facilitated by counselors and other treatment professionals in diverse treatment settings. The product's overarching goal is to help reduce relapse and sustain recovery by improving client conflict resolution knowledge, attitudes, and skills. When both Phase I and Phase II are completed, Conflict Resolution will be a bundled product consisting of the following interrelated components: 1) A facilitator's guide, which will feature talking points, exercises, and role plays, as well as tips for interacting with groups and individual/family/couple clients around substance abuse conflict resolution issues, visual aids, and evaluation forms; 2) A participant workbook that reiterates key concepts, provides visuals that reinforce content, and includes homework assignments and personal exercise sheets, and 3) A DVD with modules for both counselors and clients, including didactic and interactive elements. The goals of the conflict resolution package are to: 1) Serve as a research-based, empirically tested, psychoeducational curriculum that is effective and appropriate for use with diverse populations of adult substance abusers; 2) Provide treatment and training materials for professionals that are easy to use and integrate into existing community residential and outpatient substance abuse treatment facilities; 3) Provide an effective, cost-efficient, feasible model for improving client conflict resolution capacities; and 4) Offer an innovative program, based on concepts adapted from effective use in other disciplines/environments and making use of today's technology, to enhance relapse-prevention options. To accomplish these goals, the specific aims for the Phase I period are to: 1) Conduct a focus group with drug abuse treatment professionals; 2) Research and develop the content for the facilitator's guide and participant workbook; 3) Conduct a review of the developed content with an expert Advisory Panel; 4) Develop an outline for an accompanying DVD, to be produced in Phase II; and 5) Conduct a feasibility study of the materials with professional stakeholders. The project has the potential to impact public health by helping drug abuse clients build healthy relationships through conflict resolution principles. These healthy relationships will serve to sustain recovery and prevent relapse.          n/a",Conflict Resolution,7270276,R43DA020219,"['AODD relapse', 'Accounting', 'Active Learning', 'Address', 'Adherence', 'Adolescent', 'Adopted', 'Adult', 'Affect', 'Aftercare', 'Agreement', 'Alcohols', 'Anger', 'Area', 'Assertiveness', 'Attention', 'Attitude', 'Behavior', 'Behavioral', 'Behavioral Research', 'Brain', 'Brain Chemistry', 'Case Study', 'Chemicals', 'Child', 'Client', 'Climacteric', 'Clinical', 'Clinical Nurse Specialists', 'Clip', 'Cognitive', 'Cognitive Therapy', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Computers', 'Conflict (Psychology)', 'Contracts', 'Counseling', 'Country', 'Couples', 'Cues', 'Cyprus', 'Daily', 'Dependency', 'Depth', 'Development', 'Discipline', 'Disease', 'Disputes', 'Drug abuse', 'Drug usage', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Effectiveness', 'Elements', 'Emotional', 'Emotions', 'Empathy', 'Employment', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Exercise', 'Family', 'Family member', 'Family psychotherapy', 'Feasibility Studies', 'Feeling', 'Feeling hopeless', 'Film', 'Focus Groups', 'Frustration', 'Goals', 'Group Processes', 'Group Therapy', 'HIV', 'Healed', 'Health Personnel', 'Hearing', 'Hour', 'Housing', 'Human', 'Individual', 'Inpatients', 'Instinct', 'Institutes', 'Instruction', 'Intelligence', 'International', 'Interpersonal Relations', 'Intervention', 'Knowledge', 'Language', 'Latino', 'Lead', 'Learning', 'Left', 'Legal system', 'Length', 'Letters', 'Life', 'Life Style', 'Limbic System', 'Manuals', 'Marketing', 'Maryland', 'Mediation', 'Mental Health', 'Methods', 'Modeling', 'Motivation', 'Multimedia', 'Needs Assessment', 'Neurologic', 'Neurological Models', 'Nicotine', 'Numbers', 'Online Systems', 'Outcome', 'Outpatients', 'Participant', 'Patients', 'Pattern', 'Personal Satisfaction', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Piper', 'Play', 'Population Heterogeneity', 'Prevention approach', 'Prevention program', 'Procedures', 'Process', 'Professional counselor', 'Program Evaluation', 'Psychologist', 'Public Health', 'Publishing', 'Purpose', 'Qualifying', 'Range', 'Rate', 'Reaction', 'Recovery', 'Rehabilitation therapy', 'Relapse', 'Relative (related person)', 'Research', 'Research Proposals', 'Residential Treatment', 'Resolution', 'Resources', 'Risk', 'Role', 'Role playing therapy', 'Running', 'Schedule', 'School Teachers', 'Series', 'Services', 'Shame', 'Slide', 'Small Business Innovation Research Grant', 'Social Workers', 'Societies', 'Specialist', 'Staff Development', 'Staging', 'Stream', 'Stress', 'Substance Abuse, Other', 'Substance abuse problem', 'Suggestion', 'Surveys', 'System', 'Techniques', 'Technology', 'Teenagers', 'Testing', 'Therapeutic', 'Thinking', 'Time', 'Time Study', 'Tobacco', 'Today', 'Touch sensation', 'Trainers Training', 'Training', 'Training Programs', 'Translating', 'Turtles', 'Uncertainty', 'United States', 'Universities', 'Update', 'Variant', 'Violence', 'Visual Aid', 'Week', 'Work', 'addiction', 'adolescent smoking', 'adolescent substance abuse', 'adolescent substance use', 'alcohol rehabilitation', 'base', 'behavior change', 'brain behavior', 'brain research', 'cognitive change', 'commercial application', 'communication behavior', 'concept', 'coping', 'cost', 'day', 'design', 'disorder later incidence prevention', 'drug addict', 'emotional abuse', 'experience', 'family structure', 'healing', 'improved', 'innovation', 'instrument', 'interest', 'lectures', 'member', 'movie', 'prevent', 'problem drinker', 'programs', 'psychoeducational', 'response', 'size', 'skills', 'smoking cessation', 'social', 'substance abuser', 'technological innovation', 'text searching', 'theories', 'tool', 'treatment center', 'treatment program', 'usability', 'violence prevention']",NIDA,"DANYA INTERNATIONAL, INC.",R43,2007,99998,0.02134111877380046
"GENETIC DIFFERENTIATION IN THE AEDES ALBOPICTUS SUBGROUP The specific aims of the proposed research are to analyze genetic differentiation between 6 species in the Aedes albopictus subgroup and to genetically characterize geographic variation in the widespread species, A. albopictus.  The Aedes (Stegomyia) albopictus subgroup consists of 11 species of which A. albopictus is the most important.  It is a vector of dengue fever and dengue hemorrhagic fever in southeast Asia.  Its wide distribution extends from Madagascar to Hawaii.  In recent years it has extended its range to Guam, the south Pacific and has even been reported in light traps in Memphis, TN.  Surprisingly, little work has been done on the genetics of this or other related species in the subgroup.  The proposed research will help bridge this gap.  The long term objectives are to utilize the genetic characterization of A. albopictus populations as well as certain related species in the subgroup to evaluate their potential to serve as efficient vectors of dengue fever. The proposed genetic studies will provide the necessary foundation for future analyses on genetics of dengue transmission and competence of species and strains to transmit the disease.  The specific aims, to characterize genetic variation within A. albopictus and between species in the albopictus subgroup, will be accomplished through four different types of analyses.  Indirect measures of genetic divergence will be obtained through:  1) experimental hybridization with data collected on insemination, embryonation and egg hatch rates and on the viability of hybrid and backcross progeny, and 2) mate choice tests using species pairs in a series of replicates designed to produce indices of sexual isolation.  Direct measures of genetic divergence will be obtained from analyses of chromosome differentiation and electrophoretic detection of enzyme variability.  Chromosome differentiation will be examined through a series of studies including Giemsa C-banding to localize heterochromatin, meiotic analysis of hybrids and electrophoretically derived linkage map comparisons to determine the presence of inversions, translocations and deletions or duplications, and cytophotometric analysis of nuclear DNA content.  UPGMA clustering and principal component analysis of allele frequency data obtained from allozyme studies will be used to differentiate populations into subsets.  If certain diagnostic alleles, loci or discrete allelic frequency differences or chromosomal variants exist among geographic strains of A. albopictus from dengue epidemic versus non-epidemic areas, vector competence may become effectively marked.  n/a",GENETIC DIFFERENTIATION IN THE AEDES ALBOPICTUS SUBGROUP,3131574,R01AI021443,"['Asia', ' DNA', ' alleles', ' animal population genetics', ' biological polymorphism', ' centromere', ' chromatin', ' chromosome aberrations', ' chromosome inversion', ' chromosome translocation', ' chromosomes', ' communicable disease transmission', ' dengue', ' disease vectors', ' enzymes', ' gel electrophoresis', ' gene frequency', ' genetic crossing over', ' genetic mapping', ' genetic strain', ' genome', ' geographic site', ' hybrid cells', ' karyotype', ' meiosis', ' species difference']",NIAID,UNIVERSITY OF NOTRE DAME,R01,1986,74360,-0.015125559882599249
"GENETIC DIFFERENTIATION IN THE AEDES ALBOPICTUS SUBGROUP The specific aims of the proposed research are to analyze genetic differentiation between 6 species in the Aedes albopictus subgroup and to genetically characterize geographic variation in the widespread species, A. albopictus.  The Aedes (Stegomyia) albopictus subgroup consists of 11 species of which A. albopictus is the most important.  It is a vector of dengue fever and dengue hemorrhagic fever in southeast Asia.  Its wide distribution extends from Madagascar to Hawaii.  In recent years it has extended its range to Guam, the south Pacific and has even been reported in light traps in Memphis, TN.  Surprisingly, little work has been done on the genetics of this or other related species in the subgroup.  The proposed research will help bridge this gap.  The long term objectives are to utilize the genetic characterization of A. albopictus populations as well as certain related species in the subgroup to evaluate their potential to serve as efficient vectors of dengue fever. The proposed genetic studies will provide the necessary foundation for future analyses on genetics of dengue transmission and competence of species and strains to transmit the disease.  The specific aims, to characterize genetic variation within A. albopictus and between species in the albopictus subgroup, will be accomplished through four different types of analyses.  Indirect measures of genetic divergence will be obtained through:  1) experimental hybridization with data collected on insemination, embryonation and egg hatch rates and on the viability of hybrid and backcross progeny, and 2) mate choice tests using species pairs in a series of replicates designed to produce indices of sexual isolation.  Direct measures of genetic divergence will be obtained from analyses of chromosome differentiation and electrophoretic detection of enzyme variability.  Chromosome differentiation will be examined through a series of studies including Giemsa C-banding to localize heterochromatin, meiotic analysis of hybrids and electrophoretically derived linkage map comparisons to determine the presence of inversions, translocations and deletions or duplications, and cytophotometric analysis of nuclear DNA content.  UPGMA clustering and principal component analysis of allele frequency data obtained from allozyme studies will be used to differentiate populations into subsets.  If certain diagnostic alleles, loci or discrete allelic frequency differences or chromosomal variants exist among geographic strains of A. albopictus from dengue epidemic versus non-epidemic areas, vector competence may become effectively marked.  n/a",GENETIC DIFFERENTIATION IN THE AEDES ALBOPICTUS SUBGROUP,3131573,R01AI021443,"['Asia', ' DNA', ' alleles', ' animal population genetics', ' biological polymorphism', ' centromere', ' chromatin', ' chromosome aberrations', ' chromosome inversion', ' chromosome translocation', ' chromosomes', ' communicable disease transmission', ' dengue', ' disease vectors', ' enzymes', ' gel electrophoresis', ' gene frequency', ' genetic crossing over', ' genetic mapping', ' genetic strain', ' genome', ' geographic site', ' hybrid cells', ' karyotype', ' meiosis', ' species difference']",NIAID,UNIVERSITY OF NOTRE DAME,R01,1985,87795,-0.015125559882599249
"Understanding Genetic Basis of Dental Caries via Integrative Genomic Approaches    DESCRIPTION (provided by applicant): Despite different strategies for improving behavioral factors, dental caries (tooth decay) remains to be one of the most prevalent oral diseases and a challenging public health problem far from being controlled. In addition to environmental factors, recent studies have provided convincing evidence that genetics also plays an important role in the etiology of dental caries. However, to date, genetic studies on caries are still in an early stage compared to numerous efforts that have been made in other complex diseases or traits. In this proposal, to complement the traditional single marker/gene, we will develop innovative strategies to identify groups of functional related genes with enriched associations with dental caries in genome-wide association studies (GWAS) dataset. Our Specific Aims are as follows. (1) To develop a novel statistical method based on mixed effects models to identify genes and gene sets that have enriched association signals in GWAS. We will model all the genes and SNPs within a pathway in a hierarchical fashion using random gene effects, which will provide the ability to borrow information across genes in the same pathway. (2) To develop a novel dense module searching algorithm for identifying genes and gene modules (subnetworks) with enriched association signals on the human protein-protein interaction (PPI) networks. In addition to increased power, the identified subnetworks will also enable us to detect weakly associated genes playing central roles in the protein network by interconnecting many disease genes. (3) To perform an integrative analysis for ranking caries genes identified by Aims 1 and 2 and genes implicated by other genetic and genomic studies and to make all the data publicly available via a user-friendly web interface. We will apply the methods developed in Aims 1 and 2 to the GENEVA dental caries GWAS dataset (dbGap accession no: phs000095.v1.p1). We will then collect, organize and curate the genes identified, along with those from previous studies based on linkage scans, gene expression, and literature searches, and then develop multi-dimensional evidence-based approaches to prioritize these genes for future validation and follow up bioinformatics analysis. The successful completion of this project will provide us with important tools for integrative genomic analysis of current and future GWAS in caries (as well as other complex diseases), a user-friendly online system for caries research, and a list of prioritized candidate genes for future validation.        Dental caries (tooth decay) remains to be one of the most prevalent oral diseases and a challenging public health problem far from being controlled. In this proposal, to complement the traditional single marker/gene, we combine statistics, bioinformatics, and genetics to develop integrative genomics approaches to identify groups of functionally related genes with enriched association signals in the GENEVA dental caries genome-wide association studies (GWAS) dataset. Successful completion of this project will significantly enhance our understanding of the genetic architecture underlying caries as well as other dental diseases and will lead to more effective prevention and treatment strategies.            ",Understanding Genetic Basis of Dental Caries via Integrative Genomic Approaches,8320126,R03DE022093,"['Algorithms', 'Architecture', 'Behavioral', 'Bioinformatics', 'Candidate Disease Gene', 'Complement', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dental caries', 'Disease', 'Disease Association', 'Environmental Risk Factor', 'Etiology', 'Family', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genomics', 'Human', 'Individual', 'Label', 'Lead', 'Literature', 'Methods', 'Modeling', 'Mouth Diseases', 'Online Systems', 'Oral health', 'Other Genetics', 'Overlapping Genes', 'Pathway interactions', 'Pattern', 'Play', 'Prevention strategy', 'Property', 'Proteins', 'Public Health', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Staging', 'Statistical Methods', 'Testing', 'Tooth Diseases', 'Validation', 'base', 'database of Genotypes and Phenotypes', 'design', 'evidence base', 'experience', 'flexibility', 'follow-up', 'functional group', 'genome wide association study', 'genome-wide', 'improved', 'innovation', 'novel', 'protein protein interaction', 'statistics', 'success', 'text searching', 'tool', 'trait', 'treatment strategy', 'user-friendly', 'web interface']",NIDCR,VANDERBILT UNIVERSITY,R03,2012,231983,-0.013916723503021962
"TWO DIMENSIONAL PHOTON COUNTING POSTITION ENCODER A two-dimensional Photon Counting Position Encoder is proposed for Positron Emission Tomography (PET) medical cameras.  The new detector uses three new concepts:  1) a method of controlling the spatial distribution of photons from Bismuth Germanate Scintillators, 2) the use of all digital photon counting for processing the photomultiplier signal, and 3) the use of pattern recognition to encode position.  The new detector is expected to reduce the cost of this portion of the PET scanner by approximately a factor of eight.  The cost reduction anticipated for a typical four ring camera will be in the range of $600,000 to $1,000,000 which is 20-40 percent of the cost of the PET scanner.  In addition to the potential cost savings of this new approach, the photon division technique will allow one to obtain 2-3 mm position resolution in two dimensions.  The state-of-the art commercial scanners.  n/a",TWO DIMENSIONAL PHOTON COUNTING POSTITION ENCODER,3503987,R43NS022306,"['artificial intelligence', ' clinical biomedical equipment', ' image enhancement', ' photomultiplier', ' scintillation counter']",NINDS,"CTI, INC.",R43,1985,50000,0.03931912411813778
"Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner Project Summary/Abstract This application is for a shared instrumentation grant from the Light Microscope Imaging Facility at Case Western Reserve University (CWRU) School of Medicine (SOM) to acquire a fully automated, high-capacity, high- resolution Hamamatsu Nanozoomer S60 slide scanner that can accommodate both brightfield and fluorescence imaging in single-slide and double-slide formats. We also request MicroDimensions 3D reconstruction and alignment software packages for manipulating and analyzing the whole slide images produced with the scanner. We need to replace a scanner that is not functioning properly. Our well-established shared core facility supports NIH-funded investigators by giving them access to state-of-the-art microscopy technologies that enhance collaborative, multidisciplinary research. Acquisition of this instrument will have a high impact on the biomedical research at CWRU and expand the scope of our NIH-funded projects. Several projects have been identified that will utilize the scanner and its associated analyses programs. These include: the genetic mechanisms underlying skin fibrosis and cranial bone development (Atit); the mechanisms behind the lifelong functions of transcription factors in axonal growth and architecture (Deneris); deep-learning for histologic image predictors of various diseases (Madabhushi); the development of diagnostic probes to discriminate between glioma subtypes for screening and survival therapies (Brady-Kalnay); the role of progesterone receptors in the control of parturition and the development of therapies to prevent preterm birth (Messiano); the mechanisms by which breast cancer stem cells overcome metastatic latency leading to disease recurrence and the biomarkers that could potentially identify those tumors likely to undergo this process (Schiemann); and the significance of cholesterol-related proteins in brain and retinal function (Pikuleva). Many additional projects of minor users and others at CWRU are anticipated. All of the proposed projects are in need of a high-capacity automated scanner acquiring whole slide images so that analyses can be applied to tissues that cover hundreds of fields of view, rather than the single regions of interest that can be acquired on a standard microscope. Narrative This proposal seeks to acquire a new, state-of-the-art high-speed, high content digital slide scanner for high resolution cellular and biomarker identfcation across large tissue areas. The dual mode (fluorescence and brightfield) allows flexibility in marker visualization while the software allows the automated alignment of whole slide images for multi-stain analysis and 3d reconstruction of serial section for in-depth analysis of specimens. This equipment is essential for our NIH disease-related studies providing a profound positive impact on a wide range of public health areas.",Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner,9489976,S10OD024981,"['Architecture', 'Biological Markers', 'Biomedical Research', 'Birth', 'Bone Development', 'Brain', 'Cephalic', 'Cholesterol', 'Computer software', 'Core Facility', 'Development', 'Diagnostic', 'Disease', 'Enhancement Technology', 'Funding', 'Genetic', 'Glioma', 'Grant', 'Interdisciplinary Study', 'Light Microscope', 'Microscope', 'Microscopy', 'Minor', 'Premature Birth', 'Process', 'Progesterone Receptors', 'Proteins', 'Recurrence', 'Research Personnel', 'Resolution', 'Retinal', 'Role', 'Slide', 'Tissues', 'United States National Institutes of Health', 'Universities', 'axon growth', 'cancer stem cell', 'deep learning', 'digital', 'equipment acquisition', 'fluorescence imaging', 'histological image', 'imaging facilities', 'instrumentation', 'interest', 'malignant breast neoplasm', 'medical schools', 'prevent', 'programs', 'reconstruction', 'screening', 'skin fibrosis', 'therapy development', 'transcription factor', 'tumor', 'whole slide imaging']",OD,CASE WESTERN RESERVE UNIVERSITY,S10,2018,303390,-0.08310409433246316
"STRUCTURAL DETERMINATION OF INTERPHASE CHROMOSOMES The newly developed instrumentation and software now allows three-dimensional reconstruction, in a generalized fashion, of subcellular structures, at both the light and high voltage electron microscopic levels.  Eighteen nuclei have been reconstructed and interpreted in a quantitative fashion.  Six nuclei have their cytogenetic loci aligned with the three-dimensional structures showing that many chromosome features are three-dimensionally determined.  It is proposed to determine, three-dimensionally, many adjacent polytene nuclei in defined developmental stages and tissues so that it will be possible to see in a quantitative fashion the structural relationships. Many computational approaches are proposed to process the images, to refine the structures, to position the bands, hence genes three-dimensionally, and to determine the fine structure of nuclei.  These studies will also utilize monoclonal antibodies to localize active gene loci and their close associations one with another and the nuclear envelope, and to relate structure to function.  Diploid nuclei will, in addition, be three-dimensionally reconstructed at highest possible light microscope resolution in intact Drosophila embryos. Questions related to differences in the 3D patterns of the interphase chromosomes as a function of development, and the cell cycle will be studied.  The laboratory will continue to reconstruct mitotic chromosomes and interband/bands from polytene chromosomes from Drosophila in a resolution-overlaping fashion made possible by the three-dimensional light microscopy and much higher resolution of the high voltage electron microscope utilizing systematic high tilt about 70 degrees for three-dimensional structure.  New computational approaches to image processing in three dimensions are being continued.  New image collection hardware for the light microscopy and high voltage electron microscopy are proposed.  n/a",STRUCTURAL DETERMINATION OF INTERPHASE CHROMOSOMES,3272768,R01GM025101,"['Drosophilidae', ' animal population genetics', ' artificial intelligence', ' cell differentiation', ' chromosome disorders', ' cytogenetics', ' electron microscopy', ' endonuclease', ' eukaryote', ' fluorescence microscopy', ' fluorescent dye /probe', ' freeze etching', ' gene expression', ' genetic manipulation', ' genetic mapping', ' genetic regulation', ' genetic transcription', ' image enhancement', ' immature animal', ' immunofluorescence technique', ' larva', ' monoclonal antibody', ' nonmammalian vertebrate embryology', ' nucleic acid sequence', ' radionuclide double label', ' salivary glands', ' scanning electron microscopy', ' tissue /cell culture']",NIGMS,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,R01,1988,98271,0.03482662339913171
"STRUCTURAL DETERMINATION OF INTERPHASE CHROMOSOMES The newly developed instrumentation and software now allows three-dimensional reconstruction, in a generalized fashion, of subcellular structures, at both the light and high voltage electron microscopic levels.  Eighteen nuclei have been reconstructed and interpreted in a quantitative fashion.  Six nuclei have their cytogenetic loci aligned with the three-dimensional structures showing that many chromosome features are three-dimensionally determined.  It is proposed to determine, three-dimensionally, many adjacent polytene nuclei in defined developmental stages and tissues so that it will be possible to see in a quantitative fashion the structural relationships. Many computational approaches are proposed to process the images, to refine the structures, to position the bands, hence genes three-dimensionally, and to determine the fine structure of nuclei.  These studies will also utilize monoclonal antibodies to localize active gene loci and their close associations one with another and the nuclear envelope, and to relate structure to function.  Diploid nuclei will, in addition, be three-dimensionally reconstructed at highest possible light microscope resolution in intact Drosophila embryos. Questions related to differences in the 3D patterns of the interphase chromosomes as a function of development, and the cell cycle will be studied.  The laboratory will continue to reconstruct mitotic chromosomes and interband/bands from polytene chromosomes from Drosophila in a resolution-overlaping fashion made possible by the three-dimensional light microscopy and much higher resolution of the high voltage electron microscope utilizing systematic high tilt about 70 degrees for three-dimensional structure.  New computational approaches to image processing in three dimensions are being continued.  New image collection hardware for the light microscopy and high voltage electron microscopy are proposed.  n/a",STRUCTURAL DETERMINATION OF INTERPHASE CHROMOSOMES,3272767,R01GM025101,"['animal population genetics', ' artificial intelligence', ' cell differentiation', ' chromosome disorders', ' cytogenetics', ' electron microscopy', ' endonuclease', ' eukaryote', ' fluorescence microscopy', ' fluorescent dye /probe', ' freeze etching', ' gene expression', ' genetic manipulation', ' genetic mapping', ' genetic regulation', ' genetic transcription', ' image enhancement', ' immature animal', ' immunofluorescence technique', ' larva', ' monoclonal antibody', ' nonmammalian vertebrate embryology', ' nucleic acid sequence', ' radionuclide double label', ' salivary glands', ' scanning electron microscopy', ' tissue /cell culture']",NIGMS,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,R01,1987,110774,0.03482662339913171
"STRUCTURAL DETERMINATION OF INTERPHASE CHROMOSOMES The newly developed instrumentation and software now allows three-dimensional reconstruction, in a generalized fashion, of subcellular structures, at both the light and high voltage electron microscopic levels.  Eighteen nuclei have been reconstructed and interpreted in a quantitative fashion.  Six nuclei have their cytogenetic loci aligned with the three-dimensional structures showing that many chromosome features are three-dimensionally determined.  It is proposed to determine, three-dimensionally, many adjacent polytene nuclei in defined developmental stages and tissues so that it will be possible to see in a quantitative fashion the structural relationships. Many computational approaches are proposed to process the images, to refine the structures, to position the bands, hence genes three-dimensionally, and to determine the fine structure of nuclei.  These studies will also utilize monoclonal antibodies to localize active gene loci and their close associations one with another and the nuclear envelope, and to relate structure to function.  Diploid nuclei will, in addition, be three-dimensionally reconstructed at highest possible light microscope resolution in intact Drosophila embryos. Questions related to differences in the 3D patterns of the interphase chromosomes as a function of development, and the cell cycle will be studied.  The laboratory will continue to reconstruct mitotic chromosomes and interband/bands from polytene chromosomes from Drosophila in a resolution-overlaping fashion made possible by the three-dimensional light microscopy and much higher resolution of the high voltage electron microscope utilizing systematic high tilt about 70 degrees for three-dimensional structure.  New computational approaches to image processing in three dimensions are being continued.  New image collection hardware for the light microscopy and high voltage electron microscopy are proposed.  n/a",STRUCTURAL DETERMINATION OF INTERPHASE CHROMOSOMES,3272766,R01GM025101,"['animal population genetics', ' artificial intelligence', ' cell differentiation', ' chromosome disorders', ' cytogenetics', ' electron microscopy', ' endonuclease', ' eukaryote', ' fluorescence microscopy', ' fluorescent dye /probe', ' freeze etching', ' gene expression', ' genetic manipulation', ' genetic mapping', ' genetic regulation', ' genetic transcription', ' image enhancement', ' immature animal', ' immunofluorescence technique', ' larva', ' monoclonal antibody', ' nonmammalian vertebrate embryology', ' nucleic acid sequence', ' radionuclide double label', ' salivary glands', ' scanning electron microscopy', ' tissue /cell culture']",NIGMS,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,R01,1986,103879,0.03482662339913171
"STRUCTURAL DETERMINATION OF INTERPHASE CHROMOSOMES The newly developed instrumentation and software now allows three-dimensional reconstruction, in a generalized fashion, of subcellular structures, at both the light and high voltage electron microscopic levels.  Eighteen nuclei have been reconstructed and interpreted in a quantitative fashion.  Six nuclei have their cytogenetic loci aligned with the three-dimensional structures showing that many chromosome features are three-dimensionally determined.  It is proposed to determine, three-dimensionally, many adjacent polytene nuclei in defined developmental stages and tissues so that it will be possible to see in a quantitative fashion the structural relationships. Many computational approaches are proposed to process the images, to refine the structures, to position the bands, hence genes three-dimensionally, and to determine the fine structure of nuclei.  These studies will also utilize monoclonal antibodies to localize active gene loci and their close associations one with another and the nuclear envelope, and to relate structure to function.  Diploid nuclei will, in addition, be three-dimensionally reconstructed at highest possible light microscope resolution in intact Drosophila embryos. Questions related to differences in the 3D patterns of the interphase chromosomes as a function of development, and the cell cycle will be studied.  The laboratory will continue to reconstruct mitotic chromosomes and interband/bands from polytene chromosomes from Drosophila in a resolution-overlaping fashion made possible by the three-dimensional light microscopy and much higher resolution of the high voltage electron microscope utilizing systematic high tilt about 70 degrees for three-dimensional structure.  New computational approaches to image processing in three dimensions are being continued.  New image collection hardware for the light microscopy and high voltage electron microscopy are proposed.  n/a",STRUCTURAL DETERMINATION OF INTERPHASE CHROMOSOMES,3272765,R01GM025101,"['animal population genetics', ' artificial intelligence', ' cell differentiation', ' chromosome disorders', ' cytogenetics', ' electron microscopy', ' endonuclease', ' eukaryote', ' fluorescence microscopy', ' fluorescent dye /probe', ' freeze etching', ' gene expression', ' genetic manipulation', ' genetic mapping', ' genetic regulation', ' genetic transcription', ' image enhancement', ' immature animal', ' immunofluorescence technique', ' larva', ' monoclonal antibody', ' nonmammalian vertebrate embryology', ' nucleic acid sequence', ' radionuclide double label', ' salivary glands', ' scanning electron microscopy', ' tissue /cell culture']",NIGMS,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,R01,1985,124739,0.03482662339913171
"Beyond Association: Predictive Modeling of Nicotine Dependance    DESCRIPTION (provided by applicant): Tobacco use, primarily cigarette smoking, is the greatest source of preventable mortality in the world and costs over $160 million in health-related economic losses in the U.S. alone. Nicotine dependence is the primary reason that smokers continue smoking and that most unassisted quit attempts fail within a single week. It is known that nicotine dependence has a genetic component, but that it is a complex trait, i.e., no single gene is responsible for nicotine dependence. Thus, researchers and funding agencies have devoted considerable effort and support to identifying the genetic underpinnings of the trait through whole genome scans, putting us in a unique position to identify global genetic predictors of nicotine dependence. This study proposes to realize the promise of the NIDA-funded Collaborative Genetic Study of Nicotine Dependence (COGEND) whole genome data through the accomplishment of two specific aims: (1) to identify the set of genetic variations underlying the complex trait of nicotine dependence using a cutting-edge computational method called Bayesian networks and (2) to validate the prognostic model in an entirely independent population. This proposal represents the very first step of a broader research program aimed at discovering the complex network of interactions underpinning nicotine dependence. The ultimate result of this program will provide a clinical tool, which will accurately assess the risk of dependency, allow for individualized preventive measures, elucidate the molecular processes of dependence and nominate novel targets for the pharmaceutical treatment of nicotine addiction. Nicotine dependence places an enormous burden on individuals and society. Genetic factors are responsible for at least some part of the condition, and the NIDA has already funded a study, called COGEND, that examined over 40,000 genetic variations in people who were nicotine dependent and who were not nicotine dependent. We propose to use cutting-edge techniques to analyze this large dataset to identify a valid predictive model of nicotine dependence that will help us predict, diagnose, and treat this condition.        n/a",Beyond Association: Predictive Modeling of Nicotine Dependance,7617627,R21DA025168,"['Artificial Intelligence', 'Clinical', 'Complex', 'Computing Methodologies', 'Data', 'Data Set', 'Dental Schools', 'Dependence', 'Dependency', 'Diagnosis', 'Economics', 'Enrollment', 'Funding', 'Funding Agency', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human', 'Individual', 'Measures', 'Medicine', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'Nicotine', 'Nicotine Dependence', 'Pharmacologic Substance', 'Physiological Processes', 'Population', 'Positioning Attribute', 'Preventive', 'Principal Investigator', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Site', 'Smoker', 'Smoking', 'Societies', 'Source', 'Techniques', 'Tobacco use', 'Translating', 'Validation', 'Variant', 'base', 'cigarette smoking', 'clinical practice', 'computer based statistical methods', 'cost', 'genetic variant', 'genome wide association study', 'genome-wide', 'innovation', 'mortality', 'novel', 'predictive modeling', 'prognostic', 'programs', 'smoking cessation', 'statistics', 'tool', 'trait']",NIDA,BRIGHAM AND WOMEN'S HOSPITAL,R21,2009,175000,-0.002699095086618396
"Beyond Association: Predictive Modeling of Nicotine Dependance    DESCRIPTION (provided by applicant): Tobacco use, primarily cigarette smoking, is the greatest source of preventable mortality in the world and costs over $160 million in health-related economic losses in the U.S. alone. Nicotine dependence is the primary reason that smokers continue smoking and that most unassisted quit attempts fail within a single week. It is known that nicotine dependence has a genetic component, but that it is a complex trait, i.e., no single gene is responsible for nicotine dependence. Thus, researchers and funding agencies have devoted considerable effort and support to identifying the genetic underpinnings of the trait through whole genome scans, putting us in a unique position to identify global genetic predictors of nicotine dependence. This study proposes to realize the promise of the NIDA-funded Collaborative Genetic Study of Nicotine Dependence (COGEND) whole genome data through the accomplishment of two specific aims: (1) to identify the set of genetic variations underlying the complex trait of nicotine dependence using a cutting-edge computational method called Bayesian networks and (2) to validate the prognostic model in an entirely independent population. This proposal represents the very first step of a broader research program aimed at discovering the complex network of interactions underpinning nicotine dependence. The ultimate result of this program will provide a clinical tool, which will accurately assess the risk of dependency, allow for individualized preventive measures, elucidate the molecular processes of dependence and nominate novel targets for the pharmaceutical treatment of nicotine addiction. Nicotine dependence places an enormous burden on individuals and society. Genetic factors are responsible for at least some part of the condition, and the NIDA has already funded a study, called COGEND, that examined over 40,000 genetic variations in people who were nicotine dependent and who were not nicotine dependent. We propose to use cutting-edge techniques to analyze this large dataset to identify a valid predictive model of nicotine dependence that will help us predict, diagnose, and treat this condition.        n/a",Beyond Association: Predictive Modeling of Nicotine Dependance,7509667,R21DA025168,"['Artificial Intelligence', 'Clinical', 'Complex', 'Computing Methodologies', 'Condition', 'Data', 'Data Set', 'Dental Schools', 'Dependence', 'Dependency', 'Diagnosis', 'Economics', 'Enrollment', 'Funding', 'Funding Agency', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human', 'Individual', 'Measures', 'Medicine', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'Nicotine', 'Nicotine Dependence', 'Pharmacologic Substance', 'Physiological Processes', 'Population', 'Positioning Attribute', 'Preventive', 'Principal Investigator', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Site', 'Smoker', 'Smoking', 'Societies', 'Source', 'Techniques', 'Tobacco use', 'Translating', 'Validation', 'Variant', 'Week', 'base', 'cigarette smoking', 'computer based statistical methods', 'cost', 'genetic variant', 'genome wide association study', 'innovation', 'mortality', 'novel', 'predictive modeling', 'prognostic', 'programs', 'smoking cessation', 'statistics', 'tool', 'trait']",NIDA,BRIGHAM AND WOMEN'S HOSPITAL,R21,2008,175000,-0.002699095086618396
"Simultaneous Multinuclear Magnetic Resonance Fingerprinting for Data Fusion of Quantitative Structural and Metabolic Imaging Project Summary In this project we want to develop a new non-invasive imaging technique that will provide multi-parametric  metabolic maps of the living brain at an unprecedented resolution. The key to this new technology is the novel combination of three state-of-the-art imaging concepts: (A) new hardware that enables the simultaneous  measurement of multinuclear magnetic resonance (MR) signals at different frequencies; (B) the flexibility and robustness of Plug-and-Play (PnP) MR Fingerprinting (MRF); and (C) a data fusion process driven by a cross-modality model based on statistical learning. For brevity, we will call this fused simultaneous multinuclear PnP-MRF technique MNF (Multi-Nuclear Fusion). The idea behind MNF is to rapidly capture two different kinds of quantitative  information throughout the whole brain in one single scan: (1) structural information from proton (1H) MRF such as T1, T2, and proton density (PD) (tissue-scale morphology); and (2) metabolic information related to ion  homeostasis from sodium (23Na) MRF, such as intracellular sodium concentration, and intracellular, extracellular and cerebrospinal fluid (CSF) volume fractions (cellular-scale function). Because PnP-MRF can quantify multiple  tissue properties free of experimental bias, it enables us to employ statistical learning to discover a subject-specific cross-modality model that integrates all voxelwise inter-relationships between the multi-parametric 1H PnP-MRF (acquired at high resolution, 0.75-1 mm) and 23Na PnP-MRF (acquired at low resolution, 3-5 mm) maps. These subject-specific relations can subsequently be used to sharpen the 23Na metabolic maps to match the resolution of the 1H structural maps. The high-resolution 23Na maps will enable the assessment of metabolic processes in vivo and bridge the gap in resolution that has held back our ability to study metabolism in the living human brain, which is crucial for our understanding of the brain itself and the afflictions that affect it. This proof-of-concept implementation will be developed at 7 T, but it is expected to be adaptable to clinical 3 T MR scanners. The specific aims are: (1) Data acquisition, (1.a) multi-channel 1H/23Na RF array, (1.b) simultaneous multinuclear 3D MRF sequence; (2) Data processing, (2.a) PnP-MRF reconstruction for both 1H data (fingerprint matching to generate structural maps) and 23Na data (tissue 4-compartment model and simulation of spin 3/2 dynamics to generate metabolic maps), (2.b) cross-modality model using statistical learning, and data fusion algorithm to generate high-resolution metabolic maps; (3) Method validation, (3.a) accuracy and precision, (3.b) repeatability and reproducibility.(3) Exploratory aim: Test MNF on patients with chronic steno-occlusive disease, with  recurrent transient ischemic attacks (TIA)/minor stroke, presenting regional brain ischemia, at 3 time points (baseline, 8-month and 16-month follow-ups), and comparison with healthy controls. Project Narrative We propose to develop a new non-invasive imaging technique that will provide multi-parametric metabolic 3D maps of the living brain at an unprecedented resolution, based on the fusion of simultaneously acquired proton and sodium data with plug-and-play magnetic resonance fingerprinting. The fusion algorithm between high- resolution proton structural maps and low-resolution sodium metabolic maps will be based on a cross-modality model optimized with statistical learning methods, and will generate for the first time high-resolution metabolic maps related to ion homeostasis in the brain in vivo. These new fused high-resolution structural and metabolic maps will provide new insights into neuro-architecture, neuro-biochemistry and their interconnection, which are crucial for our understanding of the human brain and its disorders.",Simultaneous Multinuclear Magnetic Resonance Fingerprinting for Data Fusion of Quantitative Structural and Metabolic Imaging,9731533,R01EB026456,"['3-Dimensional', 'Affect', 'Age', 'Algorithms', 'Anterior', 'Architecture', 'Back', 'Biochemistry', 'Blood Circulation', 'Brain', 'Brain Ischemia', 'Cerebrospinal Fluid', 'Chronic', 'Clinical', 'Computer software', 'Data', 'Development', 'Diffusion', 'Disease', 'Ensure', 'Exhibits', 'Extracellular Fluid', 'Fingerprint', 'Frequencies', 'Gender', 'Goals', 'Homeostasis', 'Human', 'Image', 'Imaging Techniques', 'Intracellular Fluid', 'Ions', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance', 'Maps', 'Measurable', 'Measurement', 'Metabolic', 'Metabolism', 'Methods', 'Minor', 'Modality', 'Modeling', 'Monitor', 'Morphology', 'Nature', 'Nerve Degeneration', 'Neurocognitive Deficit', 'Patients', 'Perfusion', 'Physiologic pulse', 'Play', 'Process', 'Property', 'Protocols documentation', 'Protons', 'Recurrence', 'Reproducibility', 'Resolution', 'Scanning', 'Signal Transduction', 'Sodium', 'Stroke', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'Training', 'Transient Ischemic Attack', 'Validation', 'base', 'clinical application', 'computerized data processing', 'data acquisition', 'density', 'design', 'extracellular', 'flexibility', 'hemodynamics', 'in vivo', 'insight', 'learning strategy', 'metabolic abnormality assessment', 'metabolic imaging', 'models and simulation', 'molecular imaging', 'new technology', 'non-invasive imaging', 'novel', 'prototype', 'radio frequency', 'reconstruction', 'simulation']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,622031,-0.014141934804085031
"Simultaneous Multinuclear Magnetic Resonance Fingerprinting for Data Fusion of Quantitative Structural and Metabolic Imaging Project Summary In this project we want to develop a new non-invasive imaging technique that will provide multi-parametric  metabolic maps of the living brain at an unprecedented resolution. The key to this new technology is the novel combination of three state-of-the-art imaging concepts: (A) new hardware that enables the simultaneous  measurement of multinuclear magnetic resonance (MR) signals at different frequencies; (B) the flexibility and robustness of Plug-and-Play (PnP) MR Fingerprinting (MRF); and (C) a data fusion process driven by a cross-modality model based on statistical learning. For brevity, we will call this fused simultaneous multinuclear PnP-MRF technique MNF (Multi-Nuclear Fusion). The idea behind MNF is to rapidly capture two different kinds of quantitative  information throughout the whole brain in one single scan: (1) structural information from proton (1H) MRF such as T1, T2, and proton density (PD) (tissue-scale morphology); and (2) metabolic information related to ion  homeostasis from sodium (23Na) MRF, such as intracellular sodium concentration, and intracellular, extracellular and cerebrospinal fluid (CSF) volume fractions (cellular-scale function). Because PnP-MRF can quantify multiple  tissue properties free of experimental bias, it enables us to employ statistical learning to discover a subject-specific cross-modality model that integrates all voxelwise inter-relationships between the multi-parametric 1H PnP-MRF (acquired at high resolution, 0.75-1 mm) and 23Na PnP-MRF (acquired at low resolution, 3-5 mm) maps. These subject-specific relations can subsequently be used to sharpen the 23Na metabolic maps to match the resolution of the 1H structural maps. The high-resolution 23Na maps will enable the assessment of metabolic processes in vivo and bridge the gap in resolution that has held back our ability to study metabolism in the living human brain, which is crucial for our understanding of the brain itself and the afflictions that affect it. This proof-of-concept implementation will be developed at 7 T, but it is expected to be adaptable to clinical 3 T MR scanners. The specific aims are: (1) Data acquisition, (1.a) multi-channel 1H/23Na RF array, (1.b) simultaneous multinuclear 3D MRF sequence; (2) Data processing, (2.a) PnP-MRF reconstruction for both 1H data (fingerprint matching to generate structural maps) and 23Na data (tissue 4-compartment model and simulation of spin 3/2 dynamics to generate metabolic maps), (2.b) cross-modality model using statistical learning, and data fusion algorithm to generate high-resolution metabolic maps; (3) Method validation, (3.a) accuracy and precision, (3.b) repeatability and reproducibility.(3) Exploratory aim: Test MNF on patients with chronic steno-occlusive disease, with  recurrent transient ischemic attacks (TIA)/minor stroke, presenting regional brain ischemia, at 3 time points (baseline, 8-month and 16-month follow-ups), and comparison with healthy controls. Project Narrative We propose to develop a new non-invasive imaging technique that will provide multi-parametric metabolic 3D maps of the living brain at an unprecedented resolution, based on the fusion of simultaneously acquired proton and sodium data with plug-and-play magnetic resonance fingerprinting. The fusion algorithm between high- resolution proton structural maps and low-resolution sodium metabolic maps will be based on a cross-modality model optimized with statistical learning methods, and will generate for the first time high-resolution metabolic maps related to ion homeostasis in the brain in vivo. These new fused high-resolution structural and metabolic maps will provide new insights into neuro-architecture, neuro-biochemistry and their interconnection, which are crucial for our understanding of the human brain and its disorders.",Simultaneous Multinuclear Magnetic Resonance Fingerprinting for Data Fusion of Quantitative Structural and Metabolic Imaging,9574362,R01EB026456,"['Affect', 'Age', 'Algorithms', 'Anterior', 'Architecture', 'Back', 'Biochemistry', 'Blood Circulation', 'Brain', 'Brain Ischemia', 'Cerebrospinal Fluid', 'Chronic', 'Clinical', 'Computer software', 'Data', 'Development', 'Diffusion', 'Disease', 'Ensure', 'Exhibits', 'Extracellular Fluid', 'Fingerprint', 'Frequencies', 'Gender', 'Goals', 'Homeostasis', 'Human', 'Image', 'Imaging Techniques', 'Intracellular Fluid', 'Ions', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance', 'Maps', 'Measurable', 'Measurement', 'Metabolic', 'Metabolism', 'Methods', 'Minor', 'Modality', 'Modeling', 'Monitor', 'Morphology', 'Nature', 'Nerve Degeneration', 'Neurocognitive Deficit', 'Patients', 'Perfusion', 'Physiologic pulse', 'Play', 'Process', 'Property', 'Protocols documentation', 'Protons', 'Recurrence', 'Reproducibility', 'Resolution', 'Scanning', 'Signal Transduction', 'Sodium', 'Stroke', 'Techniques', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'Training', 'Transient Ischemic Attack', 'Validation', 'base', 'clinical application', 'computerized data processing', 'data acquisition', 'density', 'design', 'extracellular', 'flexibility', 'hemodynamics', 'in vivo', 'insight', 'learning strategy', 'metabolic abnormality assessment', 'metabolic imaging', 'models and simulation', 'molecular imaging', 'new technology', 'non-invasive imaging', 'novel', 'prototype', 'radiofrequency', 'reconstruction', 'simulation']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2018,685473,-0.014141934804085031
"Individualized spatial topology in functional neuroimaging Project Summary. Neuroimaging is poised to take a substantial leap forward in understanding the neurophysiological underpinnings of human behavior, due to a combination of improved analytic techniques and the quality of imaging data. These advances are allowing researchers to develop population-level multivariate models of the functional brain representations underlying behavior, performance, clinical status and prognosis, and other outcomes. Population-based models can identify patterns of brain activity, or `signatures', that can predict behavior and decode mental states in new individuals, producing generalizable knowledge and highly reproducible maps. These signatures can capture behavior with large effect sizes, and can be used and tested across research groups. However, the potential of such signatures is limited by neuroanatomical constraints, in particular individual variation in functional brain anatomy. To circumvent this problem, current models are either applied only to individual participants, severely limiting generalizability, or force participants' data into anatomical reference spaces (atlases) that do not respect individual functional topology and boundaries. Here we seek to overcome this shortcoming by developing new topological models for inter-subject alignment, which register participants' functional brain maps to one another. This will increase effective spatial resolution, and more importantly allow us to explicitly analyze the spatial topology of functional maps make inferences on differences in activation location and shape across persons and psychological states. We will test and validate the methods using a purpose-designed experiment (n = 120) that includes two types of naturalistic narrative experiences (movies and audio stories) and tasks from three functional domains (pain, emotion, and cognition). The tasks are designed with several constraints in mind, including: (1) systematic coverage of cognitive, emotional, and sensory tasks matched in stimulus properties (e.g., stimulus duration); and (2) multiple levels of task demand within each task, to permit parametric modeling and prediction of demand levels. We will compare our new methods to existing methods based on out-of-sample effect sizes in predicting behavior and test-retest reliability. We will make the analytic methods, software, and dataset available to other researchers, along with a library of functional reference spaces for multiple psychological states. Project Narrative. We develop new methods for enhancing the development of models that can predict behavior, clinical status, and other outcomes using neuroimaging data. Successful development will help improve the translational impact of neuroimaging. It will also contribute to developing multidisciplinary neuroscience, by promoting the development of neural signatures for specific mental processes in humans with increased precision and specificity.",Individualized spatial topology in functional neuroimaging,9908089,R01EB026549,"['Affective', 'Anatomy', 'Atlases', 'Behavior', 'Brain', 'Charon', 'Clinical', 'Cognition', 'Cognitive', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Emotional', 'Emotions', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Human', 'Image', 'Individual', 'Individual Differences', 'Knowledge', 'Libraries', 'Location', 'Machine Learning', 'Maps', 'Mental Processes', 'Methods', 'Mind', 'Modeling', 'Neurosciences', 'Outcome', 'Pain', 'Participant', 'Pattern', 'Pattern Recognition', 'Performance', 'Persons', 'Population', 'Process', 'Property', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Sensory', 'Shapes', 'Specificity', 'Stimulus', 'Sum', 'System', 'Techniques', 'Testing', 'Training', 'Variant', 'Wages', 'Work', 'affective neuroscience', 'analytical method', 'base', 'behavior prediction', 'behavior test', 'cognitive neuroscience', 'design', 'experience', 'experimental study', 'flexibility', 'improved', 'individual variation', 'mental state', 'model development', 'movie', 'multidisciplinary', 'neurodevelopment', 'neuroimaging', 'neurophysiology', 'outcome forecast', 'population based', 'predictive modeling', 'psychologic', 'statistics', 'translational impact']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2020,667005,-0.004996025374390988
"Individualized spatial topology in functional neuroimaging Project Summary. Neuroimaging is poised to take a substantial leap forward in understanding the neurophysiological underpinnings of human behavior, due to a combination of improved analytic techniques and the quality of imaging data. These advances are allowing researchers to develop population-level multivariate models of the functional brain representations underlying behavior, performance, clinical status and prognosis, and other outcomes. Population-based models can identify patterns of brain activity, or `signatures', that can predict behavior and decode mental states in new individuals, producing generalizable knowledge and highly reproducible maps. These signatures can capture behavior with large effect sizes, and can be used and tested across research groups. However, the potential of such signatures is limited by neuroanatomical constraints, in particular individual variation in functional brain anatomy. To circumvent this problem, current models are either applied only to individual participants, severely limiting generalizability, or force participants' data into anatomical reference spaces (atlases) that do not respect individual functional topology and boundaries. Here we seek to overcome this shortcoming by developing new topological models for inter-subject alignment, which register participants' functional brain maps to one another. This will increase effective spatial resolution, and more importantly allow us to explicitly analyze the spatial topology of functional maps make inferences on differences in activation location and shape across persons and psychological states. We will test and validate the methods using a purpose-designed experiment (n = 120) that includes two types of naturalistic narrative experiences (movies and audio stories) and tasks from three functional domains (pain, emotion, and cognition). The tasks are designed with several constraints in mind, including: (1) systematic coverage of cognitive, emotional, and sensory tasks matched in stimulus properties (e.g., stimulus duration); and (2) multiple levels of task demand within each task, to permit parametric modeling and prediction of demand levels. We will compare our new methods to existing methods based on out-of-sample effect sizes in predicting behavior and test-retest reliability. We will make the analytic methods, software, and dataset available to other researchers, along with a library of functional reference spaces for multiple psychological states. Project Narrative. We develop new methods for enhancing the development of models that can predict behavior, clinical status, and other outcomes using neuroimaging data. Successful development will help improve the translational impact of neuroimaging. It will also contribute to developing multidisciplinary neuroscience, by promoting the development of neural signatures for specific mental processes in humans with increased precision and specificity.",Individualized spatial topology in functional neuroimaging,9747296,R01EB026549,"['Affective', 'Anatomy', 'Atlases', 'Behavior', 'Brain', 'Charon', 'Clinical', 'Cognition', 'Cognitive', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Emotional', 'Emotions', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Human', 'Image', 'Individual', 'Individual Differences', 'Knowledge', 'Libraries', 'Location', 'Machine Learning', 'Maps', 'Mental Processes', 'Methods', 'Mind', 'Modeling', 'Neurosciences', 'Outcome', 'Pain', 'Participant', 'Pattern', 'Pattern Recognition', 'Performance', 'Persons', 'Population', 'Process', 'Property', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Sensory', 'Shapes', 'Specificity', 'Stimulus', 'Sum', 'System', 'Techniques', 'Testing', 'Training', 'Variant', 'Wages', 'Work', 'affective neuroscience', 'analytical method', 'base', 'behavior prediction', 'behavior test', 'cognitive neuroscience', 'design', 'experience', 'experimental study', 'flexibility', 'improved', 'individual variation', 'mental state', 'model development', 'movie', 'multidisciplinary', 'neurodevelopment', 'neuroimaging', 'neurophysiology', 'outcome forecast', 'population based', 'predictive modeling', 'psychologic', 'statistics', 'translational impact']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2019,692050,-0.004996025374390988
"Individualized spatial topology in functional neuroimaging Project Summary. Neuroimaging is poised to take a substantial leap forward in understanding the neurophysiological underpinnings of human behavior, due to a combination of improved analytic techniques and the quality of imaging data. These advances are allowing researchers to develop population-level multivariate models of the functional brain representations underlying behavior, performance, clinical status and prognosis, and other outcomes. Population-based models can identify patterns of brain activity, or `signatures', that can predict behavior and decode mental states in new individuals, producing generalizable knowledge and highly reproducible maps. These signatures can capture behavior with large effect sizes, and can be used and tested across research groups. However, the potential of such signatures is limited by neuroanatomical constraints, in particular individual variation in functional brain anatomy. To circumvent this problem, current models are either applied only to individual participants, severely limiting generalizability, or force participants' data into anatomical reference spaces (atlases) that do not respect individual functional topology and boundaries. Here we seek to overcome this shortcoming by developing new topological models for inter-subject alignment, which register participants' functional brain maps to one another. This will increase effective spatial resolution, and more importantly allow us to explicitly analyze the spatial topology of functional maps make inferences on differences in activation location and shape across persons and psychological states. We will test and validate the methods using a purpose-designed experiment (n = 120) that includes two types of naturalistic narrative experiences (movies and audio stories) and tasks from three functional domains (pain, emotion, and cognition). The tasks are designed with several constraints in mind, including: (1) systematic coverage of cognitive, emotional, and sensory tasks matched in stimulus properties (e.g., stimulus duration); and (2) multiple levels of task demand within each task, to permit parametric modeling and prediction of demand levels. We will compare our new methods to existing methods based on out-of-sample effect sizes in predicting behavior and test-retest reliability. We will make the analytic methods, software, and dataset available to other researchers, along with a library of functional reference spaces for multiple psychological states. Project Narrative. We develop new methods for enhancing the development of models that can predict behavior, clinical status, and other outcomes using neuroimaging data. Successful development will help improve the translational impact of neuroimaging. It will also contribute to developing multidisciplinary neuroscience, by promoting the development of neural signatures for specific mental processes in humans with increased precision and specificity.",Individualized spatial topology in functional neuroimaging,9577381,R01EB026549,"['Affective', 'Anatomy', 'Atlases', 'Behavior', 'Brain', 'Charon', 'Clinical', 'Cognition', 'Cognitive', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Emotional', 'Emotions', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Human', 'Image', 'Individual', 'Individual Differences', 'Knowledge', 'Libraries', 'Location', 'Machine Learning', 'Maps', 'Mental Processes', 'Methods', 'Mind', 'Modeling', 'Neurosciences', 'Outcome', 'Pain', 'Participant', 'Pattern', 'Pattern Recognition', 'Performance', 'Persons', 'Population', 'Process', 'Property', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Sensory', 'Shapes', 'Specificity', 'Stimulus', 'Sum', 'System', 'Techniques', 'Testing', 'Training', 'Variant', 'Wages', 'Work', 'affective neuroscience', 'analytical method', 'base', 'behavior prediction', 'behavior test', 'cognitive neuroscience', 'design', 'experience', 'experimental study', 'flexibility', 'improved', 'individual variation', 'mental state', 'model development', 'movie', 'multidisciplinary', 'neurodevelopment', 'neuroimaging', 'neurophysiology', 'outcome forecast', 'population based', 'predictive modeling', 'psychologic', 'statistics', 'translational impact']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2018,710896,-0.004996025374390988
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of different types of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an extensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spatial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high-resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector and Meta Datasets",10148333,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Visualization', 'Work', 'base', 'cell type', 'data exploration', 'data standards', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2020,1000000,0.039469905238597655
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE Mapping effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing of different types of individual cells, understanding the func- tion and relationships between those cell types, and modeling their individual and collective function. In order to exploit human and machine intelligence, different visual interfaces will be implemented that use the CCF in support of data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, mathematical biology, and biomedical data standards to develop a highly accurate and extensible multidimen- sional spatial basemap of the human body and associated data overlays that can be interactively explored online as an atlas of tissue maps. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across the human body along multiple functional contexts (e.g., systems physiology, vascular, or endocrine systems), and connect and integrate further computational, analytical, visualization, and biometric resources as driven by the context or “position” on the map. The CCF and the interactive data visualizations will be multi-level and multi-scale sup- porting the exploration and communication of tissue and publication data--from single cell to whole body. In the first year, the proposed Mapping Component will run user needs analyses, compile an initial CCF using pre-existing classifications and ontologies; implement two interactive data visualizations; and evaluate the usa- bility and effectiveness of the CCF and associated visualizations in formal user studies. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",9988039,OT2OD026671,"['Address', 'Anatomy', 'Artificial Intelligence', 'Atlases', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Classification', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Ecosystem', 'Educational workshop', 'Effectiveness', 'Endocrine system', 'Future', 'Genetic', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Infrastructure', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Mathematical Biology', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Organ', 'Participant', 'Physiological', 'Physiology', 'Positioning Attribute', 'Production', 'Publications', 'Resolution', 'Resources', 'Running', 'Services', 'System', 'Tissues', 'Update', 'Vascular System', 'Visual', 'Visualization software', 'Work', 'base', 'cell type', 'computing resources', 'data integration', 'data mining', 'data visualization', 'design', 'hackathon', 'human imaging', 'interoperability', 'member', 'systematic review', 'usability', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2019,49496,0.030256630111743427
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE Mapping effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing of different types of individual cells, understanding the func- tion and relationships between those cell types, and modeling their individual and collective function. In order to exploit human and machine intelligence, different visual interfaces will be implemented that use the CCF in support of data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, mathematical biology, and biomedical data standards to develop a highly accurate and extensible multidimen- sional spatial basemap of the human body and associated data overlays that can be interactively explored online as an atlas of tissue maps. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across the human body along multiple functional contexts (e.g., systems physiology, vascular, or endocrine systems), and connect and integrate further computational, analytical, visualization, and biometric resources as driven by the context or “position” on the map. The CCF and the interactive data visualizations will be multi-level and multi-scale sup- porting the exploration and communication of tissue and publication data--from single cell to whole body. In the first year, the proposed Mapping Component will run user needs analyses, compile an initial CCF using pre-existing classifications and ontologies; implement two interactive data visualizations; and evaluate the usa- bility and effectiveness of the CCF and associated visualizations in formal user studies. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",9687220,OT2OD026671,"['Address', 'Anatomy', 'Artificial Intelligence', 'Atlases', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Classification', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Ecosystem', 'Educational workshop', 'Effectiveness', 'Endocrine system', 'Future', 'Genetic', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Mathematical Biology', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Organ', 'Participant', 'Physiological', 'Physiology', 'Positioning Attribute', 'Production', 'Publications', 'Research Infrastructure', 'Resolution', 'Resources', 'Running', 'Services', 'System', 'Tissues', 'Update', 'Vascular System', 'Visual', 'Visualization software', 'Work', 'base', 'cell type', 'computing resources', 'data integration', 'data mining', 'data visualization', 'design', 'hackathon', 'human imaging', 'interoperability', 'member', 'systematic review', 'usability', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2018,330000,0.030256630111743427
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of different types of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector and Meta Datasets",9919259,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Work', 'base', 'cell type', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2019,600000,0.04306611466390766
"Mental, measurement, and model complexity in neuroscience PROJECT SUMMARY Neuroscience is producing increasingly complex data sets, including measures and manipulations of sub- cellular, cellular, and multi-cellular mechanisms operating over multiple timescales and in the context of different behaviors and task conditions. These data sets pose several fundamental challenges. First, for a given data set, what are the relevant spatial, temporal, and computational scales in which the underlying information-processing dynamics are best understood? Second, what are the best ways to design and select models to account for these dynamics, given the inevitably limited, noisy, and uneven spatial and temporal sampling used to collect the data? Third, what can increasingly complex data sets, collected under increasingly complex conditions, tells us about how the brain itself processes complex information? The goal of this project is to develop and disseminate new, theoretically grounded methods to help researchers to overcome these challenges. Our primary hypothesis is that resolving, modeling, and interpreting relevant information- processing dynamics from complex data sets depends critically on approaches that are built upon understanding the notion of complexity itself. A key insight driving this proposal is that definitions of complexity that come from different fields, and often with different interpretations, in fact have a common mathematical foundation. This common foundation implies that different approaches, from direct analyses of empirical data to model fitting, can extract statistical features related to computational complexity that can be compared directly to each other and interpreted in the context of ideal-observer benchmarks. Starting with this idea, we will pursue three specific aims: 1) establish a common theoretical foundation for analyzing both data and model complexity; 2) develop practical, complexity-based tools for data analysis and model selection; and 3) establish the usefulness of complexity-based metrics for understanding how the brain processes complex information. Together, these Aims provide new theoretical and practical tools for understanding how the brain integrates information across large temporal and spatial scales, using formal, universal definitions of complexity to facilitate the analysis and interpretation of complex neural and behavioral data sets. PROJECT NARRATIVE The proposed work will establish new, theoretically grounded computational tools to help neuroscience researchers design and analyze studies of brain function. These tools, which will be made widely available to the neuroscience research community, will help support a broad range of studies of the brain, enhance scientific discovery, and promote rigor and reproducibility.","Mental, measurement, and model complexity in neuroscience",10002220,R01EB026945,"['Address', 'Algorithms', 'Automobile Driving', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Characteristics', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Decision Making', 'Dimensions', 'Foundations', 'Goals', 'Guidelines', 'Human', 'Individual', 'Information Theory', 'Length', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Pattern', 'Physics', 'Process', 'Psyche structure', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sampling', 'Series', 'Structure', 'System', 'Techniques', 'Time', 'Work', 'base', 'complex data ', 'computer science', 'computerized tools', 'data modeling', 'data streams', 'data tools', 'design', 'information processing', 'insight', 'nonhuman primate', 'relating to nervous system', 'statistics', 'theories', 'tool']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2020,20957,0.01629745947354627
"Mental, measurement, and model complexity in neuroscience PROJECT SUMMARY Neuroscience is producing increasingly complex data sets, including measures and manipulations of sub- cellular, cellular, and multi-cellular mechanisms operating over multiple timescales and in the context of different behaviors and task conditions. These data sets pose several fundamental challenges. First, for a given data set, what are the relevant spatial, temporal, and computational scales in which the underlying information-processing dynamics are best understood? Second, what are the best ways to design and select models to account for these dynamics, given the inevitably limited, noisy, and uneven spatial and temporal sampling used to collect the data? Third, what can increasingly complex data sets, collected under increasingly complex conditions, tells us about how the brain itself processes complex information? The goal of this project is to develop and disseminate new, theoretically grounded methods to help researchers to overcome these challenges. Our primary hypothesis is that resolving, modeling, and interpreting relevant information- processing dynamics from complex data sets depends critically on approaches that are built upon understanding the notion of complexity itself. A key insight driving this proposal is that definitions of complexity that come from different fields, and often with different interpretations, in fact have a common mathematical foundation. This common foundation implies that different approaches, from direct analyses of empirical data to model fitting, can extract statistical features related to computational complexity that can be compared directly to each other and interpreted in the context of ideal-observer benchmarks. Starting with this idea, we will pursue three specific aims: 1) establish a common theoretical foundation for analyzing both data and model complexity; 2) develop practical, complexity-based tools for data analysis and model selection; and 3) establish the usefulness of complexity-based metrics for understanding how the brain processes complex information. Together, these Aims provide new theoretical and practical tools for understanding how the brain integrates information across large temporal and spatial scales, using formal, universal definitions of complexity to facilitate the analysis and interpretation of complex neural and behavioral data sets. PROJECT NARRATIVE The proposed work will establish new, theoretically grounded computational tools to help neuroscience researchers design and analyze studies of brain function. These tools, which will be made widely available to the neuroscience research community, will help support a broad range of studies of the brain, enhance scientific discovery, and promote rigor and reproducibility.","Mental, measurement, and model complexity in neuroscience",9789280,R01EB026945,"['Address', 'Algorithms', 'Automobile Driving', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Characteristics', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Decision Making', 'Dimensions', 'Foundations', 'Goals', 'Guidelines', 'Human', 'Individual', 'Information Theory', 'Length', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Pattern', 'Physics', 'Process', 'Psyche structure', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sampling', 'Series', 'Stream', 'Structure', 'System', 'Techniques', 'Time', 'Work', 'base', 'computer science', 'computerized tools', 'data modeling', 'design', 'information processing', 'insight', 'nonhuman primate', 'relating to nervous system', 'statistics', 'theories', 'tool']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2019,21171,0.01629745947354627
"Mental, measurement, and model complexity in neuroscience PROJECT SUMMARY Neuroscience is producing increasingly complex data sets, including measures and manipulations of sub- cellular, cellular, and multi-cellular mechanisms operating over multiple timescales and in the context of different behaviors and task conditions. These data sets pose several fundamental challenges. First, for a given data set, what are the relevant spatial, temporal, and computational scales in which the underlying information-processing dynamics are best understood? Second, what are the best ways to design and select models to account for these dynamics, given the inevitably limited, noisy, and uneven spatial and temporal sampling used to collect the data? Third, what can increasingly complex data sets, collected under increasingly complex conditions, tells us about how the brain itself processes complex information? The goal of this project is to develop and disseminate new, theoretically grounded methods to help researchers to overcome these challenges. Our primary hypothesis is that resolving, modeling, and interpreting relevant information- processing dynamics from complex data sets depends critically on approaches that are built upon understanding the notion of complexity itself. A key insight driving this proposal is that definitions of complexity that come from different fields, and often with different interpretations, in fact have a common mathematical foundation. This common foundation implies that different approaches, from direct analyses of empirical data to model fitting, can extract statistical features related to computational complexity that can be compared directly to each other and interpreted in the context of ideal-observer benchmarks. Starting with this idea, we will pursue three specific aims: 1) establish a common theoretical foundation for analyzing both data and model complexity; 2) develop practical, complexity-based tools for data analysis and model selection; and 3) establish the usefulness of complexity-based metrics for understanding how the brain processes complex information. Together, these Aims provide new theoretical and practical tools for understanding how the brain integrates information across large temporal and spatial scales, using formal, universal definitions of complexity to facilitate the analysis and interpretation of complex neural and behavioral data sets. PROJECT NARRATIVE The proposed work will establish new, theoretically grounded computational tools to help neuroscience researchers design and analyze studies of brain function. These tools, which will be made widely available to the neuroscience research community, will help support a broad range of studies of the brain, enhance scientific discovery, and promote rigor and reproducibility.","Mental, measurement, and model complexity in neuroscience",9615324,R01EB026945,"['Address', 'Algorithms', 'Automobile Driving', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Characteristics', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Decision Making', 'Dimensions', 'Foundations', 'Goals', 'Guidelines', 'Human', 'Individual', 'Information Theory', 'Length', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Noise', 'Pattern', 'Physics', 'Process', 'Psyche structure', 'Reproducibility', 'Research Personnel', 'Rodent', 'Sampling', 'Series', 'Stream', 'System', 'Techniques', 'Time', 'Work', 'base', 'computer science', 'computerized tools', 'data modeling', 'design', 'information processing', 'insight', 'nonhuman primate', 'relating to nervous system', 'statistics', 'theories', 'tool']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2018,342000,0.01629745947354627
"A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging Abstract The overall goal of this research is to develop next generation positron emission tomography (PET) detector technology to support non-invasive, quantitative brain imaging at spatial and temporal resolutions currently not achievable with human neuro-PET systems. The developed PET detector technology will also be compatible with operation in an MRI system. The proposed research is targeted to the NIH Brain Research through Advancing Innovative Neurotechnologies (BRAIN) initiative. Human brain imaging with PET/MRI will be an essential tool in neuroscience studies to ""Develop innovative technologies to understand the human brain and treat its disorders; create and support integrated brain research networks."" The key advancement that we introduce is a PET detector with <100 psec time-of-flight (TOF) PET coincidence resolution, <2 mm continuous depth of interaction (DOI) positioning and intrinsic detector spatial resolution to support <1 mm PET image resolution throughout the system imaging field of view (FOV). Detector modules have been designed that individually achieve these performance metrics; however, no detector module has been designed that supports all of them. To make disruptive advancements in neuro-imaging using PET, one must push the image spatial resolution (i.e., currently 2-3 mm image resolution) as well as coincidence timing resolution and also be MRI compatible. The impact of this project is that we will advance the state of the art in all of these critical performance areas. We will achieve these goals by first understanding the role that different PET detector performance parameters have on task-based figures of merit for neuroPET imaging. We will investigate how both TOF and image resolution impact figure of merit performance for estimation, detection and characterization imaging tasks. Monte Carlo simulation will be used along with both object-based (i.e., mathematical) and anthropomorphic digital phantoms. Next we will optimize SiPM device selection, electronics and detector geometry for <100 psec TOF coincidence timing, 1 mm intrinsic spatial resolution and <2 mm DOI positioning resolution. We will build and characterize a prototype PET detector module utilizing a novel dual- sided slat crystal detector design. To advance coincidence timing performance we will investigate the use of machine learning to estimate the arrival time of detected events. Finally, we will optimize the detector design for MRI compatibility. We will fully test and characterize performance of our prototype detector on the benchtop and in a MRI scanner while running clinical MRI pulse sequences. At the end of this developmental project we will be in position to build a state of the art, MRI compatible, TOF, DOI PET imaging system. Narrative The overall goal of this work is to develop detector imaging technology that will enable new research into the development, function and aging of the human brain. This technology will allow functional imaging of the brain at higher spatial resolution and higher coincidence timing resolution than previously achieved and also facilitate simultaneous multi-modality imaging (i.e., PET/MRI) at these new levels of performance.","A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging",9791188,R01EB026964,"['Aging', 'Algorithms', 'Area', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical', 'Crystallization', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electronics', 'Elements', 'Evaluation', 'Event', 'Functional Imaging', 'Geometry', 'Goals', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Individual', 'Investigation', 'Laboratory Research', 'Lead', 'Length', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monte Carlo Method', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Outcome', 'Performance', 'Physiologic pulse', 'Positioning Attribute', 'Positron-Emission Tomography', 'Property', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Side', 'Silicon', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Washington', 'Work', 'base', 'brain research', 'design', 'detector', 'digital', 'imaging detector', 'imaging system', 'improved', 'innovative neurotechnologies', 'innovative technologies', 'learning strategy', 'neuroimaging', 'next generation', 'novel', 'operation', 'prototype', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2019,22992,-0.012809022001838765
"A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging Abstract The overall goal of this research is to develop next generation positron emission tomography (PET) detector technology to support non-invasive, quantitative brain imaging at spatial and temporal resolutions currently not achievable with human neuro-PET systems. The developed PET detector technology will also be compatible with operation in an MRI system. The proposed research is targeted to the NIH Brain Research through Advancing Innovative Neurotechnologies (BRAIN) initiative. Human brain imaging with PET/MRI will be an essential tool in neuroscience studies to ""Develop innovative technologies to understand the human brain and treat its disorders; create and support integrated brain research networks."" The key advancement that we introduce is a PET detector with <100 psec time-of-flight (TOF) PET coincidence resolution, <2 mm continuous depth of interaction (DOI) positioning and intrinsic detector spatial resolution to support <1 mm PET image resolution throughout the system imaging field of view (FOV). Detector modules have been designed that individually achieve these performance metrics; however, no detector module has been designed that supports all of them. To make disruptive advancements in neuro-imaging using PET, one must push the image spatial resolution (i.e., currently 2-3 mm image resolution) as well as coincidence timing resolution and also be MRI compatible. The impact of this project is that we will advance the state of the art in all of these critical performance areas. We will achieve these goals by first understanding the role that different PET detector performance parameters have on task-based figures of merit for neuroPET imaging. We will investigate how both TOF and image resolution impact figure of merit performance for estimation, detection and characterization imaging tasks. Monte Carlo simulation will be used along with both object-based (i.e., mathematical) and anthropomorphic digital phantoms. Next we will optimize SiPM device selection, electronics and detector geometry for <100 psec TOF coincidence timing, 1 mm intrinsic spatial resolution and <2 mm DOI positioning resolution. We will build and characterize a prototype PET detector module utilizing a novel dual- sided slat crystal detector design. To advance coincidence timing performance we will investigate the use of machine learning to estimate the arrival time of detected events. Finally, we will optimize the detector design for MRI compatibility. We will fully test and characterize performance of our prototype detector on the benchtop and in a MRI scanner while running clinical MRI pulse sequences. At the end of this developmental project we will be in position to build a state of the art, MRI compatible, TOF, DOI PET imaging system. Narrative The overall goal of this work is to develop detector imaging technology that will enable new research into the development, function and aging of the human brain. This technology will allow functional imaging of the brain at higher spatial resolution and higher coincidence timing resolution than previously achieved and also facilitate simultaneous multi-modality imaging (i.e., PET/MRI) at these new levels of performance.","A TOF, DOI, MRI compatible PET detector to support sub-millimeter neuroPET imaging",9616697,R01EB026964,"['Aging', 'Algorithms', 'Area', 'Benchmarking', 'Brain', 'Brain imaging', 'Clinical', 'Crystallization', 'Data', 'Detection', 'Development', 'Devices', 'Dimensions', 'Disease', 'Electronics', 'Elements', 'Evaluation', 'Event', 'Functional Imaging', 'Geometry', 'Goals', 'Guidelines', 'Human', 'Image', 'Imaging technology', 'Individual', 'Investigation', 'Laboratory Research', 'Lead', 'Length', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monte Carlo Method', 'Multimodal Imaging', 'Neurosciences', 'Optics', 'Outcome', 'Performance', 'Physiologic pulse', 'Positioning Attribute', 'Positron-Emission Tomography', 'Property', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Running', 'Side', 'Silicon', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Washington', 'Work', 'base', 'brain research', 'design', 'detector', 'digital', 'imaging detector', 'imaging system', 'improved', 'innovative neurotechnologies', 'innovative technologies', 'learning strategy', 'neuroimaging', 'next generation', 'novel', 'operation', 'prototype', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2018,29442,-0.012809022001838765
"Development of Multi-Compartment MR-Fingerprinting for Subvoxel Estimation of Quantitative Tissue Biomarkers Project Summary Magnetic resonance fingerprinting (MRF) has been proposed as a technique to quantify tissue parameters, such as T1 and T2 relaxation times, which are biomarkers for various pathologies. One assumption of MRF is that the signal in each voxel is generated by exactly one set of tissue parameters. Due to MRI resolution at the range of millimeter in combination with the cellular structure of biological tissue, each voxel consists of multiple tissue compartments. An over-simplified single compartment model results in apparent relaxation times that are influenced by the relaxation times and the fractional proton densities of all contributing compartments. This can lead to a misinterpretation of signal changes. For example, in diseases that causes demyelination in white matter (Multiple Sclerosis, Dementia), a reduction of the myelin water fraction would result in a misleading change of the apparent relaxation time of the voxel. We propose a multi-compartment MRF method that allows to identify multiple tissue contributions within a voxel, including the fractional proton density (PD) of different compartments. Our machine learning based approach automatically identifies the number of compartments within each voxel that can be identified with the available SNR in that voxel. We will correct for partial-volume effects at the borders of two types of tissues, as well as analyze tissue microstructure. For the second case our learned model will also include chemical exchange between compartments. After an initial validation phase using numerical simulations, we will first perform MRF scans of dedicated 3D printed phantoms with multiple compartments. Our quality criterion is successful estimation of all simulated tissue compartments for all voxels with a relative error of less than 5% to the ground truth. We will then perform in-vivo MRF measurements of healthy volunteers (n=5). We will generate synthetic FLAIR and MP-RAGE contrasts from parameter maps estimated with conventional and the proposed multi-compartment MRF technique. We will compare them with currently used clinical contrasts acquired using established pulse sequences and validate the performance of our approach by measuring the cortical thickness. Further, we will validate the performance for microstructure composition in white matter. Our hypothesis is that it will be possible separate the compartments for myelin, intra- and extra-cellular water and compare the results to ex-vivo data found in literature. In summary, the methods developed in this R21 proposal will provide a novel technique to accurately and reproducibly identify biomarkers beyond the resolution of a voxel. It will allow to identify changes in tissue composition and fractional proton density at the microstructure level. Project Narrative The overarching goal of this proposal is to establish a MR imaging technique for quantifying biomarkers at the sub-voxel level. We will develop a machine learning based MR fingerprinting image reconstruction that enables the identification and characterization of multiple compartments within a voxel in terms of fractional proton density and relaxation times. We will generate accurate synthetic fluid suppressed images such as the FLAIR and MP- RAGE with accurate partial volume behavior and analyze the myelin water fraction and the corresponding relaxation times in white matter.",Development of Multi-Compartment MR-Fingerprinting for Subvoxel Estimation of Quantitative Tissue Biomarkers,10016296,R21EB027241,"['3D Print', 'Address', 'Behavior', 'Biological', 'Biological Markers', 'Cellular Structures', 'Cerebrospinal Fluid', 'Chemicals', 'Clinical', 'Complex', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Dementia', 'Demyelinations', 'Development', 'Diagnosis', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Fingerprint', 'Goals', 'Image', 'Imaging Techniques', 'Lead', 'Learning', 'Liquid substance', 'Literature', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Studies', 'Multiple Sclerosis', 'Myelin', 'Neurodegenerative Disorders', 'Noise', 'Pathology', 'Performance', 'Phase', 'Physics', 'Physiologic pulse', 'Procedures', 'Protons', 'Relaxation', 'Reproducibility', 'Resolution', 'Scanning', 'Signal Transduction', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Validation', 'Variant', 'Water', 'base', 'clinical translation', 'conditioning', 'deep neural network', 'density', 'gray matter', 'healthy volunteer', 'image reconstruction', 'imaging system', 'improved', 'in vivo', 'magnetic resonance imaging biomarker', 'millimeter', 'neuroimaging', 'noninvasive diagnosis', 'novel', 'physical process', 'reconstruction', 'simulation', 'soft tissue', 'tissue biomarkers', 'white matter']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R21,2020,252175,-0.007659331718961594
"Development of Multi-Compartment MR-Fingerprinting for Subvoxel Estimation of Quantitative Tissue Biomarkers Project Summary Magnetic resonance fingerprinting (MRF) has been proposed as a technique to quantify tissue parameters, such as T1 and T2 relaxation times, which are biomarkers for various pathologies. One assumption of MRF is that the signal in each voxel is generated by exactly one set of tissue parameters. Due to MRI resolution at the range of millimeter in combination with the cellular structure of biological tissue, each voxel consists of multiple tissue compartments. An over-simplified single compartment model results in apparent relaxation times that are influenced by the relaxation times and the fractional proton densities of all contributing compartments. This can lead to a misinterpretation of signal changes. For example, in diseases that causes demyelination in white matter (Multiple Sclerosis, Dementia), a reduction of the myelin water fraction would result in a misleading change of the apparent relaxation time of the voxel. We propose a multi-compartment MRF method that allows to identify multiple tissue contributions within a voxel, including the fractional proton density (PD) of different compartments. Our machine learning based approach automatically identifies the number of compartments within each voxel that can be identified with the available SNR in that voxel. We will correct for partial-volume effects at the borders of two types of tissues, as well as analyze tissue microstructure. For the second case our learned model will also include chemical exchange between compartments. After an initial validation phase using numerical simulations, we will first perform MRF scans of dedicated 3D printed phantoms with multiple compartments. Our quality criterion is successful estimation of all simulated tissue compartments for all voxels with a relative error of less than 5% to the ground truth. We will then perform in-vivo MRF measurements of healthy volunteers (n=5). We will generate synthetic FLAIR and MP-RAGE contrasts from parameter maps estimated with conventional and the proposed multi-compartment MRF technique. We will compare them with currently used clinical contrasts acquired using established pulse sequences and validate the performance of our approach by measuring the cortical thickness. Further, we will validate the performance for microstructure composition in white matter. Our hypothesis is that it will be possible separate the compartments for myelin, intra- and extra-cellular water and compare the results to ex-vivo data found in literature. In summary, the methods developed in this R21 proposal will provide a novel technique to accurately and reproducibly identify biomarkers beyond the resolution of a voxel. It will allow to identify changes in tissue composition and fractional proton density at the microstructure level. Project Narrative The overarching goal of this proposal is to establish a MR imaging technique for quantifying biomarkers at the sub-voxel level. We will develop a machine learning based MR fingerprinting image reconstruction that enables the identification and characterization of multiple compartments within a voxel in terms of fractional proton density and relaxation times. We will generate accurate synthetic fluid suppressed images such as the FLAIR and MP- RAGE with accurate partial volume behavior and analyze the myelin water fraction and the corresponding relaxation times in white matter.",Development of Multi-Compartment MR-Fingerprinting for Subvoxel Estimation of Quantitative Tissue Biomarkers,9825278,R21EB027241,"['3D Print', 'Address', 'Behavior', 'Biological', 'Biological Markers', 'Cellular Structures', 'Cerebrospinal Fluid', 'Chemicals', 'Clinical', 'Complex', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Dementia', 'Demyelinations', 'Development', 'Diagnosis', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Fingerprint', 'Goals', 'Image', 'Imaging Techniques', 'Lead', 'Learning', 'Liquid substance', 'Literature', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Studies', 'Multiple Sclerosis', 'Myelin', 'Neurodegenerative Disorders', 'Noise', 'Pathology', 'Performance', 'Phase', 'Physics', 'Physiologic pulse', 'Procedures', 'Protons', 'Relaxation', 'Reproducibility', 'Resolution', 'Scanning', 'Signal Transduction', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Validation', 'Variant', 'Water', 'base', 'clinical translation', 'conditioning', 'deep neural network', 'density', 'gray matter', 'healthy volunteer', 'image reconstruction', 'imaging system', 'improved', 'in vivo', 'magnetic resonance imaging biomarker', 'millimeter', 'neuroimaging', 'noninvasive diagnosis', 'novel', 'physical process', 'reconstruction', 'simulation', 'soft tissue', 'tissue biomarkers', 'white matter']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R21,2019,209851,-0.007659331718961594
"Deep learning techniques for time-of-flight PET detectors Project Summary/Abstract One of the key advances in modern positron emission tomography (PET) systems for clinical imaging is the use of time-of-flight (TOF) information. In cancer imaging TOF provides superior lesion detection and more accurate quantification that is crucial in measuring response to therapy, as well as in neurological and cardiovascular imaging applications. An additional benefit of TOF is the ability to lower the radiation dose or scan time without sacrificing image quality, important for patient safety and comfort. The magnitude of these clinical benefits is determined by the TOF resolution of the PET detectors, therefore the prospect of achieving unprecedented image quality and clinical imaging capabilities with superior TOF resolution has fueled significant research in developing detector technology for TOF-PET systems. However, these developments have been largely unaccompanied by advances in signal processing methods needed to extract TOF information from the detector’s electrical signals, with most detectors making use of crude analog algorithms that discard most of the useful timing information contained in the signals. Now, with the availability of low-cost fast waveform digitizers, there is an exciting opportunity to implement sophisticated digital signal processing algorithms to achieve superior TOF resolution. The main advantage of developing advanced signal processing algorithms is that it presents a cost-effective route to improved TOF resolution that is complementary to instrumentation innovations. In essence, the TOF gain comes for free; the detector signals already contain the information needed for better TOF resolution, it just needs to be used effectively. Here we propose to tailor deep learning techniques to estimate TOF from the detector signals. Deep learning with convolutional neural networks (CNNs) is a powerful approach to learn complex representations of input data that can be used for tasks such as classification and regression. CNNs are therefore very suitable for directly estimating TOF from the detector waveforms, since these waveforms are influenced by several complex and intertwined processes which are hard to accurately model. Furthermore, large amounts of ground truth training data are readily generated. We recently demonstrated the feasibility of CNN-based TOF estimation, and found up to 23% improvement in TOF resolution compared to standard signal processing methods. This proposal aims to optimize these methods to push the limits of achievable TOF resolution and develop methods for their practical implementation. First, we will develop CNN architectures and methods suitable for silicon photomultipliers (SiPMs) that are now used in modern TOF-PET systems. We will also optimize the digitizing parameters to make optimal use of CNNs for TOF estimation. Second, we will implement CNN-TOF methods in a modern commercial PET detector, including using a global CNN to simultaneously estimate TOF and the crystal-of-interaction from the detector waveforms, demonstrating the practical feasibility of using this promising deep learning method in next generation PET systems. Narrative The use of time-of-flight information in positron emission tomography (PET) is a powerful way to increase clinical imaging capabilities of PET, and is now used in most modern systems. Improving time-of-flight performance promises to provide substantial benefits for lesion detection in cancer imaging, kinetic modeling with dynamic imaging, and the use of lower radiation dose for patient safety. Here we introduce deep learning signal processing methods to significantly improve the performance of time-of-flight PET detectors without requiring new materials, which thereby represents a cost effective route towards maximizing the use of the rich imaging signal provided by time-of-flight.",Deep learning techniques for time-of-flight PET detectors,9651713,R03EB027268,"['Address', 'Adoption', 'Algorithms', 'Biological Neural Networks', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Coupled', 'Crystallization', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Dose', 'Electronics', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Human Engineering', 'Image', 'Industry', 'Industry Collaboration', 'Investigation', 'Kinetics', 'Knowledge', 'Learning', 'Lesion', 'Low Dose Radiation', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neurologic', 'Noise', 'Outcome', 'Patient Care', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Property', 'Radiation', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Signal Transduction', 'Silicon', 'Solid', 'Speed', 'Sum', 'System', 'Techniques', 'Technology', 'Temperature', 'Time', 'Training', 'Tube', 'analog', 'base', 'cancer imaging', 'cardiovascular imaging', 'clinical imaging', 'cost', 'cost effective', 'deep learning', 'detector', 'digital', 'imaging capabilities', 'improved', 'innovation', 'instrumentation', 'learning strategy', 'network architecture', 'next generation', 'patient safety', 'photomultiplier', 'physical process', 'response', 'scale up', 'signal processing', 'time use', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2018,78500,0.01878189679477773
"Deep learning techniques for time-of-flight PET detectors Project Summary/Abstract One of the key advances in modern positron emission tomography (PET) systems for clinical imaging is the use of time-of-flight (TOF) information. In cancer imaging TOF provides superior lesion detection and more accurate quantification that is crucial in measuring response to therapy, as well as in neurological and cardiovascular imaging applications. An additional benefit of TOF is the ability to lower the radiation dose or scan time without sacrificing image quality, important for patient safety and comfort. The magnitude of these clinical benefits is determined by the TOF resolution of the PET detectors, therefore the prospect of achieving unprecedented image quality and clinical imaging capabilities with superior TOF resolution has fueled significant research in developing detector technology for TOF-PET systems. However, these developments have been largely unaccompanied by advances in signal processing methods needed to extract TOF information from the detector’s electrical signals, with most detectors making use of crude analog algorithms that discard most of the useful timing information contained in the signals. Now, with the availability of low-cost fast waveform digitizers, there is an exciting opportunity to implement sophisticated digital signal processing algorithms to achieve superior TOF resolution. The main advantage of developing advanced signal processing algorithms is that it presents a cost-effective route to improved TOF resolution that is complementary to instrumentation innovations. In essence, the TOF gain comes for free; the detector signals already contain the information needed for better TOF resolution, it just needs to be used effectively. Here we propose to tailor deep learning techniques to estimate TOF from the detector signals. Deep learning with convolutional neural networks (CNNs) is a powerful approach to learn complex representations of input data that can be used for tasks such as classification and regression. CNNs are therefore very suitable for directly estimating TOF from the detector waveforms, since these waveforms are influenced by several complex and intertwined processes which are hard to accurately model. Furthermore, large amounts of ground truth training data are readily generated. We recently demonstrated the feasibility of CNN-based TOF estimation, and found up to 23% improvement in TOF resolution compared to standard signal processing methods. This proposal aims to optimize these methods to push the limits of achievable TOF resolution and develop methods for their practical implementation. First, we will develop CNN architectures and methods suitable for silicon photomultipliers (SiPMs) that are now used in modern TOF-PET systems. We will also optimize the digitizing parameters to make optimal use of CNNs for TOF estimation. Second, we will implement CNN-TOF methods in a modern commercial PET detector, including using a global CNN to simultaneously estimate TOF and the crystal-of-interaction from the detector waveforms, demonstrating the practical feasibility of using this promising deep learning method in next generation PET systems. Narrative The use of time-of-flight information in positron emission tomography (PET) is a powerful way to increase clinical imaging capabilities of PET, and is now used in most modern systems. Improving time-of-flight performance promises to provide substantial benefits for lesion detection in cancer imaging, kinetic modeling with dynamic imaging, and the use of lower radiation dose for patient safety. Here we introduce deep learning signal processing methods to significantly improve the performance of time-of-flight PET detectors without requiring new materials, which thereby represents a cost effective route towards maximizing the use of the rich imaging signal provided by time-of-flight.",Deep learning techniques for time-of-flight PET detectors,9784818,R03EB027268,"['Address', 'Adoption', 'Algorithms', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Coupled', 'Crystallization', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Electronics', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Human Engineering', 'Image', 'Industry', 'Industry Collaboration', 'Investigation', 'Kinetics', 'Knowledge', 'Learning', 'Lesion', 'Low Dose Radiation', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neurologic', 'Noise', 'Outcome', 'Patient Care', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Property', 'Radiation Dose Unit', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Signal Transduction', 'Silicon', 'Solid', 'Speed', 'Sum', 'System', 'Techniques', 'Technology', 'Temperature', 'Time', 'Training', 'Tube', 'analog', 'base', 'cancer imaging', 'cardiovascular imaging', 'clinical imaging', 'convolutional neural network', 'cost', 'cost effective', 'deep learning', 'detector', 'digital', 'imaging capabilities', 'improved', 'innovation', 'instrumentation', 'learning strategy', 'neural network architecture', 'next generation', 'patient safety', 'photomultiplier', 'physical process', 'response', 'scale up', 'signal processing', 'time use', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2019,78500,0.01878189679477773
"Understanding the impact of environmental disruption in biological timing systems through signal processing. Project Summary/Abstract.  Life on Earth evolved to take time cues from the Sun. Consequently, most or all cells in the mammalian body use genetic feedback loops to time their daily (circadian) rhythms. When a person or any mammal sees light, that winds an orchestrating circadian brain clock in the hypothalamic suprachiasmatic nucleus (SCN). The SCN in turn helps keep the myriad other tissue and endocrine rhythms in synchrony, enabling health. The modern environment is highly disruptive to this internal synchrony. Light at night from cell phones or urban light pollution, and social impositions like school start times or rotating work shifts all act as “temporal pollution,” causing loss of internal synchrony. The more severe the desynchrony, the higher the risk for a broad range of diseases, including obesity, cancer, infertility, depression and ultimately cognitive decline. Without knowing how these systems normally maintain synchrony or which systems are normally synchronized, it is hard to understand what happens in desynchrony to degrade health. This problem is complicated by the fact that some biological systems have ultradian (every few hours) and infradian (every few days) cycles in addition to circadian cycles. The hypothalamo-pituitary-adrenal axis (HPA) generates ultradian rhythms through negative feedback, but also shows a strong circadian cycle; the hypothalamo-pituitary-gonadal axis (HPG) shows the same negative feedback ultradian activity, circadian rhythmicity, and also infradian rhythms of ovulation and spermatogenesis. These two axes are regulated by the SCN. Recent work indicates that there is cross-talk between these axes, and that their hormonal outputs - corticosterone, and estradiol (in females) and testosterone (in males), respectively – work to synchronize extra-SCN tissues and behavioral rhythms of feeding and drinking (FaD). Finally, the SCN, HPA, and HPG axes all affect core body temperature (CBT), so that high temporal resolution recordings of CBT contain information about the cycling and synchrony of these systems across time scales.  There are three aims to this proposal, using rats as a model system: 1) Test at high temporal resolution the effects of changes to the HPA axis, HPG axis, and SCN on CBT. 2) Use these relationships to build a model that can back-predict the state of the HPA axis, HPG axis, and SCN from a high temporal resolution CBT record of a given individual. 3) Expose rats to environmental temporal disruption in the form of a 6 h “jetlag” phase advance of the light cycle, and use the model to predict the response across these systems at 1-minute temporal resolution. This work will employ within-animal comparisons before and after surgical and pharmacological manipulations of rats whose FaD, activity, and CBT are captured continuously at 1-minute resolution. These data will be analyzed using signal-processing and machine learning to define patterns and relationships. The resulting model will allow minimally-invasive exploration of environmental disruption across physiological systems in real time. The model will be used to quantify synchrony as it is disrupted and re-emerges, identifying markers for risk or resilience, and generating hypotheses for future work into preventive strategies and treatments. Project Narrative. Artificial lights and social obligation cause people living with modern infrastructure to suffer a loss of synchrony across their organs, which evolved to track the stable day and year light cycles. We know about internal synchrony mostly by the diseases that arise from its loss – everything from cancer to obesity, depression, and infertility. This work will develop a system for tracking the cycles of many body-systems at the same time with minute-to-minute accuracy, allowing rapid detection of desynchrony, and a potential way to study how synchrony works normally, and why its disruption by the modern environment causes disease.",Understanding the impact of environmental disruption in biological timing systems through signal processing.,9386306,K99ES027509,"['Address', 'Adrenal Glands', 'Affect', 'Animals', 'Automobile Driving', 'Back', 'Behavioral', 'Biological', 'Biological Models', 'Body Temperature', 'Body Temperature Changes', 'Brain', 'Cells', 'Cellular Phone', 'Chronic', 'Circadian Rhythms', 'Corticosterone', 'Coupling', 'Cues', 'Darkness', 'Data', 'Development', 'Diabetes Mellitus', 'Disease', 'Dose', 'Dysmenorrhea', 'Dyspepsia', 'Endocrine', 'Endocrine system', 'Environment', 'Environmental Impact', 'Estradiol', 'Feedback', 'Female', 'Frequencies', 'Future', 'Genetic', 'Glucocorticoids', 'Health', 'Hormonal', 'Hormonal Change', 'Hour', 'Human', 'Hypothalamic structure', 'Impaired cognition', 'Impairment', 'Implant', 'Individual', 'Infertility', 'Inflammation', 'Investigation', 'Jet Lag Syndrome', 'Life', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Measures', 'Mental Depression', 'Modeling', 'Modernization', 'Monitor', 'Myocardial Infarction', 'Obesity', 'Operative Surgical Procedures', 'Organ', 'Orphan', 'Output', 'Ovulation', 'Pattern', 'Periodicity', 'Persons', 'Pharmacology', 'Phase', 'Physiological', 'Physiology', 'Pituitary-Adrenal System', 'Planet Earth', 'Pollution', 'Prevention strategy', 'Preventive treatment', 'Rattus', 'Records', 'Regulation', 'Research Infrastructure', 'Resolution', 'Risk', 'Risk Marker', 'Sampling', 'Schools', 'Shapes', 'Signal Transduction', 'Social Obligations', 'Spermatogenesis', 'Stress', 'Stroke', 'Structure', 'System', 'Testing', 'Testosterone', 'The Sun', 'Time', 'Tissues', 'Wireless Technology', 'Work', 'base', 'biological systems', 'body system', 'comparative', 'drinking', 'feeding', 'high risk', 'male', 'mathematical model', 'minimally invasive', 'pituitary gonadal axis', 'predicting response', 'predictive modeling', 'rapid detection', 'reconstruction', 'resilience', 'response', 'shift work', 'signal processing', 'social', 'suprachiasmatic nucleus', 'targeted treatment', 'temporal measurement', 'time use']",NIEHS,UNIVERSITY OF CALIFORNIA BERKELEY,K99,2017,98712,-0.006837138869745889
"Understanding the impact of environmental disruption in biological timing systems through signal processing. Project Summary/Abstract.  Life on Earth evolved to take time cues from the Sun. Consequently, most or all cells in the mammalian body use genetic feedback loops to time their daily (circadian) rhythms. When a person or any mammal sees light, that winds an orchestrating circadian brain clock in the hypothalamic suprachiasmatic nucleus (SCN). The SCN in turn helps keep the myriad other tissue and endocrine rhythms in synchrony, enabling health. The modern environment is highly disruptive to this internal synchrony. Light at night from cell phones or urban light pollution, and social impositions like school start times or rotating work shifts all act as “temporal pollution,” causing loss of internal synchrony. The more severe the desynchrony, the higher the risk for a broad range of diseases, including obesity, cancer, infertility, depression and ultimately cognitive decline. Without knowing how these systems normally maintain synchrony or which systems are normally synchronized, it is hard to understand what happens in desynchrony to degrade health. This problem is complicated by the fact that some biological systems have ultradian (every few hours) and infradian (every few days) cycles in addition to circadian cycles. The hypothalamo-pituitary-adrenal axis (HPA) generates ultradian rhythms through negative feedback, but also shows a strong circadian cycle; the hypothalamo-pituitary-gonadal axis (HPG) shows the same negative feedback ultradian activity, circadian rhythmicity, and also infradian rhythms of ovulation and spermatogenesis. These two axes are regulated by the SCN. Recent work indicates that there is cross-talk between these axes, and that their hormonal outputs - corticosterone, and estradiol (in females) and testosterone (in males), respectively – work to synchronize extra-SCN tissues and behavioral rhythms of feeding and drinking (FaD). Finally, the SCN, HPA, and HPG axes all affect core body temperature (CBT), so that high temporal resolution recordings of CBT contain information about the cycling and synchrony of these systems across time scales.  There are three aims to this proposal, using rats as a model system: 1) Test at high temporal resolution the effects of changes to the HPA axis, HPG axis, and SCN on CBT. 2) Use these relationships to build a model that can back-predict the state of the HPA axis, HPG axis, and SCN from a high temporal resolution CBT record of a given individual. 3) Expose rats to environmental temporal disruption in the form of a 6 h “jetlag” phase advance of the light cycle, and use the model to predict the response across these systems at 1-minute temporal resolution. This work will employ within-animal comparisons before and after surgical and pharmacological manipulations of rats whose FaD, activity, and CBT are captured continuously at 1-minute resolution. These data will be analyzed using signal-processing and machine learning to define patterns and relationships. The resulting model will allow minimally-invasive exploration of environmental disruption across physiological systems in real time. The model will be used to quantify synchrony as it is disrupted and re-emerges, identifying markers for risk or resilience, and generating hypotheses for future work into preventive strategies and treatments. Project Narrative. Artificial lights and social obligation cause people living with modern infrastructure to suffer a loss of synchrony across their organs, which evolved to track the stable day and year light cycles. We know about internal synchrony mostly by the diseases that arise from its loss – everything from cancer to obesity, depression, and infertility. This work will develop a system for tracking the cycles of many body-systems at the same time with minute-to-minute accuracy, allowing rapid detection of desynchrony, and a potential way to study how synchrony works normally, and why its disruption by the modern environment causes disease.",Understanding the impact of environmental disruption in biological timing systems through signal processing.,9567170,K99ES027509,"['Address', 'Adrenal Glands', 'Affect', 'Animals', 'Automobile Driving', 'Back', 'Behavioral', 'Biological', 'Biological Models', 'Body Temperature', 'Body Temperature Changes', 'Brain', 'Cells', 'Cellular Phone', 'Chronic', 'Circadian Rhythms', 'Corticosterone', 'Coupling', 'Cues', 'Data', 'Development', 'Diabetes Mellitus', 'Disease', 'Dose', 'Dysmenorrhea', 'Dyspepsia', 'Endocrine', 'Endocrine system', 'Environment', 'Environmental Impact', 'Estradiol', 'Feedback', 'Female', 'Frequencies', 'Future', 'Genetic', 'Glucocorticoids', 'Health', 'Hormonal', 'Hormonal Change', 'Hour', 'Human', 'Hypothalamic structure', 'Impaired cognition', 'Impairment', 'Implant', 'Individual', 'Infertility', 'Inflammation', 'Investigation', 'Jet Lag Syndrome', 'Life', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Measures', 'Mental Depression', 'Modeling', 'Modernization', 'Monitor', 'Myocardial Infarction', 'Obesity', 'Operative Surgical Procedures', 'Organ', 'Orphan', 'Output', 'Ovulation', 'Pattern', 'Periodicity', 'Persons', 'Pharmacology', 'Phase', 'Physiological', 'Physiology', 'Pituitary-Adrenal System', 'Planet Earth', 'Pollution', 'Prevention strategy', 'Preventive treatment', 'Rattus', 'Records', 'Regulation', 'Research Infrastructure', 'Resolution', 'Risk', 'Risk Marker', 'Sampling', 'Schools', 'Shapes', 'Signal Transduction', 'Social Obligations', 'Spermatogenesis', 'Stress', 'Stroke', 'Structure', 'System', 'Testing', 'Testosterone', 'The Sun', 'Time', 'Tissues', 'Wireless Technology', 'Work', 'base', 'biological systems', 'body system', 'comparative', 'drinking', 'feeding', 'high risk', 'male', 'mathematical model', 'minimally invasive', 'pituitary gonadal axis', 'predicting response', 'predictive modeling', 'rapid detection', 'reconstruction', 'resilience', 'response', 'shift work', 'signal processing', 'social', 'suprachiasmatic nucleus', 'targeted treatment', 'temporal measurement', 'time use']",NIEHS,UNIVERSITY OF CALIFORNIA BERKELEY,K99,2018,104094,-0.006837138869745889
"Co-expression Networks of Addiction-Related Genes in the Mouse and Human Brain Project Summary/Abstract  The increasing availability of genome wide data sets promise to shed light into the etiology and  pathophysiology of genetically complex disorders, including substance abuse and dependence.  There remain significant challenges, however: although there is evidence for significant  heritability, genome wide association studies have typically revealed small effect sizes, possibly  due to the polygenic nature of the disorders. The brain-wide gene expression data sets from the  Allen Institute offers new data sources that could be used to group genes together based on  similarities in their expression profiles in anatomic space, thus enhancing the power of statistical  tests in genome-wide studies. Due to the unprecedented spatial resolution in these data sets, with  genome-wide and brain-wide coverage, specific hypotheses involving intercellular biochemical  networks as well as brain-wide neural networks can also be examined.  At the Allen Institute and at Cold Spring Harbor Laboratory, we have been collaboratively  analyzing the Allen Brain Atlas (ABA) adult mouse brain data set, and preliminary results  demonstrate that the spatial co-expression patterns of genes are indeed a rich source of  information. In this proposal, we intend to focus this analysis on addiction-related gene sets, in  consultation with experts on addiction research and integrating relevant online information  resources. Specific aims in the first year (R21 phase) include (1) development and refinement of  software and web-based tools for analysis of co-expression patterns in gene sets and (2)  multivariate analysis of an initial set of addiction related genes. The first year will focus on the  adult mouse brain data set that is already at hand. In subsequent years (years 2-4, R33 phase), we  will extend the co-expression analysis to mouse developmental and spinal cord data sets (Aim 1),  and human brain data sets (Aim 2), that are scheduled to become available during this period.  Additionally, we will mine existing databases and the literature to augment our initial gene lists  as well as to develop a database of associations between substance abuse phenotypes and  corresponding brain areas (Aim 3). This will allow us to more fully analyze the intra and  intercellular networks that may be involved in addiction. Finally, we will make the  computational tools and analysis results developed as part of our research publicly available in  the form of a web portal (aim 4). Project Narrative  The identification of genes and gene networks driving drug abuse and addiction is a major  current challenge in addiction genetics. The public presentation of tools for understanding  spatially mapped genomic datasets such as the ABA will have major impact on researchers  aiming to understand these genetic networks and pathways. The proposed work will encompass  both the identification of key addiction gene clusters as well as the generation of useful online  methods for addiction researchers.",Co-expression Networks of Addiction-Related Genes in the Mouse and Human Brain,8325662,R33DA027644,"['Adult', 'Anatomy', 'Area', 'Atlases', 'Automobile Driving', 'Biochemical', 'Biological Neural Networks', 'Brain', 'Brain region', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Consultations', 'Custom', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependency', 'Development', 'Disease', 'Drug Addiction', 'Drug abuse', 'Etiology', 'Exhibits', 'Female', 'Functional disorder', 'Gender', 'Gene Cluster', 'Gene Expression', 'Gene Expression Profile', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Grouping', 'Hand', 'Heritability', 'Human', 'Image', 'Imagery', 'In Situ Hybridization', 'Individual', 'Information Resources', 'Institutes', 'Internet', 'Laboratories', 'Libraries', 'Light', 'Link', 'Literature', 'Maps', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Molecular Profiling', 'Multivariate Analysis', 'Mus', 'Nature', 'Nervous system structure', 'Network-based', 'Online Systems', 'Opioid', 'Orthologous Gene', 'Pain', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Principal Component Analysis', 'Property', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Resources', 'Sampling Studies', 'Schedule', 'Series', 'Software Tools', 'Source', 'Spinal Cord', 'Staging', 'Structure', 'Substance Addiction', 'Substance abuse problem', 'Surveys', 'System', 'Testing', 'Text', 'Time', 'Weight', 'Work', 'abstracting', 'addiction', 'base', 'computerized tools', 'critical period', 'genome wide association study', 'genome-wide', 'interest', 'knowledge base', 'male', 'software development', 'text searching', 'tool', 'user-friendly']",NIDA,ALLEN INSTITUTE,R33,2012,361140,0.02431171546689009
"Co-expression Networks of Addiction-Related Genes in the Mouse and Human Brain    DESCRIPTION (provided by applicant): The increasing availability of genome wide data sets promise to shed light into the etiology and pathophysiology of genetically complex disorders, including substance abuse and dependence. There remain significant challenges, however: although there is evidence for significant heritability, genome wide association studies have typically revealed small effect sizes, possibly due to the polygenic nature of the disorders. The brain-wide gene expression data sets from the Allen Institute offers new data sources that could be used to group genes together based on similarities in their expression profiles in anatomic space, thus enhancing the power of statistical tests in genome-wide studies. Due to the unprecedented spatial resolution in these data sets, with genome-wide and brain-wide coverage, specific hypotheses involving intercellular biochemical networks as well as brain-wide neural networks can also be examined. At the Allen Institute and at Cold Spring Harbor Laboratory, we have been collaboratively analyzing the Allen Brain Atlas (ABA) adult mouse brain data set, and preliminary results demonstrate that the spatial co-expression patterns of genes are indeed a rich source of information. In this application, we intend to focus this analysis on addiction-related gene sets, in consultation with experts on addiction research and integrating relevant online information resources. Specific aims in the first year (R21 phase) include (1) development and refinement of software and web-based tools for analysis of co-expression patterns in gene sets and (2) multivariate analysis of an initial set of addiction related genes. The first year will focus on the adult mouse brain data set that is already at hand. In subsequent years (years 2-4, R33 phase), we will extend the co-expression analysis to mouse developmental and spinal cord data sets (Aim 1), and human brain data sets (Aim 2), that are scheduled to become available during this period. Additionally, we will mine existing databases and the literature to augment our initial gene lists as well as to develop a database of associations between substance abuse phenotypes and corresponding brain areas (Aim 3). This will allow us to more fully analyze the intra and intercellular networks that may be involved in addiction. Finally, we will make the computational tools and analysis results developed as part of our research publicly available in the form of a web portal (aim 4).      PUBLIC HEALTH RELEVANCE: The identification of genes and gene networks driving drug abuse and addiction is a major current challenge in addiction genetics. The public presentation of tools for understanding spatially mapped genomic datasets such as the ABA will have major impact on researchers aiming to understand these genetic networks and pathways. The proposed work will encompass both the identification of key addiction gene clusters as well as the generation of useful online methods for addiction researchers.          Project Narrative  The identification of genes and gene networks driving drug abuse and addiction is a major  current challenge in addiction genetics. The public presentation of tools for understanding  spatially mapped genomic datasets such as the ABA will have major impact on researchers  aiming to understand these genetic networks and pathways. The proposed work will encompass  both the identification of key addiction gene clusters as well as the generation of useful online  methods for addiction researchers.",Co-expression Networks of Addiction-Related Genes in the Mouse and Human Brain,8137249,R33DA027644,"['Adult', 'Anatomy', 'Area', 'Atlases', 'Automobile Driving', 'Biochemical', 'Biological Neural Networks', 'Brain', 'Brain region', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Consultations', 'Custom', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependency', 'Development', 'Disease', 'Drug Addiction', 'Drug abuse', 'Etiology', 'Exhibits', 'Female', 'Functional disorder', 'Gender', 'Gene Cluster', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Grouping', 'Hand', 'Heritability', 'Human', 'Image', 'Imagery', 'In Situ Hybridization', 'Individual', 'Information Resources', 'Institutes', 'Internet', 'Laboratories', 'Libraries', 'Light', 'Link', 'Literature', 'Maps', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Molecular Profiling', 'Multivariate Analysis', 'Mus', 'Nature', 'Nervous system structure', 'Network-based', 'Online Systems', 'Opioid', 'Orthologous Gene', 'Pain', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Principal Component Analysis', 'Property', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Resources', 'Sampling Studies', 'Schedule', 'Series', 'Software Tools', 'Source', 'Spinal Cord', 'Staging', 'Structure', 'Substance Addiction', 'Substance abuse problem', 'Surveys', 'System', 'Testing', 'Text', 'Time', 'Weight', 'Work', 'addiction', 'base', 'computerized tools', 'critical period', 'genome wide association study', 'genome-wide', 'interest', 'knowledge base', 'male', 'public health relevance', 'software development', 'text searching', 'tool', 'user-friendly']",NIDA,ALLEN INSTITUTE,R33,2011,369400,0.024518267295257135
"Co-expression Networks of Addiction-Related Genes in the Mouse and Human Brain    DESCRIPTION (provided by applicant): The increasing availability of genome wide data sets promise to shed light into the etiology and pathophysiology of genetically complex disorders, including substance abuse and dependence. There remain significant challenges, however: although there is evidence for significant heritability, genome wide association studies have typically revealed small effect sizes, possibly due to the polygenic nature of the disorders. The brain-wide gene expression data sets from the Allen Institute offers new data sources that could be used to group genes together based on similarities in their expression profiles in anatomic space, thus enhancing the power of statistical tests in genome-wide studies. Due to the unprecedented spatial resolution in these data sets, with genome-wide and brain-wide coverage, specific hypotheses involving intercellular biochemical networks as well as brain-wide neural networks can also be examined. At the Allen Institute and at Cold Spring Harbor Laboratory, we have been collaboratively analyzing the Allen Brain Atlas (ABA) adult mouse brain data set, and preliminary results demonstrate that the spatial co-expression patterns of genes are indeed a rich source of information. In this application, we intend to focus this analysis on addiction-related gene sets, in consultation with experts on addiction research and integrating relevant online information resources. Specific aims in the first year (R21 phase) include (1) development and refinement of software and web-based tools for analysis of co-expression patterns in gene sets and (2) multivariate analysis of an initial set of addiction related genes. The first year will focus on the adult mouse brain data set that is already at hand. In subsequent years (years 2-4, R33 phase), we will extend the co-expression analysis to mouse developmental and spinal cord data sets (Aim 1), and human brain data sets (Aim 2), that are scheduled to become available during this period. Additionally, we will mine existing databases and the literature to augment our initial gene lists as well as to develop a database of associations between substance abuse phenotypes and corresponding brain areas (Aim 3). This will allow us to more fully analyze the intra and intercellular networks that may be involved in addiction. Finally, we will make the computational tools and analysis results developed as part of our research publicly available in the form of a web portal (aim 4).      PUBLIC HEALTH RELEVANCE: The identification of genes and gene networks driving drug abuse and addiction is a major current challenge in addiction genetics. The public presentation of tools for understanding spatially mapped genomic datasets such as the ABA will have major impact on researchers aiming to understand these genetic networks and pathways. The proposed work will encompass both the identification of key addiction gene clusters as well as the generation of useful online methods for addiction researchers.          Project Narrative  The identification of genes and gene networks driving drug abuse and addiction is a major  current challenge in addiction genetics. The public presentation of tools for understanding  spatially mapped genomic datasets such as the ABA will have major impact on researchers  aiming to understand these genetic networks and pathways. The proposed work will encompass  both the identification of key addiction gene clusters as well as the generation of useful online  methods for addiction researchers.",Co-expression Networks of Addiction-Related Genes in the Mouse and Human Brain,7931445,R33DA027644,"['Adult', 'Anatomy', 'Area', 'Atlases', 'Automobile Driving', 'Biochemical', 'Biological Neural Networks', 'Brain', 'Brain region', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consultations', 'Custom', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Disease', 'Drug abuse', 'Etiology', 'Exhibits', 'Female', 'Functional disorder', 'Gender', 'Gene Cluster', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Grouping', 'Hand', 'Heritability', 'Human', 'Image', 'Imagery', 'In Situ Hybridization', 'Individual', 'Information Resources', 'Institutes', 'Internet', 'Laboratories', 'Libraries', 'Light', 'Link', 'Literature', 'Maps', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Molecular Profiling', 'Multivariate Analysis', 'Mus', 'Nature', 'Nervous system structure', 'Network-based', 'Online Systems', 'Opioid', 'Orthologous Gene', 'Pain', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Principal Component Analysis', 'Property', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Resources', 'Sampling Studies', 'Schedule', 'Series', 'Software Tools', 'Source', 'Spinal Cord', 'Staging', 'Structure', 'Substance abuse problem', 'Surveys', 'System', 'Testing', 'Text', 'Time', 'Weight', 'Work', 'abstracting', 'addiction', 'base', 'computerized tools', 'critical period', 'genome wide association study', 'genome-wide', 'interest', 'knowledge base', 'male', 'software development', 'text searching', 'tool', 'user-friendly']",NIDA,ALLEN INSTITUTE,R33,2010,377995,0.024518267295257135
"Co-expression Networks of Addiction-Related Genes in the Mouse and Human Brain    DESCRIPTION (provided by applicant): The increasing availability of genome wide data sets promise to shed light into the etiology and pathophysiology of genetically complex disorders, including substance abuse and dependence. There remain significant challenges, however: although there is evidence for significant heritability, genome wide association studies have typically revealed small effect sizes, possibly due to the polygenic nature of the disorders. The brain-wide gene expression data sets from the Allen Institute offers new data sources that could be used to group genes together based on similarities in their expression profiles in anatomic space, thus enhancing the power of statistical tests in genome-wide studies. Due to the unprecedented spatial resolution in these data sets, with genome-wide and brain-wide coverage, specific hypotheses involving intercellular biochemical networks as well as brain-wide neural networks can also be examined. At the Allen Institute and at Cold Spring Harbor Laboratory, we have been collaboratively analyzing the Allen Brain Atlas (ABA) adult mouse brain data set, and preliminary results demonstrate that the spatial co-expression patterns of genes are indeed a rich source of information. In this application, we intend to focus this analysis on addiction-related gene sets, in consultation with experts on addiction research and integrating relevant online information resources. Specific aims in the first year (R21 phase) include (1) development and refinement of software and web-based tools for analysis of co-expression patterns in gene sets and (2) multivariate analysis of an initial set of addiction related genes. The first year will focus on the adult mouse brain data set that is already at hand. In subsequent years (years 2-4, R33 phase), we will extend the co-expression analysis to mouse developmental and spinal cord data sets (Aim 1), and human brain data sets (Aim 2), that are scheduled to become available during this period. Additionally, we will mine existing databases and the literature to augment our initial gene lists as well as to develop a database of associations between substance abuse phenotypes and corresponding brain areas (Aim 3). This will allow us to more fully analyze the intra and intercellular networks that may be involved in addiction. Finally, we will make the computational tools and analysis results developed as part of our research publicly available in the form of a web portal (aim 4).      PUBLIC HEALTH RELEVANCE: The identification of genes and gene networks driving drug abuse and addiction is a major current challenge in addiction genetics. The public presentation of tools for understanding spatially mapped genomic datasets such as the ABA will have major impact on researchers aiming to understand these genetic networks and pathways. The proposed work will encompass both the identification of key addiction gene clusters as well as the generation of useful online methods for addiction researchers.           Project Narrative  The identification of genes and gene networks driving drug abuse and addiction is a major current challenge in addiction genetics. The public presentation of tools for understanding spatially mapped genomic datasets such as the ABA will have major impact on researchers aiming to understand these genetic networks and pathways. The proposed work will encompass both the identification of key addiction gene clusters as well as the generation of useful online methods for addiction researchers.",Co-expression Networks of Addiction-Related Genes in the Mouse and Human Brain,7765746,R21DA027644,"['Adult', 'Anatomy', 'Area', 'Atlases', 'Automobile Driving', 'Biochemical', 'Biological Neural Networks', 'Body of uterus', 'Brain', 'Brain region', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consultations', 'Custom', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Disease', 'Drug abuse', 'Etiology', 'Exhibits', 'Female', 'Functional disorder', 'Gender', 'Gene Cluster', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Grouping', 'Hand', 'Heritability', 'Human', 'Image', 'Imagery', 'In Situ Hybridization', 'Individual', 'Information Resources', 'Institutes', 'Internet', 'Laboratories', 'Libraries', 'Light', 'Link', 'Literature', 'Maps', 'Measurement', 'Metadata', 'Methods', 'Mining', 'Molecular Profiling', 'Multivariate Analysis', 'Mus', 'Nature', 'Nervous system structure', 'Network-based', 'Online Systems', 'Opioid', 'Orthologous Gene', 'Pain', 'Pathway interactions', 'Pattern', 'Phase', 'Phenotype', 'Principal Component Analysis', 'Property', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Resources', 'Sampling Studies', 'Schedule', 'Series', 'Software Tools', 'Source', 'Spinal Cord', 'Staging', 'Structure', 'Substance abuse problem', 'Surveys', 'System', 'Testing', 'Text', 'Time', 'Weight', 'Work', 'addiction', 'base', 'computerized tools', 'critical period', 'genome wide association study', 'genome-wide', 'interest', 'male', 'public health relevance', 'software development', 'text searching', 'tool', 'user-friendly']",NIDA,ALLEN INSTITUTE,R21,2009,365654,0.024518267295257135
"Generalizing Deep Learning Reconstruction for Free-Breathing and Quantitative MRI Project Summary/Abstract The goal of this project is to increase the precision and resolution of quantitative magnetic resonance imaging (MRI). Quantitative information such as tissue relaxation parameters (e.g., T1 and T2) measure tissue function and indicate disease-related changes in the heart, liver, brain, and other organs. For instance, T1 changes can provide evidence of diffuse fibrosis in the myocardium that can signal heart disease. Quantitative maps also are reproducible, directly comparable longitudinally and across subjects, and less affected by the properties of the scanner used, when compared versus common weighted (non-quantitative) clinical imaging. But, quantitative imaging involves more complicated and time-consuming pulse sequences. To accomplish this goal, this project will develop new machine learning algorithms for high-quality parameter mapping from free-breathing data. The first aim of this project will increase parameter map resolution achievable from highly accelerated, noisy data. The proposed method will integrate existing deep cascade network-based image reconstructions with convolutional network-based blocks for super-resolution and parameter map estimation. Preliminary studies suggest these new blocks improve sharpness and mitigate artifacts in the reconstructed parameter maps. The next aim will improve the training precision of such artificial neural networks to account for the significant per-voxel nonlinear fit variability in quantitative MRI. The proposed method will reweight the loss function used for calibrating these networks by the goodness-of-fit (coefficient of determination) of the reference maps obtained from fully sampled training data. Preliminary results demonstrate that quality-aware reweighting significantly improves reconstructed image quality when working with noisy training data. Experiments will evaluate the precision of both of these innovations against existing deep-learning-based reconstructions on T1 maps obtained from pre- and post-contrast cardiac images of volunteer patients. The final aim will address motion during the acquisition by estimating and tracking nonrigid motion in the data consistency stages of the deep cascade artificial neural network architecture. Two methods are proposed: deformable motion estimation already demonstrated on compressive model-based image reconstructions, and a new “re-blurring” convolutional neural network that automatically introduces artifacts into a “clean” image to match the motion-corrupted data. Both of these methods enforce consistency between motion-affected data and a motion-free image during the reconstruction. Both methods will be validated on both cardiac and abdominal images for motion artifacts and reconstruction quality against breath-held parameter mapping acquisitions. Project Narrative Quantitative magnetic resonance imaging noninvasively measures physical properties of tissue connected to cardiovascular disease and many other conditions. Novel machine learning methods for processing data to produce higher quality maps will facilitate earlier and more accurate treatment of these diseases. This project will facilitate rapid quantitative imaging with freely breathing subjects.",Generalizing Deep Learning Reconstruction for Free-Breathing and Quantitative MRI,10007241,R56EB028254,"['Abdomen', 'Address', 'Adoption', 'Affect', 'Algorithms', 'Awareness', 'Balance training', 'Brain', 'Breathing', 'Cardiac', 'Cardiovascular Diseases', 'Clinical', 'Consumption', 'Data', 'Development', 'Diagnostic', 'Diffuse', 'Disease', 'Fibrosis', 'Financial compensation', 'Goals', 'Heart', 'Heart Diseases', 'Heart failure', 'Image', 'Infiltration', 'Literature', 'Liver', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Myocardium', 'Network-based', 'Noise', 'Non-linear Models', 'Organ', 'Patients', 'Physiologic pulse', 'Process', 'Property', 'Protocols documentation', 'Relaxation', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Series', 'Signal Transduction', 'Techniques', 'Time', 'Tissues', 'Training', 'Weight', 'artificial neural network', 'base', 'clinical imaging', 'clinically relevant', 'computerized data processing', 'contrast imaging', 'convolutional neural network', 'coronary fibrosis', 'data space', 'deep learning', 'design', 'experimental study', 'heart imaging', 'image reconstruction', 'improved', 'innovation', 'learning strategy', 'loss of function', 'machine learning algorithm', 'motion sensitivity', 'multitask', 'neural network architecture', 'non-invasive imaging', 'novel', 'physical property', 'quantitative imaging', 'reconstruction', 'volunteer']",NIBIB,UNIVERSITY OF VIRGINIA,R56,2019,347527,-0.02188402037996629
"Multiband ASL for Neurodevelopment Study Project Summary/Abstract The developmental period between childhood to adolescence and young adulthood is marked by a mix of potential and vulnerability. A number of potentially life-long behavioral and emotional problems emerge during this critical period, including alcohol and illicit drug use, risky behaviors, and the first signs of emotional disorders. It is important to understand detailed patterns of typical development, so alterations can be identified and rectified as early as possible. As an entirely noninvasive and quantitative imaging method, arterial spin labeled (ASL) perfusion MRI is increasingly being recognized as an important biomarker for functional brain development in both healthy populations and neurodevelopmental disorders. However, there remain significant challenges for making ASL an impactful tool in studying neurodevelopment, including: 1) a coarse spatial resolution of ~4x4x4mm3, 2) susceptibility to head motion with segmented 3D acquisitions, and 3) potential confounding effects of age dependent variations in arterial transit time using a single post-labeling delay (PLD) scan. Simultaneous multi-slice (SMS) or multiband (MB) is a new accelerated imaging technology that simultaneously excites multiple slices and recovers each slice with parallel imaging techniques. Preliminary studies combining MB with ASL showed that MB can reduce T1 relaxation of the label, improve spatial coverage and/or resolution compared to those of standard 2D ASL. MB imaging may also overcome the limitation of 3D ASL acquisitions in terms of head motion and spatial blurring. However, the signal-to-noise ratio (SNR) of existing MB ASL is inferior to that of 3D ASL. This project builds on two recent innovations from our lab: 1) a constrained slice-dependent (CSD) background suppression (BS) technique that improves the SNR of 2D MB pCASL to be comparable to that of 3D pCASL; and 2) a single-shot 3D GRASE pCASL method with 2D CAIPIRINHA accelerations that improves the imaging speed of 3D pCASL. The goal of this R01 project is to develop and evaluate cutting-edge MB pCASL protocols that are able to offer a high spatial resolution of isotropic 2mm or higher, resistance to head motion and multi-delay capability for accurate perfusion quantification in pediatric populations. A convolutional neural network (CNN) based denoising algorithm for multi-delay MB pCASL will be further developed. The developed suite of MB pCASL protocol and post- processing algorithms will be evaluated in 40 typically developing children and adolescents. The successful completion of this R01 project will lead to a robust multi-delay MB pCASL protocol that is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care. To maximize the scientific and clinical impact, we will continue disseminating the pulse sequence and associated post-processing software as we have been doing in the past decade. Relevance to Public Health A number of potentially life-long behavioral and emotional problems emerge during the developmental period between childhood to adolescence and young adulthood, including alcohol and illicit drug use, risky behaviors, and emotional disorders. This project will develop a robust noninvasive imaging technique using magnetic resonance imaging (MRI) that offers high spatial resolution, resistance to head motion and accurate quantification of cerebral blood flow in children and adolescents. The developed technology is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care.",Multiband ASL for Neurodevelopment Study,9972888,R01EB028297,"['3-Dimensional', 'Acceleration', 'Adolescence', 'Adolescent', 'Affect', 'Age', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Behavior Disorders', 'Behavioral', 'Biological Markers', 'Brain', 'Cerebrovascular Circulation', 'Child', 'Childhood', 'Clinical', 'Computer software', 'Data', 'Databases', 'Development', 'Emotional', 'Emotional disorder', 'Goals', 'Head', 'Image', 'Imaging Techniques', 'Imaging technology', 'Inferior', 'Joint repair', 'Label', 'Life', 'Magnetic Resonance Imaging', 'Methods', 'Motion', 'Network-based', 'Neurodevelopmental Disorder', 'Noise', 'Pattern', 'Performance', 'Perfusion', 'Perfusion Weighted MRI', 'Phase', 'Physiologic pulse', 'Population', 'Predisposition', 'Principal Component Analysis', 'Protocols documentation', 'Public Health', 'Publishing', 'Relaxation', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Risk Behaviors', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Speed', 'Spin Labels', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Variant', 'age effect', 'age related', 'autism spectrum disorder', 'base', 'child depression', 'clinical care', 'convolutional neural network', 'critical period', 'denoising', 'developmental disease', 'illicit drug use', 'imaging modality', 'improved', 'innovation', 'neurodevelopment', 'non-invasive imaging', 'novel', 'perfusion imaging', 'potential biomarker', 'quantitative imaging', 'socioeconomics', 'time use', 'tool', 'young adult']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,445500,-0.0019189099533573656
"Multiband ASL for Neurodevelopment Study Project Summary/Abstract The developmental period between childhood to adolescence and young adulthood is marked by a mix of potential and vulnerability. A number of potentially life-long behavioral and emotional problems emerge during this critical period, including alcohol and illicit drug use, risky behaviors, and the first signs of emotional disorders. It is important to understand detailed patterns of typical development, so alterations can be identified and rectified as early as possible. As an entirely noninvasive and quantitative imaging method, arterial spin labeled (ASL) perfusion MRI is increasingly being recognized as an important biomarker for functional brain development in both healthy populations and neurodevelopmental disorders. However, there remain significant challenges for making ASL an impactful tool in studying neurodevelopment, including: 1) a coarse spatial resolution of ~4x4x4mm3, 2) susceptibility to head motion with segmented 3D acquisitions, and 3) potential confounding effects of age dependent variations in arterial transit time using a single post-labeling delay (PLD) scan. Simultaneous multi-slice (SMS) or multiband (MB) is a new accelerated imaging technology that simultaneously excites multiple slices and recovers each slice with parallel imaging techniques. Preliminary studies combining MB with ASL showed that MB can reduce T1 relaxation of the label, improve spatial coverage and/or resolution compared to those of standard 2D ASL. MB imaging may also overcome the limitation of 3D ASL acquisitions in terms of head motion and spatial blurring. However, the signal-to-noise ratio (SNR) of existing MB ASL is inferior to that of 3D ASL. This project builds on two recent innovations from our lab: 1) a constrained slice-dependent (CSD) background suppression (BS) technique that improves the SNR of 2D MB pCASL to be comparable to that of 3D pCASL; and 2) a single-shot 3D GRASE pCASL method with 2D CAIPIRINHA accelerations that improves the imaging speed of 3D pCASL. The goal of this R01 project is to develop and evaluate cutting-edge MB pCASL protocols that are able to offer a high spatial resolution of isotropic 2mm or higher, resistance to head motion and multi-delay capability for accurate perfusion quantification in pediatric populations. A convolutional neural network (CNN) based denoising algorithm for multi-delay MB pCASL will be further developed. The developed suite of MB pCASL protocol and post- processing algorithms will be evaluated in 40 typically developing children and adolescents. The successful completion of this R01 project will lead to a robust multi-delay MB pCASL protocol that is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care. To maximize the scientific and clinical impact, we will continue disseminating the pulse sequence and associated post-processing software as we have been doing in the past decade. Relevance to Public Health A number of potentially life-long behavioral and emotional problems emerge during the developmental period between childhood to adolescence and young adulthood, including alcohol and illicit drug use, risky behaviors, and emotional disorders. This project will develop a robust noninvasive imaging technique using magnetic resonance imaging (MRI) that offers high spatial resolution, resistance to head motion and accurate quantification of cerebral blood flow in children and adolescents. The developed technology is highly valuable as potential biomarker for both neurodevelopment research and pediatric clinical care.",Multiband ASL for Neurodevelopment Study,9800619,R01EB028297,"['3-Dimensional', 'Acceleration', 'Adolescence', 'Adolescent', 'Affect', 'Age', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Behavior Disorders', 'Behavioral', 'Biological Markers', 'Brain', 'Cerebrovascular Circulation', 'Child', 'Childhood', 'Clinical', 'Computer software', 'Data', 'Databases', 'Development', 'Emotional', 'Emotional disorder', 'Goals', 'Head', 'Image', 'Imaging Techniques', 'Imaging technology', 'Inferior', 'Joint repair', 'Label', 'Life', 'Magnetic Resonance Imaging', 'Methods', 'Motion', 'Network-based', 'Neurodevelopmental Disorder', 'Noise', 'Pattern', 'Performance', 'Perfusion', 'Perfusion Weighted MRI', 'Phase', 'Physiologic pulse', 'Population', 'Predisposition', 'Principal Component Analysis', 'Protocols documentation', 'Public Health', 'Publishing', 'Relaxation', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Risk Behaviors', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Speed', 'Spin Labels', 'Structure', 'Techniques', 'Technology', 'Testing', 'Time', 'Variant', 'age effect', 'age related', 'autism spectrum disorder', 'base', 'child depression', 'clinical care', 'convolutional neural network', 'critical period', 'denoising', 'developmental disease', 'illicit drug use', 'imaging modality', 'improved', 'innovation', 'neurodevelopment', 'non-invasive imaging', 'novel', 'perfusion imaging', 'potential biomarker', 'quantitative imaging', 'socioeconomics', 'time use', 'tool', 'young adult']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,445500,-0.0019189099533573656
"High performance PET Detector Module for Human Brain Imaging Project Summary / Abstract This proposal is in response to PA 18-484. In the BRAIN 2025 Report, PET (positron emission tomography) is identified as “the best means to translate studies of neurotransmitters, receptors, and neuromodulators to humans.” However dynamic assessment of receptor occupancy and metabolism is hindered by the spatial resolution and sensitivity of even the most modern of clinically available PET scanners. To address this challenge, we propose a next generation PET detector with a highly innovative design: a detector module with a layered scintillator structure and a side readout configuration. The crystal slabs in the module are stacked along the depth direction and are optically separated by reflective films. The scintillation light created in each layer is measured by photodetectors located on the four sides of the crystal. Compared with traditional PET detectors, which contain pixelated crystal arrays, the new design has the following advantages: (1) The layered structure provides depth of interaction (DOI) information such that a smaller diameter detector ring can be used without increasing parallax error, increasing sensitivity while lowering costs. (2) The four-sided readout method improves the energy resolution of the system with increased scintillation light collection efficiency by reducing light loss due to total internal reflection. (3) Sub millimeter spatial resolution is achievable without using very small pitch crystal arrays, since the interaction location in each crystal layer is determined via machine learning- based decoding of the light distribution collected on the four crystal sides. Therefore the production cost of the crystals is reduced. (4) Since the interaction location and energy resolution for each layer are determined independently, the system sensitivity can be increased by stacking more layers in the module without affecting the spatial and energy resolution of the system. (5) For side readout setup, a larger ratio of cross-sectional area to length requires fewer photodetectors to cover all four sides of the module; this reduces photodetector cost. The first four points above have been demonstrated in preliminary studies using a small, prototype module. We propose to build a large scale detector module with this new design to verify the fifth advantage, and to study the effect of detector size on the first four. The outcome of this proposal will be two DOI enabled detector modules with excellent spatial resolution (~1 mm) and energy resolution (~10%), as well as good timing resolution (~400 ps), and DOI resolution (~ 3 mm) and high system sensitivity. A full characterization study for the two modules and imaging studies for both the Derenzo and Hoffman brain phantoms will address the current limitations of human brain PET scanners, and will serve as the foundation for a new dynamic PET scanner for neuroimaging. Project Narrative The goal of this project is to develop a novel design for detector modules used in brain-dedicated PET system with good spatial resolution, energy resolution, timing resolution, and DOI resolution, as well as high sensitivity. If successful, the study will pave the way for building a novel PET system for greatly improved dynamic PET imaging of the human brain.",High performance PET Detector Module for Human Brain Imaging,10017238,R01EB028337,"['Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Area', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Caliber', 'Calibration', 'Clinical', 'Collection', 'Crystallization', 'Development', 'Diagnosis', 'Evaluation', 'Event', 'Film', 'Foundations', 'Gamma Rays', 'Geometry', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Individual', 'Length', 'Light', 'Location', 'Machine Learning', 'Measures', 'Metabolism', 'Methods', 'Modernization', 'Neuromodulator', 'Neurotransmitter Receptor', 'Optics', 'Outcome', 'Parkinson Disease', 'Pattern', 'Performance', 'Portugal', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Production', 'Reporting', 'Resolution', 'Rod', 'Side', 'Signal Transduction', 'Silicon', 'Source', 'Staging', 'Structure', 'Surface', 'System', 'Thinness', 'Translating', 'Variant', 'base', 'brain size', 'cost', 'design', 'detector', 'human imaging', 'imaging study', 'improved', 'innovation', 'machine learning method', 'meetings', 'millimeter', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'photomultiplier', 'prototype', 'receptor', 'response']",NIBIB,"CANON MEDICAL RESEARCH USA, INC.",R01,2020,243919,0.061962859788041585
"High performance PET Detector Module for Human Brain Imaging Project Summary / Abstract This proposal is in response to PA 18-484. In the BRAIN 2025 Report, PET (positron emission tomography) is identified as “the best means to translate studies of neurotransmitters, receptors, and neuromodulators to humans.” However dynamic assessment of receptor occupancy and metabolism is hindered by the spatial resolution and sensitivity of even the most modern of clinically available PET scanners. To address this challenge, we propose a next generation PET detector with a highly innovative design: a detector module with a layered scintillator structure and a side readout configuration. The crystal slabs in the module are stacked along the depth direction and are optically separated by reflective films. The scintillation light created in each layer is measured by photodetectors located on the four sides of the crystal. Compared with traditional PET detectors, which contain pixelated crystal arrays, the new design has the following advantages: (1) The layered structure provides depth of interaction (DOI) information such that a smaller diameter detector ring can be used without increasing parallax error, increasing sensitivity while lowering costs. (2) The four-sided readout method improves the energy resolution of the system with increased scintillation light collection efficiency by reducing light loss due to total internal reflection. (3) Sub millimeter spatial resolution is achievable without using very small pitch crystal arrays, since the interaction location in each crystal layer is determined via machine learning- based decoding of the light distribution collected on the four crystal sides. Therefore the production cost of the crystals is reduced. (4) Since the interaction location and energy resolution for each layer are determined independently, the system sensitivity can be increased by stacking more layers in the module without affecting the spatial and energy resolution of the system. (5) For side readout setup, a larger ratio of cross-sectional area to length requires fewer photodetectors to cover all four sides of the module; this reduces photodetector cost. The first four points above have been demonstrated in preliminary studies using a small, prototype module. We propose to build a large scale detector module with this new design to verify the fifth advantage, and to study the effect of detector size on the first four. The outcome of this proposal will be two DOI enabled detector modules with excellent spatial resolution (~1 mm) and energy resolution (~10%), as well as good timing resolution (~400 ps), and DOI resolution (~ 3 mm) and high system sensitivity. A full characterization study for the two modules and imaging studies for both the Derenzo and Hoffman brain phantoms will address the current limitations of human brain PET scanners, and will serve as the foundation for a new dynamic PET scanner for neuroimaging. Project Narrative The goal of this project is to develop a novel design for detector modules used in brain-dedicated PET system with good spatial resolution, energy resolution, timing resolution, and DOI resolution, as well as high sensitivity. If successful, the study will pave the way for building a novel PET system for greatly improved dynamic PET imaging of the human brain.",High performance PET Detector Module for Human Brain Imaging,9802309,R01EB028337,"['Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Area', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Caliber', 'Calibration', 'Clinical', 'Collection', 'Crystallization', 'Development', 'Diagnosis', 'Evaluation', 'Event', 'Film', 'Foundations', 'Gamma Rays', 'Geometry', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Individual', 'Length', 'Light', 'Location', 'Machine Learning', 'Measures', 'Metabolism', 'Methods', 'Modernization', 'Neuromodulator', 'Neurotransmitter Receptor', 'Optics', 'Outcome', 'Parkinson Disease', 'Pattern', 'Performance', 'Portugal', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Production', 'Reporting', 'Resolution', 'Side', 'Signal Transduction', 'Silicon', 'Source', 'Staging', 'Structure', 'Surface', 'System', 'Thinness', 'Translating', 'Variant', 'base', 'brain size', 'cost', 'design', 'detector', 'human imaging', 'imaging study', 'improved', 'innovation', 'learning strategy', 'meetings', 'millimeter', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'photomultiplier', 'prototype', 'receptor', 'response', 'retinal rods']",NIBIB,"CANON MEDICAL RESEARCH USA, INC.",R01,2019,293568,0.061962859788041585
"Opera Phenix High-Content Imaging System for Drug Discovery PROJECT SUMMARY The University of Pittsburgh Drug Discovery Institute (UPDDI) is requesting funds to purchase the Perkin Elmer OPERA PHENIX high speed, high resolution spinning disk confocal High-Content Screening (HCS) device. The Opera Phenix will replace two Molecular Devices ImageXpress Ultra high content readers purchased in 2008, which are critical to multiple NIH-, DoD-, and Foundation-funded projects at the University of Pittsburgh, but are no longer supported by the manufacturer and have been decommissioned. We have determined that one Opera Phenix instrument can replace the two IXUs. The Phenix is a third generation HCS instrument that will be essential to satisfy the diverse needs of users that the UPDDI serves. No comparable instruments exist at the University of Pittsburgh, the University of Pittsburgh Medical Center, and Carnegie Mellon University. Over the last decade, HCS has become a standard in the pharmaceutical industry for target identification, phenotypic screening, as well as toxicology, and in academia for large-scale biological studies, where cell-by- cell quantitation is critical. The UPDDI has been an academic pioneer in the application of HCS and serves an extensive number of collaborators across campus that require and rely on HCS, ranging from neurodegeneration, organ regeneration, cancer, liver diseases, organotypic model development, and traumatic brain injury. Our diverse user groups’ needs emphasize discovery models of physiological relevance and high complexity, and therefore require fast, high resolution 2D, 3D, and kinetic imaging and maximum flexibility in image analysis. The large number of HCS users working in the UPDDI further demands a fast system to permit effective sharing of instrument time, and an integrated database with off-site user access to perform off- line analysis. Key requirements for an HCS imager therefore are superior speed in acquiring z-series of images at high resolution of thick specimens in aqueous matrices, mature yet flexible image algorithms, and seamless integration of instrument software with system, public,and custom-developed UPDDI databases. The only instrument that meets all of these criteria is the Opera Phenix because it has 1) fast laser-based illumination and the ability to acquire multiple channels simultaneously 2) water immersion objectives that eliminate non-matching refractive indices, which limit spherical aberrations of air and oil objectives at longer working distances and require adjustment of correction collars depending on imaging depth; 3) a powerful suite of user-friendly yet flexible image analysis routines including a 3D module, advanced texture and morphology analysis, and intuitive and user-friendly machine learning; and 4) the ability to perform seamless “adaptive high-resolution imaging”, i.e., pre-scanning a large area at low magnification, followed by automated “on-the- fly” switching to higher magnification to acquire high resolution images of user-defined regions of interest. The Opera Phenix is the only instrument on the market that is capable of fulfilling the demands of the University of Pittsburgh’s diverse drug discovery community. PROJECT NARRATIVE Modern drug discovery increasingly demands better and more disease relevant models and the ability to analyze them. High-content screening (HCS) has become indispensable in the analysis of such models as it permits the analysis of cells, their constituents, and interactions in their proper biological context. The third generation HCS instrument, Opera Phenix, produces the quality and quantity of data from cells, tissues and experimental animals that are required for computational and systems biological investigations, while at the same time providing the throughput needed for automated screening.",Opera Phenix High-Content Imaging System for Drug Discovery,9935240,S10OD028450,"['3-Dimensional', 'Academia', 'Air', 'Algorithms', 'Area', 'Biological', 'Cells', 'Communities', 'Computer software', 'Custom', 'Databases', 'Devices', 'Drug Industry', 'Foundations', 'Funding', 'Generations', 'Image', 'Image Analysis', 'Immersion', 'Institutes', 'Intuition', 'Kinetics', 'Lasers', 'Lighting', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical center', 'Molecular', 'Morphology', 'Nerve Degeneration', 'Oils', 'Phenotype', 'Reader', 'Refractive Indices', 'Resolution', 'Scanning', 'Series', 'Site', 'Specimen', 'Speed', 'System', 'Texture', 'Thick', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Universities', 'Water', 'aqueous', 'base', 'drug discovery', 'flexibility', 'high resolution imaging', 'imager', 'imaging system', 'instrument', 'interest', 'model development', 'organ regeneration', 'physiologic model', 'screening', 'user-friendly']",OD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,S10,2020,1010594,0.018857376700855074
"A New J-Resolved MRSI Framework for Whole-Brain Simultaneous Metabolite and Neurotransmitter Mapping PROJECT SUMMARY/ABSTRACT The metabolite and neurotransmitter profiles of neural tissues provide a unique window into brain’s physiological state and can be used to extract potential biomarkers for detecting and characterizing neurodegenerative diseases. Magnetic resonance spectroscopic imaging (MRSI) allows simultaneous mapping and quantification of a number of metabolites and neurotransmitters without exogenous contrast agents thus promised tremendous opportunities for molecular imaging of the brain. However, due to several fundamental technical challenges, including low SNR, poor spatial resolution, long imaging time and inaccurate separation of spectrally overlapping molecular signals, most in vivo MRSI studies to date are still limited to very low-resolution experiments (~1cm3 voxel size) with small brain coverages. The primary goal of this proposed research is to develop, optimize and evaluate a new framework to model, acquire and process MRSI data to enable simultaneous, high-resolution, whole- brain mapping of metabolites and neurotransmitters in clinically feasible time. To achieve this goal, in Aim 1, we will design and implement a novel acquisition strategy that synergistically combines SNR- efficient, multi-slab and multi-TE excitation, sparse sampling in a (k,t,TE)-space and optimized TE selection with maximum echo sampling to generate J-resolved (multi-TE) MRSI data with an unprecedented combination of speed, resolution and organ coverage. In Aim 2, we will develop novel nonlinear low-dimensional models of general MR spectra using a learning-based strategy that integrates the biochemical priors of neural tissues, known physics-based MRSI signal modeling and deep neural networks. These learned models will effectively reduce the dimensionality of the imaging problem and allow for significantly improved speed, resolution and SNR tradeoffs as well as signal separation. Novel computational solutions that effectively exploit the learned models and other spatial-spectral-TE constraints will be developed for spatiospectral reconstruction of metabolites and neurotransmitters from the noisy, high-resolution J-resolved MRSI data. Finally, in Aim 3, we will systematically evaluate the proposed technology in terms of speed, resolution, SNR, and quantitative accuracy using computer simulations, phantom and in vivo experiments. The feasibility and robustness of the proposed technology for mapping metabolites and neurotransmitters in both healthy volunteers and temporal lobe epilepsy patients with mesial temporal sclerosis will be demonstrated. The success of the proposed research will lead to significant progress for in vivo MRSI and represent an important step towards the creation of a powerful tool for studying the molecular basis of brain functions and diseases. This tool, when fully developed, will add a transformative dimension to the existing neuroimaging technology profiles, with the potential to impact the diagnosis and management of neurological and neurodegenerative diseases. PROJECT NARRATIVE Magnetic resonance spectroscopic imaging (MRSI) is a potentially powerful modality that allows simultaneous mapping of a number of metabolites and neurotransmitters noninvasively, which provide a unique window into brain’s physiological states and can be used to extract biomarkers for detecting and characterizing neurodegenerative diseases. However, the current MRSI techniques do not provide the desired combination of resolution, imaging speed and organ coverage for many basic science and clinical applications. The proposed research will develop a new rapid, J-resolved MRSI technology to enable high-resolution, whole-brain mapping of metabolites and neurotransmitters in clinically feasible time, which, if successful, will lead to significant progress for the field of MRSI and an important step towards the creation of a powerful tool for studying the molecular basis of brain functions and diseases.",A New J-Resolved MRSI Framework for Whole-Brain Simultaneous Metabolite and Neurotransmitter Mapping,10057847,R21EB029076,"['Address', 'Algorithmic Software', 'Basic Science', 'Biochemical', 'Biological Markers', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical', 'Computer Simulation', 'Contrast Media', 'Coupling', 'Data', 'Diagnosis', 'Dimensions', 'Disease', 'Equation', 'Evaluation', 'Evolution', 'Experimental Designs', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Image', 'Imaging Techniques', 'Imaging problem', 'Imaging technology', 'Learning', 'Machine Learning', 'Maps', 'Mechanics', 'Metabolic', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Monitor', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurotransmitters', 'Noise', 'Organ', 'Pathologic', 'Patients', 'Physics', 'Physiologic pulse', 'Physiological', 'Physiological Processes', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Scheme', 'Scientist', 'Sclerosis', 'Signal Transduction', 'Software Tools', 'Solid', 'Spectrum Analysis', 'Speed', 'Technology', 'Temporal Lobe Epilepsy', 'Time', 'Tissues', 'Training', 'Validation', 'Variant', 'Water', 'base', 'clinical application', 'clinical translation', 'computerized data processing', 'deep neural network', 'design', 'experimental study', 'healthy volunteer', 'high dimensionality', 'imaging study', 'improved', 'in vivo', 'innovation', 'interest', 'magnetic field', 'magnetic resonance spectroscopic imaging', 'molecular imaging', 'nervous system disorder', 'neuroimaging', 'novel', 'novel strategies', 'patient population', 'potential biomarker', 'quantum', 'reconstruction', 'relating to nervous system', 'simulation', 'spectroscopic imaging', 'success', 'tool']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,565546,0.06083722484557675
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims to: a) Improve the understanding of the               genetics of inherited diseases with unclear modes of transmission.               Studies will evaluate the effectiveness of current methods of analysis,          including classical linkage analysis, sib-pair or affected-pedigree-             member analysis and the use of measures of association in understanding          the underlying genetic mechanisms of such traits.  Simulation studies            will continue to provide a source of family data reflecting confounding          factors thought to be a problem in linkage analysis of certain complex           traits, such as psychiatric or behavioral disorders.  Factors to be              considered include assortative mating, genetic heterogeneity and multi-          locus disease determination.  The ability of current methods to                  correctly analyze traits with one or more of these factors will be               assessed and, where appropriate, alternative methods will be developed           and tested.  b) Apply techniques of neural network pattern matching to           problems of genetic systems.  Applications include: aid in phenotype             definition for traits with multiple clinical problems of genetic                 systems.  Applications include: aid in phenotype definition for traits           with multiple clinical characteristics; determination of risk of disease         based on phenotype, known risk factors and disease profiles in                   relatives; determination of organ transplant success based on HLA                antigen matching patterns; definition of disease phenotype based on              quantitative factors.  c) Develop and apply strategies for ordering              multiple linked loci using pairwise recombination data, radiation hybrid         data, or other physical mapping data.  Some of these ordering strategies         may be adaptable to the development of techniques for integrating map            information obtained by different methods, an important step in                  organizing a comprehensive, reliable map.  d) Carry out classical                linkage analysis for specific genetic diseases.  Currently, a genome             scan is underway to identify a gene or genes for polycystic liver                disease.  Other diseases to be studied include lymphoma and prostate             cancer. Methods to be tested in the simulation studies can be applied            to these analyses in order to better understand the complete genetic             picture, including identification of heterogeneity, by detecting linkage         of different disease forms to different marker loci. Such                        differentiation will help sharpen the clinical definition of various             forms of the diseases.                                                                                                                                            As a result of advances from this work, better mathematical tools for            the study of diseases with complex or ill-defined inheritance patterns           will be available.  Applications to specific diseases will increase              understanding of interactions between clinical definition and                    predisposing genetic factors.  This will increase the precision of               genetic counseling and suggest useful approaches for studying the                mechanisms involved in determining disease state.                                 n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,6385414,R01GM029177,"['alleles', ' artificial chromosomes', ' artificial intelligence', ' computational neuroscience', ' computer program /software', ' computer simulation', ' family genetics', ' gene expression', ' genetic disorder', ' genetic markers', ' genetic susceptibility', ' histocompatibility antigens', ' human data', ' human genetic material tag', ' linkage mapping', ' liver disorder', ' lymphoma', ' mathematical model', ' model design /development', ' phenotype', ' prostate neoplasms', ' quantitative trait loci', ' sequence tagged sites']",NIGMS,NEW YORK BLOOD CENTER,R01,2001,198845,0.03286328361882904
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims to: a) Improve the understanding of the               genetics of inherited diseases with unclear modes of transmission.               Studies will evaluate the effectiveness of current methods of analysis,          including classical linkage analysis, sib-pair or affected-pedigree-             member analysis and the use of measures of association in understanding          the underlying genetic mechanisms of such traits.  Simulation studies            will continue to provide a source of family data reflecting confounding          factors thought to be a problem in linkage analysis of certain complex           traits, such as psychiatric or behavioral disorders.  Factors to be              considered include assortative mating, genetic heterogeneity and multi-          locus disease determination.  The ability of current methods to                  correctly analyze traits with one or more of these factors will be               assessed and, where appropriate, alternative methods will be developed           and tested.  b) Apply techniques of neural network pattern matching to           problems of genetic systems.  Applications include: aid in phenotype             definition for traits with multiple clinical problems of genetic                 systems.  Applications include: aid in phenotype definition for traits           with multiple clinical characteristics; determination of risk of disease         based on phenotype, known risk factors and disease profiles in                   relatives; determination of organ transplant success based on HLA                antigen matching patterns; definition of disease phenotype based on              quantitative factors.  c) Develop and apply strategies for ordering              multiple linked loci using pairwise recombination data, radiation hybrid         data, or other physical mapping data.  Some of these ordering strategies         may be adaptable to the development of techniques for integrating map            information obtained by different methods, an important step in                  organizing a comprehensive, reliable map.  d) Carry out classical                linkage analysis for specific genetic diseases.  Currently, a genome             scan is underway to identify a gene or genes for polycystic liver                disease.  Other diseases to be studied include lymphoma and prostate             cancer. Methods to be tested in the simulation studies can be applied            to these analyses in order to better understand the complete genetic             picture, including identification of heterogeneity, by detecting linkage         of different disease forms to different marker loci. Such                        differentiation will help sharpen the clinical definition of various             forms of the diseases.                                                                                                                                            As a result of advances from this work, better mathematical tools for            the study of diseases with complex or ill-defined inheritance patterns           will be available.  Applications to specific diseases will increase              understanding of interactions between clinical definition and                    predisposing genetic factors.  This will increase the precision of               genetic counseling and suggest useful approaches for studying the                mechanisms involved in determining disease state.                                 n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,6179464,R01GM029177,"['alleles', ' artificial chromosomes', ' artificial intelligence', ' computational neuroscience', ' computer program /software', ' computer simulation', ' family genetics', ' gene expression', ' genetic disorder', ' genetic markers', ' genetic susceptibility', ' histocompatibility antigens', ' human data', ' human genetic material tag', ' linkage mapping', ' liver disorder', ' lymphoma', ' mathematical model', ' model design /development', ' phenotype', ' prostate neoplasms', ' quantitative trait loci', ' sequence tagged sites']",NIGMS,NEW YORK BLOOD CENTER,R01,2000,195932,0.03286328361882904
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims to: a) Improve the understanding of the               genetics of inherited diseases with unclear modes of transmission.               Studies will evaluate the effectiveness of current methods of analysis,          including classical linkage analysis, sib-pair or affected-pedigree-             member analysis and the use of measures of association in understanding          the underlying genetic mechanisms of such traits.  Simulation studies            will continue to provide a source of family data reflecting confounding          factors thought to be a problem in linkage analysis of certain complex           traits, such as psychiatric or behavioral disorders.  Factors to be              considered include assortative mating, genetic heterogeneity and multi-          locus disease determination.  The ability of current methods to                  correctly analyze traits with one or more of these factors will be               assessed and, where appropriate, alternative methods will be developed           and tested.  b) Apply techniques of neural network pattern matching to           problems of genetic systems.  Applications include: aid in phenotype             definition for traits with multiple clinical problems of genetic                 systems.  Applications include: aid in phenotype definition for traits           with multiple clinical characteristics; determination of risk of disease         based on phenotype, known risk factors and disease profiles in                   relatives; determination of organ transplant success based on HLA                antigen matching patterns; definition of disease phenotype based on              quantitative factors.  c) Develop and apply strategies for ordering              multiple linked loci using pairwise recombination data, radiation hybrid         data, or other physical mapping data.  Some of these ordering strategies         may be adaptable to the development of techniques for integrating map            information obtained by different methods, an important step in                  organizing a comprehensive, reliable map.  d) Carry out classical                linkage analysis for specific genetic diseases.  Currently, a genome             scan is underway to identify a gene or genes for polycystic liver                disease.  Other diseases to be studied include lymphoma and prostate             cancer. Methods to be tested in the simulation studies can be applied            to these analyses in order to better understand the complete genetic             picture, including identification of heterogeneity, by detecting linkage         of different disease forms to different marker loci. Such                        differentiation will help sharpen the clinical definition of various             forms of the diseases.                                                                                                                                            As a result of advances from this work, better mathematical tools for            the study of diseases with complex or ill-defined inheritance patterns           will be available.  Applications to specific diseases will increase              understanding of interactions between clinical definition and                    predisposing genetic factors.  This will increase the precision of               genetic counseling and suggest useful approaches for studying the                mechanisms involved in determining disease state.                                 n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,6018534,R01GM029177,"['alleles', ' artificial chromosomes', ' artificial intelligence', ' computational neuroscience', ' computer program /software', ' computer simulation', ' family genetics', ' gene expression', ' genetic disorder', ' genetic markers', ' genetic susceptibility', ' histocompatibility antigens', ' human data', ' human genetic material tag', ' linkage mapping', ' liver disorder', ' lymphoma', ' mathematical model', ' model design /development', ' phenotype', ' prostate neoplasms', ' quantitative trait loci', ' sequence tagged sites']",NIGMS,NEW YORK BLOOD CENTER,R01,1999,190226,0.03286328361882904
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims to: a) Improve the understanding of the               genetics of inherited diseases with unclear modes of transmission.               Studies will evaluate the effectiveness of current methods of analysis,          including classical linkage analysis, sib-pair or affected-pedigree-             member analysis and the use of measures of association in understanding          the underlying genetic mechanisms of such traits.  Simulation studies            will continue to provide a source of family data reflecting confounding          factors thought to be a problem in linkage analysis of certain complex           traits, such as psychiatric or behavioral disorders.  Factors to be              considered include assortative mating, genetic heterogeneity and multi-          locus disease determination.  The ability of current methods to                  correctly analyze traits with one or more of these factors will be               assessed and, where appropriate, alternative methods will be developed           and tested.  b) Apply techniques of neural network pattern matching to           problems of genetic systems.  Applications include: aid in phenotype             definition for traits with multiple clinical problems of genetic                 systems.  Applications include: aid in phenotype definition for traits           with multiple clinical characteristics; determination of risk of disease         based on phenotype, known risk factors and disease profiles in                   relatives; determination of organ transplant success based on HLA                antigen matching patterns; definition of disease phenotype based on              quantitative factors.  c) Develop and apply strategies for ordering              multiple linked loci using pairwise recombination data, radiation hybrid         data, or other physical mapping data.  Some of these ordering strategies         may be adaptable to the development of techniques for integrating map            information obtained by different methods, an important step in                  organizing a comprehensive, reliable map.  d) Carry out classical                linkage analysis for specific genetic diseases.  Currently, a genome             scan is underway to identify a gene or genes for polycystic liver                disease.  Other diseases to be studied include lymphoma and prostate             cancer. Methods to be tested in the simulation studies can be applied            to these analyses in order to better understand the complete genetic             picture, including identification of heterogeneity, by detecting linkage         of different disease forms to different marker loci. Such                        differentiation will help sharpen the clinical definition of various             forms of the diseases.                                                                                                                                            As a result of advances from this work, better mathematical tools for            the study of diseases with complex or ill-defined inheritance patterns           will be available.  Applications to specific diseases will increase              understanding of interactions between clinical definition and                    predisposing genetic factors.  This will increase the precision of               genetic counseling and suggest useful approaches for studying the                mechanisms involved in determining disease state.                                 n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,2693221,R01GM029177,"['alleles', ' artificial chromosomes', ' artificial intelligence', ' computational neuroscience', ' computer program /software', ' computer simulation', ' family genetics', ' gene expression', ' genetic disorder', ' genetic markers', ' genetic susceptibility', ' histocompatibility antigens', ' human data', ' human genetic material tag', ' linkage mapping', ' liver disorder', ' lymphoma', ' mathematical model', ' model design /development', ' phenotype', ' prostate neoplasms', ' quantitative trait loci', ' sequence tagged sites']",NIGMS,NEW YORK BLOOD CENTER,R01,1998,185170,0.03286328361882904
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims: to: a) Improve the understanding of the genetics of inherited diseases with unclear modes of transmission.  Studies will evaluate the effectiveness of current methods of analysis, in particular linkage analysis and the use of measures of association, in understanding the underlying genetic mechanisms of such traits.  Simulation studies will be used to generate data reflecting confounding factors thought to be a problem in linkage analysis of certain complex traits (for example psychiatric or behavioral disorders).  Factors to be considered include assortative mating; genetic heterogeneity and trait determination by more than one locus.  The ability of current methods to correctly analyze traits with these characteristics will be assessed and, where found lacking, alternative methods will be developed and tested.  b) Carry out classical linkage analysis for specific genetic diseases.  The diseases to be studied include tuberous sclerosis and Fanconi anemia, where evidence for genetic heterogeneity has already been detected.  Methods to be tested in the simulation studies can be applied to these analyses in order to better understand the complete genetic picture, including identification of heterogeneity by detecting linkage of different disease forms to different marker loci.  Such differentiation will help sharpen the clinical definition of various forms of the diseases.  c) Refine strategies for ordering multiple linked loci on linkage maps using either pairwise recombination data or data generated from radiation hybrid experiments. d) Apply techniques of neural network pattern matching to problems of genetic systems.  Applications include aid in phenotype definition for traits with multiple clinical characteristics, prediction of risk of disease based on phenotype, values of known risk factors and disease profiles in relatives and estimation of missing recombination data in multilocus data sets using information from other linkage relationships.  As a result of advances from this work, better mathematical tools for the study of diseases with complex or ill-defined inheritance patterns will be available.  Applications to specific diseases will increase understanding of interactions between clinical definition and predisposing genetic factors.  This will increase the precision of genetic counseling and suggest useful approaches for studying the mechanisms involved in determining disease state.  n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,2175416,R01GM029177,"[""Fabry's disease"", ' artificial intelligence', ' deToni Fanconi syndrome', ' disease /disorder proneness /risk', ' family genetics', ' genetic markers', ' genetic recombination', ' human genetic material tag', ' linkage mapping', ' mathematical model', ' model design /development', ' phenotype', ' tuberous sclerosis']",NIGMS,NEW YORK BLOOD CENTER,R01,1994,187963,0.028494661934139708
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims: to: a) Improve the understanding of the genetics of inherited diseases with unclear modes of transmission.  Studies will evaluate the effectiveness of current methods of analysis, in particular linkage analysis and the use of measures of association, in understanding the underlying genetic mechanisms of such traits.  Simulation studies will be used to generate data reflecting confounding factors thought to be a problem in linkage analysis of certain complex traits (for example psychiatric or behavioral disorders).  Factors to be considered include assortative mating; genetic heterogeneity and trait determination by more than one locus.  The ability of current methods to correctly analyze traits with these characteristics will be assessed and, where found lacking, alternative methods will be developed and tested.  b) Carry out classical linkage analysis for specific genetic diseases.  The diseases to be studied include tuberous sclerosis and Fanconi anemia, where evidence for genetic heterogeneity has already been detected.  Methods to be tested in the simulation studies can be applied to these analyses in order to better understand the complete genetic picture, including identification of heterogeneity by detecting linkage of different disease forms to different marker loci.  Such differentiation will help sharpen the clinical definition of various forms of the diseases.  c) Refine strategies for ordering multiple linked loci on linkage maps using either pairwise recombination data or data generated from radiation hybrid experiments. d) Apply techniques of neural network pattern matching to problems of genetic systems.  Applications include aid in phenotype definition for traits with multiple clinical characteristics, prediction of risk of disease based on phenotype, values of known risk factors and disease profiles in relatives and estimation of missing recombination data in multilocus data sets using information from other linkage relationships.  As a result of advances from this work, better mathematical tools for the study of diseases with complex or ill-defined inheritance patterns will be available.  Applications to specific diseases will increase understanding of interactions between clinical definition and predisposing genetic factors.  This will increase the precision of genetic counseling and suggest useful approaches for studying the mechanisms involved in determining disease state.  n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,3276698,R01GM029177,"[""Fabry's disease"", ' artificial intelligence', ' deToni Fanconi syndrome', ' disease /disorder proneness /risk', ' family genetics', ' genetic markers', ' genetic recombination', ' human genetic material tag', ' linkage mapping', ' mathematical model', ' model design /development', ' phenotype', ' tuberous sclerosis']",NIGMS,NEW YORK BLOOD CENTER,R01,1993,182788,0.028494661934139708
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims: to: a) Improve the understanding of the genetics of inherited diseases with unclear modes of transmission.  Studies will evaluate the effectiveness of current methods of analysis, in particular linkage analysis and the use of measures of association, in understanding the underlying genetic mechanisms of such traits.  Simulation studies will be used to generate data reflecting confounding factors thought to be a problem in linkage analysis of certain complex traits (for example psychiatric or behavioral disorders).  Factors to be considered include assortative mating; genetic heterogeneity and trait determination by more than one locus.  The ability of current methods to correctly analyze traits with these characteristics will be assessed and, where found lacking, alternative methods will be developed and tested.  b) Carry out classical linkage analysis for specific genetic diseases.  The diseases to be studied include tuberous sclerosis and Fanconi anemia, where evidence for genetic heterogeneity has already been detected.  Methods to be tested in the simulation studies can be applied to these analyses in order to better understand the complete genetic picture, including identification of heterogeneity by detecting linkage of different disease forms to different marker loci.  Such differentiation will help sharpen the clinical definition of various forms of the diseases.  c) Refine strategies for ordering multiple linked loci on linkage maps using either pairwise recombination data or data generated from radiation hybrid experiments. d) Apply techniques of neural network pattern matching to problems of genetic systems.  Applications include aid in phenotype definition for traits with multiple clinical characteristics, prediction of risk of disease based on phenotype, values of known risk factors and disease profiles in relatives and estimation of missing recombination data in multilocus data sets using information from other linkage relationships.  As a result of advances from this work, better mathematical tools for the study of diseases with complex or ill-defined inheritance patterns will be available.  Applications to specific diseases will increase understanding of interactions between clinical definition and predisposing genetic factors.  This will increase the precision of genetic counseling and suggest useful approaches for studying the mechanisms involved in determining disease state.  n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,3276690,R01GM029177,"[""Fabry's disease"", ' artificial intelligence', ' deToni Fanconi syndrome', ' disease /disorder proneness /risk', ' family genetics', ' genetic markers', ' genetic recombination', ' human genetic material tag', ' linkage mapping', ' mathematical model', ' model design /development', ' phenotype', ' tuberous sclerosis']",NIGMS,NEW YORK BLOOD CENTER,R01,1992,184674,0.028494661934139708
"Machine learning for fast motion compensated quantitative abdominal DCE-MRI Project Summary: Functional imaging with dynamic contrast-enhanced MRI (DCE-MRI) provides important physiological markers of permeability, perfusion and glomerular filtration rate (GFR), a measure of kidney function, without exposing patients to ionizing radiation. DCE-MR images are at the same time used for evaluation of anatomy. Functional markers from DCE-MRI, if computed accurately, would play a critical role in diagnosing and assessing the progression of a number of pediatric diseases including those compromising kidney function, liver diseases, tumors, and Crohn's disease. One of the most important applications of DCE-MRI is assessing kidney function (GFR) in hydronephrosis patients with obstruction. In the absence of GFR information, children who stand to benefit from immediate surgical reconstruction might be overlooked or delayed in receiving treatment, and those who might benefit from a more conservative approach (i.e., “watchful waiting”) might receive an unnecessary surgical intervention. While the current reference standard, nuclear renography (MAG3), yields some useful diagnostic information, it is slow, provides low resolution, does not offer anatomic detail, and delivers potentially harmful ionizing radiation. There is a clinical need for accurate computation of quantitative functional markers. Unfortunately, current methods of DCE-MRI in neonates and children are less than optimal, and therefore, DCE-MRI is underutilized in clinical practice. The technical challenges include insufficient temporal resolution to capture fast arterial input function (AIF) dynamics (which are required for accurate computation of quantitative markers), unavoidable respiratory motion and bulk motion (which reduce image quality and significantly lower the accuracy of parameter estimates), and a lack of robust, fast, automated post processing techniques for accurate computation of markers. Thus, there is an urgent, unmet need to develop a motion-compensated, high spatiotemporal resolution DCE-MRI method addressing these challenges. The primary objective of this exploratory, three-year study, is three-fold: first, to develop and evaluate a new bulk and respiratory motion-compensated, high spatiotemporal resolution DCE-MRI technique for accurate estimation of functional markers; second, to further improve the robustness and speed of DCE-MRI using a fast, deep learning (DL) technique with integrated temporal prior for the reconstruction of motion-compensated, higher quality, high temporal resolution images; and third, to develop an automatic quantitative analysis pipeline including segmentation and tracer kinetic model-fitting using DL techniques for fast, robust and accurate quantification of functional markers. The successful completion of these aims will provide new, clinically important abdominal imaging capabilities, with real-time, motion-compensated image reconstruction and reliable real-time parameter estimation from high temporal and spatial resolution DCE-MRI. This work will extend the usefulness of DCE-MRI to pediatric patients who are unable to remain still in the scanner, and eliminate the need for repeated scans and sedation in infants. ! ! Project Narrative: This project addresses the need to develop advanced methods of magnetic resonance imaging (MRI) to provide new, clinically important abdominal imaging capabilities, with real-time, motion-compensated image reconstruction and reliable real-time estimation of clinically important quantitative imaging markers from high temporal and spatial resolution DCE-MRI. These markers will be used to evaluate the extent of several disorders and would play a critical role in diagnosing and assessing the progression of a number of pediatric diseases including those compromising kidney function, liver diseases, tumors, and Crohn's disease. This work will extend the usefulness of DCE-MRI to pediatric patients who are unable to remain still in the scanner, and eliminate the need of repeated scans, sedation and anesthesia when imaging newborns with congenital abnormalities such as congenital hydronephrosis, which if left untreated, can result in permanent damage to the child's kidneys.",Machine learning for fast motion compensated quantitative abdominal DCE-MRI,9957672,R21EB029627,"['Abdomen', 'Address', 'Affect', 'Algorithms', 'Anatomy', 'Anesthesia procedures', 'Breathing', 'Child', 'Childhood', 'Clinical', 'Congenital Abnormality', 'Crohn&apos', 's disease', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Disease', 'Disease Marker', 'Evaluation', 'Failure', 'Financial compensation', 'Functional Imaging', 'Glomerular Filtration Rate', 'Hydronephrosis', 'Image', 'Imaging Techniques', 'Infant', 'Ionizing radiation', 'Kidney', 'Lead', 'Left', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Newborn Infant', 'Nuclear', 'Obstruction', 'Operative Surgical Procedures', 'Organ', 'Patient observation', 'Patients', 'Performance', 'Perfusion', 'Permeability', 'Physiological', 'Play', 'Reference Standards', 'Renal function', 'Resolution', 'Role', 'Scanning', 'Sedation procedure', 'Series', 'Signal Transduction', 'Speed', 'Techniques', 'Time', 'Tracer', 'Ureteropelvic junction obstruction', 'Work', 'analysis pipeline', 'anxious', 'base', 'bulk motion', 'clinical decision-making', 'clinical practice', 'contrast enhanced', 'deep learning', 'image reconstruction', 'imaging biomarker', 'imaging capabilities', 'imaging modality', 'improved', 'kinetic model', 'neonate', 'neural network architecture', 'pediatric patients', 'quantitative imaging', 'radiologist', 'real-time images', 'reconstruction', 'recursive neural network', 'respiratory', 'spatiotemporal', 'temporal measurement', 'time use', 'tumor']",NIBIB,BOSTON CHILDREN'S HOSPITAL,R21,2020,708000,-0.008680740532077624
"NeuroExplorer: Ultra-high Performance Human Brain PET Imager for Highly-resolved In Vivo Imaging of Neurochemistry Research applications of brain Positron Emission Tomography (PET) have been in place for over 40 years. The combination of quantitative PET systems with novel radiotracers has led to a numerous imaging para- digms to understand normal brain physiology including neurotransmitter dynamics and receptor pharmacology at rest and during activation. Brain-dedicated PET systems offer important advantages over currently available PET systems in terms of sensitivity and resolution. However, the state-of-the-art for brain PET has not progressed beyond the 20-year-old HRRT. Therefore, there is a compelling need to build the next generation of brain PET systems for human studies. This proposal brings together a highly experienced collaborative team from Yale, UC Davis, and United Imaging Healthcare America (UIHA). to develop the next generation NeuroEXPLORER (NX) PET system with the following Aims. Specific Aim 1: Design and Build the NeuroEXPLORER: In 2 years, we will complete the design and build the NX system. The design includes high performance LYSO-SiPM blocks with small detectors, 4-mm depth-of-interaction, 250 ps time-of-flight resolution, and axial length of ~50 cm, paired with CT for attenuation correction. This design will produce a factor of 10 greater effective sensitivity than the HRRT and practical resolution of 1.5-2 mm in the human brain. The system will include built-in real-time state-of-art motion tracking cameras and will be tested using novel phantom experiments to assess the full-range of operation to validate the dramatic improvement in small- region precision and accuracy. Specific Aim 2: Algorithm Development for Fully-Quantitative Brain PET. We will develop the novel algorithms for this system. Using EXPLORER experience. we will implement reconstruction algorithms to produce dynamic images with uniform ultra-high resolution in space and time, Extending Yale’s HRRT motion correction experience, we will develop camera-based motion detection and correction algorithms to deliver ultra-high resolution human brain images. Using the carotid artery shape and geometry, we will develop methods to accurately measure blood activity to be compared to human arterial data with the goal to permit kinetic modeling without arterial sampling. We will develop noise reduction methods with machine learning to reduce dose for studying health brains and to eliminate the need for the CT scan for attenuation correction. Specific Aim 3: Human Paradigm Demonstration. With human subjects, we will evaluate specific imaging paradigms to demonstrate the effectiveness of the NX system: 1) demonstration of the dramatic sensitivity increase (with a direct comparison to the HRRT) and its impact on detection of pharmacologic effects, 2) leveraging high sensitivity to reliably measure uptake in small nuclei; and 3) opening new frontiers of imaging neurotransmitter dynamics, including dopamine and opioid release. The ultimate goal is a fully functioning and characterized system that dramatically expands the scope of brain PET protocols and applications. Human research applications of brain Positron Emission Tomography (PET) imaging have been in place for over 40 years and have led to a detailed understand of normal brain physiology including neurotransmitter dynamics and receptor pharmacology at rest and during activation. Brain-dedicated PET systems offer important advantages over currently available PET systems, but the state-of-the-art for brain PET imaging systems has not progressed beyond the 20-year-old HRRT. The proposed next generation NeuroEXPLORER (NX) PET system will have a factor of 10 greater sensitivity and will dramatically expand the scope of human brain PET protocols and applications.",NeuroExplorer: Ultra-high Performance Human Brain PET Imager for Highly-resolved In Vivo Imaging of Neurochemistry,10005604,U01EB029811,"['20 year old', 'Adolescent', 'Algorithms', 'Americas', 'Area', 'Blood', 'Brain', 'Brain imaging', 'Brain scan', 'Carotid Arteries', 'Cell Nucleus', 'Child', 'Clinical', 'Collaborations', 'Data', 'Detection', 'Development', 'Disease', 'Dopamine', 'Dose', 'Effectiveness', 'Enzymes', 'Evaluation', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Healthcare', 'Hippocampus (Brain)', 'Human', 'Image', 'Inferior', 'Length', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Metabolism', 'Methods', 'Midbrain structure', 'Modeling', 'Motion', 'Nerve Degeneration', 'Neurotransmitters', 'Noise', 'Opioid', 'Performance', 'Pharmacology', 'Physics', 'Physiology', 'Positron-Emission Tomography', 'Proteins', 'Protocols documentation', 'Radioactive', 'Research', 'Resolution', 'Rest', 'Sampling', 'Sensory Receptors', 'Shapes', 'Structure', 'Substantia nigra structure', 'Synapses', 'System', 'Technology', 'Testing', 'Thalamic structure', 'Time', 'Tracer', 'X-Ray Computed Tomography', 'algorithm development', 'attenuation', 'base', 'body system', 'brain health', 'data quality', 'density', 'design', 'detector', 'experience', 'experimental study', 'frontier', 'human subject', 'imager', 'imaging system', 'improved', 'in vivo imaging', 'kinetic model', 'locus ceruleus structure', 'neurochemistry', 'neurotransmitter release', 'next generation', 'novel', 'operation', 'pre-clinical', 'radiotracer', 'raphe nuclei', 'receptor', 'reconstruction', 'solid state', 'statistics', 'ultra high resolution', 'uptake']",NIBIB,YALE UNIVERSITY,U01,2020,1700000,0.018503175338911156
"Center for Mesoscale Mapping Overview of the Proposed Resource – Abstract The goal of the Center for Mesoscale Mapping is to drive the convergence of microscopic- and macroscopic- scale evaluation of brain structure and function for human translational neuroscience, by developing and applying tools to study the spatial distribution and temporal orchestration of mesoscopic events in the human brain. Our Collaborators will, through a dynamic “push-pull” relationship, provide unique problems which drive the development of these tools, and in return guide us in the design and optimization of our toolbox for practical use in a variety of normal and disease settings. While there is still no formal consensus on the definition of mesoscopic within the neuroscience community, we take as our guide the spatial and temporal scales at which local groups of neurons act in coherent fashion – in the cortex, this includes the spatial scale of columns and laminar structures (between ~0.1-1 mm), while in deeper structures includes the myriad of deep brain and brainstem nuclei. Preliminary data from our own center, and of course others throughout the world, now support the notion that we are on the threshold of being able to map, measure and perturb the human brain at these scales, and do so comprehensively across wide swaths of the human brain. Temporally too, recent advances suggest a convergence between temporal scales addressable with tools like fMRI, which can now investigate delta frequency coherent phenomena, and advanced electromagnetic tools to measure and perturb coherent electrophysiological activity at higher frequencies still. With this convergence in mind, the tools we proposed to develop within the TRDs of the CMM will provide our Collaborative and Service User community with the important “missing links” between the advances in human cognitive neuroscience at the “system level,” and the enormous strides in cellular level circuit functional characterization. Our Collaborators will bring their own unique challenges to help us define and further refine these tools, offering problems requiring distinct measures of human brain structural and functional properties in a variety of normal and disease settings. Our Service Users will utilize our tools to better understand human neural systems, and particularly human disease states from multiple sclerosis to Alzheimer’s, to depression and epilepsy. Finally, our Center will seek to disseminate these tools, through open-source software and hardware designs, industrial partnerships and “hands-on” teaching courses for hardware, and to train a new generation of human neuroscientists in the use of our advanced tools to explore the human brain at this next frontier. Overview of the Proposed Resource – Narrative The goal of the Center for Mesoscale Mapping is to drive the convergence of microscopic- and macroscopic- scale evaluation of brain structure and function for human translational neuroscience, by developing and applying tools to study the spatial distribution and temporal orchestration of mesoscopic events in the human brain. Our Collaborators will, through a dynamic “push-pull” relationship, provide unique problems which drive the development of these tools, and in return guide us in the design and optimization of our toolbox for practical use in a variety of normal and disease settings.",Center for Mesoscale Mapping,10038177,P41EB030006,"['3-Dimensional', 'Acceleration', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Basic Science', 'Biological', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cerebral Palsy', 'Communities', 'Computer Models', 'Computer software', 'Consensus', 'Data', 'Data Set', 'Development', 'Devices', 'Diffusion', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Electroencephalography', 'Electromagnetics', 'Electrophysiology (science)', 'Epilepsy', 'Evaluation', 'Event', 'Fiber', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Generations', 'Goals', 'Histologic', 'Human', 'Image', 'Investigation', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Mental Depression', 'Mental disorders', 'Microscopic', 'Mind', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Motion', 'Multiple Sclerosis', 'Neurons', 'Neurosciences', 'Online Systems', 'Performance', 'Peripheral Nerve Stimulation', 'Property', 'Publications', 'Research Personnel', 'Resolution', 'Resources', 'Respiration', 'Scanning', 'Services', 'Signal Transduction', 'Sleep Disorders', 'Slice', 'Space Models', 'Spatial Distribution', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Training Programs', 'Transcranial magnetic stimulation', 'Visualization', 'Work', 'base', 'cognitive neuroscience', 'data space', 'deep learning', 'design', 'electric field', 'frontier', 'human disease', 'human imaging', 'improved', 'in vivo', 'industry partner', 'instrumentation', 'machine learning algorithm', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'post-doctoral training', 'pre-doctoral', 'reconstruction', 'relating to nervous system', 'response', 'spatiotemporal', 'tool', 'tool development', 'translational neuroscience', 'usability', 'white matter']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,P41,2020,1731501,0.010454935826938561
"Next-Generation Ultrasound Localization Microscopy Project Summary/Abstract Abnormal alterations of tissue microcirculation are often associated with early stage of tissue pathology. Detection and characterization of these early microvascular abnormalities can greatly benefit clinical diagnosis and treatment monitoring as well as facilitating the creation of new therapies to counter disease development. For decades, there has been a longstanding quest for the development of a clinical imaging modality that can noninvasively and directly image such tissue microvascular variations. To date, however, such an imaging method remains elusive due to the fundamental compromise between imaging spatial resolution and depth penetration. Therefore, the long-term objective of this project is to fulfill this unmet clinical need by developing the next-generation ultrasound localization microscopy (ULM), which is an ultrasound-based imaging technique that can directly assess structural and functional tissue microvasculature in vivo in humans at a clinically relevant depth. Different from other imaging modalities, ULM is not limited by the resolution-penetration compromise: ULM can noninvasively image capillary-scale microvessels at several centimeters depth and quantitatively measure their blood flow speed (as low as 1 mm/s). Such combination of deep imaging penetration and exquisite spatial resolution and the unique functionality of measuring small vessel blood flow speed make ULM a promising technique for many clinical applications including cancer and cardiovascular diseases. At present, however, ULM is not ready for clinical use due to several key technical limitations: 1) ULM data acquisition is very slow (tens of seconds with breath holding); 2) ULM post-processing is very expensive computationally (several hours to generate a single 2D ULM image); 3) ULM is difficult to be extended to 3D imaging (which is important for comprehensive evaluation of tissue microvasculature such as in cancer applications). These limitations largely forbids ULM from being effectively used in the clinic to provide useful microvascular biomarkers. In this proposal, we will concentrate on addressing these technical barriers and transform ULM to a truly useful clinical imaging tool. Our approach synergistically combines deep learning (DL), parallel computing, and ultrafast 3D ultrasound imaging to fundamentally shorten ULM data acquisition time, substantially accelerate ULM post-processing, and enhance ULM to 3D imaging. Our first aim will develop and validate DL-based ULM data processing algorithms that would enable real-time 4D morphometric ULM and fast 3D quantitative ULM. Our method uniquely collects real labeled optical imaging data on a chicken embryo microvessel model for DL training. Our second aim will focus on realizing 3D-ULM on a 2D row-column-addressing transducer with ultrafast 3D plane wave imaging. We will develop a DL-based beamforming technique to enable high-fidelity 3D microbubble imaging for robust 3D-ULM. Our final aim will focus on validating the in vivo performance of the newly developed 3D-ULM imaging techniques on a mouse tumor model. We will be collaborating with world-renowned experts in deep learning, optical imaging, and comparative medicine at the University of Illinois to accomplish these aims of the proposal. Project Narrative Imaging-based detection and characterization of abnormal tissue microvascular variations is clinically significant for diagnosis, treatment evaluation, and therapy development in many pathologies such as cancer, cardiovascular diseases, inflammation, and neurodegenerative diseases. At present, there is no viable noninvasive imaging tool that can fulfill this important clinical need. To fill this gap, we propose to develop a new ultrasound-based super-resolution microvessel imaging technique that can directly and quantitatively assess the structure and the function of tissue microcirculation in vivo in humans.",Next-Generation Ultrasound Localization Microscopy,10039725,R21EB030072,"['3-Dimensional', '3D ultrasound', '4T1', 'Address', 'Adopted', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Biological Markers', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Breast Carcinoma', 'Cardiovascular Diseases', 'Chickens', 'Clinic', 'Clinical', 'Clinical Treatment', 'Complex', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Embryo', 'Evaluation', 'Goals', 'Health', 'Hour', 'Human', 'Illinois', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging Techniques', 'Incentives', 'Inflammation', 'Knowledge', 'Label', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medicine', 'Metabolic', 'Methods', 'Microbubbles', 'Microcirculation', 'Microscopy', 'Modality', 'Modeling', 'Modification', 'Monitor', 'Morphologic artifacts', 'Mus', 'Neurodegenerative Disorders', 'Noise', 'Nutrient', 'Organ', 'Oxygen', 'Pathogenesis', 'Pathology', 'Patients', 'Penetration', 'Performance', 'Property', 'Provider', 'Resolution', 'Series', 'Signal Transduction', 'Skin', 'Speed', 'Structure', 'Surface', 'Techniques', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Transducers', 'Transportation', 'Ultrasonic Transducer', 'Ultrasonography', 'Universities', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically relevant', 'clinically significant', 'comparative', 'computerized data processing', 'cost', 'data acquisition', 'deep learning', 'deep neural network', 'hemodynamics', 'imaging detection', 'imaging modality', 'in vivo', 'in vivo imaging', 'innovation', 'instrumentation', 'microCT', 'microscopic imaging', 'next generation', 'non-invasive imaging', 'novel', 'novel therapeutics', 'optical imaging', 'parallel computer', 'performance tests', 'quantitative ultrasound', 'real-time images', 'therapy development', 'tool', 'tumor', 'two photon microscopy']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,565346,-0.01614906894240515
"Computer Studies of Protein Structure and Function DESCRIPTION (provided by applicant): The research described in the current proposal has the long-range goals of enabling the prediction of protein-protein interactions and the application of this knowledge to problems of biomedical relevance. An additional long-term goal is the fuller integration of Structural and Systems Biology. Specific Aims include: a) The development of three-dimensional structure-based methods to predict, on a genome-wide scale, whether and how two proteins interact. b) The integration of structural information with other sources of evidence as to protein-protein interactions. c) The application of the methods being developed to important biomedical problems. These research goals are motivated by a number of factors. First, cellular function is mediated by tens or even hundreds of thousands of protein-protein interactions yet these are generally hard to predict in advance or to measure accurately with high-throughput experimental techniques. A method that allows the computational prediction of such interactions would thus be of significant impact. Second, there are many more protein sequences than protein structures so it is necessary to find ways to amplify the information in protein databases if structure is to be fully integrated in genome scale research. The proposed research is intended to bridge this gap.  A central element of the approach to be taken is the use of structural alignments to reveal novel functional relationships between proteins. Since structure is better conserved than sequence, these alignments can reveal new information. A novel structure-based method is introduced which exploits homology models and remote geometric relationships to amplify structural information. The evidence that is obtained is then combined with non-structural sources of evidence using Bayesian networks to yield a probability of whether two proteins interact. An important element in the proposed research strategy is the recognition that structural modeling on a large scale is necessarily imprecise so that it is necessary to use low resolution ""scoring functions for a given model that do not depend sensitively on atomic detail. Bayesian methods then allow the extraction of a clear signal from the underlying noise.  The biological impact of the research will be enhanced through computational/experimental applications in areas where structural clues have the potential of discovering truly novel interactions. Validated predictions on adhesion proteins, nuclear hormone receptors and cytokine signaling proteins demonstrate the efficacy of the methodology. New applications to viral host interactions and to cancer signaling pathways are described. PUBLIC HEALTH RELEVANCE: The health relatedness of the proposed research arises from the fact that a better understanding of protein- protein interactions opens the way to a better understanding of the biology underlying human disease. Applications to interactions involved in viral-host interactions, and in cancer-related pathways serve to highlight this aspect of the proposed research.",Computer Studies of Protein Structure and Function,8972013,R01GM030518,"['Adhesions', 'Amino Acid Sequence', 'Area', 'Bayesian Method', 'Binding', 'Biological', 'Biology', 'Birds', 'Cell physiology', 'Chromosomes', 'Collaborations', 'Complex', 'Conserved Sequence', 'Cytokine Signaling', 'Data', 'Databases', 'Development', 'Elements', 'Epigenetic Process', 'Family', 'Family suidae', 'Funding', 'Gene Fusion', 'Genetic screening method', 'Genome', 'Goals', 'Health', 'Homology Modeling', 'Human', 'Human Genome', 'Indium', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Noise', 'Nuclear Hormone Receptors', 'Pathway interactions', 'Peptide Sequence Determination', 'Peptides', 'Phylogenetic Analysis', 'Probability', 'Process', 'Protein Region', 'Protein Structure Databases', 'Proteins', 'RNA Interference', 'Research', 'Resolution', 'Sequence Alignment', 'Sequence Homology', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Signaling Protein', 'Site', 'Source', 'Specificity', 'Structural Models', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Tropism', 'Viral', 'Viral Proteins', 'Virus', 'Work', 'Yeasts', 'base', 'computer based statistical methods', 'computer infrastructure', 'computer studies', 'computerized tools', 'design', 'genome-wide', 'human disease', 'improved', 'influenzavirus', 'innovation', 'interest', 'method development', 'novel', 'predictive tools', 'programs', 'protein complex', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'success', 'three dimensional structure', 'tool', 'tumor progression', 'tumorigenesis', 'virus host interaction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2016,292404,0.010148455772555577
"Computer Studies of Protein Structure and Function DESCRIPTION (provided by applicant): The research described in the current proposal has the long-range goals of enabling the prediction of protein-protein interactions and the application of this knowledge to problems of biomedical relevance. An additional long-term goal is the fuller integration of Structural and Systems Biology. Specific Aims include: a) The development of three-dimensional structure-based methods to predict, on a genome-wide scale, whether and how two proteins interact. b) The integration of structural information with other sources of evidence as to protein-protein interactions. c) The application of the methods being developed to important biomedical problems. These research goals are motivated by a number of factors. First, cellular function is mediated by tens or even hundreds of thousands of protein-protein interactions yet these are generally hard to predict in advance or to measure accurately with high-throughput experimental techniques. A method that allows the computational prediction of such interactions would thus be of significant impact. Second, there are many more protein sequences than protein structures so it is necessary to find ways to amplify the information in protein databases if structure is to be fully integrated in genome scale research. The proposed research is intended to bridge this gap.  A central element of the approach to be taken is the use of structural alignments to reveal novel functional relationships between proteins. Since structure is better conserved than sequence, these alignments can reveal new information. A novel structure-based method is introduced which exploits homology models and remote geometric relationships to amplify structural information. The evidence that is obtained is then combined with non-structural sources of evidence using Bayesian networks to yield a probability of whether two proteins interact. An important element in the proposed research strategy is the recognition that structural modeling on a large scale is necessarily imprecise so that it is necessary to use low resolution ""scoring functions for a given model that do not depend sensitively on atomic detail. Bayesian methods then allow the extraction of a clear signal from the underlying noise.  The biological impact of the research will be enhanced through computational/experimental applications in areas where structural clues have the potential of discovering truly novel interactions. Validated predictions on adhesion proteins, nuclear hormone receptors and cytokine signaling proteins demonstrate the efficacy of the methodology. New applications to viral host interactions and to cancer signaling pathways are described. PUBLIC HEALTH RELEVANCE: The health relatedness of the proposed research arises from the fact that a better understanding of protein- protein interactions opens the way to a better understanding of the biology underlying human disease. Applications to interactions involved in viral-host interactions, and in cancer-related pathways serve to highlight this aspect of the proposed research.",Computer Studies of Protein Structure and Function,8773597,R01GM030518,"['Adhesions', 'Amino Acid Sequence', 'Area', 'Bayesian Method', 'Binding', 'Biological', 'Biology', 'Birds', 'Cell physiology', 'Chromosomes', 'Collaborations', 'Complex', 'Conserved Sequence', 'Cytokine Signaling', 'Data', 'Databases', 'Development', 'Elements', 'Epigenetic Process', 'Family', 'Family suidae', 'Funding', 'Gene Fusion', 'Genetic screening method', 'Genome', 'Goals', 'Health', 'Homology Modeling', 'Human', 'Human Genome', 'Indium', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Noise', 'Nuclear Hormone Receptors', 'Pathway interactions', 'Peptide Sequence Determination', 'Peptides', 'Phylogenetic Analysis', 'Probability', 'Process', 'Protein Region', 'Protein Structure Databases', 'Proteins', 'RNA Interference', 'Research', 'Resolution', 'Sequence Alignment', 'Sequence Homology', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Signaling Protein', 'Site', 'Source', 'Specificity', 'Structural Models', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Tropism', 'Viral', 'Viral Proteins', 'Virus', 'Work', 'Yeasts', 'base', 'computer based statistical methods', 'computer infrastructure', 'computer studies', 'computerized tools', 'design', 'genome-wide', 'human disease', 'improved', 'influenzavirus', 'innovation', 'interest', 'method development', 'novel', 'programs', 'protein complex', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'success', 'three dimensional structure', 'tool', 'tumor progression', 'tumorigenesis', 'virus host interaction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2015,291815,0.010148455772555577
"Computer Studies of Protein Structure and Function     DESCRIPTION (provided by applicant): The research described in the current proposal has the long-range goals of enabling the prediction of protein-protein interactions and the application of this knowledge to problems of biomedical relevance. An additional long-term goal is the fuller integration of Structural and Systems Biology. Specific Aims include: a) The development of three-dimensional structure-based methods to predict, on a genome-wide scale, whether and how two proteins interact. b) The integration of structural information with other sources of evidence as to protein-protein interactions. c) The application of the methods being developed to important biomedical problems. These research goals are motivated by a number of factors. First, cellular function is mediated by tens or even hundreds of thousands of protein-protein interactions yet these are generally hard to predict in advance or to measure accurately with high-throughput experimental techniques. A method that allows the computational prediction of such interactions would thus be of significant impact. Second, there are many more protein sequences than protein structures so it is necessary to find ways to amplify the information in protein databases if structure is to be fully integrated in genome scale research. The proposed research is intended to bridge this gap.  A central element of the approach to be taken is the use of structural alignments to reveal novel functional relationships between proteins. Since structure is better conserved than sequence, these alignments can reveal new information. A novel structure-based method is introduced which exploits homology models and remote geometric relationships to amplify structural information. The evidence that is obtained is then combined with non-structural sources of evidence using Bayesian networks to yield a probability of whether two proteins interact. An important element in the proposed research strategy is the recognition that structural modeling on a large scale is necessarily imprecise so that it is necessary to use low resolution ""scoring functions for a given model that do not depend sensitively on atomic detail. Bayesian methods then allow the extraction of a clear signal from the underlying noise.  The biological impact of the research will be enhanced through computational/experimental applications in areas where structural clues have the potential of discovering truly novel interactions. Validated predictions on adhesion proteins, nuclear hormone receptors and cytokine signaling proteins demonstrate the efficacy of the methodology. New applications to viral host interactions and to cancer signaling pathways are described.         PUBLIC HEALTH RELEVANCE: The health relatedness of the proposed research arises from the fact that a better understanding of protein- protein interactions opens the way to a better understanding of the biology underlying human disease. Applications to interactions involved in viral-host interactions, and in cancer-related pathways serve to highlight this aspect of the proposed research.            ",Computer Studies of Protein Structure and Function,8588329,R01GM030518,"['Adhesions', 'Amino Acid Sequence', 'Area', 'Bayesian Method', 'Binding', 'Biological', 'Biology', 'Birds', 'Cell physiology', 'Chromosomes', 'Collaborations', 'Complex', 'Conserved Sequence', 'Cytokine Signaling', 'Data', 'Databases', 'Development', 'Elements', 'Epigenetic Process', 'Family', 'Family suidae', 'Funding', 'Gene Fusion', 'Genetic screening method', 'Genome', 'Goals', 'Health', 'Homology Modeling', 'Human', 'Human Genome', 'Indium', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Noise', 'Nuclear Hormone Receptors', 'Pathway interactions', 'Peptide Sequence Determination', 'Peptides', 'Phylogenetic Analysis', 'Probability', 'Process', 'Protein Region', 'Protein Structure Databases', 'Proteins', 'RNA Interference', 'Research', 'Resolution', 'Sequence Alignment', 'Sequence Homology', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Signaling Protein', 'Site', 'Source', 'Specificity', 'Structural Models', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Tropism', 'Viral', 'Viral Proteins', 'Virus', 'Work', 'Yeasts', 'base', 'computer based statistical methods', 'computer infrastructure', 'computer studies', 'computerized tools', 'design', 'genome-wide', 'human disease', 'improved', 'influenzavirus', 'innovation', 'interest', 'method development', 'novel', 'programs', 'protein complex', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'public health relevance', 'success', 'three dimensional structure', 'tool', 'tumor progression', 'tumorigenesis', 'virus host interaction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2014,291243,0.010148455772555577
"Computer Studies of Protein Structure and Function     DESCRIPTION (provided by applicant): The research described in the current proposal has the long-range goals of enabling the prediction of protein-protein interactions and the application of this knowledge to problems of biomedical relevance. An additional long-term goal is the fuller integration of Structural and Systems Biology. Specific Aims include: a) The development of three-dimensional structure-based methods to predict, on a genome-wide scale, whether and how two proteins interact. b) The integration of structural information with other sources of evidence as to protein-protein interactions. c) The application of the methods being developed to important biomedical problems. These research goals are motivated by a number of factors. First, cellular function is mediated by tens or even hundreds of thousands of protein-protein interactions yet these are generally hard to predict in advance or to measure accurately with high-throughput experimental techniques. A method that allows the computational prediction of such interactions would thus be of significant impact. Second, there are many more protein sequences than protein structures so it is necessary to find ways to amplify the information in protein databases if structure is to be fully integrated in genome scale research. The proposed research is intended to bridge this gap.  A central element of the approach to be taken is the use of structural alignments to reveal novel functional relationships between proteins. Since structure is better conserved than sequence, these alignments can reveal new information. A novel structure-based method is introduced which exploits homology models and remote geometric relationships to amplify structural information. The evidence that is obtained is then combined with non-structural sources of evidence using Bayesian networks to yield a probability of whether two proteins interact. An important element in the proposed research strategy is the recognition that structural modeling on a large scale is necessarily imprecise so that it is necessary to use low resolution ""scoring functions for a given model that do not depend sensitively on atomic detail. Bayesian methods then allow the extraction of a clear signal from the underlying noise.  The biological impact of the research will be enhanced through computational/experimental applications in areas where structural clues have the potential of discovering truly novel interactions. Validated predictions on adhesion proteins, nuclear hormone receptors and cytokine signaling proteins demonstrate the efficacy of the methodology. New applications to viral host interactions and to cancer signaling pathways are described.         PUBLIC HEALTH RELEVANCE: The health relatedness of the proposed research arises from the fact that a better understanding of protein- protein interactions opens the way to a better understanding of the biology underlying human disease. Applications to interactions involved in viral-host interactions, and in cancer-related pathways serve to highlight this aspect of the proposed research.            ",Computer Studies of Protein Structure and Function,8437358,R01GM030518,"['Adhesions', 'Amino Acid Sequence', 'Area', 'Bayesian Method', 'Binding', 'Biological', 'Biology', 'Birds', 'Cell physiology', 'Chromosomes', 'Collaborations', 'Complex', 'Conserved Sequence', 'Cytokine Signaling', 'Data', 'Databases', 'Development', 'Elements', 'Epigenetic Process', 'Family', 'Family suidae', 'Funding', 'Fungal Genome', 'Gene Fusion', 'Genetic screening method', 'Genome', 'Goals', 'Health', 'Homology Modeling', 'Human', 'Human Genome', 'Indium', 'Influenza', 'Influenza A Virus, H1N1 Subtype', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Noise', 'Nuclear Hormone Receptors', 'Pathway interactions', 'Peptide Sequence Determination', 'Peptides', 'Phylogenetic Analysis', 'Probability', 'Process', 'Protein Region', 'Protein Structure Databases', 'Proteins', 'RNA Interference', 'Research', 'Resolution', 'Sequence Alignment', 'Sequence Homology', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Signaling Protein', 'Site', 'Source', 'Specificity', 'Structural Models', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Tropism', 'Viral', 'Viral Proteins', 'Virus', 'Work', 'base', 'computer based statistical methods', 'computer infrastructure', 'computer studies', 'computerized tools', 'design', 'genome-wide', 'human disease', 'improved', 'influenzavirus', 'innovation', 'interest', 'method development', 'novel', 'programs', 'protein complex', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure function', 'public health relevance', 'success', 'three dimensional structure', 'tool', 'tumor progression', 'tumorigenesis', 'virus host interaction']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2013,290550,0.010148455772555577
"A database for high-resolution chromatin contact maps and human genetic variants Abstract After the completion of the Human Genome Project, several landmarking consortia have accumulated large amounts of genomic data towards understanding the functions of human genome. The ENCODE project has annotated genome-wide regulatory elements. The Roadmap Epigenomic project has characterized tissue-speciﬁc variation in epigenetic state. The NIH Common Fund GTEx project has delineated tissue-speciﬁc gene expression and transcription regulation. The NIH Common Fund 4D Nucleome (4DN) project has revealed dynamic 3D chromatin organization in many cell and tissue types. Each of the aforementioned consortia has generated thousands or even tens of thousands of datasets, and provided different insights regarding human genome at an unprecedent scale and depth. However, the datasets generated from these consortia are isolated in terms of cell types and tissue types covered, how the data are stored, and the resolution of the genomic data. These gaps bring realistic data analysis challenges to biomedical researchers when they use these public datasets jointly in their research — they need to go through different data portals with heterogeneous processing pipelines, different data formats, and unmatched resolutions. We aim to develop the most cutting-edge deep learning approaches to impute high-resolution chromatin contact maps, and integrate the high-resolution chromatin contact maps with transcriptional data available from GTEx project and epigenomic data from ENCODE/Roadmap. We plan to share the integrated data on a public web server with a multi-panel interactive visualization genome browser. The integrated data will provide an important resource for understanding of tissue-speciﬁc genetic variation in the light of the spatial organization of these genomic and epigenomic elements and their functional implications. Project Narrative The goal of this project is to develop novel computational methods to integrate 4DN datasets with GTEx datasets and ENCODE/Roadmap datasets. The integrated datasets will be critical resource to unveil the mechanisms of the genetic variants identiﬁed in genome-wide association studies. The new knowledge gained here could help us understand the genetic basis of many human diseases.",A database for high-resolution chromatin contact maps and human genetic variants,10109293,R03OD030599,"['3-Dimensional', 'Address', 'Area', 'Base Pairing', 'Cells', 'Chromatin', 'Chromatin Structure', 'Communities', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Elements', 'Epigenetic Process', 'Funding', 'Gene Expression Regulation', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Internet', 'Knowledge', 'Maps', 'Molecular', 'Nucleosomes', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Technology', 'Tissue-Specific Gene Expression', 'Tissues', 'Transcriptional Regulation', 'United States National Institutes of Health', 'Variant', 'Visualization', 'Work', 'cell type', 'data format', 'data integration', 'data portal', 'data resource', 'data visualization', 'deep learning', 'epigenomics', 'expectation', 'genetic variant', 'genome annotation', 'genome browser', 'genome sciences', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'insight', 'interest', 'next generation sequencing', 'novel', 'open data', 'web server']",OD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2020,265495,-0.031979939287187384
"Expanding field-of-view with reduced tissue displacement in micro-endoscopic computational imaging PROJECT SUMMARY Optical imaging methods are well-established in neuroscience, but high-speed, high- resolution volumetric imaging of neural activity in deep tissue remains a challenge. A number of techniques address limited aspects of this goal, and most are applicable primarily to acute preparations. We propose to develop and test a novel approach to achieve three-dimensional “deep-tissue” imaging for high spatial and temporal resolution neural recording by combining aspects of embedded optical probes with computational imaging techniques. Rather than use a single micro-endoscopic probe, we propose to utilize an array of narrower probes, or optrodes, to reduce the volume of tissue displacement. Computational imaging through each probe can be performed to achieve a field of view (FOV) at a desired distance from the probe tip. Combining the fields of view from multiple probes arranged in an array then provides a composite image field that is much larger than achievable from a single micro-endoscope. In our approach, each ∼0.1 mm diameter probe of the array acts as an independent micro- endoscope. In order to achieve full-field imaging across the array, the individual fields must intersect, and the computational method must be scaled to accommodate, and stitch, multiple fields. In pursuit of these goals, we propose three Aims: Optimizing the FOV of a single micro-endoscope - The purpose of this Aim is to characterize the FOV for an individual probe at multiple depths, and optimize the FOV to about 0.3mm through control over the shape of the probe tip and light collection numerical aperture. Accelerating calibration and reconstruction - In this Aim, we will pursue efficient computational approaches for calibration based upon ray-tracing simulations and image reconstruction based on deep learning. Scaling the FOV with an endoscope array - The computational image reconstruction method will be scaled to accommodate small micro-endoscope arrays (e.g. 4 element) arranged in a hexagonal lattice with FOV of 0.6mm at a 1.5mm depth. NARRATIVE Imaging deep inside tissue, including the brain, is critical to understanding various biological processes. Doing so through a small probe is also of primary importance for minimizing tissue damage. In this proposal, we apply computational techniques to create fluorescent images using an array of microscopic glass needles to guide light in and out of a mouse brain. The simplicity and small footprint of our system have the potential for deep-brain imaging (depths > 1.5 mm) across a large (mm) field of view, which should enable a wide variety of biological and neuroscience studies in the future.",Expanding field-of-view with reduced tissue displacement in micro-endoscopic computational imaging,9829467,R21EY030717,"['3-Dimensional', 'Acute', 'Address', 'Biological', 'Biological Process', 'Brain', 'Brain imaging', 'Caliber', 'Calibration', 'Collection', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Confocal Microscopy', 'Coupled', 'Devices', 'Dimensions', 'Elements', 'Endoscopes', 'Fluorescence Microscopy', 'Fluorescent Probes', 'Future', 'Glass', 'Goals', 'Head', 'Holography', 'Image', 'Imaging Techniques', 'Individual', 'Light', 'Methods', 'Microscope', 'Microscopic', 'Microscopy', 'Miniaturization', 'Mus', 'Needles', 'Neurosciences', 'Optics', 'Penetration', 'Preparation', 'Resolution', 'Risk', 'Running', 'Scanning', 'Shapes', 'Source', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Work', 'absorption', 'adaptive optics', 'attenuation', 'base', 'cost', 'deep learning', 'fluorescence imaging', 'image reconstruction', 'imaging modality', 'improved', 'in vivo', 'interest', 'lens', 'microendoscope', 'multi-photon', 'neural circuit', 'novel strategies', 'optical fiber', 'optical imaging', 'reconstruction', 'relating to nervous system', 'retinal rods', 'simulation', 'temporal measurement']",NEI,UNIVERSITY OF UTAH,R21,2019,456800,0.01272029894538556
"Development of Hardware and Software for Clinical MEG The ongoing objective of our research, since the establishment of the HFH MEG Lab, has been to develop hardware, software, and techniques to expand the utility of Magnetoencephalography (MEG), both as a clinical diagnostic tool, and as a modality for basic neuroscience studies. With the proliferation of MEGsys- tems both in the U.S. and worldwide, and the availability of CPT codes for some clinical MEG studies, the development of new and more effective clinical applications to enable users to more fully exploit these costly systems has become our highest priority. Accordingly we are developing new analytical tools and demon- strating that MEG data contains much more clinically useful information than can be found using only the usual dipole techniques. For example, the integration of our Multi Resolution FOCUSS with Principal Com- ponent Analysis (PCA)or Singular Value Decomposition (SVD) shows promise of enhanced computational efficiency and the ability to identify regions of high brain coherence indicative of epileptic tissue. During the proposed grant, these new techniques will be further developed and applied to neurologic and learning dis- orders. In Specific Aim One, interoperative source confirmation will be compared to results of our mapping techniques. DC-MEG will be used to monitor interictal cortical excitability in migraine patients and how this excitability responds to anti-migraine medications. Determination of focal secondary generalized epileptic activity may be used to predict successful surgical resections. In Specific Aim Two we propose to continue the development of new analytical tools and to make them available to the MEG community on the Internet as they become validated. In particular, we will add new functionality to our ""MEG Tools"" software suite by incorporating ICA, Frequency Analysis, and MEG co-registration with Diffusion Tensor Imaging (DTI). In Specific Aim Three, our new techniques will be applied to imaging differences in cortical activation between normal readers and individuals with learning disorders during reading tasks. These techniques will be used to map various cortical areas activated by auditory and visual lexical stimuli, and to differentiate the re- sponses of normal and reading disabled individuals. The exquisite temporal and spatial resolution of MEG, enhanced by these new imaging techniques, will provide clinicians and researchers new noninvasive meth- ods to investigate pathological and normal neurological functioning. n/a",Development of Hardware and Software for Clinical MEG,7361358,R01NS030914,"['Ache', 'Area', 'Auditory', 'Brain', 'Brain imaging', 'Brain region', 'Characteristics', 'Clinical', 'Communities', 'Complex', 'Computer information processing', 'Computer software', 'Current Procedural Terminology Codes', 'Data', 'Detection', 'Development', 'Developmental reading disorder', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Disabled Persons', 'Disease', 'Doctor of Philosophy', 'Dyslexia', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Excision', 'Fiber', 'Frequencies', 'Grant', 'Hearing', 'Image', 'Imaging Techniques', 'Implant', 'Individual', 'Internet', 'Knowledge', 'Language', 'Learning', 'Learning Disorders', 'Link', 'Localized', 'Location', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maps', 'Migraine', 'Modality', 'Modeling', 'Monitor', 'Nervous System Physiology', 'Neurologic', 'Neurons', 'Neurosciences', 'Noise', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Principal Component Analysis', 'Purpose', 'Reader', 'Reading', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Seizures', 'Semantic memory', 'Series', 'Signal Transduction', 'Software Tools', 'Source', 'Stimulus', 'Surgeon', 'System', 'Techniques', 'Time', 'Tissues', 'Visual', 'Word Processing', 'Writing', 'analytical tool', 'base', 'clinical application', 'density', 'human prostaglandin D2 receptor', 'improved', 'lexical', 'magnetic field', 'programs', 'prophylactic', 'research clinical testing', 'response', 'technique development', 'tool']",NINDS,HENRY FORD HEALTH SYSTEM,R01,2008,565393,0.0020773245531149373
"Development of Hardware and Software for Clinical MEG    DESCRIPTION (provided by applicant): The ongoing objective of our research, since the establishment of the HFH MEG Lab, has been to develop hardware, software, and techniques to expand the utility of Magnetoencephalography (MEG), both as a clinical diagnostic tool, and as a modality for basic neuroscience studies. With the proliferation of MEG sys- tems both in the U.S. and worldwide, and the availability of CPT codes for some clinical MEG studies, the development of new and more effective clinical applications to enable users to more fully exploit these costly systems has become our highest priority. Accordingly we are developing new analytical tools and demon- strating that MEG data contains much more clinically useful information than can be found using only the usual dipole techniques. For example, the integration of our Multi Resolution FOCUSS with Principal Com- ponent Analysis (PCA) or Singular Value Decomposition (SVD) shows promise of enhanced computational efficiency and the ability to identify regions of high brain coherence indicative of epileptic tissue. During the proposed grant, these new techniques will be further developed and applied to neurologic and learning dis- orders. In Specific Aim One, interoperative source confirmation will be compared to results of our mapping techniques. DC-MEG will be used to monitor interictal cortical excitability in migraine patients and how this excitability responds to anti-migraine medications. Determination of focal secondary generalized epileptic activity may be used to predict successful surgical resections. In Specific Aim Two we propose to continue the development of new analytical tools and to make them available to the MEG community on the Internet as they become validated. In particular, we will add new functionality to our ""MEG Tools"" software suite by incorporating ICA, Frequency Analysis, and MEG co-registration with Diffusion Tensor Imaging (DTI). In Specific Aim Three, our new techniques will be applied to imaging differences in cortical activation between normal readers and individuals with learning disorders during reading tasks. These techniques will be used to map various cortical areas activated by auditory and visual lexical stimuli, and to differentiate the re- sponses of normal and reading disabled individuals. The exquisite temporal and spatial resolution of MEG, enhanced by these new imaging techniques, will provide clinicians and researchers new noninvasive meth- ods to investigate pathological and normal neurological functioning.           n/a",Development of Hardware and Software for Clinical MEG,7184328,R01NS030914,"['Ache', 'Area', 'Auditory', 'Brain', 'Brain imaging', 'Brain region', 'Characteristics', 'Clinical', 'Communities', 'Complex', 'Computer information processing', 'Computer software', 'Current Procedural Terminology Codes', 'Data', 'Detection', 'Development', 'Developmental reading disorder', 'Diagnostic', 'Diffusion Magnetic Resonance Imaging', 'Disabled Persons', 'Disease', 'Doctor of Philosophy', 'Dyslexia', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Excision', 'Fiber', 'Frequencies', 'Grant', 'Hearing', 'Image', 'Imaging Techniques', 'Implant', 'Individual', 'Internet', 'Knowledge', 'Language', 'Learning', 'Learning Disorders', 'Link', 'Localized', 'Location', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Maps', 'Migraine', 'Modality', 'Modeling', 'Monitor', 'Nervous System Physiology', 'Neurologic', 'Neurons', 'Neurosciences', 'Noise', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Principal Component Analysis', 'Purpose', 'Reader', 'Reading', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Seizures', 'Semantic memory', 'Series', 'Signal Transduction', 'Software Tools', 'Source', 'Stimulus', 'Surgeon', 'System', 'Techniques', 'Time', 'Tissues', 'Visual', 'Word Processing', 'Writing', 'analytical tool', 'base', 'clinical application', 'density', 'human prostaglandin D2 receptor', 'improved', 'lexical', 'magnetic field', 'programs', 'prophylactic', 'research clinical testing', 'response', 'technique development', 'tool']",NINDS,HENRY FORD HEALTH SYSTEM,R01,2007,567126,0.0020773245531149373
"Development of Hardware and Software for Clinical MEG    DESCRIPTION (provided by applicant): The ongoing objective of our research, since the establishment of the HFH MEG Lab, has been to develop hardware, software, and techniques to expand the utility of Magnetoencephalography (MEG), both as a clinical diagnostic tool, and as a modality for basic neuroscience studies. With the proliferation of MEG sys- tems both in the U.S. and worldwide, and the availability of CPT codes for some clinical MEG studies, the development of new and more effective clinical applications to enable users to more fully exploit these costly systems has become our highest priority. Accordingly we are developing new analytical tools and demon- strating that MEG data contains much more clinically useful information than can be found using only the usual dipole techniques. For example, the integration of our Multi Resolution FOCUSS with Principal Com- ponent Analysis (PCA) or Singular Value Decomposition (SVD) shows promise of enhanced computational efficiency and the ability to identify regions of high brain coherence indicative of epileptic tissue. During the proposed grant, these new techniques will be further developed and applied to neurologic and learning dis- orders. In Specific Aim One, interoperative source confirmation will be compared to results of our mapping techniques. DC-MEG will be used to monitor interictal cortical excitability in migraine patients and how this excitability responds to anti-migraine medications. Determination of focal secondary generalized epileptic activity may be used to predict successful surgical resections. In Specific Aim Two we propose to continue the development of new analytical tools and to make them available to the MEG community on the Internet as they become validated. In particular, we will add new functionality to our ""MEG Tools"" software suite by incorporating ICA, Frequency Analysis, and MEG co-registration with Diffusion Tensor Imaging (DTI). In Specific Aim Three, our new techniques will be applied to imaging differences in cortical activation between normal readers and individuals with learning disorders during reading tasks. These techniques will be used to map various cortical areas activated by auditory and visual lexical stimuli, and to differentiate the re- sponses of normal and reading disabled individuals. The exquisite temporal and spatial resolution of MEG, enhanced by these new imaging techniques, will provide clinicians and researchers new noninvasive meth- ods to investigate pathological and normal neurological functioning.           n/a",Development of Hardware and Software for Clinical MEG,7097791,R01NS030914,"['brain', 'clinical research', 'epilepsy', 'learning disorders', 'magnetic field', 'reading']",NINDS,HENRY FORD HEALTH SYSTEM,R01,2006,610630,0.0020773245531149373
"Development of a Fast Large Area Multiphoton Exoscope (FLAME) Summary. Our long-term goal is to develop a powerful tool based on multiphoton microscopy (MPM) for non- invasive human skin imaging in order to improve clinical diagnosis, guide effective treatment and advance clinical and cosmetic/pharmaceutical research by providing access to dynamic cellular and molecular processes during therapy. MPM is a nonlinear optical imaging technique that provides unique structural and molecular contrast based on endogenous signals such as second harmonic generation from collagen and two- photon excited fluorescence from NADH/FAD+, keratin, melanin and elastin fibers. This contrast allows MPM to provide multi-color, rich molecular information content images that can enhance diagnostic accuracy. MPM overcomes fundamental limitations of existing optical imaging technologies for sub-surface skin imaging and extends the area of applicability beyond skin lesions that can be diagnosed through morphological assessment alone. Validation of the clinical potential of this technology has been facilitated over the past 10 years by a device developed by Jenlab in Germany, currently the only clinical MPM system on the market. This device has technical limitations in terms of field-of-view (FOV), imaging speed, complexity and cost, which are major barriers to clinical adoption. The goal of this Phase I proposal is to develop and test the technical feasibility for in vivo human skin imaging of a MPM system that is highly optimized for rapid, label-free, macroscopic imaging of human skin with microscopic resolution. The Fast Large Area Multiphoton Exoscope (FLAME) imaging platform will incorporate the innovative optical engine of a benchtop prototype developed at BLI. InfraDerm will innovate on this design to transform it into a compact, portable device, suitable for human skin imaging in clinical setting. Key innovations include: 1) a compact engineering design based on integrating a compact fs fiber laser into the imaging head along with a customized folded optical design to reduce complexity and cost and enhance portability; 2) hardware and software strategies that include a customized patient interface and a combination of optical and mechanical scanning mechanisms with deep learning image restoration to allow millimeter-to-centimeter scale imaging within minutes while maintaining sub-micron resolution. This approach will expand the in vivo imaging area from mm to cm scale, which will be scanned within minutes with sub- cellular resolution. In Aim 1 we will develop the FLAME prototype that incorporates these features. In Aim 2 we will test its technical feasibility for in vivo human skin imaging by evaluating potential effects of motion artifacts. In Aim 3, we will demonstrate the FLAME system potential for non-invasive assessment of melanin content, an ability with potential impact in differential diagnosis and early assessment of treatment efficacy of pigmentary skin disorders, such as melasma. Phase II will refine the technological approach and will test the device feasibility in a first clinical application, differential diagnosis of patients with melasma, a long time dermatology challenge and a particular interest for pharma companies developing therapies for this skin condition. Narrative  InfraDerm LLC proposes to develop and test the technical feasibility for in vivo human skin imaging of a laser scanning microscope based on multiphoton microscopy (MPM) that addresses fundamental and technical limitations of existing optical imaging technologies for sub-surface skin imaging, extending the area of applicability beyond skin lesions that can be diagnosed through morphological assessment alone. The proposed Fast Large Area Multiphoton Exoscope (FLAME) prototype will be highly optimized for rapid, label- free, macroscopic imaging of human skin with microscopic resolution. An MPM clinical platform, uniquely equipped with this combination of features would embody an innovative and commercially viable product that will broadly impact clinical diagnosis and research in dermatology as well as in cosmetic and pharmaceutical research.",Development of a Fast Large Area Multiphoton Exoscope (FLAME),10153566,R43EB030931,"['3-Dimensional', 'Address', 'Adoption', 'Alopecia', 'Appearance', 'Area', 'Automobile Driving', 'Biopsy', 'Cell physiology', 'Chloasma', 'Clinic', 'Clinical', 'Clinical Research', 'Collagen', 'Color', 'Computer software', 'Cosmetics', 'Custom', 'Dermatology', 'Development', 'Devices', 'Diagnosis', 'Differential Diagnosis', 'Disclosure', 'Elastin', 'Elastin Fiber', 'Excision', 'Extracellular Matrix', 'Face', 'Fiber', 'Fluorescence', 'Generations', 'Germany', 'Goals', 'Head', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Institutes', 'Keratin', 'Label', 'Laboratories', 'Lasers', 'Legal patent', 'Lesion', 'Mechanics', 'Medical', 'Medical Device', 'Melanins', 'Microscope', 'Microscopic', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Motion', 'NADH', 'Nevus', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pharmacologic Substance', 'Phase', 'Physiological', 'Pigments', 'Process', 'Publications', 'Research', 'Resolution', 'Scalp structure', 'Scanning', 'Signal Transduction', 'Skin', 'Speed', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'Validation', 'base', 'cellular imaging', 'clinical Diagnosis', 'clinical application', 'cost', 'cost effective', 'deep learning', 'design', 'diagnostic accuracy', 'effective therapy', 'engineering design', 'human imaging', 'image guided', 'image guided therapy', 'imaging platform', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'millimeter', 'multiphoton imaging', 'multiphoton microscopy', 'optical imaging', 'portability', 'prototype', 'response', 'restoration', 'second harmonic', 'skin disorder', 'skin lesion', 'submicron', 'therapy development', 'tool', 'two-photon']",NIBIB,"INFRADERM, LLC",R43,2020,263074,0.020434735153304767
"Functional Data Analysis of Longitudinally Measured Genetic Traits.    DESCRIPTION (provided by applicant): There has been a growing interest in investigating genetic architecture of time-varying functional traits such as blood pressure, cholesterol levels or growth rate. Few of the methods proposed in the literature, however, are sufficiently general to apply to complicated situations in a computationally feasible fashion. The goal of this research is to develop general and more powerful statistical methods to map functional quantitative genetic traits. More specifically, in the first step we propose a non-parametric permutation test for overall genetic effect of functional traits by examining familial aggregation. When there is evidence for genetic contribution, the natural second step is to estimate this overall polygenic effect. We then develop methods based on mixed effects models for estimation and use functional principal components analysis to summarize the major temporal variation of the polygenic effect. When the overall genetic effect is reasonably strong, research interest lies in locating influential genes on the genome. In the third step, we propose general functional variance components models to test and estimate quantitative trait locus (QTL) genetic effects using marker genotype data in a genome-wide linkage study. Current ad-hoc methods either uses averages of repeated measurements in a univariate analysis or specifies a parametric form of time- dependent genetic effects in a longitudinal analysis. We propose a family of basis systems to capture genetic effects and estimate age-specific QTL heritability. The flexibility of such basis systems allow for identification of temporal trends of any shape. Within this functional mapping framework, we can answer research questions such as when is a QTL effect expressed to affect a trait, how does gene affect rate of change of traits and so on. Lastly, we propose to investigate our methods using Genetic Analysis Workshop (GAW) 13 simulated data, apply them to the Framingham Heart Study data, and implement them in a software package. Framingham Heart Study is a large prospective study of cardiovascular disease which aims to investigate risk factors and genetic architecture of this disease. The GAW13 simulation data was generated closely based on the Framingham Study, which provides a realistic and valuable resource for methods evaluation and comparison. An application of the developed methods to Framingham data may enhance our understanding of the genetic architecture of cardiovascular disease related traits. The developed software will be made publicly available to all investigators free of charge. PUBLIC HEALTH RELEVANCE: Dissecting genetic determinants of complex time-varying functional traits such as blood pressure, cholesterol levels or growth rate has been one of the most daunting tasks in genetic studies due to complicated nature of their etiology. This project develops new statistical methods to map genetic variants predisposing complex functional traits and applies methods to the Framingham Heart Study data. The study will offer general and more powerful analysis methods for mapping functional quantitative genetic trait and to answer research questions such as when is a gene expressed to affect a trait, how long does genetic effect last, and how does gene affect rate of change of traits.              Project Narrative Dissecting genetic determinants of complex time-varying functional traits such as blood pressure, cholesterol levels or growth rate has been one of the most daunting tasks in genetic studies due to complicated nature of their etiology. This project develops new statistical methods to map genetic variants predisposing complex functional traits and applies methods to the Framingham Heart Study data. The study will offer general and more powerful analysis methods for mapping functional quantitative genetic trait and to answer research questions such as when is a gene expressed to affect a trait, how long does genetic effect last, and how does gene affect rate of change of traits.",Functional Data Analysis of Longitudinally Measured Genetic Traits.,7862512,R03AG031113,"['Affect', 'Age', 'Architecture', 'Blood Pressure', 'Cardiovascular Diseases', 'Charge', 'Cholesterol', 'Complex', 'Computer software', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational workshop', 'Etiology', 'Evaluation', 'Family', 'Framingham Heart Study', 'Future', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genotype', 'Goals', 'Growth', 'Heritability', 'Influentials', 'Literature', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Pattern', 'Principal Component Analysis', 'Procedures', 'Prospective Studies', 'Public Domains', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Residual state', 'Resources', 'Risk Factors', 'Scanning', 'Shapes', 'Simulate', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Time', 'Variant', 'base', 'flexibility', 'genetic analysis', 'genetic linkage', 'genetic risk factor', 'genetic variant', 'genome-wide linkage', 'insight', 'interest', 'longitudinal analysis', 'public health relevance', 'simulation', 'software development', 'statistics', 'theories', 'trait', 'trend', 'user friendly software']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R03,2010,65986,0.0030239354444614665
"Functional Data Analysis of Longitudinally Measured Genetic Traits.    DESCRIPTION (provided by applicant): There has been a growing interest in investigating genetic architecture of time-varying functional traits such as blood pressure, cholesterol levels or growth rate. Few of the methods proposed in the literature, however, are sufficiently general to apply to complicated situations in a computationally feasible fashion. The goal of this research is to develop general and more powerful statistical methods to map functional quantitative genetic traits. More specifically, in the first step we propose a non-parametric permutation test for overall genetic effect of functional traits by examining familial aggregation. When there is evidence for genetic contribution, the natural second step is to estimate this overall polygenic effect. We then develop methods based on mixed effects models for estimation and use functional principal components analysis to summarize the major temporal variation of the polygenic effect. When the overall genetic effect is reasonably strong, research interest lies in locating influential genes on the genome. In the third step, we propose general functional variance components models to test and estimate quantitative trait locus (QTL) genetic effects using marker genotype data in a genome-wide linkage study. Current ad-hoc methods either uses averages of repeated measurements in a univariate analysis or specifies a parametric form of time- dependent genetic effects in a longitudinal analysis. We propose a family of basis systems to capture genetic effects and estimate age-specific QTL heritability. The flexibility of such basis systems allow for identification of temporal trends of any shape. Within this functional mapping framework, we can answer research questions such as when is a QTL effect expressed to affect a trait, how does gene affect rate of change of traits and so on. Lastly, we propose to investigate our methods using Genetic Analysis Workshop (GAW) 13 simulated data, apply them to the Framingham Heart Study data, and implement them in a software package. Framingham Heart Study is a large prospective study of cardiovascular disease which aims to investigate risk factors and genetic architecture of this disease. The GAW13 simulation data was generated closely based on the Framingham Study, which provides a realistic and valuable resource for methods evaluation and comparison. An application of the developed methods to Framingham data may enhance our understanding of the genetic architecture of cardiovascular disease related traits. The developed software will be made publicly available to all investigators free of charge. PUBLIC HEALTH RELEVANCE: Dissecting genetic determinants of complex time-varying functional traits such as blood pressure, cholesterol levels or growth rate has been one of the most daunting tasks in genetic studies due to complicated nature of their etiology. This project develops new statistical methods to map genetic variants predisposing complex functional traits and applies methods to the Framingham Heart Study data. The study will offer general and more powerful analysis methods for mapping functional quantitative genetic trait and to answer research questions such as when is a gene expressed to affect a trait, how long does genetic effect last, and how does gene affect rate of change of traits.              Project Narrative Dissecting genetic determinants of complex time-varying functional traits such as blood pressure, cholesterol levels or growth rate has been one of the most daunting tasks in genetic studies due to complicated nature of their etiology. This project develops new statistical methods to map genetic variants predisposing complex functional traits and applies methods to the Framingham Heart Study data. The study will offer general and more powerful analysis methods for mapping functional quantitative genetic trait and to answer research questions such as when is a gene expressed to affect a trait, how long does genetic effect last, and how does gene affect rate of change of traits.",Functional Data Analysis of Longitudinally Measured Genetic Traits.,7658423,R03AG031113,"['Affect', 'Age', 'Architecture', 'Blood Pressure', 'Cardiovascular Diseases', 'Charge', 'Cholesterol', 'Complex', 'Computer software', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational workshop', 'Etiology', 'Evaluation', 'Family', 'Framingham Heart Study', 'Future', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genotype', 'Goals', 'Growth', 'Heritability', 'Influentials', 'Literature', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Pattern', 'Principal Component Analysis', 'Procedures', 'Prospective Studies', 'Public Domains', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Residual state', 'Resources', 'Risk Factors', 'Scanning', 'Shapes', 'Simulate', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Time', 'Variant', 'base', 'flexibility', 'genetic analysis', 'genetic linkage', 'genetic risk factor', 'genetic variant', 'genome-wide linkage', 'insight', 'interest', 'longitudinal analysis', 'public health relevance', 'simulation', 'software development', 'statistics', 'theories', 'trait', 'trend', 'user friendly software']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R03,2009,65723,0.0030239354444614665
"MECHANISM OF PROTEIN LOCALIZATION IN ESCHERICHIA COLI The mechanisms of protein localization are of central biological importance at all levels, from the functioning of individual molecules to the biogenesis of higher ordered structures, including the cell itself. Although secreted proteins have a general requirement for some type of cellular export mechinery, the details of such secretion systems are not known.  The overall objective of this work is to use E. coli as a model system to determine the composition, function, and number of such cellular secretion systems.  Initial work is aimed at using a combination of genetics and biochemistry to define one secretion system, the secA system. Genetic approaches will be used to define the genes which code for the components of this system and to obtain mutants in these genes.  The secreted proteins which use this system will be identified using currently available mutants (SecA-) in the export system.  The site on the polypeptide chain of the secreted protein which targets it to use this expert system will be determined using gene fusion technology to create specific hybrid proteins of interest.  This latter study is aimed at understanding the specific interactions of secreted proteins with individual components of the export machinery.  This should allow a structure-function analysis for this secretion system.  n/a",MECHANISM OF PROTEIN LOCALIZATION IN ESCHERICHIA COLI,3282205,R01GM032958,"['Escherichia coli', ' bacterial capsules', ' bacterial genetics', ' chromatography', ' exocytosis', ' genetic manipulation', ' genetic mapping', ' genetic recombination', ' genetic regulation', ' molecular cloning', ' nucleic acid sequence', ' radiotracer', ' secretion', ' temperature sensitive mutant']",NIGMS,STATE UNIVERSITY NEW YORK STONY BROOK,R01,1986,66186,-0.000913744879933041
"MECHANISM OF PROTEIN LOCALIZATION IN ESCHERICHIA COLI The mechanisms of protein localization are of central biological importance at all levels, from the functioning of individual molecules to the biogenesis of higher ordered structures, including the cell itself. Although secreted proteins have a general requirement for some type of cellular export mechinery, the details of such secretion systems are not known.  The overall objective of this work is to use E. coli as a model system to determine the composition, function, and number of such cellular secretion systems.  Initial work is aimed at using a combination of genetics and biochemistry to define one secretion system, the secA system. Genetic approaches will be used to define the genes which code for the components of this system and to obtain mutants in these genes.  The secreted proteins which use this system will be identified using currently available mutants (SecA-) in the export system.  The site on the polypeptide chain of the secreted protein which targets it to use this expert system will be determined using gene fusion technology to create specific hybrid proteins of interest.  This latter study is aimed at understanding the specific interactions of secreted proteins with individual components of the export machinery.  This should allow a structure-function analysis for this secretion system.  n/a",MECHANISM OF PROTEIN LOCALIZATION IN ESCHERICHIA COLI,3282204,R01GM032958,"['Escherichia coli', ' bacterial capsules', ' bacterial genetics', ' chromatography', ' exocytosis', ' genetic manipulation', ' genetic mapping', ' genetic recombination', ' genetic regulation', ' molecular cloning', ' nucleic acid sequence', ' radiotracer', ' secretion', ' temperature sensitive mutant']",NIGMS,STATE UNIVERSITY NEW YORK STONY BROOK,R01,1985,77281,-0.000913744879933041
"DEVELOPING STRATEGIES FOR JOINT GENE-ENVIRONMENT ANALYSIS    DESCRIPTION (provided by applicant): A key challenge for genetic analysis today is to account for the bulk of the phenotypic variance in complex traits that is attributable to genetic factors, but remains unexplained after multiple well-powered GWAS (Goldstein 2009; Hirschhorn 2009; Kraft and Hunter 2009). Many believe that systematically testing datasets for joint gene-environment effects (GxE) and gene-gene (GxG) effects will be essential in order to understand the genetics of complex phenotypes. However, the new era of high throughput, high-density genomic data (genotypes and sequencing) has given rise to serious computational and statistical challenges for the analysis of joint effects. The goal of this project is to develop effective strategies for the statistical analysis of joint-gene environment effects. The specific aims are to (1) identify strengths and weaknesses of multiple analytic approaches to joint GxE effects, and (2) develop new methods for coordinated meta-analysis. To accomplish Aim 1, we will systematically examine and compare traditional (e.g. regression based) and modern (e.g. partitioning, machine learning, information theoretic) analysis methods for case-control and quantitative phenotypes. The primary product will be specific guidance as to the conditions under which each method performs well. To accomplish Aim 2, we will extend recent joint-effects methods to a meta-analytic framework and develop improvements to currently used methods. For both aims, we will also analyze real data related to smoking, thereby improving our understanding of genetic and environmental contributors to smoking and addiction risk. These analyses of real data will be guided by bioinformatics-based variant prioritization. This study therefore will provide both guidance and tools needed to move the field of joint effects analysis forward. As a result, it will ultimately have a significant impact on our ability to account for the currently unexplained genetic contribution to phenotypic variance for complex traits.        Many diseases that greatly impact public health (such as heart disease, diabetes, and nicotine addiction) are the result of a complex interplay between genes and environmental factors. The purpose of this grant is to improve data analysis strategies (applicable to a wide variety of diseases) for the detection of joint effects of genes and environment. We will apply these methods to analyze existing data on smokers to improve our understanding of gene-environment effects on nicotine addiction.            ",DEVELOPING STRATEGIES FOR JOINT GENE-ENVIRONMENT ANALYSIS,8330779,R21DA033827,"['Accounting', 'Address', 'Age', 'Bioinformatics', 'Biological Process', 'Birth', 'Cigarette', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Disease', 'Educational Background', 'Educational workshop', 'Environment', 'Environmental Risk Factor', 'Etiology', 'Evaluation', 'Family', 'Gene Frequency', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Guidelines', 'Hand', 'Heart', 'Heart Diseases', 'Joints', 'Knowledge', 'Light', 'Machine Learning', 'Meta-Analysis', 'Methods', 'Nicotine Dependence', 'Output', 'Pathway interactions', 'Performance', 'Phenotype', 'Public Health', 'Race', 'Recommendation', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sample Size', 'Sensitivity and Specificity', 'Signal Transduction', 'Simulate', 'Smoke', 'Smoker', 'Smoking', 'Staging', 'Statistical Methods', 'Testing', 'Variant', 'addiction', 'base', 'case control', 'database of Genotypes and Phenotypes', 'density', 'gene environment interaction', 'genetic analysis', 'genetic association', 'genome wide association study', 'improved', 'sex', 'tool', 'tool development', 'trait']",NIDA,WASHINGTON UNIVERSITY,R21,2012,190000,-0.03384309737764233
"DEVELOPING STRATEGIES FOR JOINT GENE-ENVIRONMENT ANALYSIS    DESCRIPTION (provided by applicant): A key challenge for genetic analysis today is to account for the bulk of the phenotypic variance in complex traits that is attributable to genetic factors, but remains unexplained after multiple well-powered GWAS (Goldstein 2009; Hirschhorn 2009; Kraft and Hunter 2009). Many believe that systematically testing datasets for joint gene-environment effects (GxE) and gene-gene (GxG) effects will be essential in order to understand the genetics of complex phenotypes. However, the new era of high throughput, high-density genomic data (genotypes and sequencing) has given rise to serious computational and statistical challenges for the analysis of joint effects. The goal of this project is to develop effective strategies for the statistical analysis of joint-gene environment effects. The specific aims are to (1) identify strengths and weaknesses of multiple analytic approaches to joint GxE effects, and (2) develop new methods for coordinated meta-analysis. To accomplish Aim 1, we will systematically examine and compare traditional (e.g. regression based) and modern (e.g. partitioning, machine learning, information theoretic) analysis methods for case-control and quantitative phenotypes. The primary product will be specific guidance as to the conditions under which each method performs well. To accomplish Aim 2, we will extend recent joint-effects methods to a meta-analytic framework and develop improvements to currently used methods. For both aims, we will also analyze real data related to smoking, thereby improving our understanding of genetic and environmental contributors to smoking and addiction risk. These analyses of real data will be guided by bioinformatics-based variant prioritization. This study therefore will provide both guidance and tools needed to move the field of joint effects analysis forward. As a result, it will ultimately have a significant impact on our ability to account for the currently unexplained genetic contribution to phenotypic variance for complex traits.      PUBLIC HEALTH RELEVANCE: Many diseases that greatly impact public health (such as heart disease, diabetes, and nicotine addiction) are the result of a complex interplay between genes and environmental factors. The purpose of this grant is to improve data analysis strategies (applicable to a wide variety of diseases) for the detection of joint effects of genes and environment. We will apply these methods to analyze existing data on smokers to improve our understanding of gene-environment effects on nicotine addiction.              Many diseases that greatly impact public health (such as heart disease, diabetes, and nicotine addiction) are the result of a complex interplay between genes and environmental factors. The purpose of this grant is to improve data analysis strategies (applicable to a wide variety of diseases) for the detection of joint effects of genes and environment. We will apply these methods to analyze existing data on smokers to improve our understanding of gene-environment effects on nicotine addiction.            ",DEVELOPING STRATEGIES FOR JOINT GENE-ENVIRONMENT ANALYSIS,8217748,R21DA033827,"['Accounting', 'Address', 'Age', 'Bioinformatics', 'Biological Process', 'Birth', 'Cigarette', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Disease', 'Educational Background', 'Educational workshop', 'Environment', 'Environmental Risk Factor', 'Etiology', 'Evaluation', 'Family', 'Gene Frequency', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Guidelines', 'Hand', 'Heart', 'Heart Diseases', 'Joints', 'Knowledge', 'Light', 'Machine Learning', 'Meta-Analysis', 'Methods', 'Nicotine Dependence', 'Output', 'Pathway interactions', 'Performance', 'Phenotype', 'Public Health', 'Race', 'Recommendation', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sample Size', 'Sensitivity and Specificity', 'Signal Transduction', 'Simulate', 'Smoke', 'Smoker', 'Smoking', 'Staging', 'Statistical Methods', 'Testing', 'Variant', 'addiction', 'base', 'case control', 'database of Genotypes and Phenotypes', 'density', 'gene environment interaction', 'genetic analysis', 'genetic association', 'genome wide association study', 'improved', 'sex', 'tool', 'tool development', 'trait']",NIDA,WASHINGTON UNIVERSITY,R21,2011,228000,-0.03381675036247135
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173928,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1991,130423,0.03471570464217325
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173927,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1990,129698,0.03471570464217325
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173926,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1989,128797,0.03471570464217325
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173925,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1988,126371,0.03471570464217325
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173924,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1987,126620,0.03471570464217325
"A ROTATING SLIT SCANNING UNIT FOR DIGITAL RADIOGRAPHY The purpose of the research we are proposing is the development of a rotational slit scanning system for digital radiographic applications.  The x-ray receptors will consist of linear photodiode arrays coated with an x-ray phosphor.  The system should be compact and of low cost compared to commercially available linear scanning units.  The spatial resolution imaging capabilities of such a device should exceed one 1p/mm, while offering shorter scan times than conventional linear scanning units.  The benefits expected from such a system would include:  1. significant reduction in the detection of compton scattered x-rays (which will degrade image contrast and increase dose)  2. scan rates sufficient to minimize many patient motion problems  3. an increase in the dynamic range available over that of film  4. adequate spatial resolution for many radiologic applications  Since the same coated arrays may be employed in a linear scan format, direct comparison of image quality between the two scanning formats for the same receptor technology will be possible.  n/a",A ROTATING SLIT SCANNING UNIT FOR DIGITAL RADIOGRAPHY,3174442,R01CA036859,"['artificial intelligence', ' clinical biomedical equipment', ' diagnosis quality /standard', ' image processing', ' online computer']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,1985,24091,0.03506084672202601
"COMPUTER SIMULATION THEORY OF GLOBULAR PROTEIN DYNA The prediction of the three dimensional structure of a globular protein          from its amino acid sequence along with the mechanism by which protein           folding occurs are among the most important unsolved problems of                 contemporary molecular biology.  The overall objectives of this proposal         are the continued development and refinement of algorithms which not only        can predict protein tertiary structure using only sequence information as        input but also may provide insights into the folding pathway.  To achieve        these goals, this proposal focuses on the lattice based aspects of a             hierarchical approach to protein folding.  High resolution lattice models        of proteins, comprised of an alpha-carbon plus reduced off lattice, side         chain description, will provide the overall folding pathways and folded          conformations.  The resulting folded lattice structures are estimated for        the alpha-carbons to have a 2-4 angstroms rms deviation from the native          state.  Turning to the folding pathways, the predicted molten globule            states and their free energy landscape will be characterized in detail.          The factors responsible for side chain fixation on passage from the molten       globule to the native state will be explored, with particular attention          focused on the interplay of protein sequence and side chain packing.             Specifically this proposal will address the following.  (1).  A new high         coordination lattice model of proteins will be refined, different side           chain realizations will be examined and the dynamic Monte Carlo algorithms       parallelized.  (2).  Better empirical free energy functions will be              developed.  These include better methods for predicting the propensities         for secondary structure and generalization of the hydrogen bond scheme to        include backbone-side chain hydrogen bonds.  To help eliminate misfolded         structures, additional very robust knowledge based rules, such as the            connections in supersecondary structural elements do not cross, will be          included in the interaction scheme.  Sequence specific tertiary                  interactions including a local burial turn, pair interactions and                generalized cooperative multibody side chain contact templates will be           self consistently derived in the presence of predicted secondary structure       propensities.  Then, a recently developed neural network which can               recognize whether 7 by 7 subfragments of sidechain contact maps are              protein like or not will be extended to include sequence specific                preferences for subsequences to adopt specific patterns.  This information       will be obtained from a neural network trained on both homologous and non        homologous subsequences that adopt these patterns.  Thus, it should be           general and not simply applicable to homologous sequence fragments.  (3).        The folding of representative motifs of globular proteins will be                undertaken.  Included are the helical proteins such as cytochrome c, whose       predicted folding pathway will be compared to experiment, myohemerythrin,        myoglobin and complement factor, 1c5a.  The mixed motif proteins include         ubiquitin, flavodoxin and PRA isomerase, and the beta-proteins include the       16th complement control protein of factor H, 1hcc, alpha-amylase,                plastocyanin and retinol binding protein.  (4).  To validate the                 methodology, additional blind predictions of proteins whose structures are       unknown will be undertaken.  Likely candidates include rusticyanin and           erythropoietin.                                                                   n/a",COMPUTER SIMULATION THEORY OF GLOBULAR PROTEIN DYNA,2022122,R01GM037408,"['amylases', ' artificial intelligence', ' chemical models', ' computer simulation', ' cytochrome c', ' globular protein', ' hemerythrin', ' hydrogen bond', ' mathematics', ' model design /development', ' molecular dynamics', ' molecular energy level', ' myoglobin', ' plastocyanin', ' protein folding', ' retinoid binding proteins']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,1996,182701,0.012970489148551846
"COMPUTER SIMULATION THEORY OF GLOBULAR PROTEIN DYNA The prediction of the three dimensional structure of a globular protein  from its amino acid sequence along with the mechanism by which protein  folding occurs are among the most important unsolved problems of  contemporary molecular biology.  The overall objectives of this proposal  are the continued development and refinement of algorithms which not only  can predict protein tertiary structure using only sequence information as  input but also may provide insights into the folding pathway.  To achieve  these goals, this proposal focuses on the lattice based aspects of a  hierarchical approach to protein folding.  High resolution lattice models  of proteins, comprised of an alpha-carbon plus reduced off lattice, side  chain description, will provide the overall folding pathways and folded  conformations.  The resulting folded lattice structures are estimated for  the alpha-carbons to have a 2-4 angstroms rms deviation from the native  state.  Turning to the folding pathways, the predicted molten globule  states and their free energy landscape will be characterized in detail.  The factors responsible for side chain fixation on passage from the molten  globule to the native state will be explored, with particular attention  focused on the interplay of protein sequence and side chain packing.  Specifically this proposal will address the following.  (1).  A new high  coordination lattice model of proteins will be refined, different side  chain realizations will be examined and the dynamic Monte Carlo algorithms  parallelized.  (2).  Better empirical free energy functions will be  developed.  These include better methods for predicting the propensities  for secondary structure and generalization of the hydrogen bond scheme to  include backbone-side chain hydrogen bonds.  To help eliminate misfolded  structures, additional very robust knowledge based rules, such as the  connections in supersecondary structural elements do not cross, will be  included in the interaction scheme.  Sequence specific tertiary  interactions including a local burial turn, pair interactions and  generalized cooperative multibody side chain contact templates will be  self consistently derived in the presence of predicted secondary structure  propensities.  Then, a recently developed neural network which can  recognize whether 7 by 7 subfragments of sidechain contact maps are  protein like or not will be extended to include sequence specific  preferences for subsequences to adopt specific patterns.  This information  will be obtained from a neural network trained on both homologous and non  homologous subsequences that adopt these patterns.  Thus, it should be  general and not simply applicable to homologous sequence fragments.  (3).  The folding of representative motifs of globular proteins will be  undertaken.  Included are the helical proteins such as cytochrome c, whose  predicted folding pathway will be compared to experiment, myohemerythrin,  myoglobin and complement factor, 1c5a.  The mixed motif proteins include  ubiquitin, flavodoxin and PRA isomerase, and the beta-proteins include the  16th complement control protein of factor H, 1hcc, alpha-amylase,  plastocyanin and retinol binding protein.  (4).  To validate the  methodology, additional blind predictions of proteins whose structures are  unknown will be undertaken.  Likely candidates include rusticyanin and  erythropoietin.  n/a",COMPUTER SIMULATION THEORY OF GLOBULAR PROTEIN DYNA,2178769,R01GM037408,"['amylases', ' artificial intelligence', ' chemical models', ' computer simulation', ' cytochrome c', ' globular protein', ' hemerythrin', ' hydrogen bond', ' mathematics', ' model design /development', ' molecular dynamics', ' molecular energy level', ' myoglobin', ' protein folding', ' retinoid binding proteins']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,1995,175781,0.012970489148551846
"COMPUTER SIMULATION THEORY OF GLOBULAR PROTEIN DYNA The prediction of the three dimensional structure of a globular protein from its amino acid sequence along with the mechanism by which protein folding occurs are among the most important unsolved problems of contemporary molecular biology.  The overall objectives of this proposal are the continued development and refinement of algorithms which not only can predict protein tertiary structure using only sequence information as input but also may provide insights into the folding pathway.  To achieve these goals, this proposal focuses on the lattice based aspects of a hierarchical approach to protein folding.  High resolution lattice models of proteins, comprised of an alpha-carbon plus reduced off lattice, side chain description, will provide the overall folding pathways and folded conformations.  The resulting folded lattice structures are estimated for the alpha-carbons to have a 2-4 angstroms rms deviation from the native state.  Turning to the folding pathways, the predicted molten globule states and their free energy landscape will be characterized in detail. The factors responsible for side chain fixation on passage from the molten globule to the native state will be explored, with particular attention focused on the interplay of protein sequence and side chain packing. Specifically this proposal will address the following.  (1).  A new high coordination lattice model of proteins will be refined, different side chain realizations will be examined and the dynamic Monte Carlo algorithms parallelized.  (2).  Better empirical free energy functions will be developed.  These include better methods for predicting the propensities for secondary structure and generalization of the hydrogen bond scheme to include backbone-side chain hydrogen bonds.  To help eliminate misfolded structures, additional very robust knowledge based rules, such as the connections in supersecondary structural elements do not cross, will be included in the interaction scheme.  Sequence specific tertiary interactions including a local burial turn, pair interactions and generalized cooperative multibody side chain contact templates will be self consistently derived in the presence of predicted secondary structure propensities.  Then, a recently developed neural network which can recognize whether 7 by 7 subfragments of sidechain contact maps are protein like or not will be extended to include sequence specific preferences for subsequences to adopt specific patterns.  This information will be obtained from a neural network trained on both homologous and non homologous subsequences that adopt these patterns.  Thus, it should be general and not simply applicable to homologous sequence fragments.  (3). The folding of representative motifs of globular proteins will be undertaken.  Included are the helical proteins such as cytochrome c, whose predicted folding pathway will be compared to experiment, myohemerythrin, myoglobin and complement factor, 1c5a.  The mixed motif proteins include ubiquitin, flavodoxin and PRA isomerase, and the beta-proteins include the 16th complement control protein of factor H, 1hcc, alpha-amylase, plastocyanin and retinol binding protein.  (4).  To validate the methodology, additional blind predictions of proteins whose structures are unknown will be undertaken.  Likely candidates include rusticyanin and erythropoietin.  n/a",COMPUTER SIMULATION THEORY OF GLOBULAR PROTEIN DYNA,2178767,R01GM037408,"['amylases', ' artificial intelligence', ' chemical models', ' computer simulation', ' cytochrome c', ' globular protein', ' hemerythrin', ' hydrogen bond', ' mathematics', ' model design /development', ' molecular dynamics', ' molecular energy level', ' myoglobin', ' protein folding', ' retinoid binding proteins']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,1994,176981,0.012970489148551846
"Center for Genetic Studies of Drug Abuse in Outbred Rats Project Summary (Overall)  The purpose of this renewal application is to continue the successful activities of our center, which uses quantitative genetic techniques to study the genetic basis of drug abuse-related behaviors in outbred rats. When our center was initially funded in June 2014, our goal was to develop outbred N/NIH heterogeneous stock (HS) rats as a platform for genetic studies of behaviors that were difficult or impossible to study in mice. The first four years of funding have allowed us to establish a vibrant community of investigators using HS rats to study drug abuse and other traits, which we refer to as an ecosystem. This ecosystem includes both the investigators who are directly involved in this renewal application and many others who have obtained separate funding, some from NIDA, and some from other sources. The growth of this ecosystem reflects one of the ways that our center has served as national resource. We are proposing three projects that involved phenotyping HS rats for a variety of traits, including intravenous cocaine and nicotine self-administration, response to novelty, social behavior, reaction time, and delay discounting. Two of those projects are continuations from the prior funding period and are designed to increase our sample size from 1,600 to 3,200 rats per phenotype. We present data showing that such an increase produces an exponential increase in the number of significant findings. This approach parallels human genetics studies of SUD, which have also benefited tremendously from larger sample sizes. We will use these data to conduct genome-wide association studies (GWAS) and a suite of related techniques. In addition, we will measure gene expression in behaviorally naïve rats using RNASeq and use those data to identify expression quantitative trait loci (eQTLs). We will then integrate GWAS and eQTL data in an effort to identify specific genes that influence the behavioral phenotypes. Many of the behavioral domains being studied are known to be sexually dimorphic; our study will use both male and female rats, which will allow us to identify sex differences and sex by genotype interactions. We will also study genetic correlations, perform phenome-wide association studies (PheWAS), transcriptome wide association studies (TWAS) and explore a novel strategy called polygenic transcriptomic risk scores (PTRS), that is intended to allow translation of polygenic signals across species. Project 4 will use a network-based approach to extend our GWAS to account for known biological networks. This proposed renewal also includes a pilot project core to support new directions and take advantage of unforeseen opportunities. Finally we propose an administrative core that supports many activities of the center, including educational, career development and public outreach. The results of these studies will enhance our understanding of the role of genes in a range of psychologically complex behaviors and will provide novel biological insights that may support future efforts at preventing or treating drug abuse. Project Narrative (Overall)  Using powerful genetic, molecular and statistical techniques, we will study the genetic basis of traits that have well-established relevance to drug abuse. We expect that these studies will enhance our understanding of drug abuse and lead to the identification of specific genes and pathways. These discoveries will improve our understanding of genetic susceptibility to drug abuse in humans and may identify new opportunities to treat psychiatric disorders including but not limited to addiction.",Center for Genetic Studies of Drug Abuse in Outbred Rats,9971494,P50DA037844,"['Adolescent', 'Animal Model', 'Attention', 'Behavior', 'Behavioral', 'Biological', 'Brain region', 'Breeding', 'Cancer Grant Supplements (P30)', 'Cessation of life', 'Cocaine', 'Communities', 'Complex', 'Crime', 'Cues', 'DNA', 'Data', 'Databases', 'Development', 'Drug abuse', 'Ecosystem', 'Education', 'Esthesia', 'Female', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Recombination', 'Genetic Techniques', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Impulsivity', 'Inbred Strains Rats', 'Individual', 'Intravenous', 'Knowledge', 'Lead', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Molecular', 'Mus', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'National Institute of Drug Abuse', 'Network-based', 'Nicotine', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Productivity', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reaction Time', 'Regulation', 'Relapse', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Sample Size', 'Self Administration', 'Sex Differences', 'Signal Transduction', 'Social Behavior', 'Social Reinforcement', 'Source', 'Statistical Methods', 'Substance Use Disorder', 'System', 'Techniques', 'Translations', 'United States National Institutes of Health', 'addiction', 'behavior influence', 'behavioral phenotyping', 'behavioral study', 'career development', 'cocaine use', 'cost', 'deep learning', 'design', 'discounting', 'drug abuse related behavior', 'effective therapy', 'genetic analysis', 'genetic approach', 'genome wide association study', 'genome-wide', 'improved', 'insight', 'male', 'nicotine use', 'novel', 'novel strategies', 'outreach', 'phenome', 'phenotypic data', 'premature', 'preservation', 'prevent', 'psychologic', 'response', 'sex', 'sexual dimorphism', 'success', 'sustained attention', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'virtual', 'web site']",NIDA,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P50,2020,2985563,0.01090967472687392
"Center for Genetic Studies of Drug Abuse in Outbred Rats Project Summary (Overall)  The purpose of this renewal application is to continue the successful activities of our center, which uses quantitative genetic techniques to study the genetic basis of drug abuse-related behaviors in outbred rats. When our center was initially funded in June 2014, our goal was to develop outbred N/NIH heterogeneous stock (HS) rats as a platform for genetic studies of behaviors that were difficult or impossible to study in mice. The first four years of funding have allowed us to establish a vibrant community of investigators using HS rats to study drug abuse and other traits, which we refer to as an ecosystem. This ecosystem includes both the investigators who are directly involved in this renewal application and many others who have obtained separate funding, some from NIDA, and some from other sources. The growth of this ecosystem reflects one of the ways that our center has served as national resource. We are proposing three projects that involved phenotyping HS rats for a variety of traits, including intravenous cocaine and nicotine self-administration, response to novelty, social behavior, reaction time, and delay discounting. Two of those projects are continuations from the prior funding period and are designed to increase our sample size from 1,600 to 3,200 rats per phenotype. We present data showing that such an increase produces an exponential increase in the number of significant findings. This approach parallels human genetics studies of SUD, which have also benefited tremendously from larger sample sizes. We will use these data to conduct genome-wide association studies (GWAS) and a suite of related techniques. In addition, we will measure gene expression in behaviorally naïve rats using RNASeq and use those data to identify expression quantitative trait loci (eQTLs). We will then integrate GWAS and eQTL data in an effort to identify specific genes that influence the behavioral phenotypes. Many of the behavioral domains being studied are known to be sexually dimorphic; our study will use both male and female rats, which will allow us to identify sex differences and sex by genotype interactions. We will also study genetic correlations, perform phenome-wide association studies (PheWAS), transcriptome wide association studies (TWAS) and explore a novel strategy called polygenic transcriptomic risk scores (PTRS), that is intended to allow translation of polygenic signals across species. Project 4 will use a network-based approach to extend our GWAS to account for known biological networks. This proposed renewal also includes a pilot project core to support new directions and take advantage of unforeseen opportunities. Finally we propose an administrative core that supports many activities of the center, including educational, career development and public outreach. The results of these studies will enhance our understanding of the role of genes in a range of psychologically complex behaviors and will provide novel biological insights that may support future efforts at preventing or treating drug abuse. Project Narrative (Overall)  Using powerful genetic, molecular and statistical techniques, we will study the genetic basis of traits that have well-established relevance to drug abuse. We expect that these studies will enhance our understanding of drug abuse and lead to the identification of specific genes and pathways. These discoveries will improve our understanding of genetic susceptibility to drug abuse in humans and may identify new opportunities to treat psychiatric disorders including but not limited to addiction.",Center for Genetic Studies of Drug Abuse in Outbred Rats,9793600,P50DA037844,"['Adolescent', 'Animal Model', 'Attention', 'Behavior', 'Behavioral', 'Biological', 'Brain region', 'Breeding', 'Cancer Grant Supplements (P30)', 'Cessation of life', 'Cocaine', 'Communities', 'Complex', 'Crime', 'Cues', 'DNA', 'Data', 'Databases', 'Development', 'Drug abuse', 'Ecosystem', 'Education', 'Esthesia', 'Female', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Recombination', 'Genetic Techniques', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Impulsivity', 'Inbred Strains Rats', 'Individual', 'Intravenous', 'Knowledge', 'Lead', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Molecular', 'Mus', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'National Institute of Drug Abuse', 'Network-based', 'Nicotine', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Productivity', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reaction Time', 'Regulation', 'Relapse', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Sample Size', 'Self Administration', 'Sex Differences', 'Signal Transduction', 'Social Behavior', 'Social Reinforcement', 'Source', 'Statistical Methods', 'Substance Use Disorder', 'System', 'Techniques', 'Translations', 'United States National Institutes of Health', 'addiction', 'behavior influence', 'behavioral study', 'career development', 'cocaine use', 'cost', 'deep learning', 'design', 'discount', 'discounting', 'drug abuse related behavior', 'effective therapy', 'genetic analysis', 'genome wide association study', 'genome-wide', 'improved', 'insight', 'male', 'nicotine use', 'novel', 'novel strategies', 'outreach', 'phenome', 'phenotypic data', 'premature', 'preservation', 'prevent', 'psychologic', 'response', 'sex', 'sexual dimorphism', 'success', 'sustained attention', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'virtual', 'web site']",NIDA,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P50,2019,2949105,0.01090967472687392
"STRUCTURAL PATTERN ANALYSIS OF HUMAN G-BANDED CHROMOSOME This is a proposal to study structural pattern analysis of human G- banded chromosomes by computer.  A database of approximately 7,000 digitized images of band-density profiles is available; each type is represented by about the same number of samples.  A mapped of the density profiles into finite strings of symbols will be developed to cast the problem as string/sequence structure analysis.  A specific mapping to be evaluated carefully is based on ""difference symbol"" strings; this mapping is simple to compute and should facilitate automatic machine learning (inference) of pattern structure from training samples.  For each chromosome type, a set of training strings will be used to infer a Markov chain as a statistical/structural model.  The inference algorithm will use dynamic programming with a relative frequency cost function to compute optimal string alignments sequentially as a search for recurrent substring patterns call ""landmark substrings"".  The inferred Markov networks will be analyzed themselves for ensemble properties of the training data and will be used in classification experiments with both the training data and separate test data.  n/a",STRUCTURAL PATTERN ANALYSIS OF HUMAN G-BANDED CHROMOSOME,3296831,R01GM039708,"['artificial intelligence', ' chromosomes', ' genetic library', ' genetic mapping', ' genetic models', ' human population genetics', ' information systems', ' mathematical model']",NIGMS,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,1988,34793,0.02790500923587875
"CANCER PROTEIN DATA BASE High resolution two dimensional electrophoresis allows a large fraction of the estimated 30,000 to 50,000 human proteins to be identified by map position and to be quantitated.  Normal and cancer cells have been mapped in orienting studies and many differences found.  To give meaning to these results, and to systematically exploit them, a large data base (the Cancer Protein Data Base) including all available and all obtainable data on each spot is required, with the data base directly linked to CRT map displays. The data base will include (for each protein) intracellular location, types of cells in which found, names, functions, disease correlations, biophysical data, literature citations, membership in coregulated sets, differentiational stage of occurrence, and chromosomal location of the coding gene.  The theses to be explored are that cells are highly integrated systems to be understood in terms of protein sets and the regulational circuits involving them, and that compositional changes in cancer cells are not random, but reflect alterations in normal regulational and differentiational functions.  This Phase I proposal is for the continued development of the TYCHO and KEPLER data base systems, specifically directed to cancer studies, in a private setting.  n/a",CANCER PROTEIN DATA BASE,3491144,R43CA040855,"['artificial intelligence', ' cancer information system', ' gel electrophoresis', ' genetic mapping', ' information systems', ' oncogenes', ' oncoproteins', ' protein tyrosine kinase']",NCI,LARGE SCALE BIOLOGY CORPORATION,R43,1986,50000,0.005166295033983434
"COMPUTERIZED ELECTROCARDIOLOGY Funds are requested to support publication of the Proceedings of the 1989 Conference on Computerized Interpretation of the Electrocardiogram in the Journal of Electrocardiology.  This will be the 14th Annual Conference which in past years has been co- sponsored by the Engineering Foundation and ISCE.  The topic area is particularly important as it is estimated that about 51 million electrocardiograms processed annually by computer in the United States, and that there are over 15,000 devices in the field with analysis capabilities.  The overall objective of this Conference is to exchange the most recent information and advances in computer analyses in electrocardiology among biomedical engineers, computer scientists, electrophysiologists, clinical researchers, and epidemiologists. Most of the participants come from academic organizations and public health agencies; many are scientists and engineers from companies with a heavy commitment to research and development activities in these areas.  The multi-disciplinary nature of the speakers will allow in depth exploration and discussion of technical/ scientific issues such as mapping endocardial, epicardial, and body surface potential distributions, sampling and data compression methods, and high resolution, low level ECG recordings.  Eight sessions are planned over a 4 day period.  The philosophy of these Conferences, like Gordon Conferences, is to maximize opportunities for participants to discuss issues on the frontiers of electrocardiology.  Formal presentations with considerable time for discussion are held mornings and evenings. Afternoons are available for free discussion in small study groups or workshops; poster sessions are also held in the afternoons.  The scientific areas addressed ideally match the interests of the clinical electrocardiologist, electrophysiologist, and bioengineer readership of the Journal of Electrocardiology (1500 subscribers).  n/a",COMPUTERIZED ELECTROCARDIOLOGY,3435660,R13HL042521,"['United States', ' artificial intelligence', ' computer assisted medical decision making', ' electrocardiography', ' health science research', ' mathematical model', ' travel']",NHLBI,LOS ANGELES COUNTY HARBOR-UCLA MED CTR,R13,1989,14404,0.016068093491225864
"CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS The long-term objective of this research is to develop and test automated cell image analysis for the improved diagnosis and prognosis of cervical cancer. our previous research has shown that contextual analysis (low resolution analysis of scenes) and marker analysis (morphometric changes in ""normal"" looking cells) adds significant information to high resolution individual cell analysis of breast, prostate, and cervical neoplasia.  The previous studies were performed in several steps, which was inefficient and only permitted us to collect small data sets.  The primary objective of the proposed research is to develop an Integrated Analysis System (IAS) that will employ more sophisticated methods to combine the single cell, contextual, and marker analyses.  The first aim of this research is to develop a system to permit simultaneous contextual, marker, and individual cell analyses of monolayer preparations of exfoliated cervical cells.  This will include the use of adaptive methodologies that incorporate a priori information to guide the analysis process.  The second aim is to test the combined methodolology to determine whether it provides an improvement over any single analysis method. The third aim is to apply these technique to investigate the feasibility of discriminating persistent/progressive from regressive and negative cases.  This research should have significant impact on cost-containment and availability of cervical cytology for pre-screening of cervical cancer Automated cytology can partly offset the growing shortage of qualified cytotechnologists.  It can also provide more objective criteria for diagnosis and prognosis of cervical neoplasia at all levels of experience and training.  The same methodology can eventually be applied to expert systems for diagnosis and teaching.  Moreover, advances made in this research should be readily transferable to other types of human cancer. Thus, we expect that this research will have far-reaching effects on practical as well as scientific aspects of cancer prevention and control.  n/a",CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS,3185093,R01CA043133,"['DVD /CD ROM', ' artificial intelligence', ' biomarker', ' biomedical automation', ' cancer risk', ' cervical /vaginal smear', ' cervix neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' cytodiagnosis', ' cytology', ' data collection', ' diagnosis design /evaluation', ' digital imaging', ' female', ' human subject', ' image processing', ' mass screening', ' morphology', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' neoplastic transformation', ' prognosis', ' single cell analysis']",NCI,TUFTS MEDICAL CENTER,R01,1993,175145,-0.021920549112473316
"CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS The long-term objective of this research is to develop and test automated cell image analysis for the improved diagnosis and prognosis of cervical cancer. our previous research has shown that contextual analysis (low resolution analysis of scenes) and marker analysis (morphometric changes in ""normal"" looking cells) adds significant information to high resolution individual cell analysis of breast, prostate, and cervical neoplasia.  The previous studies were performed in several steps, which was inefficient and only permitted us to collect small data sets.  The primary objective of the proposed research is to develop an Integrated Analysis System (IAS) that will employ more sophisticated methods to combine the single cell, contextual, and marker analyses.  The first aim of this research is to develop a system to permit simultaneous contextual, marker, and individual cell analyses of monolayer preparations of exfoliated cervical cells.  This will include the use of adaptive methodologies that incorporate a priori information to guide the analysis process.  The second aim is to test the combined methodolology to determine whether it provides an improvement over any single analysis method. The third aim is to apply these technique to investigate the feasibility of discriminating persistent/progressive from regressive and negative cases.  This research should have significant impact on cost-containment and availability of cervical cytology for pre-screening of cervical cancer Automated cytology can partly offset the growing shortage of qualified cytotechnologists.  It can also provide more objective criteria for diagnosis and prognosis of cervical neoplasia at all levels of experience and training.  The same methodology can eventually be applied to expert systems for diagnosis and teaching.  Moreover, advances made in this research should be readily transferable to other types of human cancer. Thus, we expect that this research will have far-reaching effects on practical as well as scientific aspects of cancer prevention and control.  n/a",CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS,3185090,R01CA043133,"['DVD /CD ROM', ' artificial intelligence', ' biomarker', ' biomedical automation', ' cancer risk', ' cervical /vaginal smear', ' cervix neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' cytodiagnosis', ' cytology', ' data collection', ' diagnosis design /evaluation', ' digital imaging', ' female', ' human subject', ' image processing', ' mass screening', ' morphology', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' neoplastic transformation', ' prognosis', ' single cell analysis']",NCI,TUFTS MEDICAL CENTER,R01,1992,182944,-0.021920549112473316
"MODULAR EXPERT SYSTEM FOR HPLC METHOD DEVELOPMENT Despite 10 years of intensive research into computer-assisted method development for HPLC separation, relatively few chromatographers use these techniques to a significant extent. We propose to develop a computer program (MOSES - Modular Optimization Software/Expert System) that addresses this problem. Computer-simulation modules based on chromatographic theory will be integrated into an expert system framework that addresses most of the problems encountered during HPLC method development. The program will be applicable to both small-molecule samples (which most previous work addresses) and to large biomolecules of interest in the life sciences. The program will also assist in the selection of initial conditions, sample pretreatment, optimizing the separation and scaling up for preparative separation. Previously recognized needs in computer-assisted method development (e.g., user-friendly environment, reliable and convenient mapping of separation, peak tracking, etc.) will be addressed.  n/a",MODULAR EXPERT SYSTEM FOR HPLC METHOD DEVELOPMENT,3498561,R43GM045095,"['artificial intelligence', ' biomedical equipment development', ' computer program /software', ' computer simulation', ' high performance liquid chromatography']",NIGMS,"LC RESOURCES, INC.",R43,1990,49700,0.016379695147905698
"LOW DIMENSIONAL CHAOS, NONLINEAR MAPS & NERVOUS SYSTEM Neural systems often have significant components of their behavior that appear to be random.  Traditionally this randomness is modeled in stochastic and often linear terms.  Since neural systems consist of highly interconnected nonlinear elements, however, a natural alternative explanation is that the randomness derives from complex nonlinear dynamics such as chaos.  This has been suggested by experiments on several neural systems, including irregular firing patterns in the nervous systems of gastropod molluscs, the human electroencephalogram in deep sleep and epilepsy, single neuron recordings in the cat and monkey visual cortex, and hippus in the pupil-light reflex.  However, inmost cases the evidence for chaos remains inconclusive, in large part because the data analysis is based on techniques that are notoriously unreliable, such as currently popular algorithms for computing fractal dimension.  We have recently introduced a new approach to the analysis of experimental data, which is based on the identification of good features through nonlinear generalizations of principal component analysis, and the construction of nonlinear mappings using nonparametric techniques such as local approximation.  These nonlinear mappings can be used for several purposes, including prediction, noise reduction, and system characterization.  For time series data (e.g. sequences of interspike intervals) they provide more accurate and reliable methods for measuring fractal dimension and determining whether chaos is present.  For stimulus- response experiments (e.g. event related potentials and fields) they can be used to search for regularity and predictability, both for classification and generalization.  We propose to develop further our methods to cope with problems encountered in biological neural data, such as nonstationary behavior, and to apply our methods to data from neuroscience experiments including those listed above. This will allow us to determine with much more precision than has been achieved so far whether the apparent randomness of many neural phenomena derives from complex nonlinear dynamics.  If indeed this is the case, then the result might be a significant change in the paradigm used for modeling the nervous system.  If this is not the case, then we can avert pointless further work in this direction.  Our ultimate purpose is to discover any underlying deterministic structure that may currently lie hidden in apparently random neural phenomena.  n/a","LOW DIMENSIONAL CHAOS, NONLINEAR MAPS & NERVOUS SYSTEM",3387004,R01MH047184,"['computer program /software', ' computer simulation', ' electroencephalography', ' evoked potentials', ' mathematical model', ' neural information processing', ' neurobiology', ' single cell analysis', ' stimulus /response']",NIMH,UNIVERSITY OF CALIF-LOS ALAMOS NAT LAB,R01,1991,114743,-0.059243110183293056
"LOW DIMENSIONAL CHAOS, NONLINEAR MAPS & NERVOUS SYSTEM Neural systems often have significant components of their behavior that appear to be random.  Traditionally this randomness is modeled in stochastic and often linear terms.  Since neural systems consist of highly interconnected nonlinear elements, however, a natural alternative explanation is that the randomness derives from complex nonlinear dynamics such as chaos.  This has been suggested by experiments on several neural systems, including irregular firing patterns in the nervous systems of gastropod molluscs, the human electroencephalogram in deep sleep and epilepsy, single neuron recordings in the cat and monkey visual cortex, and hippus in the pupil-light reflex.  However, inmost cases the evidence for chaos remains inconclusive, in large part because the data analysis is based on techniques that are notoriously unreliable, such as currently popular algorithms for computing fractal dimension.  We have recently introduced a new approach to the analysis of experimental data, which is based on the identification of good features through nonlinear generalizations of principal component analysis, and the construction of nonlinear mappings using nonparametric techniques such as local approximation.  These nonlinear mappings can be used for several purposes, including prediction, noise reduction, and system characterization.  For time series data (e.g. sequences of interspike intervals) they provide more accurate and reliable methods for measuring fractal dimension and determining whether chaos is present.  For stimulus- response experiments (e.g. event related potentials and fields) they can be used to search for regularity and predictability, both for classification and generalization.  We propose to develop further our methods to cope with problems encountered in biological neural data, such as nonstationary behavior, and to apply our methods to data from neuroscience experiments including those listed above. This will allow us to determine with much more precision than has been achieved so far whether the apparent randomness of many neural phenomena derives from complex nonlinear dynamics.  If indeed this is the case, then the result might be a significant change in the paradigm used for modeling the nervous system.  If this is not the case, then we can avert pointless further work in this direction.  Our ultimate purpose is to discover any underlying deterministic structure that may currently lie hidden in apparently random neural phenomena.  n/a","LOW DIMENSIONAL CHAOS, NONLINEAR MAPS & NERVOUS SYSTEM",3387003,R01MH047184,"['computer program /software', ' computer simulation', ' electroencephalography', ' evoked potentials', ' mathematical model', ' neural information processing', ' neurobiology', ' single cell analysis', ' stimulus /response']",NIMH,UNIVERSITY OF CALIF-LOS ALAMOS NAT LAB,R01,1990,110200,-0.059243110183293056
"OPTIMIZATION OF MULTIDIMENSIONAL NMR DATA ANALYSIS The advent of efficient methods for isotopic enrichment of proteins with 13C and 15N, together with the development of three- and four-dimensional (3D and 4D) NMR methods, now makes it possible to study in detail the structure and dynamics of proteins in the 15-30 kD molecular weight range, as was demonstrated most recently for the proteins interleukin- 1beta, calmodulin complexed with a fragment of myosin light chain kinase and interferon-gamma.  However, the present procedures for data collection and analysis are extremely time consuming, and the spectral resolution obtainable frequently presents a limiting factor.  The goal of this proposal is the development of improved and new procedures for the analysis of multi-dimensional NMR spectra. Significant improvements over present methodology are expected to be possible considering that most of the methodology presently does not utilize the advances which have been made in the last decade in the area of signal processing.  Improved and new procedures will focus on but not limit to the following:  (1) Improvement of the linear prediction methods:  improving the stability and computation efficiency of the 1-D and 2-D linear prediction algorithms.  (2) Optimization of a priori information:  Use of a priori information in NMR data to improve the spectral resolution.  (3) Non-linear spectral enhancement:  Development of the 3-D maximum entropy method and improving the convergence rate of methods based on iterative deconvolution.  (4) Development of fast algorithms:  Development of fast routines that make possible the use of algorithms in multi-dimensional space.  (5) signal subspace approach: Separation of the signal and the noise subspace to obtain high NMR spectral resolution.  (6) Higher-order spectra estimation:  Use of high- order statistics to gain a better estimate of dense NMR spectra.  (7) Multi-resolution techniques:  New signal representation for NMR data to achieve optimal interpretation and processing.  (8) Data compression: Compression of multi-dimensional NMR data by removing redundant information for processing, networking, and archiving.  (9) Parallel implementation:  Development of parallel routines for high-performance parallel computing.  Emphasis will be on the development of code which is easily transportable and which will be made freely available to the NMR community.  The complexities of the task of developing algorithms and software for advanced processing of multi-dimensional NMR data are substantial and require effective integration of expertise in the areas of NMR and signal processing.  This proposal is designed to foster such integration.  n/a",OPTIMIZATION OF MULTIDIMENSIONAL NMR DATA ANALYSIS,2187241,R01GM049707,"['artificial intelligence', ' bioengineering /biomedical engineering', ' computer program /software', ' computer system design /evaluation', ' mathematical model', ' method development', ' model design /development', ' nuclear magnetic resonance spectroscopy', ' parallel processing', ' protein structure']",NIGMS,UNIVERSITY OF MARYLAND COLLEGE PK CAMPUS,R01,1994,99974,0.022631671508499308
"OPTIMIZATION OF MULTIDIMENSIONAL NMR DATA ANALYSIS The advent of efficient methods for isotopic enrichment of proteins with 13C and 15N, together with the development of three- and four-dimensional (3D and 4D) NMR methods, now makes it possible to study in detail the structure and dynamics of proteins in the 15-30 kD molecular weight range, as was demonstrated most recently for the proteins interleukin- 1beta, calmodulin complexed with a fragment of myosin light chain kinase and interferon-gamma.  However, the present procedures for data collection and analysis are extremely time consuming, and the spectral resolution obtainable frequently presents a limiting factor.  The goal of this proposal is the development of improved and new procedures for the analysis of multi-dimensional NMR spectra. Significant improvements over present methodology are expected to be possible considering that most of the methodology presently does not utilize the advances which have been made in the last decade in the area of signal processing.  Improved and new procedures will focus on but not limit to the following:  (1) Improvement of the linear prediction methods:  improving the stability and computation efficiency of the 1-D and 2-D linear prediction algorithms.  (2) Optimization of a priori information:  Use of a priori information in NMR data to improve the spectral resolution.  (3) Non-linear spectral enhancement:  Development of the 3-D maximum entropy method and improving the convergence rate of methods based on iterative deconvolution.  (4) Development of fast algorithms:  Development of fast routines that make possible the use of algorithms in multi-dimensional space.  (5) signal subspace approach: Separation of the signal and the noise subspace to obtain high NMR spectral resolution.  (6) Higher-order spectra estimation:  Use of high- order statistics to gain a better estimate of dense NMR spectra.  (7) Multi-resolution techniques:  New signal representation for NMR data to achieve optimal interpretation and processing.  (8) Data compression: Compression of multi-dimensional NMR data by removing redundant information for processing, networking, and archiving.  (9) Parallel implementation:  Development of parallel routines for high-performance parallel computing.  Emphasis will be on the development of code which is easily transportable and which will be made freely available to the NMR community.  The complexities of the task of developing algorithms and software for advanced processing of multi-dimensional NMR data are substantial and require effective integration of expertise in the areas of NMR and signal processing.  This proposal is designed to foster such integration.  n/a",OPTIMIZATION OF MULTIDIMENSIONAL NMR DATA ANALYSIS,3308869,R01GM049707,"['artificial intelligence', ' bioengineering /biomedical engineering', ' computer program /software', ' computer system design /evaluation', ' mathematical model', ' method development', ' model design /development', ' nuclear magnetic resonance spectroscopy', ' parallel processing', ' protein structure']",NIGMS,UNIVERSITY OF MARYLAND COLLEGE PK CAMPUS,R01,1993,96129,0.022631671508499308
"AMPLIFIERS--DENSE ELECTRODE ARRAY ELECTROENCEPHALOGRAPHY The proposed research would develop an inexpensive electro- encephalographic (EEG) amplifier system suitable for dense (128 or 256) electrode arrays. These arrays would provide the measurements necessary for new source localization algorithms constrained by MRI data that image the electrical activity of the cortex throughout the three dimensions of intracranial space.  Although the anatomical resolution of these images remains to be determined, they are generated for each millisecond sample of electrical recording, and thus, provide information with a temporal resolution not possible with metabolic and hemodynamic methods of neuroimaging. This temporal resolution may be necessary to research the cognitive activity of cortical networks.  The major advances in visualizing dynamic brain function promised by this new technology will have immediate applications in psychology, neurology, psychiatry, education, and human factors research.  Within 5 years, this research will provide the basis for widespread clinical applications of this technology to public health problems ranging from attention deficit disorder to Alzheimer's dementia.  n/a",AMPLIFIERS--DENSE ELECTRODE ARRAY ELECTROENCEPHALOGRAPHY,3503466,R43MH051069,"['artificial intelligence', ' biomedical equipment development', ' brain electrical activity', ' brain imaging /visualization /scanning', ' clinical biomedical equipment', ' computer program /software', ' electrodes', ' electroencephalography']",NIMH,"ELECTRICAL GEODESICS, INC.",R43,1993,50000,0.0031708630282054635
"Identification and tracking of neural stem cells in vivo: a metabolomic approach    DESCRIPTION (provided by applicant):  The ability to identify human neural stem cells (NSC) by brain imaging may have profound implications for diagnostic, prognostic, and therapeutic purposes.  Currently, there are no clinical, high-resolution imaging techniques that enable investigations of the survival, migration, fate, and function of unlabeled NSC and their progeny.  The study of human NSC in vivo is hindered by the absence of well-defined markers that can distinguish them from other neural cell types.  The goal of this proposal is to define markers of NSC by characterizing metabolomic fingerprint of NSC both in vitro and in vivo.  Our objectives are to develop novel imaging and signal processing methodologies that would enable non-invasive investigations of NSC behavior in healthy and disease states, from early human development to older age.  We hypothesize that mammalian NSC have a specific metabolic marker that can be identified by spectroscopy.  Our specific aims are:  1) to characterize a metabolomic fingerprint of NSC in vitro using proton nuclear magnetic resonance (1H-NMR) spectroscopy and to compare it to the neuronal and glial 1H-NMR fingerprints; 2) to develop high resolution proton MR spectroscopy (1H-MRS) acquisition protocols that will allow for characterization of the NSC fate in vivo; 3) to develop signal processing algorithms that will provide accurate estimates of cell densities even from data with low signal-to-noise ratio and limited spectral, spatial, and temporal resolutions.  Our preliminary experiments have demonstrated that we are able to identify the NSC on the basis of their 1H-NMR metabolomic fingerprint.  In addition, we can detect both endogenous and exogenous NSC in the living rat brain, using 1H-MRS and 9.4T mMRI scanner.  We plan to further characterize the metabolomic signature of NSC and other neural cell types, and to further perform metabolomic profiling of the living rat brain.  The signal processing algorithms for identification, quantification, and tracking of NSC in vivo will be based on singular value decomposition methodology and will exploit prior knowledge gained from in vitro experiments.  This innovative research will not only demonstrate the feasibility of using 1H-MRS spectroscopy for metabolomic investigations in vivo, but will also lead to a breakthrough in the field of stem cell research.  Most importantly, this research is an essential prerequisite for future clinical investigations of NSC.  The ability to monitor the fundamental changes of the NSC in the human brain will instigate new studies of neurological disorders where NSC pathology might contribute to the etiology of the disease and will initiate developments of new treatments.  The proposed research is intrinsically multidisciplinary and involves collaborations of neuroscientists, physicists, engineers, chemists, and imaging scientists.  Each of them will provide unique yet complementary expertise and resources available at the Stony Brook University and Brookhaven National Laboratory.         n/a",Identification and tracking of neural stem cells in vivo: a metabolomic approach,7286826,R21NS053875,"['18 year old', 'Address', 'Affect', 'Age', 'Algorithms', 'Astrocytes', 'Biological', 'Brain', 'Brain imaging', 'Brain region', 'Cell Density', 'Cells', 'Cerebral Palsy', 'Cessation of life', 'Chemicals', 'Child', 'Choline', 'Chronic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Complex', 'Condition', 'Contrast Media', 'Data', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Emission-Computed Tomography', 'Engineering', 'Etiology', 'Face', 'Fingerprint', 'Functional disorder', 'Future', 'Goals', 'Human', 'Human Development', 'Image', 'Imaging Techniques', 'Imaging technology', 'In Vitro', 'Invasive', 'Investigation', 'Knowledge', 'Laboratories', 'Lead', 'Life', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Mental Retardation', 'Metabolic', 'Metabolic Marker', 'Methodology', 'Modality', 'Monitor', 'Mus', 'N-acetylaspartate', 'NMR Spectroscopy', 'Neurologic', 'Neurons', 'Noise', 'Nuclear Magnetic Resonance', 'Pathology', 'Perinatal', 'Photons', 'Population', 'Positron-Emission Tomography', 'Protocols documentation', 'Protons', 'Purpose', 'Rattus', 'Reagent', 'Research', 'Resolution', 'Resources', 'Scanning', 'Scientist', 'Signal Transduction', 'Specificity', 'Spectrum Analysis', 'Stem Cell Research', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Transplantation', 'Universities', 'Ursidae Family', 'base', 'brain tissue', 'cell behavior', 'cell type', 'computerized data processing', 'data acquisition', 'density', 'dentate gyrus', 'in vivo', 'innovation', 'interest', 'iron oxide', 'metabolomics', 'migration', 'multidisciplinary', 'myoinositol', 'neonate', 'nerve stem cell', 'nervous system disorder', 'novel', 'novel strategies', 'prenatal', 'prognostic', 'research study', 'stem cell fate']",NINDS,STATE UNIVERSITY NEW YORK STONY BROOK,R21,2007,169319,0.004846642814524615
"Identification and tracking of neural stem cells in vivo: a metabolomic approach    DESCRIPTION (provided by applicant):  The ability to identify human neural stem cells (NSC) by brain imaging may have profound implications for diagnostic, prognostic, and therapeutic purposes.  Currently, there are no clinical, high-resolution imaging techniques that enable investigations of the survival, migration, fate, and function of unlabeled NSC and their progeny.  The study of human NSC in vivo is hindered by the absence of well-defined markers that can distinguish them from other neural cell types.  The goal of this proposal is to define markers of NSC by characterizing metabolomic fingerprint of NSC both in vitro and in vivo.  Our objectives are to develop novel imaging and signal processing methodologies that would enable non-invasive investigations of NSC behavior in healthy and disease states, from early human development to older age.  We hypothesize that mammalian NSC have a specific metabolic marker that can be identified by spectroscopy.  Our specific aims are:  1) to characterize a metabolomic fingerprint of NSC in vitro using proton nuclear magnetic resonance (1H-NMR) spectroscopy and to compare it to the neuronal and glial 1H-NMR fingerprints; 2) to develop high resolution proton MR spectroscopy (1H-MRS) acquisition protocols that will allow for characterization of the NSC fate in vivo; 3) to develop signal processing algorithms that will provide accurate estimates of cell densities even from data with low signal-to-noise ratio and limited spectral, spatial, and temporal resolutions.  Our preliminary experiments have demonstrated that we are able to identify the NSC on the basis of their 1H-NMR metabolomic fingerprint.  In addition, we can detect both endogenous and exogenous NSC in the living rat brain, using 1H-MRS and 9.4T mMRI scanner.  We plan to further characterize the metabolomic signature of NSC and other neural cell types, and to further perform metabolomic profiling of the living rat brain.  The signal processing algorithms for identification, quantification, and tracking of NSC in vivo will be based on singular value decomposition methodology and will exploit prior knowledge gained from in vitro experiments.  This innovative research will not only demonstrate the feasibility of using 1H-MRS spectroscopy for metabolomic investigations in vivo, but will also lead to a breakthrough in the field of stem cell research.  Most importantly, this research is an essential prerequisite for future clinical investigations of NSC.  The ability to monitor the fundamental changes of the NSC in the human brain will instigate new studies of neurological disorders where NSC pathology might contribute to the etiology of the disease and will initiate developments of new treatments.  The proposed research is intrinsically multidisciplinary and involves collaborations of neuroscientists, physicists, engineers, chemists, and imaging scientists.  Each of them will provide unique yet complementary expertise and resources available at the Stony Brook University and Brookhaven National Laboratory.         n/a",Identification and tracking of neural stem cells in vivo: a metabolomic approach,7145549,R21NS053875,"['brain', 'cell type', 'human', 'hydrogen ions', 'metabolomics', 'stem cells', 'tissues']",NINDS,STATE UNIVERSITY NEW YORK STONY BROOK,R21,2006,209250,0.004846642814524615
"MULTIMODAL (MRI/EEG/MEG) IMAGING SOFTWARE Multimodal functional brain imaging software will be developed to                estimate and visualize the estimated spatial extent and time course of           brain activity by combining information from magnetic resonance imaging          (MRI) with electroencephalography (EEG) and/or magnetoencephalography            (MEG).  Structural information from MRI will be combined with                    extracranial EEG and/or MEG measurements through algorithms developed            to segment the MR images and to represent scalp, skull, and brain                boundaries as computational objects.  This structural information may            then be used to improve the spatial accuracy and resolution of existing          EEG and MEG source estimation algorithms, while supporting millisecond           temporal resolution.  The software will comprise a PC/Windows-based              program suite for analysis and display.  The methods will be verified            both with simulated data and with physiological data.                                                                                                             The algorithms and software may be used to study both normal brain               function, such as measurements in cognitive neuroscience which may be            studied with evoked response/event related potentials or spontaneous             EEG, and in diseases of the brain, such as epilepsy, where precise               spatial and temporal resolution may be of value for diagnosis and                presurgical evaluation.                                                                                                                                           PROPOSED COMMERCIAL APPLICATION                                                  The techniques which we propose are a non-invasive, non-radiological and         relatively low cost addition to existing EEG, MEG and MRI systems, and           provides information which is not currently available from these systems         independently.  The resulting software will have direct application in           clinical and cognitive neuroscience research.  If clinical value is              demonstrated, systems based on this methodology may find applications            in the areas of psychiatry, neurology and psychology.                             n/a",MULTIMODAL (MRI/EEG/MEG) IMAGING SOFTWARE,2890817,R44MH055915,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain electrical activity', ' computer program /software', ' computer system design /evaluation', ' electroencephalography', ' functional magnetic resonance imaging', ' human data', ' image enhancement', ' image processing', ' magnetic resonance imaging', ' magnetoencephalography', ' positron emission tomography']",NIMH,"SOURCE SIGNAL IMAGING, INC.",R44,1999,376894,-0.015224460008428023
"MULTIMODAL (MRI/EEG/MEG) IMAGING SOFTWARE Multimodal functional brain imaging software will be developed to                estimate and visualize the estimated spatial extent and time course of           brain activity by combining information from magnetic resonance imaging          (MRI) with electroencephalography (EEG) and/or magnetoencephalography            (MEG).  Structural information from MRI will be combined with                    extracranial EEG and/or MEG measurements through algorithms developed            to segment the MR images and to represent scalp, skull, and brain                boundaries as computational objects.  This structural information may            then be used to improve the spatial accuracy and resolution of existing          EEG and MEG source estimation algorithms, while supporting millisecond           temporal resolution.  The software will comprise a PC/Windows-based              program suite for analysis and display.  The methods will be verified            both with simulated data and with physiological data.                                                                                                             The algorithms and software may be used to study both normal brain               function, such as measurements in cognitive neuroscience which may be            studied with evoked response/event related potentials or spontaneous             EEG, and in diseases of the brain, such as epilepsy, where precise               spatial and temporal resolution may be of value for diagnosis and                presurgical evaluation.                                                                                                                                           PROPOSED COMMERCIAL APPLICATION                                                  The techniques which we propose are a non-invasive, non-radiological and         relatively low cost addition to existing EEG, MEG and MRI systems, and           provides information which is not currently available from these systems         independently.  The resulting software will have direct application in           clinical and cognitive neuroscience research.  If clinical value is              demonstrated, systems based on this methodology may find applications            in the areas of psychiatry, neurology and psychology.                             n/a",MULTIMODAL (MRI/EEG/MEG) IMAGING SOFTWARE,2536158,R44MH055915,"['artificial intelligence', ' brain electrical activity', ' computer program /software', ' computer system design /evaluation', ' electroencephalography', ' functional magnetic resonance imaging', ' human data', ' image enhancement', ' image processing', ' magnetic resonance imaging', ' magnetoencephalography', ' positron emission tomography']",NIMH,"SOURCE SIGNAL IMAGING, INC.",R44,1998,372691,-0.015224460008428023
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,6180774,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2000,283617,0.02029287059876889
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,2900912,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1999,207192,0.02029287059876889
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,2685132,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1998,172242,0.02029287059876889
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,2441883,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1997,185122,0.02029287059876889
"Defining the complex genetics of JIA     DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (08): Genomics and specific Challenge Topic, 08-AR-101 Genotyping of Existing Cohorts in Rheumatic, Skin, and Musculoskeletal Diseases. Juvenile idiopathic arthritis (JIA) is the most common autoimmune rheumatic disease of childhood and represents a series of childhood arthropathies that are largely based on clinically defined phenotypes. The two most common subtypes, and the focus of this study, are the oligoarticular and IgM rheumatoid factor negative (RF-) polyarticular forms of JIA. It is hypothesized that there are multiple genetic variants that predispose an individual to JIA and that the subtypes of JIA will differ in at least some of their susceptibility traits. Markers for these traits can be identified by systematically applying high throughput genotyping and copy number technology in a case:control genome-wide association study (GWAS) design. Phase I (GWAS I) genotyping has been completed and includes 1.8 million single nucleotide polymorphisms (SNPs) or copy number markers for 946 JIA cases and 1000 controls (Affymetrix(R) Genome-Wide Human SNP Array 6.0). Through this challenge grant opportunity, a second GWAS (GWAS-II) is proposed for 1100 additional existing JIA samples available from U.S. investigators of the Consortium on Juvenile Arthritis Genetics (CJAG) and international collaborators in Germany. Phenotypic information includes ILAR classification, age at disease onset, and joint counts. Approximately 1450 out-of-study controls are available through the GAIN study will be used for comparison in association testing for GWAS-II. This additional dataset when combined with existing complementary data from GWAS-I provides an unprecedented opportunity to reveal novel risk factors for JIA and is necessary for advancement of the field. This information may eventually lead to treatments for these disabling diseases and in the long-term contribute to preventing disability. In additional, this opportunity will contribute to a fundamental shift toward molecular definitions and reevaluation of the present criteria for defining subtypes of disease. This research proposal tests the view that juvenile idiopathic arthritis or JIA, is influenced by many genes conferring susceptibility to and protection from disease. As the genetic basis of the major autoimmune rheumatic disease of childhood becomes evident, eventually the treatment of these disabling diseases will become possible with the long term aim of preventing disability.                  Project Narrative This research proposal tests the view that juvenile idiopathic arthritis or JIA, is influenced by many genes conferring susceptibility to and protection from disease. As the genetic basis of the major autoimmune rheumatic disease of childhood becomes evident, eventually the treatment of these disabling diseases will become possible with the long term aim of preventing disability.",Defining the complex genetics of JIA,7941791,RC1AR058587,"['Address', 'Admixture', 'Affect', 'Age', 'Age of Onset', 'Algorithms', 'American', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Childhood', 'Chronic Childhood Arthritis', 'Classification', 'Clinical', 'Collection', 'Complex', 'Complex Genetic Trait', 'Controlled Study', 'Copy Number Polymorphism', 'DNA', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'European', 'Evaluation', 'Family history of', 'Funding', 'Gender', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Germany', 'Goals', 'Grant', 'HLA Antigens', 'Human', 'Immunoglobulin M', 'Individual', 'International', 'Joints', 'Laboratories', 'Lead', 'Linkage Disequilibrium', 'Mission', 'Molecular', 'Molecular Profiling', 'Musculoskeletal Diseases', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Odds Ratio', 'Onset of illness', 'Other Genetics', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Phase', 'Phenotype', 'Predisposition', 'Principal Component Analysis', 'Quality Control', 'Reporting', 'Research Design', 'Research Personnel', 'Research Proposals', 'Rheumatism', 'Rheumatoid Factor', 'Rheumatology', 'Risk', 'Risk Factors', 'Sampling', 'Series', 'Single Nucleotide Polymorphism', 'Skin', 'Subgroup', 'Susceptibility Gene', 'Technology', 'Testing', 'Therapeutic', 'Variant', 'arthropathies', 'base', 'case control', 'cohort', 'college', 'database of Genotypes and Phenotypes', 'disability', 'disabling disease', 'disorder subtype', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'novel', 'prevent', 'programs', 'response', 'trait']",NIAMS,CINCINNATI CHILDRENS HOSP MED CTR,RC1,2010,500000,-0.03979956001903733
"Defining the complex genetics of JIA     DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (08): Genomics and specific Challenge Topic, 08-AR-101 Genotyping of Existing Cohorts in Rheumatic, Skin, and Musculoskeletal Diseases. Juvenile idiopathic arthritis (JIA) is the most common autoimmune rheumatic disease of childhood and represents a series of childhood arthropathies that are largely based on clinically defined phenotypes. The two most common subtypes, and the focus of this study, are the oligoarticular and IgM rheumatoid factor negative (RF-) polyarticular forms of JIA. It is hypothesized that there are multiple genetic variants that predispose an individual to JIA and that the subtypes of JIA will differ in at least some of their susceptibility traits. Markers for these traits can be identified by systematically applying high throughput genotyping and copy number technology in a case:control genome-wide association study (GWAS) design. Phase I (GWAS I) genotyping has been completed and includes 1.8 million single nucleotide polymorphisms (SNPs) or copy number markers for 946 JIA cases and 1000 controls (Affymetrix(R) Genome-Wide Human SNP Array 6.0). Through this challenge grant opportunity, a second GWAS (GWAS-II) is proposed for 1100 additional existing JIA samples available from U.S. investigators of the Consortium on Juvenile Arthritis Genetics (CJAG) and international collaborators in Germany. Phenotypic information includes ILAR classification, age at disease onset, and joint counts. Approximately 1450 out-of-study controls are available through the GAIN study will be used for comparison in association testing for GWAS-II. This additional dataset when combined with existing complementary data from GWAS-I provides an unprecedented opportunity to reveal novel risk factors for JIA and is necessary for advancement of the field. This information may eventually lead to treatments for these disabling diseases and in the long-term contribute to preventing disability. In additional, this opportunity will contribute to a fundamental shift toward molecular definitions and reevaluation of the present criteria for defining subtypes of disease. This research proposal tests the view that juvenile idiopathic arthritis or JIA, is influenced by many genes conferring susceptibility to and protection from disease. As the genetic basis of the major autoimmune rheumatic disease of childhood becomes evident, eventually the treatment of these disabling diseases will become possible with the long term aim of preventing disability.                  Project Narrative This research proposal tests the view that juvenile idiopathic arthritis or JIA, is influenced by many genes conferring susceptibility to and protection from disease. As the genetic basis of the major autoimmune rheumatic disease of childhood becomes evident, eventually the treatment of these disabling diseases will become possible with the long term aim of preventing disability.",Defining the complex genetics of JIA,7833176,RC1AR058587,"['Address', 'Admixture', 'Affect', 'Age', 'Age of Onset', 'Algorithms', 'American', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Childhood', 'Chronic Childhood Arthritis', 'Classification', 'Clinical', 'Collection', 'Complex', 'Complex Genetic Trait', 'Controlled Study', 'Copy Number Polymorphism', 'DNA', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'European', 'Evaluation', 'Family history of', 'Funding', 'Gender', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Germany', 'Goals', 'Grant', 'HLA Antigens', 'Human', 'Immunoglobulin M', 'Individual', 'International', 'Joints', 'Laboratories', 'Lead', 'Linkage Disequilibrium', 'Mission', 'Molecular', 'Molecular Profiling', 'Musculoskeletal Diseases', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Odds Ratio', 'Onset of illness', 'Other Genetics', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Phase', 'Phenotype', 'Predisposition', 'Principal Component Analysis', 'Quality Control', 'Reporting', 'Research Design', 'Research Personnel', 'Research Proposals', 'Rheumatism', 'Rheumatoid Factor', 'Rheumatology', 'Risk', 'Risk Factors', 'Sampling', 'Series', 'Single Nucleotide Polymorphism', 'Skin', 'Subgroup', 'Susceptibility Gene', 'Technology', 'Testing', 'Therapeutic', 'Variant', 'arthropathies', 'base', 'case control', 'cohort', 'college', 'database of Genotypes and Phenotypes', 'disability', 'disabling disease', 'disorder subtype', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'novel', 'prevent', 'programs', 'response', 'trait']",NIAMS,CINCINNATI CHILDRENS HOSP MED CTR,RC1,2009,500000,-0.03979956001903733
"PATTERN RECOGNITION IN MACROMOLECULAR CRYSTALLOGRAPHY Computer algorithms based on pattern recognition are being used in many areas of science and technology to assist the scientist in solving complex, time-consuming, and often tedious real-world problems.  The basic premise is to train a computer to efficiently identify a known pattern in an unknown dataset.  This needle-in-a-haystack approach is being used in the area of genomics, where there are already several examples of very powerful computational pattern recognition approaches available for searching new sequences for structural motifs, similarities to other proteins and DNA, and predicting secondary structure, based solely on the DNA or amino acid sequence.  We believe that macromolecular crystallography can also benefit from the application of pattern recognition to the often daunting task of fitting atoms into an electron density map.  The fact that electron density maps are three-dimensional images provides an additional challenge to this technology in that the procedures we are developing in order to find matching patterns must be rotation invariant.  To test the validity of our hypothesis we will complete the following aims: 1) we will develop a set of rotation invariant features that can characterize the patterns in regions of an electron density map, 2) we will determine the optimal size of feature regions and the size and type of structural database required to find similar regions of electron density capable of accurately determining structures, and 3) we will develop a methodology to synthesize matched regions to produce coherent local and global models of protein structure. If these goals can be met, we will investigate the feasibility of incorporating knowledge-based methods, neural networks, and other AI techniques to augment the interpretation of structures from electron density maps.  In addition, we will attempt to extend this methodology to produce initial structures for electron density maps that are either of poor quality and/or low resolution.  n/a",PATTERN RECOGNITION IN MACROMOLECULAR CRYSTALLOGRAPHY,6182183,R21GM059398,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer simulation', ' computer system design /evaluation', ' electron crystallography', ' electron density', ' molecular biology information system', ' physical model', ' protein structure', ' structural biology']",NIGMS,TEXAS ENGINEERING EXPERIMENT STATION,R21,2000,101500,0.02090589548199651
"PATTERN RECOGNITION IN MACROMOLECULAR CRYSTALLOGRAPHY Computer algorithms based on pattern recognition are being used in many areas of science and technology to assist the scientist in solving complex, time-consuming, and often tedious real-world problems.  The basic premise is to train a computer to efficiently identify a known pattern in an unknown dataset.  This needle-in-a-haystack approach is being used in the area of genomics, where there are already several examples of very powerful computational pattern recognition approaches available for searching new sequences for structural motifs, similarities to other proteins and DNA, and predicting secondary structure, based solely on the DNA or amino acid sequence.  We believe that macromolecular crystallography can also benefit from the application of pattern recognition to the often daunting task of fitting atoms into an electron density map.  The fact that electron density maps are three-dimensional images provides an additional challenge to this technology in that the procedures we are developing in order to find matching patterns must be rotation invariant.  To test the validity of our hypothesis we will complete the following aims: 1) we will develop a set of rotation invariant features that can characterize the patterns in regions of an electron density map, 2) we will determine the optimal size of feature regions and the size and type of structural database required to find similar regions of electron density capable of accurately determining structures, and 3) we will develop a methodology to synthesize matched regions to produce coherent local and global models of protein structure. If these goals can be met, we will investigate the feasibility of incorporating knowledge-based methods, neural networks, and other AI techniques to augment the interpretation of structures from electron density maps.  In addition, we will attempt to extend this methodology to produce initial structures for electron density maps that are either of poor quality and/or low resolution.  n/a",PATTERN RECOGNITION IN MACROMOLECULAR CRYSTALLOGRAPHY,2835580,R21GM059398,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer simulation', ' computer system design /evaluation', ' electron crystallography', ' electron density', ' molecular biology information system', ' physical model', ' protein structure', ' structural biology']",NIGMS,TEXAS ENGINEERING EXPERIMENT STATION,R21,1999,101500,0.02090589548199651
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9923542,R01AG059874,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Differences', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data harmonization', 'data reuse', 'data sharing', 'data tools', 'demented', 'dementia risk', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,619917,-0.016377620320310083
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9750590,R01AG059874,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Differences', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data sharing', 'demented', 'dementia risk', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,619917,-0.016377620320310083
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9578938,R01AG059874,"['Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Characteristics', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data sharing', 'demented', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,619917,-0.016377620320310083
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures. Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8848345,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'differential expression', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait', 'transcriptome sequencing']",NIAMS,SOUTHWEST RESEARCH INSTITUTE,R01,2015,468202,0.009643896505680176
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics    DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures.        Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.         ",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8665879,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Simulate', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait', 'transcriptome sequencing']",NIAMS,TEXAS BIOMEDICAL RESEARCH INSTITUTE,R01,2014,494390,0.009643896505680176
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics    DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures.        Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.         ",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8471655,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Simulate', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait', 'transcriptome sequencing']",NIAMS,TEXAS BIOMEDICAL RESEARCH INSTITUTE,R01,2013,639128,0.009643896505680176
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics    DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures.        Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.         ",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8301575,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Gene Expression Profile', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Simulate', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait']",NIAMS,TEXAS BIOMEDICAL RESEARCH INSTITUTE,R01,2012,713809,0.009643896505680176
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics    DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures.      PUBLIC HEALTH RELEVANCE: Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.           Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.         ",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8187565,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Gene Expression Profile', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Simulate', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait']",NIAMS,TEXAS BIOMEDICAL RESEARCH INSTITUTE,R01,2011,723535,0.008166597267215778
"High Resolution in Single Particle Reconstruction DESCRIPTION (provided by applicant): The focus of this renewal application will be on the development of single particle cryo-EM structure determination methods that incorporate validation, assessment of alignment errors, and cross-validation of observed conformational variability. We will concentrate on three specific areas: (1) establishment of a well- defined goal function for structure determination, (2) structure refinement methods that incorporate validation of the outcome, and (3) quantitative analysis of conformational variability cross-validated by X-ray model-based simulations.  In (1), we will establish a goal function (a single-valued function of the 3D map and/or projection data) that would have a global extremum for the correct structure and which can be related to intuitive notion of resolution of the map. A goal function with such properties would make possible a critical evaluation of the ability of existing structure determination methods to deliver optimal structures and establish a theoretical basis for unification and rationalization of 3D-EM single particle structure determination methodology. In (2), we will introduce novel quantitative single particle cryo-EM methodology, based on jackknife-d resampling, designed to yield an estimate of alignment errors and eliminate ""reference bias"" that results in artifactual features that are indistinguishable from genuine ones in the absence of external standards. Incorporation of these developments into cryo-EM structure determination algorithms will make possible objective validation of a refined 3D map. They will provide, for the first time, a simple but robust way to eliminate artifacts and will thus increase the level of confidence in cryo-EM results. In (3), we will use our projection data resampling methodology to calculate (directly from the data) eigenvectors characterizing the conformational variability of a structure. We will then develop a deconvolution algorithm that will use this eigenvector information to eliminate from a 3D map the blurring caused by residual alignment errors. We will also use the eigenanalysis to characterize local mobility of a macromolecule and bridge the gap between experimental cryo-EM structure determination and simulations of conformational variability based on physical models. By cross-validating our methodology with the results of molecular dynamics simulations we will provide a novel tool for analyzing the energy landscape of large macromolecules.  Rather than incremental improvements, the methods we propose to develop will put single particle cryo-EM analysis on a new path towards full reliability of the results, eliminating the uncertainty that currently hinder fulfillment of cryo-EM's full potential. To assure multi-platform portability and immediate dissemination, these new methods will be implemented within the SPARX image processing package. PUBLIC HEALTH RELEVANCE: High-resolution cryo-electron microscopy (cryo-EM) has become an important tool for the structure/function determination of large macromolecular complexes. Even at limited resolution cryo-EM maps provide a wealth of structural information, eventually leading to determination of the secondary structure, as demonstrated by our work on the structure of the ribosome. In addition, cryo-EM is a unique structural technique in its ability to detect conformational variability of large molecular assemblies within one sample that may contain a mixture of complexes in various conformational states. We propose development of dedicated data processing and statistical tools for reliable cryo-EM structure determination, particularly in the absence of external information, and for studies of conformational modes of the structure, as directly obtained from the EM data.",High Resolution in Single Particle Reconstruction,9132862,R01GM060635,"['Algorithms', 'Area', 'Berlin', 'Complex', 'Complex Mixtures', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Development', 'Electron Microscopy', 'Elements', 'Environment', 'Evaluation', 'Foundations', 'Freezing', 'Genetic Transcription', 'Goals', 'Health', 'Image', 'Laboratories', 'Libraries', 'Ligand Binding', 'Link', 'Macromolecular Complexes', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Morphologic artifacts', 'Noise', 'Outcome', 'Peptide Elongation Factor G', 'Principal Component Analysis', 'Procedures', 'Property', 'Rationalization', 'Reliability of Results', 'Reproducibility', 'Research Institute', 'Residual state', 'Resolution', 'Ribosomes', 'Rice', 'Roentgen Rays', 'Sampling', 'Specimen', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Universities', 'Validation', 'Work', 'base', 'blind', 'computerized data processing', 'computerized tools', 'design', 'image processing', 'macromolecular assembly', 'macromolecule', 'microscopic imaging', 'models and simulation', 'molecular assembly/self assembly', 'molecular dynamics', 'novel', 'particle', 'physical model', 'portability', 'programs', 'reconstruction', 'simulation', 'three dimensional structure', 'three-dimensional modeling', 'tool']",NIGMS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,304000,0.042695627052861077
"High Resolution in Single Particle Reconstruction DESCRIPTION (provided by applicant): The focus of this renewal application will be on the development of single particle cryo-EM structure determination methods that incorporate validation, assessment of alignment errors, and cross-validation of observed conformational variability. We will concentrate on three specific areas: (1) establishment of a well- defined goal function for structure determination, (2) structure refinement methods that incorporate validation of the outcome, and (3) quantitative analysis of conformational variability cross-validated by X-ray model-based simulations.  In (1), we will establish a goal function (a single-valued function of the 3D map and/or projection data) that would have a global extremum for the correct structure and which can be related to intuitive notion of resolution of the map. A goal function with such properties would make possible a critical evaluation of the ability of existing structure determination methods to deliver optimal structures and establish a theoretical basis for unification and rationalization of 3D-EM single particle structure determination methodology. In (2), we will introduce novel quantitative single particle cryo-EM methodology, based on jackknife-d resampling, designed to yield an estimate of alignment errors and eliminate ""reference bias"" that results in artifactual features that are indistinguishable from genuine ones in the absence of external standards. Incorporation of these developments into cryo-EM structure determination algorithms will make possible objective validation of a refined 3D map. They will provide, for the first time, a simple but robust way to eliminate artifacts and will thus increase the level of confidence in cryo-EM results. In (3), we will use our projection data resampling methodology to calculate (directly from the data) eigenvectors characterizing the conformational variability of a structure. We will then develop a deconvolution algorithm that will use this eigenvector information to eliminate from a 3D map the blurring caused by residual alignment errors. We will also use the eigenanalysis to characterize local mobility of a macromolecule and bridge the gap between experimental cryo-EM structure determination and simulations of conformational variability based on physical models. By cross-validating our methodology with the results of molecular dynamics simulations we will provide a novel tool for analyzing the energy landscape of large macromolecules.  Rather than incremental improvements, the methods we propose to develop will put single particle cryo-EM analysis on a new path towards full reliability of the results, eliminating the uncertainty that currently hinder fulfillment of cryo-EM's full potential. To assure multi-platform portability and immediate dissemination, these new methods will be implemented within the SPARX image processing package. PUBLIC HEALTH RELEVANCE: High-resolution cryo-electron microscopy (cryo-EM) has become an important tool for the structure/function determination of large macromolecular complexes. Even at limited resolution cryo-EM maps provide a wealth of structural information, eventually leading to determination of the secondary structure, as demonstrated by our work on the structure of the ribosome. In addition, cryo-EM is a unique structural technique in its ability to detect conformational variability of large molecular assemblies within one sample that may contain a mixture of complexes in various conformational states. We propose development of dedicated data processing and statistical tools for reliable cryo-EM structure determination, particularly in the absence of external information, and for studies of conformational modes of the structure, as directly obtained from the EM data.",High Resolution in Single Particle Reconstruction,8926448,R01GM060635,"['Algorithms', 'Area', 'Berlin', 'Complex', 'Complex Mixtures', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Development', 'Electron Microscopy', 'Elements', 'Environment', 'Evaluation', 'Foundations', 'Freezing', 'Genetic Transcription', 'Goals', 'Health', 'Image', 'Laboratories', 'Libraries', 'Ligand Binding', 'Link', 'Macromolecular Complexes', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Morphologic artifacts', 'Noise', 'Outcome', 'Peptide Elongation Factor G', 'Principal Component Analysis', 'Procedures', 'Property', 'Rationalization', 'Reliability of Results', 'Reproducibility', 'Research Institute', 'Residual state', 'Resolution', 'Ribosomes', 'Rice', 'Roentgen Rays', 'Sampling', 'Solutions', 'Specimen', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Universities', 'Validation', 'Work', 'base', 'blind', 'computerized data processing', 'computerized tools', 'design', 'image processing', 'macromolecular assembly', 'macromolecule', 'models and simulation', 'molecular assembly/self assembly', 'molecular dynamics', 'novel', 'particle', 'physical model', 'portability', 'programs', 'reconstruction', 'simulation', 'three dimensional structure', 'three-dimensional modeling', 'tool']",NIGMS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,304000,0.042695627052861077
"High Resolution in Single Particle Reconstruction     DESCRIPTION (provided by applicant): The focus of this renewal application will be on the development of single particle cryo-EM structure determination methods that incorporate validation, assessment of alignment errors, and cross-validation of observed conformational variability. We will concentrate on three specific areas: (1) establishment of a well- defined goal function for structure determination, (2) structure refinement methods that incorporate validation of the outcome, and (3) quantitative analysis of conformational variability cross-validated by X-ray model-based simulations.  In (1), we will establish a goal function (a single-valued function of the 3D map and/or projection data) that would have a global extremum for the correct structure and which can be related to intuitive notion of resolution of the map. A goal function with such properties would make possible a critical evaluation of the ability of existing structure determination methods to deliver optimal structures and establish a theoretical basis for unification and rationalization of 3D-EM single particle structure determination methodology. In (2), we will introduce novel quantitative single particle cryo-EM methodology, based on jackknife-d resampling, designed to yield an estimate of alignment errors and eliminate ""reference bias"" that results in artifactual features that are indistinguishable from genuine ones in the absence of external standards. Incorporation of these developments into cryo-EM structure determination algorithms will make possible objective validation of a refined 3D map. They will provide, for the first time, a simple but robust way to eliminate artifacts and will thus increase the level of confidence in cryo-EM results. In (3), we will use our projection data resampling methodology to calculate (directly from the data) eigenvectors characterizing the conformational variability of a structure. We will then develop a deconvolution algorithm that will use this eigenvector information to eliminate from a 3D map the blurring caused by residual alignment errors. We will also use the eigenanalysis to characterize local mobility of a macromolecule and bridge the gap between experimental cryo-EM structure determination and simulations of conformational variability based on physical models. By cross-validating our methodology with the results of molecular dynamics simulations we will provide a novel tool for analyzing the energy landscape of large macromolecules.  Rather than incremental improvements, the methods we propose to develop will put single particle cryo-EM analysis on a new path towards full reliability of the results, eliminating the uncertainty that currently hinder fulfillment of cryo-EM's full potential. To assure multi-platform portability and immediate dissemination, these new methods will be implemented within the SPARX image processing package.         PUBLIC HEALTH RELEVANCE: High-resolution cryo-electron microscopy (cryo-EM) has become an important tool for the structure/function determination of large macromolecular complexes. Even at limited resolution cryo-EM maps provide a wealth of structural information, eventually leading to determination of the secondary structure, as demonstrated by our work on the structure of the ribosome. In addition, cryo-EM is a unique structural technique in its ability to detect conformational variability of large molecular assemblies within one sample that may contain a mixture of complexes in various conformational states. We propose development of dedicated data processing and statistical tools for reliable cryo-EM structure determination, particularly in the absence of external information, and for studies of conformational modes of the structure, as directly obtained from the EM data.            ",High Resolution in Single Particle Reconstruction,8744276,R01GM060635,"['Algorithms', 'Area', 'Berlin', 'Complex', 'Complex Mixtures', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Development', 'Electron Microscopy', 'Elements', 'Environment', 'Evaluation', 'Foundations', 'Freezing', 'Genetic Transcription', 'Goals', 'Image', 'Laboratories', 'Libraries', 'Ligand Binding', 'Link', 'Macromolecular Complexes', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Morphologic artifacts', 'Noise', 'Outcome', 'Peptide Elongation Factor G', 'Principal Component Analysis', 'Procedures', 'Property', 'Rationalization', 'Reliability of Results', 'Reproducibility', 'Research Institute', 'Residual state', 'Resolution', 'Ribosomes', 'Rice', 'Roentgen Rays', 'Sampling', 'Solutions', 'Specimen', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Universities', 'Validation', 'Work', 'base', 'blind', 'computerized data processing', 'computerized tools', 'design', 'image processing', 'macromolecular assembly', 'macromolecule', 'models and simulation', 'molecular assembly/self assembly', 'molecular dynamics', 'novel', 'particle', 'physical model', 'portability', 'programs', 'public health relevance', 'reconstruction', 'simulation', 'three dimensional structure', 'three-dimensional modeling', 'tool']",NIGMS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,304000,0.042695627052861077
"Bayesian Methods for Localizing Dynamic Brain Activity and Epileptogenic Zones    DESCRIPTION (provided by applicant): Magnetoencephalography (MEG) and related electroencephalography (EEG) use an array of sensors to non-invasively measure electromagnetic (EM) fields produced by synchronous current activity within the brain. While the temporal resolution is excellent relative to other functional imaging modalities, accurately localizing in 3D space the sources of brain activity involves solving a difficult, underdetermined inverse problem. Existing localization methods used clinically and for research purposes maintain significant shortcomings, including the inability to resolve complex source configurations, bias caused by source correlations, and sensitivity to sources of noise and interference. The latter can arise from eye blinks, heart beats, sensor imperfections, and industrial noise as well as from spontaneous background brain activity not associated with the brain sources of interest. Additionally, prototype algorithms ostensibly designed to deal with some of these issues are heuristic in nature and have not been rigorously evaluated or compared, making their ultimate utility difficult to assess for neuroelectromagnetic imaging practitioners. The proposed research plan addresses all of these concerns by developing a principled localization scheme that unifies and extends existing localization strategies using modern concepts from Bayesian statistics and machine learning. Based on the notion of automatic relevance determination (ARD), brain regions with probable (relevant) activity are located with high spatial resolution. Interference sources are effectively removed by integrating with a variation factor analysis model. To quantify the improvement afforded by the proposed methodology, source location estimates will be compared with standard algorithms using realistic simulations, near-ground-truth data obtained from invasive electrocorticographic (ECoG) recordings, and surgical data. The result will be implemented as a user-friendly localization toolbox and made freely available to the community by integrating with existing open-source functional brain imaging software. Non-invasive mapping of brain activity with high spatio-temporal resolution has important consequences for basic neuroscience studies of human cognition. It also has profound implications for the diagnosis, characterization and treatment of various neurological, neurooncological, mental health, developmental, and communication disorders. For example, localizations of brain sources are used to map cognitive function in epileptogenic areas and in neighboring brain regions. Such brain mapping procedures are then useful to guide neurosurgical planning, navigation, and resection and to minimize post-operative deficits.           n/a",Bayesian Methods for Localizing Dynamic Brain Activity and Epileptogenic Zones,7942859,F32NS061395,"['Academia', 'Address', 'Algorithms', 'Area', 'Automation', 'Bayesian Method', 'Benchmarking', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Engineering', 'Blinking', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Clinical', 'Code', 'Cognition', 'Cognitive Science', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Developmental Communication Disorders', 'Diagnosis', 'Diffuse', 'Electroencephalography', 'Electromagnetic Fields', 'Epilepsy', 'Evaluation', 'Event', 'Excision', 'Experimental Designs', 'Exposure to', 'Factor Analysis', 'Failure', 'Frequencies', 'Functional Imaging', 'Heart', 'Human', 'Image', 'Individual', 'Interdisciplinary Study', 'Intractable Epilepsy', 'Language', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Magnetoencephalography', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Morphologic artifacts', 'Motor', 'Nature', 'Neurologic', 'Neurosciences', 'Noise', 'Occupations', 'Operative Surgical Procedures', 'Partial Epilepsies', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Radiology Specialty', 'Relative (related person)', 'Research', 'Research Training', 'Resected', 'Resolution', 'Scalp structure', 'Scheme', 'Science', 'Series', 'Signal Transduction', 'Simulate', 'Sorting - Cell Movement', 'Source', 'Statistical Methods', 'Surface', 'Surrogate Markers', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'base', 'career', 'cognitive function', 'computerized data processing', 'cost', 'design', 'genetic pedigree', 'heuristics', 'human CYP2B6 protein', 'human subject', 'imaging modality', 'interest', 'neurophysiology', 'open source', 'operation', 'prototype', 'reconstruction', 'sensor', 'simulation', 'statistics', 'user friendly software', 'user-friendly', 'validation studies']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2011,19755,0.03798700609778563
"Bayesian Methods for Localizing Dynamic Brain Activity and Epileptogenic Zones    DESCRIPTION (provided by applicant): Magnetoencephalography (MEG) and related electroencephalography (EEG) use an array of sensors to non-invasively measure electromagnetic (EM) fields produced by synchronous current activity within the brain. While the temporal resolution is excellent relative to other functional imaging modalities, accurately localizing in 3D space the sources of brain activity involves solving a difficult, underdetermined inverse problem. Existing localization methods used clinically and for research purposes maintain significant shortcomings, including the inability to resolve complex source configurations, bias caused by source correlations, and sensitivity to sources of noise and interference. The latter can arise from eye blinks, heart beats, sensor imperfections, and industrial noise as well as from spontaneous background brain activity not associated with the brain sources of interest. Additionally, prototype algorithms ostensibly designed to deal with some of these issues are heuristic in nature and have not been rigorously evaluated or compared, making their ultimate utility difficult to assess for neuroelectromagnetic imaging practitioners. The proposed research plan addresses all of these concerns by developing a principled localization scheme that unifies and extends existing localization strategies using modern concepts from Bayesian statistics and machine learning. Based on the notion of automatic relevance determination (ARD), brain regions with probable (relevant) activity are located with high spatial resolution. Interference sources are effectively removed by integrating with a variation factor analysis model. To quantify the improvement afforded by the proposed methodology, source location estimates will be compared with standard algorithms using realistic simulations, near-ground-truth data obtained from invasive electrocorticographic (ECoG) recordings, and surgical data. The result will be implemented as a user-friendly localization toolbox and made freely available to the community by integrating with existing open-source functional brain imaging software. Non-invasive mapping of brain activity with high spatio-temporal resolution has important consequences for basic neuroscience studies of human cognition. It also has profound implications for the diagnosis, characterization and treatment of various neurological, neurooncological, mental health, developmental, and communication disorders. For example, localizations of brain sources are used to map cognitive function in epileptogenic areas and in neighboring brain regions. Such brain mapping procedures are then useful to guide neurosurgical planning, navigation, and resection and to minimize post-operative deficits.           n/a",Bayesian Methods for Localizing Dynamic Brain Activity and Epileptogenic Zones,7751495,F32NS061395,"['Academia', 'Address', 'Algorithms', 'Area', 'Arts', 'Automation', 'Bayesian Method', 'Benchmarking', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Engineering', 'Blinking', 'Brain', 'Brain Mapping', 'Brain imaging', 'Brain region', 'Clinical', 'Code', 'Cognition', 'Cognitive Science', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Developmental Communication Disorders', 'Diagnosis', 'Diffuse', 'Electroencephalography', 'Electromagnetic Fields', 'Electromagnetics', 'Epilepsy', 'Evaluation', 'Event', 'Excision', 'Experimental Designs', 'Exposure to', 'Factor Analysis', 'Failure', 'Frequencies', 'Functional Imaging', 'Heart', 'Human', 'Image', 'Individual', 'Interdisciplinary Study', 'Intractable Epilepsy', 'Language', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Magnetoencephalography', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Morphologic artifacts', 'Motor', 'Nature', 'Neurologic', 'Neurosciences', 'Noise', 'Nutmeg - dietary', 'Occupations', 'Operative Surgical Procedures', 'Partial Epilepsies', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Radiology Specialty', 'Relative (related person)', 'Research', 'Research Training', 'Resected', 'Resolution', 'Scalp structure', 'Scheme', 'Science', 'Series', 'Signal Transduction', 'Simulate', 'Sorting - Cell Movement', 'Source', 'Statistical Methods', 'Surface', 'Surrogate Markers', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'base', 'career', 'cognitive function', 'computerized data processing', 'cost', 'design', 'genetic pedigree', 'heuristics', 'human CYP2B6 protein', 'human subject', 'imaging modality', 'interest', 'neurophysiology', 'open source', 'prototype', 'reconstruction', 'sensor', 'simulation', 'statistics', 'user friendly software', 'user-friendly', 'validation studies']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2009,46257,0.03798700609778563
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6636516,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2003,374063,0.02318750826056364
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6520333,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2002,363261,0.02318750826056364
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6484619,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2001,337739,0.02318750826056364
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6193019,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN,R01,2000,478050,0.02318750826056364
"Software Relating Genes to Disease and Clinical Outcomes    DESCRIPTION (provided by applicant): The development of a software system is proposed that will combine statistical theory, computer science algorithms, and genetics expertise to take advantage of the great influx of data generated by the study of the human genome, clinical trials data and the creation of inexpensive genotyping techniques. This software will elucidate the complex relationship between drug efficacy and side effects, multiple interacting genes and environmental factors.      Our Phase I results show it is feasible to link phenotype to genotype for a list of ""candidate"" genes. A novel haplotype trend test has been developed to aid in finding associations across large SNP maps. Commercialization of this technique is essential for companies that intend to use large public or private SNP maps to locate genes that are associated with disease and drug safety and efficacy. Our statistical methods are expected to be successful even if the disease mechanism can differ from one person to another.      By analyzing and interpreting clinical trial data, the software will match drugs to target populations according to their specific genotype. This will enable pharmaceutical companies to create novel drugs that render maximum effectiveness and have minimum side effects, i.e. the right drug for the right person.         n/a",Software Relating Genes to Disease and Clinical Outcomes,7013551,R44GM062081,"['artificial intelligence', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug adverse effect', 'drug screening /evaluation', 'gene environment interaction', 'health care facility information system', 'molecular biology information system', 'statistics /biometry']",NIGMS,"GOLDEN HELIX, INC.",R44,2005,69000,-0.006617198903564095
"Software Relating Genes to Disease and Clinical Outcomes    DESCRIPTION (provided by applicant): The development of a software system is proposed that will combine statistical theory, computer science algorithms, and genetics expertise to take advantage of the great influx of data generated by the study of the human genome, clinical trials data and the creation of inexpensive genotyping techniques. This software will elucidate the complex relationship between drug efficacy and side effects, multiple interacting genes and environmental factors.      Our Phase I results show it is feasible to link phenotype to genotype for a list of ""candidate"" genes. A novel haplotype trend test has been developed to aid in finding associations across large SNP maps. Commercialization of this technique is essential for companies that intend to use large public or private SNP maps to locate genes that are associated with disease and drug safety and efficacy. Our statistical methods are expected to be successful even if the disease mechanism can differ from one person to another.      By analyzing and interpreting clinical trial data, the software will match drugs to target populations according to their specific genotype. This will enable pharmaceutical companies to create novel drugs that render maximum effectiveness and have minimum side effects, i.e. the right drug for the right person.         n/a",Software Relating Genes to Disease and Clinical Outcomes,6693828,R44GM062081,"['artificial intelligence', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug adverse effect', 'drug screening /evaluation', 'gene environment interaction', 'health care facility information system', 'molecular biology information system', 'statistics /biometry']",NIGMS,"GOLDEN HELIX, INC.",R44,2004,416498,-0.006617198903564095
"Software Relating Genes to Disease and Clinical Outcomes    DESCRIPTION (provided by applicant): The development of a software system is proposed that will combine statistical theory, computer science algorithms, and genetics expertise to take advantage of the great influx of data generated by the study of the human genome, clinical trials data and the creation of inexpensive genotyping techniques. This software will elucidate the complex relationship between drug efficacy and side effects, multiple interacting genes and environmental factors.      Our Phase I results show it is feasible to link phenotype to genotype for a list of ""candidate"" genes. A novel haplotype trend test has been developed to aid in finding associations across large SNP maps. Commercialization of this technique is essential for companies that intend to use large public or private SNP maps to locate genes that are associated with disease and drug safety and efficacy. Our statistical methods are expected to be successful even if the disease mechanism can differ from one person to another.      By analyzing and interpreting clinical trial data, the software will match drugs to target populations according to their specific genotype. This will enable pharmaceutical companies to create novel drugs that render maximum effectiveness and have minimum side effects, i.e. the right drug for the right person.         n/a",Software Relating Genes to Disease and Clinical Outcomes,6582179,R44GM062081,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' drug adverse effect', ' drug screening /evaluation', ' gene environment interaction', ' health care facility information system', ' molecular biology information system', ' statistics /biometry']",NIGMS,"GOLDEN HELIX, INC.",R44,2003,538979,-0.006617198903564095
"Multi-Resolution Docking Methods for Electron Microscopy Summary In the past decade, we have witnessed a revolutionary progress in camera technology and the attainable resolution of macromolecular assemblies via cryogenic electron microscopy (cryo-EM) and in the development of computational algorithms that relate the resulting 3D maps to atomic resolution structures. Whereas single- particle cryo-EM today is capable of directly solving atomic structures of biomolecular assemblies in isolation, electron tomography (ET) in unstained frozen-hydrated samples is widely used to capture the 3D organization of supramolecular complexes in their native (organelle, cell, or tissue) environments. We have identified three inter-related research areas where our computational modeling experience (historically rooted in pre-revolution multi-scale approaches) offers the biggest value to today's post-revolution EM community: (1) medium resolution cryo-EM modeling, (2) the segmentation and denoising of cryo-ET data, and (3) the validation of atomic models and their corresponding maps. The first aim is an extension of promising new ideas in flexible fitting as well as secondary structure prediction for medium resolution maps, which have been our key research areas in the past. medium resolution (5-10Å) maps are still widely used in EM and can be of significant biological importance. This is particularly true in the case of cryo-ET maps, which are harder to read than single particle cryo-EM maps because they often exhibit considerable noise, anisotropic resolution, and anisotropic density variations due to the low dose requirements and the missing wedge in the Fourier space. In the case of tightly packed or crowded macromolecular structures, the fusion of nearby biomolecular densities prevents an automated segmentation of geometric shapes, requiring a labor-intensive manual tracing by human experts. We are currently developing novel computational approaches to provide a more objective strategy for missing wedge correction in homogeneous specimen areas of tomograms. Our hybrid approach combines deconvolution and denoising with template matching in a unified mathematical framework that allows modeling constraints to be imposed in a least-squares optimization process. Our approach can also be extended to the flexible refinement of atomic structures using our damped dynamics flexible fitting approach by tuning the internal point-spread functions to the missing wedge of the ET data. To support these aims, we will quantitatively measure the fitness of an atomic model in local density regions and characterize the fitness of maps with reliable reference structures. The collaborative efforts supported by this grant will include the refinement of cytoskeletal filaments, molecular motors, bacterial chemoreceptor arrays, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established Internet-based mechanisms used by the Situs and Sculptor packages and as plugins for the popular UCSF Chimera graphics program. Project Narrative This project will help biological electron microscopists bridge a broad range of resolution levels, from the atomic to the living organism. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,10120245,R01GM062968,"['3-Dimensional', 'Algorithms', 'Architecture', 'Area', 'Biological', 'Cells', 'Characteristics', 'Chemoreceptors', 'Chimera organism', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Computational algorithm', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Crowding', 'Cryo-electron tomography', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Databases', 'Deposition', 'Detection', 'Development', 'Docking', 'Dose', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Elements', 'Environment', 'Equilibrium', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Human', 'Hybrids', 'Hydration status', 'Internet', 'Laboratories', 'Least-Squares Analysis', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Mathematics', 'Measures', 'Medical', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Molecular Motors', 'Molecular Structure', 'Morphologic artifacts', 'Nature', 'Noise', 'Organelles', 'Organism', 'Pattern', 'Plant Roots', 'Research', 'Resolution', 'Sampling', 'Shapes', 'Specimen', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Tomogram', 'Training', 'Validation', 'Variant', 'Visualization software', 'Work', 'algorithmic methodologies', 'automated segmentation', 'base', 'beta pleated sheet', 'computer code', 'cryogenics', 'data warehouse', 'deep learning', 'denoising', 'density', 'electron tomography', 'experience', 'feature detection', 'fitness', 'flexibility', 'fundamental research', 'heuristics', 'high standard', 'image reconstruction', 'improved', 'interest', 'learning network', 'macromolecular assembly', 'novel', 'particle', 'prevent', 'process optimization', 'programs', 'reconstruction', 'structured data', 'theories', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2020,313572,0.06898860742930625
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9517061,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Hydration status', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Reproducibility', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'algorithmic methodologies', 'base', 'computer code', 'cryogenics', 'data warehouse', 'density', 'design', 'fiber cell', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2018,306284,0.030382291493037155
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9306122,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Hydration status', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Reproducibility', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'algorithmic methodologies', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fiber cell', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2017,306527,0.030382291493037155
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9099858,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Heating', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Stereocilium', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2016,306754,0.030382291493037155
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages.         PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.            ",Multi-Resolution Docking Methods for Electron Microscopy,8964685,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Heating', 'Image', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Relative (related person)', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Stereocilium', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2015,307928,0.030382291493037155
"Genetic Architecture of the Mammalian (Canid) Skeleton DESCRIPTION (provided by applicant): As its goal, this project seeks to decipher the genetic architecture underlying the mammalian skeletal system. We use a population of Portuguese Water (PW) Dogs, descended from a few founders and characterized by frequent inbreeding events. This unstructured pedigreed population is similar to human isolates such as the Hutterites or larger well documented populations such as the Mormons. Dogs are genotyped using microsatellite markers and phenotyped from five x-rays comprising the skull, fore- and hind limbs and pelvis. From this information it has been possible to identify QTLs (haplotypes of Quantitative Trait Loci) that inform the skeleton. During the first 2+ years of the project, we have used Principal Component Analysis to define groupings of skeletal metrics that represent functional trade-offs between adaptations for power or speed (e.g. skull vs. post cranial body, limb width vs. length, pelvis size vs. limb width) and have identified genetic loci that regulate these groupings. Loci also have been identified that regulate variation in the right vs. the left hip joints (bilateral asymmetry); and an interaction between QTLs affecting size has been identified that, in part, explains sexual dimorphism.      In continuing this project we shall (i) complete the analysis of the canine genome; (ii) analyze several QTLs in detail; and (iii) attempt to transfer specific canine genetic information to the mouse, (i) Missing genotypic information (gaps in genome markers) will be supplied using the canine genomic sequence as a source of new markers to identify QTLs in the approximately 30% of the genome that remains to be analyzed, (ii) In a collaborative effort with Dr. Elaine Ostrander, four unlinked QTLs will be examined in detail that regulate: a) limb bone length vs. limb width; b) skull length vs. limb width; c) overall size; and d) size differences between males and females (sexual dimorphism). This detailed analysis will utilize the emerging sequence of the canine genome, analyzing each QTL haplotype with a high density of markers (SSR and then SNP) to pinpoint the informative region of sequence. Linkage disequilibrium analysis within the PWD population as well as between PW dogs and other breeds will be a powerful tool, (iii) Emerging murine transgenic technology suggests that it will be possible for canine genes to be transferred to, and function in, the mouse. In a collaborative effort with Dr. Capecchi, we shall carry out such a transfer. n/a",Genetic Architecture of the Mammalian (Canid) Skeleton,7275980,R01GM063056,"['Address', 'Adult', 'Affect', 'Anatomy', 'Animal Rights', 'Animals', 'Architecture', 'Behavior', 'Behavioral', 'Bilateral', 'Biological Assay', 'Biological Models', 'Breeding', 'Candidate Disease Gene', 'Canis familiaris', 'Cephalic', 'Chromosomes', 'Collaborations', 'Complex', 'Condition', 'Control Locus', 'Development', 'Distant', 'Elements', 'Environment', 'Etiology', 'Event', 'Evolution', 'Exercise', 'Facility Construction Funding Category', 'Female', 'Foxes', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genetic Research', 'Genome', 'Genome Scan', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Grouping', 'Growth', 'Haplotypes', 'Hip Joint', 'Hominidae', 'Human', 'Human Genetics', 'Inbreeding', 'Individual', 'Invaded', 'Laboratories', 'Left', 'Length', 'Life', 'Limb structure', 'Linkage Disequilibrium', 'Litter Size', 'Location', 'Mammals', 'Medical Research', 'Methods', 'Metric', 'Microsatellite Repeats', 'Modeling', 'Mormon', 'Morphology', 'Mus', 'Newborn Infant', 'Numbers', 'Organism', 'Pelvis', 'Phenotype', 'Phylogenetic Analysis', 'Phylogeny', 'Polygenic Traits', 'Population', 'Principal Component Analysis', 'Principal Investigator', 'Privacy', 'Procedures', 'Process', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Range', 'Records', 'Regulation', 'Regulator Genes', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Support', 'Resources', 'Role', 'Shapes', 'Side', 'Silver', 'Single-Gene Defect', 'Skeletal system', 'Skeleton', 'Source', 'Speed', 'Structure', 'Symptoms', 'System', 'Systems Analysis', 'Technology', 'Time', 'Transgenic Mice', 'Transgenic Organisms', 'Variant', 'Vulpes', 'Water', 'Width', 'Work', 'base', 'bone', 'comparative', 'cranium', 'day', 'density', 'disease phenotype', 'functional group', 'genetic pedigree', 'genome sequencing', 'insight', 'interest', 'limb bone', 'male', 'new technology', 'nutrition', 'programs', 'receptor', 'sexual dimorphism', 'size', 'tool', 'trait']",NIGMS,UNIVERSITY OF UTAH,R01,2007,391025,0.011110076062733435
"Genetic Architecture of the Mammalian (Canid) Skeleton DESCRIPTION (provided by applicant): As its goal, this project seeks to decipher the genetic architecture underlying the mammalian skeletal system. We use a population of Portuguese Water (PW) Dogs, descended from a few founders and characterized by frequent inbreeding events. This unstructured pedigreed population is similar to human isolates such as the Hutterites or larger well documented populations such as the Mormons. Dogs are genotyped using microsatellite markers and phenotyped from five x-rays comprising the skull, fore- and hind limbs and pelvis. From this information it has been possible to identify QTLs (haplotypes of Quantitative Trait Loci) that inform the skeleton. During the first 2+ years of the project, we have used Principal Component Analysis to define groupings of skeletal metrics that represent functional trade-offs between adaptations for power or speed (e.g. skull vs. post cranial body, limb width vs. length, pelvis size vs. limb width) and have identified genetic loci that regulate these groupings. Loci also have been identified that regulate variation in the right vs. the left hip joints (bilateral asymmetry); and an interaction between QTLs affecting size has been identified that, in part, explains sexual dimorphism.      In continuing this project we shall (i) complete the analysis of the canine genome; (ii) analyze several QTLs in detail; and (iii) attempt to transfer specific canine genetic information to the mouse, (i) Missing genotypic information (gaps in genome markers) will be supplied using the canine genomic sequence as a source of new markers to identify QTLs in the approximately 30% of the genome that remains to be analyzed, (ii) In a collaborative effort with Dr. Elaine Ostrander, four unlinked QTLs will be examined in detail that regulate: a) limb bone length vs. limb width; b) skull length vs. limb width; c) overall size; and d) size differences between males and females (sexual dimorphism). This detailed analysis will utilize the emerging sequence of the canine genome, analyzing each QTL haplotype with a high density of markers (SSR and then SNP) to pinpoint the informative region of sequence. Linkage disequilibrium analysis within the PWD population as well as between PW dogs and other breeds will be a powerful tool, (iii) Emerging murine transgenic technology suggests that it will be possible for canine genes to be transferred to, and function in, the mouse. In a collaborative effort with Dr. Capecchi, we shall carry out such a transfer. n/a",Genetic Architecture of the Mammalian (Canid) Skeleton,7118238,R01GM063056,"['animal population genetics', 'biopsy', 'dogs', 'gender difference', 'genetic markers', 'genetic regulation', 'genetically modified animals', 'genotype', 'laboratory mouse', 'linkage disequilibriums', 'morphology', 'nucleic acid repetitive sequence', 'phenotype', 'quantitative trait loci', 'single nucleotide polymorphism', 'skeletal system', 'tissue /cell culture']",NIGMS,UNIVERSITY OF UTAH,R01,2006,310222,0.011110076062733435
"Genetic Architecture of the Mammalian (Canid) Skeleton DESCRIPTION (provided by applicant): As its goal, this project seeks to decipher the genetic architecture underlying the mammalian skeletal system. We use a population of Portuguese Water (PW) Dogs, descended from a few founders and characterized by frequent inbreeding events. This unstructured pedigreed population is similar to human isolates such as the Hutterites or larger well documented populations such as the Mormons. Dogs are genotyped using microsatellite markers and phenotyped from five x-rays comprising the skull, fore- and hind limbs and pelvis. From this information it has been possible to identify QTLs (haplotypes of Quantitative Trait Loci) that inform the skeleton. During the first 2+ years of the project, we have used Principal Component Analysis to define groupings of skeletal metrics that represent functional trade-offs between adaptations for power or speed (e.g. skull vs. post cranial body, limb width vs. length, pelvis size vs. limb width) and have identified genetic loci that regulate these groupings. Loci also have been identified that regulate variation in the right vs. the left hip joints (bilateral asymmetry); and an interaction between QTLs affecting size has been identified that, in part, explains sexual dimorphism.      In continuing this project we shall (i) complete the analysis of the canine genome; (ii) analyze several QTLs in detail; and (iii) attempt to transfer specific canine genetic information to the mouse, (i) Missing genotypic information (gaps in genome markers) will be supplied using the canine genomic sequence as a source of new markers to identify QTLs in the approximately 30% of the genome that remains to be analyzed, (ii) In a collaborative effort with Dr. Elaine Ostrander, four unlinked QTLs will be examined in detail that regulate: a) limb bone length vs. limb width; b) skull length vs. limb width; c) overall size; and d) size differences between males and females (sexual dimorphism). This detailed analysis will utilize the emerging sequence of the canine genome, analyzing each QTL haplotype with a high density of markers (SSR and then SNP) to pinpoint the informative region of sequence. Linkage disequilibrium analysis within the PWD population as well as between PW dogs and other breeds will be a powerful tool, (iii) Emerging murine transgenic technology suggests that it will be possible for canine genes to be transferred to, and function in, the mouse. In a collaborative effort with Dr. Capecchi, we shall carry out such a transfer. n/a",Genetic Architecture of the Mammalian (Canid) Skeleton,6915344,R01GM063056,"['animal population genetics', 'biopsy', 'dogs', 'gender difference', 'genetic markers', 'genetic regulation', 'genetically modified animals', 'genotype', 'laboratory mouse', 'linkage disequilibriums', 'morphology', 'nucleic acid repetitive sequence', 'phenotype', 'quantitative trait loci', 'single nucleotide polymorphism', 'skeletal system', 'tissue /cell culture']",NIGMS,UNIVERSITY OF UTAH,R01,2005,317688,0.011110076062733435
"New Kinetic Approaches to Investigate Protein Folding  DESCRIPTION (provided by applicant): Proteins must fold into specific three-dimensional structures to be functional, in a process dictated by their primary sequence. Current understanding of the mechanisms by which proteins fold is limited by the deceivingly simple picture arising from standard kinetic experiments. In these experiments, folding appears as a two or three-state process because the inter-conversions between the myriad of intermediate structures that determine the mechanism are too transient to be directly detected. In this proposal, a group of new experimental approaches to circumvent these limitation is presented. To facilitate extracting mechanistic information from kinetics observations, a catalog of small proteins with simple structural patterns; i.e., structural archetypes, will be produced. Their folding properties will be investigated by fast-kinetic methods such as the laser-induced temperature-jump technique. In an alternative approach, the existence of the theoretically predicted downhill scenario for folding will be explored experimentally. Identification of downhill folders is important because during downhill folding all intermediate structures are potentially detectable. Additionally, kinetic methods with improved structural and/or time resolution will be developed. A two-dimensional version of the phi-analysis will be implemented to investigate the population dynamics of transition-state ensembles for folding. Time-dependent information on transient intermediates will be obtained for the first time from equilibrium nuclear magnetic resonance hydrogen-exchange experiments by performing them in kinetic coupling mode. The application of these kinetic techniques to study the folding of structural archetypes and downhill folders will provide direct information about the structural rules governing protein folding.     n/a",New Kinetic Approaches to Investigate Protein Folding,7226235,R01GM066800,"['Behavior', 'Cataloging', 'Catalogs', 'Complex', 'Computer Simulation', 'Coupling', 'Dimensions', 'Elements', 'Equilibrium', 'Goals', 'Hydrogen', 'Kinetics', 'Lasers', 'Measures', 'Methods', 'Molecular Conformation', 'Monitor', 'Nature', 'Nuclear Magnetic Resonance', 'Pathway interactions', 'Pattern', 'Population', 'Population Dynamics', 'Positioning Attribute', 'Process', 'Property', 'Protein Engineering', 'Proteins', 'Range', 'Rate', 'Reporter', 'Research', 'Resolution', 'Series', 'Standards of Weights and Measures', 'Structure', 'Techniques', 'Testing', 'Thermodynamics', 'Time', 'Urea', 'base', 'design', 'improved', 'protein folding', 'protein structure', 'research study', 'residence', 'stop flow technique', 'temperature jump', 'text searching', 'theories', 'three dimensional structure', 'two-dimensional']",NIGMS,UNIVERSITY OF MARYLAND COLLEGE PK CAMPUS,R01,2007,241173,0.007277156688751013
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7798636,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'disease diagnosis', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2010,35821,0.01838537745057784
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7616408,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'disease diagnosis', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2009,35821,0.01838537745057784
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7392804,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease regression', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Numbers', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2008,35821,0.01838537745057784
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7269518,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease regression', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Numbers', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2007,35821,0.01838537745057784
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7125904,R01MH066990,"['bioinformatics', 'computational neuroscience', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'information system analysis', 'mathematical model', 'model design /development', 'neural information processing', 'neurophysiology', 'sensory feedback', 'sensory mechanism', 'statistics /biometry']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2006,295127,0.01838537745057784
"Optimization of Stuctures and Networks of Proteins    DESCRIPTION (provided by applicant): This application has three major aims that exploit the use of mathematical programming tools for biophysically motivated problems. The first goal is the refinement of protein structures that are obtained from homology. Structures based on homology are rarely of atomic resolution; a resolution which is necessary for detailed modeling of protein function, and for the design of drug molecules. Based on mathematical programming approach a new class of energy functions, suitable for the refinement problem, will be designed. The second goal is to investigate a new type of network; the network of sequence flow between protein structures. We examine the process in which new sequences, generated by point mutations, remain in the current fold, or switch to other stable structures (we exclude sequences with no stable fold). The adjustments to the structure are accepted or rejected based on stability criterion. The net. work defines a master equation which makes it possible to investigate past (ancient) folds, and future structures that serve as attractors. The third aim examines the network of protein-protein (physical) interactions and will be examined with bioinformatics and biophysical approaches. Comparison will be made between the network of sequence flow and the network of protein-protein interactions to better understand the evolution of biological mechanisms and recognition.  PUBLIC HEALTH RELEVANCE The design of new algorithms to predict protein structures and protein-protein interactions is likely to help with the design of new drug molecules.             n/a",Optimization of Stuctures and Networks of Proteins,7846806,R01GM067823,"['Address', 'Algorithms', 'Area', 'Bioinformatics', 'Biological', 'Categories', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Docking', 'Drug Design', 'Electrostatics', 'Employee Strikes', 'Equation', 'Evaluation', 'Evolution', 'Future', 'Gene Duplication', 'Goals', 'Grant', 'Graph', 'Homology Modeling', 'Humulus', 'Hydrogen Bonding', 'Hydrophobicity', 'Learning', 'Machine Learning', 'Martes zibellina', 'Modeling', 'Molecular Conformation', 'Output', 'Pathway interactions', 'Pattern', 'Pediatric Hospitals', 'Performance', 'Pharmaceutical Preparations', 'Physics', 'Point Mutation', 'Process', 'Progress Reports', 'Protein Dynamics', 'Proteins', 'Research', 'Resolution', 'Roentgen Rays', 'Sequence Analysis', 'Services', 'Signal Transduction', 'Solvents', 'Structure', 'Surface', 'Testing', 'Torsion', 'Universities', 'Work', 'base', 'design', 'experience', 'improved', 'insertion/deletion mutation', 'molecular dynamics', 'novel', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure prediction', 'public health relevance', 'research study', 'simulation', 'tool']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2010,280930,-0.03373623608883262
"Optimization of Stuctures and Networks of Proteins    DESCRIPTION (provided by applicant): This application has three major aims that exploit the use of mathematical programming tools for biophysically motivated problems. The first goal is the refinement of protein structures that are obtained from homology. Structures based on homology are rarely of atomic resolution; a resolution which is necessary for detailed modeling of protein function, and for the design of drug molecules. Based on mathematical programming approach a new class of energy functions, suitable for the refinement problem, will be designed. The second goal is to investigate a new type of network; the network of sequence flow between protein structures. We examine the process in which new sequences, generated by point mutations, remain in the current fold, or switch to other stable structures (we exclude sequences with no stable fold). The adjustments to the structure are accepted or rejected based on stability criterion. The net. work defines a master equation which makes it possible to investigate past (ancient) folds, and future structures that serve as attractors. The third aim examines the network of protein-protein (physical) interactions and will be examined with bioinformatics and biophysical approaches. Comparison will be made between the network of sequence flow and the network of protein-protein interactions to better understand the evolution of biological mechanisms and recognition.  PUBLIC HEALTH RELEVANCE The design of new algorithms to predict protein structures and protein-protein interactions is likely to help with the design of new drug molecules.             n/a",Optimization of Stuctures and Networks of Proteins,7620913,R01GM067823,"['Address', 'Algorithms', 'Area', 'Bioinformatics', 'Biological', 'Categories', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Docking', 'Drug Design', 'Electrostatics', 'Employee Strikes', 'Equation', 'Evaluation', 'Evolution', 'Future', 'Gene Duplication', 'Goals', 'Grant', 'Graph', 'Homology Modeling', 'Humulus', 'Hydrogen Bonding', 'Hydrophobicity', 'Learning', 'Machine Learning', 'Martes zibellina', 'Modeling', 'Molecular Conformation', 'Output', 'Pathway interactions', 'Pattern', 'Pediatric Hospitals', 'Performance', 'Pharmaceutical Preparations', 'Physics', 'Point Mutation', 'Process', 'Progress Reports', 'Protein Dynamics', 'Proteins', 'Research', 'Resolution', 'Roentgen Rays', 'Sequence Analysis', 'Services', 'Signal Transduction', 'Solvents', 'Structure', 'Surface', 'Testing', 'Torsion', 'Universities', 'Work', 'base', 'design', 'experience', 'improved', 'insertion/deletion mutation', 'molecular dynamics', 'novel', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure prediction', 'public health relevance', 'research study', 'simulation', 'tool']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2009,283731,-0.03373623608883262
"Optimization of Stuctures and Networks of Proteins    DESCRIPTION (provided by applicant): This application has three major aims that exploit the use of mathematical programming tools for biophysically motivated problems. The first goal is the refinement of protein structures that are obtained from homology. Structures based on homology are rarely of atomic resolution; a resolution which is necessary for detailed modeling of protein function, and for the design of drug molecules. Based on mathematical programming approach a new class of energy functions, suitable for the refinement problem, will be designed. The second goal is to investigate a new type of network; the network of sequence flow between protein structures. We examine the process in which new sequences, generated by point mutations, remain in the current fold, or switch to other stable structures (we exclude sequences with no stable fold). The adjustments to the structure are accepted or rejected based on stability criterion. The net. work defines a master equation which makes it possible to investigate past (ancient) folds, and future structures that serve as attractors. The third aim examines the network of protein-protein (physical) interactions and will be examined with bioinformatics and biophysical approaches. Comparison will be made between the network of sequence flow and the network of protein-protein interactions to better understand the evolution of biological mechanisms and recognition.  PUBLIC HEALTH RELEVANCE The design of new algorithms to predict protein structures and protein-protein interactions is likely to help with the design of new drug molecules.             n/a",Optimization of Stuctures and Networks of Proteins,7466765,R01GM067823,"['Address', 'Algorithms', 'Area', 'Bioinformatics', 'Biological', 'Categories', 'Class', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Docking', 'Drug Design', 'Electrostatics', 'Employee Strikes', 'Equation', 'Evaluation', 'Evolution', 'Facility Construction Funding Category', 'Future', 'Gene Duplication', 'Goals', 'Grant', 'Graph', 'Homology Modeling', 'Humulus', 'Hydrogen Bonding', 'Hydrophobicity', 'Learning', 'Machine Learning', 'Martes zibellina', 'Modeling', 'Molecular Conformation', 'Output', 'Pathway interactions', 'Pattern', 'Pediatric Hospitals', 'Performance', 'Pharmaceutical Preparations', 'Physics', 'Point Mutation', 'Process', 'Progress Reports', 'Protein Dynamics', 'Proteins', 'Public Health', 'Research', 'Resolution', 'Roentgen Rays', 'Score', 'Sequence Analysis', 'Services', 'Signal Transduction', 'Solvents', 'Structure', 'Surface', 'Testing', 'Torsion', 'University Hospitals', 'Work', 'base', 'design', 'desire', 'experience', 'improved', 'insertion/deletion mutation', 'molecular dynamics', 'novel', 'programs', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure prediction', 'research study', 'simulation', 'tool']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2008,305195,-0.03373623608883262
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9274155,R01AR068456,"['Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Bone structure', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cortical bone', 'cost', 'density', 'experience', 'fracture risk', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'population based', 'public health relevance', 'response', 'screening', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'tool', 'treatment response']",NIAMS,UNIVERSITY OF COLORADO DENVER,R01,2017,269514,0.04796203118295771
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9911975,R01AR068456,"['3-Dimensional', 'Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Bone structure', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Screening procedure', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Visualization', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cortical bone', 'cost', 'density', 'experience', 'fracture risk', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'osteoporosis with pathological fracture', 'patient response', 'population based', 'public health relevance', 'response', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'treatment response']",NIAMS,UNIVERSITY OF COLORADO DENVER,R01,2020,276227,0.04796203118295771
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9688116,R01AR068456,"['3-Dimensional', 'Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Bone structure', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Screening procedure', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cortical bone', 'cost', 'density', 'experience', 'fracture risk', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'population based', 'public health relevance', 'response', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'treatment response']",NIAMS,UNIVERSITY OF COLORADO DENVER,R01,2019,275934,0.04796203118295771
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9548457,R01AR068456,"['Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Bone structure', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Screening procedure', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cortical bone', 'cost', 'density', 'experience', 'fracture risk', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'population based', 'public health relevance', 'response', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'treatment response']",NIAMS,UNIVERSITY OF COLORADO DENVER,R01,2018,273031,0.04796203118295771
"Multi-Parametric Spatial Assessment of Bone with HR-pQCT ﻿    DESCRIPTION (provided by applicant):  Osteoporosis is a skeletal disorder characterized by compromised bone strength predisposing a person to an increased risk of fracture. In the U.S. today, 10 million individuals are estimated to already have the disease and almost 34 million more are estimated to have low bone density, placing them at increased risk for osteoporosis and broken bones. Currently, determination of fracture risk, aging effects, and therapeutic efficacy is primarily based on bone mineral density (BMD) measured by areal or volumetric X-ray-based imaging techniques. BMD can predict bone strength and fracture risk to some extent, however, studies have shown that BMD only explains about 70%-75% of the variance in strength, while the remaining variance has been attributed to the cumulative and synergistic effect of other factors such as bone structure, topology, geometry, tissue composition, microdamage, and biomechanical factors. High-resolution peripheral quantitative computed tomography (HR-pQCT) is a noninvasive in-vivo imaging technique which depicts many of these features, including density, geometry, structure, topology, and mechanics of cortical and trabecular bone in the distal radius and distal tibia. To date HR-pQCT imagery has been analyzed using conventional quantitative approaches that average bone features over large regions of interest. The individual quantification of average bone features (uni-parametric) or their statistical combination (multi-parametric) disregard how these three-dimensional (3D) features synergistically contribute to bone strength. As a result the traditional methods fail to capture the spatial patterning of the effect being studied, which is key to understanding the underlying biology. Bone is a 3D organ experiencing constant adaptation through remodeling, and should therefore be analyzed with 3D techniques that reflect the complementary and interdependent nature of different bone features. Statistical parametric mapping (SPM) is a technique that enables 3D spatial comparisons of multi-parametric maps between groups of subjects. Instead of measuring summary properties for arbitrary or subjective volumes of interest, this data-driven process identifies regions significantly associated with a variable of interest through valid statistical tests, thus generating 3D statistical and P-value maps that facilitate the visualization and consequently the interpretation of comparisons between target populations. The ultimate goal of this proposal is to establish a framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. For this purpose, specialized SPM techniques have been developed for HR-pQCT. To evaluate the potential of SPM in clinical science, we propose to apply SPM to image data from three existing in-vivo HR-pQCT studies investigating: a) regional variations in bone structure related to gender and age; b) differences due to fracture of the forearm; and c) longitudinal effects of two osteoporosis treatments.         PUBLIC HEALTH RELEVANCE:  We propose a population-based framework to automatically identify relevant bone sub-regions and features in specific populations for the targeted quantitative assessment of the spatial distribution and prediction of bone strength using HR-pQCT. To demonstrate the potential of this framework in clinical science, we apply it to existing HR-pQCT studies to identify bone sub-regions and features significantly associated with age, gender, fracture status and response to osteoporosis treatment in post menopausal women; identify spatial associations between the central and distal skeleton with respect to treatment response; and improve fracture discrimination, and the prediction and understanding of the effects of osteoporosis treatment. This framework could improve the development of innovative, more active and safer drugs and therapies, and directly benefit patients suffering osteoporosis and other bone disorders since based on HR-pQCT maps of parameters estimating bone density and quality, a treatment offering the most clinical benefits to them could be prescribed.            ",Multi-Parametric Spatial Assessment of Bone with HR-pQCT,9106828,R01AR068456,"['Accounting', 'Affect', 'Age', 'Aging', 'Biology', 'Biomechanics', 'Bone Density', 'Bone Diseases', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Data', 'Development', 'Diagnosis', 'Discrimination', 'Disease', 'Distal', 'Elderly', 'Etiology', 'Exercise', 'Forearm Fracture', 'Fracture', 'Gender', 'Geometry', 'Goals', 'Hip region structure', 'Hormonal', 'Image', 'Imagery', 'Imaging Techniques', 'Incidence', 'Individual', 'Information Distribution', 'Machine Learning', 'Maps', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Nature', 'Organ', 'Osteoporosis', 'Patients', 'Pattern', 'Peripheral', 'Persons', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Postmenopause', 'Process', 'Property', 'Public Health', 'Radial', 'Resolution', 'Risk', 'Roentgen Rays', 'Role', 'Skeleton', 'Spatial Distribution', 'Stimulus', 'Structure', 'Target Populations', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Treatment Efficacy', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'age effect', 'base', 'bone', 'bone quality', 'bone strength', 'cost', 'density', 'experience', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'population based', 'public health relevance', 'response', 'screening', 'skeletal', 'skeletal disorder', 'spatial relationship', 'substantia spongiosa', 'tibia', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2016,31678,0.04796203118295771
"Deep-learning based spatial multiple testing for Alzheimer's neuroimaging data Project Summary The broad objective of this research is to develop a powerful deep-learning based multiple testing approach for high-dimensional spatial data that arise commonly in biomedical imaging studies, in particular, brain imaging studies. The motivating problem is to detect the cerebral metabolic abnormalities in Alzheimer’s disease (AD) from Fluorine-18 fluorodeoxyglucose positron emission tomography (FDG-PET) data. Existing multiple testing approaches in solving this problem often ignore or inadequately capture the spatial dependence among the test statistics obtained from brain voxels and thus lose substantial power for the detection. We will develop a novel spatial multiple testing method that utilizes the deep convolutional neural network (DCNN), a key deep- learning technique, to well capture the spatial dependence among test statistics and thus to achieve the optimal power in the sense of minimizing the false nondiscovery rate (FNR) while correctly controlling the false discovery rate (FDR) at a given level. The proposed DCNN-based FDR controlling method has enhanced power to discover new AD-related brain regions that are missed by conventional methods, thereby leading to novel clinical and pathological studies. The specific aims of this proposal include: 1. To develop an optimal spatial FDR controlling approach by connecting the unsupervised local-significance-index based multiple testing with the supervised DCNN-based image segmentation; 2. To evaluate the proposed spatial FDR controlling approach via extensive simulations under various three-dimensional spatial dependence structures, in comparison with multiple classical and state-of-the-art methods; 3. To apply proposed spatial FDR controlling approach to detect AD-related brain regions using the FDG-PET datasets from the Alzheimer’s Disease Neuroimaging Initiative and the Weill Cornell Brain Health Imaging Institute; 4. To develop a user- friendly and publicly available software package with versions in both Python and R to implement the proposed spatial FDR controlling approach. The proposed DCNN-based approach will also be widely applicable to large- scale multiple testing problems in other fields of biomedical research that involve spatial dependence. Project Narrative This project will exploit recent advances in deep learning to efficiently solve the large-scale spatial multiple testing problems that arise commonly in biomedical imaging studies. The proposed powerful deep-learning based spatial multiple testing approach will be particularly useful in brain imaging studies on neurodegenerative disorders such as Alzheimer’s disease and age-related cognitive impairment.",Deep-learning based spatial multiple testing for Alzheimer's neuroimaging data,10107565,R21AG070303,"['3-Dimensional', 'Affect', 'Age-associated memory impairment', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Architecture', 'Biomedical Research', 'Brain', 'Brain imaging', 'Brain region', 'Cerebrum', 'Clinical', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Detection', 'Disease', 'Early Diagnosis', 'Family', 'Fluorine', 'Glucose', 'Goals', 'Health Sciences', 'Image', 'Institutes', 'Learning', 'Literature', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Monitor', 'Network-based', 'Neurodegenerative Disorders', 'Pathologic', 'Patients', 'Performance', 'Population Group', 'Positron-Emission Tomography', 'Problem Solving', 'Procedures', 'Pythons', 'Research', 'Research Personnel', 'Structural Models', 'Structure', 'Supervision', 'Techniques', 'Testing', 'Training', 'base', 'bioimaging', 'brain health', 'convolutional neural network', 'deep learning', 'fluorodeoxyglucose positron emission tomography', 'high dimensionality', 'imaging Segmentation', 'imaging study', 'indexing', 'metabolic rate', 'mild cognitive impairment', 'neuroimaging', 'novel', 'repository', 'simulation', 'statistics', 'success', 'theories', 'user friendly software', 'user-friendly']",NIA,NEW YORK UNIVERSITY,R21,2020,435875,-0.03222310521479616
"Multiparametric Computational Echocardiography DESCRIPTION (provided by applicant):    In the United States, myocardial ischemia is the underlying etiology in nearly 70% of the 5 million patients suffering from mechanical failure of the cardiac left ventricle (LV). Echocardiography (echo) is well suited for the analysis of LV function, however, the problem of conveying this clinically important information in a quantitative, objective, and reproducible manner persists.      To address this problem and respond to the NIH PA-00-117 solicitation for innovations in biomedical information science and technology, the long-term goal of the proposed R21/R33 project is to develop methods for 1) quantitative and objective measurement of LV function, 2) reproducible diagnostic interpretation based on these measurements, and 3) standardized topologic mapping and parametric display of the results. We defined 3 parameters of LV function: 1) rate of local deformation (strain rate), 2) amplitude of deformation (strain), and 3) time interval to the transition (crossover) point of cyclic deformation.      The practical implementation of the long-term objectives will be achieved through the development of a Multiparametric Computational Echo (MPCE) system. The main hypothesis of this R21/R33 project is that the MPCE system will a) precisely and accurately quantitate (R21 phase) and b) reproducibly clinically interpret (R33 phase) segmental LV function. This hypothesis will be tested on digital echo data from animal models and clinical cases of myocardial ischemia representing a wide range of segmental LV dysfunction.      Specific Aims (R21 phase):   Aim 1 - Develop algorithms for parametric analysis of local ventricular function (Year 1).   Aim 2 - Test precision and accuracy of local LV functional analysis using MPCE (Year 2).   Satisfaction of the predefined milestones will initiate the commencement of the R33 phase.      Specific Aims (R33 phase):   Aim 1 - Develop a neural network MPCE system and test it initially in animals (Year 3).   Aim 2 - Refine parametric mapping and test reproducibility of MPCE data in humans (Year 4).   Successful completion of this project will result in noninvasive, quantitative, objective, and reproducible interpretation of LV function, thus facilitating optimal diagnostic and therapeutic decisions in cardiology. n/a",Multiparametric Computational Echocardiography,6783325,R21HL070363,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'echocardiography', 'evaluation /testing', 'heart function', 'human subject', 'method development', 'swine']",NHLBI,MAYO CLINIC,R21,2004,144693,-0.01987252922609098
"Multiparametric Computational Echocardiography DESCRIPTION (provided by applicant):    In the United States, myocardial ischemia is the underlying etiology in nearly 70% of the 5 million patients suffering from mechanical failure of the cardiac left ventricle (LV). Echocardiography (echo) is well suited for the analysis of LV function, however, the problem of conveying this clinically important information in a quantitative, objective, and reproducible manner persists.      To address this problem and respond to the NIH PA-00-117 solicitation for innovations in biomedical information science and technology, the long-term goal of the proposed R21/R33 project is to develop methods for 1) quantitative and objective measurement of LV function, 2) reproducible diagnostic interpretation based on these measurements, and 3) standardized topologic mapping and parametric display of the results. We defined 3 parameters of LV function: 1) rate of local deformation (strain rate), 2) amplitude of deformation (strain), and 3) time interval to the transition (crossover) point of cyclic deformation.      The practical implementation of the long-term objectives will be achieved through the development of a Multiparametric Computational Echo (MPCE) system. The main hypothesis of this R21/R33 project is that the MPCE system will a) precisely and accurately quantitate (R21 phase) and b) reproducibly clinically interpret (R33 phase) segmental LV function. This hypothesis will be tested on digital echo data from animal models and clinical cases of myocardial ischemia representing a wide range of segmental LV dysfunction.      Specific Aims (R21 phase):   Aim 1 - Develop algorithms for parametric analysis of local ventricular function (Year 1).   Aim 2 - Test precision and accuracy of local LV functional analysis using MPCE (Year 2).   Satisfaction of the predefined milestones will initiate the commencement of the R33 phase.      Specific Aims (R33 phase):   Aim 1 - Develop a neural network MPCE system and test it initially in animals (Year 3).   Aim 2 - Refine parametric mapping and test reproducibility of MPCE data in humans (Year 4).   Successful completion of this project will result in noninvasive, quantitative, objective, and reproducible interpretation of LV function, thus facilitating optimal diagnostic and therapeutic decisions in cardiology. n/a",Multiparametric Computational Echocardiography,6688878,R21HL070363,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' echocardiography', ' evaluation /testing', ' heart function', ' human subject', ' method development', ' swine']",NHLBI,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R21,2003,136861,-0.01987252922609098
"fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS    DESCRIPTION (provided by applicant):    Functional magnetic resonance imaging offers an unmatched combination of spatial and temporal resolution that continues to be pushed to new levels. Recently, the limits of BOLD fMRI have been challenged to the level of sub-millimeter structures. The reliability and reproducibility of these maps, as well as the optimization of the fMRI methods to acquire these maps has not yet been established, especially in humans. Differential mapping using gradient echoes, which may not be reliable in the general case because of the well known large vessel artifacts (more significantly at low fields), has been used in humans. We have recently demonstrated, made possible by funding from an R21 proposal, at sub-millimeter spatial resolutions, the advantages of high field Hahn spin echo (HSE) BOLD signals. Differences in specificity to neural activity between GE and HSE BOLD signals at high fields has not yet been addressed. Optimized BOLD signals to map brain function could allow for mapping of functional architecture without apriori knowledge of orthogonal conditions (i.e. single condition mapping). This would be an invaluable tool for many neuroscience applications where orthogonal conditions and columnar organizations in general are not known. This work will advance the foundation of our previous R21 proposal which investigated T2 weighted fMRI at high magnetic fields. The central hypothesis of this application is that HSE based BOLD fMRI signals at high fields (7 Tesla) can be used to attain a higher spatial specificity and therefore more reliable maps of cortical columns, in awake humans, than at lower fields (4 Tesla) and/or with gradient echoes. Finally, the existence of orientation columns in humans, which has never been shown, can be addressed using fMRI techniques developed in this work.         n/a",fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS,7385960,R01MH070800,"['Address', 'Architecture', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Condition', 'Cortical Column', 'Data', 'Dependence', 'Felis catus', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Generations', 'Human', 'Image', 'Knowledge', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Methods', 'Monitor', 'Morphologic artifacts', 'Neurons', 'Neurosciences', 'Numbers', 'Ocular dominance columns', 'Perfusion', 'Publications', 'Publishing', 'Reproducibility', 'Resolution', 'Signal Transduction', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Veins', 'Visual Cortex', 'Weight', 'Width', 'Work', 'awake', 'base', 'blood oxygen level dependent', 'blood oxygenation level dependent response', 'capillary', 'hemodynamics', 'improved', 'magnetic field', 'millimeter', 'orientation columns', 'relating to nervous system', 'research study', 'response', 'tool']",NIMH,UNIVERSITY OF MINNESOTA,R01,2008,316811,0.026051508952098536
"fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS    DESCRIPTION (provided by applicant):    Functional magnetic resonance imaging offers an unmatched combination of spatial and temporal resolution that continues to be pushed to new levels. Recently, the limits of BOLD fMRI have been challenged to the level of sub-millimeter structures. The reliability and reproducibility of these maps, as well as the optimization of the fMRI methods to acquire these maps has not yet been established, especially in humans. Differential mapping using gradient echoes, which may not be reliable in the general case because of the well known large vessel artifacts (more significantly at low fields), has been used in humans. We have recently demonstrated, made possible by funding from an R21 proposal, at sub-millimeter spatial resolutions, the advantages of high field Hahn spin echo (HSE) BOLD signals. Differences in specificity to neural activity between GE and HSE BOLD signals at high fields has not yet been addressed. Optimized BOLD signals to map brain function could allow for mapping of functional architecture without apriori knowledge of orthogonal conditions (i.e. single condition mapping). This would be an invaluable tool for many neuroscience applications where orthogonal conditions and columnar organizations in general are not known. This work will advance the foundation of our previous R21 proposal which investigated T2 weighted fMRI at high magnetic fields. The central hypothesis of this application is that HSE based BOLD fMRI signals at high fields (7 Tesla) can be used to attain a higher spatial specificity and therefore more reliable maps of cortical columns, in awake humans, than at lower fields (4 Tesla) and/or with gradient echoes. Finally, the existence of orientation columns in humans, which has never been shown, can be addressed using fMRI techniques developed in this work.         n/a",fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS,7189859,R01MH070800,"['Address', 'Architecture', 'Blood Vessels', 'Blood capillaries', 'Brain', 'Brain Mapping', 'Condition', 'Cortical Column', 'Data', 'Dependence', 'Felis catus', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Generations', 'Human', 'Image', 'Knowledge', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Methods', 'Monitor', 'Morphologic artifacts', 'Neurons', 'Neurosciences', 'Numbers', 'Ocular dominance columns', 'Perfusion', 'Publications', 'Publishing', 'Reproducibility', 'Resolution', 'Signal Transduction', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Veins', 'Visual Cortex', 'Weight', 'Width', 'Work', 'awake', 'base', 'blood oxygen level dependent', 'blood oxygenation level dependent response', 'capillary', 'hemodynamics', 'improved', 'magnetic field', 'millimeter', 'orientation columns', 'relating to nervous system', 'research study', 'response', 'tool']",NIMH,UNIVERSITY OF MINNESOTA,R01,2007,316811,0.026051508952098536
"fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS    DESCRIPTION (provided by applicant):    Functional magnetic resonance imaging offers an unmatched combination of spatial and temporal resolution that continues to be pushed to new levels. Recently, the limits of BOLD fMRI have been challenged to the level of sub-millimeter structures. The reliability and reproducibility of these maps, as well as the optimization of the fMRI methods to acquire these maps has not yet been established, especially in humans. Differential mapping using gradient echoes, which may not be reliable in the general case because of the well known large vessel artifacts (more significantly at low fields), has been used in humans. We have recently demonstrated, made possible by funding from an R21 proposal, at sub-millimeter spatial resolutions, the advantages of high field Hahn spin echo (HSE) BOLD signals. Differences in specificity to neural activity between GE and HSE BOLD signals at high fields has not yet been addressed. Optimized BOLD signals to map brain function could allow for mapping of functional architecture without apriori knowledge of orthogonal conditions (i.e. single condition mapping). This would be an invaluable tool for many neuroscience applications where orthogonal conditions and columnar organizations in general are not known. This work will advance the foundation of our previous R21 proposal which investigated T2 weighted fMRI at high magnetic fields. The central hypothesis of this application is that HSE based BOLD fMRI signals at high fields (7 Tesla) can be used to attain a higher spatial specificity and therefore more reliable maps of cortical columns, in awake humans, than at lower fields (4 Tesla) and/or with gradient echoes. Finally, the existence of orientation columns in humans, which has never been shown, can be addressed using fMRI techniques developed in this work.         n/a",fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS,7035857,R01MH070800,"['bioimaging /biomedical imaging', 'brain mapping', 'cats', 'clinical research', 'electrophysiology', 'functional magnetic resonance imaging', 'hemodynamics', 'human subject', 'magnetic field', 'neurophysiology', 'technology /technique development', 'visual cortex', 'visual stimulus']",NIMH,UNIVERSITY OF MINNESOTA TWIN CITIES,R01,2006,326274,0.026051508952098536
"fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS    DESCRIPTION (provided by applicant):    Functional magnetic resonance imaging offers an unmatched combination of spatial and temporal resolution that continues to be pushed to new levels. Recently, the limits of BOLD fMRI have been challenged to the level of sub-millimeter structures. The reliability and reproducibility of these maps, as well as the optimization of the fMRI methods to acquire these maps has not yet been established, especially in humans. Differential mapping using gradient echoes, which may not be reliable in the general case because of the well known large vessel artifacts (more significantly at low fields), has been used in humans. We have recently demonstrated, made possible by funding from an R21 proposal, at sub-millimeter spatial resolutions, the advantages of high field Hahn spin echo (HSE) BOLD signals. Differences in specificity to neural activity between GE and HSE BOLD signals at high fields has not yet been addressed. Optimized BOLD signals to map brain function could allow for mapping of functional architecture without apriori knowledge of orthogonal conditions (i.e. single condition mapping). This would be an invaluable tool for many neuroscience applications where orthogonal conditions and columnar organizations in general are not known. This work will advance the foundation of our previous R21 proposal which investigated T2 weighted fMRI at high magnetic fields. The central hypothesis of this application is that HSE based BOLD fMRI signals at high fields (7 Tesla) can be used to attain a higher spatial specificity and therefore more reliable maps of cortical columns, in awake humans, than at lower fields (4 Tesla) and/or with gradient echoes. Finally, the existence of orientation columns in humans, which has never been shown, can be addressed using fMRI techniques developed in this work.         n/a",fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS,6869607,R01MH070800,"['bioimaging /biomedical imaging', 'brain mapping', 'cats', 'clinical research', 'electrophysiology', 'functional magnetic resonance imaging', 'hemodynamics', 'human subject', 'magnetic field', 'neurophysiology', 'technology /technique development', 'visual cortex', 'visual stimulus']",NIMH,UNIVERSITY OF MINNESOTA TWIN CITIES,R01,2005,334125,0.026051508952098536
"fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS    DESCRIPTION (provided by applicant):    Functional magnetic resonance imaging offers an unmatched combination of spatial and temporal resolution that continues to be pushed to new levels. Recently, the limits of BOLD fMRI have been challenged to the level of sub-millimeter structures. The reliability and reproducibility of these maps, as well as the optimization of the fMRI methods to acquire these maps has not yet been established, especially in humans. Differential mapping using gradient echoes, which may not be reliable in the general case because of the well known large vessel artifacts (more significantly at low fields), has been used in humans. We have recently demonstrated, made possible by funding from an R21 proposal, at sub-millimeter spatial resolutions, the advantages of high field Hahn spin echo (HSE) BOLD signals. Differences in specificity to neural activity between GE and HSE BOLD signals at high fields has not yet been addressed. Optimized BOLD signals to map brain function could allow for mapping of functional architecture without apriori knowledge of orthogonal conditions (i.e. single condition mapping). This would be an invaluable tool for many neuroscience applications where orthogonal conditions and columnar organizations in general are not known. This work will advance the foundation of our previous R21 proposal which investigated T2 weighted fMRI at high magnetic fields. The central hypothesis of this application is that HSE based BOLD fMRI signals at high fields (7 Tesla) can be used to attain a higher spatial specificity and therefore more reliable maps of cortical columns, in awake humans, than at lower fields (4 Tesla) and/or with gradient echoes. Finally, the existence of orientation columns in humans, which has never been shown, can be addressed using fMRI techniques developed in this work.         n/a",fMRI ABILITY TO MAP COLUMNAR STRUCTURES IN HUMANS,6770600,R01MH070800,"['bioimaging /biomedical imaging', 'brain mapping', 'cats', 'clinical research', 'electrophysiology', 'functional magnetic resonance imaging', 'hemodynamics', 'human subject', 'magnetic field', 'neurophysiology', 'technology /technique development', 'visual cortex', 'visual stimulus']",NIMH,UNIVERSITY OF MINNESOTA TWIN CITIES,R01,2004,317756,0.026051508952098536
"NEW STATISTICAL METHODS FOR MEDICAL SIGNALS AND IMAGES DESCRIPTION:  (Adapted from the applicant's abstract):  Medical and              biological data often come in the form of digitized signals and images, for      example magnetic resonance images (MRI), ion channel electrical series, and      human gait paths.  As data acquisition becomes easier, sequences of such         images or signals are collected, often along with other covariate                measurements, resulting in data sets where the basic unit of measurement or      response is a high dimensional object.  This project proposes a battery of       statistical techniques for modeling and understanding such data, that            explicitly takes into account and indeed exploits the inherent, spatial, or      temporal correlation, and when appropriate, relates it to covariate              information.  By imposing spatial smoothness in the image or signal domain,      pixel-wise regression, and canonical correlation models can borrow strength      from neighboring pixels.  This not only improves the overall efficiency of       these techniques, but also allows identification of important regions rather     than individual pixels.  The project develops appropriate versions of            nonparametric regressions for such series of images, as well as data             descriptions such as clustering, principal component, and singular value         decomposition models.  In many cases, wavelets will be used to achieve           spatial smoothness.  In the case of ion channel data, the models are used to     isolate particular weak high frequency components from correlated noise.         Much of this work will be carried out in collaboration with radiologists,        physiologists, and other biomedical researchers working on cancer, heart         disease and stroke, brain mapping, and gait analysis.                             n/a",NEW STATISTICAL METHODS FOR MEDICAL SIGNALS AND IMAGES,2769887,R01CA072028,"['computer data analysis', ' diagnosis design /evaluation', ' digital imaging', ' mathematical model', ' statistics /biometry']",NCI,STANFORD UNIVERSITY,R01,1998,146191,-0.022710392220089713
"NEW STATISTICAL METHODS FOR MEDICAL SIGNALS AND IMAGES DESCRIPTION:  (Adapted from the applicant's abstract):  Medical and              biological data often come in the form of digitized signals and images, for      example magnetic resonance images (MRI), ion channel electrical series, and      human gait paths.  As data acquisition becomes easier, sequences of such         images or signals are collected, often along with other covariate                measurements, resulting in data sets where the basic unit of measurement or      response is a high dimensional object.  This project proposes a battery of       statistical techniques for modeling and understanding such data, that            explicitly takes into account and indeed exploits the inherent, spatial, or      temporal correlation, and when appropriate, relates it to covariate              information.  By imposing spatial smoothness in the image or signal domain,      pixel-wise regression, and canonical correlation models can borrow strength      from neighboring pixels.  This not only improves the overall efficiency of       these techniques, but also allows identification of important regions rather     than individual pixels.  The project develops appropriate versions of            nonparametric regressions for such series of images, as well as data             descriptions such as clustering, principal component, and singular value         decomposition models.  In many cases, wavelets will be used to achieve           spatial smoothness.  In the case of ion channel data, the models are used to     isolate particular weak high frequency components from correlated noise.         Much of this work will be carried out in collaboration with radiologists,        physiologists, and other biomedical researchers working on cancer, heart         disease and stroke, brain mapping, and gait analysis.                             n/a",NEW STATISTICAL METHODS FOR MEDICAL SIGNALS AND IMAGES,2517753,R01CA072028,"['computer data analysis', ' diagnosis design /evaluation', ' digital imaging', ' mathematical model', ' statistics /biometry']",NCI,STANFORD UNIVERSITY,R01,1997,143855,-0.022710392220089713
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7563977,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug candidate', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2009,355016,0.013031905741932224
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7405144,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Numbers', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Range', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2008,394557,0.013031905741932224
"Building a Latino admixture map & pilot study to find Type 2 Diabetes risk    DESCRIPTION (provided by applicant): Admixture mapping is a novel way to screen the genome for disease genes. It has as much power as a traditional haplotype-based association study, but is practical today, because it requires studying only a couple of thousand polymorphic genetic markers. The idea of admixture mapping is that people with disease who descend from the recent mixing of ethnic groups should have an increased probability of inheriting DNA from the ancestral population with higher disease risk. For example, because of the association of Amerindian ancestry with Type 2 diabetes, Latino Americans who have 30% Amerindian and 70% European ancestry on average might tend to have an unusually high level of Amerindian ancestry near a T2D gene. We recently created the first practical resource for admixture mapping in African Americans, and developed a Hidden Markov Model nested within a Markov Chain Monte Carlo to analyze data from admixture scans, and applied it to localize a risk gene for multiple sclerosis. We now propose to create a practical admixture map for Amerindian mixed populations, and to use it to study Type 2 Diabetes in 600 cases and 250 controls from Antioquia, Colombia. We will begin this study by searching a company database of 1.56 million single nucleotide polymorphisms (SNPs) with known frequencies in populations of both Amerindian and European American descent. We will then validate 4,608 of these SNPs in our laboratory in 377 samples drawn from Amerindian, European American, and African populations. Based on this validation genotyping, we will then select a subset of about 1,536 markers that are maximally informative for admixture mapping. This panel of markers will constitute our Latino admixture 'map'. As the second goal of this application, we will use the map to measure ancestry along the genome in 600 Type 2 diabetes cases, and 250 matched controls from Colombia. The cases have all been extensively phenotyped for a range of Type 2 Diabetes-related traits. Using our map, we will scan the genome to look for regions of unusually high (or low) Amerindian ancestry in the Type 2 Diabetes cases, which could indicate the presence of a diabetes risk gene. This pilot study will provide a first application of our admixture map, with potential to find new risk genes for Type 2 Diabetes. The study will also enable larger admixture mapping studies with many thousands of patients with Type 2 Diabetes, which we would like to pursue both in U.S. Latino and in Latin American populations.           n/a",Building a Latino admixture map & pilot study to find Type 2 Diabetes risk,7273883,R21DK073818,"['Admixture', 'African American', 'American', 'Colombia', 'DNA', 'Data Analyses', 'Databases', 'Disease', 'Ethnic group', 'European', 'Frequencies', 'Genes', 'Genetic Markers', 'Genome', 'Genome Scan', 'Genotype', 'Goals', 'Haplotypes', 'Inherited', 'Laboratories', 'Latino', 'Localized', 'Maps', 'Markov Chains', 'Measures', 'Multiple Sclerosis', 'Non-Insulin-Dependent Diabetes Mellitus', 'Patients', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Range', 'Research Design', 'Resources', 'Risk', 'Sampling', 'Scanning', 'Single Nucleotide Polymorphism', 'Today', 'Validation', 'base', 'diabetes risk', 'disorder risk', 'markov model', 'novel', 'trait']",NIDDK,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2007,150650,0.03500261633528452
"Building a Latino admixture map & pilot study to find Type 2 Diabetes risk    DESCRIPTION (provided by applicant): Admixture mapping is a novel way to screen the genome for disease genes. It has as much power as a traditional haplotype-based association study, but is practical today, because it requires studying only a couple of thousand polymorphic genetic markers. The idea of admixture mapping is that people with disease who descend from the recent mixing of ethnic groups should have an increased probability of inheriting DNA from the ancestral population with higher disease risk. For example, because of the association of Amerindian ancestry with Type 2 diabetes, Latino Americans who have 30% Amerindian and 70% European ancestry on average might tend to have an unusually high level of Amerindian ancestry near a T2D gene. We recently created the first practical resource for admixture mapping in African Americans, and developed a Hidden Markov Model nested within a Markov Chain Monte Carlo to analyze data from admixture scans, and applied it to localize a risk gene for multiple sclerosis. We now propose to create a practical admixture map for Amerindian mixed populations, and to use it to study Type 2 Diabetes in 600 cases and 250 controls from Antioquia, Colombia. We will begin this study by searching a company database of 1.56 million single nucleotide polymorphisms (SNPs) with known frequencies in populations of both Amerindian and European American descent. We will then validate 4,608 of these SNPs in our laboratory in 377 samples drawn from Amerindian, European American, and African populations. Based on this validation genotyping, we will then select a subset of about 1,536 markers that are maximally informative for admixture mapping. This panel of markers will constitute our Latino admixture 'map'. As the second goal of this application, we will use the map to measure ancestry along the genome in 600 Type 2 diabetes cases, and 250 matched controls from Colombia. The cases have all been extensively phenotyped for a range of Type 2 Diabetes-related traits. Using our map, we will scan the genome to look for regions of unusually high (or low) Amerindian ancestry in the Type 2 Diabetes cases, which could indicate the presence of a diabetes risk gene. This pilot study will provide a first application of our admixture map, with potential to find new risk genes for Type 2 Diabetes. The study will also enable larger admixture mapping studies with many thousands of patients with Type 2 Diabetes, which we would like to pursue both in U.S. Latino and in Latin American populations.           n/a",Building a Latino admixture map & pilot study to find Type 2 Diabetes risk,7146551,R21DK073818,"['African', 'Hispanic Americans', 'Native Americans', 'South American', 'biotechnology', 'caucasian American', 'diabetes risk', 'genetic mapping', 'genetic markers', 'genetic polymorphism', 'genetic susceptibility', 'genotype', 'human data', 'noninsulin dependent diabetes mellitus', 'population genetics']",NIDDK,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2006,260020,0.03500261633528452
"Meta-Analysis in Human Brain Mapping    DESCRIPTION (provided by applicant):  The overall objective of the present proposal is to develop, evaluate, distribute, and apply tools for the BrainMap Project, which provides the human brain mapping (HBM) community with data sets, computational tools, and informatics resources for quantitative meta-analyses and meta-analysis-based data interpretation.  The development of coordinate-based, voxel-wise meta-analysis (CVM) has been a breakthrough for HBM, enabling statistically rigorous meta-analysis and systems-level modeling of published results.  The HBM literature suitable for CVM meta-analysis was estimated in 2007 to be ~6,000 papers, with ~1000 new conforming papers being published each year.  In this renewal, we propose numerous enhancements to widely used coordinate-based meta-analysis tools (Aim 1).  Meta-analytic connectivity mapping (MACM) is a new application of CVM, which derives inter-regional connectivity maps from inter-study co-occurrence patterns.  In this renewal, we propose to extend the functionality of our MACM tools, construct connectivity atlases through data mining, and validate these atlases by comparison to non-meta-analytic approaches (Aim 2).  In BrainMap, behavioral meta-data are coded using a taxonomy developed and progressively refined by the BrainMap team.  Recent application of independent component analysis (ICA) to BrainMap extracted intrinsic neural systems that were well, but not perfectly, discriminated by the BrainMap coding scheme.  This observation suggests robust computational approaches both for providing a behavioral ontology for intrinsically connected networks and also for programmatic refinement of the BrainMap coding scheme (Aim 3).  Finally, it has recently been demonstrated that CVM can be applied to voxel-based morphometry (VBM) structural neuroimaging studies.  In Aim 4, we anticipate the rapid growth of VBM research by creating a BrainMap-like database of the standards- compliant VBM literature.  These proposed enhancements and extensions of the BrainMap Project will allow this rich set of neuroinformatics tools to continue to meet the research and educational needs for knowledge discovery and data mining in the neuroimaging community.  1         An extraordinary amount of neuroimaging data has been acquired and analyzed over the last two decades in both healthy subjects and patients diagnosed with various neurologic or psychiatric diseases and disorders.  The BrainMap Project aims to improve public health by developing methods that will enable more informed cognitive, perceptual, and motor models of brain function and dysfunction.  The proposed research will allow 2            ",Meta-Analysis in Human Brain Mapping,8700514,R01MH074457,"['Adopted', 'Adoption', 'Algorithms', 'Atlases', 'Behavioral', 'Brain', 'Brain Mapping', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Computational Science', 'Computer software', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Fostering', 'Functional disorder', 'Funding', 'Goals', 'Human', 'Knowledge Discovery', 'Label', 'Laboratories', 'Literature', 'Maps', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Mining', 'Modeling', 'Motor', 'Neurologic', 'Ontology', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Property', 'Public Health', 'Publications', 'Publishing', 'Research', 'Resource Informatics', 'Resource Sharing', 'Resources', 'Rest', 'Scheme', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Taxonomy', 'Technology', 'United States National Institutes of Health', 'base', 'computerized tools', 'data mining', 'data space', 'developmental disease', 'improved', 'independent component analysis', 'innovation', 'meetings', 'morphometry', 'nervous system disorder', 'neuroimaging', 'neuroinformatics', 'parent grant', 'rapid growth', 'relating to nervous system', 'text searching', 'tool']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R01,2014,614757,-0.013244599624552881
"Meta-Analysis in Human Brain Mapping    DESCRIPTION (provided by applicant):  The overall objective of the present proposal is to develop, evaluate, distribute, and apply tools for the BrainMap Project, which provides the human brain mapping (HBM) community with data sets, computational tools, and informatics resources for quantitative meta-analyses and meta-analysis-based data interpretation.  The development of coordinate-based, voxel-wise meta-analysis (CVM) has been a breakthrough for HBM, enabling statistically rigorous meta-analysis and systems-level modeling of published results.  The HBM literature suitable for CVM meta-analysis was estimated in 2007 to be ~6,000 papers, with ~1000 new conforming papers being published each year.  In this renewal, we propose numerous enhancements to widely used coordinate-based meta-analysis tools (Aim 1).  Meta-analytic connectivity mapping (MACM) is a new application of CVM, which derives inter-regional connectivity maps from inter-study co-occurrence patterns.  In this renewal, we propose to extend the functionality of our MACM tools, construct connectivity atlases through data mining, and validate these atlases by comparison to non-meta-analytic approaches (Aim 2).  In BrainMap, behavioral meta-data are coded using a taxonomy developed and progressively refined by the BrainMap team.  Recent application of independent component analysis (ICA) to BrainMap extracted intrinsic neural systems that were well, but not perfectly, discriminated by the BrainMap coding scheme.  This observation suggests robust computational approaches both for providing a behavioral ontology for intrinsically connected networks and also for programmatic refinement of the BrainMap coding scheme (Aim 3).  Finally, it has recently been demonstrated that CVM can be applied to voxel-based morphometry (VBM) structural neuroimaging studies.  In Aim 4, we anticipate the rapid growth of VBM research by creating a BrainMap-like database of the standards- compliant VBM literature.  These proposed enhancements and extensions of the BrainMap Project will allow this rich set of neuroinformatics tools to continue to meet the research and educational needs for knowledge discovery and data mining in the neuroimaging community.  1       PUBLIC HEALTH RELEVANCE:  An extraordinary amount of neuroimaging data has been acquired and analyzed over the last two decades in both healthy subjects and patients diagnosed with various neurologic or psychiatric diseases and disorders.  The BrainMap Project aims to improve public health by developing methods that will enable more informed cognitive, perceptual, and motor models of brain function and dysfunction.  The proposed research will allow 2            ",Meta-Analysis in Human Brain Mapping,8464784,R01MH074457,"['Adopted', 'Adoption', 'Algorithms', 'Atlases', 'Behavioral', 'Brain', 'Brain Mapping', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Computational Science', 'Computer software', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Fostering', 'Functional disorder', 'Funding', 'Goals', 'Human', 'Knowledge Discovery', 'Label', 'Laboratories', 'Literature', 'Maps', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Mining', 'Modeling', 'Motor', 'Neurologic', 'Ontology', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Property', 'Public Health', 'Publications', 'Publishing', 'Research', 'Resource Informatics', 'Resource Sharing', 'Resources', 'Rest', 'Scheme', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Taxonomy', 'Technology', 'United States National Institutes of Health', 'base', 'computerized tools', 'data mining', 'data space', 'developmental disease', 'improved', 'independent component analysis', 'innovation', 'meetings', 'morphometry', 'nervous system disorder', 'neuroimaging', 'neuroinformatics', 'parent grant', 'public health relevance', 'rapid growth', 'relating to nervous system', 'text searching', 'tool']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R01,2013,602922,-0.013244599624552881
"Meta-Analysis in Human Brain Mapping    DESCRIPTION (provided by applicant):  The overall objective of the present proposal is to develop, evaluate, distribute, and apply tools for the BrainMap Project, which provides the human brain mapping (HBM) community with data sets, computational tools, and informatics resources for quantitative meta-analyses and meta-analysis-based data interpretation.  The development of coordinate-based, voxel-wise meta-analysis (CVM) has been a breakthrough for HBM, enabling statistically rigorous meta-analysis and systems-level modeling of published results.  The HBM literature suitable for CVM meta-analysis was estimated in 2007 to be ~6,000 papers, with ~1000 new conforming papers being published each year.  In this renewal, we propose numerous enhancements to widely used coordinate-based meta-analysis tools (Aim 1).  Meta-analytic connectivity mapping (MACM) is a new application of CVM, which derives inter-regional connectivity maps from inter-study co-occurrence patterns.  In this renewal, we propose to extend the functionality of our MACM tools, construct connectivity atlases through data mining, and validate these atlases by comparison to non-meta-analytic approaches (Aim 2).  In BrainMap, behavioral meta-data are coded using a taxonomy developed and progressively refined by the BrainMap team.  Recent application of independent component analysis (ICA) to BrainMap extracted intrinsic neural systems that were well, but not perfectly, discriminated by the BrainMap coding scheme.  This observation suggests robust computational approaches both for providing a behavioral ontology for intrinsically connected networks and also for programmatic refinement of the BrainMap coding scheme (Aim 3).  Finally, it has recently been demonstrated that CVM can be applied to voxel-based morphometry (VBM) structural neuroimaging studies.  In Aim 4, we anticipate the rapid growth of VBM research by creating a BrainMap-like database of the standards- compliant VBM literature.  These proposed enhancements and extensions of the BrainMap Project will allow this rich set of neuroinformatics tools to continue to meet the research and educational needs for knowledge discovery and data mining in the neuroimaging community.  1      PUBLIC HEALTH RELEVANCE:  An extraordinary amount of neuroimaging data has been acquired and analyzed over the last two decades in both healthy subjects and patients diagnosed with various neurologic or psychiatric diseases and disorders.  The BrainMap Project aims to improve public health by developing methods that will enable more informed cognitive, perceptual, and motor models of brain function and dysfunction.  The proposed research will allow 2              PUBLIC HEALTH RELEVANCE STATEMENT (PROJECT NARRATIVE) (Using no more than 2 or 3 sentences, describe the relevance of this research to public health. In this section, be succinct and use plain language that can be understood by a general, lay audience.) An extraordinary amount of neuroimaging data has been acquired and analyzed over the last two decades in both healthy subjects and patients diagnosed with various neurologic or psychiatric diseases and disorders. The BrainMap Project aims to improve public health by developing methods that will enable more informed cognitive, perceptual, and motor models of brain function and dysfunction. The proposed research will allow 2",Meta-Analysis in Human Brain Mapping,8301788,R01MH074457,"['Adopted', 'Adoption', 'Algorithms', 'Atlases', 'Behavioral', 'Brain', 'Brain Mapping', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Computational Science', 'Computer software', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Fostering', 'Functional disorder', 'Funding', 'Goals', 'Human', 'Knowledge Discovery', 'Label', 'Laboratories', 'Language', 'Literature', 'Maps', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Mining', 'Modeling', 'Motor', 'Neurologic', 'Ontology', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Property', 'Public Health', 'Publications', 'Publishing', 'Research', 'Resource Informatics', 'Resource Sharing', 'Resources', 'Rest', 'Scheme', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Taxonomy', 'Technology', 'United States National Institutes of Health', 'base', 'computerized tools', 'data mining', 'data space', 'developmental disease', 'improved', 'independent component analysis', 'innovation', 'meetings', 'morphometry', 'nervous system disorder', 'neuroimaging', 'neuroinformatics', 'parent grant', 'public health relevance', 'rapid growth', 'relating to nervous system', 'text searching', 'tool']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R01,2012,640093,-0.008241044256840137
"Meta-Analysis in Human Brain Mapping    DESCRIPTION (provided by applicant):  The overall objective of the present proposal is to develop, evaluate, distribute, and apply tools for the BrainMap Project, which provides the human brain mapping (HBM) community with data sets, computational tools, and informatics resources for quantitative meta-analyses and meta-analysis-based data interpretation.  The development of coordinate-based, voxel-wise meta-analysis (CVM) has been a breakthrough for HBM, enabling statistically rigorous meta-analysis and systems-level modeling of published results.  The HBM literature suitable for CVM meta-analysis was estimated in 2007 to be ~6,000 papers, with ~1000 new conforming papers being published each year.  In this renewal, we propose numerous enhancements to widely used coordinate-based meta-analysis tools (Aim 1).  Meta-analytic connectivity mapping (MACM) is a new application of CVM, which derives inter-regional connectivity maps from inter-study co-occurrence patterns.  In this renewal, we propose to extend the functionality of our MACM tools, construct connectivity atlases through data mining, and validate these atlases by comparison to non-meta-analytic approaches (Aim 2).  In BrainMap, behavioral meta-data are coded using a taxonomy developed and progressively refined by the BrainMap team.  Recent application of independent component analysis (ICA) to BrainMap extracted intrinsic neural systems that were well, but not perfectly, discriminated by the BrainMap coding scheme.  This observation suggests robust computational approaches both for providing a behavioral ontology for intrinsically connected networks and also for programmatic refinement of the BrainMap coding scheme (Aim 3).  Finally, it has recently been demonstrated that CVM can be applied to voxel-based morphometry (VBM) structural neuroimaging studies.  In Aim 4, we anticipate the rapid growth of VBM research by creating a BrainMap-like database of the standards- compliant VBM literature.  These proposed enhancements and extensions of the BrainMap Project will allow this rich set of neuroinformatics tools to continue to meet the research and educational needs for knowledge discovery and data mining in the neuroimaging community.  1      PUBLIC HEALTH RELEVANCE:  An extraordinary amount of neuroimaging data has been acquired and analyzed over the last two decades in both healthy subjects and patients diagnosed with various neurologic or psychiatric diseases and disorders.  The BrainMap Project aims to improve public health by developing methods that will enable more informed cognitive, perceptual, and motor models of brain function and dysfunction.  The proposed research will allow 2              PUBLIC HEALTH RELEVANCE STATEMENT (PROJECT NARRATIVE) (Using no more than 2 or 3 sentences, describe the relevance of this research to public health. In this section, be succinct and use plain language that can be understood by a general, lay audience.) An extraordinary amount of neuroimaging data has been acquired and analyzed over the last two decades in both healthy subjects and patients diagnosed with various neurologic or psychiatric diseases and disorders. The BrainMap Project aims to improve public health by developing methods that will enable more informed cognitive, perceptual, and motor models of brain function and dysfunction. The proposed research will allow 2",Meta-Analysis in Human Brain Mapping,8115191,R01MH074457,"['Adopted', 'Adoption', 'Algorithms', 'Atlases', 'Behavioral', 'Brain', 'Brain Mapping', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Computational Science', 'Computer software', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Fostering', 'Functional disorder', 'Funding', 'Goals', 'Human', 'Knowledge Discovery', 'Label', 'Laboratories', 'Language', 'Literature', 'Maps', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Mining', 'Modeling', 'Motor', 'Neurologic', 'Ontology', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Property', 'Public Health', 'Publications', 'Publishing', 'Research', 'Resource Informatics', 'Resource Sharing', 'Resources', 'Rest', 'Scheme', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Taxonomy', 'Technology', 'United States National Institutes of Health', 'base', 'computerized tools', 'data mining', 'data space', 'developmental disease', 'improved', 'independent component analysis', 'innovation', 'meetings', 'morphometry', 'nervous system disorder', 'neuroimaging', 'neuroinformatics', 'parent grant', 'public health relevance', 'rapid growth', 'relating to nervous system', 'text searching', 'tool']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R01,2011,658731,-0.008241044256840137
"Theoretical Population Genetics    DESCRIPTION (provided by applicant): This project is concerned with developing new statistical methodology for population genetic data. Attention will be focused on three main areas concerned with dependencies among sets of alleles: the characterization of population structure, the characterization of the association patterns within and between genetic markers and along haplotypes, and the characterization of relatedness and inbreeding for individuals. Theory will be developed at least in part in response to the needs of current large-scale SNP surveys for humans and in anticipation of whole-genome sequence data sets. The work is proposed by a group of investigators in the Department of Biostatistics at the University of Washington. They propose to continue collaboration with W.G. Hill at the University of Edinburgh and P.M. Visscher at the Queensland Institute of Medical Research. This extended group has interacted successfully over the previous award period, as evidenced by a set of 40 publications. The Beagle approach of S.R. and B.L. Browning will be applied to the detection of tracts of identity by descent. The resulting measures of relationship will be used to refine tests for marker-disease association and to estimate heritability of complex human traits. The population-specific measures of population structure described by B.S. Weir and W.G. Hill will be applied to recently published whole-genome SNP data sets and whole-genome sequence data sets. Methods will be sought to improve methods of drawing inferences about these quantities. Measures of identity by descent and of population structure have the potential to identify regions of the human genome that have been subject to natural selection, and these analyses will be conducted with attention to the large variation and skewness imposed by the evolutionary process. The work of C.C. Laurie and B.S. Weir on detecting chromosomal features, such as inversions, by examining correlations of individual SNPs with principal components derived from large sets of SNPs will be extended. The partial regression approach introduced for QTL mapping will be applied to this problem. Measures of linkage disequilibrium that do not depend on genotypic phase were introduced and have been used previously by these investigators. They will now be extended to the situation of disequilibrium between pairs of loci when several SNPs typed for each gene. Association mapping continues to be of considerable interest to human geneticists and the problem of accounting for (even low level) relatedness will be addressed. Ignoring individuals with at least one relative in a case-control study, for example, can lead to a loss of power. Previous work of Y. Choi and B.S. Weir that modified simple allelic association tests will be extended to the more appropriate logistic regression methods.        As population genetic datasets grow, there is both the need and the opportunity to quantify the dependencies among alleles within and between individuals, or within and between populations. Individual-level dependencies address inbreeding and relatedness and can lead to estimates of heritability of complex human traits. Relatedness estimates can be used to modify tests of association between genetic markers and human diseases. Allelic dependencies at the population level provide characterization of population structure and can be used to infer the presence of natural selection in the history of the populations. Work is proposed to strengthen ways of estimating allelic dependencies, with attention being paid to the variation imposed by the evolutionary process as well as the variation from sampling individuals from current populations.         ",Theoretical Population Genetics,8656698,R01GM075091,"['Accounting', 'Address', 'Alleles', 'Area', 'Attention', 'Award', 'Biometry', 'Case-Control Studies', 'Chromosome Mapping', 'Chromosomes', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Dependency', 'Detection', 'Disease Association', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Markers', 'Genome', 'Genomics', 'Haplotypes', 'Heritability', 'Human', 'Human Genome', 'Inbreeding', 'Individual', 'Institutes', 'Lead', 'Linkage Disequilibrium', 'Logistic Regressions', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phase', 'Population', 'Population Genetics', 'Principal Component Analysis', 'Process', 'Publications', 'Publishing', 'Quantitative Trait Loci', 'Queensland', 'Recording of previous events', 'Relative (related person)', 'Research Personnel', 'Sampling', 'Structure', 'Surveys', 'Testing', 'Uniparental Disomy', 'United States National Institutes of Health', 'Universities', 'Variant', 'Washington', 'Work', 'genome sequencing', 'genome wide association study', 'human disease', 'improved', 'interest', 'response', 'theories', 'trait']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2014,404708,-0.0032283860942789394
"Theoretical Population Genetics    DESCRIPTION (provided by applicant): This project is concerned with developing new statistical methodology for population genetic data. Attention will be focused on three main areas concerned with dependencies among sets of alleles: the characterization of population structure, the characterization of the association patterns within and between genetic markers and along haplotypes, and the characterization of relatedness and inbreeding for individuals. Theory will be developed at least in part in response to the needs of current large-scale SNP surveys for humans and in anticipation of whole-genome sequence data sets. The work is proposed by a group of investigators in the Department of Biostatistics at the University of Washington. They propose to continue collaboration with W.G. Hill at the University of Edinburgh and P.M. Visscher at the Queensland Institute of Medical Research. This extended group has interacted successfully over the previous award period, as evidenced by a set of 40 publications. The Beagle approach of S.R. and B.L. Browning will be applied to the detection of tracts of identity by descent. The resulting measures of relationship will be used to refine tests for marker-disease association and to estimate heritability of complex human traits. The population-specific measures of population structure described by B.S. Weir and W.G. Hill will be applied to recently published whole-genome SNP data sets and whole-genome sequence data sets. Methods will be sought to improve methods of drawing inferences about these quantities. Measures of identity by descent and of population structure have the potential to identify regions of the human genome that have been subject to natural selection, and these analyses will be conducted with attention to the large variation and skewness imposed by the evolutionary process. The work of C.C. Laurie and B.S. Weir on detecting chromosomal features, such as inversions, by examining correlations of individual SNPs with principal components derived from large sets of SNPs will be extended. The partial regression approach introduced for QTL mapping will be applied to this problem. Measures of linkage disequilibrium that do not depend on genotypic phase were introduced and have been used previously by these investigators. They will now be extended to the situation of disequilibrium between pairs of loci when several SNPs typed for each gene. Association mapping continues to be of considerable interest to human geneticists and the problem of accounting for (even low level) relatedness will be addressed. Ignoring individuals with at least one relative in a case-control study, for example, can lead to a loss of power. Previous work of Y. Choi and B.S. Weir that modified simple allelic association tests will be extended to the more appropriate logistic regression methods.        As population genetic datasets grow, there is both the need and the opportunity to quantify the dependencies among alleles within and between individuals, or within and between populations. Individual-level dependencies address inbreeding and relatedness and can lead to estimates of heritability of complex human traits. Relatedness estimates can be used to modify tests of association between genetic markers and human diseases. Allelic dependencies at the population level provide characterization of population structure and can be used to infer the presence of natural selection in the history of the populations. Work is proposed to strengthen ways of estimating allelic dependencies, with attention being paid to the variation imposed by the evolutionary process as well as the variation from sampling individuals from current populations.         ",Theoretical Population Genetics,8536826,R01GM075091,"['Accounting', 'Address', 'Alleles', 'Area', 'Attention', 'Award', 'Biometry', 'Case-Control Studies', 'Chromosome Mapping', 'Chromosomes', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Dependency', 'Detection', 'Disease Association', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Markers', 'Genome', 'Genomics', 'Haplotypes', 'Heritability', 'Human', 'Human Genome', 'Inbreeding', 'Individual', 'Institutes', 'Lead', 'Linkage Disequilibrium', 'Logistic Regressions', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phase', 'Population', 'Population Genetics', 'Principal Component Analysis', 'Process', 'Publications', 'Publishing', 'Quantitative Trait Loci', 'Queensland', 'Recording of previous events', 'Relative (related person)', 'Research Personnel', 'Sampling', 'Structure', 'Surveys', 'Testing', 'Uniparental Disomy', 'United States National Institutes of Health', 'Universities', 'Variant', 'Washington', 'Work', 'genome sequencing', 'genome wide association study', 'human disease', 'improved', 'interest', 'response', 'theories', 'trait']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2013,390545,-0.0032283860942789394
"Theoretical Population Genetics    DESCRIPTION (provided by applicant): This project is concerned with developing new statistical methodology for population genetic data. Attention will be focused on three main areas concerned with dependencies among sets of alleles: the characterization of population structure, the characterization of the association patterns within and between genetic markers and along haplotypes, and the characterization of relatedness and inbreeding for individuals. Theory will be developed at least in part in response to the needs of current large-scale SNP surveys for humans and in anticipation of whole-genome sequence data sets. The work is proposed by a group of investigators in the Department of Biostatistics at the University of Washington. They propose to continue collaboration with W.G. Hill at the University of Edinburgh and P.M. Visscher at the Queensland Institute of Medical Research. This extended group has interacted successfully over the previous award period, as evidenced by a set of 40 publications. The Beagle approach of S.R. and B.L. Browning will be applied to the detection of tracts of identity by descent. The resulting measures of relationship will be used to refine tests for marker-disease association and to estimate heritability of complex human traits. The population-specific measures of population structure described by B.S. Weir and W.G. Hill will be applied to recently published whole-genome SNP data sets and whole-genome sequence data sets. Methods will be sought to improve methods of drawing inferences about these quantities. Measures of identity by descent and of population structure have the potential to identify regions of the human genome that have been subject to natural selection, and these analyses will be conducted with attention to the large variation and skewness imposed by the evolutionary process. The work of C.C. Laurie and B.S. Weir on detecting chromosomal features, such as inversions, by examining correlations of individual SNPs with principal components derived from large sets of SNPs will be extended. The partial regression approach introduced for QTL mapping will be applied to this problem. Measures of linkage disequilibrium that do not depend on genotypic phase were introduced and have been used previously by these investigators. They will now be extended to the situation of disequilibrium between pairs of loci when several SNPs typed for each gene. Association mapping continues to be of considerable interest to human geneticists and the problem of accounting for (even low level) relatedness will be addressed. Ignoring individuals with at least one relative in a case-control study, for example, can lead to a loss of power. Previous work of Y. Choi and B.S. Weir that modified simple allelic association tests will be extended to the more appropriate logistic regression methods.        As population genetic datasets grow, there is both the need and the opportunity to quantify the dependencies among alleles within and between individuals, or within and between populations. Individual-level dependencies address inbreeding and relatedness and can lead to estimates of heritability of complex human traits. Relatedness estimates can be used to modify tests of association between genetic markers and human diseases. Allelic dependencies at the population level provide characterization of population structure and can be used to infer the presence of natural selection in the history of the populations. Work is proposed to strengthen ways of estimating allelic dependencies, with attention being paid to the variation imposed by the evolutionary process as well as the variation from sampling individuals from current populations.         ",Theoretical Population Genetics,8301543,R01GM075091,"['Accounting', 'Address', 'Alleles', 'Area', 'Attention', 'Award', 'Biometry', 'Case-Control Studies', 'Chromosome Mapping', 'Chromosomes', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Dependency', 'Detection', 'Disease Association', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Markers', 'Genome', 'Genomics', 'Haplotypes', 'Heritability', 'Human', 'Human Genome', 'Inbreeding', 'Individual', 'Institutes', 'Lead', 'Linkage Disequilibrium', 'Logistic Regressions', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phase', 'Population', 'Population Genetics', 'Principal Component Analysis', 'Process', 'Publications', 'Publishing', 'Quantitative Trait Loci', 'Queensland', 'Recording of previous events', 'Relative (related person)', 'Research Personnel', 'Sampling', 'Structure', 'Surveys', 'Testing', 'Uniparental Disomy', 'United States National Institutes of Health', 'Universities', 'Variant', 'Washington', 'Work', 'genome sequencing', 'genome wide association study', 'human disease', 'improved', 'interest', 'response', 'theories', 'trait']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2012,404545,-0.0032283860942789394
"Theoretical Population Genetics    DESCRIPTION (provided by applicant): This project is concerned with developing new statistical methodology for population genetic data. Attention will be focused on three main areas concerned with dependencies among sets of alleles: the characterization of population structure, the characterization of the association patterns within and between genetic markers and along haplotypes, and the characterization of relatedness and inbreeding for individuals. Theory will be developed at least in part in response to the needs of current large-scale SNP surveys for humans and in anticipation of whole-genome sequence data sets. The work is proposed by a group of investigators in the Department of Biostatistics at the University of Washington. They propose to continue collaboration with W.G. Hill at the University of Edinburgh and P.M. Visscher at the Queensland Institute of Medical Research. This extended group has interacted successfully over the previous award period, as evidenced by a set of 40 publications. The Beagle approach of S.R. and B.L. Browning will be applied to the detection of tracts of identity by descent. The resulting measures of relationship will be used to refine tests for marker-disease association and to estimate heritability of complex human traits. The population-specific measures of population structure described by B.S. Weir and W.G. Hill will be applied to recently published whole-genome SNP data sets and whole-genome sequence data sets. Methods will be sought to improve methods of drawing inferences about these quantities. Measures of identity by descent and of population structure have the potential to identify regions of the human genome that have been subject to natural selection, and these analyses will be conducted with attention to the large variation and skewness imposed by the evolutionary process. The work of C.C. Laurie and B.S. Weir on detecting chromosomal features, such as inversions, by examining correlations of individual SNPs with principal components derived from large sets of SNPs will be extended. The partial regression approach introduced for QTL mapping will be applied to this problem. Measures of linkage disequilibrium that do not depend on genotypic phase were introduced and have been used previously by these investigators. They will now be extended to the situation of disequilibrium between pairs of loci when several SNPs typed for each gene. Association mapping continues to be of considerable interest to human geneticists and the problem of accounting for (even low level) relatedness will be addressed. Ignoring individuals with at least one relative in a case-control study, for example, can lead to a loss of power. Previous work of Y. Choi and B.S. Weir that modified simple allelic association tests will be extended to the more appropriate logistic regression methods.      PUBLIC HEALTH RELEVANCE: As population genetic datasets grow, there is both the need and the opportunity to quantify the dependencies among alleles within and between individuals, or within and between populations. Individual-level dependencies address inbreeding and relatedness and can lead to estimates of heritability of complex human traits. Relatedness estimates can be used to modify tests of association between genetic markers and human diseases. Allelic dependencies at the population level provide characterization of population structure and can be used to infer the presence of natural selection in the history of the populations. Work is proposed to strengthen ways of estimating allelic dependencies, with attention being paid to the variation imposed by the evolutionary process as well as the variation from sampling individuals from current populations.           As population genetic datasets grow, there is both the need and the opportunity to quantify the dependencies among alleles within and between individuals, or within and between populations. Individual-level dependencies address inbreeding and relatedness and can lead to estimates of heritability of complex human traits. Relatedness estimates can be used to modify tests of association between genetic markers and human diseases. Allelic dependencies at the population level provide characterization of population structure and can be used to infer the presence of natural selection in the history of the populations. Work is proposed to strengthen ways of estimating allelic dependencies, with attention being paid to the variation imposed by the evolutionary process as well as the variation from sampling individuals from current populations.         ",Theoretical Population Genetics,8185482,R01GM075091,"['Accounting', 'Address', 'Alleles', 'Area', 'Attention', 'Award', 'Biometry', 'Case-Control Studies', 'Chromosome Mapping', 'Chromosomes', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Dependency', 'Detection', 'Disease Association', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Markers', 'Genome', 'Genomics', 'Haplotypes', 'Heritability', 'Human', 'Human Genome', 'Inbreeding', 'Individual', 'Institutes', 'Lead', 'Linkage Disequilibrium', 'Logistic Regressions', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phase', 'Population', 'Population Genetics', 'Principal Component Analysis', 'Process', 'Publications', 'Publishing', 'Quantitative Trait Loci', 'Queensland', 'Recording of previous events', 'Relative (related person)', 'Research Personnel', 'Sampling', 'Structure', 'Surveys', 'Testing', 'Uniparental Disomy', 'United States National Institutes of Health', 'Universities', 'Variant', 'Washington', 'Work', 'genome sequencing', 'genome wide association study', 'human disease', 'improved', 'interest', 'response', 'theories', 'trait']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2011,500388,-0.004746421791084236
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8653848,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2014,436094,0.016054632801903834
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8461069,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,425454,0.016054632801903834
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8259135,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'public health relevance', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,445075,0.016054632801903834
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8163481,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,459174,0.016054632801903834
"HIGH RESOLUTION ROBOTIC TELEMAMMOGRAPHY SYSTEM Telemammography requires high spatial resolution, the transfer of large          image files and rapid lossless transmission of images.  Current                  teleradiology techniques fail to meet these requirements.  A novel               approach addressing these difficulties, involving robotic control of             image acquisition, optical magnification and unique transmission                 strategies licensed from BellSouth Telecommunications, is proposed.              Phase I goals include prototype development, software design and                 testing, objective characterization of the system and subjective system          evaluation by a board certified radiologist.  Following completion of            Phase I, a Phase II application will be filed.  Phase II will include            optimization of system configuration, extensive testing and evaluation,          both in-house and by consulting radiologists, culminating in clinical            trials at a minimum of three sites.  Following this we expect to file for        FDA clearance of the device.  This research should result in affordable,         high resolution telemammography system that will provide better                  service to remote locations.  With this system, even remote locations            could have access to expertise and rapid diagnosis, affording women              better care in a stressful time.  This novel approach will have                  application to all of teleradiology, especially those specialties requiring      a high spatial resolution.                                                                                                                                        PROPOSED COMMERCIAL APPLICATION:  The proposed project will result               in a telemammography system that allows re-acquisition of high spatial           resolution images by a remote radiologist via a roboticly controlled X-          ray viewer. This system will allow transmission of high quality                  mammographic images from a center to a remote physician or form a                remote hospital or clinic to a center for a more rapid referral and/or           diagnosis. This improved affordable system for the transmission of               radiologic images will have application to teleradiology in general.              n/a",HIGH RESOLUTION ROBOTIC TELEMAMMOGRAPHY SYSTEM,2422962,R43CA075766,"['artificial intelligence', ' biomedical equipment development', ' charge coupled device camera', ' clinical biomedical equipment', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' digital imaging', ' human data', ' image enhancement', ' mammography', ' phantom model', ' robotics', ' telemetry']",NCI,"DIVERSIFIED SCIENTIFIC, INC.",R43,1997,100000,0.04775292673724355
"ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR Imaging detectors for 10 to 150 keV photons have many uses in medical technology, including tumor imaging, SPECT, and radiography. Digital output is particularly useful since it allows image enhancement, analysis, transmission and storage. In Phase I we proposed a new technology that could capture images with 100 microm spatial resolution and 1 keV energy resolution or better. This capability would facilitate entirely new classes of medical diagnostic procedures, particularly for transgenic small animal imaging. Our Phase I work demonstrated the feasibility of this approach. In this Phase II effort, collaborating with Paul Luke at LBNL, we will construct 1 cm thick crossed-strip HPGe detectors having 10 x 10 strips, each 2 mm x 20 mm. We will develop cooled FET preamplifiers having low noise and large bandwidth properties specifically required by this approach. We will also develop analog filtering electronics to condition the detector's novel signals and employ digital pulse processing electronics to acquire these signals at rates up to 10/6 cps. Finally, we will devise procedures to test the detector's linearity and develop processing algorithms to perfect this quality. Phase II will conclude with a working and tested prototype. Phase III will entail primarily production engineering efforts. PROPOSED COMMERCIAL APPLICATION: As an energy resolved digital detector with 100 microm spatial resolution, the proposed detector technology could find many medical applications, including SPECT, energy resolved angiography for small mammals, bone densitometry on rodent bones, and small, hand-held gamma cameras. Non-medical applications would include non-destructive testing, astrophysical gamma imaging, nuclear cleanup uses, and x-ray diffraction detectors.  n/a",ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR,6376544,R44CA075844,"['X ray', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R44,2001,373949,0.0018784772274199767
"ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR Imaging detectors for 10 to 150 keV photons have many uses in medical technology, including tumor imaging, SPECT, and radiography. Digital output is particularly useful since it allows image enhancement, analysis, transmission and storage. In Phase I we proposed a new technology that could capture images with 100 microm spatial resolution and 1 keV energy resolution or better. This capability would facilitate entirely new classes of medical diagnostic procedures, particularly for transgenic small animal imaging. Our Phase I work demonstrated the feasibility of this approach. In this Phase II effort, collaborating with Paul Luke at LBNL, we will construct 1 cm thick crossed-strip HPGe detectors having 10 x 10 strips, each 2 mm x 20 mm. We will develop cooled FET preamplifiers having low noise and large bandwidth properties specifically required by this approach. We will also develop analog filtering electronics to condition the detector's novel signals and employ digital pulse processing electronics to acquire these signals at rates up to 10/6 cps. Finally, we will devise procedures to test the detector's linearity and develop processing algorithms to perfect this quality. Phase II will conclude with a working and tested prototype. Phase III will entail primarily production engineering efforts. PROPOSED COMMERCIAL APPLICATION: As an energy resolved digital detector with 100 microm spatial resolution, the proposed detector technology could find many medical applications, including SPECT, energy resolved angiography for small mammals, bone densitometry on rodent bones, and small, hand-held gamma cameras. Non-medical applications would include non-destructive testing, astrophysical gamma imaging, nuclear cleanup uses, and x-ray diffraction detectors.  n/a",ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR,6211037,R44CA075844,"['X ray', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R44,2000,416478,0.0018784772274199767
"DIGITAL CZT X FOR GAMMA RAY IMAGING DETECTOR Imaging detectors for photons in the 10 to 150 keV energy range have             many uses in medical technology including tumor imaging, SPECT, and              radiography.  Digital output is particularly useful since it allows              image enhancement, analysis, transmission and storage.  An approach is           proposed for developing a new technology, using CdZnTe detector                  material, which would allow images to be obtained with 100 u spatial             resolution and energy resolution of 2% or better. This capability would          facilitate entirely new classes of medical diagnostic procedures. For            example, ""dual energy"" angiography could now be done using a                     polychromatic x-ray source.                                                                                                                                       The present effort will demonstrate the feasibility of the conceptual            approach and create the technological foundation upon which later,               application specific instruments can be built.  Detectors will be                modeled, using Monte Carlo and electron transport, to predict their              signal outputs. These outputs will be compared to measured signals to            validate the models. The models will then be employed to develop signal          processing algorithms which achieve the desired energy and spatial               resolutions.  Finally, electronics will be designed to implement the             algorithms.  In Phase II a working model would be constructed and                tested.                                                                          PROPOSED COMMERCIAL APPLICATION                                                  As an energy resolved digital detector with 100 u spatial resolution,            the proposed detector technology could find many medical applications,           including SPECT, energy resolved angiography for small mammals, bone             densitometry on rodent bones, and small, hand-held gamma cameras.  Non-          medical applications would include non-destructive testing,                      astrophysical gamma imaging, nuclear cleanup uses, and scientific                instruments.                                                                      n/a",DIGITAL CZT X FOR GAMMA RAY IMAGING DETECTOR,2423599,R43CA075844,"['X ray', ' artificial intelligence', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' imaging /visualization /scanning', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R43,1997,100000,0.016557201110299898
"Fusion of Electromagnetic Brain Imaging and fMRI    DESCRIPTION (provided by applicant): Multimodal non-invasive functional brain imaging has made a tremendous impact in improving our understanding of the neural correlates of human behavior, and is now an indispensable tool for systems and cognitive neuroscientists. We propose to develop state-of-the-art multimodal functional imaging fusion algorithms for accurate visualization of the brain's dynamic activity and high spatial and temporal resolution. We propose to develop algorithms that combine complementary high spatial resolution of functional MRI (fMRI) and high-temporal resolution of magnetoencephalography (MEG) and electroencephalography (EEG) data for high-fidelity reconstruction of brain activity. In recent years, our research group has developed a suite of novel and powerful algorithms for MEG/EEG imaging superior to existing benchmark algorithms, and we have compared these results with electrocorticography (ECOG). Specifically, our algorithms can solve for many brain sources, including sources located far from the sensors, in the presence of large interference from unrelated brain sources using fast and robust probabilistic inference techniques. Here, we propose to extend this success in M/EEG inverse algorithms into the domain of multimodal imaging data fusion. Our overall goal here is to ultimately produce robust, high fidelity videos of event-related brain activation at a sub-millimeter and sub-millisecond resolution from noisy MEG/EEG and fMRI data using state-of-the-art machine learning algorithms. Specifically, we propose to extend a powerful new algorithm that we have recently developed, called Champagne, into two new fusion algorithms that combine fMRI, MEG and EEG data in different ways. Performance of both algorithms will first be rigorously evaluated in simulations, including performance comparisons with existing benchmark fusion algorithms. Algorithms will then tested for consistency on four fMRI-MEG+EEG datasets from healthy controls obtained for identical paradigms (auditory, motor, picture naming and verb-generation) and two fMRI-EEG datasets (face and motion perception). Additional validation studies will also be performed on fMRI-MEG/EEG datasets obtained from epilepsy patients and compared to electrocorticography (ECoG). Following successful testing and evaluation, all algorithms developed in this grant proposal, as well as example validation datasets, will be distributed using NUTMEG (nutmeg.berkeley.edu), an open-source software toolbox that we have developed.        Multimodal non-invasive functional brain imaging has made a tremendous impact in improving our understanding of the neural correlates of human behavior, and is now an indispensable tool for systems and cognitive neuroscientists. With the development of appropriate analytical tools, multimodal functional brain imaging is in the process of revolutionizing the diagnosis and treatment of a variety of neurological and psychiatric disorders such as autism, schizophrenia, dementia, and epilepsy that affect tens of millions of Americans.         ",Fusion of Electromagnetic Brain Imaging and fMRI,8320120,R21NS076171,"['Affect', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Autistic Disorder', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cognitive', 'Computer software', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnosis', 'Electrocorticogram', 'Electroencephalography', 'Electromagnetics', 'Epilepsy', 'Event', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Generations', 'Goals', 'Human', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Magnetoencephalography', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Motion Perception', 'Motor', 'Multimodal Imaging', 'Names', 'Nutmeg - dietary', 'Patients', 'Pattern', 'Performance', 'Process', 'Research', 'Resolution', 'Scalp structure', 'Schizophrenia', 'Signal Transduction', 'Source', 'Specific qualifier value', 'Surface', 'Techniques', 'Testing', 'Time', 'Validation', 'Variant', 'analytical tool', 'base', 'blood oxygen level dependent', 'cognitive system', 'evaluation/testing', 'face perception', 'foot', 'hemodynamics', 'imaging modality', 'improved', 'magnetic field', 'millimeter', 'millisecond', 'nervous system disorder', 'novel', 'open source', 'reconstruction', 'relating to nervous system', 'sensor', 'simulation', 'spatiotemporal', 'success', 'tool', 'validation studies']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2012,193125,-0.007786233822180464
"Molecular Mechanisms of Social Behavior    DESCRIPTION (provided by applicant): The goal of this project to fully understand the genetics of certain inherited behaviors segregating in specific strains of silver foxes. The range of behaviors in these foxes has significant parallels to that of normal and disordered patterns of human sociability. The proposed research will characterize the genetic loci determining fox behavioral phenotypes to yield insights into the genetics of social behavior and its underlying molecular mechanisms, not only in foxes, but in other mammals, including humans. In previous studies, specific strains of silver fox (Vulpes vulpes) were developed, at the Russian Institute of Cytology and Genetics (ICG), that exhibit extremely friendly behavior towards humans, in contrast to their wild-type ancestors that resist human contact. The current proposal is a joint research project between scientists at Cornell University, ICG, and the University of Utah, to define the molecular genetic mechanisms underlying these different behaviors. Fox behavioral phenotypes have been defined using principal-components analysis. Genetic loci underlying these behavioral phenotypes have been mapped in powerful sets of fox backcross pedigrees using the newly developed meiotic linkage map of the fox genome. These identified quantitative trait loci will be validated in extended sets of highly informative experimental pedigrees. Combined linkage and linkage disequilibrium mapping will be applied to define the critical regions of the fox genome in which quantitative trait loci have been identified, and identify potential candidate genes. The effect of identified loci on behavior will be determined in experimental pedigrees using marker assisted selection. The identification of genes and loci influencing social behavior in foxes is anticipated to provide new insights into, and candidate genes for human disorders of social behavior. Furthermore, such a well- established large animal model, intermediate between rodents and primates in biological complexity, would then offer opportunities to investigate potential therapies for such human disorders as autism, schizophrenia, anxiety, depression, personality disorders, panic disorder and other traits.           n/a",Molecular Mechanisms of Social Behavior,7478703,R01MH077811,"['Academy', 'Animal Model', 'Anxiety', 'Autistic Disorder', 'Backcrossings', 'Behavior', 'Behavior Control', 'Behavior Disorders', 'Behavioral', 'Biological', 'Breeding', 'Candidate Disease Gene', 'Canis familiaris', 'Chromosome Mapping', 'Classification', 'Collaborations', 'Condition', 'Cytology', 'Data', 'Development', 'Disease', 'Etiology', 'Exhibits', 'Founder Generation', 'Foxes', 'Functional disorder', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Haplotypes', 'Human', 'Infant', 'Inherited', 'Institutes', 'Joints', 'Laboratories', 'Linkage Disequilibrium', 'Linkage Disequilibrium Mapping', 'Mammals', 'Maps', 'Measurable', 'Measures', 'Meiosis', 'Mental Depression', 'Methods', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Panic Disorder', 'Pattern', 'Personality Disorders', 'Phenotype', 'Pilot Projects', 'Positioning Attribute', 'Primates', 'Principal Component Analysis', 'Quantitative Trait Loci', 'Range', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rodent', 'Schizophrenia', 'Science', 'Scientist', 'Silver', 'Social Behavior', 'Social Behavior Disorders', 'Social Interaction', 'Staging', 'Testing', 'Universities', 'Utah', 'Vulpes', 'genetic pedigree', 'insight', 'novel', 'professor', 'programs', 'tool', 'trait']",NIMH,CORNELL UNIVERSITY,R01,2008,325800,0.021752798646943974
"Molecular Mechanisms of Social Behavior    DESCRIPTION (provided by applicant): The goal of this project to fully understand the genetics of certain inherited behaviors segregating in specific strains of silver foxes. The range of behaviors in these foxes has significant parallels to that of normal and disordered patterns of human sociability. The proposed research will characterize the genetic loci determining fox behavioral phenotypes to yield insights into the genetics of social behavior and its underlying molecular mechanisms, not only in foxes, but in other mammals, including humans. In previous studies, specific strains of silver fox (Vulpes vulpes) were developed, at the Russian Institute of Cytology and Genetics (ICG), that exhibit extremely friendly behavior towards humans, in contrast to their wild-type ancestors that resist human contact. The current proposal is a joint research project between scientists at Cornell University, ICG, and the University of Utah, to define the molecular genetic mechanisms underlying these different behaviors. Fox behavioral phenotypes have been defined using principal-components analysis. Genetic loci underlying these behavioral phenotypes have been mapped in powerful sets of fox backcross pedigrees using the newly developed meiotic linkage map of the fox genome. These identified quantitative trait loci will be validated in extended sets of highly informative experimental pedigrees. Combined linkage and linkage disequilibrium mapping will be applied to define the critical regions of the fox genome in which quantitative trait loci have been identified, and identify potential candidate genes. The effect of identified loci on behavior will be determined in experimental pedigrees using marker assisted selection. The identification of genes and loci influencing social behavior in foxes is anticipated to provide new insights into, and candidate genes for human disorders of social behavior. Furthermore, such a well- established large animal model, intermediate between rodents and primates in biological complexity, would then offer opportunities to investigate potential therapies for such human disorders as autism, schizophrenia, anxiety, depression, personality disorders, panic disorder and other traits.           n/a",Molecular Mechanisms of Social Behavior,7905174,R01MH077811,"['Academy', 'Animal Model', 'Anxiety', 'Autistic Disorder', 'Backcrossings', 'Behavior', 'Behavior Control', 'Behavior Disorders', 'Behavioral', 'Biological', 'Breeding', 'Candidate Disease Gene', 'Canis familiaris', 'Chromosome Mapping', 'Collaborations', 'Cytology', 'Data', 'Development', 'Disease', 'Etiology', 'Exhibits', 'Founder Generation', 'Foxes', 'Functional disorder', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Haplotypes', 'Human', 'Infant', 'Inherited', 'Institutes', 'Joints', 'Laboratories', 'Linkage Disequilibrium', 'Linkage Disequilibrium Mapping', 'Mammals', 'Maps', 'Measurable', 'Measures', 'Meiosis', 'Mental Depression', 'Methods', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Panic Disorder', 'Pattern', 'Personality Disorders', 'Phenotype', 'Pilot Projects', 'Positioning Attribute', 'Primates', 'Principal Component Analysis', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rodent', 'Schizophrenia', 'Science', 'Scientist', 'Silver', 'Social Behavior', 'Social Behavior Disorders', 'Social Interaction', 'Staging', 'Testing', 'Universities', 'Utah', 'Vulpes', 'genetic pedigree', 'insight', 'novel', 'professor', 'programs', 'tool', 'trait']",NIMH,CORNELL UNIVERSITY,R01,2010,325800,0.021752798646943974
"Molecular Mechanisms of Social Behavior    DESCRIPTION (provided by applicant): The goal of this project to fully understand the genetics of certain inherited behaviors segregating in specific strains of silver foxes. The range of behaviors in these foxes has significant parallels to that of normal and disordered patterns of human sociability. The proposed research will characterize the genetic loci determining fox behavioral phenotypes to yield insights into the genetics of social behavior and its underlying molecular mechanisms, not only in foxes, but in other mammals, including humans. In previous studies, specific strains of silver fox (Vulpes vulpes) were developed, at the Russian Institute of Cytology and Genetics (ICG), that exhibit extremely friendly behavior towards humans, in contrast to their wild-type ancestors that resist human contact. The current proposal is a joint research project between scientists at Cornell University, ICG, and the University of Utah, to define the molecular genetic mechanisms underlying these different behaviors. Fox behavioral phenotypes have been defined using principal-components analysis. Genetic loci underlying these behavioral phenotypes have been mapped in powerful sets of fox backcross pedigrees using the newly developed meiotic linkage map of the fox genome. These identified quantitative trait loci will be validated in extended sets of highly informative experimental pedigrees. Combined linkage and linkage disequilibrium mapping will be applied to define the critical regions of the fox genome in which quantitative trait loci have been identified, and identify potential candidate genes. The effect of identified loci on behavior will be determined in experimental pedigrees using marker assisted selection. The identification of genes and loci influencing social behavior in foxes is anticipated to provide new insights into, and candidate genes for human disorders of social behavior. Furthermore, such a well- established large animal model, intermediate between rodents and primates in biological complexity, would then offer opportunities to investigate potential therapies for such human disorders as autism, schizophrenia, anxiety, depression, personality disorders, panic disorder and other traits.           n/a",Molecular Mechanisms of Social Behavior,7679147,R01MH077811,"['Academy', 'Animal Model', 'Anxiety', 'Autistic Disorder', 'Backcrossings', 'Behavior', 'Behavior Control', 'Behavior Disorders', 'Behavioral', 'Biological', 'Breeding', 'Candidate Disease Gene', 'Canis familiaris', 'Chromosome Mapping', 'Classification', 'Collaborations', 'Cytology', 'Data', 'Development', 'Disease', 'Etiology', 'Exhibits', 'Founder Generation', 'Foxes', 'Functional disorder', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Haplotypes', 'Human', 'Infant', 'Inherited', 'Institutes', 'Joints', 'Laboratories', 'Linkage Disequilibrium', 'Linkage Disequilibrium Mapping', 'Mammals', 'Maps', 'Measurable', 'Measures', 'Meiosis', 'Methods', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Panic Disorder', 'Pattern', 'Personality Disorders', 'Phenotype', 'Pilot Projects', 'Positioning Attribute', 'Primates', 'Principal Component Analysis', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rodent', 'Schizophrenia', 'Science', 'Scientist', 'Silver', 'Social Behavior', 'Social Behavior Disorders', 'Social Interaction', 'Staging', 'Testing', 'Universities', 'Utah', 'Vulpes', 'depression', 'genetic pedigree', 'insight', 'novel', 'professor', 'programs', 'tool', 'trait']",NIMH,CORNELL UNIVERSITY,R01,2009,325800,0.021752798646943974
"Molecular Mechanisms of Social Behavior    DESCRIPTION (provided by applicant): The goal of this project to fully understand the genetics of certain inherited behaviors segregating in specific strains of silver foxes. The range of behaviors in these foxes has significant parallels to that of normal and disordered patterns of human sociability. The proposed research will characterize the genetic loci determining fox behavioral phenotypes to yield insights into the genetics of social behavior and its underlying molecular mechanisms, not only in foxes, but in other mammals, including humans. In previous studies, specific strains of silver fox (Vulpes vulpes) were developed, at the Russian Institute of Cytology and Genetics (ICG), that exhibit extremely friendly behavior towards humans, in contrast to their wild-type ancestors that resist human contact. The current proposal is a joint research project between scientists at Cornell University, ICG, and the University of Utah, to define the molecular genetic mechanisms underlying these different behaviors. Fox behavioral phenotypes have been defined using principal-components analysis. Genetic loci underlying these behavioral phenotypes have been mapped in powerful sets of fox backcross pedigrees using the newly developed meiotic linkage map of the fox genome. These identified quantitative trait loci will be validated in extended sets of highly informative experimental pedigrees. Combined linkage and linkage disequilibrium mapping will be applied to define the critical regions of the fox genome in which quantitative trait loci have been identified, and identify potential candidate genes. The effect of identified loci on behavior will be determined in experimental pedigrees using marker assisted selection. The identification of genes and loci influencing social behavior in foxes is anticipated to provide new insights into, and candidate genes for human disorders of social behavior. Furthermore, such a well- established large animal model, intermediate between rodents and primates in biological complexity, would then offer opportunities to investigate potential therapies for such human disorders as autism, schizophrenia, anxiety, depression, personality disorders, panic disorder and other traits.           n/a",Molecular Mechanisms of Social Behavior,7322389,R01MH077811,"['Academy', 'Animal Model', 'Anxiety', 'Autistic Disorder', 'Backcrossings', 'Behavior', 'Behavior Control', 'Behavior Disorders', 'Behavioral', 'Biological', 'Breeding', 'Candidate Disease Gene', 'Canis familiaris', 'Chromosome Mapping', 'Classification', 'Collaborations', 'Condition', 'Cytology', 'Data', 'Development', 'Disease', 'Etiology', 'Exhibits', 'Founder Generation', 'Foxes', 'Functional disorder', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Haplotypes', 'Human', 'Infant', 'Inherited', 'Institutes', 'Joints', 'Laboratories', 'Linkage Disequilibrium', 'Linkage Disequilibrium Mapping', 'Mammals', 'Maps', 'Measurable', 'Measures', 'Meiosis', 'Mental Depression', 'Methods', 'Modeling', 'Molecular', 'Molecular Genetics', 'Nature', 'Panic Disorder', 'Pattern', 'Personality Disorders', 'Phenotype', 'Pilot Projects', 'Positioning Attribute', 'Primates', 'Principal Component Analysis', 'Quantitative Trait Loci', 'Range', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rodent', 'Schizophrenia', 'Science', 'Scientist', 'Silver', 'Social Behavior', 'Social Behavior Disorders', 'Social Interaction', 'Staging', 'Testing', 'Universities', 'Utah', 'Vulpes', 'genetic pedigree', 'insight', 'novel', 'professor', 'programs', 'tool', 'trait']",NIMH,CORNELL UNIVERSITY,R01,2007,326238,0.021752798646943974
"Informatics Infrastructure for vector-based neuroanatomical atlases  Abstract The adage: 'all data is spatial' is especially pertinent in the field of neuroscience, since neuronal data must be indexed by the neuroanatomical location of phenomena or entities under study. Brain atlases are very widely used as laboratory tools, being some of the most highly cited publications in science. This proposal seeks to use brain atlases as a method for indexing data from the literature in a neuroinformatics system. This data includes both textual and graphical information, ranging from highly detailed maps constructed from vector- based spatial primitives, histological photographs and drawings, to textual reports of experimental findings in the literature (which we will analyze on a large scale). These data represent a significant scientific investment that are currently locked away in previously published journal articles (and the detailed data-sets and drawings from researchers that were used to write the articles). A prototype that summarizes the last fifteen years' output of one of the world's most prominent neuroanatomy laboratories is immediately available. This project will develop a collaborative environment to enable neuroscientists to use these valuable maps within the community as a whole by contributing data to a shared system with an open-source system (called 'NeuARt II') that permits querying, overlaying, viewing and annotating such data in an integrated manner. We will also use Natural Language Processing (NLP) techniques to index neuroanatomical references in large numbers of journal articles to be accessible within our infrastructure. As an initial text corpus, we over 110,000 documents taken from last 35 years of published information from the primary neuroanatomical literature. We will construct a neuroanatomical interface that conceptually resembles the 'Google Maps' system, permitting users to use an intuitive spatial interface to browse large amounts of biomedical data in spatial register. The proposed infrastructure will also provide new opportunities to compare and synthesize the anatomical components of neuroscience data multiple modalities (physiological, behavioral, clinical, genetic, molecular, etc.).  Narrative Given the scope of the use of neuroanatomical maps from the rat and mouse in the study of neurobiological disease, we expect our research impact scientists working in almost all subfields of the subject. Our collaborators who form the early adopters of this approach are neuroendocrinology researchers studying the mechanisms of stress and anxiety disorders which are estimated to affect 19.1 million people in the USA, costing $42 billion in health care costs per year (source: Anxiety Disorders Association of America). A better understanding of the neuronal mechanisms underlying these disorders could lead to new, effective therapies and treatments.",Informatics Infrastructure for vector-based neuroanatomical atlases,8426190,R01MH079068,"['Accounting', 'Address', 'Affect', 'Americas', 'Anxiety Disorders', 'Atlases', 'Behavioral', 'Brain', 'Chromosome Mapping', 'Clinical', 'Communities', 'Community Outreach', 'Data', 'Data Set', 'Databases', 'Devices', 'Disease', 'Engineering', 'Environment', 'Fluoro-Gold', 'Harvest', 'Health Care Costs', 'Image', 'Informatics', 'Investments', 'Laboratories', 'Lead', 'Lesion', 'Literature', 'Location', 'Maps', 'Methods', 'Modality', 'Molecular Genetics', 'Mus', 'Names', 'Natural Language Processing', 'Neuroanatomy', 'Neurobiology', 'Neuroendocrinology', 'Neurons', 'Neurosciences', 'Online Systems', 'Output', 'Paper', 'Physiological', 'Publications', 'Publishing', 'Rattus', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Semantics', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Tissues', 'Work', 'Writing', 'abstracting', 'base', 'biomedical ontology', 'cost', 'effective therapy', 'indexing', 'journal article', 'neuroinformatics', 'novel', 'open source', 'prototype', 'research study', 'stress disorder', 'text searching', 'tool', 'vector', 'web services']",NIMH,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2013,315672,0.013020099702769513
"Informatics Infrastructure for vector-based neuroanatomical atlases  Abstract The adage: 'all data is spatial' is especially pertinent in the field of neuroscience, since neuronal data must be indexed by the neuroanatomical location of phenomena or entities under study. Brain atlases are very widely used as laboratory tools, being some of the most highly cited publications in science. This proposal seeks to use brain atlases as a method for indexing data from the literature in a neuroinformatics system. This data includes both textual and graphical information, ranging from highly detailed maps constructed from vector- based spatial primitives, histological photographs and drawings, to textual reports of experimental findings in the literature (which we will analyze on a large scale). These data represent a significant scientific investment that are currently locked away in previously published journal articles (and the detailed data-sets and drawings from researchers that were used to write the articles). A prototype that summarizes the last fifteen years' output of one of the world's most prominent neuroanatomy laboratories is immediately available. This project will develop a collaborative environment to enable neuroscientists to use these valuable maps within the community as a whole by contributing data to a shared system with an open-source system (called 'NeuARt II') that permits querying, overlaying, viewing and annotating such data in an integrated manner. We will also use Natural Language Processing (NLP) techniques to index neuroanatomical references in large numbers of journal articles to be accessible within our infrastructure. As an initial text corpus, we over 110,000 documents taken from last 35 years of published information from the primary neuroanatomical literature. We will construct a neuroanatomical interface that conceptually resembles the 'Google Maps' system, permitting users to use an intuitive spatial interface to browse large amounts of biomedical data in spatial register. The proposed infrastructure will also provide new opportunities to compare and synthesize the anatomical components of neuroscience data multiple modalities (physiological, behavioral, clinical, genetic, molecular, etc.).  Narrative Given the scope of the use of neuroanatomical maps from the rat and mouse in the study of neurobiological disease, we expect our research impact scientists working in almost all subfields of the subject. Our collaborators who form the early adopters of this approach are neuroendocrinology researchers studying the mechanisms of stress and anxiety disorders which are estimated to affect 19.1 million people in the USA, costing $42 billion in health care costs per year (source: Anxiety Disorders Association of America). A better understanding of the neuronal mechanisms underlying these disorders could lead to new, effective therapies and treatments.",Informatics Infrastructure for vector-based neuroanatomical atlases,8238371,R01MH079068,"['Accounting', 'Address', 'Affect', 'Americas', 'Anxiety Disorders', 'Atlases', 'Behavioral', 'Brain', 'Chromosome Mapping', 'Clinical', 'Communities', 'Community Outreach', 'Data', 'Data Set', 'Databases', 'Devices', 'Disease', 'Engineering', 'Environment', 'Fluoro-Gold', 'Harvest', 'Health Care Costs', 'Image', 'Informatics', 'Investments', 'Laboratories', 'Lead', 'Lesion', 'Literature', 'Location', 'Maps', 'Methods', 'Modality', 'Molecular Genetics', 'Mus', 'Names', 'Natural Language Processing', 'Neuroanatomy', 'Neurobiology', 'Neuroendocrinology', 'Neurons', 'Neurosciences', 'Online Systems', 'Output', 'Paper', 'Physiological', 'Publications', 'Publishing', 'Rattus', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Semantics', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Tissues', 'Traumatic Stress Disorders', 'Work', 'Writing', 'abstracting', 'base', 'biomedical ontology', 'cost', 'effective therapy', 'indexing', 'journal article', 'neuroinformatics', 'novel', 'open source', 'prototype', 'research study', 'text searching', 'tool', 'vector', 'web services']",NIMH,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2012,326844,0.013020099702769513
"Informatics Infrastructure for vector-based neuroanatomical atlases    DESCRIPTION (provided by applicant):  The adage:  'all data is spatial' is especially pertinent in the field of neuroscience, since neuronal data must be indexed by the neuroanatomical location of phenomena or entities under study.  Brain atlases are very widely used as laboratory tools, being some of the most highly cited publications in science.  This proposal seeks to use brain atlases as a method for indexing data from the literature in a neuroinformatics system.  This data includes both textual and graphical information, ranging from highly detailed maps constructed from vector- based spatial primitives, histological photographs and drawings, to textual reports of experimental findings in the literature (which we will analyze on a large scale).  These data represent a significant scientific investment that are currently locked away in previously published journal articles (and the detailed data-sets and drawings from researchers that were used to write the articles).  A prototype that summarizes the last fifteen years' output of one of the world's most prominent neuroanatomy laboratories is immediately available.  This project will develop a collaborative environment to enable neuroscientists to use these valuable maps within the community as a whole by contributing data to a shared system with an open-source system (called 'NeuARt II') that permits querying, overlaying, viewing and annotating such data in an integrated manner.  We will also use Natural Language Processing (NLP) techniques to index neuroanatomical references in large numbers of journal articles to be accessible within our infrastructure.  As an initial text corpus, we over 110,000 documents taken from last 35 years of published information from the primary neuroanatomical literature.  We will construct a neuroanatomical interface that conceptually resembles the 'Google Maps' system, permitting users to use an intuitive spatial interface to browse large amounts of biomedical data in spatial register.  The proposed infrastructure will also provide new opportunities to compare and synthesize the anatomical components of neuroscience data multiple modalities (physiological, behavioral, clinical, genetic, molecular, etc.).PUBLIC HEALTH RELEVANCE:  Given the scope of the use of neuroanatomical maps from the rat and mouse in the study of neurobiological disease, we expect our research impact scientists working in almost all subfields of the subject.  Our collaborators who form the early adopters of this approach are neuroendocrinology researchers studying the mechanisms of stress and anxiety disorders which are estimated to affect 19.1 million people in the USA, costing $42 billion in health care costs per year (source:  Anxiety Disorders Association of America).  A better understanding of the neuronal mechanisms underlying these disorders could lead to new, effective therapies and treatments.        Narrative Given the scope of the use of neuroanatomical maps from the rat and mouse in the study of neurobiological disease, we expect our research impact scientists working in almost all subfields of the subject. Our collaborators who form the early adopters of this approach are neuroendocrinology researchers studying the mechanisms of stress and anxiety disorders which are estimated to affect 19.1 million people in the USA, costing $42 billion in health care costs per year (source: Anxiety Disorders Association of America). A better understanding of the neuronal mechanisms underlying these disorders could lead to new, effective therapies and treatments.",Informatics Infrastructure for vector-based neuroanatomical atlases,8044673,R01MH079068,"['Accounting', 'Address', 'Affect', 'Americas', 'Anxiety Disorders', 'Atlases', 'Behavioral', 'Brain', 'Chromosome Mapping', 'Clinical', 'Communities', 'Community Outreach', 'Data', 'Data Set', 'Databases', 'Devices', 'Disease', 'Engineering', 'Environment', 'Fluoro-Gold', 'Harvest', 'Health', 'Health Care Costs', 'Image', 'Informatics', 'Investments', 'Laboratories', 'Lead', 'Lesion', 'Literature', 'Location', 'Maps', 'Methods', 'Modality', 'Molecular Genetics', 'Mus', 'Names', 'Natural Language Processing', 'Neuroanatomy', 'Neurobiology', 'Neuroendocrinology', 'Neurons', 'Neurosciences', 'Online Systems', 'Output', 'Paper', 'Physiological', 'Publications', 'Publishing', 'Rattus', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Semantics', 'Source', 'Structure', 'System', 'Techniques', 'Text', 'Tissues', 'Traumatic Stress Disorders', 'Work', 'Writing', 'base', 'biomedical ontology', 'cost', 'effective therapy', 'indexing', 'journal article', 'neuroinformatics', 'novel', 'open source', 'prototype', 'research study', 'text searching', 'tool', 'vector', 'web services']",NIMH,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2011,324859,0.016661389044324328
"Informatics Infrastructure for vector-based neuroanatomical atlases    DESCRIPTION (provided by applicant):  The adage:  'all data is spatial' is especially pertinent in the field of neuroscience, since neuronal data must be indexed by the neuroanatomical location of phenomena or entities under study.  Brain atlases are very widely used as laboratory tools, being some of the most highly cited publications in science.  This proposal seeks to use brain atlases as a method for indexing data from the literature in a neuroinformatics system.  This data includes both textual and graphical information, ranging from highly detailed maps constructed from vector- based spatial primitives, histological photographs and drawings, to textual reports of experimental findings in the literature (which we will analyze on a large scale).  These data represent a significant scientific investment that are currently locked away in previously published journal articles (and the detailed data-sets and drawings from researchers that were used to write the articles).  A prototype that summarizes the last fifteen years' output of one of the world's most prominent neuroanatomy laboratories is immediately available.  This project will develop a collaborative environment to enable neuroscientists to use these valuable maps within the community as a whole by contributing data to a shared system with an open-source system (called 'NeuARt II') that permits querying, overlaying, viewing and annotating such data in an integrated manner.  We will also use Natural Language Processing (NLP) techniques to index neuroanatomical references in large numbers of journal articles to be accessible within our infrastructure.  As an initial text corpus, we over 110,000 documents taken from last 35 years of published information from the primary neuroanatomical literature.  We will construct a neuroanatomical interface that conceptually resembles the 'Google Maps' system, permitting users to use an intuitive spatial interface to browse large amounts of biomedical data in spatial register.  The proposed infrastructure will also provide new opportunities to compare and synthesize the anatomical components of neuroscience data multiple modalities (physiological, behavioral, clinical, genetic, molecular, etc.).PUBLIC HEALTH RELEVANCE:  Given the scope of the use of neuroanatomical maps from the rat and mouse in the study of neurobiological disease, we expect our research impact scientists working in almost all subfields of the subject.  Our collaborators who form the early adopters of this approach are neuroendocrinology researchers studying the mechanisms of stress and anxiety disorders which are estimated to affect 19.1 million people in the USA, costing $42 billion in health care costs per year (source:  Anxiety Disorders Association of America).  A better understanding of the neuronal mechanisms underlying these disorders could lead to new, effective therapies and treatments.        Narrative Given the scope of the use of neuroanatomical maps from the rat and mouse in the study of neurobiological disease, we expect our research impact scientists working in almost all subfields of the subject. Our collaborators who form the early adopters of this approach are neuroendocrinology researchers studying the mechanisms of stress and anxiety disorders which are estimated to affect 19.1 million people in the USA, costing $42 billion in health care costs per year (source: Anxiety Disorders Association of America). A better understanding of the neuronal mechanisms underlying these disorders could lead to new, effective therapies and treatments.",Informatics Infrastructure for vector-based neuroanatomical atlases,7846105,R01MH079068,"['Accounting', 'Address', 'Affect', 'Americas', 'Anxiety Disorders', 'Atlases', 'Behavioral', 'Brain', 'Chromosome Mapping', 'Clinical', 'Communities', 'Community Outreach', 'Data', 'Data Set', 'Databases', 'Devices', 'Disease', 'Engineering', 'Environment', 'Fluoro-Gold', 'Harvest', 'Health Care Costs', 'Image', 'Informatics', 'Internet', 'Investments', 'Laboratories', 'Lead', 'Lesion', 'Literature', 'Location', 'Maps', 'Methods', 'Modality', 'Molecular Genetics', 'Mus', 'Names', 'Natural Language Processing', 'Neuroanatomy', 'Neurobiology', 'Neuroendocrinology', 'Neurons', 'Neurosciences', 'Online Systems', 'Output', 'Paper', 'Physiological', 'Publications', 'Publishing', 'Rattus', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Semantics', 'Services', 'Source', 'Stress', 'Structure', 'System', 'Techniques', 'Text', 'Tissues', 'Work', 'Writing', 'base', 'biomedical ontology', 'cost', 'effective therapy', 'indexing', 'journal article', 'neuroinformatics', 'novel', 'open source', 'prototype', 'public health relevance', 'research study', 'text searching', 'tool', 'vector']",NIMH,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2010,326254,0.016661389044324328
"Informatics Infrastructure for vector-based neuroanatomical atlases    DESCRIPTION (provided by applicant):  The adage:  'all data is spatial' is especially pertinent in the field of neuroscience, since neuronal data must be indexed by the neuroanatomical location of phenomena or entities under study.  Brain atlases are very widely used as laboratory tools, being some of the most highly cited publications in science.  This proposal seeks to use brain atlases as a method for indexing data from the literature in a neuroinformatics system.  This data includes both textual and graphical information, ranging from highly detailed maps constructed from vector- based spatial primitives, histological photographs and drawings, to textual reports of experimental findings in the literature (which we will analyze on a large scale).  These data represent a significant scientific investment that are currently locked away in previously published journal articles (and the detailed data-sets and drawings from researchers that were used to write the articles).  A prototype that summarizes the last fifteen years' output of one of the world's most prominent neuroanatomy laboratories is immediately available.  This project will develop a collaborative environment to enable neuroscientists to use these valuable maps within the community as a whole by contributing data to a shared system with an open-source system (called 'NeuARt II') that permits querying, overlaying, viewing and annotating such data in an integrated manner.  We will also use Natural Language Processing (NLP) techniques to index neuroanatomical references in large numbers of journal articles to be accessible within our infrastructure.  As an initial text corpus, we over 110,000 documents taken from last 35 years of published information from the primary neuroanatomical literature.  We will construct a neuroanatomical interface that conceptually resembles the 'Google Maps' system, permitting users to use an intuitive spatial interface to browse large amounts of biomedical data in spatial register.  The proposed infrastructure will also provide new opportunities to compare and synthesize the anatomical components of neuroscience data multiple modalities (physiological, behavioral, clinical, genetic, molecular, etc.).PUBLIC HEALTH RELEVANCE:  Given the scope of the use of neuroanatomical maps from the rat and mouse in the study of neurobiological disease, we expect our research impact scientists working in almost all subfields of the subject.  Our collaborators who form the early adopters of this approach are neuroendocrinology researchers studying the mechanisms of stress and anxiety disorders which are estimated to affect 19.1 million people in the USA, costing $42 billion in health care costs per year (source:  Anxiety Disorders Association of America).  A better understanding of the neuronal mechanisms underlying these disorders could lead to new, effective therapies and treatments.        Narrative Given the scope of the use of neuroanatomical maps from the rat and mouse in the study of neurobiological disease, we expect our research impact scientists working in almost all subfields of the subject. Our collaborators who form the early adopters of this approach are neuroendocrinology researchers studying the mechanisms of stress and anxiety disorders which are estimated to affect 19.1 million people in the USA, costing $42 billion in health care costs per year (source: Anxiety Disorders Association of America). A better understanding of the neuronal mechanisms underlying these disorders could lead to new, effective therapies and treatments.",Informatics Infrastructure for vector-based neuroanatomical atlases,7582189,R01MH079068,"['Accounting', 'Address', 'Affect', 'Americas', 'Anxiety Disorders', 'Atlases', 'Behavioral', 'Body of uterus', 'Brain', 'Chromosome Mapping', 'Clinical', 'Communities', 'Community Outreach', 'Data', 'Data Set', 'Databases', 'Devices', 'Disease', 'Engineering', 'Environment', 'Fluoro-Gold', 'Harvest', 'Health Care Costs', 'Image', 'Informatics', 'Internet', 'Investments', 'Laboratories', 'Lead', 'Lesion', 'Literature', 'Location', 'Maps', 'Methods', 'Modality', 'Molecular Genetics', 'Mus', 'Names', 'Natural Language Processing', 'Neuroanatomy', 'Neurobiology', 'Neuroendocrinology', 'Neurons', 'Neurosciences', 'Online Systems', 'Output', 'Paper', 'Physiological', 'Publications', 'Publishing', 'Rattus', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Semantics', 'Services', 'Source', 'Stress', 'Structure', 'System', 'Techniques', 'Text', 'Tissues', 'Work', 'Writing', 'base', 'biomedical ontology', 'cost', 'effective therapy', 'indexing', 'journal article', 'neuroinformatics', 'novel', 'open source', 'prototype', 'public health relevance', 'research study', 'text searching', 'tool', 'vector']",NIMH,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,312453,0.016661389044324328
"Support Vector Machine modeling software for improving RNAi efficacy prediction    DESCRIPTION (provided by applicant): Title Support vector machines predict sequence ~ activity relationships in RNA interference: Project Summary/Abstract: Support Vector Machines (SVMs) are a group of algorithms in supervised machine learning that are able to build classification or regression models on training data such that these models can be used to predict information not seen during model construction. RNA interference (RNAi) is the property of small (20 to 23 bases) RNA sequences that with the help of the RNA Induced Silencing Complex (RISC) enable the catalytic cleavage of target RNA sequences and the knockdown of the expression level of the target gene. The steps involved in loading and associating an RNAi sequences into an active RISC are several in addition to the multi-factorial variation in biochemical activities of RNAi sequences once in an active RISC. Finding the relevant biochemical features that associate with these quantifiable measures of RNAi can allow i) better predictive models of RNAi and RNAi-like (e.g. microRNAs) activities and ii) a better understanding of the relevant biochemical properties since presumably less relevant properties should not increase the predictive abilities of models containing those properties. We have developed a novel feature mapping method, referred to as Binary Base mapping, that improves the ability of a SVM to predict RNAi activities when compared to 2 previous methods, refered to as Unit Vector and N-gram mapping. Alone, the Binary Base SVM method has greater predictive accuracy than a recently published neural network machine learning method, on the same training and testing data. Several additional mapping methods can be envisioned, including methods that incorporate RNAi thermodynamics, secondary structure or measures of entropy, and whether alone or in combination these mappings of sequence to vector space for SVM model construction lead to better predictive models or understanding of RNAi biochemistry is unknown. We are requesting funding for the specific aims of: i) testing whether the Binary Base method can be used to further dissect and identify relevant biochemical feature associated with RNAi activity, ii) analyzing what additional vector mapping methods lead to predictive models with increased accuracy or greater understanding of relevant biochemical properties, and iii) investigating the distribution of sites within and among target mRNA genes where predictive SVM models identify high versus low activity. Title Support vector machines predict sequence ~ activity relationships in RNA interference: Project Narrative: Small non-coding RNAs (sncRNAs) have regulatory influence in human development and disease and better understanding how these molecules function involves the development of predictive models. Machine learning methods such as Support Vector Machines (SVMs) are 1 way to develop predictive models for these small RNA sequences and the incorporation of novel mapping methods in SVMs leads to model improvement. Finding and combining additional sequence mapping methods can lead to better predictive models for RNA interference activity as well as related processes such as microRNA activity, chemical modification of RNAi and RNAi stability or RNAi toxicity; further improving the understanding of how scnRNAs function and how they might be regulated.          n/a",Support Vector Machine modeling software for improving RNAi efficacy prediction,7157547,R43GM079132,"['RNA interference', 'biotechnology', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'gene targeting', 'genetic mapping', 'mathematical model', 'messenger RNA', 'method development', 'molecular genetics', 'nucleic acid sequence', 'nucleic acid structure', 'thermodynamics']",NIGMS,"INTEGRATED DNA TECHNOLOGIES, INC.",R43,2006,97773,-0.011441994213301892
"Genetical Genomics Analysis Software    DESCRIPTION (provided by applicant): Response to drug treatment is thought dependent upon genotype for many modern therapies. Knowledge of how each genotype responds to a particular therapy is bene?cial only in that one can identify portions of the population which cannot reap the benefits of said treatment. A better course of action is to identify not only which genotype responds, or not, to a particular therapy, but to identify which region of the genome is responding, or not, and how. We believe that this information will lead to new drug targets and better therapies that benefit a larger portion of the population. The goal of this proposal is to provide a suite of software tools for genetic and genomic scientists performing gene mapping experiments with genomic data as the response variable. These tools will ideally provide functionality for 1) detecting polymorphic regions of the genome that con- fer transcript expression differences, 2) identify polymorphic regions of the genome that impart expression differences in genes located elsewhere in the genome, and 3) detecting interactions between loci that may correspond to epistatic effects on transcription. Some software already exists to perform each of these tasks as distinct independent solutions. This proposal intends to produce an integrated solution, S+EQTL (S-PLUS for expression quantitative trait loci mapping), that utilizes the power of S-PLUS and both incorporates and extends the functionality of an exist- ing genetics suite. By providing scientists with an integrated set of tools for genomics experiments with a genetic component, more productive time can be spent interpreting the results rather than transforming data into different formats to be processed by multiple software analysis packages. This software should also address one of the most dif?cult aspects of genetical genomics exper- iments, the so called curse of dimensionality. As the genomics community continues gathering knowledge of transcripts in various organisms, the arrays that interrogate transcript abundance only grow larger in the number of transcript species included. In the absence of tools designed for this purpose, the research scientist is left with the option of either focusing on a narrow set of previously known genes or performing a grid-wise search on all genes in the array. The former is not interesting as these genes are likely well studied and may provide little novel insight. The latter is computationally demanding and may not be possible on the new, larger arrays. A recent publication presents a novel solution that may be enhanced to gain both power and scale using Bayesian methodology. Knowledge of how each genotype responds to a particular drug therapy is beneficial only in that one can identify portions of the population which cannot reap the benefits of said treatment. A better course of action is to identify not only which genotype responds, or not, to a particular therapy, but to identify which region of the genome is responding, or not, and how. We believe that the development of analytic tools for gene mapping experiments to identify this information will lead to new drug targets and better therapies that benefit a larger portion of the population.          n/a",Genetical Genomics Analysis Software,7216142,R43GM079852,"['Address', 'Air', 'Algorithms', 'Animal Genetics', 'Anus', 'Arizona', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biometry', 'Biotechnology', 'Bovine Spongiform Encephalopathy', 'Cations', 'Cattle', 'Chromosome Mapping', 'Code', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Con-fer', 'Data', 'Data Analyses', 'Data Set', 'Department of Defense', 'Depth', 'Development', 'Diagnostic', 'Disease', 'Disease regression', 'Doctor of Philosophy', 'Drug Delivery Systems', 'Educational process of instructing', 'Educational workshop', 'Employment', 'Ensure', 'Exons', 'Family suidae', 'Fatty acid glycerol esters', 'Foundations', 'Gene Combinations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Research', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Government', 'Government Agencies', 'Graph', 'Imagery', 'Individual', 'Industry', 'Institution', 'International', 'Investments', 'Iowa', 'Knowledge', 'Lead', 'Left', 'Libraries', 'Literature', 'Liver', 'Location', 'Machine Learning', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Molecular Genetics', 'Mus', 'Nebraska', 'North Carolina', 'Numbers', 'Obese Mice', 'Obesity', 'Organism', 'Output', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Pharmaceutical Services', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Process', 'Publications', 'Purpose', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Single Nucleotide Polymorphism', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Tools', 'Solutions', 'Standards of Weights and Measures', 'Sus scrofa', 'Techniques', 'Telecommunications', 'Testing', 'Therapeutic', 'Thermogenesis', 'Thinking', 'Time', 'Time Series Analysis', 'Tissues', 'Training', 'Transcript', 'Treatment Protocols', 'United States National Aeronautics and Space Administration', 'United States National Institutes of Health', 'Universities', 'Washington', 'Work', 'animal breeding', 'base', 'design', 'experience', 'expression vector', 'genetic pedigree', 'hazard', 'improved', 'insight', 'interest', 'lecturer', 'novel', 'professor', 'programs', 'prototype', 'research and development', 'research study', 'response', 'skills', 'software development', 'success', 'tool']",NIGMS,INSIGHTFUL CORPORATION,R43,2007,101707,0.017240890669844192
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,10021685,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'algorithm development', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'data quality', 'deep learning', 'denoising', 'detector', 'drug action', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,344862,0.03405367137436783
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,9886087,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Quality', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Drug effect disorder', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'deep learning', 'denoising', 'detector', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,344862,0.03405367137436783
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,8131721,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative genomics', 'computerized data processing', 'cost effective', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2011,238085,-0.030325130466904555
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7910601,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative genomics', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2010,240491,-0.030325130466904555
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7669377,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2009,240426,-0.030325130466904555
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7483692,SC1AI080579,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Endopeptidases', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIAID,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2008,242920,-0.030325130466904555
"Systems Biology of Plasmodium falciparum: Building and Exploring Network Models    DESCRIPTION (provided by applicant):  There is an urgent need for novel anti-malaria interventions, due to the growing resistance of Plasmodium parasites to available drugs. The long-term objective of our research is to identify potential drug or vaccine targets using an efficient and cost-effective data-mining approach. This proposed study is aimed at the identification of biological networks as the first step toward a systems-level understanding of parasite biology. Compared to functional genomics, which requires a priori information about the identity or function of targets, a systems-level understanding of parasite biology will allow us to identify targets based on their key roles in networks. Specific aim 1 focuses on the harvest of data relevant to three gene families: the proteases, transporters, and transcription factors that are essential components in cellular networks for parasite growth and infection. Our project will encompass genomic data, expression data, and data derived from other high throughput experiments and bioinformatic and statistical analyses. Specific aim 2 focuses on the integration and encapsulation of these data in the form of network models. The models will be inferred using probabilistic graphical methods drawn from the field of engineering. Specific aim 3 focuses on the exploration of these models, particularly in the light of data from wet lab gene mapping and drug resistance experiments. Our ""biological maps"" will enable the visualization of evolutionary forces driving changes in the parasite's phenotype and should allow us to identify network design weaknesses in the parasite--potential vulnerabilities that could result in new malarial control strategies.           n/a",Systems Biology of Plasmodium falciparum: Building and Exploring Network Models,7287978,SC1GM081068,"['Animal Model', 'Antimalarials', 'Area', 'Artificial Intelligence', 'Be++ element', 'Beryllium', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle Regulation', 'Cell physiology', 'Chromosome Mapping', 'Complex', 'Data', 'Data Set', 'Development', 'Digestion', 'Discipline', 'Drug resistance', 'Electrical Engineering', 'Elements', 'Endopeptidases', 'Engineering', 'Family', 'Gene Family', 'Gene Proteins', 'Genes', 'Genomics', 'Growth', 'Harvest', 'Hemoglobin', 'Imagery', 'Immune', 'Infection', 'Intervention', 'Life Cycle Stages', 'Light', 'Location', 'Malaria', 'Maps', 'Mediating', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Open Reading Frames', 'Parasites', 'Pattern', 'Peptide Hydrolases', 'Pharmaceutical Preparations', 'Phenotype', 'Plant Roots', 'Plasmodium', 'Plasmodium falciparum', 'Prevalence', 'Process', 'Property', 'Proteins', 'Proteomics', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Rupture', 'Signal Transduction', 'Specialist', 'Staging', 'Statistical Models', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Therapeutic', 'Transcription Factor 3', 'Vaccines', 'Work', 'base', 'comparative', 'computerized data processing', 'cost', 'data integration', 'data mining', 'design', 'driving force', 'experience', 'functional genomics', 'insight', 'member', 'mortality', 'network models', 'novel', 'pressure', 'programs', 'prototype', 'quantum', 'research study', 'response', 'stem', 'theories', 'trafficking', 'transcription factor', 'transcriptomics']",NIGMS,UNIVERSITY OF TEXAS SAN ANTONIO,SC1,2007,247625,-0.030325130466904555
"High-Accuracy Protein Models Derived from Lower Resolution Data An outstanding international interdisciplinary team has been assembled that will bring a broad variety of expertise to bear on protein model building, bringing together researchers from chemistry, physics, computer science, mathematics, structural biology, and bioinformatics. The expertise ranges from quantum chemistry to machine learning, and from datamining to high performance computing. Input from collaborating NMR and crystallographers will be essential for validating the protein models. Improving abilities to model proteins can impact public health in important ways by enhancing our basic understanding of protein behavior and by facilitating a more efficient selection of protein targets for drug design. The overall goal is to improve a wide range of protein modeling approaches, both by developing new approaches, and by combining those previously been developed. The specific aims are to: 1) Improve existing comparative (homology) modeling and 2) Improve models obtained by fold-recognition and ab initio procedures to make them useful for molecular replacement. There will be some new methods development. Efforts are in four areas - databases, interaction potentials, conformational sampling, and optimization for combining approaches. We will develop ways to include constraints mined from sub-atomic resolution protein structures using a new HIRES Database (to include structures with resolution < 0.85 A). These will include a structure fragment database, as well as short-range distance distributions. These data can be used to compare modeled structures against the collected data. Uses of the high resolution data will ilclude selecting higher quality fragments to replace poor quality segments in the models, for mining interaction potentials, and as a source of a variety of other high quality information regarding protein structures. Better assessments of protein structural models will be developed, including the assessment of the quality of individual segments within a protein structure; the new metrics developed will be used for assessing the quality of computer-built models, crystal structures and NMR structures, and provide indicators of the expected quality of whole protein models as well as of its segments. New ways to sample protein motions will be pursued. Combining diverse methods will lead to significant gains in the computer modeling of protein structures. Extensive testing and validation will be carried out at each stage and in each part of the project to ensure large gains in model accuracy. n/a",High-Accuracy Protein Models Derived from Lower Resolution Data,7683856,R01GM081680,"['Amino Acid Sequence', 'Area', 'Arts', 'Behavior', 'Bioinformatics', 'Biology', 'CASP6 gene', 'Carbon', 'Categories', 'Cellular biology', 'Cereals', 'Chemistry', 'Code', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer Simulation', 'Computers', 'Consensus', 'Crystallography', 'Data', 'Databases', 'Detection', 'Development', 'Drug Design', 'Ensure', 'Enzymes', 'Evaluation', 'Foundations', 'Future', 'Generations', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Guidelines', 'High Performance Computing', 'Homology Modeling', 'Individual', 'Institutes', 'International', 'Investments', 'Iowa', 'Laboratories', 'Lead', 'Letters', 'Machine Learning', 'Mathematics', 'Medal', 'Methodology', 'Methods', 'Metric', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Conformation', 'Molecular Models', 'Monsters', 'Motion', 'Organism', 'Peptide Sequence Determination', 'Performance', 'Pharmaceutical Preparations', 'Physics', 'Polishes', 'Principal Investigator', 'Procedures', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Sampling', 'Solutions', 'Source', 'Staging', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Torsion', 'Universities', 'Ursidae Family', 'Validation', 'Variant', 'Wisconsin', 'Work', 'base', 'comparative', 'computer science', 'data mining', 'database structure', 'experience', 'improved', 'insertion/deletion mutation', 'member', 'method development', 'molecular mechanics', 'molecular modeling', 'network models', 'novel strategies', 'numb protein', 'programs', 'protein structure', 'protein structure prediction', 'quantum', 'quantum chemistry', 'reconstruction', 'research study', 'restraint', 'scaffold', 'simulation', 'software development', 'structural biology', 'theories', 'three dimensional structure', 'tool', 'web site']",NIGMS,IOWA STATE UNIVERSITY,R01,2009,231392,0.04126214001942315
"High-Accuracy Protein Models Derived from Lower Resolution Data An outstanding international interdisciplinary team has been assembled that will bring a broad variety of expertise to bear on protein model building, bringing together researchers from chemistry, physics, computer science, mathematics, structural biology, and bioinformatics. The expertise ranges from quantum chemistry to machine learning, and from datamining to high performance computing. Input from collaborating NMR and crystallographers will be essential for validating the protein models. Improving abilities to model proteins can impact public health in important ways by enhancing our basic understanding of protein behavior and by facilitating a more efficient selection of protein targets for drug design. The overall goal is to improve a wide range of protein modeling approaches, both by developing new approaches, and by combining those previously been developed. The specific aims are to: 1) Improve existing comparative (homology) modeling and 2) Improve models obtained by fold-recognition and ab initio procedures to make them useful for molecular replacement. There will be some new methods development. Efforts are in four areas - databases, interaction potentials, conformational sampling, and optimization for combining approaches. We will develop ways to include constraints mined from sub-atomic resolution protein structures using a new HIRES Database (to include structures with resolution < 0.85 A). These will include a structure fragment database, as well as short-range distance distributions. These data can be used to compare modeled structures against the collected data. Uses of the high resolution data will ilclude selecting higher quality fragments to replace poor quality segments in the models, for mining interaction potentials, and as a source of a variety of other high quality information regarding protein structures. Better assessments of protein structural models will be developed, including the assessment of the quality of individual segments within a protein structure; the new metrics developed will be used for assessing the quality of computer-built models, crystal structures and NMR structures, and provide indicators of the expected quality of whole protein models as well as of its segments. New ways to sample protein motions will be pursued. Combining diverse methods will lead to significant gains in the computer modeling of protein structures. Extensive testing and validation will be carried out at each stage and in each part of the project to ensure large gains in model accuracy. n/a",High-Accuracy Protein Models Derived from Lower Resolution Data,7931242,R01GM081680,"['Amino Acid Sequence', 'Area', 'Arts', 'Behavior', 'Bioinformatics', 'Biology', 'CASP6 gene', 'Carbon', 'Categories', 'Cellular biology', 'Cereals', 'Chemistry', 'Code', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer Simulation', 'Computers', 'Consensus', 'Crystallography', 'Data', 'Databases', 'Detection', 'Development', 'Drug Design', 'Ensure', 'Enzymes', 'Evaluation', 'Foundations', 'Future', 'Generations', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Guidelines', 'High Performance Computing', 'Homology Modeling', 'Individual', 'Institutes', 'International', 'Investments', 'Iowa', 'Laboratories', 'Lead', 'Letters', 'Machine Learning', 'Mathematics', 'Medal', 'Methodology', 'Methods', 'Metric', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Conformation', 'Molecular Models', 'Monsters', 'Motion', 'Organism', 'Peptide Sequence Determination', 'Performance', 'Pharmaceutical Preparations', 'Physics', 'Polishes', 'Principal Investigator', 'Procedures', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Sampling', 'Solutions', 'Source', 'Staging', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Torsion', 'Universities', 'Ursidae Family', 'Validation', 'Variant', 'Wisconsin', 'Work', 'base', 'comparative', 'computer science', 'data mining', 'database structure', 'experience', 'improved', 'insertion/deletion mutation', 'member', 'method development', 'molecular mechanics', 'molecular modeling', 'network models', 'novel strategies', 'numb protein', 'programs', 'protein structure', 'protein structure prediction', 'quantum', 'quantum chemistry', 'reconstruction', 'research study', 'restraint', 'scaffold', 'simulation', 'software development', 'structural biology', 'theories', 'three dimensional structure', 'tool', 'web site']",NIGMS,IOWA STATE UNIVERSITY,R01,2009,52007,0.04126214001942315
"High-Accuracy Protein Models Derived from Lower Resolution Data An outstanding international interdisciplinary team has been assembled that will bring a broad variety of expertise to bear on protein model building, bringing together researchers from chemistry, physics, computer science, mathematics, structural biology, and bioinformatics. The expertise ranges from quantum chemistry to machine learning, and from datamining to high performance computing. Input from collaborating NMR and crystallographers will be essential for validating the protein models. Improving abilities to model proteins can impact public health in important ways by enhancing our basic understanding of protein behavior and by facilitating a more efficient selection of protein targets for drug design. The overall goal is to improve a wide range of protein modeling approaches, both by developing new approaches, and by combining those previously been developed. The specific aims are to: 1) Improve existing comparative (homology) modeling and 2) Improve models obtained by fold-recognition and ab initio procedures to make them useful for molecular replacement. There will be some new methods development. Efforts are in four areas - databases, interaction potentials, conformational sampling, and optimization for combining approaches. We will develop ways to include constraints mined from sub-atomic resolution protein structures using a new HIRES Database (to include structures with resolution < 0.85 A). These will include a structure fragment database, as well as short-range distance distributions. These data can be used to compare modeled structures against the collected data. Uses of the high resolution data will ilclude selecting higher quality fragments to replace poor quality segments in the models, for mining interaction potentials, and as a source of a variety of other high quality information regarding protein structures. Better assessments of protein structural models will be developed, including the assessment of the quality of individual segments within a protein structure; the new metrics developed will be used for assessing the quality of computer-built models, crystal structures and NMR structures, and provide indicators of the expected quality of whole protein models as well as of its segments. New ways to sample protein motions will be pursued. Combining diverse methods will lead to significant gains in the computer modeling of protein structures. Extensive testing and validation will be carried out at each stage and in each part of the project to ensure large gains in model accuracy. n/a",High-Accuracy Protein Models Derived from Lower Resolution Data,7495009,R01GM081680,"['Amino Acid Sequence', 'Area', 'Arts', 'Behavior', 'Bioinformatics', 'Biology', 'CASP6 gene', 'Carbon', 'Categories', 'Cellular biology', 'Cereals', 'Chemistry', 'Code', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer Simulation', 'Computers', 'Consensus', 'Crystallography', 'Data', 'Databases', 'Detection', 'Development', 'Drug Design', 'Ensure', 'Enzymes', 'Evaluation', 'Foundations', 'Future', 'Generations', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Guidelines', 'High Performance Computing', 'Homology Modeling', 'Individual', 'Institutes', 'International', 'Internet', 'Investments', 'Iowa', 'Laboratories', 'Lead', 'Letters', 'Machine Learning', 'Mathematics', 'Medal', 'Methodology', 'Methods', 'Metric', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Conformation', 'Monsters', 'Motion', 'Numbers', 'Organism', 'Peptide Sequence Determination', 'Performance', 'Pharmaceutical Preparations', 'Physics', 'Polishes', 'Principal Investigator', 'Procedures', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Public Health', 'Purpose', 'Range', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Sampling', 'Score', 'Site', 'Solutions', 'Source', 'Staging', 'Standards of Weights and Measures', 'Structural Models', 'Structural Protein', 'Structure', 'Techniques', 'Testing', 'Torsion', 'Universities', 'Ursidae Family', 'Validation', 'Variant', 'Wisconsin', 'Work', 'base', 'comparative', 'computer science', 'data mining', 'experience', 'improved', 'insertion/deletion mutation', 'member', 'method development', 'molecular mechanics', 'molecular modeling', 'network models', 'novel strategies', 'numb protein', 'programs', 'protein structure', 'protein structure prediction', 'quantum', 'quantum chemistry', 'reconstruction', 'research study', 'restraint', 'scaffold', 'simulation', 'size', 'software development', 'structural biology', 'theories', 'three dimensional structure', 'tool']",NIGMS,IOWA STATE UNIVERSITY,R01,2008,231555,0.04126214001942315
"High-Accuracy Protein Models Derived from Lower Resolution Data    DESCRIPTION (provided by applicant):  An outstanding international interdisciplinary team has been assembled that will bring a broad variety of expertise to bear on protein model building, bringing together researchers from chemistry, physics, computer science, mathematics, structural biology, and bioinformatics. The expertise ranges from quantum chemistry to machine learning, and from data-mining to high performance computing. Input from collaborators in NMR and crystallography will be essential for validating the protein models. Improving abilities to model proteins can impact public health in important ways by enhancing our basic understanding of protein behavior and by facilitating a more efficient selection of protein targets for drug design.      The overall goal is to improve a wide range of protein modeling approaches, both by developing new approaches and by combining those previously been developed. The specific aims are to: (1) improve existing comparative (homology) modeling and (2) improve models obtained by fold recognition and ab initio procedures to make them useful for molecular replacement. There will be some new methods development. Efforts are in four areas--databases, interaction potentials, conformational sampling, and optimization for combining approaches. We will develop ways to include constraints mined from sub-atomic resolution protein structures using a new HIRES database (to include structures with resolution <0.85 A). These will include a structure fragment database, as well as short-range distance distributions. These data can be used to compare modeled structures against the collected data. Uses of the high resolution data will include selecting higher quality fragments to replace poor quality segments in the models, for mining interaction potentials, and as a source of a variety of other high quality information regarding protein structures.       Better assessments of protein structural models will be developed, including the assessment of the quality of individual segments within a protein structure; the new metrics developed will be used for assessing the quality of computer-built models, crystal structures and NMR structures, and provide indicators of the expected quality of whole protein models as well as of their segments. New ways to sample protein motions will be pursued. Combining diverse methods will lead to significant gains in the computer modeling of protein structures. Extensive testing and validation will be carried out at each stage and in each part of the project to ensure large gains in model accuracy.          n/a",High-Accuracy Protein Models Derived from Lower Resolution Data,7304272,R01GM081680,"['Amino Acid Sequence', 'Area', 'Arts', 'Behavior', 'Bioinformatics', 'Biology', 'CASP6 gene', 'Carbon', 'Categories', 'Cellular biology', 'Cereals', 'Chemistry', 'Code', 'Collaborations', 'Communicable Diseases', 'Communities', 'Computer Simulation', 'Computers', 'Consensus', 'Crystallography', 'Data', 'Databases', 'Detection', 'Development', 'Drug Design', 'Ensure', 'Enzymes', 'Evaluation', 'Foundations', 'Future', 'Generations', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Guidelines', 'High Performance Computing', 'Homology Modeling', 'Individual', 'Institutes', 'International', 'Internet', 'Investments', 'Iowa', 'Laboratories', 'Lead', 'Letters', 'Machine Learning', 'Mathematics', 'Medal', 'Methodology', 'Methods', 'Metric', 'Mining', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Conformation', 'Monsters', 'Motion', 'Numbers', 'Organism', 'Peptide Sequence Determination', 'Performance', 'Pharmaceutical Preparations', 'Physics', 'Polishes', 'Principal Investigator', 'Procedures', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Public Health', 'Purpose', 'Range', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Sampling', 'Score', 'Site', 'Solutions', 'Source', 'Staging', 'Standards of Weights and Measures', 'Structural Models', 'Structural Protein', 'Structure', 'Techniques', 'Testing', 'Torsion', 'Universities', 'Ursidae Family', 'Validation', 'Variant', 'Wisconsin', 'Work', 'base', 'comparative', 'computer science', 'data mining', 'experience', 'improved', 'insertion/deletion mutation', 'member', 'method development', 'molecular mechanics', 'molecular modeling', 'network models', 'novel strategies', 'numb protein', 'programs', 'protein structure', 'protein structure prediction', 'quantum', 'quantum chemistry', 'reconstruction', 'research study', 'restraint', 'scaffold', 'simulation', 'size', 'software development', 'structural biology', 'theories', 'three dimensional structure', 'tool']",NIGMS,IOWA STATE UNIVERSITY,R01,2007,248049,0.04087004547921032
"Empirical conformation-dependent covalent geometry variation in proteins    DESCRIPTION (provided by applicant): A detailed and accurate understanding of the structure of proteins is one cornerstone of modern biomedical research, and an explicit goal of the NIH is to define the structure of all proteins either by accurate experimental determination or comparative model-building. The most successful structure prediction approaches employ empirical knowledge-based energy terms derived from features of known protein structures - most notably single-residue ???-distributions, backbone-dependent side chain rotamer preferences, and tight packing criteria. One known unrealistic feature of these prediction programs is the assumption of a fixed ideal geometry for the backbone. The driving hypothesis behind this proposal is that there exists a largely unappreciated but real, systematic, significant and pervasive variation in backbone bond angles and peptide planarity that occurs as a function of backbone torsion angles, and accounting properly for this variation will be required to achieve X-ray crystal structure quality for comparative models. The overall goal of this work is to generate accurate empirical values for this covalent variation that will lead to tangible improvements in the accuracy of structures produced by comparative modeling and de novo structure prediction as well as by X-ray crystallography. We propose to achieve this overall goal by pursuing the following three specific aims: 1) to design, develop, and make available a flexibly-searchable database containing bond lengths, bond angles, and torsion angles for all structures known at better than 1.75 ¿ resolution (currently ~500,000 residues); 2) to use conventional query-based and modern machine learning approaches to derive accurate empirical information from the database about the systematic correlation of local conformation with variations in covalent geometry; and 3) to create a modular conformation-dependent expected covalent geometry library and to facilitate its incorporation into leading applications for comparative and crystallographic protein structure modeling. With the dramatically increased number of ultrahigh-resolution resolution crystal structures now known, the time is ripe for construction of this Protein Geometry Database that will provide facile access to a massive treasure trove of reliable and detailed empirical information about protein structure. To be done well, this work will require painstaking attention to detail and an intimate familiarity with the limitations of crystallographic refinement and the principles of protein structure. Dr. Karplus is well-suited to lead this work as he has a 20+-year track record of quality crystallographic structure determinations combined with contributions of more general insights into protein structure, among them being the pioneering characterization of the conformation-dependent variations in covalent geometry that serves as this project's foundation. Collaborations with world-leading groups in structure prediction, in crystallographic refinement and structure validation, and in knowledge-based library development ensure a rapid and effective translation of the gleaned information into improvements in protein modeling. PUBLIC HEALTH RELEVANCE: Proteins are responsible for carrying out most of the processes of life and their function depends exquisitely on their structure, even on the tiniest structural details. For this reason, determining accurate structures of proteins is a cornerstone of modern biomedical research. This work is aimed at leading to a universal improvement in the accuracy with which protein structure can be built.           n/a",Empirical conformation-dependent covalent geometry variation in proteins,7525973,R01GM083136,"['Accounting', 'Attention', 'Automobile Driving', 'Biomedical Research', 'Catalysis', 'Classification', 'Collaborations', 'Communities', 'Crystallography', 'Databases', 'Development', 'Ensure', 'Enzymes', 'Facility Construction Funding Category', 'Familiarity', 'Foundations', 'Glean', 'Goals', 'Heart', 'Homology Modeling', 'Investments', 'Knowledge', 'Lead', 'Length', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Methodology', 'Mining', 'Modeling', 'Molecular Conformation', 'Numbers', 'Object Attachment', 'Online Systems', 'Other Resources', 'Pattern', 'Peptides', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Process', 'Protein Conformation', 'Protein Structure Initiative', 'Proteins', 'Public Health', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Roentgen Rays', 'Side', 'Structure', 'Technology', 'Time', 'Torsion', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebral column', 'Work', 'X-Ray Crystallography', 'base', 'comparative', 'cost', 'design', 'disease-causing mutation', 'falls', 'inhibitor/antagonist', 'innovation', 'insight', 'knowledge base', 'molecular mechanics', 'novel', 'predictive modeling', 'preference', 'programs', 'protein structure', 'protein structure prediction', 'software development', 'structural biology', 'structural genomics']",NIGMS,OREGON STATE UNIVERSITY,R01,2008,213756,-0.0001132248651428064
"Improving Modeling by Learning from Details of High Accuracy Protein Structures DESCRIPTION (provided by applicant): The functions of proteins depend exquisitely on their structure, with details at the 0.1 � scale influencing enzyme catalysis, disease-causing mutations, and drug recognition. For this reason, having detailed and accurate structures of proteins is a cornerstone of modern biomedical research, and the NIH funded the Protein Structure Initiative with the goal of obtaining models for every protein structure with an accuracy approaching that of a high-resolution crystal structure. Current technology for template-based modeling is powerful, but cannot yet deliver ""near-crystal-structure"" quality. Tests show that the best minimization routines still fall short of consistently producing protein models for close homologs that approach within ~1 � rmsd of the 'native' structure as ultimately revealed by crystal structures. To help break through this 1 � barrier, during the previous period of support we used ultrahigh-resolution structures to create a library of conformation- dependent ideal geometry functions for the protein backbone, and showed that its use improves the quality of protein crystal structures and holds promise to improve template-based model refinement. We also discovered that ultrahigh-resolution crystal structures are a rich source of details about protein structure that are not accurately attainable from structures in the ~1.5-2 � resolution range and thus have not yet been fully accounted for in current energy functions. Here, our central hypothesis is that a major step forward in template-based modeling accuracy will come from identifying and explicitly taking into account detailed features of protein covalent geometry, conformation and non-covalent packing interactions that have not yet been characterized, and can now be gleaned from the study of highly accurate ultrahigh-resolution protein structures. The overall goal of our proposal is to mine such information so it can be used to improve the accuracy of predictive modeling. With many ultrahigh-resolution structures now available, the time is ripe to achieve this goal by pursuing three specific aims related to (1) extending the impact of the 'ideal geometry function' paradigm by creating, optimizing, and implementing conformation- dependent libraries accounting for peptide planarity, side chains, and cis-peptides, (2) mining ultrahigh- resolution crystal structures to glean information for next-generation empirical energy functions, and (3) analyzing ultrahigh-resolution protein structures solved in varying environments to produce a set of benchmark test cases and developing residue level assessment tools to use with these test cases to evaluate and hone template-based modeling refinement applications. This proposed work is low cost and low risk, and has a high likelihood of substantial impact as it provides basic information that can be widely incorporated into predictive and experimental modeling applications to improve their accuracy. It is also distinct from major efforts being invested into template-based modeling. Introducing this greater level of realism is a prerequisite to improving the refinement step of template-based modeling and achieving the goals of the Protein Structure Initiative. Proteins carry out the work that gets done inside of cells, so figuring out what they look like helps us understand things like how drugs work and how to design new drugs that will work even better. It is not practical to experimentally determine every protein structure, so having reliable ways to use computers to predict their structures is quite important. Current methods are not quite accurate enough, and the goal of this work is to look carefully at the best known protein structures to learn from their exact features how we can improve prediction technology to get the details right.",Improving Modeling by Learning from Details of High Accuracy Protein Structures,8895978,R01GM083136,"['Accounting', 'Automobile Driving', 'Behavior', 'Benchmarking', 'Biomedical Research', 'Catalysis', 'Cells', 'Computers', 'Crystallography', 'Databases', 'Development', 'Drug Formulations', 'Environment', 'Enzymes', 'Experimental Models', 'Funding', 'Generations', 'Geometry', 'Glean', 'Goals', 'Homologous Gene', 'Investments', 'Learning', 'Libraries', 'Life', 'Machine Learning', 'Maintenance', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular Conformation', 'Peptides', 'Pharmaceutical Preparations', 'Process', 'Protein Conformation', 'Protein Structure Initiative', 'Proteins', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Side', 'Source', 'Structure', 'Technology', 'Testing', 'Time', 'Torsion', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebral column', 'Work', 'base', 'cost', 'design', 'disease-causing mutation', 'falls', 'improved', 'inhibitor/antagonist', 'innovation', 'knowledge base', 'model building', 'molecular mechanics', 'next generation', 'predictive modeling', 'protein function', 'protein structure', 'protein structure prediction', 'tool', 'trend', 'ultra high resolution']",NIGMS,OREGON STATE UNIVERSITY,R01,2015,206832,-0.014323131696750674
"Improving Modeling by Learning from Details of High Accuracy Protein Structures     DESCRIPTION (provided by applicant): The functions of proteins depend exquisitely on their structure, with details at the 0.1 ¿ scale influencing enzyme catalysis, disease-causing mutations, and drug recognition. For this reason, having detailed and accurate structures of proteins is a cornerstone of modern biomedical research, and the NIH funded the Protein Structure Initiative with the goal of obtaining models for every protein structure with an accuracy approaching that of a high-resolution crystal structure. Current technology for template-based modeling is powerful, but cannot yet deliver ""near-crystal-structure"" quality. Tests show that the best minimization routines still fall short of consistently producing protein models for close homologs that approach within ~1 ¿ rmsd of the 'native' structure as ultimately revealed by crystal structures. To help break through this 1 ¿ barrier, during the previous period of support we used ultrahigh-resolution structures to create a library of conformation- dependent ideal geometry functions for the protein backbone, and showed that its use improves the quality of protein crystal structures and holds promise to improve template-based model refinement. We also discovered that ultrahigh-resolution crystal structures are a rich source of details about protein structure that are not accurately attainable from structures in the ~1.5-2 ¿ resolution range and thus have not yet been fully accounted for in current energy functions. Here, our central hypothesis is that a major step forward in template-based modeling accuracy will come from identifying and explicitly taking into account detailed features of protein covalent geometry, conformation and non-covalent packing interactions that have not yet been characterized, and can now be gleaned from the study of highly accurate ultrahigh-resolution protein structures. The overall goal of our proposal is to mine such information so it can be used to improve the accuracy of predictive modeling. With many ultrahigh-resolution structures now available, the time is ripe to achieve this goal by pursuing three specific aims related to (1) extending the impact of the 'ideal geometry function' paradigm by creating, optimizing, and implementing conformation- dependent libraries accounting for peptide planarity, side chains, and cis-peptides, (2) mining ultrahigh- resolution crystal structures to glean information for next-generation empirical energy functions, and (3) analyzing ultrahigh-resolution protein structures solved in varying environments to produce a set of benchmark test cases and developing residue level assessment tools to use with these test cases to evaluate and hone template-based modeling refinement applications. This proposed work is low cost and low risk, and has a high likelihood of substantial impact as it provides basic information that can be widely incorporated into predictive and experimental modeling applications to improve their accuracy. It is also distinct from major efforts being invested into template-based modeling. Introducing this greater level of realism is a prerequisite to improving the refinement step of template-based modeling and achieving the goals of the Protein Structure Initiative.           Proteins carry out the work that gets done inside of cells, so figuring out what they look like helps us understand things like how drugs work and how to design new drugs that will work even better. It is not practical to experimentally determine every protein structure, so having reliable ways to use computers to predict their structures is quite important. Current methods are not quite accurate enough, and the goal of this work is to look carefully at the best known protein structures to learn from their exact features how we can improve prediction technology to get the details right.            ",Improving Modeling by Learning from Details of High Accuracy Protein Structures,8708105,R01GM083136,"['Accounting', 'Automobile Driving', 'Behavior', 'Benchmarking', 'Biomedical Research', 'Catalysis', 'Cells', 'Computers', 'Crystallography', 'Databases', 'Development', 'Drug Formulations', 'Environment', 'Enzymes', 'Experimental Models', 'Funding', 'Generations', 'Geometry', 'Glean', 'Goals', 'Homologous Gene', 'Investments', 'Learning', 'Libraries', 'Life', 'Machine Learning', 'Maintenance', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular Conformation', 'Peptides', 'Pharmaceutical Preparations', 'Process', 'Protein Conformation', 'Protein Structure Initiative', 'Proteins', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Side', 'Source', 'Structure', 'Technology', 'Testing', 'Time', 'Torsion', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebral column', 'Work', 'base', 'cost', 'design', 'disease-causing mutation', 'falls', 'improved', 'inhibitor/antagonist', 'innovation', 'knowledge base', 'molecular mechanics', 'next generation', 'predictive modeling', 'protein function', 'protein structure', 'protein structure prediction', 'tool', 'trend', 'ultra high resolution']",NIGMS,OREGON STATE UNIVERSITY,R01,2014,207408,-0.014323131696750674
"Improving Modeling by Learning from Details of High Accuracy Protein Structures     DESCRIPTION (provided by applicant): The functions of proteins depend exquisitely on their structure, with details at the 0.1 ¿ scale influencing enzyme catalysis, disease-causing mutations, and drug recognition. For this reason, having detailed and accurate structures of proteins is a cornerstone of modern biomedical research, and the NIH funded the Protein Structure Initiative with the goal of obtaining models for every protein structure with an accuracy approaching that of a high-resolution crystal structure. Current technology for template-based modeling is powerful, but cannot yet deliver ""near-crystal-structure"" quality. Tests show that the best minimization routines still fall short of consistently producing protein models for close homologs that approach within ~1 ¿ rmsd of the 'native' structure as ultimately revealed by crystal structures. To help break through this 1 ¿ barrier, during the previous period of support we used ultrahigh-resolution structures to create a library of conformation- dependent ideal geometry functions for the protein backbone, and showed that its use improves the quality of protein crystal structures and holds promise to improve template-based model refinement. We also discovered that ultrahigh-resolution crystal structures are a rich source of details about protein structure that are not accurately attainable from structures in the ~1.5-2 ¿ resolution range and thus have not yet been fully accounted for in current energy functions. Here, our central hypothesis is that a major step forward in template-based modeling accuracy will come from identifying and explicitly taking into account detailed features of protein covalent geometry, conformation and non-covalent packing interactions that have not yet been characterized, and can now be gleaned from the study of highly accurate ultrahigh-resolution protein structures. The overall goal of our proposal is to mine such information so it can be used to improve the accuracy of predictive modeling. With many ultrahigh-resolution structures now available, the time is ripe to achieve this goal by pursuing three specific aims related to (1) extending the impact of the 'ideal geometry function' paradigm by creating, optimizing, and implementing conformation- dependent libraries accounting for peptide planarity, side chains, and cis-peptides, (2) mining ultrahigh- resolution crystal structures to glean information for next-generation empirical energy functions, and (3) analyzing ultrahigh-resolution protein structures solved in varying environments to produce a set of benchmark test cases and developing residue level assessment tools to use with these test cases to evaluate and hone template-based modeling refinement applications. This proposed work is low cost and low risk, and has a high likelihood of substantial impact as it provides basic information that can be widely incorporated into predictive and experimental modeling applications to improve their accuracy. It is also distinct from major efforts being invested into template-based modeling. Introducing this greater level of realism is a prerequisite to improving the refinement step of template-based modeling and achieving the goals of the Protein Structure Initiative.           Proteins carry out the work that gets done inside of cells, so figuring out what they look like helps us understand things like how drugs work and how to design new drugs that will work even better. It is not practical to experimentally determine every protein structure, so having reliable ways to use computers to predict their structures is quite important. Current methods are not quite accurate enough, and the goal of this work is to look carefully at the best known protein structures to learn from their exact features how we can improve prediction technology to get the details right.            ",Improving Modeling by Learning from Details of High Accuracy Protein Structures,8547080,R01GM083136,"['Accounting', 'Automobile Driving', 'Behavior', 'Benchmarking', 'Biomedical Research', 'Catalysis', 'Cells', 'Computers', 'Crystallography', 'Databases', 'Development', 'Drug Formulations', 'Environment', 'Enzymes', 'Experimental Models', 'Funding', 'Generations', 'Glean', 'Goals', 'Homologous Gene', 'Investments', 'Learning', 'Libraries', 'Life', 'Machine Learning', 'Maintenance', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular Conformation', 'Peptides', 'Pharmaceutical Preparations', 'Process', 'Protein Conformation', 'Protein Structure Initiative', 'Proteins', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Side', 'Source', 'Structure', 'Technology', 'Testing', 'Time', 'Torsion', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebral column', 'Work', 'base', 'cost', 'design', 'disease-causing mutation', 'falls', 'improved', 'inhibitor/antagonist', 'innovation', 'knowledge base', 'molecular mechanics', 'next generation', 'predictive modeling', 'protein function', 'protein structure', 'protein structure prediction', 'tool', 'trend', 'ultra high resolution']",NIGMS,OREGON STATE UNIVERSITY,R01,2013,200665,-0.014323131696750674
"Improving Modeling by Learning from Details of High Accuracy Protein Structures     DESCRIPTION (provided by applicant): The functions of proteins depend exquisitely on their structure, with details at the 0.1 ¿ scale influencing enzyme catalysis, disease-causing mutations, and drug recognition. For this reason, having detailed and accurate structures of proteins is a cornerstone of modern biomedical research, and the NIH funded the Protein Structure Initiative with the goal of obtaining models for every protein structure with an accuracy approaching that of a high-resolution crystal structure. Current technology for template-based modeling is powerful, but cannot yet deliver ""near-crystal-structure"" quality. Tests show that the best minimization routines still fall short of consistently producing protein models for close homologs that approach within ~1 ¿ rmsd of the 'native' structure as ultimately revealed by crystal structures. To help break through this 1 ¿ barrier, during the previous period of support we used ultrahigh-resolution structures to create a library of conformation- dependent ideal geometry functions for the protein backbone, and showed that its use improves the quality of protein crystal structures and holds promise to improve template-based model refinement. We also discovered that ultrahigh-resolution crystal structures are a rich source of details about protein structure that are not accurately attainable from structures in the ~1.5-2 ¿ resolution range and thus have not yet been fully accounted for in current energy functions. Here, our central hypothesis is that a major step forward in template-based modeling accuracy will come from identifying and explicitly taking into account detailed features of protein covalent geometry, conformation and non-covalent packing interactions that have not yet been characterized, and can now be gleaned from the study of highly accurate ultrahigh-resolution protein structures. The overall goal of our proposal is to mine such information so it can be used to improve the accuracy of predictive modeling. With many ultrahigh-resolution structures now available, the time is ripe to achieve this goal by pursuing three specific aims related to (1) extending the impact of the 'ideal geometry function' paradigm by creating, optimizing, and implementing conformation- dependent libraries accounting for peptide planarity, side chains, and cis-peptides, (2) mining ultrahigh- resolution crystal structures to glean information for next-generation empirical energy functions, and (3) analyzing ultrahigh-resolution protein structures solved in varying environments to produce a set of benchmark test cases and developing residue level assessment tools to use with these test cases to evaluate and hone template-based modeling refinement applications. This proposed work is low cost and low risk, and has a high likelihood of substantial impact as it provides basic information that can be widely incorporated into predictive and experimental modeling applications to improve their accuracy. It is also distinct from major efforts being invested into template-based modeling. Introducing this greater level of realism is a prerequisite to improving the refinement step of template-based modeling and achieving the goals of the Protein Structure Initiative.        PUBLIC HEALTH RELEVANCE:  Proteins carry out the work that gets done inside of cells, so figuring out what they look like helps us understand things like how drugs work and how to design new drugs that will work even better. It is not practical to experimentally determine every protein structure, so having reliable ways to use computers to predict their structures is quite important. Current methods are not quite accurate enough, and the goal of this work is to look carefully at the best known protein structures to learn from their exact features how we can improve prediction technology to get the details right.               Proteins carry out the work that gets done inside of cells, so figuring out what they look like helps us understand things like how drugs work and how to design new drugs that will work even better. It is not practical to experimentally determine every protein structure, so having reliable ways to use computers to predict their structures is quite important. Current methods are not quite accurate enough, and the goal of this work is to look carefully at the best known protein structures to learn from their exact features how we can improve prediction technology to get the details right.            ",Improving Modeling by Learning from Details of High Accuracy Protein Structures,8438862,R01GM083136,"['Accounting', 'Automobile Driving', 'Behavior', 'Benchmarking', 'Biomedical Research', 'Catalysis', 'Cells', 'Computers', 'Crystallography', 'Databases', 'Development', 'Drug Formulations', 'Environment', 'Enzymes', 'Experimental Models', 'Funding', 'Generations', 'Glean', 'Goals', 'Homologous Gene', 'Investments', 'Learning', 'Libraries', 'Life', 'Machine Learning', 'Maintenance', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular Conformation', 'Peptides', 'Pharmaceutical Preparations', 'Process', 'Protein Conformation', 'Protein Structure Initiative', 'Proteins', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Side', 'Source', 'Structure', 'Technology', 'Testing', 'Time', 'Torsion', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebral column', 'Work', 'base', 'cost', 'design', 'disease-causing mutation', 'falls', 'improved', 'inhibitor/antagonist', 'innovation', 'knowledge base', 'molecular mechanics', 'next generation', 'predictive modeling', 'protein function', 'protein structure', 'protein structure prediction', 'tool', 'trend', 'ultra high resolution']",NIGMS,OREGON STATE UNIVERSITY,R01,2012,208438,-0.012601093410095049
"Empirical conformation-dependent covalent geometry variation in proteins    DESCRIPTION (provided by applicant): A detailed and accurate understanding of the structure of proteins is one cornerstone of modern biomedical research, and an explicit goal of the NIH is to define the structure of all proteins either by accurate experimental determination or comparative model-building. The most successful structure prediction approaches employ empirical knowledge-based energy terms derived from features of known protein structures - most notably single-residue ???-distributions, backbone-dependent side chain rotamer preferences, and tight packing criteria. One known unrealistic feature of these prediction programs is the assumption of a fixed ideal geometry for the backbone. The driving hypothesis behind this proposal is that there exists a largely unappreciated but real, systematic, significant and pervasive variation in backbone bond angles and peptide planarity that occurs as a function of backbone torsion angles, and accounting properly for this variation will be required to achieve X-ray crystal structure quality for comparative models. The overall goal of this work is to generate accurate empirical values for this covalent variation that will lead to tangible improvements in the accuracy of structures produced by comparative modeling and de novo structure prediction as well as by X-ray crystallography. We propose to achieve this overall goal by pursuing the following three specific aims: 1) to design, develop, and make available a flexibly-searchable database containing bond lengths, bond angles, and torsion angles for all structures known at better than 1.75 ¿ resolution (currently ~500,000 residues); 2) to use conventional query-based and modern machine learning approaches to derive accurate empirical information from the database about the systematic correlation of local conformation with variations in covalent geometry; and 3) to create a modular conformation-dependent expected covalent geometry library and to facilitate its incorporation into leading applications for comparative and crystallographic protein structure modeling. With the dramatically increased number of ultrahigh-resolution resolution crystal structures now known, the time is ripe for construction of this Protein Geometry Database that will provide facile access to a massive treasure trove of reliable and detailed empirical information about protein structure. To be done well, this work will require painstaking attention to detail and an intimate familiarity with the limitations of crystallographic refinement and the principles of protein structure. Dr. Karplus is well-suited to lead this work as he has a 20+-year track record of quality crystallographic structure determinations combined with contributions of more general insights into protein structure, among them being the pioneering characterization of the conformation-dependent variations in covalent geometry that serves as this project's foundation. Collaborations with world-leading groups in structure prediction, in crystallographic refinement and structure validation, and in knowledge-based library development ensure a rapid and effective translation of the gleaned information into improvements in protein modeling. PUBLIC HEALTH RELEVANCE: Proteins are responsible for carrying out most of the processes of life and their function depends exquisitely on their structure, even on the tiniest structural details. For this reason, determining accurate structures of proteins is a cornerstone of modern biomedical research. This work is aimed at leading to a universal improvement in the accuracy with which protein structure can be built.           n/a",Empirical conformation-dependent covalent geometry variation in proteins,8111114,R01GM083136,"['Accounting', 'Attention', 'Automobile Driving', 'Biomedical Research', 'Catalysis', 'Collaborations', 'Communities', 'Crystallography', 'Databases', 'Development', 'Ensure', 'Enzymes', 'Familiarity', 'Foundations', 'Glean', 'Goals', 'Health', 'Heart', 'Homology Modeling', 'Investments', 'Knowledge', 'Lead', 'Length', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Methodology', 'Mining', 'Modeling', 'Molecular Conformation', 'Online Systems', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Process', 'Protein Conformation', 'Protein Structure Initiative', 'Proteins', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Roentgen Rays', 'Side', 'Structure', 'Technology', 'Time', 'Torsion', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebral column', 'Work', 'X-Ray Crystallography', 'base', 'comparative', 'cost', 'design', 'disease-causing mutation', 'falls', 'flexibility', 'inhibitor/antagonist', 'innovation', 'insight', 'knowledge base', 'molecular mechanics', 'novel', 'predictive modeling', 'preference', 'programs', 'protein structure', 'protein structure prediction', 'software development', 'structural biology', 'structural genomics']",NIGMS,OREGON STATE UNIVERSITY,R01,2011,208186,-0.0001132248651428064
"Empirical conformation-dependent covalent geometry variation in proteins    DESCRIPTION (provided by applicant): A detailed and accurate understanding of the structure of proteins is one cornerstone of modern biomedical research, and an explicit goal of the NIH is to define the structure of all proteins either by accurate experimental determination or comparative model-building. The most successful structure prediction approaches employ empirical knowledge-based energy terms derived from features of known protein structures - most notably single-residue ???-distributions, backbone-dependent side chain rotamer preferences, and tight packing criteria. One known unrealistic feature of these prediction programs is the assumption of a fixed ideal geometry for the backbone. The driving hypothesis behind this proposal is that there exists a largely unappreciated but real, systematic, significant and pervasive variation in backbone bond angles and peptide planarity that occurs as a function of backbone torsion angles, and accounting properly for this variation will be required to achieve X-ray crystal structure quality for comparative models. The overall goal of this work is to generate accurate empirical values for this covalent variation that will lead to tangible improvements in the accuracy of structures produced by comparative modeling and de novo structure prediction as well as by X-ray crystallography. We propose to achieve this overall goal by pursuing the following three specific aims: 1) to design, develop, and make available a flexibly-searchable database containing bond lengths, bond angles, and torsion angles for all structures known at better than 1.75 ¿ resolution (currently ~500,000 residues); 2) to use conventional query-based and modern machine learning approaches to derive accurate empirical information from the database about the systematic correlation of local conformation with variations in covalent geometry; and 3) to create a modular conformation-dependent expected covalent geometry library and to facilitate its incorporation into leading applications for comparative and crystallographic protein structure modeling. With the dramatically increased number of ultrahigh-resolution resolution crystal structures now known, the time is ripe for construction of this Protein Geometry Database that will provide facile access to a massive treasure trove of reliable and detailed empirical information about protein structure. To be done well, this work will require painstaking attention to detail and an intimate familiarity with the limitations of crystallographic refinement and the principles of protein structure. Dr. Karplus is well-suited to lead this work as he has a 20+-year track record of quality crystallographic structure determinations combined with contributions of more general insights into protein structure, among them being the pioneering characterization of the conformation-dependent variations in covalent geometry that serves as this project's foundation. Collaborations with world-leading groups in structure prediction, in crystallographic refinement and structure validation, and in knowledge-based library development ensure a rapid and effective translation of the gleaned information into improvements in protein modeling. PUBLIC HEALTH RELEVANCE: Proteins are responsible for carrying out most of the processes of life and their function depends exquisitely on their structure, even on the tiniest structural details. For this reason, determining accurate structures of proteins is a cornerstone of modern biomedical research. This work is aimed at leading to a universal improvement in the accuracy with which protein structure can be built.           n/a",Empirical conformation-dependent covalent geometry variation in proteins,7905142,R01GM083136,"['Accounting', 'Attention', 'Automobile Driving', 'Biomedical Research', 'Catalysis', 'Collaborations', 'Communities', 'Crystallography', 'Databases', 'Development', 'Ensure', 'Enzymes', 'Familiarity', 'Foundations', 'Glean', 'Goals', 'Heart', 'Homology Modeling', 'Investments', 'Knowledge', 'Lead', 'Length', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Methodology', 'Mining', 'Modeling', 'Molecular Conformation', 'Online Systems', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Process', 'Protein Conformation', 'Protein Structure Initiative', 'Proteins', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Roentgen Rays', 'Side', 'Structure', 'Technology', 'Time', 'Torsion', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebral column', 'Work', 'X-Ray Crystallography', 'base', 'comparative', 'cost', 'design', 'disease-causing mutation', 'falls', 'flexibility', 'inhibitor/antagonist', 'innovation', 'insight', 'knowledge base', 'molecular mechanics', 'novel', 'predictive modeling', 'preference', 'programs', 'protein structure', 'protein structure prediction', 'public health relevance', 'software development', 'structural biology', 'structural genomics']",NIGMS,OREGON STATE UNIVERSITY,R01,2010,210764,-0.0001132248651428064
"Empirical conformation-dependent covalent geometry variation in proteins    DESCRIPTION (provided by applicant): A detailed and accurate understanding of the structure of proteins is one cornerstone of modern biomedical research, and an explicit goal of the NIH is to define the structure of all proteins either by accurate experimental determination or comparative model-building. The most successful structure prediction approaches employ empirical knowledge-based energy terms derived from features of known protein structures - most notably single-residue ???-distributions, backbone-dependent side chain rotamer preferences, and tight packing criteria. One known unrealistic feature of these prediction programs is the assumption of a fixed ideal geometry for the backbone. The driving hypothesis behind this proposal is that there exists a largely unappreciated but real, systematic, significant and pervasive variation in backbone bond angles and peptide planarity that occurs as a function of backbone torsion angles, and accounting properly for this variation will be required to achieve X-ray crystal structure quality for comparative models. The overall goal of this work is to generate accurate empirical values for this covalent variation that will lead to tangible improvements in the accuracy of structures produced by comparative modeling and de novo structure prediction as well as by X-ray crystallography. We propose to achieve this overall goal by pursuing the following three specific aims: 1) to design, develop, and make available a flexibly-searchable database containing bond lengths, bond angles, and torsion angles for all structures known at better than 1.75 ¿ resolution (currently ~500,000 residues); 2) to use conventional query-based and modern machine learning approaches to derive accurate empirical information from the database about the systematic correlation of local conformation with variations in covalent geometry; and 3) to create a modular conformation-dependent expected covalent geometry library and to facilitate its incorporation into leading applications for comparative and crystallographic protein structure modeling. With the dramatically increased number of ultrahigh-resolution resolution crystal structures now known, the time is ripe for construction of this Protein Geometry Database that will provide facile access to a massive treasure trove of reliable and detailed empirical information about protein structure. To be done well, this work will require painstaking attention to detail and an intimate familiarity with the limitations of crystallographic refinement and the principles of protein structure. Dr. Karplus is well-suited to lead this work as he has a 20+-year track record of quality crystallographic structure determinations combined with contributions of more general insights into protein structure, among them being the pioneering characterization of the conformation-dependent variations in covalent geometry that serves as this project's foundation. Collaborations with world-leading groups in structure prediction, in crystallographic refinement and structure validation, and in knowledge-based library development ensure a rapid and effective translation of the gleaned information into improvements in protein modeling. PUBLIC HEALTH RELEVANCE: Proteins are responsible for carrying out most of the processes of life and their function depends exquisitely on their structure, even on the tiniest structural details. For this reason, determining accurate structures of proteins is a cornerstone of modern biomedical research. This work is aimed at leading to a universal improvement in the accuracy with which protein structure can be built.           n/a",Empirical conformation-dependent covalent geometry variation in proteins,7656854,R01GM083136,"['Accounting', 'Attention', 'Automobile Driving', 'Biomedical Research', 'Catalysis', 'Classification', 'Collaborations', 'Communities', 'Crystallography', 'Databases', 'Development', 'Ensure', 'Enzymes', 'Familiarity', 'Foundations', 'Glean', 'Goals', 'Heart', 'Homology Modeling', 'Investments', 'Knowledge', 'Lead', 'Length', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Methodology', 'Mining', 'Modeling', 'Molecular Conformation', 'Online Systems', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Process', 'Protein Conformation', 'Protein Structure Initiative', 'Proteins', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Roentgen Rays', 'Side', 'Structure', 'Technology', 'Time', 'Torsion', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebral column', 'Work', 'X-Ray Crystallography', 'base', 'comparative', 'cost', 'design', 'disease-causing mutation', 'falls', 'flexibility', 'inhibitor/antagonist', 'innovation', 'insight', 'knowledge base', 'molecular mechanics', 'novel', 'predictive modeling', 'preference', 'programs', 'protein structure', 'protein structure prediction', 'public health relevance', 'software development', 'structural biology', 'structural genomics']",NIGMS,OREGON STATE UNIVERSITY,R01,2009,286440,-0.0001132248651428064
"The Dynamics of Human Atrial Fibrillation Project Summary  Atrial fibrillation (AF) is a major arrhythmia worldwide, causing palpitations, stroke and mortality, and affecting 2-5 million Americans. Unfortunately, therapy to eliminate AF has had limited success. In our last funding cycle, we focused on localized drivers as potential AF mechanisms. Mapping of drivers has now been validated by concurrent optical mapping of human AF, and their features and have been validated by several other methods in patients. Nevertheless, ablation results for these and other proposed mechanisms for AF outside the pulmonary veins are mixed. It is unclear if this reflects difficulties of AF mapping, or different mechanisms between patients.  The project will develop a novel mechanistic framework for AF that simplifies existing indices by building on scientific consensus that organized AF is easier to treat, and disorganized AF has worse prognosis. This concept spans many existing indices and may help to reconcile them. We have 3 specific aims: (1) To define if the impact of ablation depends on the extent of organizing surrounding the ablation site; (2) To establish candidate mechanisms for organized and disorganized AF zones in individual patients with specific profiles, using machine learning applied to known cases with and without ablation success in our large registry. This comprises detailed AF maps during ablation and after Maze surgery, clinical data and outcomes. (3) To use novel clinical tools to predict whether patients will respond to PVI, other ablation or Maze surgery based on whether targeted regions control larger atrial areas and their locations.  This study will deliver immediate translational and clinical impact, and directly enable personalized medicine for AF ablation. We use detailed clinical mapping in patients, signal processing and computer modeling to develop a novel mechanistic framework and widely applicable clinical tools. We will use tools including machine learning and statistics to classify mechanisms based upon outcomes from ablation in individual patients. We will make our data and code available online. Our team is experienced in electrophysiology, computer science, machine learning, biological physics and statistics. The proposal is thus highly feasible. The Dynamics of Human Atrial Fibrillation Narrative Atrial fibrillation (AF) is an enormous public health problem in the United States, affecting 2-5 million Americans and causing rapid heart beats, stroke, heart failure or death. In this project, the applicant will develop a novel framework to better understand human AF that builds on agreement between several concepts for the disease. The applicant will develop strategies to identify AF patients who will best respond to each of several therapies, to guide personalized therapy.",The Dynamics of Human Atrial Fibrillation,10071621,R01HL083359,"['Ablation', 'Acute', 'Address', 'Affect', 'Agreement', 'American', 'Anatomy', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological', 'Biometry', 'Body Surface', 'Cessation of life', 'Clinical', 'Clinical Data', 'Code', 'Computer Models', 'Consensus', 'Data', 'Data Element', 'Disease', 'Electrocardiogram', 'Electrophysiology (science)', 'Fibrosis', 'Funding', 'Goals', 'Heart', 'Heart Atrium', 'Heart failure', 'Human', 'Image', 'Individual', 'Intervention', 'Lesion', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Observational Study', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Palpitations', 'Paper', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Physics', 'Prediction of Response to Therapy', 'Procedures', 'Public Health', 'Pulmonary veins', 'Registries', 'Right atrial structure', 'Rotation', 'Schools', 'Site', 'Statistical Data Interpretation', 'Stroke', 'Structural defect', 'Techniques', 'Testing', 'Time', 'Tissues', 'United States', 'United States National Institutes of Health', 'Work', 'base', 'clinical application', 'cohort', 'computer science', 'demographics', 'digital', 'experience', 'genomic data', 'hands-on learning', 'indexing', 'individual patient', 'insight', 'mortality', 'novel', 'novel diagnostics', 'novel therapeutics', 'outcome forecast', 'patient stratification', 'personalized medicine', 'prevent', 'prospective', 'response', 'signal processing', 'statistics', 'success', 'therapy development', 'tool']",NHLBI,STANFORD UNIVERSITY,R01,2020,770947,-0.06013926405348325
"Structural Dynamics of Biomolecular Systems Many proteins function as molecular machines. Understanding the principles that control the machinery of biomolecular systems is a computational challenge in many cases due to the involvement of macromolecular structures composed of multiple subunits and cooperative interactions manifested by allosteric changes in conformations, which are beyond the range of atomic simulations. Our goal in a recently funded R33 has been to develop and utilize low resolution models for exploring the collective dynamics of such complex systems, and bridging between structure and function, based on the paradigm structure-encodes-dynamics-encodes-function. The elastic network models and methods we introduced to this aim have found utility in many applications and helped us gain insights into the intrinsic, structure- encoded ability of proteins to favor the reconfiguration of native structures between functional substates. In the present R01, we are proposing to build on our previous work, to further explore the structure -> dynamics -> function mapping of allosteric and/or multimeric proteins using physically-based and computationally efficient models in collaboration with the NCBC Simbios at Stanford U (PI: Altman). The Simbios group has already started to construct a new simulation package, Simbody, the utility of which is expected to be significantly enhanced by a collaborative work. Our specific aims are (1) to build models and methods for automated coarse-graining of complex structures at multiple levels of resolution and assessing their collective dynamics, toward using the resulting models (structure) and data (motions) in Simbody; (2) to complement the physics-based approach developed in Aim 1 by information-theoretic approaches toward delineating signal transduction pathways/mechanisms in allosteric systems, and establishing the connection between these pathways and structural dynamics, and (3) to gain insights into the machinery of molecular chaperones, using as prototypes the bacterial chaperonin GroEL-GroES and the DnaK chaperone system, in collaboration with the Gierasch lab currently doing NIH-supported experiments for understanding the allosteric dynamics of the DnaK system. An important outcome of this project will be the establishment of a methodology for simulating the machinery of biomolecular systems on the order of Megadaltons, which will be achieved in collaboration with the Schulten lab, in addition to our partnership with the Simbios team. Project Narrative  Many proteins function as molecular machines. Understanding the dynamics or underlying molecular principles of these machines is a challenge due to the highly cooperative nature of interactions, which simultaneously involve multiple molecules. The aim of this project is twofold: to develop and implement computational models and methods to improve our understanding of the collective dynamics of proteins; and to elucidate the machinery of molecular chaperones - molecular systems that play an essential role in cellular physiology by assisting the folding and assembly/disassembly of proteins and directing them to transport and degradation pathways. These aims will be pursued in collaboration with the National Center for Biomedical Computing Simbios at Stanford U.",Structural Dynamics of Biomolecular Systems,8212307,R01GM086238,"['Algorithms', 'Allosteric Regulation', 'Biological', 'Biological Process', 'Biomedical Computing', 'Cell physiology', 'Cereals', 'Collaborations', 'Communication', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Databases', 'Degradation Pathway', 'Elements', 'Engineering', 'Environment', 'Funding', 'Goals', 'Grant', 'Graph', 'Hybrids', 'Information Sciences', 'Knowledge', 'Length', 'Libraries', 'Machine Learning', 'Maps', 'Mediating', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Chaperones', 'Molecular Conformation', 'Molecular Machines', 'Molecular Structure', 'Motion', 'Motor', 'Myosin ATPase', 'Nature', 'Nonlinear Dynamics', 'Outcome', 'Pathway interactions', 'Physics', 'Physiological', 'Play', 'Polymers', 'Process', 'Property', 'Protein Dynamics', 'Proteins', 'Research', 'Resolution', 'Role', 'Shapes', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Simulate', 'Site', 'Statistical Mechanics', 'Structure', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'chaperonin', 'computer framework', 'data modeling', 'design', 'improved', 'insight', 'interest', 'intermolecular interaction', 'molecular dynamics', 'network models', 'novel', 'protein folding', 'protein function', 'prototype', 'research study', 'simulation', 'structural genomics', 'theories']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2012,328628,0.024631914974828063
"Structural Dynamics of Biomolecular Systems Many proteins function as molecular machines. Understanding the principles that control the machinery of biomolecular systems is a computational challenge in many cases due to the involvement of macromolecular structures composed of multiple subunits and cooperative interactions manifested by allosteric changes in conformations, which are beyond the range of atomic simulations. Our goal in a recently funded R33 has been to develop and utilize low resolution models for exploring the collective dynamics of such complex systems, and bridging between structure and function, based on the paradigm structure-encodes-dynamics-encodes-function. The elastic network models and methods we introduced to this aim have found utility in many applications and helped us gain insights into the intrinsic, structure- encoded ability of proteins to favor the reconfiguration of native structures between functional substates. In the present R01, we are proposing to build on our previous work, to further explore the structure -> dynamics -> function mapping of allosteric and/or multimeric proteins using physically-based and computationally efficient models in collaboration with the NCBC Simbios at Stanford U (PI: Altman). The Simbios group has already started to construct a new simulation package, Simbody, the utility of which is expected to be significantly enhanced by a collaborative work. Our specific aims are (1) to build models and methods for automated coarse-graining of complex structures at multiple levels of resolution and assessing their collective dynamics, toward using the resulting models (structure) and data (motions) in Simbody; (2) to complement the physics-based approach developed in Aim 1 by information-theoretic approaches toward delineating signal transduction pathways/mechanisms in allosteric systems, and establishing the connection between these pathways and structural dynamics, and (3) to gain insights into the machinery of molecular chaperones, using as prototypes the bacterial chaperonin GroEL-GroES and the DnaK chaperone system, in collaboration with the Gierasch lab currently doing NIH-supported experiments for understanding the allosteric dynamics of the DnaK system. An important outcome of this project will be the establishment of a methodology for simulating the machinery of biomolecular systems on the order of Megadaltons, which will be achieved in collaboration with the Schulten lab, in addition to our partnership with the Simbios team. Project Narrative  Many proteins function as molecular machines. Understanding the dynamics or underlying molecular principles of these machines is a challenge due to the highly cooperative nature of interactions, which simultaneously involve multiple molecules. The aim of this project is twofold: to develop and implement computational models and methods to improve our understanding of the collective dynamics of proteins; and to elucidate the machinery of molecular chaperones - molecular systems that play an essential role in cellular physiology by assisting the folding and assembly/disassembly of proteins and directing them to transport and degradation pathways. These aims will be pursued in collaboration with the National Center for Biomedical Computing Simbios at Stanford U.",Structural Dynamics of Biomolecular Systems,8017445,R01GM086238,"['Algorithms', 'Allosteric Regulation', 'Biological', 'Biological Process', 'Biomedical Computing', 'Cell physiology', 'Cereals', 'Collaborations', 'Communication', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Databases', 'Degradation Pathway', 'Elements', 'Engineering', 'Environment', 'Funding', 'Goals', 'Grant', 'Graph', 'Hybrids', 'Information Sciences', 'Knowledge', 'Length', 'Libraries', 'Machine Learning', 'Maps', 'Mediating', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Chaperones', 'Molecular Conformation', 'Molecular Machines', 'Molecular Structure', 'Motion', 'Motor', 'Myosin ATPase', 'Nature', 'Nonlinear Dynamics', 'Outcome', 'Pathway interactions', 'Physics', 'Physiological', 'Play', 'Polymers', 'Process', 'Property', 'Protein Dynamics', 'Proteins', 'Research', 'Resolution', 'Role', 'Shapes', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Simulate', 'Site', 'Statistical Mechanics', 'Structure', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'chaperonin', 'computer framework', 'data modeling', 'design', 'improved', 'insight', 'interest', 'intermolecular interaction', 'molecular dynamics', 'network models', 'novel', 'protein folding', 'protein function', 'prototype', 'research study', 'simulation', 'structural genomics', 'theories']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2011,328558,0.024631914974828063
"Structural Dynamics of Biomolecular Systems Many proteins function as molecular machines. Understanding the principles that control the machinery of biomolecular systems is a computational challenge in many cases due to the involvement of macromolecular structures composed of multiple subunits and cooperative interactions manifested by allosteric changes in conformations, which are beyond the range of atomic simulations. Our goal in a recently funded R33 has been to develop and utilize low resolution models for exploring the collective dynamics of such complex systems, and bridging between structure and function, based on the paradigm structure-encodes-dynamics-encodes-function. The elastic network models and methods we introduced to this aim have found utility in many applications and helped us gain insights into the intrinsic, structure- encoded ability of proteins to favor the reconfiguration of native structures between functional substates. In the present R01, we are proposing to build on our previous work, to further explore the structure -> dynamics -> function mapping of allosteric and/or multimeric proteins using physically-based and computationally efficient models in collaboration with the NCBC Simbios at Stanford U (PI: Altman). The Simbios group has already started to construct a new simulation package, Simbody, the utility of which is expected to be significantly enhanced by a collaborative work. Our specific aims are (1) to build models and methods for automated coarse-graining of complex structures at multiple levels of resolution and assessing their collective dynamics, toward using the resulting models (structure) and data (motions) in Simbody; (2) to complement the physics-based approach developed in Aim 1 by information-theoretic approaches toward delineating signal transduction pathways/mechanisms in allosteric systems, and establishing the connection between these pathways and structural dynamics, and (3) to gain insights into the machinery of molecular chaperones, using as prototypes the bacterial chaperonin GroEL-GroES and the DnaK chaperone system, in collaboration with the Gierasch lab currently doing NIH-supported experiments for understanding the allosteric dynamics of the DnaK system. An important outcome of this project will be the establishment of a methodology for simulating the machinery of biomolecular systems on the order of Megadaltons, which will be achieved in collaboration with the Schulten lab, in addition to our partnership with the Simbios team. Project Narrative  Many proteins function as molecular machines. Understanding the dynamics or underlying molecular principles of these machines is a challenge due to the highly cooperative nature of interactions, which simultaneously involve multiple molecules. The aim of this project is twofold: to develop and implement computational models and methods to improve our understanding of the collective dynamics of proteins; and to elucidate the machinery of molecular chaperones - molecular systems that play an essential role in cellular physiology by assisting the folding and assembly/disassembly of proteins and directing them to transport and degradation pathways. These aims will be pursued in collaboration with the National Center for Biomedical Computing Simbios at Stanford U.",Structural Dynamics of Biomolecular Systems,7751334,R01GM086238,"['Administrator', 'Algorithms', 'Allosteric Regulation', 'Area', 'Automobile Driving', 'Benchmarking', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Biomedical Computing', 'Biomedical Engineering', 'Biomedical Research', 'Cardiovascular system', 'Cell physiology', 'Cells', 'Cereals', 'Chemicals', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complement', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Databases', 'Degradation Pathway', 'Development', 'Disease', 'Doctor of Philosophy', 'Documentation', 'Drug Delivery Systems', 'Elements', 'Engineering', 'Environment', 'Equation', 'Exhibits', 'Faculty', 'Family member', 'Fostering', 'Funding', 'Future', 'Generations', 'Genetic Medicine', 'Goals', 'Grant', 'Graph', 'Hybrids', 'Imagery', 'Individual', 'Information Sciences', 'Institutes', 'Institution', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Length', 'Libraries', 'Licensing', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Mechanics', 'Mediating', 'Medical Device', 'Medical Research', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Modification', 'Molecular', 'Molecular Chaperones', 'Molecular Conformation', 'Molecular Machines', 'Molecular Structure', 'Motion', 'Motor', 'Movement', 'Myopathy', 'Myosin ATPase', 'Nature', 'Newsletter', 'Nonlinear Dynamics', 'Operative Surgical Procedures', 'Organism', 'Outcome', 'Paper', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Play', 'Polymers', 'Process', 'Property', 'Protein Dynamics', 'Proteins', 'Publishing', 'RNA', 'RNA Folding', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Role', 'Scheme', 'Scientist', 'Sequence Analysis', 'Shapes', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Simulate', 'Site', 'Software Engineering', 'Source', 'Statistical Mechanics', 'Structure', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'United States National Institutes of Health', 'Universities', 'Ursidae Family', 'Validation', 'Work', 'advanced simulation', 'analytical tool', 'base', 'biological systems', 'biomedical scientist', 'body system', 'chaperone machinery', 'chaperonin', 'commercialization', 'computer framework', 'computer science', 'computerized tools', 'data modeling', 'data sharing', 'design', 'dissemination research', 'flexibility', 'graphical user interface', 'image visualization', 'improved', 'innovation', 'insight', 'interest', 'intermolecular interaction', 'macromolecule', 'mathematical model', 'meetings', 'member', 'models and simulation', 'molecular dynamics', 'nanometer', 'network models', 'neuromuscular', 'novel', 'open source', 'programs', 'protein folding', 'protein function', 'prototype', 'repository', 'research study', 'response', 'simulation', 'software development', 'structural genomics', 'theories', 'tool', 'user-friendly', 'web site']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,324772,0.024631914974828063
"Structural Dynamics of Biomolecular Systems    DESCRIPTION (provided by applicant):  Many proteins function as molecular machines. Understanding the principles that control the machinery of biomolecular systems is a computational challenge in many cases due to the involvement of macromolecular structures composed of multiple subunits and cooperative interactions manifested by allosteric changes in conformations, which are beyond the range of atomic simulations. Our goal in a recently funded R33 has been to develop and utilize low resolution models for exploring the collective dynamics of such complex systems, and bridging between structure and function, based on the paradigm structure-encodes-dynamics-encodes-function. The elastic network models and methods we introduced to this aim have found utility in many applications and helped us gain insights into the intrinsic, structure- encoded ability of proteins to favor the reconfiguration of native structures between functional substates. In the present R01, we are proposing to build on our previous work, to further explore the structure -> dynamics -> function mapping of allosteric and/or multimeric proteins using physically-based and computationally efficient models in collaboration with the NCBC Simbios at Stanford U (PI: Altman). The Simbios group has already started to construct a new simulation package, Simbody, the utility of which is expected to be significantly enhanced by a collaborative work. Our specific aims are (1) to build models and methods for automated coarse-graining of complex structures at multiple levels of resolution and assessing their collective dynamics, toward using the resulting models (structure) and data (motions) in Simbody; (2) to complement the physics-based approach developed in Aim 1 by information-theoretic approaches toward delineating signal transduction pathways/mechanisms in allosteric systems, and establishing the connection between these pathways and structural dynamics, and (3) to gain insights into the machinery of molecular chaperones, using as prototypes the bacterial chaperonin GroEL-GroES and the DnaK chaperone system, in collaboration with the Gierasch lab currently doing NIH-supported experiments for understanding the allosteric dynamics of the DnaK system. An important outcome of this project will be the establishment of a methodology for simulating the machinery of biomolecular systems on the order of Megadaltons, which will be achieved in collaboration with the Schulten lab, in addition to our partnership with the Simbios team. Project Narrative Many proteins function as molecular machines. Understanding the dynamics or underlying molecular principles of these machines is a challenge due to the highly cooperative nature of interactions, which simultaneously involve multiple molecules. The aim of this project is twofold: to develop and implement computational models and methods to improve our understanding of the collective dynamics of proteins; and to elucidate the machinery of molecular chaperones - molecular systems that play an essential role in cellular physiology by assisting the folding and assembly/disassembly of proteins and directing them to transport and degradation pathways. These aims will be pursued in collaboration with the National Center for Biomedical Computing Simbios at Stanford U.          n/a",Structural Dynamics of Biomolecular Systems,7556196,R01GM086238,"['Algorithms', 'Allosteric Regulation', 'Biological', 'Biological Process', 'Biomedical Computing', 'Cell physiology', 'Cereals', 'Collaborations', 'Communication', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Databases', 'Degradation Pathway', 'Elements', 'Engineering', 'Environment', 'Funding', 'Goals', 'Grant', 'Graph', 'Hybrids', 'Information Sciences', 'Knowledge', 'Length', 'Libraries', 'Machine Learning', 'Maps', 'Mediating', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Chaperones', 'Molecular Conformation', 'Molecular Machines', 'Molecular Structure', 'Motion', 'Motor', 'Myosin ATPase', 'Nature', 'Nonlinear Dynamics', 'Outcome', 'Pathway interactions', 'Physics', 'Physiological', 'Play', 'Polymers', 'Process', 'Property', 'Protein Dynamics', 'Proteins', 'Research', 'Resolution', 'Role', 'Shapes', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Simulate', 'Site', 'Statistical Mechanics', 'Structure', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'chaperonin', 'computer framework', 'data modeling', 'design', 'improved', 'insight', 'interest', 'intermolecular interaction', 'molecular dynamics', 'network models', 'novel', 'protein folding', 'protein function', 'prototype', 'research study', 'simulation', 'structural genomics', 'theories']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,327483,0.024631914974828063
"Intelligent Microtome Instrumentation    DESCRIPTION (provided by applicant): Locating fluorescently-tagged cells in whole organisms is important to the development of gene therapy, stem cell therapy delivery methods, and for drug research. This project will develop an intelligent microtome to identify fluorescently labeled cells in whole mice and to collect those cells in thin sections. During Phase I, a small-mammal cryomicrotome with LED-based tissue illumination for fluorescence imaging will be constructed. Several CCD cameras will be evaluated to establish the spatial resolution and gray-scale resolution needed to provide necessary fluorescence-imaging capabilities for the instrument. The instrument will be tested on isolated muscle, tissue homogenates containing green fluorescent protein (GFP) labeled cells, and on whole mice. The cells expressing GFP in these samples will provide data for the development of next-generation instrumentation during Phase II.       Phase II will add capabilities to use the fluorescence image data to intelligently acquire thin sections only when fluorescent cells are detected. Fluorescence images acquired during sectioning will provide morphological guides to identify and isolate the same cells in mounted sections by laser-capture microdissection. Automated thin-tissue acquisition will be an added capability and will be integrated with intelligent fluorescence analysis to produce a completely automated instrument. The instrument will allow processing of whole animals to obtain thin sections for laser dissection and for biochemical and/or PCR post processing of select tissue regions.           n/a",Intelligent Microtome Instrumentation,7154878,R43HL086267,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical equipment', 'biomedical equipment development', 'computer program /software', 'computer system hardware', 'digital imaging', 'fluorescence microscopy', 'genetically modified animals', 'green fluorescent proteins', 'laboratory mouse', 'molecular /cellular imaging', 'muscle', 'muscular dystrophy', 'phantom model', 'sectioning', 'three dimensional imaging /topography']",NHLBI,"BARLOW SCIENTIFIC, INC.",R43,2006,100000,0.02472825581699907
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu    DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. PUBLIC HEALTH RELEVANCE: We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured association mapping between disease-relevant elements in the genome, transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and interdependent genome variations, structured association analysis at multi-omic level is not only needed, but also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view of complex diseases, which may lead to the identification of genes underlying disease processes; in addition, such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.           Project Narrative We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured association mapping between disease-relevant elements in the genome, transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and interdependent genome variations, structured association analysis at multi-omic level is not only needed, but also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view of complex diseases, which may lead to the identification of genes underlying disease processes; in addition, such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,7636332,R01GM087694,"['Address', 'Admixture', 'Affect', 'Algorithms', 'Architecture', 'Arts', 'Asthma', 'Atlases', 'Behavior', 'Biological', 'Biological Assay', 'Biological Markers', 'Blood Pressure', 'Body Weight', 'Bronchoalveolar Lavage', 'Cell model', 'Cells', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'Coupling', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Dependency', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Documentation', 'Elements', 'Enzyme-Linked Immunosorbent Assay', 'Epithelial', 'Etiology', 'Evaluation', 'Evolution', 'Exhibits', 'Family', 'Gene Conversion', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Gold', 'Graph', 'Hand', 'Haplotypes', 'Housing', 'Human', 'Hybrids', 'Indium', 'Individual', 'Internet', 'Investigation', 'Joints', 'Knock-out', 'Knowledge', 'Lasso', 'Lead', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Medical center', 'Medicine', 'Methodology', 'Methods', 'Microsatellite Repeats', 'Mining', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mutation', 'Obesity', 'Ontology', 'Outcome', 'Output', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Pattern', 'Penetrance', 'Performance', 'Phase', 'Phenotype', 'Plastics', 'Population', 'Procedures', 'Process', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Recombinant Haplotype', 'Recruitment Activity', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Regulatory Pathway', 'Reporting', 'Research', 'Risk', 'Role', 'Sampling', 'Severities', 'Shapes', 'Signal Transduction', 'Simulate', 'Software Tools', 'Specificity', 'Statistical Models', 'Structure', 'Study Subject', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Transcription Regulation Pathway', 'Transcriptional Regulation', 'Trees', 'Triplet Multiple Birth', 'Unified Medical Language System', 'Universities', 'Validation', 'Variant', 'Western Blotting', 'Work', 'Yeasts', 'base', 'clinical phenotype', 'cohort', 'combinatorial', 'computer based statistical methods', 'cost', 'data integration', 'data mining', 'disease phenotype', 'disorder control', 'disorder subtype', 'gene function', 'genetic linkage analysis', 'genome wide association study', 'grasp', 'high throughput analysis', 'hydroxy-aluminum polymer', 'improved', 'innovation', 'mathematical model', 'molecular phenotype', 'network models', 'novel', 'phenome', 'programs', 'public health relevance', 'reconstruction', 'response', 'scale up', 'software systems', 'statistics', 'tool', 'trait', 'user friendly software']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2009,544383,-0.00854989090429636
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of structured association mapping between disease-relevant elements in the genome,  transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the  outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and  interdependent genome variations, structured association analysis at multi-omic level is not only needed, but  also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations  we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view  of complex diseases, which may lead to the identification of genes underlying disease processes; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to  disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,8054816,R01GM087694,"['Address', 'Admixture', 'Affect', 'Algorithms', 'Asthma', 'Biological Markers', 'Cells', 'Clinical', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Haplotypes', 'Indium', 'Individual', 'Joints', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Obesity', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Phenotype', 'Plastics', 'Population', 'Process', 'Quantitative Trait Loci', 'Regulator Genes', 'Research', 'Role', 'Software Tools', 'Statistical Models', 'Structure', 'Study Subject', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Variant', 'Work', 'base', 'clinical phenotype', 'data integration', 'data mining', 'disorder control', 'gene function', 'genetic analysis', 'genetic linkage analysis', 'grasp', 'improved', 'innovation', 'novel', 'phenome', 'trait']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2011,513100,-0.009915493708057067
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu    DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. PUBLIC HEALTH RELEVANCE: We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured association mapping between disease-relevant elements in the genome, transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and interdependent genome variations, structured association analysis at multi-omic level is not only needed, but also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view of complex diseases, which may lead to the identification of genes underlying disease processes; in addition, such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.          Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of structured association mapping between disease-relevant elements in the genome,  transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the  outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and  interdependent genome variations, structured association analysis at multi-omic level is not only needed, but  also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations  we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view  of complex diseases, which may lead to the identification of genes underlying disease processes; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to  disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,7845048,R01GM087694,"['Address', 'Admixture', 'Affect', 'Algorithms', 'Asthma', 'Biological Markers', 'Cells', 'Clinical', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Haplotypes', 'Indium', 'Individual', 'Joints', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Obesity', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Phenotype', 'Plastics', 'Population', 'Process', 'Quantitative Trait Loci', 'Regulator Genes', 'Research', 'Role', 'Software Tools', 'Statistical Models', 'Structure', 'Study Subject', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Variant', 'Work', 'base', 'clinical phenotype', 'data integration', 'data mining', 'disorder control', 'gene function', 'genetic linkage analysis', 'grasp', 'improved', 'innovation', 'novel', 'phenome', 'public health relevance', 'trait']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2010,515713,-0.00854989090429636
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of structured association mapping between disease-relevant elements in the genome,  transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the  outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and  interdependent genome variations, structured association analysis at multi-omic level is not only needed, but  also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations  we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view  of complex diseases, which may lead to the identification of genes underlying disease processes; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to  disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,8656359,R01GM087694,"['Address', 'Admixture', 'Affect', 'Asthma', 'Biological Markers', 'Cells', 'Clinical', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Haplotypes', 'High-Throughput Nucleotide Sequencing', 'Indium', 'Individual', 'Joints', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Obesity', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Phenotype', 'Plastics', 'Population', 'Process', 'Quantitative Trait Loci', 'Regulator Genes', 'Research', 'Role', 'Software Tools', 'Statistical Algorithm', 'Statistical Models', 'Structure', 'Study Subject', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Variant', 'Work', 'base', 'clinical phenotype', 'data integration', 'data mining', 'disorder control', 'gene function', 'genetic analysis', 'genetic linkage analysis', 'grasp', 'improved', 'innovation', 'novel', 'phenome', 'trait']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2014,492794,-0.009915493708057067
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of structured association mapping between disease-relevant elements in the genome,  transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the  outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and  interdependent genome variations, structured association analysis at multi-omic level is not only needed, but  also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations  we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view  of complex diseases, which may lead to the identification of genes underlying disease processes; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to  disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,8251157,R01GM087694,"['Address', 'Admixture', 'Affect', 'Algorithms', 'Asthma', 'Biological Markers', 'Cells', 'Clinical', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Haplotypes', 'Indium', 'Individual', 'Joints', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Obesity', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Phenotype', 'Plastics', 'Population', 'Process', 'Quantitative Trait Loci', 'Regulator Genes', 'Research', 'Role', 'Software Tools', 'Statistical Models', 'Structure', 'Study Subject', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Variant', 'Work', 'base', 'clinical phenotype', 'data integration', 'data mining', 'disorder control', 'gene function', 'genetic analysis', 'genetic linkage analysis', 'grasp', 'improved', 'innovation', 'novel', 'phenome', 'trait']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2013,477069,-0.009915493708057067
"Accurate detection of chromosomal abnormalities with multi-color image processing    DESCRIPTION (provided by applicant): The combination of high resolution assays in genomics with microscopic imaging has been used for the detection of complex chromosomal rearrangements, a significant but difficult problem in prenatal and postnatal diagnosis, birth defect detection and cancer research. As a recently developed molecular cytogenetic technique, multiplex fluorescence in situ hybridization (M-FISH) imaging has provided rapid and high resolution detection of chromosomal abnormalities associated with cancer and genetic disorders. However, the technique is currently limited to research use and only serves as an adjunct tool to the G-banding based monochromatic chromosomal karyotyping in a clinical laboratory. A primary barrier of the technique is the lower classification accuracy when classifying chromosomes from multi-color microscopic imaging data. Therefore, the goal of this R15 project is to develop innovative multi-spectral image processing and machine learning techniques for M-FISH image analysis so that chromosomal rearrangement detection can be made more reproducible, robust, and faster, thereby significantly increasing the ability and efficacy of this newly developed cellular imaging technique. Our proposed approaches such as multiscale feature extraction, nonlinear manifold analysis and adaptive fuzzy clustering are able to target specific features of multi-spectral imaging data, promising a significant improvement over the current techniques. In order to validate the technique and bring it into clinical use, we will partner with a clinical geneticist, Dr. Merlin Butler, and a cytogeneticist, Dr. Diane Persons both at Kansas University Medical Center. In addition, we will collaborate with an industrial scientist, Dr. Kenneth Castleman, who is the pioneer in developing and commercializing cytogenetic imaging products. Through our interdisciplinary research and collaboration, we will accomplish the following specific aims: 1) develop image normalization approaches to improve the acquisition of multi-color FISH images; 2) develop multiscale dimension analysis to extract features from multi-color images; 3) design adaptive fuzzy clustering and incorporate contextual information to improve the pixel-wise classification of chromosomes; and 4) validate computational approaches with clinical testing in collaboration with medical and industrial partners. This research project will also enhance our research infrastructure in biomedical image informatics and provide undergraduate and graduate students opportunities to touch the frontier of molecular and cellular imaging by participating in the proposed research activities. PUBLIC HEALTH RELEVANCE: Unraveling complex rearrangements using cytogenetic approaches such as M-FISH imaging has been extremely useful in prenatal, postnatal and cancer diagnoses. Our proposed approaches have the potential to significantly improve the reliability of the newly developed M-FISH imaging technique, making it feasible for clinical use. This will in turn benefit the health of human beings. Furthermore, the developed computational techniques can be applicable to a wide range of multi-color bio-imaging problems, thereby having a broad impact on the biomedical community.           Project Narrative Unraveling complex rearrangements using cytogenetic approaches such as M-FISH imaging has been extremely useful in prenatal, postnatal and cancer diagnoses. Our proposed approaches have the potential to significantly improve the reliability of the newly developed M-FISH imaging technique, making it feasible for clinical use. This will in turn benefit the health of human beings. Furthermore, the developed computational techniques can be applicable to a wide range of multi-color bio-imaging problems, thereby having a broad impact on the biomedical community.",Accurate detection of chromosomal abnormalities with multi-color image processing,7727717,R15GM088802,"['Academic Medical Centers', 'Academic Research Enhancement Awards', 'Address', 'Algorithms', 'Biological Assay', 'Cells', 'Chromosomal Rearrangement', 'Chromosome abnormality', 'Chromosomes', 'Chromosomes, Human, Pair 4', 'Cities', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Color', 'Communities', 'Complex', 'Computational Technique', 'Congenital Abnormality', 'Cytogenetic Analysis', 'Cytogenetics', 'DNA Sequence Rearrangement', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Engineering', 'Environment', 'Figs - dietary', 'Fluorescent in Situ Hybridization', 'G-Banding', 'Genetic', 'Genomics', 'Goals', 'Health Benefit', 'Hereditary Disease', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging problem', 'Interdisciplinary Study', 'Kansas', 'Karyotype', 'Karyotype determination procedure', 'Laboratories', 'Learning', 'Machine Learning', 'Masks', 'Medical', 'Methods', 'Microscopic', 'Missouri', 'Molecular Probes', 'Neurofibromin 2', 'Patients', 'Persons', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Project Grants', 'Resolution', 'Resources', 'Schools', 'Scientist', 'Signal Transduction', 'Spectral Karyotyping', 'Techniques', 'Technology', 'Time', 'Touch sensation', 'Training', 'United States National Institutes of Health', 'Universities', 'anticancer research', 'assay development', 'base', 'bioimaging', 'cancer diagnosis', 'cancer genetics', 'cellular imaging', 'clinical application', 'clinical effect', 'design', 'experience', 'frontier', 'graduate student', 'high throughput screening', 'image processing', 'imaging informatics', 'improved', 'innovation', 'leukemia', 'meetings', 'molecular/cellular imaging', 'multidisciplinary', 'novel', 'postnatal', 'prenatal', 'prevent', 'programs', 'public health relevance', 'research clinical testing', 'response', 'tool']",NIGMS,UNIVERSITY OF MISSOURI KANSAS CITY,R15,2009,229519,0.013297007476109061
"Simulation Algorithms for Spatial Pattern Recognition    DESCRIPTION (provided by applicant):    This SBIR project is developing methods and software for the specification, construction and simulation of neutral spatial models, and for applying these neutral models within the framework of probabilistic pattern recognition. Results will allow epidemiologists, environmental scientists and image analysts across a broad range of commercial disciplines to more accurately identify patterns in spatial data by removing the bias towards false positives that is caused by unrealistic null hypotheses such as ""complete spatial randomness"" (CSR). This project will accomplish 5 aims:      1. Conduct a requirements analysis to specify the neutral models and functionality to incorporate in the software.   2. Develop and test a software prototype to evaluate feasibility of the proposed models.   3. Propose a topology of neutral models and develop strategies to generate them and to conduct sensitivity analysis for investigating the impact of implicit assumptions (i.e. spatial autocorrelation or non-uniform risk) and number of realizations on test results.   4. Incorporate the neutral models in the first commercially established software package that allows for user-specified alternate hypothesis in spatial statistical tests.   5. Apply the software and methods to demonstrate the approach and its unique benefits for exposure and health risk assessment.      Feasibility of this project was demonstrated in the Phase I. This Phase II project will accomplish aims three through five. These technologic, scientific and commercial innovations will revolutionize our ability to identify, document and assess the probability of spatial patterns relative to neutral models that incorporate realistic local, spatial and multivariate dependencies. The neutral models and methods in this proposal make possible, for the first time ever, evaluation of the sensitivity of the results of cluster or boundary analyses to specification of the null hypothesis.         n/a",Simulation Algorithms for Spatial Pattern Recognition,7015648,R44CA092807,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'human data', 'image processing', 'imaging /visualization /scanning', 'statistics /biometry', 'visual cortex']",NCI,BIOMEDWARE,R44,2006,500182,0.007574308293261705
"Simulation Algorithms for Spatial Pattern Recognition    DESCRIPTION (provided by applicant):    This SBIR project is developing methods and software for the specification, construction and simulation of neutral spatial models, and for applying these neutral models within the framework of probabilistic pattern recognition. Results will allow epidemiologists, environmental scientists and image analysts across a broad range of commercial disciplines to more accurately identify patterns in spatial data by removing the bias towards false positives that is caused by unrealistic null hypotheses such as ""complete spatial randomness"" (CSR). This project will accomplish 5 aims:      1. Conduct a requirements analysis to specify the neutral models and functionality to incorporate in the software.   2. Develop and test a software prototype to evaluate feasibility of the proposed models.   3. Propose a topology of neutral models and develop strategies to generate them and to conduct sensitivity analysis for investigating the impact of implicit assumptions (i.e. spatial autocorrelation or non-uniform risk) and number of realizations on test results.   4. Incorporate the neutral models in the first commercially established software package that allows for user-specified alternate hypothesis in spatial statistical tests.   5. Apply the software and methods to demonstrate the approach and its unique benefits for exposure and health risk assessment.      Feasibility of this project was demonstrated in the Phase I. This Phase II project will accomplish aims three through five. These technologic, scientific and commercial innovations will revolutionize our ability to identify, document and assess the probability of spatial patterns relative to neutral models that incorporate realistic local, spatial and multivariate dependencies. The neutral models and methods in this proposal make possible, for the first time ever, evaluation of the sensitivity of the results of cluster or boundary analyses to specification of the null hypothesis.         n/a",Simulation Algorithms for Spatial Pattern Recognition,6863029,R44CA092807,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'human data', 'image processing', 'imaging /visualization /scanning', 'statistics /biometry', 'visual cortex']",NCI,BIOMEDWARE,R44,2005,498368,0.007574308293261705
"Simulation Algorithms for Spatial Pattern Recognition   DESCRIPTION (provided by applicant): A new generation of satellites is imaging       the earth's surface with unprecedented spatial and spectral resolution. With         the ability to identify local features related to environmental exposures, this      high-resolution imagery is gong to revolutionize health risk assessment. The         realization of this potential depends critically on our ability to recognize         spatial patterns on these large images. This project will develop fast spatial       null models for use in statistical pattern recognition, and will accomplish 4        aims.                                                                                                                                                                     (1) Implement fast simulation algorithms conditioned on properties of the data,      and on spatial functions;                                                            (2) Assess project feasibility by evaluating the performance of these                algorithms on existing high-resolution, hyperspectral imagery;                       (3) Implement the simulation algorithms in 2 commercial spatial analysis             software packages;                                                                   (4) Apply the software and methods to demonstrate the approach and unique            benefits for risk assessment.                                                                                                                                             The phase 1 research will address the first two aims; aims three and four will       be accomplished in phase 2 once feasibility is demonstrated. The technologic         and scientific innovations from this project are expected to greatly enhance         our ability to extract knowledge from high resolution imagery.                       PROPOSED COMMERCIAL APPLICATION:  The imminent launch of over a dozen satellites capable of high-resolution imagery is giving  health researchers powerful new data for relating environmental features to health   outcomes, but existing software packages cannot undertake spatial analysis of these  extraordinarly large data sets.   The fast simulation algorithms from this research will  be incorporated into 2 commercial software packages, providing advanced spatial  analysis for large imagery.                                                                                     n/a",Simulation Algorithms for Spatial Pattern Recognition,6401389,R43CA092807,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data management', ' image processing', ' imaging /visualization /scanning', ' statistics /biometry']",NCI,BIOMEDWARE,R43,2001,170490,0.009667243634267408
"Systematic Review and Meta-Analysis of COPD Genetic Studies    DESCRIPTION (provided by applicant): COPD is the fourth leading cause of the death in the United States and the fifth most common cause of death worldwide. The rapidly increasing knowledge of human genetic variation offers hope for new treatments and more accurate risk prediction tools for COPD. With the large volume of genetic data available for COPD association testing, it is important to develop a publicly accessible research infrastructure for accessing, organizing, and synthesizing genetic association data. As one means of accomplishing this task, The Human Genome Epidemiology Network has emphasized the need for disease specific, regularly updated systematic reviews and meta-analyses of genetic association studies. This proposal will conduct a comprehensive search of the literature in order to: 1.) Conduct a detailed descriptive assessment of all published studies of common genetic variants and COPD. 2.) Perform a quantitative meta-analysis of genetic loci studied in three or more independent study populations. 3.) Produce visual maps of the human genome representing the amount of research performed and the number of positive associations reported for particular genomic areas. Using data gathered from the descriptive assessment, we will quantify between-study heterogeneity in genetic effect size and identify causes of this heterogeneity. We will also incorporate primary data from a pending genome-wide association study (one of the first such studies in COPD) into the meta-analysis and visual maps. This project will accomplish the initial work required to establish an online, publicly available compendium of COPD genetic associations similar to preexisting websites for other complex diseases such as AlzGene and PDGene. The development of an online, publicly available database to compile and synthesize information from COPD genetic studies will be a major benefit to the COPD research community, and will help to fulfill one of the missions of the NHLBI to promote research leading to improved prevention, diagnosis, and treatment of COPD. PUBLIC HEALTH RELEVANCE: The proposed research will provide needed infrastructure for the research field of COPD genetics. It will aid current efforts to identify the genetic causes of COPD. Understanding these genetic causes will lead to better treatments for COPD.             n/a",Systematic Review and Meta-Analysis of COPD Genetic Studies,7545112,F32HL094035,"['Alzheimer&apos', 's Disease', 'Area', 'Biomass', 'Case-Control Studies', 'Cause of Death', 'Chronic', 'Chronic Obstructive Airway Disease', 'Collaborations', 'Communities', 'Complex', 'Confidence Intervals', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Association', 'Disease regression', 'Environment', 'Environmental Exposure', 'Epidemiology', 'Future', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genomics', 'Hereditary Disease', 'Heterogeneity', 'Human Genetics', 'Human Genome', 'Individual', 'Knowledge', 'Lead', 'Literature', 'Lung diseases', 'Maps', 'Mentors', 'Meta-Analysis', 'Methods', 'Mission', 'Morbidity - disease rate', 'Numbers', 'Odds Ratio', 'Online Systems', 'Parkinson Disease', 'Population Study', 'Prevention', 'Public Health', 'Publishing', 'Relative (related person)', 'Reporting', 'Reproducibility', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Respiratory physiology', 'Review, Systematic (PT)', 'Risk', 'Scanning', 'Smoke', 'Smoker', 'Staging', 'Statistically Significant', 'Testing', 'Tobacco', 'United States', 'Update', 'Variant', 'Visual', 'Work', 'concept', 'disability', 'genetic association', 'genetic variant', 'genome wide association study', 'improved', 'mortality', 'prevent', 'size', 'smoking cessation', 'text searching', 'tool', 'visual map']",NHLBI,TUFTS MEDICAL CENTER,F32,2008,71006,-0.020674074212017113
"Modulation of Lung Disease by Genetic/Epigenetic Profiling Project Summary/Abstract Therapeutic management of lung disorders hallmarked by the loss-of-function of the Cystic Fibrosis (CF) Transmembrane conductance Regulator (CFTR) leading to CF are challenged by genetic and epigenetic diversity found in the CF population. Given the Precision Medicine Initiative (All of Us for You (https://allofus.nih.gov/) and the large amount of genomic and phenomic diversity found in patients, it is now generally recognized that we must find new approaches to address the complexity in CF presentation in the clinic. This will require an understanding of fundamental principles dictating disease onset at birth, defined by familial genetic variation, and its progression, influenced by epigenetic programs, both unique to the individual. This proposal is about understanding the role of genetic and epigenetic diversity in CF in response to Histone DeACetylase (HDAC) activity. We have shown these relationships to be responsive to the activity of HDACs, proteins that manage the acetylation/deacetylation balance of the genome and the proteome (the epigenome) to integrate the complex functions linking the genome to the proteome and phenome. Based on the premise that the genome and epigenome are sensitive to manipulation(s) that will favor increased functionality of the CFTR variant fold, the objective of this proposal is to mechanistically define the impact of HDAC modulation on CFTR function observed at the bench and the bedside. We hypothesize that CF can be best understood based on the rationale that disease can be defined by the collective of variation found in the CF population that alters CFTR sequence-to-function-to-structure relationships in the individual as now described using Variation Spatial Profiling (VSP) and the new principle of Spatial CoVariance (SCV) (Wang and Balch, 2018, In press). It is the objective of this proposal to apply VSP/SCV to analysis of the role of the epigenome in CF. Key goals to be achieved in this proposal are to 1) define molecular, cellular and physiological states that 2) describe the role of genetic/epigenetic/proteomic diversity in the CF population to 3) provide a sequence-to-function-to-structure characterization of disease in the individual. Aim 1 will explore the impact of HDAC inhibitors (HDACi) to define, from a biochemical/genetic diversity perspective, how variation across the entire CF population will respond to rebalancing of acetylation/deacetylation dynamics. Aim 2 will focus on the role of HDAC7 in the management of CF genetic diversity using molecular, biochemical and cellular approaches. Aim 3 will analyze the role of select HDAC7-sensitive CFTR interactors to address their role in the management of CF variation from an epigenetic perspective. We hypothesize that the completion of these Aims will describe relationships in the population that define the epigenome-linked genome features that impact progression of CF in the individual. Our integrated genome/epigenome/proteome platform will advance our understanding of the contribution of genetic diversity in the progression and management of CF as a complex disease. Project Narrative CF is a complex loss-of-function disease caused by genetic and epigenetic variation in the Cystic Fibrosis Transmembrane conductance Regulator (CFTR). We will focus on understanding spatial relationships defined by genetic diversity across the CF population that are sensitive to Histone DeACetylase (HDAC) activity to understand the role of the acetylation/deacetylation balance in facilitating function in the individual. We will use a combination of genomic/epigenomic/proteomic approaches based on the principles of Variation Spatial Profiling (VSP) and Spatial CoVariance (SCV) to dissect the role of HDAC in integrated pathways that affect CFTR variant synthesis, folding, trafficking and stability/function at the cell surface that may be responsive to chemical and/or biological manipulation of the epigenome.",Modulation of Lung Disease by Genetic/Epigenetic Profiling,9928091,R01HL095524,"['Acetylation', 'Address', 'Affect', 'Amino Acids', 'Automobile Driving', 'Biochemical', 'Biochemical Genetics', 'Biological', 'Biology', 'Birth', 'Cell Death', 'Cell surface', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Collection', 'Complex', 'Cystic Fibrosis', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Deacetylation', 'Disease', 'Disease Progression', 'Environment', 'Epigenetic Process', 'Equilibrium', 'Fibrosis', 'Funding', 'Gaussian model', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'HDAC7 histone deacetylase', 'Health', 'Histone Deacetylase', 'Histone Deacetylase Inhibitor', 'Human', 'Immune', 'Individual', 'Inflammatory Response', 'Lead', 'Link', 'Lung diseases', 'Machine Learning', 'Membrane', 'Mendelian disorder', 'Modification', 'Molecular', 'Mucous body substance', 'Onset of illness', 'Pathology', 'Pathway interactions', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Precision Medicine Initiative', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Publications', 'Role', 'Structure', 'System', 'Therapeutic', 'Tissues', 'Variant', 'base', 'bench to bedside', 'cystic fibrosis patients', 'epigenetic profiling', 'epigenetic variation', 'epigenome', 'epigenomics', 'genomic platform', 'healthspan', 'insight', 'loss of function', 'novel strategies', 'phenome', 'phenomics', 'programs', 'response', 'spatial relationship', 'success', 'trafficking', 'transcription factor']",NHLBI,SCRIPPS RESEARCH INSTITUTE,R01,2020,483750,-0.04380156464720561
"Modulation of Lung Disease by Genetic/Epigenetic Profiling Project Summary/Abstract Therapeutic management of lung disorders hallmarked by the loss-of-function of the Cystic Fibrosis (CF) Transmembrane conductance Regulator (CFTR) leading to CF are challenged by genetic and epigenetic diversity found in the CF population. Given the Precision Medicine Initiative (All of Us for You (https://allofus.nih.gov/) and the large amount of genomic and phenomic diversity found in patients, it is now generally recognized that we must find new approaches to address the complexity in CF presentation in the clinic. This will require an understanding of fundamental principles dictating disease onset at birth, defined by familial genetic variation, and its progression, influenced by epigenetic programs, both unique to the individual. This proposal is about understanding the role of genetic and epigenetic diversity in CF in response to Histone DeACetylase (HDAC) activity. We have shown these relationships to be responsive to the activity of HDACs, proteins that manage the acetylation/deacetylation balance of the genome and the proteome (the epigenome) to integrate the complex functions linking the genome to the proteome and phenome. Based on the premise that the genome and epigenome are sensitive to manipulation(s) that will favor increased functionality of the CFTR variant fold, the objective of this proposal is to mechanistically define the impact of HDAC modulation on CFTR function observed at the bench and the bedside. We hypothesize that CF can be best understood based on the rationale that disease can be defined by the collective of variation found in the CF population that alters CFTR sequence-to-function-to-structure relationships in the individual as now described using Variation Spatial Profiling (VSP) and the new principle of Spatial CoVariance (SCV) (Wang and Balch, 2018, In press). It is the objective of this proposal to apply VSP/SCV to analysis of the role of the epigenome in CF. Key goals to be achieved in this proposal are to 1) define molecular, cellular and physiological states that 2) describe the role of genetic/epigenetic/proteomic diversity in the CF population to 3) provide a sequence-to-function-to-structure characterization of disease in the individual. Aim 1 will explore the impact of HDAC inhibitors (HDACi) to define, from a biochemical/genetic diversity perspective, how variation across the entire CF population will respond to rebalancing of acetylation/deacetylation dynamics. Aim 2 will focus on the role of HDAC7 in the management of CF genetic diversity using molecular, biochemical and cellular approaches. Aim 3 will analyze the role of select HDAC7-sensitive CFTR interactors to address their role in the management of CF variation from an epigenetic perspective. We hypothesize that the completion of these Aims will describe relationships in the population that define the epigenome-linked genome features that impact progression of CF in the individual. Our integrated genome/epigenome/proteome platform will advance our understanding of the contribution of genetic diversity in the progression and management of CF as a complex disease. Project Narrative CF is a complex loss-of-function disease caused by genetic and epigenetic variation in the Cystic Fibrosis Transmembrane conductance Regulator (CFTR). We will focus on understanding spatial relationships defined by genetic diversity across the CF population that are sensitive to Histone DeACetylase (HDAC) activity to understand the role of the acetylation/deacetylation balance in facilitating function in the individual. We will use a combination of genomic/epigenomic/proteomic approaches based on the principles of Variation Spatial Profiling (VSP) and Spatial CoVariance (SCV) to dissect the role of HDAC in integrated pathways that affect CFTR variant synthesis, folding, trafficking and stability/function at the cell surface that may be responsive to chemical and/or biological manipulation of the epigenome.",Modulation of Lung Disease by Genetic/Epigenetic Profiling,9739114,R01HL095524,"['Acetylation', 'Address', 'Affect', 'Amino Acids', 'Automobile Driving', 'Biochemical', 'Biochemical Genetics', 'Biological', 'Biology', 'Birth', 'Cell Death', 'Cell surface', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Collection', 'Complex', 'Cystic Fibrosis', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Deacetylation', 'Disease', 'Disease Progression', 'Environment', 'Epigenetic Process', 'Equilibrium', 'Fibrosis', 'Funding', 'Gaussian model', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'HDAC7 histone deacetylase', 'Health', 'Histone Deacetylase', 'Histone Deacetylase Inhibitor', 'Human', 'Immune', 'Individual', 'Inflammatory Response', 'Lead', 'Link', 'Lung diseases', 'Machine Learning', 'Membrane', 'Mendelian disorder', 'Modification', 'Molecular', 'Mucous body substance', 'Onset of illness', 'Pathology', 'Pathway interactions', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Precision Medicine Initiative', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Publications', 'Role', 'Structure', 'System', 'Therapeutic', 'Tissues', 'Variant', 'base', 'bench to bedside', 'cystic fibrosis patients', 'epigenetic profiling', 'epigenetic variation', 'epigenome', 'epigenomics', 'genomic platform', 'healthspan', 'insight', 'loss of function', 'novel strategies', 'phenome', 'phenomics', 'programs', 'response', 'spatial relationship', 'success', 'trafficking', 'transcription factor']",NHLBI,SCRIPPS RESEARCH INSTITUTE,R01,2019,483750,-0.04380156464720561
"Novel Statistical methods for DNA Sequencing Data, and applications to Autism. Summary One of the major problems in human genetics is understanding the genetic causes underlying complex phenotypes, including neuropsychiatric traits such as autism spectrum disorders and schizophrenia. Despite tremendous work over the past few decades, the underlying biological mechanisms are poorly understood in most cases. Recent advances in high-throughput, massively parallel genomic technologies have revolutionized the field of human genetics and promise to lead to important scientific advances. Despite this progress in data generation, it remains very challenging to analyze and interpret these data. The main focus of this proposal is the development of powerful statistical methods for the integration of whole-genome sequencing data with rich functional genomics data with the goal to improve the discovery of genes involved in autism spectrum disorders. We propose to integrate data from many different sources, including epigenetic data from projects such as ENCODE, Roadmap, and PsychENCODE, eQTL data from the GTEx, PsychENCODE and CommonMind consortia, data from large scale databases of genetic variation such as ExAC and gnomAD, in order to predict functional effects of genetic variants in non-coding genetic regions in a tissue and cell type specific manner, and generate functional maps across large number of tissues and cell types in the human body that we can then use to identify novel associations with autism in whole-genome sequencing studies. The proposed functional predictions and functional maps will be broadly available in the popular ANNOVAR database. We further propose to use these functional predictions in the analysis of almost 20,000 whole genomes from three large whole genome sequencing studies for autism. We believe that the proposed research is very timely and has the potential to substantially improve the analysis of non-coding genetic variation, and hence provide new insights into the biological mechanisms underlying risk to autism, and more broadly to other neuropsychiatric diseases. Narrative Autism Spectrum Disorders are common diseases with major impact on public health. Although coding variation has been extensively studied for its role in affecting risk to autism, the analysis of non-coding variation poses tremendous challenges. The proposed statistical methods and their applications to nearly 20,000 whole genomes from three large autism whole genome sequencing studies will improve our understanding of the biological mechanisms involved in autism with important implications for disease treatment strategies.","Novel Statistical methods for DNA Sequencing Data, and applications to Autism.",9923466,R01MH095797,"['Affect', 'Anterior', 'Biochemical', 'Biological', 'Biological Assay', 'Brain region', 'Chromatin', 'Code', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Encyclopedia of DNA Elements', 'Epigenetic Process', 'Generations', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human body', 'Individual', 'International', 'Lead', 'Maps', 'Measures', 'Methods', 'Molecular', 'Phenotype', 'Prefrontal Cortex', 'Public Health', 'Research', 'Risk', 'Role', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Source', 'Statistical Methods', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'autism spectrum disorder', 'cell type', 'cingulate cortex', 'data integration', 'design', 'epigenomics', 'exome', 'frontal lobe', 'functional genomics', 'gene discovery', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'histone modification', 'improved', 'insight', 'large scale data', 'large-scale database', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'software development', 'supervised learning', 'tool', 'trait', 'treatment strategy', 'whole genome']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,446831,-0.038475737583407846
"Novel Statistical methods for DNA Sequencing Data, and applications to Autism. Summary One of the major problems in human genetics is understanding the genetic causes underlying complex phenotypes, including neuropsychiatric traits such as autism spectrum disorders and schizophrenia. Despite tremendous work over the past few decades, the underlying biological mechanisms are poorly understood in most cases. Recent advances in high-throughput, massively parallel genomic technologies have revolutionized the field of human genetics and promise to lead to important scientific advances. Despite this progress in data generation, it remains very challenging to analyze and interpret these data. The main focus of this proposal is the development of powerful statistical methods for the integration of whole-genome sequencing data with rich functional genomics data with the goal to improve the discovery of genes involved in autism spectrum disorders. We propose to integrate data from many different sources, including epigenetic data from projects such as ENCODE, Roadmap, and PsychENCODE, eQTL data from the GTEx, PsychENCODE and CommonMind consortia, data from large scale databases of genetic variation such as ExAC and gnomAD, in order to predict functional effects of genetic variants in non-coding genetic regions in a tissue and cell type specific manner, and generate functional maps across large number of tissues and cell types in the human body that we can then use to identify novel associations with autism in whole-genome sequencing studies. The proposed functional predictions and functional maps will be broadly available in the popular ANNOVAR database. We further propose to use these functional predictions in the analysis of almost 20,000 whole genomes from three large whole genome sequencing studies for autism. We believe that the proposed research is very timely and has the potential to substantially improve the analysis of non-coding genetic variation, and hence provide new insights into the biological mechanisms underlying risk to autism, and more broadly to other neuropsychiatric diseases. Narrative Autism Spectrum Disorders are common diseases with major impact on public health. Although coding variation has been extensively studied for its role in affecting risk to autism, the analysis of non-coding variation poses tremendous challenges. The proposed statistical methods and their applications to nearly 20,000 whole genomes from three large autism whole genome sequencing studies will improve our understanding of the biological mechanisms involved in autism with important implications for disease treatment strategies.","Novel Statistical methods for DNA Sequencing Data, and applications to Autism.",9735436,R01MH095797,"['Affect', 'Anterior', 'Biochemical', 'Biological', 'Biological Assay', 'Brain region', 'Chromatin', 'Code', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Encyclopedia of DNA Elements', 'Epigenetic Process', 'Generations', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human body', 'Individual', 'International', 'Lead', 'Maps', 'Measures', 'Methods', 'Molecular', 'Phenotype', 'Prefrontal Cortex', 'Public Health', 'Research', 'Risk', 'Role', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Source', 'Statistical Methods', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'autism spectrum disorder', 'cell type', 'cingulate cortex', 'data integration', 'design', 'epigenomics', 'exome', 'frontal lobe', 'functional genomics', 'gene discovery', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'histone modification', 'improved', 'insight', 'large-scale database', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'software development', 'supervised learning', 'tool', 'trait', 'treatment strategy', 'whole genome']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,454366,-0.038475737583407846
"Population mixture in evolutionary and medical genetics DESCRIPTION (provided by applicant): Mixture between populations is a fundamental process that shapes biology, genetic variation, and the risk for disease. Despite its importance, the analytical methods that are available to study mixture on a genome-wide scale are limited. This makes it a priority to develop methods that can analyze this history in the large data sets that are now practical to generate. No federal grant currently supports the development of such methods. This grant proposes to develop methods and make software available for studying mixture. The Aims are:  (1) To develop tools that make inferences about mixture based on allele frequency and haplotype frequency differences.  (2) To develop tools that estimate dates of mixture based on admixture linkage disequilibrium and genetic divergence data.  We expect that this grant will be of value in three areas. (a) It will support the development of methods and user-friendly software that will be important for evolutionary and medical genetics. (b) It will support work that will result in insights relevant to finding disease genes in human populations that are recently or anciently admixed. (c) It will lead to new insights about human history as well as the history of other organisms.  The connection to medical genetics is particularly important. Our laboratory's past work on the evolutionary history of populations has been intertwined with our work on disease gene mapping, and the approaches that we developed in both areas were synergistic. In particular, we have leveraged the history of admixture in human populations to make new gene discoveries and to understand variation in disease risk across populations. We expect to be able to make further connections between evolutionary and medical genetics by developing sophisticated approaches for understanding and modeling population mixture. The history of population mixture is of importance to public health because it determines the genetic variants that individuals and populations inherit, which in turn make some people more or less susceptible to disease. In the last decade, it has become clear that many human populations are the result of mixtures of populations with divergent ancestries: not only African Americans and Latinos, but also South Asians and all non-Africans (who have Neandertal genetic material). For example, our group has developed methods for studying population mixture and directly applied them to discover genetic risk factors for prostate in African Americans. This grant proposes to develop sophisticated methods to understand and quantify mixture in human populations using modern genomic data. We anticipate that a deeper understanding of human population mixture will assist in the development of more powerful methods to discover genetic risk factors for disease.",Population mixture in evolutionary and medical genetics,8881218,R01GM100233,"['Accounting', 'Admixture', 'Affect', 'African American', 'Area', 'Biology', 'Chromosome Mapping', 'Computer software', 'Core Grant', 'Data', 'Data Set', 'Development', 'Disease', 'European', 'Frequencies', 'Funding', 'Gene Frequency', 'Generations', 'Genes', 'Genetic', 'Genetic Drift', 'Genetic Materials', 'Genetic Variation', 'Genetic study', 'Genomics', 'Geography', 'Grant', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Individual', 'Inherited', 'Laboratories', 'Latino', 'Lead', 'Linkage Disequilibrium', 'Medical Genetics', 'Methods', 'Modeling', 'Mutation', 'Organism', 'Paper', 'Phylogenetic Analysis', 'Population', 'Population Study', 'Principal Component Analysis', 'Process', 'Prostate', 'Public Health', 'Publications', 'Recording of previous events', 'Research', 'Shapes', 'Software Tools', 'South Asian', 'Stratification', 'Testing', 'Trees', 'United States National Institutes of Health', 'Variant', 'Work', 'Writing', 'analytical method', 'base', 'design', 'disorder risk', 'gene discovery', 'genetic linkage', 'genetic risk factor', 'genetic variant', 'genome-wide', 'human disease', 'insight', 'meetings', 'method development', 'migration', 'next generation sequencing', 'novel', 'pathogen', 'programs', 'statistics', 'tool', 'user friendly software']",NIGMS,HARVARD MEDICAL SCHOOL,R01,2015,233068,-0.018037655920543863
"Population mixture in evolutionary and medical genetics    DESCRIPTION (provided by applicant): Mixture between populations is a fundamental process that shapes biology, genetic variation, and the risk for disease. Despite its importance, the analytical methods that are available to study mixture on a genome-wide scale are limited. This makes it a priority to develop methods that can analyze this history in the large data sets that are now practical to generate. No federal grant currently supports the development of such methods. This grant proposes to develop methods and make software available for studying mixture. The Aims are:  (1) To develop tools that make inferences about mixture based on allele frequency and haplotype frequency differences.  (2) To develop tools that estimate dates of mixture based on admixture linkage disequilibrium and genetic divergence data.  We expect that this grant will be of value in three areas. (a) It will support the development of methods and user-friendly software that will be important for evolutionary and medical genetics. (b) It will support work that will result in insights relevant to finding disease genes in human populations that are recently or anciently admixed. (c) It will lead to new insights about human history as well as the history of other organisms.  The connection to medical genetics is particularly important. Our laboratory's past work on the evolutionary history of populations has been intertwined with our work on disease gene mapping, and the approaches that we developed in both areas were synergistic. In particular, we have leveraged the history of admixture in human populations to make new gene discoveries and to understand variation in disease risk across populations. We expect to be able to make further connections between evolutionary and medical genetics by developing sophisticated approaches for understanding and modeling population mixture.        The history of population mixture is of importance to public health because it determines the genetic variants that individuals and populations inherit, which in turn make some people more or less susceptible to disease. In the last decade, it has become clear that many human populations are the result of mixtures of populations with divergent ancestries: not only African Americans and Latinos, but also South Asians and all non-Africans (who have Neandertal genetic material). For example, our group has developed methods for studying population mixture and directly applied them to discover genetic risk factors for prostate in African Americans. This grant proposes to develop sophisticated methods to understand and quantify mixture in human populations using modern genomic data. We anticipate that a deeper understanding of human population mixture will assist in the development of more powerful methods to discover genetic risk factors for disease.            ",Population mixture in evolutionary and medical genetics,8608552,R01GM100233,"['Accounting', 'Admixture', 'Affect', 'African American', 'Area', 'Biology', 'Cancer Center Support Grant', 'Chromosome Mapping', 'Computer software', 'Data', 'Data Set', 'Development', 'Disease', 'Disease Association', 'European', 'Frequencies', 'Funding', 'Gene Frequency', 'Generations', 'Genes', 'Genetic', 'Genetic Drift', 'Genetic Materials', 'Genetic Variation', 'Genomics', 'Geography', 'Grant', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Individual', 'Inherited', 'Laboratories', 'Latino', 'Lead', 'Linkage Disequilibrium', 'Medical Genetics', 'Methods', 'Modeling', 'Mutation', 'Organism', 'Paper', 'Phylogenetic Analysis', 'Population', 'Population Study', 'Principal Component Analysis', 'Process', 'Prostate', 'Public Health', 'Publications', 'Recording of previous events', 'Research', 'Shapes', 'Software Tools', 'South Asian', 'Stratification', 'Testing', 'Trees', 'United States National Institutes of Health', 'Variant', 'Work', 'Writing', 'analytical method', 'base', 'design', 'disorder risk', 'gene discovery', 'genetic linkage', 'genetic risk factor', 'genetic variant', 'genome-wide', 'human disease', 'insight', 'meetings', 'method development', 'migration', 'next generation sequencing', 'novel', 'pathogen', 'programs', 'statistics', 'tool', 'user friendly software']",NIGMS,HARVARD MEDICAL SCHOOL,R01,2014,235659,-0.018037655920543863
"Population mixture in evolutionary and medical genetics    DESCRIPTION (provided by applicant): Mixture between populations is a fundamental process that shapes biology, genetic variation, and the risk for disease. Despite its importance, the analytical methods that are available to study mixture on a genome-wide scale are limited. This makes it a priority to develop methods that can analyze this history in the large data sets that are now practical to generate. No federal grant currently supports the development of such methods. This grant proposes to develop methods and make software available for studying mixture. The Aims are:  (1) To develop tools that make inferences about mixture based on allele frequency and haplotype frequency differences.  (2) To develop tools that estimate dates of mixture based on admixture linkage disequilibrium and genetic divergence data.  We expect that this grant will be of value in three areas. (a) It will support the development of methods and user-friendly software that will be important for evolutionary and medical genetics. (b) It will support work that will result in insights relevant to finding disease genes in human populations that are recently or anciently admixed. (c) It will lead to new insights about human history as well as the history of other organisms.  The connection to medical genetics is particularly important. Our laboratory's past work on the evolutionary history of populations has been intertwined with our work on disease gene mapping, and the approaches that we developed in both areas were synergistic. In particular, we have leveraged the history of admixture in human populations to make new gene discoveries and to understand variation in disease risk across populations. We expect to be able to make further connections between evolutionary and medical genetics by developing sophisticated approaches for understanding and modeling population mixture.        The history of population mixture is of importance to public health because it determines the genetic variants that individuals and populations inherit, which in turn make some people more or less susceptible to disease. In the last decade, it has become clear that many human populations are the result of mixtures of populations with divergent ancestries: not only African Americans and Latinos, but also South Asians and all non-Africans (who have Neandertal genetic material). For example, our group has developed methods for studying population mixture and directly applied them to discover genetic risk factors for prostate in African Americans. This grant proposes to develop sophisticated methods to understand and quantify mixture in human populations using modern genomic data. We anticipate that a deeper understanding of human population mixture will assist in the development of more powerful methods to discover genetic risk factors for disease.            ",Population mixture in evolutionary and medical genetics,8461149,R01GM100233,"['Accounting', 'Admixture', 'Affect', 'African American', 'Area', 'Biology', 'Cancer Center Support Grant', 'Chromosome Mapping', 'Computer software', 'Data', 'Data Set', 'Development', 'Disease', 'Disease Association', 'European', 'Frequencies', 'Funding', 'Gene Frequency', 'Generations', 'Genes', 'Genetic', 'Genetic Drift', 'Genetic Materials', 'Genetic Variation', 'Genomics', 'Geography', 'Grant', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Individual', 'Inherited', 'Laboratories', 'Latino', 'Lead', 'Linkage Disequilibrium', 'Medical Genetics', 'Methods', 'Modeling', 'Mutation', 'Organism', 'Paper', 'Phylogenetic Analysis', 'Population', 'Population Study', 'Principal Component Analysis', 'Process', 'Prostate', 'Public Health', 'Publications', 'Recording of previous events', 'Research', 'Shapes', 'Software Tools', 'South Asian', 'Stratification', 'Testing', 'Trees', 'United States National Institutes of Health', 'Variant', 'Work', 'Writing', 'analytical method', 'base', 'design', 'disorder risk', 'gene discovery', 'genetic linkage', 'genetic risk factor', 'genetic variant', 'genome-wide', 'human disease', 'insight', 'meetings', 'method development', 'migration', 'next generation sequencing', 'novel', 'pathogen', 'programs', 'statistics', 'tool', 'user friendly software']",NIGMS,HARVARD MEDICAL SCHOOL,R01,2013,276772,-0.018037655920543863
"Population mixture in evolutionary and medical genetics    DESCRIPTION (provided by applicant): Mixture between populations is a fundamental process that shapes biology, genetic variation, and the risk for disease. Despite its importance, the analytical methods that are available to study mixture on a genome-wide scale are limited. This makes it a priority to develop methods that can analyze this history in the large data sets that are now practical to generate. No federal grant currently supports the development of such methods. This grant proposes to develop methods and make software available for studying mixture. The Aims are:  (1) To develop tools that make inferences about mixture based on allele frequency and haplotype frequency differences.  (2) To develop tools that estimate dates of mixture based on admixture linkage disequilibrium and genetic divergence data.  We expect that this grant will be of value in three areas. (a) It will support the development of methods and user-friendly software that will be important for evolutionary and medical genetics. (b) It will support work that will result in insights relevant to finding disease genes in human populations that are recently or anciently admixed. (c) It will lead to new insights about human history as well as the history of other organisms.  The connection to medical genetics is particularly important. Our laboratory's past work on the evolutionary history of populations has been intertwined with our work on disease gene mapping, and the approaches that we developed in both areas were synergistic. In particular, we have leveraged the history of admixture in human populations to make new gene discoveries and to understand variation in disease risk across populations. We expect to be able to make further connections between evolutionary and medical genetics by developing sophisticated approaches for understanding and modeling population mixture.      PUBLIC HEALTH RELEVANCE: The history of population mixture is of importance to public health because it determines the genetic variants that individuals and populations inherit, which in turn make some people more or less susceptible to disease. In the last decade, it has become clear that many human populations are the result of mixtures of populations with divergent ancestries: not only African Americans and Latinos, but also South Asians and all non-Africans (who have Neandertal genetic material). For example, our group has developed methods for studying population mixture and directly applied them to discover genetic risk factors for prostate in African Americans. This grant proposes to develop sophisticated methods to understand and quantify mixture in human populations using modern genomic data. We anticipate that a deeper understanding of human population mixture will assist in the development of more powerful methods to discover genetic risk factors for disease.              The history of population mixture is of importance to public health because it determines the genetic variants that individuals and populations inherit, which in turn make some people more or less susceptible to disease. In the last decade, it has become clear that many human populations are the result of mixtures of populations with divergent ancestries: not only African Americans and Latinos, but also South Asians and all non-Africans (who have Neandertal genetic material). For example, our group has developed methods for studying population mixture and directly applied them to discover genetic risk factors for prostate in African Americans. This grant proposes to develop sophisticated methods to understand and quantify mixture in human populations using modern genomic data. We anticipate that a deeper understanding of human population mixture will assist in the development of more powerful methods to discover genetic risk factors for disease.            ",Population mixture in evolutionary and medical genetics,8220483,R01GM100233,"['Accounting', 'Admixture', 'Affect', 'African American', 'Area', 'Biology', 'Cancer Center Support Grant', 'Chromosome Mapping', 'Computer software', 'Data', 'Data Set', 'Development', 'Disease', 'Disease Association', 'European', 'Frequencies', 'Funding', 'Gene Frequency', 'Generations', 'Genes', 'Genetic', 'Genetic Drift', 'Genetic Materials', 'Genetic Variation', 'Genomics', 'Geography', 'Grant', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Individual', 'Inherited', 'Laboratories', 'Latino', 'Lead', 'Linkage Disequilibrium', 'Medical Genetics', 'Methods', 'Modeling', 'Mutation', 'Organism', 'Paper', 'Phylogenetic Analysis', 'Population', 'Population Study', 'Principal Component Analysis', 'Process', 'Prostate', 'Public Health', 'Publications', 'Recording of previous events', 'Research', 'Shapes', 'Software Tools', 'South Asian', 'Stratification', 'Testing', 'Trees', 'United States National Institutes of Health', 'Variant', 'Work', 'Writing', 'analytical method', 'base', 'design', 'disorder risk', 'gene discovery', 'genetic linkage', 'genetic risk factor', 'genetic variant', 'genome-wide', 'human disease', 'insight', 'meetings', 'method development', 'migration', 'next generation', 'novel', 'pathogen', 'programs', 'statistics', 'tool', 'user friendly software']",NIGMS,HARVARD MEDICAL SCHOOL,R01,2012,321100,-0.03157150723176989
"Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid DESCRIPTION (provided by applicant): Cell membrane heterogeneity, such as raft (-like) domains, plays an essential and active role in various cellular processes and pathogeneses. Yet, the heterogeneity is poorly understood. A main difficulty is the lack of appropriate techniques for molecular organization examination of living cell plasma membranes. Current technical approaches often need labeling, which induce artifacts, such as photo-oxidation. Their temporal and spatial resolutions are also often limited. In this project, label-free, non-intrusive radio frequency (RF) scanning techniques will be developed to fill the instrumentation gap. The obtained RF scanners have 100-nm or better spatial resolution and ~ 10 μs temporal resolution. The relative concentration levels of cholesterol, n-3 polyunsaturated fatty acids (PUFA) and sphingomyelin (SPM) in raft (-like) lipid domains of living B cells will be obtained.  The functionality of the developed ultra-sensitive RF scanners is based on measuring local capacitance and conductance of membrane organizations at multiple frequencies. It is hypothesized that measurements over a wide-frequency-range capture molecular- and structure-specific information, such as the relaxation time and dispersion of molecular organizations. Then inverse effective-medium-theory enables the identification and analysis of the targeted molecular components and structures. Thus, the obtained RF specificity enables label-free and non-intrusive imaging. To achieve sufficient RF sensitivity, it is hypothesized that an interference process eliminates RF probing waves at the output-port while preserving minute membrane domain signals. The two working hypotheses are based on the PI's preliminary results and the results from other research groups. To test the central hypothesis, which consists of the two working hypotheses, super- sensitive, high-resolution, multi-frequency RF scanners will be designed, fabricated, and tested. In addition to hydraulic approaches, a 3D electrode structure will be included for electrical manipulation and control of cell positions for F scanning. To identify the quantitative relationship between plasma membrane organizations and their RF properties, the raft (-like) domains of ternary giant-unilamellar-vesicle (GUV) lipid bilayers and B cell plasma membranes will be characterized. The domains will be modified by adjusting molecular compositions during synthesis for GUVs and feeding n-3 polyunsaturated fatty acids of different doses for B cells. Comparisons with the results obtained from conventional imaging and molecular composition analysis methods will be conducted to help verify the RF techniques.  The main contribution of the proposed research is a label-free, non-invasive and ultra-sensitive RF scanning technique with RF specificity for living cell membrane heterogeneity studies. The spatial resolution is 100 nm or better, and the temporal resolution is ~10 μs. Additionally, the concentration of cholesterol, SPM, and n-3 PUFA in the lipid raft (-like) domains of living B cells will be obtained with the RF scanners. The RF scanners provide a critical technique for quantitative characterization of living-cell-plasma-membrane heterogeneity and facilitate the understanding of diverse cellular processes and pathogeneses. The obtained knowledge on B cells helps identify new mechanisms through which n-3 PUFAs exert their effects.",Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid,9130189,K25GM100480,"['B-Lymphocytes', 'Back', 'Biological Models', 'Biology', 'Cell Differentiation process', 'Cell Membrane Structures', 'Cell membrane', 'Cell physiology', 'Cells', 'Cholesterol', 'Complement', 'Data', 'Detergents', 'Disease', 'Dose', 'Electric Capacitance', 'Electrodes', 'Engineering', 'Frequencies', 'Goals', 'HIV', 'Heterogeneity', 'Image', 'Imaging Device', 'Investigation', 'Knowledge', 'Label', 'Life', 'Lipid Bilayers', 'Lipids', 'Liquid substance', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Membrane', 'Membrane Fusion', 'Membrane Lipids', 'Membrane Microdomains', 'Membrane Structure and Function', 'Methods', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Morphologic artifacts', 'N-3 polyunsaturated fatty acid', 'Outcome', 'Output', 'Pathogenesis', 'Physics', 'Play', 'Polyunsaturated Fatty Acids', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Publications', 'Relaxation', 'Research', 'Resolution', 'Role', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'Spectrum Analysis', 'Sphingomyelins', 'Structure', 'Support Groups', 'Suspension substance', 'Suspensions', 'Techniques', 'Testing', 'Time', 'Vesicle', 'Virus', 'Work', 'Yeasts', 'base', 'design', 'electrical property', 'experience', 'feeding', 'information organization', 'insight', 'instrument', 'instrumentation', 'mathematical model', 'membrane model', 'molecular imaging', 'nanometer', 'optical imaging', 'oxidation', 'particle', 'radio frequency', 'sensor', 'single molecule', 'temporal measurement', 'theories', 'unilamellar vesicle', 'web site']",NIGMS,CLEMSON UNIVERSITY,K25,2016,144703,0.033369562641915665
"Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid DESCRIPTION (provided by applicant): Cell membrane heterogeneity, such as raft (-like) domains, plays an essential and active role in various cellular processes and pathogeneses. Yet, the heterogeneity is poorly understood. A main difficulty is the lack of appropriate techniques for molecular organization examination of living cell plasma membranes. Current technical approaches often need labeling, which induce artifacts, such as photo-oxidation. Their temporal and spatial resolutions are also often limited. In this project, label-free, non-intrusive radio frequency (RF) scanning techniques will be developed to fill the instrumentation gap. The obtained RF scanners have 100-nm or better spatial resolution and ~ 10 μs temporal resolution. The relative concentration levels of cholesterol, n-3 polyunsaturated fatty acids (PUFA) and sphingomyelin (SPM) in raft (-like) lipid domains of living B cells will be obtained.  The functionality of the developed ultra-sensitive RF scanners is based on measuring local capacitance and conductance of membrane organizations at multiple frequencies. It is hypothesized that measurements over a wide-frequency-range capture molecular- and structure-specific information, such as the relaxation time and dispersion of molecular organizations. Then inverse effective-medium-theory enables the identification and analysis of the targeted molecular components and structures. Thus, the obtained RF specificity enables label-free and non-intrusive imaging. To achieve sufficient RF sensitivity, it is hypothesized that an interference process eliminates RF probing waves at the output-port while preserving minute membrane domain signals. The two working hypotheses are based on the PI's preliminary results and the results from other research groups. To test the central hypothesis, which consists of the two working hypotheses, super- sensitive, high-resolution, multi-frequency RF scanners will be designed, fabricated, and tested. In addition to hydraulic approaches, a 3D electrode structure will be included for electrical manipulation and control of cell positions for F scanning. To identify the quantitative relationship between plasma membrane organizations and their RF properties, the raft (-like) domains of ternary giant-unilamellar-vesicle (GUV) lipid bilayers and B cell plasma membranes will be characterized. The domains will be modified by adjusting molecular compositions during synthesis for GUVs and feeding n-3 polyunsaturated fatty acids of different doses for B cells. Comparisons with the results obtained from conventional imaging and molecular composition analysis methods will be conducted to help verify the RF techniques.  The main contribution of the proposed research is a label-free, non-invasive and ultra-sensitive RF scanning technique with RF specificity for living cell membrane heterogeneity studies. The spatial resolution is 100 nm or better, and the temporal resolution is ~10 μs. Additionally, the concentration of cholesterol, SPM, and n-3 PUFA in the lipid raft (-like) domains of living B cells will be obtained with the RF scanners. The RF scanners provide a critical technique for quantitative characterization of living-cell-plasma-membrane heterogeneity and facilitate the understanding of diverse cellular processes and pathogeneses. The obtained knowledge on B cells helps identify new mechanisms through which n-3 PUFAs exert their effects.",Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid,8918671,K25GM100480,"['B-Lymphocytes', 'Back', 'Biological Models', 'Biology', 'Cell Differentiation process', 'Cell Membrane Structures', 'Cell membrane', 'Cell physiology', 'Cells', 'Cholesterol', 'Complement', 'Data', 'Detergents', 'Disease', 'Dose', 'Electric Capacitance', 'Electrodes', 'Engineering', 'Frequencies', 'Goals', 'HIV', 'Heterogeneity', 'Image', 'Investigation', 'Knowledge', 'Label', 'Life', 'Lipid Bilayers', 'Lipids', 'Liquid substance', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Membrane', 'Membrane Fusion', 'Membrane Lipids', 'Membrane Microdomains', 'Membrane Structure and Function', 'Methods', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Morphologic artifacts', 'N-3 polyunsaturated fatty acid', 'Outcome', 'Output', 'Pathogenesis', 'Physics', 'Play', 'Polyunsaturated Fatty Acids', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Publications', 'Relative (related person)', 'Relaxation', 'Research', 'Resolution', 'Role', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'Spectrum Analysis', 'Sphingomyelins', 'Structure', 'Support Groups', 'Suspension substance', 'Suspensions', 'Techniques', 'Testing', 'Time', 'Vesicle', 'Virus', 'Work', 'Yeasts', 'base', 'design', 'electrical property', 'experience', 'feeding', 'information organization', 'insight', 'instrument', 'instrumentation', 'mathematical model', 'membrane model', 'molecular imaging', 'nanometer', 'optical imaging', 'oxidation', 'particle', 'radio frequency', 'sensor', 'single molecule', 'spectroscopic imaging', 'temporal measurement', 'theories', 'unilamellar vesicle', 'web site']",NIGMS,CLEMSON UNIVERSITY,K25,2015,144703,0.033369562641915665
"Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid     DESCRIPTION (provided by applicant): Cell membrane heterogeneity, such as raft (-like) domains, plays an essential and active role in various cellular processes and pathogeneses. Yet, the heterogeneity is poorly understood. A main difficulty is the lack of appropriate techniques for molecular organization examination of living cell plasma membranes. Current technical approaches often need labeling, which induce artifacts, such as photo-oxidation. Their temporal and spatial resolutions are also often limited. In this project, label-free, non-intrusive radio frequency (RF) scanning techniques will be developed to fill the instrumentation gap. The obtained RF scanners have 100-nm or better spatial resolution and ~ 10 ?s temporal resolution. The relative concentration levels of cholesterol, n-3 polyunsaturated fatty acids (PUFA) and sphingomyelin (SPM) in raft (-like) lipid domains of living B cells will be obtained.  The functionality of the developed ultra-sensitive RF scanners is based on measuring local capacitance and conductance of membrane organizations at multiple frequencies. It is hypothesized that measurements over a wide-frequency-range capture molecular- and structure-specific information, such as the relaxation time and dispersion of molecular organizations. Then inverse effective-medium-theory enables the identification and analysis of the targeted molecular components and structures. Thus, the obtained RF specificity enables label-free and non-intrusive imaging. To achieve sufficient RF sensitivity, it is hypothesized that an interference process eliminates RF probing waves at the output-port while preserving minute membrane domain signals. The two working hypotheses are based on the PI's preliminary results and the results from other research groups. To test the central hypothesis, which consists of the two working hypotheses, super- sensitive, high-resolution, multi-frequency RF scanners will be designed, fabricated, and tested. In addition to hydraulic approaches, a 3D electrode structure will be included for electrical manipulation and control of cell positions for F scanning. To identify the quantitative relationship between plasma membrane organizations and their RF properties, the raft (-like) domains of ternary giant-unilamellar-vesicle (GUV) lipid bilayers and B cell plasma membranes will be characterized. The domains will be modified by adjusting molecular compositions during synthesis for GUVs and feeding n-3 polyunsaturated fatty acids of different doses for B cells. Comparisons with the results obtained from conventional imaging and molecular composition analysis methods will be conducted to help verify the RF techniques.  The main contribution of the proposed research is a label-free, non-invasive and ultra-sensitive RF scanning technique with RF specificity for living cell membrane heterogeneity studies. The spatial resolution is 100 nm or better, and the temporal resolution is ~10 ?s. Additionally, the concentration of cholesterol, SPM, and n-3 PUFA in the lipid raft (-like) domains of living B cells will be obtained with the RF scanners.          The RF scanners provide a critical technique for quantitative characterization of living-cell-plasma-membrane heterogeneity and facilitate the understanding of diverse cellular processes and pathogeneses. The obtained knowledge on B cells helps identify new mechanisms through which n-3 PUFAs exert their effects.            ",Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid,8733177,K25GM100480,"['B-Lymphocytes', 'Back', 'Biological Models', 'Biology', 'Cell Differentiation process', 'Cell Membrane Structures', 'Cell membrane', 'Cell physiology', 'Cells', 'Cholesterol', 'Complement', 'Data', 'Detergents', 'Disease', 'Dose', 'Electric Capacitance', 'Electrodes', 'Engineering', 'Frequencies', 'Goals', 'HIV', 'Heterogeneity', 'Image', 'Investigation', 'Knowledge', 'Label', 'Life', 'Lipid Bilayers', 'Lipids', 'Liquid substance', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Membrane', 'Membrane Fusion', 'Membrane Lipids', 'Membrane Microdomains', 'Membrane Structure and Function', 'Methods', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Morphologic artifacts', 'N-3 polyunsaturated fatty acid', 'Outcome', 'Output', 'Pathogenesis', 'Physics', 'Play', 'Polyunsaturated Fatty Acids', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Publications', 'Radio', 'Relative (related person)', 'Relaxation', 'Research', 'Resolution', 'Role', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'Spectrum Analysis', 'Sphingomyelins', 'Structure', 'Support Groups', 'Suspension substance', 'Suspensions', 'Techniques', 'Testing', 'Time', 'Virus', 'Work', 'Yeasts', 'base', 'design', 'electrical property', 'experience', 'feeding', 'information organization', 'insight', 'instrument', 'instrumentation', 'mathematical model', 'membrane model', 'molecular imaging', 'nanometer', 'optical imaging', 'oxidation', 'particle', 'sensor', 'single molecule', 'theories', 'unilamellar vesicle', 'web site']",NIGMS,CLEMSON UNIVERSITY,K25,2014,145103,0.033369562641915665
"Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid     DESCRIPTION (provided by applicant): Cell membrane heterogeneity, such as raft (-like) domains, plays an essential and active role in various cellular processes and pathogeneses. Yet, the heterogeneity is poorly understood. A main difficulty is the lack of appropriate techniques for molecular organization examination of living cell plasma membranes. Current technical approaches often need labeling, which induce artifacts, such as photo-oxidation. Their temporal and spatial resolutions are also often limited. In this project, label-free, non-intrusive radio frequency (RF) scanning techniques will be developed to fill the instrumentation gap. The obtained RF scanners have 100-nm or better spatial resolution and ~ 10 ?s temporal resolution. The relative concentration levels of cholesterol, n-3 polyunsaturated fatty acids (PUFA) and sphingomyelin (SPM) in raft (-like) lipid domains of living B cells will be obtained.  The functionality of the developed ultra-sensitive RF scanners is based on measuring local capacitance and conductance of membrane organizations at multiple frequencies. It is hypothesized that measurements over a wide-frequency-range capture molecular- and structure-specific information, such as the relaxation time and dispersion of molecular organizations. Then inverse effective-medium-theory enables the identification and analysis of the targeted molecular components and structures. Thus, the obtained RF specificity enables label-free and non-intrusive imaging. To achieve sufficient RF sensitivity, it is hypothesized that an interference process eliminates RF probing waves at the output-port while preserving minute membrane domain signals. The two working hypotheses are based on the PI's preliminary results and the results from other research groups. To test the central hypothesis, which consists of the two working hypotheses, super- sensitive, high-resolution, multi-frequency RF scanners will be designed, fabricated, and tested. In addition to hydraulic approaches, a 3D electrode structure will be included for electrical manipulation and control of cell positions for F scanning. To identify the quantitative relationship between plasma membrane organizations and their RF properties, the raft (-like) domains of ternary giant-unilamellar-vesicle (GUV) lipid bilayers and B cell plasma membranes will be characterized. The domains will be modified by adjusting molecular compositions during synthesis for GUVs and feeding n-3 polyunsaturated fatty acids of different doses for B cells. Comparisons with the results obtained from conventional imaging and molecular composition analysis methods will be conducted to help verify the RF techniques.  The main contribution of the proposed research is a label-free, non-invasive and ultra-sensitive RF scanning technique with RF specificity for living cell membrane heterogeneity studies. The spatial resolution is 100 nm or better, and the temporal resolution is ~10 ?s. Additionally, the concentration of cholesterol, SPM, and n-3 PUFA in the lipid raft (-like) domains of living B cells will be obtained with the RF scanners.          The RF scanners provide a critical technique for quantitative characterization of living-cell-plasma-membrane heterogeneity and facilitate the understanding of diverse cellular processes and pathogeneses. The obtained knowledge on B cells helps identify new mechanisms through which n-3 PUFAs exert their effects.            ",Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid,8536874,K25GM100480,"['B-Lymphocytes', 'Back', 'Biological Models', 'Biology', 'Cell Differentiation process', 'Cell Membrane Structures', 'Cell membrane', 'Cell physiology', 'Cells', 'Cholesterol', 'Complement', 'Data', 'Detergents', 'Disease', 'Dose', 'Electric Capacitance', 'Electrodes', 'Engineering', 'Frequencies', 'Goals', 'HIV', 'Heterogeneity', 'Image', 'Investigation', 'Knowledge', 'Label', 'Life', 'Lipid Bilayers', 'Lipids', 'Liquid substance', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Membrane', 'Membrane Fusion', 'Membrane Lipids', 'Membrane Microdomains', 'Membrane Structure and Function', 'Methods', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Morphologic artifacts', 'N-3 polyunsaturated fatty acid', 'Outcome', 'Output', 'Pathogenesis', 'Physics', 'Play', 'Polyunsaturated Fatty Acids', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Publications', 'Radio', 'Relative (related person)', 'Relaxation', 'Research', 'Resolution', 'Role', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'Spectrum Analysis', 'Sphingomyelins', 'Structure', 'Support Groups', 'Suspension substance', 'Suspensions', 'Techniques', 'Testing', 'Time', 'Virus', 'Work', 'Yeasts', 'base', 'design', 'electrical property', 'experience', 'feeding', 'information organization', 'insight', 'instrument', 'instrumentation', 'mathematical model', 'membrane model', 'molecular imaging', 'nanometer', 'optical imaging', 'oxidation', 'particle', 'sensor', 'single molecule', 'theories', 'unilamellar vesicle', 'web site']",NIGMS,CLEMSON UNIVERSITY,K25,2013,145503,0.033369562641915665
"Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid     DESCRIPTION (provided by applicant): Cell membrane heterogeneity, such as raft (-like) domains, plays an essential and active role in various cellular processes and pathogeneses. Yet, the heterogeneity is poorly understood. A main difficulty is the lack of appropriate techniques for molecular organization examination of living cell plasma membranes. Current technical approaches often need labeling, which induce artifacts, such as photo-oxidation. Their temporal and spatial resolutions are also often limited. In this project, label-free, non-intrusive radio frequency (RF) scanning techniques will be developed to fill the instrumentation gap. The obtained RF scanners have 100-nm or better spatial resolution and ~ 10 ?s temporal resolution. The relative concentration levels of cholesterol, n-3 polyunsaturated fatty acids (PUFA) and sphingomyelin (SPM) in raft (-like) lipid domains of living B cells will be obtained.  The functionality of the developed ultra-sensitive RF scanners is based on measuring local capacitance and conductance of membrane organizations at multiple frequencies. It is hypothesized that measurements over a wide-frequency-range capture molecular- and structure-specific information, such as the relaxation time and dispersion of molecular organizations. Then inverse effective-medium-theory enables the identification and analysis of the targeted molecular components and structures. Thus, the obtained RF specificity enables label-free and non-intrusive imaging. To achieve sufficient RF sensitivity, it is hypothesized that an interference process eliminates RF probing waves at the output-port while preserving minute membrane domain signals. The two working hypotheses are based on the PI's preliminary results and the results from other research groups. To test the central hypothesis, which consists of the two working hypotheses, super- sensitive, high-resolution, multi-frequency RF scanners will be designed, fabricated, and tested. In addition to hydraulic approaches, a 3D electrode structure will be included for electrical manipulation and control of cell positions for F scanning. To identify the quantitative relationship between plasma membrane organizations and their RF properties, the raft (-like) domains of ternary giant-unilamellar-vesicle (GUV) lipid bilayers and B cell plasma membranes will be characterized. The domains will be modified by adjusting molecular compositions during synthesis for GUVs and feeding n-3 polyunsaturated fatty acids of different doses for B cells. Comparisons with the results obtained from conventional imaging and molecular composition analysis methods will be conducted to help verify the RF techniques.  The main contribution of the proposed research is a label-free, non-invasive and ultra-sensitive RF scanning technique with RF specificity for living cell membrane heterogeneity studies. The spatial resolution is 100 nm or better, and the temporal resolution is ~10 ?s. Additionally, the concentration of cholesterol, SPM, and n-3 PUFA in the lipid raft (-like) domains of living B cells will be obtained with the RF scanners.        PUBLIC HEALTH RELEVANCE: The RF scanners provide a critical technique for quantitative characterization of living-cell-plasma-membrane heterogeneity and facilitate the understanding of diverse cellular processes and pathogeneses. The obtained knowledge on B cells helps identify new mechanisms through which n-3 PUFAs exert their effects.              The RF scanners provide a critical technique for quantitative characterization of living-cell-plasma-membrane heterogeneity and facilitate the understanding of diverse cellular processes and pathogeneses. The obtained knowledge on B cells helps identify new mechanisms through which n-3 PUFAs exert their effects.            ",Label-free RF Imaging of Cell Membrane Heterogeneity in Liquid,8383194,K25GM100480,"['B-Lymphocytes', 'Back', 'Biological Models', 'Biology', 'Cell Differentiation process', 'Cell Membrane Structures', 'Cell membrane', 'Cell physiology', 'Cells', 'Cholesterol', 'Complement', 'Data', 'Detergents', 'Disease', 'Dose', 'Electric Capacitance', 'Electrodes', 'Engineering', 'Frequencies', 'Goals', 'HIV', 'Heterogeneity', 'Image', 'Investigation', 'Knowledge', 'Label', 'Life', 'Lipid Bilayers', 'Lipids', 'Liquid substance', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Membrane', 'Membrane Fusion', 'Membrane Lipids', 'Membrane Microdomains', 'Membrane Structure and Function', 'Methods', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Morphologic artifacts', 'N-3 polyunsaturated fatty acid', 'Outcome', 'Output', 'Pathogenesis', 'Physics', 'Play', 'Polyunsaturated Fatty Acids', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Publications', 'Radio', 'Relative (related person)', 'Relaxation', 'Research', 'Resolution', 'Role', 'Scanning', 'Science', 'Sensitivity and Specificity', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'Spectrum Analysis', 'Sphingomyelins', 'Structure', 'Support Groups', 'Suspension substance', 'Suspensions', 'Techniques', 'Testing', 'Time', 'Virus', 'Work', 'Yeasts', 'base', 'design', 'electrical property', 'experience', 'feeding', 'information organization', 'insight', 'instrument', 'instrumentation', 'mathematical model', 'membrane model', 'molecular imaging', 'nanometer', 'optical imaging', 'oxidation', 'particle', 'sensor', 'single molecule', 'theories', 'unilamellar vesicle', 'web site']",NIGMS,CLEMSON UNIVERSITY,K25,2012,145503,0.03324282222287325
"Dynamics of cellular senescence in single human cells Admin Supplement Project Summary/Abstract  Dynamics of cellular senescence in single human cells  The goal of this proposal is to investigate the timing and control of cellular senescence in single human cells.  Senescence is a state of permanent cell cycle arrest and an inherent defense against tumor progression.  Exploiting senescence for therapeutic gain will require a better understanding of basic senescence biology,  novel experimental tools to study the phenotype at single-cell resolution, and computational approaches to  understand how cells integrate multiple senescence signals. This proposal provides a career transition plan for  Dr. Jeremy Purvis that will equip him with the additional training necessary to study senescence at single-cell  resolution and form the foundation for developing treatments that induce premature senescence in cells with  defective stress responses. During the mentored phase of the award (K99), he will develop a live-cell imaging  system for monitoring DNA damage-induced senescence in real time and use this system to determine how  upstream signaling of the tumor suppressor p53 control expression of senescence markers (Aim 1). This  critical phase of training will be co-supervised by Dr. Galit Lahav and Dr. Peter Sorger (Harvard Medical  School), who are both experts in time-lapse microscopy and cell fate decision processes. During the transition  to independence (K99/R00), he will identify transcriptional regulators that initiate expression of the key  senescence regulator p16INK4a and characterize the dynamics of this transition (Aim 2). The final step in  achieving independence (R00) will involve transferring these tools and concepts to study senescence in  primary cells lines, focusing specifically on how multiple signals are integrated to achieve a senescence  decision (Aim 3). This three-phase transition plan will illuminate our basic understanding of cellular  senescence and provide an extensible computational/experimental platform for identifying therapies that  induce premature senescence in cancer cells. These aims are highly congruent with the NIGMS's primary goal  of supporting basic discoveries that advance the treatment and prevention of human disease. Cellular senescence is a natural biological process that prevents cells from dividing; in some cases,  senescence stops the progression of cancer. The goal of this project is to understand how individual cells enter  senescence by observing this transition in real time.",Dynamics of cellular senescence in single human cells Admin Supplement,8841972,R00GM102372,"['Address', 'Affect', 'Apoptosis', 'Award', 'Biological Assay', 'Biological Process', 'Biology', 'Breast Epithelial Cells', 'CDKN1A gene', 'CDKN2A gene', 'Cell Aging', 'Cell Cycle Arrest', 'Cell Line', 'Cell Proliferation', 'Cells', 'Characteristics', 'Commit', 'Complex', 'DNA Damage', 'Data', 'Doctor of Philosophy', 'Dose', 'End Point Assay', 'Event', 'Exhibits', 'Fibroblasts', 'Foundations', 'Genes', 'Genotoxic Stress', 'Goals', 'Human', 'Hypoxia', 'Image', 'Individual', 'Life', 'MAPK14 gene', 'Machine Learning', 'Mediating', 'Mentors', 'Microscopy', 'Modeling', 'Molecular Profiling', 'Monitor', 'Mus', 'Oncogene Activation', 'Pathway interactions', 'Phase', 'Phase Transition', 'Phenotype', 'Population', 'Prevention', 'Procedures', 'Process', 'Protein p53', 'Regulatory Element', 'Reporter', 'Research', 'Resolution', 'Series', 'Signal Transduction', 'Stress', 'System', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tumor Suppressor Genes', 'abstracting', 'base', 'biological adaptation to stress', 'cancer cell', 'career', 'cell fixing', 'cell type', 'cellular imaging', 'chromatin immunoprecipitation', 'genome-wide', 'human disease', 'in vivo', 'knock-down', 'medical schools', 'novel', 'premature', 'prevent', 'programs', 'response', 'senescence', 'therapeutic target', 'time use', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2014,15522,-0.04705900582986351
"Dynamics of cellular senescence in single human cells Project Summary/Abstract  Dynamics of cellular senescence in single human cells  The goal of this proposal is to investigate the timing and control of cellular senescence in single human cells.  Senescence is a state of permanent cell cycle arrest and an inherent defense against tumor progression.  Exploiting senescence for therapeutic gain will require a better understanding of basic senescence biology,  novel experimental tools to study the phenotype at single-cell resolution, and computational approaches to  understand how cells integrate multiple senescence signals. This proposal provides a career transition plan for  Dr. Jeremy Purvis that will equip him with the additional training necessary to study senescence at single-cell  resolution and form the foundation for developing treatments that induce premature senescence in cells with  defective stress responses. During the mentored phase of the award (K99), he will develop a live-cell imaging  system for monitoring DNA damage-induced senescence in real time and use this system to determine how  upstream signaling of the tumor suppressor p53 control expression of senescence markers (Aim 1). This  critical phase of training will be co-supervised by Dr. Galit Lahav and Dr. Peter Sorger (Harvard Medical  School), who are both experts in time-lapse microscopy and cell fate decision processes. During the transition  to independence (K99/R00), he will identify transcriptional regulators that initiate expression of the key  senescence regulator p16INK4a and characterize the dynamics of this transition (Aim 2). The final step in  achieving independence (R00) will involve transferring these tools and concepts to study senescence in  primary cells lines, focusing specifically on how multiple signals are integrated to achieve a senescence  decision (Aim 3). This three-phase transition plan will illuminate our basic understanding of cellular  senescence and provide an extensible computational/experimental platform for identifying therapies that  induce premature senescence in cancer cells. These aims are highly congruent with the NIGMS's primary goal  of supporting basic discoveries that advance the treatment and prevention of human disease. Cellular senescence is a natural biological process that prevents cells from dividing; in some cases,  senescence stops the progression of cancer. The goal of this project is to understand how individual cells enter  senescence by observing this transition in real time.",Dynamics of cellular senescence in single human cells,8724088,R00GM102372,"['Address', 'Affect', 'Apoptosis', 'Award', 'Biological Assay', 'Biological Process', 'Biology', 'Breast', 'CDKN1A gene', 'CDKN2A gene', 'Cell Aging', 'Cell Cycle Arrest', 'Cell Line', 'Cell Proliferation', 'Cells', 'Characteristics', 'Commit', 'Complex', 'DNA Damage', 'Data', 'Doctor of Philosophy', 'Dose', 'End Point Assay', 'Epithelial Cells', 'Event', 'Exhibits', 'Fibroblasts', 'Foundations', 'Genes', 'Genotoxic Stress', 'Goals', 'Human', 'Hypoxia', 'Image', 'Individual', 'Life', 'MAPK14 gene', 'Machine Learning', 'Mediating', 'Mentors', 'Microscopy', 'Modeling', 'Molecular Profiling', 'Monitor', 'Mus', 'Oncogene Activation', 'Pathway interactions', 'Phase', 'Phase Transition', 'Phenotype', 'Population', 'Prevention', 'Procedures', 'Process', 'Protein p53', 'Regulatory Element', 'Reporter', 'Research', 'Resolution', 'Series', 'Signal Transduction', 'Stress', 'System', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tumor Suppressor Genes', 'abstracting', 'base', 'biological adaptation to stress', 'cancer cell', 'career', 'cell fixing', 'cell type', 'cellular imaging', 'chromatin immunoprecipitation', 'genome-wide', 'human disease', 'in vivo', 'knock-down', 'medical schools', 'novel', 'premature', 'prevent', 'programs', 'response', 'senescence', 'therapeutic target', 'time use', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2013,248330,-0.04705900582986351
"Dynamics of cellular senescence in single human cells     DESCRIPTION (provided by applicant): The goal of this proposal is to investigate the timing and control of cellular senescence in single human cells.  Senescence is a state of permanent cell cycle arrest and an inherent defense against tumor progression.  Exploiting senescence for therapeutic gain will require a better understanding of basic senescence biology, novel experimental tools to study the phenotype at single-cell resolution, and computational approaches to understand how cells integrate multiple senescence signals. This proposal provides a career transition plan for Dr. Jeremy Purvis that will equip him with the additional training necessary to study senescence at single-cell resolution and form the foundation for developing treatments that induce premature senescence in cells with defective stress responses. During the mentored phase of the award (K99), he will develop a live-cell imaging system for monitoring DNA damage-induced senescence in real time and use this system to determine how upstream signaling of the tumor suppressor p53 control expression of senescence markers (Aim 1). This critical phase of training will be co-supervised by Dr. Galit Lahav and Dr. Peter Sorger (Harvard Medical School), who are both experts in time-lapse microscopy and cell fate decision processes. During the transition to independence (K99/R00), he will identify transcriptional regulators that initiate expression of the key senescence regulato p16INK4a and characterize the dynamics of this transition (Aim 2). The final step in achieving independence (R00) will involve transferring these tools and concepts to study senescence in primary cells lines, focusing specifically on how multiple signals are integrated to achieve a senescence decision (Aim 3). This three-phase transition plan will illuminate our basic understanding of cellular senescence and provide an extensible computational/experimental platform for identifying therapies that induce premature senescence in cancer cells. These aims are highly congruent with the NIGMS's primary goal of supporting basic discoveries that advance the treatment and prevention of human disease.    PUBLIC HEALTH RELEVANCE: Cellular senescence is a natural biological process that prevents cells from dividing; in some cases, senescence stops the progression of cancer. The goal of this project is to understand how individual cells enter senescence by observing this transition in real time.                  Cellular senescence is a natural biological process that prevents cells from dividing; in some cases, senescence stops the progression of cancer. The goal of this project is to understand how individual cells enter senescence by observing this transition in real time.                ",Dynamics of cellular senescence in single human cells,8353599,K99GM102372,"['Address', 'Affect', 'Apoptosis', 'Award', 'Biological Assay', 'Biological Process', 'Biology', 'Breast', 'CDKN1A gene', 'CDKN2A gene', 'Cell Aging', 'Cell Cycle Arrest', 'Cell Line', 'Cell Proliferation', 'Cells', 'Characteristics', 'Commit', 'Complex', 'DNA Damage', 'Data', 'Doctor of Philosophy', 'Dose', 'End Point Assay', 'Epithelial Cells', 'Event', 'Exhibits', 'Fibroblasts', 'Foundations', 'Genes', 'Genotoxic Stress', 'Goals', 'Human', 'Hypoxia', 'Image', 'Individual', 'Life', 'MAPK14 gene', 'Machine Learning', 'Mediating', 'Mentors', 'Microscopy', 'Modeling', 'Molecular Profiling', 'Monitor', 'Mus', 'Oncogene Activation', 'Pathway interactions', 'Phase', 'Phase Transition', 'Phenotype', 'Population', 'Prevention', 'Procedures', 'Process', 'Protein p53', 'Regulatory Element', 'Reporter', 'Research', 'Resolution', 'Series', 'Signal Transduction', 'Stress', 'System', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tumor Suppressor Genes', 'base', 'biological adaptation to stress', 'cancer cell', 'career', 'cell fixing', 'cell type', 'cellular imaging', 'chromatin immunoprecipitation', 'genome-wide', 'human disease', 'in vivo', 'medical schools', 'novel', 'premature', 'prevent', 'programs', 'response', 'senescence', 'therapeutic target', 'time use', 'tool', 'tumor', 'tumor progression']",NIGMS,HARVARD MEDICAL SCHOOL,K99,2012,90000,-0.04508128537448601
"Tissue-specific protein interactome mapping in a vertebrate embryo Abstract Proteins rarely act in isolation, but rather function in multi-protein complexes. Accordingly, protein-protein interactomes are exceptionally valuable resources that provide deep mechanistic insights and generate myriad hypotheses. Current methods for interactome mapping, such as affinity purification mass-spectrometry (APMS), are extremely difficult to deploy in vivo, so little comprehensive interactome data yet exists for developing embryos and even less for specific tissues within embryos. This fact poses an especially acute problem for understanding highly dynamic processes in which post-transcriptional controls dominate, for example collective cell movements. Here, we will use tissue engaged in convergent extension, a crucial collective movement that elongates the axis of animal embryos, to test the efficacy of new label-free interactome mapping approaches. Successful completion of the project will therefore be significant both for developing broadly applicable new methods and also for providing systems-level insights into a disease- relevant, vertebrate collective cell movement. Project Narrative: This study centers on developing novel methods for systematically identifying protein-protein interactions in embryos. To explore the utility of the method, we focus our efforts on proteins involved in collective cell movements called convergent extension, which are governed by the planar cell polarity (or PCP) proteins. These experiments will be significant because defects in PCP proteins or convergent extension lead to “neural tube defects” such as spina bifida and anencephaly, as well as congenital skeletal dysplasias.",Tissue-specific protein interactome mapping in a vertebrate embryo,10104048,R21HD103882,"['Actomyosin', 'Acute', 'Adhesions', 'Affinity Chromatography', 'Amphibia', 'Anencephaly and spina bifida X linked', 'Animals', 'Biological', 'Cadherins', 'Cells', 'Cellular biology', 'Communities', 'Data', 'Data Set', 'Defect', 'Developmental Biology', 'Developmental Process', 'Disease', 'Dorsal', 'Embryo', 'Fractionation', 'Genetic', 'In Vitro', 'Label', 'Lead', 'Light', 'Machine Learning', 'Mammals', 'Mass Spectrum Analysis', 'Mesoderm', 'Methods', 'Modeling', 'Molecular', 'Movement', 'Multiprotein Complexes', 'Neural Tube Closure', 'Neural Tube Defects', 'Post-Transcriptional Regulation', 'Process', 'Protein Interaction Mapping', 'Protein-Protein Interaction Map', 'Proteins', 'Proteome', 'Proteomics', 'Rana', 'Resources', 'Sampling', 'Spectrometry', 'System', 'Testing', 'Tissues', 'Vertebrates', 'Work', 'Xenopus', 'base', 'cell motility', 'convergent extension', 'data integration', 'efficacy testing', 'embryo tissue', 'experimental study', 'improved', 'in vivo', 'insight', 'novel', 'planar cell polarity', 'protein complex', 'protein protein interaction', 'skeletal dysplasia', 'success', 'vertebrate embryos']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",R21,2020,237750,0.0072233218449549086
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease. The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,9126587,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Bayesian Modeling', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genetic study', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2016,241086,0.0006607027566849758
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease. The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,8919917,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Bayesian Modeling', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genetic study', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Relative (related person)', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2015,241086,0.0006607027566849758
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations     DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease.              The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.            ",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,8725211,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Bayesian Modeling', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Relative (related person)', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2014,241086,0.0006607027566849758
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations     DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease.              The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.            ",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,8550119,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Relative (related person)', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2013,232648,0.0006607027566849758
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations     DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease.        PUBLIC HEALTH RELEVANCE:     The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.                  The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.            ",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,8420828,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Relative (related person)', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2012,241086,0.0051640278075386035
"Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology ﻿    DESCRIPTION (provided by applicant): Youth with externalizing psychopathologies, including attention-deficit/hyperactivity disorder, oppositional defiant disorder, and conduct disorder, present with diverse kinds of impulsivity symptoms, which in turn reflect deficits in regulatory control functioning. An emerging neurodevelopmental model, which we call the Impulsivity as Immaturity Model, could potentially transform our understanding of the brain basis of regulatory dysfunction. The brain's regulatory control architecture (RCA) undergoes massive maturation during childhood and adolescence. The Impulsivity as Immaturity Model proposes that aberrant maturation in distinct components of the RCA gives rise to distinct patterns of impulsivity symptoms-e.g., delayed maturation in certain attention control components gives rise to attentional variability, a specific form of attention dysfunction. Informed by this model, we will use a mixed cohort/longitudinal design enrolling 135 healthy youth and 135 youth with externalizing psychopathologies. Using advanced multivariate/multimodal analytic methods, we will map the normative neurodevelopmental trajectories of major components of the RCA including components involved in attention, motor, emotion, and appetitive control. We will then construct multivariate models that predict different forms of impulsivity based on neurodevelopment patterns of RCA components. Successful completion of this project will be a critical first step in development of a new class of imaging-based immaturity biomarkers that index distinct types of impulsivity irrespective of the specific externalizing disorders in which they manifest. This will lead to earlier, more reliable diagnosis of impulsivity problems in youth and spur the development of transdiagnostic, biologically based interventions that target specific forms of RCA dysmaturation. PUBLIC HEALTH RELEVANCE: Using neuroimaging, we will map the development of key components of the brain's regulatory control architecture in a sample of youth with externalizing disorders and diverse kinds of impulsivity symptoms. We will use these maps to develop a new class of neuroimaging biomarkers for specific forms of impulsivity. This research will advance the development of biologically informed dimensional approaches for characterizing complex impulsivity phenotypes and will spur the development of new treatments.",Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology,9501776,R01MH107741,"['Adolescence', 'Adult', 'Advanced Development', 'Architecture', 'Attention', 'Attention deficit hyperactivity disorder', 'Biological', 'Biological Markers', 'Brain', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Complex', 'Conduct Disorder', 'Data', 'Desire for food', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Emotional', 'Emotions', 'Enrollment', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Hyperactive behavior', 'Image', 'Impulsivity', 'Intervention', 'Investigation', 'Joints', 'Lead', 'Link', 'Longitudinal cohort', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Motor', 'National Institute of Mental Health', 'Neuropsychology', 'Oppositional Defiant Disorder', 'Participant', 'Pattern', 'Phenotype', 'Pilot Projects', 'Protocols documentation', 'Psychopathology', 'Research', 'Research Domain Criteria', 'Rest', 'Rewards', 'Sampling', 'Symptoms', 'Testing', 'Time', 'Validation', 'Youth', 'analytical method', 'attentional control', 'base', 'cohort', 'connectome', 'design', 'disease classification', 'early adolescence', 'emotion dysregulation', 'follow-up', 'independent component analysis', 'indexing', 'longitudinal design', 'mind control', 'multimodality', 'neurodevelopment', 'neuroimaging', 'neuroimaging marker', 'predictive modeling', 'public health relevance', 'recruit', 'research study', 'specific biomarkers', 'vector', 'young adult']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,483815,0.0019884136849515613
"Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology ﻿    DESCRIPTION (provided by applicant): Youth with externalizing psychopathologies, including attention-deficit/hyperactivity disorder, oppositional defiant disorder, and conduct disorder, present with diverse kinds of impulsivity symptoms, which in turn reflect deficits in regulatory control functioning. An emerging neurodevelopmental model, which we call the Impulsivity as Immaturity Model, could potentially transform our understanding of the brain basis of regulatory dysfunction. The brain's regulatory control architecture (RCA) undergoes massive maturation during childhood and adolescence. The Impulsivity as Immaturity Model proposes that aberrant maturation in distinct components of the RCA gives rise to distinct patterns of impulsivity symptoms-e.g., delayed maturation in certain attention control components gives rise to attentional variability, a specific form of attention dysfunction. Informed by this model, we will use a mixed cohort/longitudinal design enrolling 135 healthy youth and 135 youth with externalizing psychopathologies. Using advanced multivariate/multimodal analytic methods, we will map the normative neurodevelopmental trajectories of major components of the RCA including components involved in attention, motor, emotion, and appetitive control. We will then construct multivariate models that predict different forms of impulsivity based on neurodevelopment patterns of RCA components. Successful completion of this project will be a critical first step in development of a new class of imaging-based immaturity biomarkers that index distinct types of impulsivity irrespective of the specific externalizing disorders in which they manifest. This will lead to earlier, more reliable diagnosis of impulsivity problems in youth and spur the development of transdiagnostic, biologically based interventions that target specific forms of RCA dysmaturation. PUBLIC HEALTH RELEVANCE: Using neuroimaging, we will map the development of key components of the brain's regulatory control architecture in a sample of youth with externalizing disorders and diverse kinds of impulsivity symptoms. We will use these maps to develop a new class of neuroimaging biomarkers for specific forms of impulsivity. This research will advance the development of biologically informed dimensional approaches for characterizing complex impulsivity phenotypes and will spur the development of new treatments.",Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology,9725782,R01MH107741,"['Adolescence', 'Adult', 'Advanced Development', 'Architecture', 'Attention', 'Attention deficit hyperactivity disorder', 'Biologic Development', 'Biological', 'Biological Markers', 'Brain', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Complex', 'Conduct Disorder', 'Data', 'Desire for food', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Emotional', 'Emotions', 'Enrollment', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Hyperactive behavior', 'Image', 'Impulsivity', 'Intervention', 'Investigation', 'Joints', 'Lead', 'Link', 'Longitudinal cohort', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Motor', 'National Institute of Mental Health', 'Neuropsychology', 'Oppositional Defiant Disorder', 'Participant', 'Pattern', 'Phenotype', 'Pilot Projects', 'Protocols documentation', 'Psychopathology', 'Research', 'Research Domain Criteria', 'Rest', 'Rewards', 'Sampling', 'Structure', 'Symptoms', 'Testing', 'Time', 'Validation', 'Youth', 'analytical method', 'attentional control', 'base', 'cohort', 'connectome', 'design', 'disease classification', 'early adolescence', 'emotion dysregulation', 'follow-up', 'independent component analysis', 'indexing', 'longitudinal design', 'mind control', 'multimodality', 'neurodevelopment', 'neuroimaging', 'neuroimaging marker', 'predictive modeling', 'public health relevance', 'recruit', 'research study', 'specific biomarkers', 'vector', 'young adult']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,446742,0.0019884136849515613
"Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology ﻿    DESCRIPTION (provided by applicant): Youth with externalizing psychopathologies, including attention-deficit/hyperactivity disorder, oppositional defiant disorder, and conduct disorder, present with diverse kinds of impulsivity symptoms, which in turn reflect deficits in regulatory control functioning. An emerging neurodevelopmental model, which we call the Impulsivity as Immaturity Model, could potentially transform our understanding of the brain basis of regulatory dysfunction. The brain's regulatory control architecture (RCA) undergoes massive maturation during childhood and adolescence. The Impulsivity as Immaturity Model proposes that aberrant maturation in distinct components of the RCA gives rise to distinct patterns of impulsivity symptoms-e.g., delayed maturation in certain attention control components gives rise to attentional variability, a specific form of attention dysfunction. Informed by this model, we will use a mixed cohort/longitudinal design enrolling 135 healthy youth and 135 youth with externalizing psychopathologies. Using advanced multivariate/multimodal analytic methods, we will map the normative neurodevelopmental trajectories of major components of the RCA including components involved in attention, motor, emotion, and appetitive control. We will then construct multivariate models that predict different forms of impulsivity based on neurodevelopment patterns of RCA components. Successful completion of this project will be a critical first step in development of a new class of imaging-based immaturity biomarkers that index distinct types of impulsivity irrespective of the specific externalizing disorders in which they manifest. This will lead to earlier, more reliable diagnosis of impulsivity problems in youth and spur the development of transdiagnostic, biologically based interventions that target specific forms of RCA dysmaturation. PUBLIC HEALTH RELEVANCE: Using neuroimaging, we will map the development of key components of the brain's regulatory control architecture in a sample of youth with externalizing disorders and diverse kinds of impulsivity symptoms. We will use these maps to develop a new class of neuroimaging biomarkers for specific forms of impulsivity. This research will advance the development of biologically informed dimensional approaches for characterizing complex impulsivity phenotypes and will spur the development of new treatments.",Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology,9296185,R01MH107741,"['Adolescence', 'Adult', 'Advanced Development', 'Architecture', 'Attention', 'Attention deficit hyperactivity disorder', 'Biological', 'Biological Markers', 'Brain', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Complex', 'Conduct Disorder', 'Data', 'Desire for food', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Emotional', 'Emotions', 'Enrollment', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Hyperactive behavior', 'Image', 'Impulsivity', 'Intervention', 'Investigation', 'Joints', 'Lead', 'Link', 'Longitudinal cohort', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Motor', 'National Institute of Mental Health', 'Neuropsychology', 'Oppositional Defiant Disorder', 'Participant', 'Pattern', 'Phenotype', 'Pilot Projects', 'Protocols documentation', 'Psychopathology', 'Recruitment Activity', 'Research', 'Research Domain Criteria', 'Rest', 'Rewards', 'Sampling', 'Symptoms', 'Testing', 'Time', 'Validation', 'Youth', 'analytical method', 'attentional control', 'base', 'cohort', 'connectome', 'design', 'disease classification', 'early adolescence', 'emotion dysregulation', 'follow-up', 'independent component analysis', 'indexing', 'longitudinal design', 'mind control', 'multimodality', 'neurodevelopment', 'neuroimaging', 'neuroimaging marker', 'predictive modeling', 'public health relevance', 'research study', 'specific biomarkers', 'vector', 'young adult']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2017,572607,0.0019884136849515613
"Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology ﻿    DESCRIPTION (provided by applicant): Youth with externalizing psychopathologies, including attention-deficit/hyperactivity disorder, oppositional defiant disorder, and conduct disorder, present with diverse kinds of impulsivity symptoms, which in turn reflect deficits in regulatory control functioning. An emerging neurodevelopmental model, which we call the Impulsivity as Immaturity Model, could potentially transform our understanding of the brain basis of regulatory dysfunction. The brain's regulatory control architecture (RCA) undergoes massive maturation during childhood and adolescence. The Impulsivity as Immaturity Model proposes that aberrant maturation in distinct components of the RCA gives rise to distinct patterns of impulsivity symptoms-e.g., delayed maturation in certain attention control components gives rise to attentional variability, a specific form of attention dysfunction. Informed by this model, we will use a mixed cohort/longitudinal design enrolling 135 healthy youth and 135 youth with externalizing psychopathologies. Using advanced multivariate/multimodal analytic methods, we will map the normative neurodevelopmental trajectories of major components of the RCA including components involved in attention, motor, emotion, and appetitive control. We will then construct multivariate models that predict different forms of impulsivity based on neurodevelopment patterns of RCA components. Successful completion of this project will be a critical first step in development of a new class of imaging-based immaturity biomarkers that index distinct types of impulsivity irrespective of the specific externalizing disorders in which they manifest. This will lead to earlier, more reliable diagnosis of impulsivity problems in youth and spur the development of transdiagnostic, biologically based interventions that target specific forms of RCA dysmaturation. PUBLIC HEALTH RELEVANCE: Using neuroimaging, we will map the development of key components of the brain's regulatory control architecture in a sample of youth with externalizing disorders and diverse kinds of impulsivity symptoms. We will use these maps to develop a new class of neuroimaging biomarkers for specific forms of impulsivity. This research will advance the development of biologically informed dimensional approaches for characterizing complex impulsivity phenotypes and will spur the development of new treatments.",Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology,9109682,R01MH107741,"['Adolescence', 'Adult', 'Advanced Development', 'Architecture', 'Attention', 'Attention deficit hyperactivity disorder', 'Base of the Brain', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Complex', 'Conduct Disorder', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Emotional', 'Emotions', 'Enrollment', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Health', 'Hyperactive behavior', 'Image', 'Impulsivity', 'Intervention', 'Investigation', 'Joints', 'Lead', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Motor', 'National Institute of Mental Health', 'Oppositional Defiant Disorder', 'Participant', 'Pattern', 'Phenotype', 'Pilot Projects', 'Protocols documentation', 'Psychopathology', 'Recruitment Activity', 'Research', 'Research Domain Criteria', 'Rest', 'Rewards', 'Sampling', 'Symptoms', 'Testing', 'Time', 'Validation', 'Youth', 'base', 'cohort', 'connectome', 'design', 'disease classification', 'early adolescence', 'emotion dysregulation', 'follow-up', 'independent component analysis', 'indexing', 'longitudinal design', 'mind control', 'neurodevelopment', 'neuroimaging', 'neuropsychological', 'research study', 'specific biomarkers', 'vector', 'young adult']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2016,454953,0.0019884136849515613
"Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology ﻿    DESCRIPTION (provided by applicant): Youth with externalizing psychopathologies, including attention-deficit/hyperactivity disorder, oppositional defiant disorder, and conduct disorder, present with diverse kinds of impulsivity symptoms, which in turn reflect deficits in regulatory control functioning. An emerging neurodevelopmental model, which we call the Impulsivity as Immaturity Model, could potentially transform our understanding of the brain basis of regulatory dysfunction. The brain's regulatory control architecture (RCA) undergoes massive maturation during childhood and adolescence. The Impulsivity as Immaturity Model proposes that aberrant maturation in distinct components of the RCA gives rise to distinct patterns of impulsivity symptoms-e.g., delayed maturation in certain attention control components gives rise to attentional variability, a specific form of attention dysfunction. Informed by this model, we will use a mixed cohort/longitudinal design enrolling 135 healthy youth and 135 youth with externalizing psychopathologies. Using advanced multivariate/multimodal analytic methods, we will map the normative neurodevelopmental trajectories of major components of the RCA including components involved in attention, motor, emotion, and appetitive control. We will then construct multivariate models that predict different forms of impulsivity based on neurodevelopment patterns of RCA components. Successful completion of this project will be a critical first step in development of a new class of imaging-based immaturity biomarkers that index distinct types of impulsivity irrespective of the specific externalizing disorders in which they manifest. This will lead to earlier, more reliable diagnosis of impulsivity problems in youth and spur the development of transdiagnostic, biologically based interventions that target specific forms of RCA dysmaturation.         PUBLIC HEALTH RELEVANCE: Using neuroimaging, we will map the development of key components of the brain's regulatory control architecture in a sample of youth with externalizing disorders and diverse kinds of impulsivity symptoms. We will use these maps to develop a new class of neuroimaging biomarkers for specific forms of impulsivity. This research will advance the development of biologically informed dimensional approaches for characterizing complex impulsivity phenotypes and will spur the development of new treatments.                ",Impulsivity as Immaturity: Mapping Dysmaturation of the Brain's Control Architecture in Youth Externalizing Psychopathology,8956794,R01MH107741,"['Adolescence', 'Adult', 'Advanced Development', 'Architecture', 'Attention', 'Attention deficit hyperactivity disorder', 'Base of the Brain', 'Biological Markers', 'Brain', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Complex', 'Conduct Disorder', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Emotional', 'Emotions', 'Enrollment', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Hyperactive behavior', 'Image', 'Impulsivity', 'Intervention', 'Investigation', 'Joints', 'Lead', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Motor', 'National Institute of Mental Health', 'Oppositional Defiant Disorder', 'Participant', 'Pattern', 'Phenotype', 'Pilot Projects', 'Protocols documentation', 'Psychopathology', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Research Domain Criteria', 'Rest', 'Rewards', 'Sampling', 'Symptoms', 'Testing', 'Time', 'Validation', 'Youth', 'base', 'cohort', 'design', 'disease classification', 'early adolescence', 'emotion dysregulation', 'follow-up', 'independent component analysis', 'indexing', 'longitudinal design', 'mind control', 'neurodevelopment', 'neuroimaging', 'neuropsychological', 'public health relevance', 'research study', 'vector', 'young adult']",NIMH,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2015,382086,0.0019884136849515613
"Detection and characterization of critical under-immunized hotspots Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots,9887876,R01GM109718,"['Affect', 'Bayesian Method', 'Behavioral Model', 'California', 'Characteristics', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Disease model', 'Economic Burden', 'Economics', 'Epidemic', 'Epidemiology', 'Exhibits', 'Funding', 'Geography', 'Growth', 'Health', 'Health Personnel', 'Herd Immunity', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Individual', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Measles-Mumps-Rubella Vaccine', 'Medical', 'Methodology', 'Methods', 'Minnesota', 'Modeling', 'New Jersey', 'New York', 'Oregon', 'Outcome', 'Pathway interactions', 'Policies', 'Policy Maker', 'Population', 'Population Analysis', 'Privatization', 'Public Health', 'Records', 'Registries', 'Resolution', 'Resource Allocation', 'Resources', 'Risk', 'Scanning', 'Schools', 'Science', 'Source', 'System', 'Systems Analysis', 'Techniques', 'Time', 'Uncertainty', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Washington', 'Work', 'base', 'data mining', 'demographics', 'diverse data', 'economic cost', 'economic outcome', 'health care delivery', 'health disparity', 'health organization', 'improved', 'interest', 'novel', 'novel strategies', 'population based', 'provider networks', 'public health intervention', 'social', 'social media', 'spatiotemporal', 'statistics', 'tool', 'transmission process']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2020,324178,-0.009251657008419314
"Genetic Network Inference with Combinational Phenotypes DESCRIPTION (provided by applicant): The reverse engineering of cellular genetic circuits from gene expression data is an important and scientifically challenging problem. When applied to system more complex than a yeast cell, however, most of the approaches for reverse engineering are limited by their reliance on a significant number of ad-hoc perturbation, such as gene knockout.  We propose to address these issues and to attempt to reconstruct the genetic circuitry of human B-cells by coupling three distinct components: 1) an information theoretic method for the inference of cellular networks from microarray profile data for a large number of distinct cellular and molecular phenotypes 2) A synthetic network simulation framework for the assessment of the performance of the reverse engineering under a variety of constraints and conditions, such as noise and network complexity. 3) An adaptive learning method that will iteratively apply optimal perturbations to the biological system, which will allow refining the cellular network model over time.  Furthermore, we propose to biologically validate this approach by elucidating the cellular networks of human B lymphocytes, from a variety of normal, tumor-derived, and experimentally manipulated B cell phenotypes, which are significant both from an oncological and immunological perspective. This will be accomplished by analyzing an existing set of over 340 high-quality microarray expression profiles.  Finally, we will create a software platform to reverse engineer any biological system for which adequate microarray data is available. The platform will also allow to design and perform virtual, in-silico gene perturbation experiments. n/a",Genetic Network Inference with Combinational Phenotypes,7082976,R01CA109755,"['B lymphocyte', 'artificial intelligence', 'cellular oncology', 'computer program /software', 'computer simulation', 'cytogenetics', 'functional /structural genomics', 'gene expression profiling', 'genetic models', 'human data', 'lymphoma', 'microarray technology', 'molecular biology information system', 'molecular genetics', 'molecular oncology', 'neoplasm /cancer genetics', 'nucleic acid structure', 'statistics /biometry']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,373483,0.0021270175263133993
"Genetic Network Inference with Combinational Phenotypes DESCRIPTION (provided by applicant): The reverse engineering of cellular genetic circuits from gene expression data is an important and scientifically challenging problem. When applied to system more complex than a yeast cell, however, most of the approaches for reverse engineering are limited by their reliance on a significant number of ad-hoc perturbation, such as gene knockout.  We propose to address these issues and to attempt to reconstruct the genetic circuitry of human B-cells by coupling three distinct components: 1) an information theoretic method for the inference of cellular networks from microarray profile data for a large number of distinct cellular and molecular phenotypes 2) A synthetic network simulation framework for the assessment of the performance of the reverse engineering under a variety of constraints and conditions, such as noise and network complexity. 3) An adaptive learning method that will iteratively apply optimal perturbations to the biological system, which will allow refining the cellular network model over time.  Furthermore, we propose to biologically validate this approach by elucidating the cellular networks of human B lymphocytes, from a variety of normal, tumor-derived, and experimentally manipulated B cell phenotypes, which are significant both from an oncological and immunological perspective. This will be accomplished by analyzing an existing set of over 340 high-quality microarray expression profiles.  Finally, we will create a software platform to reverse engineer any biological system for which adequate microarray data is available. The platform will also allow to design and perform virtual, in-silico gene perturbation experiments. n/a",Genetic Network Inference with Combinational Phenotypes,6925178,R01CA109755,"['B lymphocyte', 'artificial intelligence', 'cellular oncology', 'computer program /software', 'computer simulation', 'cytogenetics', 'functional /structural genomics', 'gene expression profiling', 'genetic models', 'human data', 'lymphoma', 'microarray technology', 'molecular biology information system', 'molecular genetics', 'molecular oncology', 'neoplasm /cancer genetics', 'nucleic acid structure', 'statistics /biometry']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,387233,0.0021270175263133993
"CRCNS: Real-time neural decoding for calcium imaging Program Director/Principal Investigator (Last, First, Middle): Chen, Rong PROJECT DESCRIPTION A. BACKGROUND AND SIGNIFICANCE Real-time neural decoding centers on predicting behavior variables based on neural activity data, where the prediction is performed at a pace that reliably keeps up with the speed of the activity that is being monitored. Neuromodulation devices are becoming one of the most powerful tools for the treatment of brain disorders, enhancing neurocognitive performance, and demonstrating causality (Bergmann et al., 2016; Knotkova and Rasche, 2015). A precise neuromodulation system (Figure 1) integrates neural activity monitoring, real-time neural decoding, and neuromodulation. In precise neuromodulation, a decoding device predicts a behavior variable based on neural data streams in real-time. Based on the decoding results, neuromodulation parameters such as timing, frequency, duration, and amplitude are changed. Precise neuromodulation systems with closed-loop real-time feedback are superior to the fixed (open- loop) neuromodulation paradigm (Brocker et al., 2017; deBettencourt et al., 2015; Ezzyat et al., 2017). A recent direct brain stimulation study (Ezzyat et al., 2017) demonstrated significant advantages of precise neuromodulation over open-loop neuromodulation. Ezzyat et al. applied direct brain stimulation with decoding capability to patients with epilepsy to improve their memory. They found that stimulation increased memory function only if delivered when the decoding device indicated low encoding efficiency while stimulation decreased memory function if delivered when the decoding device indicated high encoding efficiency. An open-loop neuromodulation system with a fixed stimulation paradigm may not always facilitate memory function.  Miniature cellular imaging (Ghosh et al., 2011; Kerr and Nimmerjahn, 2012; Scott et al., 2013) is one of the most powerful ways to study neural circuits. It enables us to investigate neural circuits during behaviors for an understanding of network architecture of behavior, cognition, and emotion. Miniature cellular imaging records neuronal activity at cellular and sub-second levels of spatial and temporal resolution in freely moving animals. Miniature cellular imaging has many advantages. First, compared with in vivo multi-electrode recording, miniature calcium imaging can probe all cells in the field of view, and visualize the spatial location of monitored cells (Kerr et al., 2005). Second, compared with magnetic resonance imaging, which measures brain activity at the macroscopic scale and with low temporal resolution, miniature cellular imaging provides high spatial and temporal resolution. Third, fiber photometry (Cui et al., 2014) lacks cellular-level resolution, while miniature cellular imaging allows concurrent tracking of neural calcium activities at cellular spatial resolution. Simultaneous neural activity monitoring and intetvention Stimulation Calcium imaging Real-time decoding system Figure 1 A precise neuromodulation system. Our project centers on developing RNDC-Lab. PHS 398 (Rev. 01 /18 Approved Through 03/31/2020) Page 26  Miniature cellular imaging with real- time decoding capability captures the central vision of brain science, (The brain initiative, 2014). Combined with optogenetics, it is a tremendous asset to studying neural mechanisms underlying normal and disease states, and leads to precise neuromodulation. However, developing such systems is a challenging task. A major obstacle is the analysis of the large imaging streams that are generated. The massive high-dimensional data streams that are generated include 0MB No. 0925-0001 n/a",CRCNS: Real-time neural decoding for calcium imaging,10001622,R01NS110421,"['Address', 'Algorithms', 'Animals', 'Attention', 'BRAIN initiative', 'Behavior', 'Biological Models', 'Brain', 'Brain Diseases', 'Calcium', 'Cells', 'Cognition', 'Collection', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Devices', 'Disease', 'Electrodes', 'Emotions', 'Encapsulated', 'Epilepsy', 'Esthesia', 'Etiology', 'Event', 'Feedback', 'Fiber', 'Frequencies', 'Generations', 'Image', 'Knowledge', 'Laboratories', 'Language', 'Learning', 'Link', 'Location', 'Magnetic Resonance Imaging', 'Masks', 'Measures', 'Memory', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Network-based', 'Neurocognitive', 'Neurons', 'Neurosciences', 'Pain', 'Patients', 'Perception', 'Performance', 'Photometry', 'Principal Investigator', 'Process', 'Records', 'Research', 'Resolution', 'Science', 'Scientist', 'Sleep', 'Speed', 'Stream', 'System', 'Techniques', 'Time', 'Training', 'Vision', 'Wakefulness', 'Work', 'automated algorithm', 'base', 'cellular imaging', 'cost efficient', 'data acquisition', 'data streams', 'deep neural network', 'design', 'experimental study', 'high dimensionality', 'improved', 'in vivo', 'innovation', 'multidimensional data', 'nervous system disorder', 'network architecture', 'neural circuit', 'neural stimulation', 'neuromechanism', 'neuroregulation', 'neurotransmission', 'novel', 'optical imaging', 'optogenetics', 'predictive modeling', 'programs', 'prototype', 'real-time images', 'relating to nervous system', 'signal processing', 'spatiotemporal', 'temporal measurement', 'tool']",NINDS,UNIVERSITY OF MARYLAND BALTIMORE,R01,2020,227854,0.0020659833523771452
"CRCNS: Real-time neural decoding for calcium imaging Program Director/Principal Investigator (Last, First, Middle): Chen, Rong PROJECT DESCRIPTION A. BACKGROUND AND SIGNIFICANCE Real-time neural decoding centers on predicting behavior variables based on neural activity data, where the prediction is performed at a pace that reliably keeps up with the speed of the activity that is being monitored. Neuromodulation devices are becoming one of the most powerful tools for the treatment of brain disorders, enhancing neurocognitive performance, and demonstrating causality (Bergmann et al., 2016; Knotkova and Rasche, 2015). A precise neuromodulation system (Figure 1) integrates neural activity monitoring, real-time neural decoding, and neuromodulation. In precise neuromodulation, a decoding device predicts a behavior variable based on neural data streams in real-time. Based on the decoding results, neuromodulation parameters such as timing, frequency, duration, and amplitude are changed. Precise neuromodulation systems with closed-loop real-time feedback are superior to the fixed (open- loop) neuromodulation paradigm (Brocker et al., 2017; deBettencourt et al., 2015; Ezzyat et al., 2017). A recent direct brain stimulation study (Ezzyat et al., 2017) demonstrated significant advantages of precise neuromodulation over open-loop neuromodulation. Ezzyat et al. applied direct brain stimulation with decoding capability to patients with epilepsy to improve their memory. They found that stimulation increased memory function only if delivered when the decoding device indicated low encoding efficiency while stimulation decreased memory function if delivered when the decoding device indicated high encoding efficiency. An open-loop neuromodulation system with a fixed stimulation paradigm may not always facilitate memory function.  Miniature cellular imaging (Ghosh et al., 2011; Kerr and Nimmerjahn, 2012; Scott et al., 2013) is one of the most powerful ways to study neural circuits. It enables us to investigate neural circuits during behaviors for an understanding of network architecture of behavior, cognition, and emotion. Miniature cellular imaging records neuronal activity at cellular and sub-second levels of spatial and temporal resolution in freely moving animals. Miniature cellular imaging has many advantages. First, compared with in vivo multi-electrode recording, miniature calcium imaging can probe all cells in the field of view, and visualize the spatial location of monitored cells (Kerr et al., 2005). Second, compared with magnetic resonance imaging, which measures brain activity at the macroscopic scale and with low temporal resolution, miniature cellular imaging provides high spatial and temporal resolution. Third, fiber photometry (Cui et al., 2014) lacks cellular-level resolution, while miniature cellular imaging allows concurrent tracking of neural calcium activities at cellular spatial resolution. Simultaneous neural activity monitoring and intetvention Stimulation Calcium imaging Real-time decoding system Figure 1 A precise neuromodulation system. Our project centers on developing RNDC-Lab. PHS 398 (Rev. 01 /18 Approved Through 03/31/2020) Page 26  Miniature cellular imaging with real- time decoding capability captures the central vision of brain science, (The brain initiative, 2014). Combined with optogenetics, it is a tremendous asset to studying neural mechanisms underlying normal and disease states, and leads to precise neuromodulation. However, developing such systems is a challenging task. A major obstacle is the analysis of the large imaging streams that are generated. The massive high-dimensional data streams that are generated include 0MB No. 0925-0001 n/a",CRCNS: Real-time neural decoding for calcium imaging,9769912,R01NS110421,"['Address', 'Algorithms', 'Animals', 'Attention', 'BRAIN initiative', 'Behavior', 'Biological Models', 'Brain', 'Brain Diseases', 'Calcium', 'Cells', 'Cognition', 'Collection', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Devices', 'Disease', 'Electrodes', 'Emotions', 'Encapsulated', 'Epilepsy', 'Esthesia', 'Etiology', 'Event', 'Feedback', 'Fiber', 'Frequencies', 'Generations', 'Image', 'Knowledge', 'Laboratories', 'Language', 'Learning', 'Link', 'Location', 'Magnetic Resonance Imaging', 'Masks', 'Measures', 'Memory', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Network-based', 'Neurocognitive', 'Neurons', 'Neurosciences', 'Pain', 'Patients', 'Perception', 'Performance', 'Photometry', 'Principal Investigator', 'Process', 'Records', 'Research', 'Resolution', 'Science', 'Scientist', 'Sleep', 'Speed', 'Stream', 'System', 'Techniques', 'Time', 'Training', 'Vision', 'Wakefulness', 'Work', 'base', 'cellular imaging', 'cost efficient', 'data acquisition', 'deep neural network', 'design', 'experimental study', 'high dimensionality', 'improved', 'in vivo', 'innovation', 'multidimensional data', 'nervous system disorder', 'network architecture', 'neural circuit', 'neural stimulation', 'neuromechanism', 'neuroregulation', 'neurotransmission', 'novel', 'optical imaging', 'optogenetics', 'predictive modeling', 'programs', 'prototype', 'real-time images', 'relating to nervous system', 'signal processing', 'spatiotemporal', 'temporal measurement', 'tool']",NINDS,UNIVERSITY OF MARYLAND BALTIMORE,R01,2019,228265,0.0020659833523771452
"Integrating Machine Learning and Genomic Approaches to Understand Cerebral Small Vessel Disease Pathogenesis from White Matter Hyperintensity Patterns PROJECT SUMMARY  As a neurointensivist and neurologist at Washington University School of Medicine in St. Louis (WUSM), my career goal is to develop an independent research program as a computational biologist capable of using advanced bioinformatics and statistical methods to integrate analysis of large-scale neuroimaging and genetic data, with the aim of deepening understanding of the biological mechanisms influencing cerebral small vessel disease (SVD) and identifying new targets for therapeutic development. As a first step towards this goal, I have designed an innovative proposal that combine machine-learning (ML) methods and integrated imaging genetic analyses of large-scale neuroimaging and genetic data to improve characterization of SVD disease mechanisms.  The clinical, imaging, and etiologic heterogeneity of SVD have impeded efforts to uncover the pathophysiology of this common and debilitating neurological disease. White matter hyperintensities (WMH), a major imaging endpoint of SVD, are comprised of multiple SVD pathologic processes. Growing evidence suggests location-specific vulnerability of brain parenchyma to different underlying SVD pathologic processes, in which spatially localized WMH patterns may reflect distinct SVD etiologies. Characterizing WMH spatial pattern variations in SVD will not only provide insights into underlying pathogenesis, such as vascular amyloid deposition, arteriolosclerosis, and other less well defined or as-yet unknown disease mechanisms, but also lead to creation of novel imaging biomarkers of these SVD pathologic processes. This proposal addresses a key inadequacy, as existing WMH pattern definitions are determined empirically and cannot distinguish overlapping SVD etiologies and risk factors. In this proposal, I aim to capture WMH spatial pattern variations that reflect distinct SVD etiologies in an unbiased manner, by applying clustering analysis/ML methods to structural MRI data to create novel etiology-specific SVD imaging phenotypes. Moreover, given that genetics influence the variance of WMH, I will integrate genetic analyses of these WMH patterns to uncover novel mechanisms that influence SVD pathogenesis. My preliminary data demonstrate the feasibility of identifying data-driven WMH spatial pattern variations, which are specific to distinct SVD etiologies, and allow detection of genetic risk variants that may help inform SVD pathologic processes.  My career plan leverages the extensive resources and exceptional environments at WUSM, under the guidance of a multidisciplinary mentorship team with expertise across diverse fields including cerebrovascular physiology, neuroimaging, informatics, genetics, and machine learning (Drs. Jin-Moo Lee, Daniel Marcus, Carlos Cruchaga and Yasheng Chen). In this Career Development Award, I propose to: 1) determine distinct WMH spatial patterns that can discriminate underlying SVD pathology and/or risk factors by applying pattern analysis ML methods to structural MRI data from three unique cohorts (n=2,710) enriched for different SVD pathologies (Aim 1a), and examining if the ML-defined WMH patterns segregate individuals by well-defined SVD risk factors as biologic validation (Aim 1b), and 2) identify genetic variants (Aim 2a) associated with WMH patterns that reflect diverse pathologic processes influencing SVD using genome wide association and gene-based analyses; replicate the top variants (Aim 2b) in an independent population-based cohort (n=21,708); and use advanced bioinformatics tools to uncover new biologic pathways associated with WMH spatial patterns (Aim 2c).  This research proposal and accompanying development plan with focused training in machine learning, neuroimaging, and multivariate methods for integrated imaging genetics analysis, will build on my background in genetics towards a career investigating cerebrovascular disorders using translational bioinformatics. This Award will provide me with the necessary training to evolve into an independent investigator with a computational research program that can integrate large imaging and genetics datasets to derive results that are highly relevant to the prevention and treatment of cerebrovascular disease in my clinical patient population. PROJECT NARRATIVE Cerebral small vessel disease (SVD) is one of the most prevalent neurological conditions in older adults, and a leading cause of stroke and cognitive impairment, for which existing treatment and preventative options have been limited or lack efficacy. This project’s goal is to enhance our knowledge of the complex disease processes underlying SVD using machine learning and integrating individual imaging and genetic data from over 20,000 adults. By understanding these disease processes, we can design novel methods to more effectively treat and prevent stroke and dementia.",Integrating Machine Learning and Genomic Approaches to Understand Cerebral Small Vessel Disease Pathogenesis from White Matter Hyperintensity Patterns,10022173,K23NS110927,"['3-Dimensional', 'Address', 'Adult', 'Affect', 'Alzheimer&apos', 's Disease', 'Amyloid deposition', 'Archives', 'Arteries', 'Award', 'Bioinformatics', 'Biological', 'Biology', 'Blood Vessels', 'Brain', 'Categories', 'Cerebral Amyloid Angiopathy', 'Cerebral hemisphere hemorrhage', 'Cerebral small vessel disease', 'Cerebrovascular Disorders', 'Cerebrovascular Physiology', 'Clinical', 'Cluster Analysis', 'Complex', 'Computational Technique', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Development Plans', 'Disease', 'Disease Progression', 'Distal', 'Elderly', 'Environment', 'Etiology', 'Failure', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Risk', 'Genetic Variation', 'Genomic approach', 'Genotype', 'Goals', 'Grant', 'Heritability', 'Heterogeneity', 'Hypertension', 'Image', 'Impaired cognition', 'Individual', 'Informatics', 'Intervention', 'Investigation', 'Ischemic Stroke', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Lobar', 'Location', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mentorship', 'Methods', 'Microvascular Dysfunction', 'Neurologic', 'Neurologist', 'Pathogenesis', 'Pathogenicity', 'Pathologic', 'Pathologic Processes', 'Pathology', 'Pathway interactions', 'Pattern', 'Phenotype', 'Play', 'Population', 'Prevention', 'Process', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Risk Factors', 'Role', 'Statistical Methods', 'Stroke', 'Stroke prevention', 'Structure', 'Testing', 'Training', 'Universities', 'Validation', 'Variant', 'Washington', 'White Matter Hyperintensity', 'arteriole', 'base', 'biobank', 'bioinformatics tool', 'brain parenchyma', 'career', 'cohort', 'design', 'disorder subtype', 'effective therapy', 'genetic analysis', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'hypertension control', 'imaging biomarker', 'imaging genetics', 'improved', 'innovation', 'insight', 'interdisciplinary approach', 'machine learning method', 'medical schools', 'multidisciplinary', 'nervous system disorder', 'neuroimaging', 'new therapeutic target', 'novel', 'patient population', 'population based', 'programs', 'racial and ethnic', 'risk variant', 'serial imaging', 'stroke therapy', 'success', 'therapeutic development', 'tool', 'treatment strategy', 'unsupervised learning']",NINDS,WASHINGTON UNIVERSITY,K23,2020,178809,-0.038715708584182704
"Integrating Machine Learning and Genomic Approaches to Understand Cerebral Small Vessel Disease Pathogenesis from White Matter Hyperintensity Patterns PROJECT SUMMARY  As a neurointensivist and neurologist at Washington University School of Medicine in St. Louis (WUSM), my career goal is to develop an independent research program as a computational biologist capable of using advanced bioinformatics and statistical methods to integrate analysis of large-scale neuroimaging and genetic data, with the aim of deepening understanding of the biological mechanisms influencing cerebral small vessel disease (SVD) and identifying new targets for therapeutic development. As a first step towards this goal, I have designed an innovative proposal that combine machine-learning (ML) methods and integrated imaging genetic analyses of large-scale neuroimaging and genetic data to improve characterization of SVD disease mechanisms.  The clinical, imaging, and etiologic heterogeneity of SVD have impeded efforts to uncover the pathophysiology of this common and debilitating neurological disease. White matter hyperintensities (WMH), a major imaging endpoint of SVD, are comprised of multiple SVD pathologic processes. Growing evidence suggests location-specific vulnerability of brain parenchyma to different underlying SVD pathologic processes, in which spatially localized WMH patterns may reflect distinct SVD etiologies. Characterizing WMH spatial pattern variations in SVD will not only provide insights into underlying pathogenesis, such as vascular amyloid deposition, arteriolosclerosis, and other less well defined or as-yet unknown disease mechanisms, but also lead to creation of novel imaging biomarkers of these SVD pathologic processes. This proposal addresses a key inadequacy, as existing WMH pattern definitions are determined empirically and cannot distinguish overlapping SVD etiologies and risk factors. In this proposal, I aim to capture WMH spatial pattern variations that reflect distinct SVD etiologies in an unbiased manner, by applying clustering analysis/ML methods to structural MRI data to create novel etiology-specific SVD imaging phenotypes. Moreover, given that genetics influence the variance of WMH, I will integrate genetic analyses of these WMH patterns to uncover novel mechanisms that influence SVD pathogenesis. My preliminary data demonstrate the feasibility of identifying data-driven WMH spatial pattern variations, which are specific to distinct SVD etiologies, and allow detection of genetic risk variants that may help inform SVD pathologic processes.  My career plan leverages the extensive resources and exceptional environments at WUSM, under the guidance of a multidisciplinary mentorship team with expertise across diverse fields including cerebrovascular physiology, neuroimaging, informatics, genetics, and machine learning (Drs. Jin-Moo Lee, Daniel Marcus, Carlos Cruchaga and Yasheng Chen). In this Career Development Award, I propose to: 1) determine distinct WMH spatial patterns that can discriminate underlying SVD pathology and/or risk factors by applying pattern analysis ML methods to structural MRI data from three unique cohorts (n=2,710) enriched for different SVD pathologies (Aim 1a), and examining if the ML-defined WMH patterns segregate individuals by well-defined SVD risk factors as biologic validation (Aim 1b), and 2) identify genetic variants (Aim 2a) associated with WMH patterns that reflect diverse pathologic processes influencing SVD using genome wide association and gene-based analyses; replicate the top variants (Aim 2b) in an independent population-based cohort (n=21,708); and use advanced bioinformatics tools to uncover new biologic pathways associated with WMH spatial patterns (Aim 2c).  This research proposal and accompanying development plan with focused training in machine learning, neuroimaging, and multivariate methods for integrated imaging genetics analysis, will build on my background in genetics towards a career investigating cerebrovascular disorders using translational bioinformatics. This Award will provide me with the necessary training to evolve into an independent investigator with a computational research program that can integrate large imaging and genetics datasets to derive results that are highly relevant to the prevention and treatment of cerebrovascular disease in my clinical patient population. PROJECT NARRATIVE Cerebral small vessel disease (SVD) is one of the most prevalent neurological conditions in older adults, and a leading cause of stroke and cognitive impairment, for which existing treatment and preventative options have been limited or lack efficacy. This project’s goal is to enhance our knowledge of the complex disease processes underlying SVD using machine learning and integrating individual imaging and genetic data from over 20,000 adults. By understanding these disease processes, we can design novel methods to more effectively treat and prevent stroke and dementia.",Integrating Machine Learning and Genomic Approaches to Understand Cerebral Small Vessel Disease Pathogenesis from White Matter Hyperintensity Patterns,9886424,K23NS110927,"['3-Dimensional', 'Address', 'Adult', 'Affect', 'Alzheimer&apos', 's Disease', 'Amyloid deposition', 'Archives', 'Arteries', 'Award', 'Bioinformatics', 'Biological', 'Biology', 'Blood Vessels', 'Brain', 'Categories', 'Cerebral Amyloid Angiopathy', 'Cerebral hemisphere hemorrhage', 'Cerebral small vessel disease', 'Cerebrovascular Disorders', 'Cerebrovascular Physiology', 'Clinical', 'Cluster Analysis', 'Complex', 'Computational Technique', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Development Plans', 'Disease', 'Disease Progression', 'Distal', 'Elderly', 'Environment', 'Etiology', 'Failure', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Risk', 'Genetic Variation', 'Genomic approach', 'Genotype', 'Goals', 'Grant', 'Heritability', 'Heterogeneity', 'Hypertension', 'Image', 'Impaired cognition', 'Individual', 'Informatics', 'Intervention', 'Investigation', 'Ischemic Stroke', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Lobar', 'Location', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mentorship', 'Methods', 'Microvascular Dysfunction', 'Neurologic', 'Neurologist', 'Pathogenesis', 'Pathogenicity', 'Pathologic', 'Pathologic Processes', 'Pathology', 'Pathway interactions', 'Pattern', 'Phenotype', 'Play', 'Population', 'Prevention', 'Process', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Risk Factors', 'Role', 'Statistical Methods', 'Stroke', 'Stroke prevention', 'Structure', 'Testing', 'Training', 'Universities', 'Validation', 'Variant', 'Washington', 'White Matter Hyperintensity', 'arteriole', 'base', 'biobank', 'bioinformatics tool', 'brain parenchyma', 'career', 'cohort', 'design', 'disorder subtype', 'effective therapy', 'genetic analysis', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'hypertension control', 'imaging biomarker', 'imaging genetics', 'improved', 'innovation', 'insight', 'interdisciplinary approach', 'learning strategy', 'medical schools', 'multidisciplinary', 'nervous system disorder', 'neuroimaging', 'new therapeutic target', 'novel', 'patient population', 'population based', 'programs', 'racial and ethnic', 'risk variant', 'serial imaging', 'stroke therapy', 'success', 'therapeutic development', 'tool', 'treatment strategy', 'unsupervised learning']",NINDS,WASHINGTON UNIVERSITY,K23,2019,179997,-0.038715708584182704
"Assessing psychosis-related deficits based on gaze behavior ﻿    DESCRIPTION (provided by applicant): Assessing psychosis-related deficits based on gaze behavior Existing tests of psychotic disorders are either functionally-informative or biologically-valid, but rarely both. The ultimate project goal is to improve behavioral health and reduce societal costs by providing a battery of user-friendly tests that offer functional relevance couple with biological validity. This project aims to establish the feasibility of using gaze measures as trait and state markers of psychosis. PUBLIC HEALTH RELEVANCE: Assessing psychosis-related deficits based on gaze behavior Existing tests of psychotic disorders are either functionally-informative or biologically-valid, bu rarely both. The ultimate project goal is to improve behavioral health and reduce societal costs by providing a battery of user-friendly tests that offer functional relevance coupled with biologicl validity. This project aims to establish the feasibility of using gaze measures as trait and state markers of psychosis.",Assessing psychosis-related deficits based on gaze behavior,9278261,R43MH111539,"['Academia', 'Attention', 'Basic Science', 'Behavior', 'Biological', 'Biology', 'Bipolar Disorder', 'Brain', 'Brain scan', 'Categories', 'Classification', 'Clinical', 'Cognitive', 'Computer software', 'Confidential Information', 'Coupled', 'Data', 'Data Files', 'Database Management Systems', 'Dimensions', 'Disease', 'Emotional', 'Etiology', 'Evaluation', 'Exhibits', 'Foundations', 'Future', 'Goals', 'Government', 'Individual', 'Industry', 'Link', 'Machine Learning', 'Masks', 'Measures', 'Memory', 'Monitor', 'Monte Carlo Method', 'Moods', 'Morphologic artifacts', 'Motivation', 'Neurologic', 'Outcome', 'Perception', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Psychopathology', 'Psychotic Disorders', 'ROC Curve', 'Reporting', 'Research', 'Risk', 'Saccades', 'Scanning', 'Schizophrenia', 'Severities', 'Software Tools', 'Solid', 'Stimulus', 'Symptoms', 'Techniques', 'Testing', 'Thalamic structure', 'Translations', 'Unconscious State', 'Vendor', 'Volition', 'Youth', 'base', 'behavioral health', 'case control', 'cingulate gyrus', 'clinical practice', 'cognitive testing', 'community setting', 'computerized data processing', 'cost', 'design', 'flexibility', 'frontal lobe', 'gaze', 'improved', 'indexing', 'innovation', 'outcome prediction', 'proband', 'prototype', 'public health relevance', 'software as a service', 'spatiotemporal', 'success', 'therapeutic development', 'trait', 'treatment response', 'user-friendly', 'vestibulo-ocular reflex', 'vigilance']",NIMH,"EYE-PREDICT, LLC",R43,2017,349999,-0.0006220258806641852
"Assessing psychosis-related deficits based on gaze behavior ﻿    DESCRIPTION (provided by applicant): Assessing psychosis-related deficits based on gaze behavior Existing tests of psychotic disorders are either functionally-informative or biologically-valid, but rarely both. The ultimate project goal is to improve behavioral health and reduce societal costs by providing a battery of user-friendly tests that offer functional relevance couple with biological validity. This project aims to establish the feasibility of using gaze measures as trait and state markers of psychosis.         PUBLIC HEALTH RELEVANCE: Assessing psychosis-related deficits based on gaze behavior Existing tests of psychotic disorders are either functionally-informative or biologically-valid, bu rarely both. The ultimate project goal is to improve behavioral health and reduce societal costs by providing a battery of user-friendly tests that offer functional relevance coupled with biologicl validity. This project aims to establish the feasibility of using gaze measures as trait and state markers of psychosis.        ",Assessing psychosis-related deficits based on gaze behavior,9139172,R43MH111539,"['Academia', 'Attention', 'Basic Science', 'Behavior', 'Biological', 'Biology', 'Bipolar Disorder', 'Brain', 'Brain scan', 'Categories', 'Classification', 'Clinical', 'Cognitive', 'Computer software', 'Confidential Information', 'Coupled', 'Data', 'Data Files', 'Database Management Systems', 'Dimensions', 'Disease', 'Emotional', 'Evaluation', 'Exhibits', 'Foundations', 'Future', 'Goals', 'Government', 'Individual', 'Industry', 'Link', 'Machine Learning', 'Masks', 'Measures', 'Memory', 'Monitor', 'Monte Carlo Method', 'Moods', 'Morphologic artifacts', 'Motivation', 'Neurologic', 'Outcome', 'Perception', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Psychopathology', 'Psychotic Disorders', 'ROC Curve', 'Reporting', 'Research', 'Risk', 'Saccades', 'Scanning', 'Schizophrenia', 'Severities', 'Software Tools', 'Solid', 'Stimulus', 'Symptoms', 'Techniques', 'Testing', 'Thalamic structure', 'Translations', 'Unconscious State', 'Vendor', 'Work', 'Youth', 'base', 'behavioral health', 'case control', 'cingulate gyrus', 'clinical practice', 'cognitive testing', 'community setting', 'computerized data processing', 'cost', 'design', 'flexibility', 'frontal lobe', 'gaze', 'improved', 'indexing', 'innovation', 'proband', 'prototype', 'public health relevance', 'software as a service', 'spatiotemporal', 'success', 'therapeutic development', 'trait', 'treatment response', 'user-friendly', 'vestibulo-ocular reflex', 'vigilance']",NIMH,"EYE-PREDICT, LLC",R43,2016,349999,-0.0006220258806641852
"Development of advanced voltammetric method for basal neurotransmitter level measurement PROJECT SUMMARY We propose to develop and optimize an advanced neurochemical recording technique that would be able to measure relatively rapid physiologically representative second-to-second changes in basal concentrations of specific neurochemicals, such as dopamine, in the brains of awake behaving animals. Microdialysis, a commonly used in vivo sampling technique, is able to measure changes that occur in basal levels. However, in practice the sampling timescale is significantly limited to minute-to-minute changes and it suffers from poor spatial resolution and induces significant tissue damage. As well, conventional in vivo electrochemical recording techniques, such as fast-scan cyclic voltammetry, are intrinsically limited to measuring phasic (stimulation-induced) changes in neurochemical concentrations and not changes in basal concentrations. The proposed electrochemical technique we call Multiple Cyclic Square Wave Voltammetry (M-CSWV) will enable second-to-second measurements of basal extracellular levels of neurochemicals with exceptional spatial resolution, sensitivity, specificity, and minimal tissue disturbance. This proposal leverages our unique expertise in neuroscience, electrochemistry, software development, and engineering to develop and validate this novel neurochemical recording technology for broad use in basic neuroscience research, clinical brain neuromodulation, and a variety of electrochemical applications. Our initial animal studies will guide and inform the application of our investigational technique for use by the general neuroscience and medical community. Our proposal seeks to (1) establish M-CSWV as a reliable research tool that is capable of identifying and quantifying basal dopamine extracellular levels in vivo with unsurpassed sensitivity and selectivity; and (2) validate the use of M-CSWV for in vivo chronic selective measurement of basal dopamine concentrations and application in an animal model of drug-induced neurochemical sensitization. PROJECT NARRATIVE Neurochemicals in the brain, such as dopamine, transmit information between neurons to process input and produce normal behavior, but that occasionally when their levels are disrupted lead to neurologic and psychiatric disorders. We have developed a novel neurochemical recording method called Multi-Cyclic Square Wave Voltammetry that for the first time measures basal neurochemical concentrations in real-time in the brain with single-second time resolution and unprecedented chemical selectivity. Furthermore, we propose to standardize this novel technique for use in neuroscience research directed to understanding the neurochemical basis of neuropsychiatric diseases by demonstrating its capability to quantify basal levels in a well-known animal model of drug-induced neurochemical and behavioral sensitization.",Development of advanced voltammetric method for basal neurotransmitter level measurement,9994394,R01NS112176,"['Acute', 'Adsorption', 'Advanced Development', 'Amphetamines', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Biological', 'Brain', 'Cells', 'Characteristics', 'Chemicals', 'Chronic', 'Clinical', 'Communities', 'Computer software', 'Corpus striatum structure', 'Data', 'Data Analyses', 'Dialysis procedure', 'Dimensions', 'Disease', 'Dopamine', 'Dopaminergic Agents', 'Drug Modelings', 'Electrochemistry', 'Engineering', 'Equilibrium', 'Future', 'Goals', 'Implant', 'In Vitro', 'Injections', 'Investigation', 'Lead', 'Link', 'Literature', 'Measurement', 'Measures', 'Medical', 'Mental disorders', 'Methods', 'Microdialysis', 'Microelectrodes', 'Modeling', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Neurotransmitters', 'Periodicity', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Physiological', 'Principal Component Analysis', 'Process', 'Publishing', 'Rattus', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Slice', 'Spectrum Analysis', 'Standardization', 'Stimulus', 'Surface', 'Synapses', 'Synaptic plasticity', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Validation', 'Variant', 'awake', 'base', 'behavioral sensitization', 'carbon fiber', 'electric impedance', 'extracellular', 'in vivo', 'kinetic model', 'method development', 'nervous system disorder', 'neurochemistry', 'neuropsychiatric disorder', 'neuroregulation', 'neurotransmission', 'noradrenergic', 'novel', 'phase change', 'receptor', 'response', 'software development', 'temporal measurement', 'tool', 'two-dimensional']",NINDS,MAYO CLINIC ROCHESTER,R01,2020,334425,-0.004010210677655923
"Development of advanced voltammetric method for basal neurotransmitter level measurement PROJECT SUMMARY We propose to develop and optimize an advanced neurochemical recording technique that would be able to measure relatively rapid physiologically representative second-to-second changes in basal concentrations of specific neurochemicals, such as dopamine, in the brains of awake behaving animals. Microdialysis, a commonly used in vivo sampling technique, is able to measure changes that occur in basal levels. However, in practice the sampling timescale is significantly limited to minute-to-minute changes and it suffers from poor spatial resolution and induces significant tissue damage. As well, conventional in vivo electrochemical recording techniques, such as fast-scan cyclic voltammetry, are intrinsically limited to measuring phasic (stimulation-induced) changes in neurochemical concentrations and not changes in basal concentrations. The proposed electrochemical technique we call Multiple Cyclic Square Wave Voltammetry (M-CSWV) will enable second-to-second measurements of basal extracellular levels of neurochemicals with exceptional spatial resolution, sensitivity, specificity, and minimal tissue disturbance. This proposal leverages our unique expertise in neuroscience, electrochemistry, software development, and engineering to develop and validate this novel neurochemical recording technology for broad use in basic neuroscience research, clinical brain neuromodulation, and a variety of electrochemical applications. Our initial animal studies will guide and inform the application of our investigational technique for use by the general neuroscience and medical community. Our proposal seeks to (1) establish M-CSWV as a reliable research tool that is capable of identifying and quantifying basal dopamine extracellular levels in vivo with unsurpassed sensitivity and selectivity; and (2) validate the use of M-CSWV for in vivo chronic selective measurement of basal dopamine concentrations and application in an animal model of drug-induced neurochemical sensitization. PROJECT NARRATIVE Neurochemicals in the brain, such as dopamine, transmit information between neurons to process input and produce normal behavior, but that occasionally when their levels are disrupted lead to neurologic and psychiatric disorders. We have developed a novel neurochemical recording method called Multi-Cyclic Square Wave Voltammetry that for the first time measures basal neurochemical concentrations in real-time in the brain with single-second time resolution and unprecedented chemical selectivity. Furthermore, we propose to standardize this novel technique for use in neuroscience research directed to understanding the neurochemical basis of neuropsychiatric diseases by demonstrating its capability to quantify basal levels in a well-known animal model of drug-induced neurochemical and behavioral sensitization.",Development of advanced voltammetric method for basal neurotransmitter level measurement,9796267,R01NS112176,"['Acute', 'Adsorption', 'Advanced Development', 'Amphetamines', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Biological', 'Brain', 'Cells', 'Characteristics', 'Chemicals', 'Chronic', 'Clinical', 'Communities', 'Computer software', 'Corpus striatum structure', 'Data', 'Data Analyses', 'Dialysis procedure', 'Dimensions', 'Disease', 'Dopamine', 'Dopaminergic Agents', 'Drug Modelings', 'Electrochemistry', 'Engineering', 'Equilibrium', 'Future', 'Goals', 'Implant', 'In Vitro', 'Injections', 'Investigation', 'Kinetics', 'Lead', 'Link', 'Literature', 'Measurement', 'Measures', 'Medical', 'Mental disorders', 'Methods', 'Microdialysis', 'Microelectrodes', 'Modeling', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Neurotransmitters', 'Periodicity', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacotherapy', 'Phase', 'Physiological', 'Principal Component Analysis', 'Process', 'Publishing', 'Rattus', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Sensitivity and Specificity', 'Slice', 'Spectrum Analysis', 'Standardization', 'Stimulus', 'Surface', 'Synapses', 'Synaptic plasticity', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Validation', 'Variant', 'awake', 'base', 'behavioral sensitization', 'carbon fiber', 'electric impedance', 'extracellular', 'in vivo', 'method development', 'nervous system disorder', 'neurochemistry', 'neuropsychiatric disorder', 'neuroregulation', 'neurotransmission', 'noradrenergic', 'novel', 'phase change', 'receptor', 'response', 'software development', 'temporal measurement', 'tool', 'two-dimensional']",NINDS,MAYO CLINIC ROCHESTER,R01,2019,349175,-0.004010210677655923
"Genetic interaction (GI) analysis of the mammalian ERAD system ﻿    DESCRIPTION (provided by applicant): Newly synthesized proteins must fold into the correct 3-dimensional conformation in order to function properly in the cell; however, protein folding is a complex and error-prone process. Terminally misfolded proteins that accumulate in the cell or organism can have toxic effects, and therefore must be recognized and promptly removed. ER-associated degradation (ERAD), a protein quality control system that is essential for cellular homeostasis, identifies and degrades terminally misfolded proteins in the endoplasmic reticulum (ER). Defects in ERAD have been linked to numerous human diseases including cystic fibrosis and neurodegenerative disorders; thus, understanding the molecular details of this system may illuminate the underlying pathologies of multiple diseases and reveal new therapeutic targets for the treatment of these diseases. Previous studies of mammalian ERAD have identified some of the components of this system and suggest that ERAD functions as a dynamic network of physically and functionally connected protein complexes. The long-term goal of this study is to gain detailed insight into the organization of the metazoan ERAD network, and understand how this organizational structure allows the system to monitor the folding status of a highly diverse mammalian proteome. The immediate goal of this proposal is to use genetic interaction (GI) mapping to perform a systems-level analysis of the ERAD network topology. The focus of Specific Aim 1 is to perform a genome-wide RNAi screen to identify genes involved in ERAD substrate dislocation. In Specific Aim 2, GIs in the ERAD system will be measured and organized by hierarchical clustering to define network organization and relationships between genes. In Specific Aim 3, the dynamics of the ERAD network will be studied using functional genomics and differential GI analysis. Together, these studies will be used to build a dynamic network map of the mammalian ERAD system.         PUBLIC HEALTH RELEVANCE: ER-associated degradation (ERAD) is charged with identifying and disposing of misfolded proteins in the endoplasmic reticulum, and defects in ERAD have been linked to several incurable human diseases including cystic fibrosis and neurodegenerative disorders. While individual proteins that are part of this complex system have been identified, a detailed understanding of how these proteins function together to mediate the disposal of misfolded proteins is lacking. Genetic interaction analysis will be used to better understand the mammalian ERAD system.              ",Genetic interaction (GI) analysis of the mammalian ERAD system,8908452,F32GM113370,"['3-Dimensional', 'Biochemical', 'Cell Line', 'Cell physiology', 'Cells', 'Charge', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Complex', 'Cystic Fibrosis', 'Cytoplasm', 'Cytotoxin', 'Defect', 'Disease', 'Dislocations', 'Distal', 'Endoplasmic Reticulum', 'Environment', 'Failure', 'Fibrinogen', 'Genes', 'Genetic', 'Genetic Screening', 'Genomic approach', 'Goals', 'Guide RNA', 'Homeostasis', 'Human', 'Individual', 'Lectin', 'Libraries', 'Life', 'Link', 'Lower Organism', 'Mammalian Cell', 'Maps', 'Measures', 'Mediating', 'Molecular', 'Molecular Chaperones', 'Molecular Conformation', 'Monitor', 'Neurodegenerative Disorders', 'Organism', 'Pathology', 'Phenotype', 'Plants', 'Polysaccharides', 'Post-Translational Protein Processing', 'Process', 'Protein Dynamics', 'Proteins', 'Proteome', 'Proteomics', 'Quality Control', 'RNA Interference', 'RNA library', 'Reporter', 'Ricin A Chain', 'Route', 'Structure', 'System', 'Tetracyclines', 'Toxic effect', 'Ubiquitin', 'Ubiquitination', 'Variant', 'Work', 'base', 'cell killing', 'density', 'disulfide bond', 'functional genomics', 'gene function', 'genetic approach', 'genome-wide', 'human disease', 'insight', 'mutant', 'new therapeutic target', 'novel', 'organizational structure', 'polypeptide', 'protein complex', 'protein folding', 'protein function', 'protein misfolding', 'public health relevance', 'small hairpin RNA', 'ubiquitin ligase']",NIGMS,STANFORD UNIVERSITY,F32,2015,57962,0.02216905684195237
"Construction of a high-resolution human tractography atlas and its related toolbox PROJECT SUMMARY Mapping the human connectome and exploring its characteristics is one of the largest endeavors in the neuroscience field, but a detailed tractography atlas that provides the 3D trajectories in a standard space has yet to be constructed and validated. A tractography atlas can provide neuroanatomical insight into the structural organization of the human brain and allow for modeling, simulation, and confirmation of cortical connections to facilitate the new development of treatment and intervention for brain diseases. In this study, we propose to construct a high spatial and angular resolution tractography atlas using a large sample of the Human Connectome Project (HCP) diffusion MRI data, averaging them into a template for fiber tracking, validating the tracks by post-mortem Klingler microdissection on 100 cadavers under a neurosurgery microscope digitized using high resolution 3D scanners, and building a deep learning toolbox that allows for automatic track recognition in individuals. This study will construct the most detailed and accurate tractography of human connectome and provide a novel toolbox for future HCP data analysis. PROJECT NARRATIVE The proposed research will construct an atlas of human brain fiber pathways and a related toolbox for track- specific analysis, aiming to understand the structural characteristics of brain connections in healthy individuals and provide track-specific analysis for brain imaging data.",Construction of a high-resolution human tractography atlas and its related toolbox,9771640,R56MH113634,"['Algorithms', 'Aphasia', 'Architecture', 'Atlases', 'Autopsy', 'Base of the Brain', 'Brain', 'Brain Diseases', 'Brain Stem', 'Brain imaging', 'Brain scan', 'Cadaver', 'Cerebellum', 'Characteristics', 'Complement', 'Cranial Nerves', 'Data', 'Data Analyses', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Fiber', 'Future', 'Human', 'Individual', 'Intervention', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Memory', 'Microdissection', 'Microscope', 'Neuroanatomy', 'Neurosciences', 'Neurosurgeon', 'Parkinson Disease', 'Pathway interactions', 'Patients', 'Perception', 'Performance', 'Population', 'Records', 'Research', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Source', 'Structure', 'Surface', 'System', 'Thinking', 'Tissues', 'Training', 'Validation', 'Variant', 'base', 'brain abnormalities', 'brain research', 'clinical application', 'connectome', 'deep learning', 'deep neural network', 'digital', 'experience', 'human data', 'human subject', 'insight', 'models and simulation', 'neuropsychiatric disorder', 'neurosurgery', 'novel', 'therapy development', 'tool', 'tractography', 'virtual', 'white matter', 'young adult']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R56,2018,452250,0.015054187174381872
"SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy Project Abstract Advances in imaging have had a profound effect on our ability to generate high-resolution measurements of the brain’s structure. One of the major hurdles in processing modern neuroimaging datasets designed to produce large-scale maps of the connections and the organization of the brain lies in the sheer size of these data. For instance, electron microscopic (EM) images of a cubic millimeter of cortex occupies roughly 3 PBon disk, and lower resolution emerging X-ray microtomography (XRM) data can exceed 10 TB for a single mouse brain. When dealing with datasets of this size, the application of even simple algorithms becomes difficult. The size of datasets also exacerbates the considerable challenges for dissemination, reproducibility, and collaboration across laboratories. Addressing these challenges requires a new approach that leverages state-of-the-art computer science technology while remaining conscientious of the underlying bioinformatics. We propose Scalable Analytics for Brain Exploration Research (SABER), a user-friendly and portable framework that automates the retrieval, extraction, and analysis of large-scale imagery data to facilitate neuroscientific analyses. SABER aims to improve the reliability and reproducibility of neuroimagery research by providing a common substrate upon which algorithms may be developed. Leveraging SABER’s containers — a standardized packaging for software — this substrate can then be trivially transferred to other machines by the same researcher or by other teams aiming to reproduce or adapt the prior work, making sharing workflows and extracting knowledge commonplace. Using SABER will ensure that the analysis runs identically, regardless of by whom or where the workflow is executed. Because developing and deploying these analysis solutions for large image volumes are acute barriers to developing consistently reproducible workflows, SABER will further the neuroscientific analysis community by simplifying the workflow-development and workflow-execution steps. To demonstrate this, we plan to distribute two community-vetted, optimized workflows to convert large-scale EM and XRM volumetric imagery into maps of neuronal connectivity. Many neurological diseases are characterized by their impact on the density of cells and vessels, neuron death, connectivity, or other factors that are visible with imaging technologies. SABER will provide a framework for producing reproducible estimates of cell counts, vasculature density, and connectomes, thus enabling increased understanding of the impact of disease on the neuroanatomy of many brains. This work will enable the development of tools that can both be applied to massive data and shared amongst many scientists, which will in turn accelerate progress and neuroscientific discovery. Project Narrative: Our Johns Hopkins University Applied Physics Laboratory team leverages prior neuroscience analysis experience to present SABER: Scalable Analytics for Brain Exploration Research — a portable, easy-to-install framework that enables large-scale neuroanatomical data processing by providing a scaffold upon which highly-reproducible bioinformatics protocols may be built. To support emerging efforts to understand the biological basis of disease, we demonstrate turn-key pipelines to translate multi-terabyte electron microscopy and X-ray microtomography data volumes into maps of neuronal connectivity.",SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy,9733348,R24MH114799,"['Acute', 'Address', 'Algorithms', 'Artificial Arm', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Brain', 'Cell Count', 'Cell Density', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Discovery', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Ensure', 'Environment', 'Evaluation', 'Grant', 'Human Resources', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Infrastructure', 'Intelligence', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Microscopic', 'Modality', 'Modernization', 'Mus', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Neurons', 'Neurosciences', 'Optics', 'Physics', 'Pluto', 'Process', 'Protocols documentation', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrieval', 'Roentgen Rays', 'Running', 'Science', 'Scientist', 'Source', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translating', 'Traumatic Brain Injury', 'Universities', 'Work', 'brain research', 'brain tissue', 'computer science', 'computerized data processing', 'connectome', 'data access', 'data archive', 'data management', 'data sharing', 'density', 'design', 'experience', 'experimental study', 'high resolution imaging', 'improved', 'innovative neurotechnologies', 'microscopic imaging', 'millimeter', 'nervous system disorder', 'neuroimaging', 'neuron loss', 'novel', 'novel strategies', 'portability', 'relating to nervous system', 'scaffold', 'software development', 'terabyte', 'tool', 'tool development', 'user-friendly', 'virtual technology']",NIMH,JOHNS HOPKINS UNIVERSITY,R24,2019,379357,-0.0019689237149699734
"SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy Project Abstract Advances in imaging have had a profound effect on our ability to generate high-resolution measurements of the brain’s structure. One of the major hurdles in processing modern neuroimaging datasets designed to produce large-scale maps of the connections and the organization of the brain lies in the sheer size of these data. For instance, electron microscopic (EM) images of a cubic millimeter of cortex occupies roughly 3 PBon disk, and lower resolution emerging X-ray microtomography (XRM) data can exceed 10 TB for a single mouse brain. When dealing with datasets of this size, the application of even simple algorithms becomes difficult. The size of datasets also exacerbates the considerable challenges for dissemination, reproducibility, and collaboration across laboratories. Addressing these challenges requires a new approach that leverages state-of-the-art computer science technology while remaining conscientious of the underlying bioinformatics. We propose Scalable Analytics for Brain Exploration Research (SABER), a user-friendly and portable framework that automates the retrieval, extraction, and analysis of large-scale imagery data to facilitate neuroscientific analyses. SABER aims to improve the reliability and reproducibility of neuroimagery research by providing a common substrate upon which algorithms may be developed. Leveraging SABER’s containers — a standardized packaging for software — this substrate can then be trivially transferred to other machines by the same researcher or by other teams aiming to reproduce or adapt the prior work, making sharing workflows and extracting knowledge commonplace. Using SABER will ensure that the analysis runs identically, regardless of by whom or where the workflow is executed. Because developing and deploying these analysis solutions for large image volumes are acute barriers to developing consistently reproducible workflows, SABER will further the neuroscientific analysis community by simplifying the workflow-development and workflow-execution steps. To demonstrate this, we plan to distribute two community-vetted, optimized workflows to convert large-scale EM and XRM volumetric imagery into maps of neuronal connectivity. Many neurological diseases are characterized by their impact on the density of cells and vessels, neuron death, connectivity, or other factors that are visible with imaging technologies. SABER will provide a framework for producing reproducible estimates of cell counts, vasculature density, and connectomes, thus enabling increased understanding of the impact of disease on the neuroanatomy of many brains. This work will enable the development of tools that can both be applied to massive data and shared amongst many scientists, which will in turn accelerate progress and neuroscientific discovery. Project Narrative: Our Johns Hopkins University Applied Physics Laboratory team leverages prior neuroscience analysis experience to present SABER: Scalable Analytics for Brain Exploration Research — a portable, easy-to-install framework that enables large-scale neuroanatomical data processing by providing a scaffold upon which highly-reproducible bioinformatics protocols may be built. To support emerging efforts to understand the biological basis of disease, we demonstrate turn-key pipelines to translate multi-terabyte electron microscopy and X-ray microtomography data volumes into maps of neuronal connectivity.",SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy,9568023,R24MH114799,"['Acute', 'Address', 'Algorithms', 'Artificial Arm', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Brain', 'Cell Count', 'Cell Density', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Discovery', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Ensure', 'Environment', 'Evaluation', 'Grant', 'Human Resources', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Intelligence', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Microscopic', 'Modality', 'Modernization', 'Mus', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Neurons', 'Neurosciences', 'Optics', 'Physics', 'Pluto', 'Process', 'Protocols documentation', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrieval', 'Roentgen Rays', 'Running', 'Science', 'Scientist', 'Source', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translating', 'Traumatic Brain Injury', 'Universities', 'Work', 'brain research', 'brain tissue', 'computer science', 'computerized data processing', 'connectome', 'data access', 'data archive', 'data management', 'density', 'design', 'experience', 'experimental study', 'high resolution imaging', 'improved', 'innovative neurotechnologies', 'microscopic imaging', 'millimeter', 'nervous system disorder', 'neuroimaging', 'neuron loss', 'novel', 'novel strategies', 'portability', 'relating to nervous system', 'scaffold', 'software development', 'terabyte', 'tool', 'tool development', 'user-friendly', 'virtual']",NIMH,JOHNS HOPKINS UNIVERSITY,R24,2018,386960,-0.0019689237149699734
"SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy Project Abstract Advances in imaging have had a profound effect on our ability to generate high-resolution measurements of the brain’s structure. One of the major hurdles in processing modern neuroimaging datasets designed to produce large-scale maps of the connections and the organization of the brain lies in the sheer size of these data. For instance, electron microscopic (EM) images of a cubic millimeter of cortex occupies roughly 3 PBon disk, and lower resolution emerging X-ray microtomography (XRM) data can exceed 10 TB for a single mouse brain. When dealing with datasets of this size, the application of even simple algorithms becomes difficult. The size of datasets also exacerbates the considerable challenges for dissemination, reproducibility, and collaboration across laboratories. Addressing these challenges requires a new approach that leverages state-of-the-art computer science technology while remaining conscientious of the underlying bioinformatics. We propose Scalable Analytics for Brain Exploration Research (SABER), a user-friendly and portable framework that automates the retrieval, extraction, and analysis of large-scale imagery data to facilitate neuroscientific analyses. SABER aims to improve the reliability and reproducibility of neuroimagery research by providing a common substrate upon which algorithms may be developed. Leveraging SABER’s containers — a standardized packaging for software — this substrate can then be trivially transferred to other machines by the same researcher or by other teams aiming to reproduce or adapt the prior work, making sharing workflows and extracting knowledge commonplace. Using SABER will ensure that the analysis runs identically, regardless of by whom or where the workflow is executed. Because developing and deploying these analysis solutions for large image volumes are acute barriers to developing consistently reproducible workflows, SABER will further the neuroscientific analysis community by simplifying the workflow-development and workflow-execution steps. To demonstrate this, we plan to distribute two community-vetted, optimized workflows to convert large-scale EM and XRM volumetric imagery into maps of neuronal connectivity. Many neurological diseases are characterized by their impact on the density of cells and vessels, neuron death, connectivity, or other factors that are visible with imaging technologies. SABER will provide a framework for producing reproducible estimates of cell counts, vasculature density, and connectomes, thus enabling increased understanding of the impact of disease on the neuroanatomy of many brains. This work will enable the development of tools that can both be applied to massive data and shared amongst many scientists, which will in turn accelerate progress and neuroscientific discovery. Project Narrative: Our Johns Hopkins University Applied Physics Laboratory team leverages prior neuroscience analysis experience to present SABER: Scalable Analytics for Brain Exploration Research — a portable, easy-to-install framework that enables large-scale neuroanatomical data processing by providing a scaffold upon which highly-reproducible bioinformatics protocols may be built. To support emerging efforts to understand the biological basis of disease, we demonstrate turn-key pipelines to translate multi-terabyte electron microscopy and X-ray microtomography data volumes into maps of neuronal connectivity.",SABER: Scalable Analytics for Brain Exploration Research using X-Ray Microtomography and Electron Microscopy,9414126,R24MH114799,"['Acute', 'Address', 'Algorithms', 'Artificial Arm', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Brain', 'Cell Count', 'Cell Density', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Discovery', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Ensure', 'Environment', 'Evaluation', 'Grant', 'Human Resources', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Intelligence', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Microscopic', 'Modality', 'Modernization', 'Mus', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Neurons', 'Neurosciences', 'Optics', 'Physics', 'Pluto', 'Process', 'Protocols documentation', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retrieval', 'Roentgen Rays', 'Running', 'Science', 'Scientist', 'Source', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Tissue imaging', 'Tissues', 'Training', 'Translating', 'Traumatic Brain Injury', 'Universities', 'Work', 'brain research', 'brain tissue', 'computer science', 'computerized data processing', 'connectome', 'data access', 'data archive', 'data management', 'density', 'design', 'experience', 'experimental study', 'high resolution imaging', 'improved', 'innovative neurotechnologies', 'microscopic imaging', 'millimeter', 'nervous system disorder', 'neuroimaging', 'neuron loss', 'novel', 'novel strategies', 'portability', 'relating to nervous system', 'scaffold', 'software development', 'terabyte', 'tool', 'tool development', 'user-friendly', 'virtual']",NIMH,JOHNS HOPKINS UNIVERSITY,R24,2017,395542,-0.0019689237149699734
"Spatial Genomics for in situ single cell expression analysis in the brain Summary Identifying the spatial organization of tissues at cellular resolution from single cell gene expression profiles is essential to understanding neurological systems. We have developed a spatial genomics approach that allows in situ 3D multiplexed imaging of many genes in single cells called sequential Fluorescence in situ hybridization (seqFISH). This technology can profile transcriptional states of single cells directly in their native tissue context with up to 249 genes multiplexed with single molecule sensitivity on each gene. We have demonstrated over 15,000 cells profiled in mouse brain slices. This SBIR project will be focused on the design, production and optimization of an instrument that allows hundreds of genes to be multiplexed and imaged in single cells within their native tissue context. The resulting machine will be commercially launched and targeted to imaging or sequencing cores at research institutions. We will design the hardware, code the control software, and build the prototype instrument. We will engineer the hardware component including automated fluidics and multiple camera imaging system with a parallel effort to develop software controls as well as integrated analysis tools. In phase II, we will beta-test the instrument, generate probe sets for gene panels targeting different brain samples, and receive valuable feedback from users and optimize our instrument design. Narrative A major challenge of the BRAIN initiative and international Human Cell Atlas project is to identifying distinct cell populations in the brain within their native spatial environment. Addressing this challenge is essential not only to fundamental biological questions of understanding how different cell types interact to form neural circuits, but also essential in investigating mechanisms of human diseases where small subpopulations of cells, such as microglial, play pivotal roles. We have developed an in situ 3D multiplexed imaging method called sequential Fluorescence in situ hybridization (seqFISH), that can profile transcriptional states of single cells directly in a mouse coronal section with up to 249 genes multiplexed in the hippocampus and the cortex (Shah et al., Neuron 2016, Frieda et al., Nature 2016). Delivering this technology as a robust platform that can be used by neuroscientists would enable breakthrough discoveries and treatment options. To make this technology available for a broad range of users and customers, this phase I SBIR project will be focused on the design, production and optimization of an instrument called seqFISH100 and the parallel development of the control software to operate the seqFISH100.",Spatial Genomics for in situ single cell expression analysis in the brain,9730606,R43MH115538,"['3-Dimensional', 'Address', 'Adoption', 'Algorithms', 'Atlases', 'Automation', 'BRAIN initiative', 'Basic Science', 'Biological', 'Brain', 'Cells', 'Clinical Pathways', 'Clinical Research', 'Code', 'Computer software', 'Contracts', 'Custom', 'DNA Sequencing Facility', 'Development', 'Drops', 'Educational workshop', 'Effector Cell', 'Engineering', 'Environment', 'Expression Profiling', 'Feedback', 'Fluorescent in Situ Hybridization', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomic approach', 'Genomics', 'Hippocampus (Brain)', 'Human', 'Hypothalamic structure', 'Image', 'In Situ', 'Individual', 'Institutes', 'Institution', 'International', 'Intervention', 'Liquid substance', 'Machine Learning', 'Manufacturer Name', 'Measurement', 'Messenger RNA', 'Methods', 'Microscope', 'Molecular', 'Mus', 'Nature', 'Neuroglia', 'Neurologic', 'Neurons', 'Neurosciences', 'Pattern', 'Phase', 'Play', 'Population', 'Process', 'Production', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Services', 'Signal Transduction', 'Site', 'Slice', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Visualization software', 'Work', 'base', 'cell type', 'data visualization', 'design', 'experimental study', 'fluorescence imaging', 'genome wide association study', 'human disease', 'imaging modality', 'imaging system', 'instrument', 'interest', 'multiplexed\xa0imaging', 'neural circuit', 'operation', 'programs', 'prototype', 'scale up', 'single molecule', 'software development', 'tool', 'touchscreen', 'user-friendly']",NIMH,"SPATIAL GENOMICS, INC.",R43,2019,265936,0.0021673790748634536
"Spatial Genomics for in situ single cell expression analysis in the brain Summary Identifying the spatial organization of tissues at cellular resolution from single cell gene expression profiles is essential to understanding neurological systems. We have developed a spatial genomics approach that allows in situ 3D multiplexed imaging of many genes in single cells called sequential Fluorescence in situ hybridization (seqFISH). This technology can profile transcriptional states of single cells directly in their native tissue context with up to 249 genes multiplexed with single molecule sensitivity on each gene. We have demonstrated over 15,000 cells profiled in mouse brain slices. This SBIR project will be focused on the design, production and optimization of an instrument that allows hundreds of genes to be multiplexed and imaged in single cells within their native tissue context. The resulting machine will be commercially launched and targeted to imaging or sequencing cores at research institutions. We will design the hardware, code the control software, and build the prototype instrument. We will engineer the hardware component including automated fluidics and multiple camera imaging system with a parallel effort to develop software controls as well as integrated analysis tools. In phase II, we will beta-test the instrument, generate probe sets for gene panels targeting different brain samples, and receive valuable feedback from users and optimize our instrument design. Narrative A major challenge of the BRAIN initiative and international Human Cell Atlas project is to identifying distinct cell populations in the brain within their native spatial environment. Addressing this challenge is essential not only to fundamental biological questions of understanding how different cell types interact to form neural circuits, but also essential in investigating mechanisms of human diseases where small subpopulations of cells, such as microglial, play pivotal roles. We have developed an in situ 3D multiplexed imaging method called sequential Fluorescence in situ hybridization (seqFISH), that can profile transcriptional states of single cells directly in a mouse coronal section with up to 249 genes multiplexed in the hippocampus and the cortex (Shah et al., Neuron 2016, Frieda et al., Nature 2016). Delivering this technology as a robust platform that can be used by neuroscientists would enable breakthrough discoveries and treatment options. To make this technology available for a broad range of users and customers, this phase I SBIR project will be focused on the design, production and optimization of an instrument called seqFISH100 and the parallel development of the control software to operate the seqFISH100.",Spatial Genomics for in situ single cell expression analysis in the brain,9748985,R43MH115538,"['Address', 'Adoption', 'Algorithms', 'Atlases', 'Automation', 'BRAIN initiative', 'Basic Science', 'Biological', 'Brain', 'Cells', 'Clinical Pathways', 'Clinical Research', 'Code', 'Computer software', 'Contracts', 'Custom', 'DNA Sequencing Facility', 'Development', 'Drops', 'Educational workshop', 'Effector Cell', 'Engineering', 'Environment', 'Expression Profiling', 'Feedback', 'Fluorescent in Situ Hybridization', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomic approach', 'Genomics', 'Hippocampus (Brain)', 'Human', 'Hypothalamic structure', 'Image', 'In Situ', 'Individual', 'Institutes', 'Institution', 'International', 'Intervention', 'Liquid substance', 'Machine Learning', 'Manufacturer Name', 'Measurement', 'Messenger RNA', 'Methods', 'Microscope', 'Molecular', 'Mus', 'Nature', 'Neuroglia', 'Neurologic', 'Neurons', 'Neurosciences', 'Pattern', 'Phase', 'Play', 'Population', 'Process', 'Production', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Services', 'Signal Transduction', 'Site', 'Slice', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Visualization software', 'Work', 'base', 'cell type', 'data visualization', 'design', 'experimental study', 'fluorescence imaging', 'genome wide association study', 'human disease', 'imaging modality', 'imaging system', 'instrument', 'interest', 'neural circuit', 'operation', 'programs', 'prototype', 'scale up', 'single molecule', 'software development', 'tool', 'touchscreen', 'user-friendly']",NIMH,"SPATIAL GENOMICS, INC.",R43,2018,30000,0.0021673790748634536
"Spatial Genomics for in situ single cell expression analysis in the brain Summary Identifying the spatial organization of tissues at cellular resolution from single cell gene expression profiles is essential to understanding neurological systems. We have developed a spatial genomics approach that allows in situ 3D multiplexed imaging of many genes in single cells called sequential Fluorescence in situ hybridization (seqFISH). This technology can profile transcriptional states of single cells directly in their native tissue context with up to 249 genes multiplexed with single molecule sensitivity on each gene. We have demonstrated over 15,000 cells profiled in mouse brain slices. This SBIR project will be focused on the design, production and optimization of an instrument that allows hundreds of genes to be multiplexed and imaged in single cells within their native tissue context. The resulting machine will be commercially launched and targeted to imaging or sequencing cores at research institutions. We will design the hardware, code the control software, and build the prototype instrument. We will engineer the hardware component including automated fluidics and multiple camera imaging system with a parallel effort to develop software controls as well as integrated analysis tools. In phase II, we will beta-test the instrument, generate probe sets for gene panels targeting different brain samples, and receive valuable feedback from users and optimize our instrument design. Narrative A major challenge of the BRAIN initiative and international Human Cell Atlas project is to identifying distinct cell populations in the brain within their native spatial environment. Addressing this challenge is essential not only to fundamental biological questions of understanding how different cell types interact to form neural circuits, but also essential in investigating mechanisms of human diseases where small subpopulations of cells, such as microglial, play pivotal roles. We have developed an in situ 3D multiplexed imaging method called sequential Fluorescence in situ hybridization (seqFISH), that can profile transcriptional states of single cells directly in a mouse coronal section with up to 249 genes multiplexed in the hippocampus and the cortex (Shah et al., Neuron 2016, Frieda et al., Nature 2016). Delivering this technology as a robust platform that can be used by neuroscientists would enable breakthrough discoveries and treatment options. To make this technology available for a broad range of users and customers, this phase I SBIR project will be focused on the design, production and optimization of an instrument called seqFISH100 and the parallel development of the control software to operate the seqFISH100.",Spatial Genomics for in situ single cell expression analysis in the brain,9559516,R43MH115538,"['Address', 'Adoption', 'Algorithms', 'Atlases', 'Automation', 'BRAIN initiative', 'Basic Science', 'Biological', 'Brain', 'Cells', 'Clinical Pathways', 'Clinical Research', 'Code', 'Computer software', 'Contracts', 'Custom', 'DNA Sequencing Facility', 'Development', 'Drops', 'Educational workshop', 'Effector Cell', 'Engineering', 'Environment', 'Expression Profiling', 'Feedback', 'Fluorescent in Situ Hybridization', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomic approach', 'Genomics', 'Hippocampus (Brain)', 'Human', 'Hypothalamic structure', 'Image', 'In Situ', 'Individual', 'Institutes', 'Institution', 'International', 'Intervention', 'Liquid substance', 'Machine Learning', 'Manufacturer Name', 'Measurement', 'Messenger RNA', 'Methods', 'Microscope', 'Molecular', 'Mus', 'Nature', 'Neuroglia', 'Neurologic', 'Neurons', 'Neurosciences', 'Pattern', 'Phase', 'Play', 'Population', 'Process', 'Production', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Services', 'Signal Transduction', 'Site', 'Slice', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Visualization software', 'Work', 'base', 'cell type', 'data visualization', 'design', 'experimental study', 'fluorescence imaging', 'genome wide association study', 'human disease', 'imaging modality', 'imaging system', 'instrument', 'interest', 'neural circuit', 'operation', 'programs', 'prototype', 'scale up', 'single molecule', 'software development', 'tool', 'touchscreen', 'user-friendly']",NIMH,"SPATIAL GENOMICS, INC.",R43,2018,885468,0.0021673790748634536
"Novel single cell assay for quantitative analysis of cell heterogeneity by noninvasive probing of molecular composition of specific organelles in individual cells Project Summary ACIS, LLC proposes a conceptually novel cellular heterogeneity assay, based on confocal Raman  spectrometry and Biomolecular Component Analysis (BCA). The goal of Phase II is to implement a BCA toolbox in a commercial confocal micro- Raman instrument  for quantitative assessment of cellular heterogeneity and potential quantitative classification of  cellular states based on macromolecular compositions in specific organelles, a single cell assay  developed during the Phase I, Phase II focuses on bringing this new device to the market. This project is motivated by the fact, that there is no currently any commercial tool, which  provides direct probing of local biomolecular concentration in live cells. At the same time, this  tool is extremely valuable for solving a number of problems, which require determination of  quantitative markers for different cellular states (i) in diseased cell population  (cancer-non-cancer, different cancer stages etc), (ii) during cell-drug interaction, and (iii) in  the intracellular processes (apoptosis, proliferation, differentiation, etc). The Phase I research and development of this assay have met stated technical milestones. In  particular, it is found that the BCA potential for characterization of cellular heterogeneity  significantly exceeds that of the standard math tool of Principal Component Analysis routinely used  for analysis of Raman spectra,. The specific aims of this proposal are: (1) Adaptation of a Thermo-Fisher micro-Raman system DXR2  model to meet requirements for BCA applications; (2) Development of Biomolecular Component Analysis   Software package in C++ and/or Java and incorporation to DXR2 model of Thermo-Fisher micro-Raman  system; (3) Validation of the BCA toolbox integrated with Thermo-Fisher micro-Raman system DXR2  model for ongoing biomedical research (a) Comparative analysis of heterogeneity between IDH-  mutated and WT-IDH glioma cells and assessment of cell-drug interaction in IDH-mutant cells in  collaboration with NCI, (Bethesda, MD) (b) Molecular profiling of cellular organelles for  categorization of Prostate Cancer with RPCI (Buffalo, NY); (4) Pre-market evaluation of the  Thermo-Fisher DXR2 micro-Raman system, equipped by the BCA toolbox. The outcome of this project will be a commercial confocal micro-Raman system with an implemented  BCA toolbox, along with customized software for quantitative assessment of cellular heterogeneity,  which can be used for a broad range of biomedical applications in many sectors such as clinical  labs, Biomedical cellular Research labs, Pharmaceutical industries, National Cancer Institutes ,  etc. ACIS, LLC proposes to implement a conceptually novel cellular heterogeneity assay, based on  confocal Raman spectrometry and Biomolecular Component Analysis (BCA), in a commercial confocal  micro-Raman system. This assay will be implemented as BCA toolbox for quantitative assessment of  macromolecular concentrations in specific cellular organelles.",Novel single cell assay for quantitative analysis of cell heterogeneity by noninvasive probing of molecular composition of specific organelles in individual cells,9565597,R44GM116193,"['Analysis of Variance', 'Apoptosis', 'Biological Assay', 'Biomedical Research', 'Buffaloes', 'Calibration', 'Cells', 'Cellular Assay', 'Classification', 'Clinical', 'Collaborations', 'Computer software', 'Custom', 'Data', 'Development', 'Devices', 'Disease', 'Drug Industry', 'Drug Interactions', 'Evaluation', 'Glioma', 'Goals', 'Heterogeneity', 'Individual', 'Java', 'Least-Squares Analysis', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Manufacturer Name', 'Mathematics', 'Modeling', 'Molecular Probes', 'Molecular Profiling', 'Mutate', 'National Cancer Institute', 'Optics', 'Organelles', 'Outcome', 'Pharmacology', 'Phase', 'Population', 'Principal Component Analysis', 'Procedures', 'Process', 'Raman Spectrum Analysis', 'Research', 'Site', 'System', 'Techniques', 'Therapeutic', 'Time', 'Validation', 'assay development', 'base', 'commercialization', 'comparative', 'cost', 'curve fitting', 'graphical user interface', 'instrument', 'mutant', 'neuro-oncology', 'novel', 'research and development', 'tool', 'user-friendly']",NIGMS,ADVANCED CYTOMETRY INSTRUMENTATION SYS,R44,2018,523168,0.008099560905482465
"Novel single cell assay for quantitative analysis of cell heterogeneity by noninvasive probing of molecular composition of specific organelles in individual cells Project Summary ACIS, LLC proposes a conceptually novel cellular heterogeneity assay, based on confocal Raman  spectrometry and Biomolecular Component Analysis (BCA). The goal of Phase II is to implement a BCA toolbox in a commercial confocal micro- Raman instrument  for quantitative assessment of cellular heterogeneity and potential quantitative classification of  cellular states based on macromolecular compositions in specific organelles, a single cell assay  developed during the Phase I, Phase II focuses on bringing this new device to the market. This project is motivated by the fact, that there is no currently any commercial tool, which  provides direct probing of local biomolecular concentration in live cells. At the same time, this  tool is extremely valuable for solving a number of problems, which require determination of  quantitative markers for different cellular states (i) in diseased cell population  (cancer-non-cancer, different cancer stages etc), (ii) during cell-drug interaction, and (iii) in  the intracellular processes (apoptosis, proliferation, differentiation, etc). The Phase I research and development of this assay have met stated technical milestones. In  particular, it is found that the BCA potential for characterization of cellular heterogeneity  significantly exceeds that of the standard math tool of Principal Component Analysis routinely used  for analysis of Raman spectra,. The specific aims of this proposal are: (1) Adaptation of a Thermo-Fisher micro-Raman system DXR2  model to meet requirements for BCA applications; (2) Development of Biomolecular Component Analysis   Software package in C++ and/or Java and incorporation to DXR2 model of Thermo-Fisher micro-Raman  system; (3) Validation of the BCA toolbox integrated with Thermo-Fisher micro-Raman system DXR2  model for ongoing biomedical research (a) Comparative analysis of heterogeneity between IDH-  mutated and WT-IDH glioma cells and assessment of cell-drug interaction in IDH-mutant cells in  collaboration with NCI, (Bethesda, MD) (b) Molecular profiling of cellular organelles for  categorization of Prostate Cancer with RPCI (Buffalo, NY); (4) Pre-market evaluation of the  Thermo-Fisher DXR2 micro-Raman system, equipped by the BCA toolbox. The outcome of this project will be a commercial confocal micro-Raman system with an implemented  BCA toolbox, along with customized software for quantitative assessment of cellular heterogeneity,  which can be used for a broad range of biomedical applications in many sectors such as clinical  labs, Biomedical cellular Research labs, Pharmaceutical industries, National Cancer Institutes ,  etc. ACIS, LLC proposes to implement a conceptually novel cellular heterogeneity assay, based on  confocal Raman spectrometry and Biomolecular Component Analysis (BCA), in a commercial confocal  micro-Raman system. This assay will be implemented as BCA toolbox for quantitative assessment of  macromolecular concentrations in specific cellular organelles.",Novel single cell assay for quantitative analysis of cell heterogeneity by noninvasive probing of molecular composition of specific organelles in individual cells,9407906,R44GM116193,"['Analysis of Variance', 'Apoptosis', 'Biological Assay', 'Biomedical Research', 'Buffaloes', 'Calibration', 'Cells', 'Classification', 'Clinical', 'Collaborations', 'Computer software', 'Custom', 'Data', 'Development', 'Devices', 'Disease', 'Drug Industry', 'Drug Interactions', 'Evaluation', 'Glioma', 'Goals', 'Heterogeneity', 'Individual', 'Java', 'Least-Squares Analysis', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Manufacturer Name', 'Mathematics', 'Modeling', 'Molecular Probes', 'Molecular Profiling', 'Mutate', 'National Cancer Institute', 'Optics', 'Organelles', 'Outcome', 'Pharmacology', 'Phase', 'Population', 'Principal Component Analysis', 'Procedures', 'Process', 'Raman Spectrum Analysis', 'Research', 'Site', 'System', 'Techniques', 'Therapeutic', 'Time', 'Validation', 'assay development', 'base', 'commercialization', 'comparative', 'cost', 'curve fitting', 'graphical user interface', 'instrument', 'mutant', 'neuro-oncology', 'novel', 'research and development', 'tool', 'user-friendly']",NIGMS,ADVANCED CYTOMETRY INSTRUMENTATION SYS,R44,2017,670777,0.008099560905482465
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7661365,R01CA116778,"['Algorithms', 'Bioinformatics', 'Cancer Etiology', 'Characteristics', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Disease Progression', 'Etiology', 'Event', 'Foundations', 'Genetic', 'Genetic Transcription', 'Genomics', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Monitor', 'Mutation', 'Oncogenic', 'Patients', 'Pattern', 'Phenotype', 'Research Infrastructure', 'Resources', 'Signal Transduction', 'Statistical Models', 'Transcriptional Regulation', 'Treatment Efficacy', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'cell growth', 'combinatorial', 'graphical user interface', 'prognostic', 'tool', 'transcription factor', 'treatment response']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2009,199526,-0.016524364868420644
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7477758,R01CA116778,"['Algorithms', 'Bioinformatics', 'Cancer Etiology', 'Characteristics', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Disease Progression', 'Etiology', 'Event', 'Foundations', 'Genetic', 'Genetic Transcription', 'Genomics', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Monitor', 'Mutation', 'Oncogenic', 'Patients', 'Pattern', 'Phenotype', 'Research Infrastructure', 'Resources', 'Signal Transduction', 'Statistical Models', 'Transcriptional Regulation', 'Treatment Efficacy', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'cell growth', 'combinatorial', 'graphical user interface', 'prognostic', 'response', 'tool', 'transcription factor']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2008,363604,-0.016524364868420644
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7882364,R01CA116778,"['Algorithms', 'Bioinformatics', 'Cancer Etiology', 'Characteristics', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Disease Progression', 'Etiology', 'Event', 'Foundations', 'Genetic', 'Genetic Transcription', 'Genomics', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Monitor', 'Mutation', 'Oncogenic', 'Patients', 'Pattern', 'Phenotype', 'Research Infrastructure', 'Resources', 'Signal Transduction', 'Statistical Models', 'Transcriptional Regulation', 'Treatment Efficacy', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'cell growth', 'combinatorial', 'graphical user interface', 'prognostic', 'tool', 'transcription factor', 'treatment response']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2010,199526,-0.016524364868420644
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7291530,R01CA116778,"['Algorithms', 'Bioinformatics', 'Cancer Etiology', 'Characteristics', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Disease Progression', 'Etiology', 'Event', 'Foundations', 'Genetic', 'Genetic Transcription', 'Genomics', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Monitor', 'Mutation', 'Oncogenic', 'Patients', 'Pattern', 'Phenotype', 'Research Infrastructure', 'Resources', 'Signal Transduction', 'Statistical Models', 'Transcriptional Regulation', 'Treatment Efficacy', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'cell growth', 'combinatorial', 'graphical user interface', 'prognostic', 'response', 'tool', 'transcription factor']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2007,439085,-0.016524364868420644
"Combinatorial Genomics in Cancer    DESCRIPTION (provided by applicant): Targeted therapy of cancer requires a clear understanding of the genetic alterations that drive malignant cell growth. Identification of causal genetic alterations is complicated by three characteristics of cancer etiology: 1.) multiple interacting alterations are often required to cause cancer, 2.) several distinct alterations may be sufficient to generate a single cancer phenotype, and 3.) oncogenic alterations appear in a dense background of normal genetic activity and spurious consequences of malignant cell growth. We propose to apply a variant of the machine learning algorithm PRIM to the task of identifying disjunctive sets of conjunctive genetic alterations that cause specific cancers or provide prognostic information about clinical course and treatment efficacy. These analyses synthesize information from low-level bioinformatics resources we have already developed to map chromosomal alterations and monitor global patterns of transcription factor activity. Based on those foundations, the present studies develop high-level analytic tools to map combinatorial interactions among low-level genomic events. Specifically, these studies seek to: Aim 1: Develop graphical user interface (GUI) software to support combinatorial genomic analyses by biologists with limited computational background. Aim 2: Optimize combinatorial prediction of disease progression and treatment response. Aim 3: Develop PRIM-based statistical models to identify functional complementation groups of genetic alterations and transcriptional control signals. The bioinformatic tools produced in these studies will create a generalized analytic infrastructure for mapping complex etiologies in cancer and deploying patient-specific targeted therapies.          n/a",Combinatorial Genomics in Cancer,7213111,R01CA116778,"['bioinformatics', 'clinical research', 'genetics', 'neoplasm /cancer']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,274238,-0.016524364868420644
"Towards integrated 3D reconstruction of whole human brains at subcellular resolution Project Summary A detailed understanding of the anatomical and molecular architectures of brain cells and their brain-wide organization is essential for interrogating human brain function and dysfunction. Extensive efforts have been made toward mapping brain cells through various lenses, which have established invaluable databases yielding new insights. However, integrative extraction of the multimodal properties of various cell-types brain-wide within the same brain, crucial to elucidating complex intercellular relationships, remains nearly impossible. We have developed high-throughput, cost-effective technology platforms to create a fully integrated three-dimensional (3D) human brain cell atlas by simultaneously mapping high-dimensional features (e.g., spatial, molecular, morphological, and microenvironment information) of all cells acquired from the same whole brain. The proposed work will establish the most comprehensive 3D human brain map to date, with unprecedented resolution and completeness. We envision that this atlas will facilitate the integration of a broad range of studies and allow the research community to interrogate human brain structure and function at multiple levels. In Aim 1, we will apply a novel technology to transform whole human brain tissue into indestructible hydrogel–tissue hybrids that allow highly multiplexed molecular labeling and subcellular-resolution volume imaging. In Aim 2, we will apply scalable labeling and imaging technologies to map the brain-wide 3D distribution of various cell-type and structural markers at subcellular resolution within the same brain. Our chemical engineering–based approach to this aim will enable cost-effective, lossless 3D labeling of the entire human brain at lower cost as traditional subsampling approaches. True volume labeling and subcellular-resolution imaging will allow us to extract fine morphological and connectivity information from labeled cells and reconstruct the microenvironment of all cells. In Aim 3, we will use a host of rapid and highly automated algorithms to perform unbiased, integrative high- dimensional phenotyping of all cells based on their spatial location, molecular expression, morphology, and microenvironment. In Aim 4, we will perform super-resolution phenotyping of cells in a selected brain region from the same sample used in Aim 3 to map inter-areal axonal connectivity at single-fiber resolution and to characterize chemical synapses. This integrative approach will likely unveil unique cell-types and brain regions, a crucial step toward a better understanding of brain function. The complete 3D dataset will be linked to magnetic resonance and diffusion spectrum images and existing reference atlases to facilitate the integration of a wide breadth of study at multiple levels and to make the data publicly accessible for mining and analysis. A detailed picture of the human brain’s complex intermolecular, intercellular, and interareal interactions is of paramount importance for understanding its function and dysfunction. However, the immense complexity of the human brain and the absence of enabling technologies have hither-to made it impossible to interrogate these interactions brain-wide. Here we propose to use a host of new technology platforms to create a fully integrated whole human brain cell atlas with unprecedented levels of resolution and completeness.",Towards integrated 3D reconstruction of whole human brains at subcellular resolution,9935968,U01MH117072,"['3-Dimensional', 'Algorithms', 'Anatomy', 'Antibodies', 'Architecture', 'Atlases', 'Axon', 'Brain', 'Brain Mapping', 'Brain Stem', 'Brain region', 'Cell Nucleus', 'Cells', 'Cerebral hemisphere', 'Chemical Engineering', 'Chemical Synapse', 'Communities', 'Complex', 'Custom', 'Cytoplasm', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Disease', 'Dyes', 'Fiber', 'Formalin', 'Functional disorder', 'Goals', 'Histologic', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Label', 'Left', 'Libraries', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Microscope', 'Mining', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Optics', 'Pattern', 'Permeability', 'Phenotype', 'Process', 'Property', 'Proteins', 'Proteome', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Slice', 'Stains', 'Structure', 'Synapses', 'Techniques', 'Technology', 'Thick', 'Tissues', 'Work', 'antibody libraries', 'automated algorithm', 'base', 'brain cell', 'brain tissue', 'cell type', 'cost', 'cost effective', 'deep learning', 'high dimensionality', 'imaging biomarker', 'insight', 'lens', 'macromolecule', 'molecular phenotype', 'multidisciplinary', 'multimodal data', 'multimodality', 'new technology', 'novel', 'novel therapeutics', 'preservation', 'reconstruction', 'spectrograph', 'two-photon']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2020,1563930,0.023259121163879855
"Towards integrated 3D reconstruction of whole human brains at subcellular resolution Project Summary A detailed understanding of the anatomical and molecular architectures of brain cells and their brain-wide organization is essential for interrogating human brain function and dysfunction. Extensive efforts have been made toward mapping brain cells through various lenses, which have established invaluable databases yielding new insights. However, integrative extraction of the multimodal properties of various cell-types brain-wide within the same brain, crucial to elucidating complex intercellular relationships, remains nearly impossible. We have developed high-throughput, cost-effective technology platforms to create a fully integrated three-dimensional (3D) human brain cell atlas by simultaneously mapping high-dimensional features (e.g., spatial, molecular, morphological, and microenvironment information) of all cells acquired from the same whole brain. The proposed work will establish the most comprehensive 3D human brain map to date, with unprecedented resolution and completeness. We envision that this atlas will facilitate the integration of a broad range of studies and allow the research community to interrogate human brain structure and function at multiple levels. In Aim 1, we will apply a novel technology to transform whole human brain tissue into indestructible hydrogel–tissue hybrids that allow highly multiplexed molecular labeling and subcellular-resolution volume imaging. In Aim 2, we will apply scalable labeling and imaging technologies to map the brain-wide 3D distribution of various cell-type and structural markers at subcellular resolution within the same brain. Our chemical engineering–based approach to this aim will enable cost-effective, lossless 3D labeling of the entire human brain at lower cost as traditional subsampling approaches. True volume labeling and subcellular-resolution imaging will allow us to extract fine morphological and connectivity information from labeled cells and reconstruct the microenvironment of all cells. In Aim 3, we will use a host of rapid and highly automated algorithms to perform unbiased, integrative high- dimensional phenotyping of all cells based on their spatial location, molecular expression, morphology, and microenvironment. In Aim 4, we will perform super-resolution phenotyping of cells in a selected brain region from the same sample used in Aim 3 to map inter-areal axonal connectivity at single-fiber resolution and to characterize chemical synapses. This integrative approach will likely unveil unique cell-types and brain regions, a crucial step toward a better understanding of brain function. The complete 3D dataset will be linked to magnetic resonance and diffusion spectrum images and existing reference atlases to facilitate the integration of a wide breadth of study at multiple levels and to make the data publicly accessible for mining and analysis. A detailed picture of the human brain’s complex intermolecular, intercellular, and interareal interactions is of paramount importance for understanding its function and dysfunction. However, the immense complexity of the human brain and the absence of enabling technologies have hither-to made it impossible to interrogate these interactions brain-wide. Here we propose to use a host of new technology platforms to create a fully integrated whole human brain cell atlas with unprecedented levels of resolution and completeness.",Towards integrated 3D reconstruction of whole human brains at subcellular resolution,9768578,U01MH117072,"['3-Dimensional', 'Algorithms', 'Anatomy', 'Antibodies', 'Architecture', 'Atlases', 'Axon', 'Brain', 'Brain Mapping', 'Brain Stem', 'Brain region', 'Cell Nucleus', 'Cells', 'Cerebral hemisphere', 'Chemical Engineering', 'Chemical Synapse', 'Communities', 'Complex', 'Custom', 'Cytoplasm', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Disease', 'Dyes', 'Fiber', 'Formalin', 'Functional disorder', 'Goals', 'Histologic', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Label', 'Left', 'Libraries', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Microscope', 'Mining', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Optics', 'Pattern', 'Permeability', 'Phenotype', 'Process', 'Property', 'Proteins', 'Proteome', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Slice', 'Stains', 'Structure', 'Synapses', 'Techniques', 'Technology', 'Thick', 'Tissues', 'Work', 'antibody libraries', 'base', 'brain cell', 'brain tissue', 'cell type', 'cost', 'cost effective', 'deep learning', 'high dimensionality', 'imaging biomarker', 'insight', 'lens', 'macromolecule', 'molecular phenotype', 'multidisciplinary', 'multimodality', 'new technology', 'novel', 'novel therapeutics', 'preservation', 'reconstruction', 'spectrograph', 'two-photon']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2019,2003389,0.023259121163879855
"Towards integrated 3D reconstruction of whole human brains at subcellular resolution Project Summary A detailed understanding of the anatomical and molecular architectures of brain cells and their brain-wide organization is essential for interrogating human brain function and dysfunction. Extensive efforts have been made toward mapping brain cells through various lenses, which have established invaluable databases yielding new insights. However, integrative extraction of the multimodal properties of various cell-types brain-wide within the same brain, crucial to elucidating complex intercellular relationships, remains nearly impossible. We have developed high-throughput, cost-effective technology platforms to create a fully integrated three-dimensional (3D) human brain cell atlas by simultaneously mapping high-dimensional features (e.g., spatial, molecular, morphological, and microenvironment information) of all cells acquired from the same whole brain. The proposed work will establish the most comprehensive 3D human brain map to date, with unprecedented resolution and completeness. We envision that this atlas will facilitate the integration of a broad range of studies and allow the research community to interrogate human brain structure and function at multiple levels. In Aim 1, we will apply a novel technology to transform whole human brain tissue into indestructible hydrogel–tissue hybrids that allow highly multiplexed molecular labeling and subcellular-resolution volume imaging. In Aim 2, we will apply scalable labeling and imaging technologies to map the brain-wide 3D distribution of various cell-type and structural markers at subcellular resolution within the same brain. Our chemical engineering–based approach to this aim will enable cost-effective, lossless 3D labeling of the entire human brain at lower cost as traditional subsampling approaches. True volume labeling and subcellular-resolution imaging will allow us to extract fine morphological and connectivity information from labeled cells and reconstruct the microenvironment of all cells. In Aim 3, we will use a host of rapid and highly automated algorithms to perform unbiased, integrative high- dimensional phenotyping of all cells based on their spatial location, molecular expression, morphology, and microenvironment. In Aim 4, we will perform super-resolution phenotyping of cells in a selected brain region from the same sample used in Aim 3 to map inter-areal axonal connectivity at single-fiber resolution and to characterize chemical synapses. This integrative approach will likely unveil unique cell-types and brain regions, a crucial step toward a better understanding of brain function. The complete 3D dataset will be linked to magnetic resonance and diffusion spectrum images and existing reference atlases to facilitate the integration of a wide breadth of study at multiple levels and to make the data publicly accessible for mining and analysis. A detailed picture of the human brain’s complex intermolecular, intercellular, and interareal interactions is of paramount importance for understanding its function and dysfunction. However, the immense complexity of the human brain and the absence of enabling technologies have hither-to made it impossible to interrogate these interactions brain-wide. Here we propose to use a host of new technology platforms to create a fully integrated whole human brain cell atlas with unprecedented levels of resolution and completeness.",Towards integrated 3D reconstruction of whole human brains at subcellular resolution,9584926,U01MH117072,"['Algorithms', 'Anatomy', 'Antibodies', 'Architecture', 'Atlases', 'Axon', 'Brain', 'Brain Mapping', 'Brain Stem', 'Brain region', 'Cell Nucleus', 'Cells', 'Cerebral hemisphere', 'Chemical Engineering', 'Chemical Synapse', 'Communities', 'Complex', 'Custom', 'Cytoplasm', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Disease', 'Dyes', 'Fiber', 'Formalin', 'Functional disorder', 'Goals', 'Histologic', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Imaging technology', 'Individual', 'Knowledge', 'Label', 'Left', 'Libraries', 'Link', 'Location', 'MRI Scans', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Microscope', 'Mining', 'Molecular', 'Molecular Profiling', 'Morphology', 'Mus', 'Optics', 'Pattern', 'Permeability', 'Phenotype', 'Process', 'Property', 'Proteins', 'Proteome', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Slice', 'Stains', 'Structure', 'Synapses', 'Techniques', 'Technology', 'Thick', 'Tissues', 'Work', 'antibody libraries', 'base', 'brain cell', 'brain tissue', 'cell type', 'cost', 'cost effective', 'deep learning', 'high dimensionality', 'imaging biomarker', 'insight', 'lens', 'macromolecule', 'molecular phenotype', 'multidisciplinary', 'multimodality', 'new technology', 'novel', 'novel therapeutics', 'reconstruction', 'spectrograph', 'two-photon']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,U01,2018,1882491,0.023259121163879855
"Neurosurgical Planning with Robust Eloquent area Delineation from Individualized Connectivity-based Techniques (NeuroPREDICT) Project Summary/Abstract  The idiosyncrasies of the human brain require that individualized mapping of functional regions be performed before surgical interventions for cancer or epilepsy. The success of this mapping procedure has direct effects on surgical outcomes and preserving cognitive and sensory function post-surgery. Current gold standard procedures for pre-surgical mapping are invasive, time-consuming, and technically demanding. Several non-invasive procedures have emerged in recent years; however, they have not yet displaced the gold standard procedures. Task-based functional magnetic resonance imaging (t-fMRI), the most widely used non-invasive pre-surgical mapping technique, requires that patients perform cognitive or motor tasks while in the scanner—a time-consuming and expensive procedure. Also, not all patients can perform fMRI tasks due to language barriers, sensory deficits, being unconscious, etc. Connectome Fingerprinting (CF) is a recently developed technique that uses machine learning to train a model capable of predicting functional brain activation from task-free resting-state fMRI (rs-fMRI). Once trained on a set of t-fMRI and rs- fMRI data, an unseen subject's unique pattern of brain activation can be predicted using only an rs-fMRI scan of their brain—therefore eliminating the need to perform tasks during the fMRI scan. Despite the promise of CF, the accuracy of the current best practice modeling techniques is not high enough yet to be clinically useful and studies applying CF have nearly always used healthy populations. Much research remains to be done to increase the accuracy of CF models before they can be deployed for pre-surgical mapping.  The long-term objective of the research proposed here is to develop a software application that combines applied machine learning with medical imaging to provide a non-invasive means for mapping the brains of neurosurgical patients before surgery. Importantly, we aim to increase the accuracy of CF modeling by expanding the modeling efforts to probabilistic Bayesian approaches that leverage prior information from the structure of the data. We will test a wide array of tunable data and model parameters to arrive at a current recommendation for best practices in CF research and applications. Finally, we will test our modeling procedures with a dataset of healthy control and pre-surgical patients diagnosed with brain tumors. We will test the software's ability to accurately predict functional brain organization in these patients and adaptively retrain the models to produce the most accurate results. This work has the potential to revolutionize pre-surgical brain mapping and expand its applicability to a greater number of patients. Project Narrative  In the United States, approximately 24,000 new cases of brain tumors are reported each year, with many patients requiring expensive pre-surgical planning and mapping of functional regions to minimize post-surgical impairments. In many neurosurgical practices [96% per 1], this involves performing a time-consuming and costly task-based fMRI acquisitions (nearly $1200/scan in 2014; [2]) before surgery to identify eloquent brain areas recruited for motor control, language, and cognition that must be spared during surgery. By combing task-based fMRI, resting-state fMRI and advanced machine learning to map the functional topology of the brain, the proposed technology will lower pre-surgical planning costs, reduce the burden on physicians and technicians, and expand pre-surgical mapping to previously excluded patients who cannot perform fMRI tasks.",Neurosurgical Planning with Robust Eloquent area Delineation from Individualized Connectivity-based Techniques (NeuroPREDICT),10139299,R43NS117226,"['Activities of Daily Living', 'Anatomy', 'Area', 'Bayesian Method', 'Blindness', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Cancer Intervention', 'Clinical', 'Cognition', 'Cognitive', 'Comb animal structure', 'Computer software', 'Conscious', 'Consumption', 'Cost Savings', 'Data', 'Data Set', 'Diagnosis', 'Engineering', 'Ensure', 'Epilepsy', 'Evaluation', 'Fingerprint', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Generations', 'Gold', 'Government', 'Health Care Costs', 'Healthcare Systems', 'Hospitals', 'Human', 'Impairment', 'Individual', 'Language', 'Learning', 'Linear Models', 'Machine Learning', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Motor', 'Neurologic', 'Neurosurgeon', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Physicians', 'Population', 'Preparation', 'Procedures', 'Recommendation', 'Reporting', 'Research', 'Rest', 'Scanning', 'Sensory', 'Software Engineering', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unconscious State', 'United States', 'Validation', 'Visual', 'Visual impairment', 'Woman', 'Work', 'anatomic imaging', 'base', 'cognitive task', 'compliance behavior', 'computerized data processing', 'connectome', 'cost', 'data acquisition', 'data quality', 'design', 'functional MRI scan', 'improved', 'individual variation', 'large scale data', 'motor control', 'multisensory', 'next generation', 'preservation', 'prototype', 'recruit', 'structured data', 'success', 'surgery outcome', 'usability']",NINDS,"CHARLES RIVER ANALYTICS, INC.",R43,2020,252569,0.0015788196378774542
"Genetic and Epidemiological Predictors of Glucose Homeostasis Measures Summary Insulin sensitivity and insulin secretion are traits that have a significant impact on the risk of type 2 diabetes (T2D). The over-arching goal of this proposal is to understand the pathophysiology underlying variation of these intermediate phenotypes in Mexican Americans, the largest US minority group and one at high risk of T2D. The Genetics Underlying Diabetes in Hispanics (GUARDIAN) Consortium represents the largest effort to identify the genetic determinants underlying diabetes-related intermediate phenotypes (DK085175). During the previous funding period, genome-wide association studies (GWAS) focused on common genetic variation identified four genome-wide significant loci underlying variation in glucose homeostasis traits which translated to the clinical endpoint, T2D. In this application, we will build upon significant prior genetic findings with integration of biological (metabolomics) and analytical (hierarchical clustering and interaction analysis) approaches to further refine insulin resistance and insulin secretion phenotypes and explore their biological basis. Aim 1 will develop a novel methodology using existing GWAS and metabolomics data to impute genetically regulated metabolites (GReM) and test their association with measures of glucose homeostasis in the GUARDIAN Consortium. Aim 2 will refine known and novel variants associated with T2D and related phenotypes through hierarchical clustering and perform interaction analyses which exploit the bimodal nature of T2D to identify additional insulin resistance loci. Aim 3 will identify genetic determinants of dynamic measures of glucose homeostasis in diverse human populations and translate these loci to T2D. The unique strengths of this proposal include detailed phenotypes for glucose homeostasis that have not been extensively examined in the GWAS setting, a focus on the Mexican American population, and our long-standing, highly productive collaborative team. This project has great public health significance as it is focused on increasing our biological understanding and resultant mechanisms for the prevention of T2D using pre-diabetic measures of glucose homeostasis. Narrative The over-arching goal of this proposal is to understand the pathophysiology underlying basal and dynamic measures of insulin resistance and insulin secretion with translation of their impact to clinical disease, i.e. type 2 diabetes.",Genetic and Epidemiological Predictors of Glucose Homeostasis Measures,9902414,R01DK118062,"['Affect', 'African American', 'American', 'Architecture', 'Asians', 'Beta Cell', 'Biological', 'Biological Process', 'Cardiovascular Diseases', 'Case-Control Studies', 'Cellular biology', 'Clinical', 'Clinical Management', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Data', 'Data Set', 'Defect', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Economic Burden', 'Effectiveness', 'Epidemiology', 'European', 'Evaluation', 'Functional disorder', 'Funding', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic study', 'Glucose', 'Goals', 'Heritability', 'Hispanics', 'Human', 'Individual', 'Insulin Resistance', 'Intervention', 'Letters', 'Linkage Disequilibrium', 'Maps', 'Measures', 'Medical Care Costs', 'Meta-Analysis', 'Methodology', 'Mexican', 'Mexican Americans', 'Minority Groups', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Pattern', 'Phenotype', 'Physiological', 'Population', 'Prediabetes syndrome', 'Prevention', 'Public Health', 'Recording of previous events', 'Report (document)', 'Research', 'Resources', 'Risk', 'Sample Size', 'Sampling', 'South Asian', 'Testing', 'Translating', 'Translations', 'Variant', 'blood glucose regulation', 'case control', 'clinical phenotype', 'clinically relevant', 'cohort', 'design', 'diabetes risk', 'genome wide association study', 'genome-wide', 'high risk', 'improved', 'in silico', 'indexing', 'insight', 'insulin secretion', 'insulin sensitivity', 'metabolomics', 'molecular phenotype', 'multiple omics', 'next generation sequencing', 'novel', 'rare variant', 'resistance gene', 'success', 'trait']",NIDDK,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2020,665128,-0.044214897124926135
"Genetic and Epidemiological Predictors of Glucose Homeostasis Measures Summary Insulin sensitivity and insulin secretion are traits that have a significant impact on the risk of type 2 diabetes (T2D). The over-arching goal of this proposal is to understand the pathophysiology underlying variation of these intermediate phenotypes in Mexican Americans, the largest US minority group and one at high risk of T2D. The Genetics Underlying Diabetes in Hispanics (GUARDIAN) Consortium represents the largest effort to identify the genetic determinants underlying diabetes-related intermediate phenotypes (DK085175). During the previous funding period, genome-wide association studies (GWAS) focused on common genetic variation identified four genome-wide significant loci underlying variation in glucose homeostasis traits which translated to the clinical endpoint, T2D. In this application, we will build upon significant prior genetic findings with integration of biological (metabolomics) and analytical (hierarchical clustering and interaction analysis) approaches to further refine insulin resistance and insulin secretion phenotypes and explore their biological basis. Aim 1 will develop a novel methodology using existing GWAS and metabolomics data to impute genetically regulated metabolites (GReM) and test their association with measures of glucose homeostasis in the GUARDIAN Consortium. Aim 2 will refine known and novel variants associated with T2D and related phenotypes through hierarchical clustering and perform interaction analyses which exploit the bimodal nature of T2D to identify additional insulin resistance loci. Aim 3 will identify genetic determinants of dynamic measures of glucose homeostasis in diverse human populations and translate these loci to T2D. The unique strengths of this proposal include detailed phenotypes for glucose homeostasis that have not been extensively examined in the GWAS setting, a focus on the Mexican American population, and our long-standing, highly productive collaborative team. This project has great public health significance as it is focused on increasing our biological understanding and resultant mechanisms for the prevention of T2D using pre-diabetic measures of glucose homeostasis. Narrative The over-arching goal of this proposal is to understand the pathophysiology underlying basal and dynamic measures of insulin resistance and insulin secretion with translation of their impact to clinical disease, i.e. type 2 diabetes.",Genetic and Epidemiological Predictors of Glucose Homeostasis Measures,9738202,R01DK118062,"['Affect', 'African American', 'American', 'Architecture', 'Asians', 'Beta Cell', 'Biological', 'Biological Process', 'Cardiovascular Diseases', 'Case-Control Studies', 'Cellular biology', 'Clinical', 'Clinical Management', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Data', 'Data Set', 'Defect', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Economic Burden', 'Effectiveness', 'Epidemiology', 'European', 'Evaluation', 'Functional disorder', 'Funding', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic study', 'Glucose', 'Goals', 'Heritability', 'Hispanics', 'Human', 'Individual', 'Insulin Resistance', 'Intervention', 'Letters', 'Linkage Disequilibrium', 'Maps', 'Measures', 'Medical Care Costs', 'Meta-Analysis', 'Methodology', 'Mexican', 'Mexican Americans', 'Minority Groups', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Pattern', 'Phenotype', 'Physiological', 'Population', 'Prediabetes syndrome', 'Prevention', 'Public Health', 'Recording of previous events', 'Report (document)', 'Research', 'Resources', 'Risk', 'Sample Size', 'Sampling', 'South Asian', 'Testing', 'Translating', 'Translations', 'Variant', 'blood glucose regulation', 'case control', 'clinical phenotype', 'clinically relevant', 'cohort', 'design', 'diabetes risk', 'genome wide association study', 'genome-wide', 'high risk', 'improved', 'indexing', 'insight', 'insulin secretion', 'insulin sensitivity', 'metabolomics', 'molecular phenotype', 'multiple omics', 'next generation sequencing', 'novel', 'rare variant', 'resistance gene', 'success', 'trait']",NIDDK,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2019,721488,-0.044214897124926135
"Spatial Regulators of Skeletal Muscle Regeneration and Disease Skeletal muscles are responsible for movement, breathing, posture and metabolism. Loss of muscle function via acute injury or chronic neuromuscular disease (NMD) is debilitating to quality of life and is associated with high healthcare burden. In the US, there are over 12 million cases of sprains and strains injuries each year, an estimated 50 million people living with age-related sarcopenia, and another 250,000 with NMDs. My long-term goal is to elucidate the cellular and molecular mechanisms which underlie the muscle repair and develop therapies for chronic muscle disorders. A major barrier in this endeavor is our limited of understanding of the multiplicity of cell types involved during muscle regeneration. Little is known regarding functions of each cell type and how they interact with tissue-resident stem cells to regulate the restoration of muscle function. Thus, tissue cytometry, the mapping of single cells within tissues, is necessary to gain novel insights into cellular interactions during muscle regeneration and in dysregulated disease states. My central hypothesis is that local signaling in the cellular microenvironment regulate the behavior of critical cell types to remodel or repair the tissue. To this, I have optimized a novel multiplexed imaging technology (CODEX) that enables visualizes 40+ antibodies on a single muscle section. In the proposed research, I aim to (i) develop technologies to study cellular interactions using high dimensional imaging data and build a single cell resolution spatial map of the localization, abundance, dynamics, and interactions of 25 cell type within normal muscle regeneration and disease states; (ii) elucidate critical cell types and spatially-localized signaling that determine the proper expansion and differentiation of muscle stem cells; (iii) deep profile the function of M2 macrophages and fibroadipogenic precursors in process of motor neuron and neuromuscular junction remodeling. The training I will receive during the mentored phase of this proposal will be critical for the success of this project. Moreover, application of this systematic approach to study inter-cellular signaling will allow me to achieve academic independence. The proposed experiments in the K99 phase will provide novel insights into the coordinated process of tissue regeneration and will yield candidate signaling molecules with the potential to modulate the function of muscle stem cells. Further, the proposed project for the R00 phase will lead to better understanding of the cellular responses and fundamental mechanisms of motor neuron and neuromuscular junction remodeling, which has significant relevance for nerve injuries and chronic autoimmune neuromuscular diseases. Loss of muscle function in chronic neuromuscular disease (NMD) is debilitating to quality of life and is associated with high healthcare burden. A major barrier in the development of effective therapies for NMDs is our limited of understanding of the various types of cells involved in normal muscle repair and what goes awry in disease. Here, I develop novel technologies to simultaneously visualize and study the interaction of more than 25 cell types in skeletal muscle, which will allow us to uncover critical interactions that determine efficient muscle regeneration as well as pinpoint disruptions in chronic NMD.",Spatial Regulators of Skeletal Muscle Regeneration and Disease,10104351,K99NS120278,"['Acute', 'Algorithms', 'Antibodies', 'Autoimmune Process', 'Autoimmune Responses', 'Autoimmunity', 'Behavior', 'Bioinformatics', 'Biological Process', 'Biology', 'Breathing', 'Cell Communication', 'Cell physiology', 'Cells', 'Chronic', 'Collaborations', 'Computational algorithm', 'Cytometry', 'Data', 'Denervation', 'Development', 'Disease', 'Experimental Autoimmune Myasthenia Gravis', 'Goals', 'Healthcare', 'Image', 'Imaging technology', 'Immune', 'In Vitro', 'Injury', 'Ligands', 'Maps', 'Mentors', 'Metabolism', 'Methods', 'Modeling', 'Molecular', 'Motor Neurons', 'Movement', 'Muscle', 'Muscle Cells', 'Muscle Fibers', 'Muscle function', 'Muscle satellite cell', 'Muscular Atrophy', 'Myasthenia Gravis', 'Myopathy', 'Natural regeneration', 'Nerve', 'Nerve Crush', 'Neuroglia', 'Neuromuscular Diseases', 'Neuromuscular Junction', 'PTPRC gene', 'Phase', 'Population', 'Posture', 'Process', 'Quality of life', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Signaling Molecule', 'Skeletal Muscle', 'Sprains and Strains', 'Standardization', 'Technology', 'Tissues', 'Training', 'age related', 'cell type', 'connectome', 'effective therapy', 'experimental study', 'high dimensionality', 'in vivo', 'insight', 'intercellular communication', 'macrophage', 'mdx mouse', 'mouse model', 'multiplexed imaging', 'muscle regeneration', 'myogenesis', 'nerve injury', 'neuromuscular', 'new technology', 'novel', 'progenitor', 'programs', 'reinnervation', 'repaired', 'response', 'restoration', 'sarcopenia', 'sciatic nerve', 'stem cells', 'strain injury', 'success', 'therapy development', 'tissue regeneration', 'tissue repair', 'transcriptomics', 'unsupervised learning']",NINDS,STANFORD UNIVERSITY,K99,2020,88722,-0.006217157855564857
"An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography SUMMARY – OVERALL Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function. Although the basic electron cryo-tomography technique has been used for several decades, the technology is being revolutionized by recent advances in sample preparation, electron cryo-microscopy hardware, improved capabilities for automatic data collection, direct electron detection imaging devices, and phase plate technologies. Combined, these advances led to the ability to generate extraordinarily large numbers of cellular cryo-tomograms of exquisite quality. In principle, such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. However, collection of cellular data is now at a far faster rate than can currently be analyzed with existing methods, producing a serious barrier to progress: to match the data production rates of a single laboratory, at least 50 experienced scientists would need to handle the data analysis. The primary goal of this Program Project is to establish quantitative and highly automated tools for the reconstruction and interpretation of highly complex cellular tomographic data. We have assembled a highly synergistic team of PIs with complimentary expertise in cutting-edge computational and experimental electron microscopy techniques to achieve this goal through collaborative efforts. Project 1 (Hanein & Penczek) focuses on development and implementation of tomogram quality assessment and validation techniques and on experimentally guided optimization of data collection strategies. Project 2 focuses on automatic tomographic reconstruction technology, extraction of various features from the tomograms, and the analysis of distribution patterns derived from the extracted features. Project 3 focuses on development of quantitative tools for tomogram annotation through deep learning and sub-tomogram alignment as well as interactive visualization tools. The set of highly automated tools developed in this Program Project will permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study. NARRATIVE Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function and—with recent instrumental advances—it is now possible to image hundreds of cells per months, enabling collection of cellular data at a far faster rate than can currently be analyzed. Such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. This Program Project brings together an accomplished team of investigators to develop new strategies for effectively processing and interpreting this massive influx of data, developing a set of highly automated tools to permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study.",An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography,9769773,P01GM121203,"['Address', 'Algorithms', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biology', 'Cancer Diagnostics', 'Cell physiology', 'Cells', 'Classification', 'Collection', 'Complex', 'Computing Methodologies', 'Cryo-electron tomography', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Electrons', 'Environment', 'Floods', 'Goals', 'Health', 'Heart', 'Human', 'Image', 'Imaging Device', 'Individual', 'Knowledge', 'Laboratories', 'Methodology', 'Methods', 'Molecular', 'Molecular Structure', 'Morphology', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Preparation', 'Process', 'Production', 'Real-Time Systems', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Tomogram', 'Validation', 'Variant', 'Visualization software', 'base', 'computer framework', 'convolutional neural network', 'deep learning', 'electron tomography', 'experience', 'imaging detection', 'improved', 'insight', 'knowledge base', 'learning strategy', 'nanomachine', 'novel diagnostics', 'particle', 'programs', 'reconstruction', 'response', 'software development', 'statistics', 'tomography', 'tool', 'virtual']",NIGMS,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,P01,2019,928444,0.0126996374829918
"An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography SUMMARY – OVERALL Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function. Although the basic electron cryo-tomography technique has been used for several decades, the technology is being revolutionized by recent advances in sample preparation, electron cryo-microscopy hardware, improved capabilities for automatic data collection, direct electron detection imaging devices, and phase plate technologies. Combined, these advances led to the ability to generate extraordinarily large numbers of cellular cryo-tomograms of exquisite quality. In principle, such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. However, collection of cellular data is now at a far faster rate than can currently be analyzed with existing methods, producing a serious barrier to progress: to match the data production rates of a single laboratory, at least 50 experienced scientists would need to handle the data analysis. The primary goal of this Program Project is to establish quantitative and highly automated tools for the reconstruction and interpretation of highly complex cellular tomographic data. We have assembled a highly synergistic team of PIs with complimentary expertise in cutting-edge computational and experimental electron microscopy techniques to achieve this goal through collaborative efforts. Project 1 (Hanein & Penczek) focuses on development and implementation of tomogram quality assessment and validation techniques and on experimentally guided optimization of data collection strategies. Project 2 focuses on automatic tomographic reconstruction technology, extraction of various features from the tomograms, and the analysis of distribution patterns derived from the extracted features. Project 3 focuses on development of quantitative tools for tomogram annotation through deep learning and sub-tomogram alignment as well as interactive visualization tools. The set of highly automated tools developed in this Program Project will permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study. NARRATIVE Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function and—with recent instrumental advances—it is now possible to image hundreds of cells per months, enabling collection of cellular data at a far faster rate than can currently be analyzed. Such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. This Program Project brings together an accomplished team of investigators to develop new strategies for effectively processing and interpreting this massive influx of data, developing a set of highly automated tools to permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study.",An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography,9416022,P01GM121203,"['Address', 'Algorithms', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biological Neural Networks', 'Biology', 'Cancer Diagnostics', 'Cell physiology', 'Cells', 'Classification', 'Collection', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Electrons', 'Environment', 'Floods', 'Goals', 'Health', 'Heart', 'Human', 'Image', 'Imaging Device', 'Individual', 'Knowledge', 'Laboratories', 'Methodology', 'Methods', 'Molecular', 'Molecular Structure', 'Morphology', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Preparation', 'Process', 'Production', 'Real-Time Systems', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Stimulus', 'System', 'Techniques', 'Technology', 'Tomogram', 'Validation', 'Variant', 'Visualization software', 'base', 'computer framework', 'deep learning', 'electron tomography', 'experience', 'imaging detection', 'improved', 'insight', 'knowledge base', 'learning strategy', 'nanomachine', 'novel diagnostics', 'particle', 'programs', 'reconstruction', 'response', 'software development', 'statistics', 'tomography', 'tool', 'virtual']",NIGMS,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,P01,2018,981617,0.0126996374829918
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),8110238,U54CA121852,"['Address', 'Algorithms', 'Area', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Databases', 'Development', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Genes', 'Genetic Engineering', 'Genomics', 'Internet', 'Investigation', 'Literature', 'Machine Learning', 'Maps', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Research Personnel', 'Resources', 'Signal Pathway', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'base', 'biomedical ontology', 'computer framework', 'data mining', 'design', 'genome-wide', 'graphical user interface', 'knowledge base', 'multidisciplinary', 'natural language', 'novel', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2010,29814,-0.018869658555521158
"National Center: Multiscale Analysis of Genomic and Cellular Networks (MAGNet) A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.   n/a",National Center: Multiscale Analysis of Genomic and Cellular Networks (MAGNet),8012947,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2010,3757192,-0.018869658555521158
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7914681,U54CA121852,"['Address', 'Algorithms', 'Area', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Databases', 'Development', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Genes', 'Genetic Engineering', 'Genomics', 'Internet', 'Investigation', 'Literature', 'Machine Learning', 'Maps', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Research Personnel', 'Resources', 'Signal Pathway', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'base', 'biomedical ontology', 'computer framework', 'data mining', 'design', 'genome-wide', 'graphical user interface', 'knowledge base', 'multidisciplinary', 'natural language', 'novel', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2009,116802,-0.018869658555521158
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7676864,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2009,3464579,-0.018869658555521158
"Nation Center: Multi-Scale Study- Cellular Networks(RMI) A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genomewide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 1 investigators to combine molecular interaction clues from Core 2 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions. n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7674889,U54CA121852,"['Address', 'Algorithms', 'Area', 'Automobile Driving', 'Binding', 'Bioinformatics', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'DNA-Protein Interaction', 'Databases', 'Development', 'Dissection', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Genes', 'Genetic Engineering', 'Genomics', 'Individual', 'Internet', 'Investigation', 'Knowledge', 'Language', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Published Comment', 'Range', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'Science', 'Signal Pathway', 'Skeleton', 'Source', 'Structure', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'Work', 'base', 'computer framework', 'data mining', 'design', 'graphical user interface', 'improved', 'innovation', 'knowledge base', 'multidisciplinary', 'novel', 'response', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2008,113826,-0.019740778826066785
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7502135,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2008,3570137,-0.018869658555521158
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7286779,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2007,3638557,-0.018869658555521158
"Nation Center: Multi-Scale Study- Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7126050,U54CA121852,"['NIH Roadmap Initiative tag', 'bioinformatics', 'cell biology', 'computational biology', 'cooperative study', 'genome']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2006,3747227,-0.018830366716337827
"Nation Center: Multi-Scale Study- Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7012104,U54CA121852,"['bioinformatics', 'cell biology', 'computational biology', 'cooperative study', 'genome']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2005,3758967,-0.018830366716337827
"Spatiotemporal Coordination of Actin Regulators and Traction Forces in Heterogeneous Cell Protrusions Project Summary/Abstract Cancer cells within tumors often exist in highly heterogeneous phenotypic states, which is a major challenge in cancer therapeutics. Although there have been great advances in studying cellular heterogeneity and discovering hidden phenotypes, little effort has been made in achieving mechanistic understandings of each phenotype in heterogeneous cell populations in living cells. Most of our understandings of cell biological processes are based on the ensemble average of experimental measurements drawn from cell population. However, biological systems are inherently heterogeneous even in isogenic cell cultures. One of the prominent examples of cellular/subcellular heterogeneity is cell protrusion, driven by actin polymerization pushing the leading edge plasma membrane. Actin cytoskeleton is a highly dynamic complex system which integrates numerous biochemical and mechanical signals. Hundreds of actin regulators collectively organize actin structures, which are spatiotemporally heterogeneous in micron length and minute time scales. Due to this heterogeneous issues, experimental outcomes are often context-dependent and difficult to interpret. Thus, it is necessary to develop a new quantitative live cell imaging method which allows us to achieve distinct molecular understandings of each cellular phenotype from heterogeneous cell population. Therefore, the goal of this project is to deconvolve the heterogeneity of cell protrusion to characterize each cellular/subcellular protrusive phenotype by combining quantitative live cell imaging and machine learning analysis, and we will determine the coordination of distinct sets of actin regulators with respect to each protrusive phenotype. This will lead to mechanistic understanding specific to each protrusive phenotype. The central hypothesis in this project is that heterogeneous cell protrusions are driven by the distinct sets of spatiotemporal coordinated actin regulators and traction forces at the leading edge. We will Evaluate how the coordination of actin regulators at the leading edge generates heterogeneous multiple protrusions (Aim 1). We will Evaluate how actin organization at the leading edge during the retraction generates reinforced multiple cell protrusion (Aim 2). Finally, we will determine how the traction forces at the leading edge play roles in heterogeneous cell protrusions (Aim 3). It is expected that the experimental and computational imaging tools developed in this project can be applied to many complex cytoskeleton related processes including cellular morphogenesis by revealing a wide range of molecular and cellular coordination at various length and time scales. We also anticipate the new insight on cellular/subcellular heterogeneity in cell protrusion will allow us to better understand the heterogeneity of cancer metastasis, where only small number of tumor cells metastasize. Project Narrative This proposed project will be able to contribute to public health because new insight on the heterogeneity of cell protrusion will shed light on heterogeneity of cancer metastasis. This will allow us to find better therapeutic targets for more aggressive metastatic cells. The quantitative live cell imaging method developed in this project will enable the biomedical research community to tackle cellular heterogeneity to find more specific mechanism of specific phenotype.",Spatiotemporal Coordination of Actin Regulators and Traction Forces in Heterogeneous Cell Protrusions,9232608,R15GM122012,"['ANGPTL2 gene', 'Actins', 'Address', 'Atomic Force Microscopy', 'Biochemical', 'Biological Assay', 'Biological Process', 'Biomedical Research', 'Cancer Etiology', 'Cell Culture Techniques', 'Cell membrane', 'Cell physiology', 'Cells', 'Color', 'Communities', 'Complex', 'Cytoskeleton', 'Data', 'Environment', 'Generations', 'Goals', 'Heterogeneity', 'Imaging Device', 'Imaging technology', 'Individual', 'Length', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Mechanics', 'Membrane', 'Modeling', 'Molecular', 'Morphogenesis', 'Neoplasm Metastasis', 'Outcome', 'Phenotype', 'Play', 'Population', 'Process', 'Public Health', 'Role', 'Series', 'Signal Transduction', 'Structure', 'System', 'Therapeutic', 'Time', 'Traction', 'Work', 'base', 'biological systems', 'cancer cell', 'cancer heterogeneity', 'cancer therapy', 'cell motility', 'cofilin', 'computerized tools', 'depolymerization', 'imaging modality', 'insight', 'live cell imaging', 'mortality', 'neoplastic cell', 'polymerization', 'population based', 'quantitative imaging', 'spatiotemporal', 'therapeutic target', 'tool', 'tumor', 'vasodilator-stimulated phosphoprotein']",NIGMS,WORCESTER POLYTECHNIC INSTITUTE,R15,2017,449520,-0.03904993877952084
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9750722,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'predictive modeling', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2019,527585,0.015087559140034814
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9530668,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'predictive modeling', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2018,584485,0.015087559140034814
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9355693,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2017,406785,0.015087559140034814
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9241579,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'improved', 'infancy', 'insight', 'model building', 'network models', 'novel', 'research study', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2016,409580,0.015087559140034814
"Brain-wide quantitative mapping of microglia activation SUMMARY Recent technological developments such as tissue clearing and light sheet imaging have allowed for the three- dimensional visualization of the entire brain at cellular resolution. Translucence Biosystems has advanced this technology further by developing a) a proprietary Mesoscale Imaging System that allows visualization of an entire mouse brain much faster than prior techniques, b) machine learning-based algorithms that identify individual cells across the entire intact mouse brain and c) routines that rapidly determine cell densities in >1,200 brain regions defined by the annotated Allen Brain Atlas.  In the present proposal we will show the power of our technique by visualizing microglia density across the entire mouse brain as a biological marker for neuroinflammation. Microglia are the resident immune cells in the brain. While they play important roles in healthy brain function, they also mediate neuroinflammatory processes that have a significant impact in multiple neurodegenerative diseases such as Alzheimer's, Parkinson's, and multiple sclerosis as well as play possible roles in several neurodevelopmental and neurological disorders (e.g., schizophrenia, autism spectrum disorder, chemo brain). A tool for three-dimensional imaging of neuroinflammation patterns across the whole brain will help advance our understanding of neuroinflammatory processes in neurological diseases and aid in the evaluation of therapeutic approaches.  To visualize microglia, we will evaluate multiple strategies, including the CX3CR1-GFP mouse line, which expresses GFP in microglia, Iba1 immunolabeling and other antibody markers of activated microglia. The utility of our approach for monitoring neuroinflammation will be demonstrated in CX3CR1-GFP mice by treating them with the inflammatory agent lipopolysaccharide (LPS). Mice will be injected with three different LPS doses, and then microglia will be visualized and automatically counted across >1,200 brain regions. We will confirm the neuroinflammatory response to LPS by measuring protein markers of inflammation.  The applicability of our technique to neurodegenerative disease will be demonstrated by studying a mouse line used as a model of Alzheimer's disease that presents pronounced patterns of neuroinflammation. These experiments are designed to prove that our approach can provide reliable and detailed information describing neuroinflammation and that our results are better in terms of speed, resolution, and richness of information than any other technique available.  Once the goals for Phase I are met, we will be positioned to develop our microglia activation assay into a new gold standard for precise and complete histological detection of neuroinflammation. During phase II, we plan to 1) develop machine learning tools to establish morphological criteria that differentiate resting from activated microglia, 2) characterize microglial signatures in various mouse models of diseases with known or suspected neuroinflammation components, and 3) validate the microglial targeting of anti-inflammatory therapeutic candidates. NARRATIVE Microglia, the resident immune cells of the brain, protect against injury and infection. Microglia also play a critical role in dysfunctional neuroinflammatory processes that contribute to the development of brain diseases. We have developed novel methods to make mouse brains transparent so we can visualize and precisely count microglia throughout the intact mouse brain. In this proposal, we will test the feasibility of measuring brain-wide microglia activation using two disease models with a strong neuroinflammatory component, including a common transgenic mouse model that recapitulates the amyloid plaque accumulation that is a central feature of Alzheimer’s Disease.",Brain-wide quantitative mapping of microglia activation,9908302,R43MH122070,"['AIDS dementia', 'Affect', 'Aftercare', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Amyloid', 'Amyloid beta-Protein', 'Amyloid deposition', 'Anti-inflammatory', 'Antibodies', 'Atlases', 'Biological Assay', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain region', 'Cell Density', 'Cells', 'Deposition', 'Detection', 'Development', 'Dimensions', 'Disease model', 'Dose', 'Encephalitis', 'Evaluation', 'Exhibits', 'Genes', 'Genetic Transcription', 'Goals', 'Gold', 'Histologic', 'Histology', 'Human', 'Image', 'Imagery', 'Imaging Techniques', 'Immune', 'Individual', 'Infection', 'Inflammation', 'Inflammatory', 'Injury', 'Label', 'Light', 'Lipopolysaccharides', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Microglia', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Multiple Sclerosis', 'Mus', 'Nature', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Parkinson Disease', 'Pathologic', 'Pathology', 'Pattern', 'Phase', 'Phenotype', 'Physical shape', 'Play', 'Positioning Attribute', 'Process', 'Proliferating', 'Property', 'Protocols documentation', 'Publishing', 'Resolution', 'Rest', 'Role', 'Schizophrenia', 'Senile Plaques', 'Site', 'Speed', 'Stains', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Transgenic Mice', 'Traumatic Brain Injury', 'abeta deposition', 'autism spectrum disorder', 'base', 'brain cell', 'chemobrain', 'cytokine', 'density', 'design', 'experimental study', 'imaging Segmentation', 'imaging system', 'improved', 'in vitro Assay', 'in vivo', 'inflammatory marker', 'interest', 'mouse model', 'nervous system disorder', 'neuroinflammation', 'novel', 'protein biomarkers', 'response', 'selective expression', 'therapeutic candidate', 'therapeutic evaluation', 'tool']",NIMH,"TRANSLUCENCE BIOSYSTEMS, INC.",R43,2019,449956,-0.006778361496234705
"Protein structure determination from low-resolution experimental data Project Abstract Determination of a protein’s three-dimensional structure is of critical importance in biology, providing insights to biological mechanisms and important targets for drug design. While high- resolution X-ray diffraction data provides an atomic view of cellular components, for many interesting and biologically relevant complexes, it may only be possible to obtain low-resolution structural information. Both cryo-electron microscopy and X-ray crystallography, when applied to large, flexible molecular machines, often produce data of 3-6 Å resolution. Extracting detailed atomic information from this data, critical in understanding function, the effects of mutation, or in designing drugs is impossible due to the low number of observations and the large conformational space proteins may adopt. I propose to develop computational methods for extracting high-resolution atomic models from this low-resolution data, bridging the “resolution gap” with computational methods. My proposed research develops and extends our labs’ methods for automatically inferring atomic accuracy models, from these “near-atomic” resolution sources of experimental data. We develop novel conformational sampling methods, guided by experimental data, to infer atomic information both in cases where homologous high-resolution data is available, and where it is not. Additionally, we propose development of methods for estimating model uncertainty; these are critical in understanding to what degree structural conclusions may be made from a particular dataset. Finally, in pushing the resolution limit further, we develop general tools for biomolecular forcefield optimization. These machine-learning tools will allow development of a next-generation forcefield, critical in extending the resolution limit of data from which we can infer atomic details. The overall goal of the proposed research is robust and accessible methods to determine protein structures to atomic accuracy from only sparse experimental data. Combined, the three aims in this proposal will lead to dramatic improvements in our ability to infer atomic interactions from sparse experimental data. This will lead to determination of structures that will reveal key insights into how biomedically important protein complexes perform their function and what goes wrong in human disease. Project Narrative This project develops computational tools for accurately determining protein structure from low- resolution experimental data. The proposed work will lead to dramatic improvements in our ability to model dynamic structures from sparse data. Obtaining accurate structures from this data will reveal insights into how biomedically important protein complexes perform their function, and what goes wrong in human disease.",Protein structure determination from low-resolution experimental data,9988448,R01GM123089,"['Address', 'Adopted', 'Biological', 'Biology', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Development', 'Drug Design', 'Drug Targeting', 'Goals', 'Homologous Gene', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Mutation', 'Phase', 'Positioning Attribute', 'Proteins', 'Refit', 'Research', 'Resolution', 'Roentgen Rays', 'Sampling', 'Source', 'Structure', 'System', 'Testing', 'Torsion', 'Uncertainty', 'Validation', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'atomic data', 'atomic interactions', 'computerized tools', 'exhaustion', 'flexibility', 'heterogenous data', 'human disease', 'improved', 'insight', 'method development', 'model building', 'next generation', 'novel', 'protein complex', 'protein structure', 'reconstruction', 'structured data', 'three dimensional structure', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,279050,0.025863411884760684
"Protein structure determination from low-resolution experimental data Project Abstract Determination of a protein’s three-dimensional structure is of critical importance in biology, providing insights to biological mechanisms and important targets for drug design. While high- resolution X-ray diffraction data provides an atomic view of cellular components, for many interesting and biologically relevant complexes, it may only be possible to obtain low-resolution structural information. Both cryo-electron microscopy and X-ray crystallography, when applied to large, flexible molecular machines, often produce data of 3-6 Å resolution. Extracting detailed atomic information from this data, critical in understanding function, the effects of mutation, or in designing drugs is impossible due to the low number of observations and the large conformational space proteins may adopt. I propose to develop computational methods for extracting high-resolution atomic models from this low-resolution data, bridging the “resolution gap” with computational methods. My proposed research develops and extends our labs’ methods for automatically inferring atomic accuracy models, from these “near-atomic” resolution sources of experimental data. We develop novel conformational sampling methods, guided by experimental data, to infer atomic information both in cases where homologous high-resolution data is available, and where it is not. Additionally, we propose development of methods for estimating model uncertainty; these are critical in understanding to what degree structural conclusions may be made from a particular dataset. Finally, in pushing the resolution limit further, we develop general tools for biomolecular forcefield optimization. These machine-learning tools will allow development of a next-generation forcefield, critical in extending the resolution limit of data from which we can infer atomic details. The overall goal of the proposed research is robust and accessible methods to determine protein structures to atomic accuracy from only sparse experimental data. Combined, the three aims in this proposal will lead to dramatic improvements in our ability to infer atomic interactions from sparse experimental data. This will lead to determination of structures that will reveal key insights into how biomedically important protein complexes perform their function and what goes wrong in human disease. Project Narrative This project develops computational tools for accurately determining protein structure from low- resolution experimental data. The proposed work will lead to dramatic improvements in our ability to model dynamic structures from sparse data. Obtaining accurate structures from this data will reveal insights into how biomedically important protein complexes perform their function, and what goes wrong in human disease.",Protein structure determination from low-resolution experimental data,9768492,R01GM123089,"['Address', 'Adopted', 'Biological', 'Biology', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Development', 'Drug Design', 'Drug Targeting', 'Goals', 'Homologous Gene', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Mutation', 'Phase', 'Positioning Attribute', 'Proteins', 'Refit', 'Research', 'Resolution', 'Roentgen Rays', 'Sampling', 'Source', 'Structural Protein', 'Structure', 'System', 'Testing', 'Torsion', 'Uncertainty', 'Validation', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'atomic data', 'atomic interactions', 'computerized tools', 'exhaustion', 'flexibility', 'human disease', 'improved', 'insight', 'method development', 'model building', 'next generation', 'novel', 'protein complex', 'protein structure', 'reconstruction', 'three dimensional structure', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,279675,0.025863411884760684
"Protein structure determination from low-resolution experimental data Project Abstract Determination of a protein’s three-dimensional structure is of critical importance in biology, providing insights to biological mechanisms and important targets for drug design. While high- resolution X-ray diffraction data provides an atomic view of cellular components, for many interesting and biologically relevant complexes, it may only be possible to obtain low-resolution structural information. Both cryo-electron microscopy and X-ray crystallography, when applied to large, flexible molecular machines, often produce data of 3-6 Å resolution. Extracting detailed atomic information from this data, critical in understanding function, the effects of mutation, or in designing drugs is impossible due to the low number of observations and the large conformational space proteins may adopt. I propose to develop computational methods for extracting high-resolution atomic models from this low-resolution data, bridging the “resolution gap” with computational methods. My proposed research develops and extends our labs’ methods for automatically inferring atomic accuracy models, from these “near-atomic” resolution sources of experimental data. We develop novel conformational sampling methods, guided by experimental data, to infer atomic information both in cases where homologous high-resolution data is available, and where it is not. Additionally, we propose development of methods for estimating model uncertainty; these are critical in understanding to what degree structural conclusions may be made from a particular dataset. Finally, in pushing the resolution limit further, we develop general tools for biomolecular forcefield optimization. These machine-learning tools will allow development of a next-generation forcefield, critical in extending the resolution limit of data from which we can infer atomic details. The overall goal of the proposed research is robust and accessible methods to determine protein structures to atomic accuracy from only sparse experimental data. Combined, the three aims in this proposal will lead to dramatic improvements in our ability to infer atomic interactions from sparse experimental data. This will lead to determination of structures that will reveal key insights into how biomedically important protein complexes perform their function and what goes wrong in human disease. Project Narrative This project develops computational tools for accurately determining protein structure from low- resolution experimental data. The proposed work will lead to dramatic improvements in our ability to model dynamic structures from sparse data. Obtaining accurate structures from this data will reveal insights into how biomedically important protein complexes perform their function, and what goes wrong in human disease.",Protein structure determination from low-resolution experimental data,9536048,R01GM123089,"['Address', 'Adopted', 'Biological', 'Biology', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Development', 'Drug Design', 'Drug Targeting', 'Goals', 'Homologous Gene', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Mutation', 'Phase', 'Positioning Attribute', 'Proteins', 'Refit', 'Research', 'Resolution', 'Roentgen Rays', 'Sampling', 'Source', 'Structure', 'System', 'Testing', 'Torsion', 'Uncertainty', 'Validation', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'atomic data', 'atomic interactions', 'computerized tools', 'exhaustion', 'flexibility', 'human disease', 'improved', 'insight', 'method development', 'model building', 'next generation', 'novel', 'protein complex', 'protein structure', 'reconstruction', 'three dimensional structure', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2018,280284,0.025863411884760684
"Protein structure determination from low-resolution experimental data Project Abstract Determination of a protein’s three-dimensional structure is of critical importance in biology, providing insights to biological mechanisms and important targets for drug design. While high- resolution X-ray diffraction data provides an atomic view of cellular components, for many interesting and biologically relevant complexes, it may only be possible to obtain low-resolution structural information. Both cryo-electron microscopy and X-ray crystallography, when applied to large, flexible molecular machines, often produce data of 3-6 Å resolution. Extracting detailed atomic information from this data, critical in understanding function, the effects of mutation, or in designing drugs is impossible due to the low number of observations and the large conformational space proteins may adopt. I propose to develop computational methods for extracting high-resolution atomic models from this low-resolution data, bridging the “resolution gap” with computational methods. My proposed research develops and extends our labs’ methods for automatically inferring atomic accuracy models, from these “near-atomic” resolution sources of experimental data. We develop novel conformational sampling methods, guided by experimental data, to infer atomic information both in cases where homologous high-resolution data is available, and where it is not. Additionally, we propose development of methods for estimating model uncertainty; these are critical in understanding to what degree structural conclusions may be made from a particular dataset. Finally, in pushing the resolution limit further, we develop general tools for biomolecular forcefield optimization. These machine-learning tools will allow development of a next-generation forcefield, critical in extending the resolution limit of data from which we can infer atomic details. The overall goal of the proposed research is robust and accessible methods to determine protein structures to atomic accuracy from only sparse experimental data. Combined, the three aims in this proposal will lead to dramatic improvements in our ability to infer atomic interactions from sparse experimental data. This will lead to determination of structures that will reveal key insights into how biomedically important protein complexes perform their function and what goes wrong in human disease. Project Narrative This project develops computational tools for accurately determining protein structure from low- resolution experimental data. The proposed work will lead to dramatic improvements in our ability to model dynamic structures from sparse data. Obtaining accurate structures from this data will reveal insights into how biomedically important protein complexes perform their function, and what goes wrong in human disease.",Protein structure determination from low-resolution experimental data,9287589,R01GM123089,"['Address', 'Adopted', 'Biological', 'Biology', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Set', 'Development', 'Drug Design', 'Drug Targeting', 'Goals', 'Homologous Gene', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Mutation', 'Phase', 'Positioning Attribute', 'Proteins', 'Refit', 'Research', 'Resolution', 'Roentgen Rays', 'Sampling', 'Source', 'Structure', 'System', 'Testing', 'Torsion', 'Uncertainty', 'Validation', 'Work', 'X ray diffraction analysis', 'X-Ray Crystallography', 'X-Ray Diffraction', 'atomic data', 'atomic interactions', 'computerized tools', 'exhaustion', 'flexibility', 'human disease', 'improved', 'insight', 'method development', 'model building', 'next generation', 'novel', 'protein complex', 'protein structure', 'reconstruction', 'three dimensional structure', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2017,280183,0.025863411884760684
"Mapping human brain perivascular space in lifespan using human connectome project data PROJECT SUMMARY Perivascular spaces are a critical component of the glia-lymphatic circuit, facilitating the clearance of soluble waste. The role of perivascular spaces and changes in the brain’s clearance system in normal development, aging, and cognition is not fully understood, mainly due to lack of neuroimaging capabilities. However, noninvasive in vivo mapping of the perivascular space fluid with high accuracy and reliability is now made possible with our recent analytical developments, using human connectome project (HCP) data. The objective of this project is to map structural and diffusion features of perivascular space fluid across lifespan. PVS features include PVS presence (e.g., count and volume fraction) and diffusion (e.g., diffusivity and anisotropy). These features will be extracted regionally and globally across the brain. Structural MRI will provide information regarding localization and extent of the PVS and diffusion MRI will be used to investigate biophysical properties of the PVS fluid and surrounding tissue. The central hypothesis is that the perivascular space fluid increases across lifespan. We also hypothesize that individual differences exist in perivascular spaces as a function of demographic, general health and lifestyle health choices, such as body mass index, blood pressure, tobacco use and sleep quality. The central hypothesis will be tested by characterizing the normative map of the perivascular space fluid across the lifespan and in relation to various demographic, cognitive measures, and health factors. We will also examine whether subjects neuro-behavioral performances can be predicted by perivascular space features. We will pursue these aims by applying innovative MRI-based computational techniques that we recently developed and optimized on HCP data. We will also use Adolescent Brain Cognitive Development (ABCD) Studies to build first normative template of PVS in neurodevelopment. Together, our findings will ultimately allow for a better understanding of the human brain clearance system, and our shared perivascular space mapping workflow can provide a resource for researchers to study a wide range of neurological conditions. PROJECT NARRATIVE The proposed research is relevant to public health because it is expected to fill our gap knowledge regarding the role of the clearance system in brain health and cognition and its neuroimaging signature. We will identify and provide access to quantitative morphological and diffusion features of brain glia-lymphatic network to the larger scientific community to help facilitate our understanding of what role the brain clearance system has across lifespan. The analytical workflow and the analyzed data can also be used to study a wide range of neurological conditions.",Mapping human brain perivascular space in lifespan using human connectome project data,10012731,RF1MH123223,"['3-Dimensional', 'Adolescent', 'Affect', 'Age', 'Aging', 'Anisotropy', 'BRAIN initiative', 'Biological', 'Blood Pressure', 'Body mass index', 'Brain', 'Brain region', 'Caliber', 'Cerebrospinal Fluid', 'Cognition', 'Cognitive', 'Communities', 'Computational Technique', 'Data', 'Data Analyses', 'Data Set', 'Deposition', 'Development', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Drug Delivery Systems', 'Early Diagnosis', 'Foundations', 'Future', 'Gatekeeping', 'Goals', 'Health', 'Heterogeneity', 'Human', 'Image', 'Immune system', 'Individual Differences', 'Intercellular Fluid', 'Knowledge', 'Life', 'Life Style', 'Light', 'Liquid substance', 'Longevity', 'Lymphatic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Modeling', 'Morphology', 'National Institute of Mental Health', 'Neuroglia', 'Neurologic', 'Outcome', 'Participant', 'Pathologic', 'Pathway interactions', 'Pediatric cohort', 'Performance', 'Physiology', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Robin bird', 'Role', 'Sample Size', 'Sampling', 'Short-Term Memory', 'Sleep', 'Smoking', 'Statistical Data Interpretation', 'Structure', 'System', 'T2 weighted imaging', 'Techniques', 'Testing', 'Tissues', 'Tobacco use', 'Variant', 'Visual', 'Walking', 'Work', 'age related', 'base', 'biophysical properties', 'brain health', 'cardiovascular health', 'cognitive development', 'cognitive function', 'cognitive performance', 'cohort', 'connectome', 'data archive', 'glymphatic system', 'human imaging', 'in vivo', 'innovation', 'insight', 'interest', 'lifestyle factors', 'neurobehavioral', 'neurodevelopment', 'neuroimaging', 'neurovascular unit', 'novel', 'sex', 'sleep quality', 'tool', 'wasting']",NIMH,UNIVERSITY OF SOUTHERN CALIFORNIA,RF1,2020,1336500,-0.001789228310985447
"Computational Design of Crystal Lattice Interactions to Determine Recalcitrant Protein Structures PROJECT SUMMARY Proteins are macromolecules that carry out innumerable biological functions ranging from intracellular signaling to immune response. The specific function of a protein is determined by its three-dimensional structure. Therefore, an essential step towards understanding protein function is elucidating protein structure. However, the premier method for structure determination, X-ray crystallography, can be limited by many potential factors including the quality of the protein crystal. The proposed research will investigate the effects of protein– protein interactions in the crystal lattice on crystal quality and resolution and develop a design approach to stabilize lattice interactions, which should result in higher-quality crystals.  First, the molecular determinants of high-quality protein crystal structures will be identified by (1) curating a set of representative structures from the Protein Data Bank, (2) extracting relevant features, such as interaction energy, buried solvent accessible surface area, interfacial packing quality, and residue usage, and (3) analyzing the features’ relationship to crystal resolution (a proxy for quality). Based on these findings, a design strategy and score function for ranking designs within the Rosetta framework will be developed.  Second, the design strategy will be applied to SNase, a model protein that is easy to purify and well- behaved in crystallization and diffraction experiments. The designed proteins will be crystallized and the crystal structures will be solved, testing for improved resolution. Analysis of the resultant crystal structures will drive development of the design strategy.  Third, the design strategy will be applied on a bacterial gyrase, an antibiotic-target protein for which there are several drug-bound structures at low resolution, lacking sufficient detail to reveal key antibiotic– gyrase interactions. Preliminary data suggests that the designed gyrase mutants will yield high-resolution structures, permitting a better understanding of antibiotic–gyrase interactions, with implications for drug design.  Should the method be successful, it will be immediately applicable to ~26,000 structures in the Protein Data Bank, and countless structures that have not been published due to lack of resolution. Re-engineered, high-resolution structures of these proteins could yield structural data on molecular interactions pertinent to disease, drug development, and basic understanding of protein function. PROJECT NARRATIVE This project will develop methods to improve low-resolution crystal structures of proteins to high-resolution sufficient (1) to resolve key mechanistic features of enzyme function and disease, and (2) to design or screen drug molecules. In addition to method development, we will pursue crystal structure of M. tuberculosis DNA gyrase in complex with relevant antibiotic drugs.",Computational Design of Crystal Lattice Interactions to Determine Recalcitrant Protein Structures,9644449,F31GM123616,"['Address', 'Affect', 'Algorithm Design', 'Anti-Bacterial Agents', 'Antibiotics', 'Area', 'Basic Science', 'Benchmarking', 'Binding', 'Biochemical', 'Biological', 'Biological Process', 'Complex', 'Crystallization', 'Crystallography', 'DNA', 'DNA Gyrase', 'Data', 'Development', 'Discipline', 'Disease', 'Drug Design', 'Drug Screening', 'Engineering', 'Enzymes', 'Free Energy', 'Glean', 'Goals', 'Immune response', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Mycobacterium tuberculosis', 'Pharmaceutical Preparations', 'Pharmacology', 'Protein Engineering', 'Proteins', 'Proxy', 'Publishing', 'Research', 'Resolution', 'Side', 'Signal Transduction', 'Solvents', 'Staphylococcus aureus', 'Structure', 'Surface', 'System', 'Testing', 'X-Ray Crystallography', 'base', 'data warehouse', 'design', 'drug development', 'experimental study', 'functional gain', 'improved', 'insight', 'interfacial', 'macromolecule', 'method development', 'mutant', 'novel', 'nuclease', 'protein function', 'protein protein interaction', 'protein structure', 'research and development', 'structural biology', 'three dimensional structure', 'tool']",NIGMS,JOHNS HOPKINS UNIVERSITY,F31,2018,37308,0.04048837612595986
"Proteomics of ciliopathy protein complexes Summary Ciliopathies are a diverse class of developmental diseases that can manifest as defects in kidney, skeletal, eye, heart, reproductive, or mental function. Many ciliopathies, including Bardet-Biedl, Joubert, and Meckel Gruber Syndromes, are caused by defects in the major protein complexes that characterize the ciliary compartment. At least 1,000 proteins are associated with cilia biogenesis and function; uncovering the principles of ciliary protein organization thus requires a large scale, systematic investigation. Our current human protein complex maps, while extensive, have only moderate coverage of ciliary proteins, warranting the collection of targeted experimental datasets. I will use comparative proteomic analysis of cilia from multiple organisms to determine deeply conserved protein-protein interactions likely to be critical to ciliary function in humans. Examining human biological systems in the context of their level of conservation across species is a productive route to distinguish biological signal from noise. My preliminary data on three ciliated species confirm that this approach is capable of identifying conserved ciliary protein complexes. If a pair of proteins are found in physical contact in diverse species, having survived speciation events and gene loss, it can be predicted that this physical interaction is important. First, using mass spectrometry, we will experimentally detect protein complexes within the cilia across a spectrum of eukaryotic organisms, broadly defining conserved ciliary proteins. Second, we will integrate our own experimental data, some of which we have already collected, with outside data to construct a system-wide map of conserved ciliary protein complexes. These conserved ciliary protein complexes are strongly predicted to be functionally important in humans, and potentially involved in human birth defects. Finally, we will test a targeted subset of proteins predicted to associate with known birth defect proteins in vivo using Xenopus laevis embryos as a model system. We have four candidate genes in hand, and will consider candidates from the prior aims as appropriate. This project will lead to a map of critical conserved ciliary protein complexes, a future primary resource for research into diverse ciliopathies. Project Narrative! Ciliopathies are a class of birth defects caused by defective cilia. This project will determine conserved ciliary protein complexes in a series of targeted proteomics experiments, systematically mapping ciliary protein organization as a guide for research into ciliopathies and cilia function.",Proteomics of ciliopathy protein complexes,9588803,F31GM123683,"['Animals', 'Biochemical', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Candidate Disease Gene', 'Cilia', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collection', 'Comparative Biology', 'Complex', 'Congenital Abnormality', 'Core Protein', 'Data', 'Data Set', 'Databases', 'Defect', 'Development', 'Disease', 'Embryo', 'Epithelium', 'Event', 'Eye', 'Fractionation', 'Future', 'Genes', 'Genetic Diseases', 'Genetic screening method', 'Hand', 'Health', 'Human', 'Human Genetics', 'Investigation', 'Joubert syndrome', 'Kidney', 'Knock-out', 'Knockout Mice', 'Link', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Meckel-Gruber syndrome', 'Methods', 'Modeling', 'Molecular Biology', 'Mus', 'Mutation', 'Noise', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plant Proteins', 'Plants', 'Process', 'Protein-Protein Interaction Map', 'Proteins', 'Proteomics', 'Research', 'Resources', 'Route', 'Sampling', 'Series', 'Signal Transduction', 'System', 'Techniques', 'Testing', 'Whole Organism', 'Xenopus', 'Xenopus laevis', 'base', 'biological systems', 'ciliopathy', 'cilium biogenesis', 'comparative', 'developmental disease', 'exome', 'experimental study', 'heart function', 'in vivo', 'link protein', 'mental function', 'novel', 'protein complex', 'protein protein interaction', 'reproductive function', 'skeletal']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",F31,2019,35616,0.0171048920820361
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed understanding of admixture is essential for effective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on phenotype are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simplified models at the risk of inaccurate inferences. This proposal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to leverage this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate powerful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as effectively as homogeneous populations. The first step in obtaining a thorough understanding of admixture is a principled and scalable statistical framework to infer fine-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop effective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major impact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to efficiently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human phenotypes, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on fine-scale genomic structure and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can benefit from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9990809,R35GM125055,"['Admixture', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'statistical and machine learning', 'structural genomics', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2020,332952,0.0032461402622566958
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed understanding of admixture is essential for effective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on phenotype are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simplified models at the risk of inaccurate inferences. This proposal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to leverage this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate powerful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as effectively as homogeneous populations. The first step in obtaining a thorough understanding of admixture is a principled and scalable statistical framework to infer fine-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop effective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major impact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to efficiently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human phenotypes, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on fine-scale genomic structure and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can benefit from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9774249,R35GM125055,"['Admixture', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'structural genomics', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2019,332952,0.0032461402622566958
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed un- derstanding of admixture is essential for e ective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on pheno- type are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simpli ed models at the risk of inaccurate inferences. This pro- posal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to lever- age this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate power- ful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as e ectively as homogeneous populations. The rst step in obtaining a thorough understanding of admixture is a principled and scalable statis- tical framework to infer ne-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop e ective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major im- pact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to eciently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human pheno- types, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on ne-scale genomic struc- ture and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can bene t from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9547454,R35GM125055,"['Admixture', 'Age', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2018,332952,0.003034117288097028
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed un- derstanding of admixture is essential for e ective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on pheno- type are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simpli ed models at the risk of inaccurate inferences. This pro- posal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to lever- age this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate power- ful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as e ectively as homogeneous populations. The rst step in obtaining a thorough understanding of admixture is a principled and scalable statis- tical framework to infer ne-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop e ective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major im- pact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to eciently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human pheno- types, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on ne-scale genomic struc- ture and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can bene t from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9382936,R35GM125055,"['Admixture', 'Age', 'Alleles', 'Architecture', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'insight', 'novel', 'reference genome', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2017,225087,0.003034117288097028
"Clinical resting state fMRI software for surgical planning Abstract Classically, anatomic information provided by MRI has been essential to the neurosurgeon to maximize extent of tumor resection and, as a result, improve survival statistics. That said, it is not routine during resections to make use of similar imaging information that reflect the functional organization of the brain. Task-based fMRI has been employed as a means of pre-operatively localizing function. However, task-based fMRI depends on the patient’s ability to comply with the task paradigm, which frequently is lacking. This problem can be overcome by using the recently developed method of resting state functional magnetic resonance imaging (rsfMRI) to localize function. Moreover, rsfMRI is highly efficient, as multiple resting state networks (RSNs) associated with multiple cognitive domains can be mapped at the same time. With this in mind, the long-term goal of our research is to improve survival and quality of life after surgical resection of brain tumors by improving the identification/preservation of eloquent cortex. The current barrier that prevents the widespread use of rsfMRI is 1) the high degree of advanced imaging expertise currently necessary to create and interpret the images and 2) the necessary IT infrastructure necessary to support the analyses. To address this shortcoming, we propose to create a turnkey system for functional mapping within the brain that resides on a cloud-computing platform. At the heart of our methodology is a multi-layer perceptron (MLP) algorithm that assigns RSN membership to each locus within the brain using supervised classification of rsfMRI data. Current data demonstrate that MLP-based RSN mapping is more reliable than conventional task-based fMRI and is extremely sensitive to sites identified by cortical stimulation (the standard in intraoperative mapping). Translation of the science and techniques created at Washington University will be accomplished by a deep collaboration with Radiologics, an emerging company with strong expertise in cloud computing for clinical imaging. Towards this end, the overall objective of the proposed project is to create an imaging technology package, named Cirrus, that will integrate automatic MLP-based RSN mapping with cloud-based computing. The Specific Aims of this proposal are to 1) Create Cloud-Based rsfMRI Brain Mapping Capability - Cirrus, 2) Deploy Cloud-Based rsfMRI Capability (Cirrus Platform) to New User Host Institutions, and 3) Optimize the Clinical User Interface (UI) of Cirrus. The expected outcome of this translational strategy will be an integrated imaging/surgical presurgical mapping technology using rsfMRI with clearly defined performance capabilities, well delineated localization outputs, and a clinician friendly user experience that scales to all types of health care settings. Thus, this proposal is innovative because there currently does not exist any comparable system that integrates cutting edge image analysis tools with cloud-based capabilities. This work is significant because it will disseminate technology that fundamentally enhances the surgeon’s understanding of the functional implications of their surgical strategy, thereby enables safer, more tailored approaches to improving outcomes. Project Narrative The proposed research is an academic industry partnership that will make available, to any neurosurgical practice advanced functional MRI methodology to define critical regions in the brain. This development is relevant to public health because it has the potential to improve functional outcomes following surgical removal of brain tumors. Towards this end, we propose to create an imaging technology package that will integrate 1) advanced machine learning techniques using resting state functional magnetic resonance imaging, and 2) cloud-based computing, to perform advanced brain mapping. Thus, advanced functional localization can be standardized and acquired at any institution by being uniformly processed in the cloud and sent back to the home institution without the need for costly infrastructure. The integrated package will enable clinicians in any practice environment to efficiently and reliably visualize function on the brain’s anatomy prior to surgery.",Clinical resting state fMRI software for surgical planning,9409171,R44GM125438,"['Address', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Back', 'Biological Preservation', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Child', 'Classification', 'Clinical', 'Cloud Computing', 'Cognitive', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Environment', 'Excision', 'Failure', 'Functional Magnetic Resonance Imaging', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Home environment', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Institution', 'Intuition', 'Language', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Glioma', 'Maps', 'Methodology', 'Methods', 'Mind', 'Names', 'Network-based', 'Neural Network Simulation', 'Neurosurgeon', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Population', 'Process', 'Public Health', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Rest', 'Scanning', 'Science', 'Site', 'Standardization', 'Stress Tests', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training Activity', 'Translating', 'Translations', 'Universities', 'Washington', 'Work', 'base', 'brain tumor resection', 'clinical imaging', 'cloud based', 'computing resources', 'cost', 'experience', 'flexibility', 'functional outcomes', 'functional status', 'imaging capabilities', 'imaging software', 'improved', 'improved outcome', 'industry partner', 'innovation', 'patient population', 'personalized approach', 'prevent', 'statistics', 'tool', 'translational approach', 'tumor', 'user-friendly']",NIGMS,"RADIOLOGICS, INC.",R44,2017,749900,-0.03252007978596464
"Clinical resting state fMRI software for surgical planning Abstract Classically, anatomic information provided by MRI has been essential to the neurosurgeon to maximize extent of tumor resection and, as a result, improve survival statistics. That said, it is not routine during resections to make use of similar imaging information that reflect the functional organization of the brain. Task-based fMRI has been employed as a means of pre-operatively localizing function. However, task-based fMRI depends on the patient’s ability to comply with the task paradigm, which frequently is lacking. This problem can be overcome by using the recently developed method of resting state functional magnetic resonance imaging (rsfMRI) to localize function. Moreover, rsfMRI is highly efficient, as multiple resting state networks (RSNs) associated with multiple cognitive domains can be mapped at the same time. With this in mind, the long-term goal of our research is to improve survival and quality of life after surgical resection of brain tumors by improving the identification/preservation of eloquent cortex. The current barrier that prevents the widespread use of rsfMRI is 1) the high degree of advanced imaging expertise currently necessary to create and interpret the images and 2) the necessary IT infrastructure necessary to support the analyses. To address this shortcoming, we propose to create a turnkey system for functional mapping within the brain that resides on a cloud-computing platform. At the heart of our methodology is a multi-layer perceptron (MLP) algorithm that assigns RSN membership to each locus within the brain using supervised classification of rsfMRI data. Current data demonstrate that MLP-based RSN mapping is more reliable than conventional task-based fMRI and is extremely sensitive to sites identified by cortical stimulation (the standard in intraoperative mapping). Translation of the science and techniques created at Washington University will be accomplished by a deep collaboration with Radiologics, an emerging company with strong expertise in cloud computing for clinical imaging. Towards this end, the overall objective of the proposed project is to create an imaging technology package, named Cirrus, that will integrate automatic MLP-based RSN mapping with cloud-based computing. The Specific Aims of this proposal are to 1) Create Cloud-Based rsfMRI Brain Mapping Capability - Cirrus, 2) Deploy Cloud-Based rsfMRI Capability (Cirrus Platform) to New User Host Institutions, and 3) Optimize the Clinical User Interface (UI) of Cirrus. The expected outcome of this translational strategy will be an integrated imaging/surgical presurgical mapping technology using rsfMRI with clearly defined performance capabilities, well delineated localization outputs, and a clinician friendly user experience that scales to all types of health care settings. Thus, this proposal is innovative because there currently does not exist any comparable system that integrates cutting edge image analysis tools with cloud-based capabilities. This work is significant because it will disseminate technology that fundamentally enhances the surgeon’s understanding of the functional implications of their surgical strategy, thereby enables safer, more tailored approaches to improving outcomes. Project Narrative The proposed research is an academic industry partnership that will make available, to any neurosurgical practice advanced functional MRI methodology to define critical regions in the brain. This development is relevant to public health because it has the potential to improve functional outcomes following surgical removal of brain tumors. Towards this end, we propose to create an imaging technology package that will integrate 1) advanced machine learning techniques using resting state functional magnetic resonance imaging, and 2) cloud-based computing, to perform advanced brain mapping. Thus, advanced functional localization can be standardized and acquired at any institution by being uniformly processed in the cloud and sent back to the home institution without the need for costly infrastructure. The integrated package will enable clinicians in any practice environment to efficiently and reliably visualize function on the brain’s anatomy prior to surgery.",Clinical resting state fMRI software for surgical planning,9552903,R44GM125438,"['Address', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Back', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Child', 'Classification', 'Clinical', 'Cloud Computing', 'Cognitive', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Environment', 'Excision', 'Failure', 'Functional Magnetic Resonance Imaging', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Home environment', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Institution', 'Intuition', 'Language', 'Lesion', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Glioma', 'Maps', 'Methodology', 'Methods', 'Mind', 'Names', 'Network-based', 'Neural Network Simulation', 'Neurosurgeon', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Population', 'Process', 'Public Health', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Rest', 'Science', 'Site', 'Standardization', 'Stress Tests', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training Activity', 'Translating', 'Translations', 'Universities', 'Washington', 'Work', 'base', 'brain tumor resection', 'clinical imaging', 'cloud based', 'computing resources', 'cost', 'experience', 'flexibility', 'functional outcomes', 'functional status', 'health care settings', 'imaging capabilities', 'imaging software', 'improved', 'improved outcome', 'industry partner', 'innovation', 'patient population', 'personalized approach', 'preservation', 'prevent', 'statistics', 'tool', 'translational approach', 'tumor', 'user-friendly']",NIGMS,"RADIOLOGICS, INC.",R44,2018,740001,-0.03252007978596464
"Electrical connectomics: an innovative approach for dissecting brain mechanisms underlying behavioral states Project Summary: Understanding the mechanisms by which the brain encodes behavior presents a major challenge for developing effective therapies with which to treat neurological and psychiatric disorders. The development of brain-wide measurements of neural connectivity in mammalian models holds great potential for overcoming this challenge. Here we propose an innovative approach for collecting and integrating such data across an unprecedented number of interconnected brain regions for use in elucidating the mechanisms by which sensory processing is altered in disease. A number of neurological and psychiatric disorders are triggered or exacerbated by sensory stimuli, yet little is understood about the brain connectivity underlying such sensory hyper/hypo- sensitization. Sensory processing plays a major role in the pathology of: autism spectrum disorders (ASD), schizophrenia, fibromyalgia, attention deficit hyperactivity disorder (ADHD), sensory perception disorders (SPDs), and migraine. Migraine in particular represents a compelling model of sensory hypersensitization, as the response to sensory stimuli is clear, dose- dependent, and measurable. Using state-of-the-art, multi-site in vivo recordings in a well- characterized migraine model, coupled with machine learning, we will develop network-wide electrical maps of the sensory hypersensitivity that underlies migraine. These networks will be validated for their roles in migraine using multiple behavioral assays and migraine-related pharmacological manipulations. We will additionally dissect the mechanisms underlying the sensory hypersensitivity brain state in a mouse model of migraine using optogenetic circuit manipulations as well as single-cell RNA-Seq, with the aim of identifying the contributions of specific circuits, cells, and molecules to this state. This approach is expected to substantially facilitate the use of neural oscillation-based brain networks in biomedical research, as well as provide: 1) a tool for rapid identification of a sensory hypersensitive brain state that can be tested for mechanisms shared across disorders, 2) a map of features of electrical brain networks, which serve as strong hypotheses regarding the routes whereby sensory hypersensitivity brain networks are regulated, and 3) insight into the contributions of specific cell types and molecules to the hypersensitive brain state. Collectively, this study is expected to provide insights into the etiology of migraine and other sensory hypersensitivity disorders that will be critical to developing brain network-based therapies for these diseases. RELEVANCE TO PUBLIC HEALTH: This proposal seeks to harness a powerful approach for mapping electrical activity across the brain and to use this information to dissect the biological mechanisms underlying sensory hypersensitivity, a key aspect of many neurological and psychiatric disorders. The data collected from this study will provide a comprehensive map of electrical activity in sensory hypersensitivity in a preclinical migraine model; migraine is the most prevalent neurological disorder in the general population. These maps will then be used to identify novel brain-network based targets for the development of new therapeutics, establishing a unique approach that could be applied broadly to many brain disorders for which effective therapies remain elusive.",Electrical connectomics: an innovative approach for dissecting brain mechanisms underlying behavioral states,10001808,DP2MH126377,"['Attention deficit hyperactivity disorder', 'Base of the Brain', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Biological', 'Biomedical Research', 'Brain', 'Brain Diseases', 'Brain region', 'Cells', 'Coupled', 'Data', 'Development', 'Disease', 'Dose', 'Etiology', 'Fibromyalgia', 'General Population', 'Hypersensitivity', 'Machine Learning', 'Maps', 'Measurable', 'Measurement', 'Mental disorders', 'Migraine', 'Modeling', 'Network-based', 'Pathology', 'Perceptual Disorders', 'Pharmacology', 'Play', 'Public Health', 'Role', 'Route', 'Schizophrenia', 'Sensory', 'Site', 'Testing', 'autism spectrum disorder', 'cell type', 'effective therapy', 'hypersensitivity desensitization', 'in vivo', 'innovation', 'insight', 'mouse model', 'nervous system disorder', 'novel', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'relating to nervous system', 'response', 'sensory stimulus', 'single-cell RNA sequencing', 'tool']",NIMH,UNIVERSITY OF IOWA,DP2,2020,2317500,-0.013093419036254807
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efficiently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be infinitely replicated. Their combination, the multiparental genetic reference population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, flies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions considered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and find variance-controlling genes; and more rigorous and expansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered include: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only fill significant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9893003,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'causal variant', 'computerized tools', 'design', 'fly', 'human disease', 'human model', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2020,336445,-0.01528140512204755
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efficiently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be infinitely replicated. Their combination, the multiparental genetic reference population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, flies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions considered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and find variance-controlling genes; and more rigorous and expansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered include: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only fill significant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9672510,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'causal variant', 'computerized tools', 'design', 'fly', 'human disease', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2019,336445,-0.01528140512204755
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efﬁciently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be inﬁnitely replicated. Their combination, the multiparental genetic refer- ence population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, ﬂies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions consid- ered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and ﬁnd variance-controlling genes; and more rigorous and ex- pansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered in- clude: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only ﬁll signiﬁcant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientiﬁc output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9485688,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'computerized tools', 'design', 'human disease', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2018,336445,-0.01528140512204755
"SPOTs: Optical Technologies for Instantly Quantifying Multicellular Response Profiles PROJECT SUMMARY/ABSTRACT Human organ systems require temporally and spatially coordinated multicellular actions at a macroscale to actuate, sustain, or terminate dedicated and vital functions. Cells that comprise discrete or distributed physiologic systems that fail to respond to appropriate stimuli with coordination may cause significant morbidity and often mortality. Collective and coordinated physiologic activities typically involve millions to billions of cells that may span large physical distances. Technologies for quantifying the electrical, chemical, and mechanical coupling in these multicellular systems are critically important to understanding the underlying mechanisms of disease and develop therapeutic approaches. However, no technology currently exists to quantify rapid mechanical cell responses to transmitted distal perturbations for all cells within a collection of cells. This multi- PI proposal (Chiou (contact PI) and Teitell) aims to develop a new platform imaging technology called SPOT (single pixel optical technology) for concurrent and direct measurements of cellular traction forces over a 1.0 x 1.0 cm2 field of view (FOV) with cellular spatial resolution, and a 1,000 frames/sec temporal resolution. SPOT provides a 4-order of magnitude larger FOV than conventional traction force microscopy. Cardiomyocytes (CMs) are the test bed here because of a high potential for impact in cardiovascular disease, the leading cause of mortality in the Western World. We will demonstrate the ability for SPOT to determine quantitative indices of abnormalities for human CM contraction and relaxation in healthy and diseased states. We will establish proof of concept studies in SPOT screens for small molecules that augment or affect CM contraction in desmoplakin deficient states. We will build a platform that integrates SPOT for direct contraction force measurements and Optical Mapping for electrical property measurements for sheets of CMs. This will enable, for the first time, studies of temporal and spatial electromechanical coupling behaviors for sheets of CMs at single cell resolution. We will distinguish different subtypes of CMs, their distributions, their interactions, and their phenotypic responses under external perturbations. And we will apply this platform to investigate the structural and electromechanical coupling properties of hESC-derived CMs by integrating quantitative biomass and stiffness data measured using non-invasive live cell interferometry (LCI). Changes in biomass and cell stiffness are druggable biophysical parameters with correlates to mechanical contraction/relaxation cycles of CMs. In addition to detailed studies of CMs that have the potential to impact the number one killer of US citizens, SPOT applications should have utility and provide new insights in additional settings that require cell or tissue traction-force generation. Such settings could include models in a dish for wound healing, cancer cell metastasis, or models of diseases that affect cell and tissue structural integrity, such as connective tissue disorders Ehlers-Danlos or Marfan syndromes. PROJECT NARATIVE Our proposal is exclusively technology development but portends public health relevance because we will invent a way to quantify previously undiscoverable interactions and mechanical responses to external and internal perturbations in interconnected biological systems, as occurs in physiologic and pathologic states. We will develop, test and fine-tune a new technology platform called SPOT (Single Pixel Optical Technology) to extract mechanical responses at cellular resolution in a very wide field, in real-time, concurrently for all cells in a sheet to enable studies and potentially new-age therapeutics that are currently impossible.",SPOTs: Optical Technologies for Instantly Quantifying Multicellular Response Profiles,9972477,R01GM127985,"['Address', 'Affect', 'Age', 'Area', 'Arrhythmogenic Right Ventricular Dysplasia', 'Beds', 'Behavior', 'Biomass', 'Cardiac', 'Cardiac Myocytes', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Collection', 'Color', 'Connective Tissue Diseases', 'Coupling', 'Data', 'Defect', 'Development', 'Disease', 'Disease model', 'Distal', 'Drug Screening', 'Electrophysiology (science)', 'Fibroblasts', 'Future', 'Generations', 'Genes', 'Genetic Diseases', 'Giant Cells', 'Goals', 'Heart Atrium', 'Human', 'Imaging technology', 'Interferometry', 'Left', 'Machine Learning', 'Marfan Syndrome', 'Measurement', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Neoplasm Metastasis', 'Optics', 'Pathologic', 'Pharmacology Study', 'Phenotype', 'Physiological', 'Population', 'Process', 'Property', 'Relaxation', 'Reporting', 'Resolution', 'Series', 'Spottings', 'Stimulus', 'Structure', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Traction', 'Traction Force Microscopy', 'Transplantation', 'Ventricular', 'Western World', 'biological systems', 'biophysical properties', 'body system', 'cancer cell', 'design', 'desmoplakin', 'electrical measurement', 'electrical property', 'human embryonic stem cell', 'human pluripotent stem cell', 'imaging platform', 'improved', 'indexing', 'insight', 'instrument', 'mechanical properties', 'mortality', 'new technology', 'patch clamp', 'prospective', 'public health relevance', 'regenerative', 'response', 'screening', 'small molecule', 'technology development', 'temporal measurement', 'tool', 'wound healing']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,530374,0.019974006868843482
"Imaging Live Cells with Super-Resolution Microscopy NIH-R15 “Imaging Live Cells with Super-Resolution Microscopy” Project Summary Fluorescence optical microscopy is one of the most important tools available for the study of biological systems at the cellular level. Unfortunately, due to diffraction phenomena the resolution of fluorescence microscopes in the lateral dimension is limited to about 250 nm. As many biological structures within cells are much smaller than this, increasing resolution is of prime importance. Although several methods are now available which are able to extend the resolution of optical microscopes beyond the diffraction limit, imaging live cells with these methods remains a major challenge. Super-resolution structured illumination microscopy (SIM), which can achieve a resolution of approximately 100 nm, is a suitable super-resolution method for imaging live cells. However, adoption of this technique by biologists is hindered by the inflexible equipment and artifact-prone image analysis algorithms which are currently available. The solution to this problem demands innovations in both optical design and in data processing methods which are used in SIM. Another new method, single molecule localization microscopy, achieves much higher resolution. Although live cell imaging has been demonstrated using single molecule localization approaches, applicability of this method in live cell studies is extremely limited due to the need to collect several thousand images to reconstruct a single super-resolution image. One solution to this problem is to greatly increase the density of photoactivated molecules in a given camera frame, but doing so requires more sophisticated computational methods to produce a satisfactory result. The goal of this interdisciplinary project is to develop, improve, and utilize super-resolution microscopy with a focus on imaging live cells. In Aim 1 we will develop alternative illumination approaches for SIM using economical components, and we will develop and implement improved SIM reconstruction algorithms which produce higher quality, more reliable results than are available with current methods. In Aim 2, we will improve single molecule localization microscopy, by developing and implementing algorithms for analysis of images with high densities of photoactivated molecules. Using the high density single molecule methods we develop, we expect to be able to accelerate imaging speed by a factor of 50, with a resulting image resolution of approximately 20 nm. In Aim 3, we will use the newly developed methods for studies of the molecular basis of allergic responses. We will use a novel total internal reflection-SIM microscope with polarized excitation to reveal the relationship between cell surface receptors and the morphology of the plasma membrane, in particular membrane regions with high curvature. NIH-R15: Imaging Live Cells with Super-Resolution Microscopy Project Narrative Several methods are now available which are able to produce optical fluorescence microscopy images of cells with a resolution that is not limited by diffraction. These methods, known together as super-resolution microscopy, are limited in their capabilities and applications when imaging live cells. This interdisciplinary AREA project, submitted by a team of three investigators, will involve undergraduate and graduate students at the University of Colorado, Colorado Springs in improving live cell imaging with super-resolution microscopy techniques. We will use the improved methods for studies of the molecular basis of allergic responses, which affect more than 50 million Americans each year.",Imaging Live Cells with Super-Resolution Microscopy,9515507,R15GM128166,"['Adoption', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'American', 'Award', 'Basophilic leukemia', 'Biological', 'Biological Models', 'Biology', 'Cell Surface Receptors', 'Cell membrane', 'Cells', 'Chemistry', 'Colorado', 'Computing Methodologies', 'Data', 'Data Analyses', 'Development', 'Dimensions', 'Doctor of Philosophy', 'Equipment', 'Event', 'Fluorescence', 'Fluorescence Microscopy', 'Focus Groups', 'Frequencies', 'Goals', 'HELLS gene', 'IgE Receptors', 'Image', 'Image Analysis', 'Lateral', 'Lighting', 'Lysosomes', 'Machine Learning', 'Malignant neoplasm of pancreas', 'Membrane', 'Membrane Proteins', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Nobel Prize', 'Noise', 'Optics', 'Pattern', 'Photobleaching', 'Phototoxicity', 'Physics', 'Principal Investigator', 'Proteins', 'Quantitative Evaluations', 'Rattus', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Signal Transduction', 'Software Tools', 'Speed', 'Structure', 'Students', 'Techniques', 'Testing', 'Thick', 'United States National Institutes of Health', 'Universities', 'Work', 'allergic response', 'biological systems', 'cellular imaging', 'computer science', 'computerized data processing', 'computerized tools', 'deep learning', 'density', 'design', 'experimental study', 'fluorescence imaging', 'fluorescence microscope', 'graduate student', 'imaging detector', 'imaging modality', 'immunological synapse formation', 'improved', 'innovation', 'live cell imaging', 'microscopic imaging', 'novel', 'optical imaging', 'overexpression', 'receptor', 'reconstruction', 'single molecule', 'tool', 'undergraduate student']",NIGMS,UNIVERSITY OF COLORADO,R15,2018,432000,0.0036592839454901607
"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",Joint Analysis of Microbiome and Other Genomic Data Types,9763572,R01GM129512,"['Achievement', 'Address', 'Area', 'Automobile Driving', 'Biological', 'Birth', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Early Diagnosis', 'Future', 'Genes', 'Genetic', 'Genomics', 'Grouping', 'Health', 'Human Genome Project', 'Joints', 'Lasso', 'Learning', 'Machine Learning', 'Maintenance', 'Maps', 'Medical', 'Menopause', 'Metabolic', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Modification', 'Molecular Target', 'Network-based', 'Outcome', 'Pathway interactions', 'Performance', 'Phylogenetic Analysis', 'Pregnancy Outcome', 'Premature Birth', 'Procedures', 'Public Health', 'Quantitative Trait Loci', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Structure', 'System', 'Taxonomy', 'Training', 'Woman', 'Work', 'base', 'biological systems', 'computerized tools', 'experience', 'genetic variant', 'genomic data', 'human disease', 'improved', 'interest', 'loss of function', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiome analysis', 'microbiome components', 'microbiome composition', 'microbiome research', 'new therapeutic target', 'novel', 'open source', 'population stratification', 'predictive modeling', 'simulation', 'software development', 'therapeutic target', 'tool', 'translational study', 'user friendly software', 'vaginal microbiome']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,396000,0.005445206084581578
"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",Joint Analysis of Microbiome and Other Genomic Data Types,9577818,R01GM129512,"['Achievement', 'Address', 'Area', 'Automobile Driving', 'Biological', 'Birth', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Early Diagnosis', 'Future', 'Genes', 'Genetic', 'Genomics', 'Grouping', 'Health', 'Human Genome Project', 'Joints', 'Lasso', 'Learning', 'Machine Learning', 'Maintenance', 'Maps', 'Medical', 'Menopause', 'Metabolic', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Modification', 'Molecular Target', 'Network-based', 'Outcome', 'Pathway interactions', 'Performance', 'Phylogenetic Analysis', 'Pregnancy Outcome', 'Premature Birth', 'Procedures', 'Public Health', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Structure', 'System', 'Taxonomy', 'Training', 'Woman', 'Work', 'base', 'biological systems', 'computerized tools', 'experience', 'genetic variant', 'genomic data', 'human disease', 'improved', 'interest', 'loss of function', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiome analysis', 'microbiome components', 'microbiome composition', 'microbiome research', 'new therapeutic target', 'novel', 'open source', 'population stratification', 'predictive modeling', 'simulation', 'software development', 'therapeutic target', 'tool', 'translational study', 'user friendly software', 'vaginal microbiome']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2018,396000,0.005445206084581578
"Turning a sequence barcode into a spectral barcode for single-cell analysis. Project Summary: The use of sequence barcodes has enabled high-throughput transcriptomic analysis of single cells. But one challenge remains – there is no method to map the physical assessments of single cells and the downstream transcriptomic data of single cells to the same cells of origin. This is because currently sequence barcodes are only read by sequencing which takes place after all single cells are lysed, reverse transcription is completed, and cDNA are amplified and pooled. In order to perform transcriptomic analysis and physical assessments on the same single cells, we will need a method that allows us to decipher the sequence barcodes while in the process of single-cell physical interrogation. Our goal in this proposed research is to develop a new method to turn sequence barcodes into spectral barcodes that can be read locally in the process. The proposed sequence- barcode-reading technique, if it can be realized, will have substantial impact to the single-cell community as it will become the only method to map the physical assessments and the downstream molecular analysis data to the same cells of origin in a high-throughput, streamlined format. Project Narrative: High-throughput single-cell analysis has advanced our knowledge in developmental biology and disease origins. But currently there is no method to map the physical and transcriptional analysis data of single cells to the same cells of origin. Here we propose to develop a method to overcome this limitation and enable both physical and molecular interrogation performed on the same single cells.",Turning a sequence barcode into a spectral barcode for single-cell analysis.,9586857,R21GM129617,"['Address', 'Architecture', 'Bioinformatics', 'Biology', 'Bypass', 'Cell Nucleus', 'Cells', 'Code', 'Color', 'Complementary DNA', 'Cytoplasm', 'DNA', 'DNA Probes', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Development', 'Developmental Biology', 'Encapsulated', 'Fluorescence', 'Fluorescent Probes', 'Genetic Transcription', 'Genomics', 'Goals', 'Hybrids', 'Hydrogels', 'Image', 'Individual', 'Knowledge', 'Libraries', 'Light', 'Machine Learning', 'Maps', 'Mechanics', 'Metals', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Mining', 'Molecular', 'Molecular Analysis', 'Motivation', 'Nature', 'Nuclear', 'Nucleic Acids', 'Nucleotides', 'Phenotype', 'Physical assessment', 'Process', 'Reading', 'Reporter', 'Research', 'Reverse Transcription', 'Series', 'Silver', 'Specificity', 'Stretching', 'Techniques', 'Technology', 'Testing', 'base', 'cell community', 'cost', 'design', 'developmental disease', 'droplet sequencing', 'experimental study', 'fluorescence imaging', 'interest', 'multiplex detection', 'nanocluster', 'nanoparticle', 'next generation', 'nucleobase', 'screening', 'single cell analysis', 'technology development', 'tool', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R21,2019,215902,-0.0007615918769910819
"Turning a sequence barcode into a spectral barcode for single-cell analysis. Project Summary: The use of sequence barcodes has enabled high-throughput transcriptomic analysis of single cells. But one challenge remains – there is no method to map the physical assessments of single cells and the downstream transcriptomic data of single cells to the same cells of origin. This is because currently sequence barcodes are only read by sequencing which takes place after all single cells are lysed, reverse transcription is completed, and cDNA are amplified and pooled. In order to perform transcriptomic analysis and physical assessments on the same single cells, we will need a method that allows us to decipher the sequence barcodes while in the process of single-cell physical interrogation. Our goal in this proposed research is to develop a new method to turn sequence barcodes into spectral barcodes that can be read locally in the process. The proposed sequence- barcode-reading technique, if it can be realized, will have substantial impact to the single-cell community as it will become the only method to map the physical assessments and the downstream molecular analysis data to the same cells of origin in a high-throughput, streamlined format. Project Narrative: High-throughput single-cell analysis has advanced our knowledge in developmental biology and disease origins. But currently there is no method to map the physical and transcriptional analysis data of single cells to the same cells of origin. Here we propose to develop a method to overcome this limitation and enable both physical and molecular interrogation performed on the same single cells.",Turning a sequence barcode into a spectral barcode for single-cell analysis.,9898410,R21GM129617,"['Address', 'Architecture', 'Bar Codes', 'Bioinformatics', 'Biology', 'Bypass', 'Cell Nucleus', 'Cells', 'Code', 'Color', 'Complementary DNA', 'Cytoplasm', 'DNA', 'DNA Probes', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Development', 'Developmental Biology', 'Encapsulated', 'Fluorescence', 'Fluorescent Probes', 'Genetic Transcription', 'Genomics', 'Goals', 'Hybrids', 'Hydrogels', 'Image', 'Individual', 'Knowledge', 'Libraries', 'Light', 'Machine Learning', 'Maps', 'Mechanics', 'Metals', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Mining', 'Molecular', 'Molecular Analysis', 'Motivation', 'Nature', 'Nuclear', 'Nucleic Acids', 'Nucleotides', 'Phenotype', 'Physical assessment', 'Process', 'Reading', 'Reporter', 'Research', 'Reverse Transcription', 'Series', 'Silver', 'Specificity', 'Stretching', 'Techniques', 'Technology', 'Testing', 'base', 'cell community', 'cost', 'design', 'developmental disease', 'droplet sequencing', 'experimental study', 'fluorescence imaging', 'interest', 'multiplex detection', 'nanocluster', 'nanoparticle', 'next generation', 'nucleobase', 'screening', 'single cell analysis', 'technology development', 'tool', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R21,2020,181900,-0.0007615918769910819
"VISUALIZATION OF SUBCELLULAR DYNAMICS IN MULTICELLULAR ORGANISMS Abstract Contemporary fluorescence microscopy connects our understanding of molecular events from biochemistry and structural biology with their activities in living cells. Lattice light sheet microscopy (LLSM) has made it possible for us to track phenomena such as endocytic vesicle assembly or lipid kinase recruitment across an entire cell with high resolution, in both space and time, and with nearly single-molecule sensitivity. Development during the past year of lattice light sheet microscopy with adaptive optics (AO-LLSM) has overcome the optical limitations that have so far restricted most studies to individual cells in culture, allowing us to achieve comparable resolution and sensitivity in the complex optical environment of an intact, living, multicellular organism. It promises to bridge the gap between cells and organisms, through high sensitivity, volumetric imaging, with diffraction-limited resolution, of living tissues and developing embryos. We propose a research program in three overlapping stages: implementation of AO-LLSM (in collaboration with its developer), development of the new kinds of visualization and analysis software required by the scale and complexity of the datasets, and use of AO-LLSM to solve a problem in vertebrate development. To meet the computational challenges of analyzing the 4D data sets (from low signal-to-noise, the often non- punctate characteristics of the objects being studied, the temporally varying spatial complexity of the data, and the size of the data sets), we will develop new approaches using deep learning and related algorithms, with consultation from experts. As a paradigm application, we will study the consequences of Notch signaling and the related membrane-traffic and protein translocation events for cell differentiation in zebrafish early neurogenesis. AO-LLSM will for the first time allow us to relate molecular signaling events occurring on a timescale of seconds at cell interfaces to the ultimate fate of daughter cells many hours later. We therefore expect that in the course of resolving some long- standing issues in cell fate determination, we will develop microscopy approaches and computer visualization tools that are widely applicable to a range of model systems and biological questions. Narrative We will implement and apply a novel, live-cell imaging strategy (Lattice Light-Sheet Microscopy with Adaptive Optics: AO-LLSM) that spans, with diffraction-limited resolution, a range from molecules to tissues and from seconds to hours. We will use this new technology to study cell differentiation in the embryonic zebrafish brain, concentrating on how Notch-mediated signaling exerts long-range control over neuronal development. Obtaining accurate and comprehensive models of the underlying biology will require that we devise new and generalizable ways to display and analyze complex data sets, while overcoming the computational challenges posed by the low SNR of the imaging regime, the time-varying spatial complexity of the data, and the size of the data sets.",VISUALIZATION OF SUBCELLULAR DYNAMICS IN MULTICELLULAR ORGANISMS,9872183,R35GM130386,"['Algorithms', 'Biochemistry', 'Biological', 'Biological Models', 'Biology', 'Brain', 'Cell Differentiation process', 'Cells', 'Characteristics', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'Consultations', 'Data', 'Data Set', 'Development', 'Embryo', 'Endocytic Vesicle', 'Environment', 'Event', 'Fluorescence Microscopy', 'Hour', 'Image', 'Individual', 'Light', 'Lipids', 'Mediating', 'Membrane Protein Traffic', 'Microscopy', 'Modeling', 'Molecular', 'Noise', 'Optics', 'Organism', 'Phosphotransferases', 'Protein translocation', 'Research', 'Resolution', 'Signal Transduction', 'Time', 'Tissues', 'Visualization', 'Visualization software', 'Zebrafish', 'adaptive optics', 'complex data ', 'daughter cell', 'deep learning', 'live cell imaging', 'neurogenesis', 'neuron development', 'new technology', 'notch protein', 'novel', 'novel strategies', 'programs', 'recruit', 'single molecule', 'structural biology']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R35,2020,442500,0.03583806052846124
"VISUALIZATION OF SUBCELLULAR DYNAMICS IN MULTICELLULAR ORGANISMS Abstract Contemporary fluorescence microscopy connects our understanding of molecular events from biochemistry and structural biology with their activities in living cells. Lattice light sheet microscopy (LLSM) has made it possible for us to track phenomena such as endocytic vesicle assembly or lipid kinase recruitment across an entire cell with high resolution, in both space and time, and with nearly single-molecule sensitivity. Development during the past year of lattice light sheet microscopy with adaptive optics (AO-LLSM) has overcome the optical limitations that have so far restricted most studies to individual cells in culture, allowing us to achieve comparable resolution and sensitivity in the complex optical environment of an intact, living, multicellular organism. It promises to bridge the gap between cells and organisms, through high sensitivity, volumetric imaging, with diffraction-limited resolution, of living tissues and developing embryos. We propose a research program in three overlapping stages: implementation of AO-LLSM (in collaboration with its developer), development of the new kinds of visualization and analysis software required by the scale and complexity of the datasets, and use of AO-LLSM to solve a problem in vertebrate development. To meet the computational challenges of analyzing the 4D data sets (from low signal-to-noise, the often non- punctate characteristics of the objects being studied, the temporally varying spatial complexity of the data, and the size of the data sets), we will develop new approaches using deep learning and related algorithms, with consultation from experts. As a paradigm application, we will study the consequences of Notch signaling and the related membrane-traffic and protein translocation events for cell differentiation in zebrafish early neurogenesis. AO-LLSM will for the first time allow us to relate molecular signaling events occurring on a timescale of seconds at cell interfaces to the ultimate fate of daughter cells many hours later. We therefore expect that in the course of resolving some long- standing issues in cell fate determination, we will develop microscopy approaches and computer visualization tools that are widely applicable to a range of model systems and biological questions. Narrative We will implement and apply a novel, live-cell imaging strategy (Lattice Light-Sheet Microscopy with Adaptive Optics: AO-LLSM) that spans, with diffraction-limited resolution, a range from molecules to tissues and from seconds to hours. We will use this new technology to study cell differentiation in the embryonic zebrafish brain, concentrating on how Notch-mediated signaling exerts long-range control over neuronal development. Obtaining accurate and comprehensive models of the underlying biology will require that we devise new and generalizable ways to display and analyze complex data sets, while overcoming the computational challenges posed by the low SNR of the imaging regime, the time-varying spatial complexity of the data, and the size of the data sets.",VISUALIZATION OF SUBCELLULAR DYNAMICS IN MULTICELLULAR ORGANISMS,9946046,R35GM130386,"['Algorithms', 'Biochemistry', 'Biological', 'Biological Models', 'Biology', 'Brain', 'Cell Differentiation process', 'Cells', 'Characteristics', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'Consultations', 'Data', 'Data Set', 'Development', 'Embryo', 'Endocytic Vesicle', 'Environment', 'Event', 'Fluorescence Microscopy', 'Hour', 'Image', 'Imagery', 'Individual', 'Light', 'Lipids', 'Mediating', 'Membrane Protein Traffic', 'Microscopy', 'Modeling', 'Molecular', 'Noise', 'Optics', 'Organism', 'Phosphotransferases', 'Protein translocation', 'Research', 'Resolution', 'Signal Transduction', 'Time', 'Tissues', 'Visualization software', 'Zebrafish', 'adaptive optics', 'daughter cell', 'deep learning', 'live cell imaging', 'neurogenesis', 'neuron development', 'new technology', 'notch protein', 'novel', 'novel strategies', 'programs', 'recruit', 'single molecule', 'structural biology']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R35,2019,233580,0.03583806052846124
"VISUALIZATION OF SUBCELLULAR DYNAMICS IN MULTICELLULAR ORGANISMS Abstract Contemporary fluorescence microscopy connects our understanding of molecular events from biochemistry and structural biology with their activities in living cells. Lattice light sheet microscopy (LLSM) has made it possible for us to track phenomena such as endocytic vesicle assembly or lipid kinase recruitment across an entire cell with high resolution, in both space and time, and with nearly single-molecule sensitivity. Development during the past year of lattice light sheet microscopy with adaptive optics (AO-LLSM) has overcome the optical limitations that have so far restricted most studies to individual cells in culture, allowing us to achieve comparable resolution and sensitivity in the complex optical environment of an intact, living, multicellular organism. It promises to bridge the gap between cells and organisms, through high sensitivity, volumetric imaging, with diffraction-limited resolution, of living tissues and developing embryos. We propose a research program in three overlapping stages: implementation of AO-LLSM (in collaboration with its developer), development of the new kinds of visualization and analysis software required by the scale and complexity of the datasets, and use of AO-LLSM to solve a problem in vertebrate development. To meet the computational challenges of analyzing the 4D data sets (from low signal-to-noise, the often non- punctate characteristics of the objects being studied, the temporally varying spatial complexity of the data, and the size of the data sets), we will develop new approaches using deep learning and related algorithms, with consultation from experts. As a paradigm application, we will study the consequences of Notch signaling and the related membrane-traffic and protein translocation events for cell differentiation in zebrafish early neurogenesis. AO-LLSM will for the first time allow us to relate molecular signaling events occurring on a timescale of seconds at cell interfaces to the ultimate fate of daughter cells many hours later. We therefore expect that in the course of resolving some long- standing issues in cell fate determination, we will develop microscopy approaches and computer visualization tools that are widely applicable to a range of model systems and biological questions. Narrative We will implement and apply a novel, live-cell imaging strategy (Lattice Light-Sheet Microscopy with Adaptive Optics: AO-LLSM) that spans, with diffraction-limited resolution, a range from molecules to tissues and from seconds to hours. We will use this new technology to study cell differentiation in the embryonic zebrafish brain, concentrating on how Notch-mediated signaling exerts long-range control over neuronal development. Obtaining accurate and comprehensive models of the underlying biology will require that we devise new and generalizable ways to display and analyze complex data sets, while overcoming the computational challenges posed by the low SNR of the imaging regime, the time-varying spatial complexity of the data, and the size of the data sets.",VISUALIZATION OF SUBCELLULAR DYNAMICS IN MULTICELLULAR ORGANISMS,9626714,R35GM130386,"['Algorithms', 'Biochemistry', 'Biological', 'Biological Models', 'Biology', 'Brain', 'Cell Differentiation process', 'Cells', 'Characteristics', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'Consultations', 'Data', 'Data Set', 'Development', 'Embryo', 'Endocytic Vesicle', 'Environment', 'Event', 'Fluorescence Microscopy', 'Hour', 'Image', 'Imagery', 'Individual', 'Light', 'Lipids', 'Mediating', 'Membrane Protein Traffic', 'Microscopy', 'Modeling', 'Molecular', 'Noise', 'Optics', 'Organism', 'Phosphotransferases', 'Protein translocation', 'Research', 'Resolution', 'Signal Transduction', 'Time', 'Tissues', 'Visualization software', 'Zebrafish', 'adaptive optics', 'daughter cell', 'deep learning', 'live cell imaging', 'neurogenesis', 'neuron development', 'new technology', 'notch protein', 'novel', 'novel strategies', 'programs', 'recruit', 'single molecule', 'structural biology']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R35,2019,442500,0.03583806052846124
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,9936138,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,617708,-0.034378072642122844
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,9703885,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,625626,-0.034378072642122844
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,9501686,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,633392,-0.034378072642122844
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,9407909,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,650713,-0.034378072642122844
"Unravel the cellular biophysical dynamics of spatial constraint-induced membrane blebbing and 3D migration using a microfluidic platform and data-driven mathematical modeling PROJECT SUMMARY Plasma Membrane blebbing and the relevant three-dimensional cell migration are vital biophysical processes, which trigger some critical cellular events and are implicated in a wide range of disease. Despite the preliminary success in identifying a key gene pathway and characterizing the basic cell morphology, the underlying mechanism are still poorly understood, due to the lack of effective research platforms. It remains to be a key question how the blebbing transduce the cell environmental stimuli into the cell and drive the cell migration. We recently developed a microfluidic device for the study of blebbing and cell migration. This device recapitulates the native environment for blebbing-involved migration, while providing some unprecedented advantages for investigating the cellular biophysics. We also established a data-driven mathematical modeling framework to study the complex morphology of bleb-like protrusions. Based on our preliminary data and other previous studies, we hypothesize that it is through the polarization of sensory ion channels that the environmental stimuli induce polarized blebbing, which provides the driving force for the migration. To test the hypothesis, we propose to study the blebbing dynamics, using a novel experimental-theoretical integrated platform, which is based on the previously established microfluidic device and data-driven mathematical model. First, we will define the correlation and cause-effect relationship of blebbing dynamics and the cell motility. Then we will define the correlation of blebbing dynamics to ion channel activities and regulation of pathways. Finally, we will assess the influence of the environmental stimuli on the blebbing-related cellular behavior and molecular regulation. The outcome of this study will significantly enhance our understanding towards the role of PM blebbing in cell migration and, in the long run, promote the bleb-targeting therapy. The developed experimental-theoretical integrated platform will also serve as a valuable technology for other cellular biophysical studies. PROJECT NARRATIVE Plasma Membrane blebbing, a fundamental and essential cell behavior that takes place in various cell types, can be induced by spatial constraint and drive cell motility in the three-dimensional environment. The proposed research uses a specialized engineering platform integrated with mathematical modeling to unravel the underlying physical dynamics and molecular mechanisms. The accomplishment of this project may facilitate the mechanistic study of membrane blebs and shed the lights on various bleb- implicated diseases.",Unravel the cellular biophysical dynamics of spatial constraint-induced membrane blebbing and 3D migration using a microfluidic platform and data-driven mathematical modeling,9731778,R15GM132877,"['3-Dimensional', 'Affect', 'Antiinflammatory Effect', 'Apoptosis', 'Autoimmune Diseases', 'Automobile Driving', 'Biochemical', 'Biological Assay', 'Biology', 'Biophysical Process', 'Biophysics', 'Bulla', 'Cell division', 'Cell membrane', 'Cells', 'Cellular Morphology', 'Chemical Interference', 'Chemicals', 'Chemotaxis', 'Complex', 'Computer Simulation', 'Cues', 'Data', 'Development', 'Devices', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Event', 'Frequencies', 'Genes', 'Health', 'Image', 'Image Analysis', 'In Vitro', 'Inflammation', 'Inflammatory', 'Ion Channel', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Membrane', 'Microfluidic Microchips', 'Microfluidics', 'Molecular', 'Molecular Biology', 'Morphology', 'National Institute of General Medical Sciences', 'Organ', 'Outcome', 'Outcome Study', 'Pathway interactions', 'Process', 'Proteins', 'Regulation', 'Research', 'Role', 'Sensory', 'Speed', 'Stimulus', 'Technology', 'Testing', 'Theoretical Studies', 'Time', 'base', 'biophysical analysis', 'cell behavior', 'cell dimension', 'cell motility', 'cell type', 'cellular imaging', 'cellular transduction', 'driving force', 'drug candidate', 'in vivo Model', 'inhibitor/antagonist', 'interest', 'malformation', 'mathematical model', 'migration', 'molecular dynamics', 'multidisciplinary', 'novel', 'pathogen', 'sensor', 'success', 'targeted treatment', 'tool', 'tumorigenesis', 'vesicular release']",NIGMS,UTAH STATE UNIVERSITY,R15,2019,435000,-0.020694606921295627
"Unraveling subcellular heterogeneity of molecular coordination by machine learning PROJECT SUMMARY/ABSTRACT Recent advances in fluorescence microscopy allow researchers to acquire an unprecedented amount of live cell image data at high spatial and temporal resolutions. However, these images pose a significant challenge for data analyses due to massive subcellular heterogeneity. Although conventional computer vision algorithms have facilitated automatic image analysis, traditional ensemble-averaging of subcellular heterogeneity could lead to the loss of critical mechanistic details. Given the current rapid growth of cell biological data from new technological development, it is nearly impossible to keep up with the data generation if we solely rely on human intelligence for algorithm development and data analysis. Recently, machine learning (ML) is making tremendous progress and has shown that computers can outperform humans in the analysis of complex high dimensional datasets. Conventional ML application in cell biology, however, is usually limited to fixed cells or low spatial resolution setting (single cell resolution), which is limited in analyzing dynamic subcellular information. To fill this voids, we have been developing an ML framework for fluorescence live cell image analyses at the subcellular level. In our previous study, we established the method to deconvolve the subcellular heterogeneity of lamellipodial protrusion from live cell imaging, which identified distinct subcellular protrusion phenotypes with differential drug susceptibility. Thus, our goal is to advance this ML framework and address technical and cell biological challenges in the live cell analysis. The overall goal of our research is two- fold: i) advancing a new ML framework for cell biological research (technological development) and ii) applying our ML framework to integrate mechanobiology and metabolism in cell protrusion (targeted cell biological study). First, we will advance our ML framework for the deconvolution of subcellular heterogeneity of protrusion and molecular coordination in live cells. This method will integrate time-series modeling and ML to deconvolve subcellular molecular coordination. Second, we will develop deep learning based high-throughput fluorescence live cell imaging. This will include microscope automation, resolution enhancement, and data synthesis, which will build up the massive dataset for ML. Third, we will apply our ML framework to study the mechanosensitivity of subcellular bioenergetic status in cell protrusion. We will evaluate how AMPK reacts to mechanical forces and controls the subcellular organization of actin assembly and mitochondria to promote energy-demanding protrusion phenotypes. Our ML framework will bring unprecedented analytical power to cell biology by analyzing a large numbers of individual cells at the high spatial resolution and automatically extracting a multitude of subcellular phenotypes. This framework can be applied to various areas of cell biology such as cytoskeleton, membrane remodeling, and membrane-bound organelles. PROJECT NARRATIVE We propose to develop a novel machine learning framework for automated, large-scale analyses of single cells at the subcellular level. By integrating time-series modeling and machine learning, this new system will enable us to identify hidden phenotypes and molecular coordination from live cell movies. We will apply the developed technology to study the interplay between mechanical forces and metabolism in cell protrusion.",Unraveling subcellular heterogeneity of molecular coordination by machine learning,9797909,R35GM133725,"['Actins', 'Address', 'Algorithms', 'Area', 'Automation', 'Bioenergetics', 'Biological', 'Cells', 'Cellular biology', 'Complex', 'Computer Vision Systems', 'Computers', 'Cytoskeleton', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Fluorescence', 'Fluorescence Microscopy', 'Generations', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Lead', 'Machine Learning', 'Membrane', 'Metabolism', 'Methods', 'Microscope', 'Mitochondria', 'Modeling', 'Molecular', 'Organelles', 'Pharmaceutical Preparations', 'Phenotype', 'Predisposition', 'Research', 'Research Personnel', 'Resolution', 'Series', 'System', 'Technology', 'Time', 'base', 'biological research', 'cell growth', 'deep learning', 'high dimensionality', 'live cell imaging', 'mechanical force', 'movie', 'novel', 'rapid growth', 'single cell analysis', 'temporal measurement']",NIGMS,WORCESTER POLYTECHNIC INSTITUTE,R35,2019,232688,0.04327897605367616
"Building protein structure models for intermediate resolution cryo-electron microscopy maps Project Summary Cryo-electron microscopy (cryo-EM) is an emerging technique in structural biology, which is capable of determining three-dimensional (3D) structures of biological macromolecules. Compared to conventional structural biology techniques, such as X-ray crystallography and NMR, a major advantage of cryo-EM is its ability to solve large macromolecular assemblies. Moreover, recent technical breakthroughs in cryo-EM have enabled determination of 3D structures at nearly atomic-level resolutions. Cryo-EM will undoubtedly become a method of central importance in structural biology in the next decade. With the rapid accumulation of cryo-EM structure data, it has become crucial to develop computational methods that can effectively build and extract 3D structures of biological macromolecules from EM maps. The goal of this project is to develop computational methods for modeling both global and local structures and for interpreting 3D structures embedded in EM maps of around 4 Å to medium-resolution. Recently, we have developed a new de novo protein structure modeling method, MAINMAST, which can model protein structures from an EM density map without using existing template or fragment structures on the map. Based on the successful development of MAINMAST, we further extend the capability of MAINMAST toward more accurate modeling and for multiple-chain modeling. In addition, we will also develop novel modeling methods for medium-resolution EM maps, which combine a coarse-grained protein structure modeling technique, methods in protein structure prediction, and a low- resolution image processing approach with deep learning, a state-of-the-art powerful machine learning method. The proposed project capitalizes on the tremendous efforts and progress made in structural determination with cryo-EM by developing computational tools that allow researchers to perform efficient and reliable structure analyses for 3D EM density maps. The project will greatly facilitate investigation into the molecular mechanisms of macromolecule function by providing an efficient means of 3D structure modeling. Narrative Cryo-electron microscopy is an emerging technique for determining the three-dimensional structure of biological macromolecules. We propose to develop computational methods that can accurately and effectively model and interpret structures of biomolecules embedded in electron microscopy density maps and thereby facilitate the understanding of molecular mechanisms of protein function and disease.",Building protein structure models for intermediate resolution cryo-electron microscopy maps,9971996,R01GM133840,"['3-Dimensional', 'Algorithms', 'Amino Acids', 'Area', 'Biological', 'Cells', 'Chimera organism', 'Code', 'Communication', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'Cryoelectron Microscopy', 'DNA', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Goals', 'Grain', 'Human', 'Intervention', 'Investigation', 'Knowledge', 'Ligands', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Multiprotein Complexes', 'Nature', 'Positioning Attribute', 'Preparation', 'Protein Region', 'Proteins', 'Publishing', 'RNA', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Side', 'Source Code', 'Structural Models', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Visualization software', 'X-Ray Crystallography', 'base', 'computerized tools', 'data acquisition', 'deep learning', 'density', 'graphical user interface', 'image processing', 'improved', 'machine learning method', 'macromolecular assembly', 'macromolecule', 'model building', 'novel', 'programs', 'protein function', 'protein structure', 'protein structure prediction', 'repository', 'software development', 'structural biology', 'structured data', 'three dimensional structure', 'tool']",NIGMS,PURDUE UNIVERSITY,R01,2020,305459,0.054944109102462384
"Methods for determination of glycoprotein glycosylation similarities among disease states Abstract This application addresses NIGMS PAR-17-045 “Focused Technology Research and Development (R01)”. This initiative supports projects that focus solely on development of technologies with the potential to enable biomedical research. Dysregulation of the cellular microenvironment occurs in cancers, neurodevelopmental and neuropsychiatric diseases. Known as the matrisome, the set of extracellular matrix and cell surface molecules control the availability of growth factors to cellular receptors and the mechanical-physical properties of the cell microenvironment. Currently, the limited understanding of regulation of matrisome glycosylation hinders understanding of the roles of glycosylation-dependent matrisome networks in the basic mechanisms necessary for targeted intervention of many diseases. Matrisome function depends on networks of interaction among glycosylated proteins and glycan-binding lectins. It is not possible using present proteomics and glycoproteomics methods to compare using rigorous statistics similarities of glycoproteins that differ by disease-related changes in site-specific glycosylation. We propose to develop technologies to meet this need. Present proteomics methods quantify proteins using a few representative peptides per gene product; sequence coverage for most proteins is low. Such low sequence coverage does not suffice to reconstruct the predominant glycosylated proteoforms active in a biological context. We propose to develop technologies to compare glycoprotein similarities among biological sample sets. To do this, we will develop MS acquisition and bioinformatics methods for rapid, sensitive and reproducible mapping of glycoprotein glycosylation to enable statistically rigorous comparison of glycoprotein similarities. By making these technologies available, we will enable a new level of understanding of the roles of matrisome networks in human diseases. Project narrative The matrisome consists of glycosylated extracellular matrix and cell surface proteins that surround cells and support normal physiological activity. While it is known that glycosylation changes during disease processes, it has not been possible to quantitatively compare glycoprotein structure among biological samples. We aim to develop technologies to meet this need.",Methods for determination of glycoprotein glycosylation similarities among disease states,10135316,R01GM133963,"['Address', 'Algorithms', 'Atherosclerosis', 'Autoimmune Diseases', 'Binding', 'Bioinformatics', 'Biological', 'Biological Process', 'Biomedical Research', 'Brain', 'Brain region', 'CSPG3 gene', 'Cell Surface Proteins', 'Cell surface', 'Cells', 'Chondroitin Sulfate Proteoglycan', 'Collagen', 'Complex', 'Core Protein', 'Data', 'Data Set', 'Disease', 'Dissociation', 'Electron Transport', 'Environment', 'Enzymes', 'Extracellular Matrix', 'Family', 'Functional disorder', 'Genes', 'Glycopeptides', 'Glycoproteins', 'Growth Factor', 'Growth Factor Receptors', 'Heart', 'Heparitin Sulfate', 'Intelligence', 'Intervention', 'Ions', 'Knowledge', 'Lectin', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Neurodegenerative Disorders', 'Pathway interactions', 'Peptides', 'Physiological', 'Polysaccharides', 'Process', 'Protein Glycosylation', 'Proteins', 'Proteoglycan', 'Proteomics', 'Receptor Protein-Tyrosine Kinases', 'Regulation', 'Reproducibility', 'Role', 'Sampling', 'Signal Pathway', 'Site', 'Structure', 'Technology', 'Tissues', 'aggrecan', 'bioinformatics tool', 'brevican', 'cell growth', 'data acquisition', 'data to knowledge', 'extracellular', 'gene product', 'glycoprotein structure', 'glycoproteomics', 'glycosylation', 'human disease', 'hydrophilicity', 'neuropsychiatric disorder', 'pathogen', 'physical property', 'rapid technique', 'receptor', 'statistics', 'technology development', 'technology research and development', 'versican']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R01,2020,100000,0.00587468302981322
"Methods for determination of glycoprotein glycosylation similarities among disease states Abstract This application addresses NIGMS PAR-17-045 “Focused Technology Research and Development (R01)”. This initiative supports projects that focus solely on development of technologies with the potential to enable biomedical research. Dysregulation of the cellular microenvironment occurs in cancers, neurodevelopmental and neuropsychiatric diseases. Known as the matrisome, the set of extracellular matrix and cell surface molecules control the availability of growth factors to cellular receptors and the mechanical-physical properties of the cell microenvironment. Currently, the limited understanding of regulation of matrisome glycosylation hinders understanding of the roles of glycosylation-dependent matrisome networks in the basic mechanisms necessary for targeted intervention of many diseases. Matrisome function depends on networks of interaction among glycosylated proteins and glycan-binding lectins. It is not possible using present proteomics and glycoproteomics methods to compare using rigorous statistics similarities of glycoproteins that differ by disease-related changes in site-specific glycosylation. We propose to develop technologies to meet this need. Present proteomics methods quantify proteins using a few representative peptides per gene product; sequence coverage for most proteins is low. Such low sequence coverage does not suffice to reconstruct the predominant glycosylated proteoforms active in a biological context. We propose to develop technologies to compare glycoprotein similarities among biological sample sets. To do this, we will develop MS acquisition and bioinformatics methods for rapid, sensitive and reproducible mapping of glycoprotein glycosylation to enable statistically rigorous comparison of glycoprotein similarities. By making these technologies available, we will enable a new level of understanding of the roles of matrisome networks in human diseases. Project narrative The matrisome consists of glycosylated extracellular matrix and cell surface proteins that surround cells and support normal physiological activity. While it is known that glycosylation changes during disease processes, it has not been possible to quantitatively compare glycoprotein structure among biological samples. We aim to develop technologies to meet this need.",Methods for determination of glycoprotein glycosylation similarities among disease states,9995540,R01GM133963,"['Address', 'Algorithms', 'Atherosclerosis', 'Autoimmune Diseases', 'Binding', 'Bioinformatics', 'Biological', 'Biological Process', 'Biomedical Research', 'Brain', 'Brain region', 'CSPG3 gene', 'Cell Surface Proteins', 'Cell surface', 'Cells', 'Chondroitin Sulfate Proteoglycan', 'Collagen', 'Complex', 'Core Protein', 'Data', 'Data Set', 'Disease', 'Dissociation', 'Electron Transport', 'Environment', 'Enzymes', 'Extracellular Matrix', 'Family', 'Functional disorder', 'Genes', 'Glycopeptides', 'Glycoproteins', 'Growth Factor', 'Growth Factor Receptors', 'Heart', 'Heparitin Sulfate', 'Intelligence', 'Intervention', 'Ions', 'Knowledge', 'Lectin', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Neurodegenerative Disorders', 'Pathway interactions', 'Peptides', 'Physiological', 'Polysaccharides', 'Process', 'Protein Glycosylation', 'Proteins', 'Proteoglycan', 'Proteomics', 'Receptor Protein-Tyrosine Kinases', 'Regulation', 'Reproducibility', 'Role', 'Sampling', 'Signal Pathway', 'Site', 'Structure', 'Technology', 'Tissues', 'aggrecan', 'bioinformatics tool', 'brevican', 'cell growth', 'data acquisition', 'data to knowledge', 'extracellular', 'gene product', 'glycoprotein structure', 'glycoproteomics', 'glycosylation', 'human disease', 'hydrophilicity', 'neuropsychiatric disorder', 'pathogen', 'physical property', 'rapid technique', 'receptor', 'statistics', 'technology development', 'technology research and development', 'versican']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R01,2020,420750,0.00587468302981322
"Methods for determination of glycoprotein glycosylation similarities among disease states Abstract This application addresses NIGMS PAR-17-045 “Focused Technology Research and Development (R01)”. This initiative supports projects that focus solely on development of technologies with the potential to enable biomedical research. Dysregulation of the cellular microenvironment occurs in cancers, neurodevelopmental and neuropsychiatric diseases. Known as the matrisome, the set of extracellular matrix and cell surface molecules control the availability of growth factors to cellular receptors and the mechanical-physical properties of the cell microenvironment. Currently, the limited understanding of regulation of matrisome glycosylation hinders understanding of the roles of glycosylation-dependent matrisome networks in the basic mechanisms necessary for targeted intervention of many diseases. Matrisome function depends on networks of interaction among glycosylated proteins and glycan-binding lectins. It is not possible using present proteomics and glycoproteomics methods to compare using rigorous statistics similarities of glycoproteins that differ by disease-related changes in site-specific glycosylation. We propose to develop technologies to meet this need. Present proteomics methods quantify proteins using a few representative peptides per gene product; sequence coverage for most proteins is low. Such low sequence coverage does not suffice to reconstruct the predominant glycosylated proteoforms active in a biological context. We propose to develop technologies to compare glycoprotein similarities among biological sample sets. To do this, we will develop MS acquisition and bioinformatics methods for rapid, sensitive and reproducible mapping of glycoprotein glycosylation to enable statistically rigorous comparison of glycoprotein similarities. By making these technologies available, we will enable a new level of understanding of the roles of matrisome networks in human diseases. Project narrative The matrisome consists of glycosylated extracellular matrix and cell surface proteins that surround cells and support normal physiological activity. While it is known that glycosylation changes during disease processes, it has not been possible to quantitatively compare glycoprotein structure among biological samples. We aim to develop technologies to meet this need.",Methods for determination of glycoprotein glycosylation similarities among disease states,9800244,R01GM133963,"['Address', 'Algorithms', 'Atherosclerosis', 'Autoimmune Diseases', 'Binding', 'Bioinformatics', 'Biological', 'Biological Process', 'Biomedical Research', 'Bos taurus structural-GP protein', 'Brain', 'Brain region', 'CSPG3 gene', 'Cell Surface Proteins', 'Cell surface', 'Cells', 'Chondroitin Sulfate Proteoglycan', 'Collagen', 'Complex', 'Core Protein', 'Data', 'Data Set', 'Disease', 'Dissociation', 'Electron Transport', 'Environment', 'Enzymes', 'Extracellular Matrix', 'Family', 'Functional disorder', 'Genes', 'Glycopeptides', 'Glycoproteins', 'Growth Factor', 'Growth Factor Receptors', 'Heart', 'Heparitin Sulfate', 'Intelligence', 'Intervention', 'Ions', 'Knowledge', 'Lectin', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Neurodegenerative Disorders', 'Pathway interactions', 'Peptides', 'Physiological', 'Polysaccharides', 'Process', 'Protein Glycosylation', 'Proteins', 'Proteoglycan', 'Proteomics', 'Receptor Protein-Tyrosine Kinases', 'Regulation', 'Reproducibility', 'Role', 'Sampling', 'Signal Pathway', 'Site', 'Structure', 'Technology', 'Tissues', 'aggrecan', 'bioinformatics tool', 'brevican', 'cell growth', 'data acquisition', 'data to knowledge', 'extracellular', 'gene product', 'glycoprotein structure', 'glycoproteomics', 'glycosylation', 'human disease', 'hydrophilicity', 'neuropsychiatric disorder', 'pathogen', 'physical property', 'rapid technique', 'receptor', 'statistics', 'technology development', 'technology research and development', 'versican']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R01,2019,420750,0.00587468302981322
"Novel machine learning approaches for improving structural discrimination in cryo-electron tomography Project Summary Cellular cryo-electron tomography (Cryo-ET) has made possible the observation of cellular organelles and macromolecular complexes at nanometer resolution with native conformations. The rapid increasing amount of Cryo-ET data available however brings along some major challenges for analysis which we will timely ad- dress in this proposal. We will design novel data-driven machine learning algorithms for improving structural discrimination and resolution. In particular, we have the following speciﬁc aims: (1) We will develop a novel Autoencoder and Iterative region Matching (AIM) algorithm for marker-free alignment of image tilt-series to re- construct tomograms with improved resolution; (2) We will develop a saliency-based auto-picking algorithm for better detecting macromolecular complexes, and combine it with an innovative 2D-to-3D framework to further improve structure detection accuracy; (3) We will design an end-to-end convolutional model for pose-invariant clustering of subtomograms. This model will produce an initial clustering which will be reﬁned by a new subto- mogram averaging algorithm that automatically down-weights subtomograms of noise and little contribution; (4) We will perform experimental evaluations by using previously reported bacterial secretion systems and mito- chondrial ultrastructures datasets to improve the ﬁnal resolution. Implementing algorithms in Aims 1-3, we will develop a user-friendly open-source graphical user interface -tom to directly beneﬁt the scientiﬁc community.  -tom will be systematically compared with existing software including IMOD, EMAN2, and Relion on simulated and benchmark datasets. To facilitate distribution, -tom will be integrated into existing software platforms Sci- pion and TomoMiner. Our data-driven algorithms and software not only will facilitate and accelerate the future use of Cryo-ET, but also can be readily used on analyzing the existing large amounts of Cryo-ET data to im- prove our understanding of the structure, function, and spatial organization of macromolecular complexes in situ. Project Narrative This project will create a system of machine learning algorithms to accelerate and facilitate the use and re-use of the rapidly accumulating Cryo-ET datasets. For easy use, we will develop an open-source GUI -Tom (to be disseminated into the Scipion and TomoMiner software platforms) that streamlines the new approaches from the initial tomogram reconstruction step to the ﬁnal subtomogram averaging step. We will validate the performance of our system by applying it on published Cryo-ET datasets and monitor the improvement of the ﬁnal results.",Novel machine learning approaches for improving structural discrimination in cryo-electron tomography,9973462,R01GM134020,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Back', 'Benchmarking', 'Biological Process', 'Cells', 'Communities', 'Computer Analysis', 'Computer software', 'Cryo-electron tomography', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Discrimination', 'Evaluation', 'Future', 'Gaussian model', 'Group Structure', 'Hour', 'Image', 'In Situ', 'Knowledge', 'Laplacian', 'Literature', 'Machine Learning', 'Macromolecular Complexes', 'Manuals', 'Methods', 'Mitochondria', 'Modeling', 'Molecular Conformation', 'Monitor', 'Neurophysiology - biologic function', 'Noise', 'Organelles', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Series', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tomogram', 'Weight', 'Work', 'autoencoder', 'automated algorithm', 'base', 'deep learning', 'design', 'falls', 'feature detection', 'graphical user interface', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'nano', 'nanometer resolution', 'novel', 'novel strategies', 'open source', 'particle', 'pi-Mesons', 'programs', 'reconstruction', 'success', 'user-friendly']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2020,342970,0.040834517863635025
"Incorporating molecular network knowledge into predictive data-driven models Modern computational techniques based on machine-learning (ML) and, more recently, deep-learning (DL) are playing a critical role in realizing the precision medicine initiative. However, there is a critical need to systematically combine these powerful data-driven techniques with prior molecular network knowledge to make more accurate predictive models while also satisfactorily explaining their predictions in terms of mechanisms underlying complex traits and diseases. I propose to use domain specific knowledge from biology and computing to tackle three outstanding problems: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? ​Network-constrained Deep Learning for Metadata Imputation: ​​Most multifactorial phenotypes are tissue dependent and manifest differently depending on age, sex, and ethnicity. However, a majority of publicly-available genomic data lack these labels. I will develop a network-guided approach to predict missing metadata of samples based on their expression profiles by designing novel data-driven models where the model architecture and/or structure of the input data are constrained by an underlying gene network. ​Network-guided Functional Analysis of Genomic Data: ​​High-throughput experiments often generate lists of genes of interest that are hard to interpret. Functional enrichment analysis (FEA) is a powerful tool that attaches functional meaning to an experimental set of genes by summarizing them into sets of pathways/processes. However, standard FEA analysis is limited by incomplete knowledge of gene function, lack of context of the underlying gene network, and noise in expression data. I will address these limitations by developing a network-guided approach that jointly captures genes, their interactions, and their known biological pathways/processes into a common, low-dimensional space that facilitates deriving biological meaning by comparing the distance between the experimental gene set and the pathway/process of interest. ​Joint Multi-Species Genomic Data Analysis and Knowledge Transfer: ​​In particular, finding the optimal model system to use in a follow-up study based on genetic signatures derived from human experiments is challenging because genetic networks can be quite different from species to species. I propose to use data-driven models to embed heterogeneous networks comprised of human genes and model species genes into a common, low-dimensional space to better compare genetic signatures between two (or even multiple) species. I will apply these methods to three specific tasks, but I emphasize that the results of this study will be transferable to any other biological problem where complex gene/protein interactions are a major component. I have surrounded myself with a great support team and developed a strong professional development plan. The freedom and support provided by the F32 fellowship will be instrumental in achieving my goal of becoming a professor with an independent research group. This proposal aims to develop novel computational approaches that systematically combine prior molecular network knowledge, powerful data-driven computational techniques, and large transcriptome data collections to answer three critical questions in biomedicine: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? The core goal of my fellowship is to achieve this by infusing prior-knowledge into state-of-the-art data-driven statistical/machine learning methods so that we can overcome two major hurdles in studying complex, multifactorial traits and diseases: a) complex genetic interactions underlie multi-factorial traits and diseases, and b) these traits and diseases often differ in how they manifest from patient to patient.",Incorporating molecular network knowledge into predictive data-driven models,10022122,F32GM134595,"['Accounting', 'Address', 'Age', 'Architecture', 'Back', 'Binding', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Cell physiology', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Collection', 'Development Plans', 'Dimensions', 'Disease', 'Engineering', 'Ethnic Origin', 'Expression Profiling', 'Fellowship', 'Follow-Up Studies', 'Freedom', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Human', 'Joints', 'Knowledge', 'Label', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Nature', 'Noise', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Process', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Source', 'Structure', 'Techniques', 'Tissues', 'Translating', 'base', 'data to knowledge', 'deep learning', 'design', 'disease phenotype', 'driving force', 'experimental study', 'functional genomics', 'gene function', 'genetic association', 'genetic signature', 'genomic data', 'genomic profiles', 'human data', 'interest', 'machine learning method', 'mathematical sciences', 'novel', 'predictive modeling', 'professor', 'sex', 'statistical and machine learning', 'tool', 'trait', 'transcriptome']",NIGMS,MICHIGAN STATE UNIVERSITY,F32,2020,67446,0.008607740632255828
"Incorporating molecular network knowledge into predictive data-driven models Modern computational techniques based on machine-learning (ML) and, more recently, deep-learning (DL) are playing a critical role in realizing the precision medicine initiative. However, there is a critical need to systematically combine these powerful data-driven techniques with prior molecular network knowledge to make more accurate predictive models while also satisfactorily explaining their predictions in terms of mechanisms underlying complex traits and diseases. I propose to use domain specific knowledge from biology and computing to tackle three outstanding problems: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? ​Network-constrained Deep Learning for Metadata Imputation: ​​Most multifactorial phenotypes are tissue dependent and manifest differently depending on age, sex, and ethnicity. However, a majority of publicly-available genomic data lack these labels. I will develop a network-guided approach to predict missing metadata of samples based on their expression profiles by designing novel data-driven models where the model architecture and/or structure of the input data are constrained by an underlying gene network. ​Network-guided Functional Analysis of Genomic Data: ​​High-throughput experiments often generate lists of genes of interest that are hard to interpret. Functional enrichment analysis (FEA) is a powerful tool that attaches functional meaning to an experimental set of genes by summarizing them into sets of pathways/processes. However, standard FEA analysis is limited by incomplete knowledge of gene function, lack of context of the underlying gene network, and noise in expression data. I will address these limitations by developing a network-guided approach that jointly captures genes, their interactions, and their known biological pathways/processes into a common, low-dimensional space that facilitates deriving biological meaning by comparing the distance between the experimental gene set and the pathway/process of interest. ​Joint Multi-Species Genomic Data Analysis and Knowledge Transfer: ​​In particular, finding the optimal model system to use in a follow-up study based on genetic signatures derived from human experiments is challenging because genetic networks can be quite different from species to species. I propose to use data-driven models to embed heterogeneous networks comprised of human genes and model species genes into a common, low-dimensional space to better compare genetic signatures between two (or even multiple) species. I will apply these methods to three specific tasks, but I emphasize that the results of this study will be transferable to any other biological problem where complex gene/protein interactions are a major component. I have surrounded myself with a great support team and developed a strong professional development plan. The freedom and support provided by the F32 fellowship will be instrumental in achieving my goal of becoming a professor with an independent research group. This proposal aims to develop novel computational approaches that systematically combine prior molecular network knowledge, powerful data-driven computational techniques, and large transcriptome data collections to answer three critical questions in biomedicine: 1) how to predict missing labels associated with millions of publicly available samples? 2) what molecular/cellular function can be attached to these samples and 3) how can we translate the findings from human data to a model species and back? The core goal of my fellowship is to achieve this by infusing prior-knowledge into state-of-the-art data-driven statistical/machine learning methods so that we can overcome two major hurdles in studying complex, multifactorial traits and diseases: a) complex genetic interactions underlie multi-factorial traits and diseases, and b) these traits and diseases often differ in how they manifest from patient to patient.",Incorporating molecular network knowledge into predictive data-driven models,9835005,F32GM134595,"['Accounting', 'Address', 'Age', 'Architecture', 'Back', 'Binding', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Cell physiology', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Collection', 'Development Plans', 'Dimensions', 'Disease', 'Engineering', 'Ethnic Origin', 'Expression Profiling', 'Fellowship', 'Follow-Up Studies', 'Freedom', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Human', 'Joints', 'Knowledge', 'Label', 'Machine Learning', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Nature', 'Noise', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Process', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Source', 'Structure', 'Techniques', 'Tissues', 'Translating', 'base', 'data to knowledge', 'deep learning', 'design', 'disease phenotype', 'driving force', 'experimental study', 'functional genomics', 'gene function', 'genetic association', 'genetic signature', 'genomic data', 'genomic profiles', 'human data', 'human model', 'interest', 'learning strategy', 'mathematical sciences', 'novel', 'predictive modeling', 'professor', 'sex', 'tool', 'trait', 'transcriptome']",NIGMS,MICHIGAN STATE UNIVERSITY,F32,2019,61610,0.008607740632255828
"Software for Antibody Epitope Prediction Accurate epitope prediction is important for the development of antibody-based therapies. When multiple new antibodies are discovered against the whole antigen, their epitopes and, therefore, potential novelty and mechanism of action are usually unknown Site-directed mutagenesis, the routine method for epitope mapping, requires testing a large number of mutants since any part of the antigen can potentially form an epitope The goal of this proposal is developing methodology and software for the accurate computational prediction of discontinuous B-cell epitopes based on the structure of an antigen and the structure or sequence of an antibody. Our starting point is PIPER, a protein-protein docking program licensed by Acpharis from Boston University. PIPER is the docking engine in the software packages BioLuminate by Schrodinger and the CyrusBench Suite of Cyrus Biotechnology, as well as in the public server ClusPro. PIPER has a special option for antibody-antigen docking, and has been used for epitope prediction. However, in its present form the software generally results in a high number of putative epitopes, and more accurate prediction requires substantial experimental efforts, e.g., by site-directed mutagenesis. We will modify PIPER to maximize the information available from the docking by generating a large ensemble of low energy docked structures and calculating a contact map rather than discrete docked structures. The number of potential epitopes will be further reduced by a template-based approach based on vector contact maps to characterize antibody-antigen interfaces. We also explore predicting the epitope based on models of the CDR regions. Generating large ensembles of docked structures with a large variety of CDR conformations will reduce the sensitivity of the method to inevitable modeling and docking uncertainty. By increasing the reliability of the predicted epitopes, we expect to reduce or even to eliminate the need for mutagenesis experiments. Finally, we will develop a machine- learning algorithm for the mapping of amino acid composition of CDR regions into epitope composition, a method that can be used when only the antibody sequence available and structure prediction is uncertain due to the lack of suitable templates. When multiple new antibodies are discovered against a whole antigen, their epitopes and, therefore, potential novelty and mechanism of action are usually unknown. Computational software tools can significantly reduce experimental efforts required for epitope determination by guiding experimental efforts toward most probable epitope locations. We propose new computational capabilities based on protein-protein docking and machine learning, which are specifically designed to improve the accuracy of epitope prediction.",Software for Antibody Epitope Prediction,9845171,R43GM134769,"['Address', 'Amino Acid Sequence', 'Amino Acids', 'Antibodies', 'Antibody Binding Sites', 'Antibody Therapy', 'Antigen-Antibody Complex', 'Antigens', 'B-Lymphocyte Epitopes', 'Base Sequence', 'Biotechnology', 'Boston', 'Collection', 'Computer software', 'Consensus', 'Crystallization', 'Data', 'Data Set', 'Databases', 'Development', 'Docking', 'Epitope Mapping', 'Epitopes', 'Goals', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Mutagenesis', 'Probability', 'Property', 'Proteins', 'Scheme', 'Site-Directed Mutagenesis', 'Software Tools', 'Specific qualifier value', 'Structure', 'Surface Antigens', 'Techniques', 'Testing', 'Training', 'Uncertainty', 'Universities', 'Vertebral column', 'artificial neural network', 'base', 'design', 'experimental study', 'improved', 'machine learning algorithm', 'mutant', 'programs', 'relating to nervous system', 'vector']",NIGMS,"ACPHARIS, INC.",R43,2019,149999,0.03781698995819182
"DNA repair, Cell cycle Checkpoints and Apoptosis and Bladder Cancer Risk My long-term goal is to become an independent molecular epidemiologist with in-depth training in genetics and advanced statistical methods in order to be able to analyzehigh throughput gene variant data to explore gene- gene and gene-environment interactions in cancer susceptibility. Mycareer development plan includedidatic courses/seminars, meetings with mentors in the areas of human genetics, cancer biology and advanced statistical methods. Myresearch proposal will focus on genetic susceptibility of blader cancer (BC). I propose to capitalize on availabilityof epidemiologicand genentic marker data from an on-going case-control study, ""Markers of GeneticSusceptibilityto Bladder Cancer""(R01 CA74880,PI:Xifeng. Wu). The parent study currently include over 2,500,mostly Caucasian,BCcases and controls, matched on sex, age and ethnicity. Mygoal is to identify novel loci that confer bladder cancer susceptibility using state-of-the-art genotyping techology and novel statistical and bioinformaticstools. The Specific Aims are: 1) To enhance my knowledge and skills in genetics and statistics to identify novel genetic loci as susceptibility markers of BC by extending the original45 potential functional SNPs to include additional 2112 tagging SNPs in genes in the DNArepair, cell cycle control and apoptotic pathways in 800 Caucasiancases and 800 Caucasiancontrols using the Illumina Golden Gate Assay; 2) To assess haplotypes and diplotypes as markers of susceptibility; 3) To use bioinformaticstools to assess functional significance of SNPs in the DNArepair, cell cycle control and apoptotic pathways and to correlate genotype data of DNArepair and cell cycle control with functional data derived from phenotypic assays. The secondary aim is to apply hierarchical models to refine risk assessment and to apply novel machine-learning tools to explore any gene-environment and gene-gene interactions influencing BCrisk. My project complements the parent grant in that it: 1) adds tagging SNPs to potential functional SNPs addressed in the parent grant; 2) adds haplotype analyses; 3) proposes novel statistical and bioinformaticsapproaches. RELEVANCE (See instructions): Bladder cancer is a tobacco-related cancer which is the fourth most common cancer in men in U.S. The fact that only a fraction of smokers develop bladder caricer indicating genetic susceptibility to the disease. This study will identify novel genetic markers may be useful as biomarkers to identify high-risk populationsthat could then be targeted for intervention programs. n/a","DNA repair, Cell cycle Checkpoints and Apoptosis and Bladder Cancer Risk",8268502,K07CA134831,"['Address', 'Age', 'Algorithms', 'Alleles', 'American', 'Apoptosis', 'Apoptotic', 'Area', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Markers', 'Bladder', 'Cancer Biology', 'Cancer Center', 'Carcinogen Metabolism', 'Carcinogens', 'Case Study', 'Case-Control Studies', 'Caucasians', 'Caucasoid Race', 'Cell Cycle Checkpoint', 'Cell Cycle Regulation', 'Cell physiology', 'Cells', 'Clinic', 'Clinical', 'Clinical Oncology', 'Complement', 'Complex', 'Correlation Studies', 'DNA', 'DNA Repair', 'Data', 'Development', 'Development Plans', 'Dietary Practices', 'Disease', 'Doctor of Medicine', 'Enrollment', 'Environment', 'Environmental Exposure', 'Environmental Risk Factor', 'Epidemiologist', 'Epidemiology', 'Erythrocytes', 'Ethnic Origin', 'Exposure to', 'Frequencies', 'Funding', 'Gender', 'Gene Order', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Polymorphism', 'Genetic Predisposition to Disease', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Haplotypes', 'Human Genetics', 'Individual', 'Instruction', 'Journal of the National Cancer Institute', 'Journals', 'Knowledge', 'Length', 'Lymphocyte', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of urinary bladder', 'Medical', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'Molecular Epidemiology', 'Mutagens', 'Newly Diagnosed', 'Nutritional', 'Occupational', 'Outcome', 'Paper', 'Parents', 'Pathway interactions', 'Penetrance', 'Phenotype', 'Physicians', 'Plasma', 'Predictive Value', 'Predisposition', 'Publishing', 'Recruitment Activity', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk Assessment', 'Sampling', 'Smoker', 'Specimen', 'Statistical Methods', 'Suspension substance', 'Suspensions', 'Tobacco', 'Tobacco smoke', 'Training', 'Variant', 'anticancer research', 'base', 'cancer risk', 'carcinogenesis', 'college', 'coping', 'gene environment interaction', 'gene interaction', 'high risk', 'intervention program', 'medical specialties', 'meetings', 'men', 'new technology', 'novel', 'parent grant', 'sex', 'skills', 'statistics', 'telomere', 'tool']",NCI,UNIVERSITY OF TX MD ANDERSON CAN CTR,K07,2012,137537,-0.04138372673225336
"Improved Informatics for Epitope Mapping by Hydrogen Exchange-Mass Spectrometry PROJECT SUMMARY Determination of the molecular structures of B cell epitopes recognized by protective antibodies provides essential insights to guide rational vaccine design. Obtaining atomically-resolved maps that comprehensively cover the surface of the antigen represents an ideal goal that would provide invaluable information to guide vaccine development. While X-ray crystallography can provide atomically-resolved maps of epitopes, at the present time, it does not have sufficient throughput for deep analysis of the diversity of the antibody repertoire. Hydrogen exchange-mass spectrometry (HX-MS) is emerging as an effective tool for epitope mapping. While promising, the method is limited both by data analysis bottlenecks and limited spatial resolution that prevent it from achieving its full potential for high resolution, high throughput epitope mapping. This collaborative research between Dr. David Weis and Dr. Jeffrey Gray brings together their complementary expertise in HX-MS and protein modelling to produce new software tools to improve the accuracy, resolution, and throughput of HX-MS-based epitope mapping. The outcome will enable epitope-mapping pipelines capable of generating 10-20 atomically-resolved epitopes per week, allowing researchers to more fully define the repertoire of antibody responses to infectious agents and toxins. This research is significant because it will yield new tools to accelerate the rational design and testing of much-needed vaccines to counteract emerging infectious diseases and biothreat agents within NIAID's portfolio. The specific aims of this proposal are to develop new algorithms and software for (1) rapid, fully-automated processing of HX-MS data, (2) fully-automated classification of HX-MS results, and (3) obtaining atomically- resolved epitopes from HX-MS data. The product of the proposed research will be new software tools that implement innovative algorithms. To accomplish Aim #1, algorithms that treat HX-MS data as two-dimensional images and adapt image comparison algorithms to identify and extract the shifted mass spectra will be developed. To accomplish Aim #2, significance testing based on the volcano plot method and classify the results using k-means clustering will be used. To accomplish Aim #3, medium-resolution HX-MS-mapped epitope will be used to constrain computational protein docking between the solved antigen structure and the modeled antibody using the Rosetta protein modeling suite. Through an existing collaboration with Dr. Nicholas Mantis sponsored by NIAID, the team has access to VHHs and an expanding library of solved structures of these VHHs bound to ricin toxin. The solved structures present a unique opportunity to independently refine and validate the epitope mapping pipeline based on solved structures. PROJECT NARRATIVE Vaccines stimulate the immune system to produce antibodies that recognize specific regions called epitopes on bacteria, viruses, and toxins. Information about the molecular structures of these epitopes can provide useful guidance to the development of new vaccines. The proposed research is relevant to public health because it is expected to contribute new tools to determine epitope structures more quickly.",Improved Informatics for Epitope Mapping by Hydrogen Exchange-Mass Spectrometry,9610636,R21AI135701,"['Algorithmic Software', 'Algorithms', 'Amino Acids', 'Antibodies', 'Antibody Diversity', 'Antibody Repertoire', 'Antibody Response', 'Antigens', 'Area', 'B-Lymphocyte Epitopes', 'Bacteria', 'Basic Science', 'Benchmarking', 'Binding', 'Chemistry', 'Classification', 'Collaborations', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic Reagent', 'Distal', 'Docking', 'Emerging Communicable Diseases', 'Engineering', 'Epitope Mapping', 'Epitopes', 'Glycoproteins', 'Goals', 'Human Resources', 'Hydrogen', 'Image', 'Immune system', 'Immunology', 'Individual', 'Infectious Agent', 'Informatics', 'Length', 'Letters', 'Libraries', 'Maps', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Structure', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Outcomes Research', 'Peptoids', 'Performance', 'Pharmacologic Substance', 'Proteins', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Ricin', 'Site', 'Software Tools', 'Structural Models', 'Structure', 'Surface Antigens', 'Testing', 'Therapeutic', 'Time', 'Toxin', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Virus', 'X-Ray Crystallography', 'analysis pipeline', 'antibody libraries', 'automated analysis', 'base', 'biothreat', 'computerized tools', 'computing resources', 'design', 'experimental study', 'improved', 'innovation', 'insight', 'novel vaccines', 'open source', 'prevent', 'structural biology', 'tool', 'two-dimensional', 'vaccine development', 'vaccine discovery', 'volcano']",NIAID,UNIVERSITY OF KANSAS LAWRENCE,R21,2019,192392,0.06934353634805208
"Improved Informatics for Epitope Mapping by Hydrogen Exchange-Mass Spectrometry PROJECT SUMMARY Determination of the molecular structures of B cell epitopes recognized by protective antibodies provides essential insights to guide rational vaccine design. Obtaining atomically-resolved maps that comprehensively cover the surface of the antigen represents an ideal goal that would provide invaluable information to guide vaccine development. While X-ray crystallography can provide atomically-resolved maps of epitopes, at the present time, it does not have sufficient throughput for deep analysis of the diversity of the antibody repertoire. Hydrogen exchange-mass spectrometry (HX-MS) is emerging as an effective tool for epitope mapping. While promising, the method is limited both by data analysis bottlenecks and limited spatial resolution that prevent it from achieving its full potential for high resolution, high throughput epitope mapping. This collaborative research between Dr. David Weis and Dr. Jeffrey Gray brings together their complementary expertise in HX-MS and protein modelling to produce new software tools to improve the accuracy, resolution, and throughput of HX-MS-based epitope mapping. The outcome will enable epitope-mapping pipelines capable of generating 10-20 atomically-resolved epitopes per week, allowing researchers to more fully define the repertoire of antibody responses to infectious agents and toxins. This research is significant because it will yield new tools to accelerate the rational design and testing of much-needed vaccines to counteract emerging infectious diseases and biothreat agents within NIAID's portfolio. The specific aims of this proposal are to develop new algorithms and software for (1) rapid, fully-automated processing of HX-MS data, (2) fully-automated classification of HX-MS results, and (3) obtaining atomically- resolved epitopes from HX-MS data. The product of the proposed research will be new software tools that implement innovative algorithms. To accomplish Aim #1, algorithms that treat HX-MS data as two-dimensional images and adapt image comparison algorithms to identify and extract the shifted mass spectra will be developed. To accomplish Aim #2, significance testing based on the volcano plot method and classify the results using k-means clustering will be used. To accomplish Aim #3, medium-resolution HX-MS-mapped epitope will be used to constrain computational protein docking between the solved antigen structure and the modeled antibody using the Rosetta protein modeling suite. Through an existing collaboration with Dr. Nicholas Mantis sponsored by NIAID, the team has access to VHHs and an expanding library of solved structures of these VHHs bound to ricin toxin. The solved structures present a unique opportunity to independently refine and validate the epitope mapping pipeline based on solved structures. PROJECT NARRATIVE Vaccines stimulate the immune system to produce antibodies that recognize specific regions called epitopes on bacteria, viruses, and toxins. Information about the molecular structures of these epitopes can provide useful guidance to the development of new vaccines. The proposed research is relevant to public health because it is expected to contribute new tools to determine epitope structures more quickly.",Improved Informatics for Epitope Mapping by Hydrogen Exchange-Mass Spectrometry,9435525,R21AI135701,"['Algorithmic Software', 'Algorithms', 'Amino Acids', 'Antibodies', 'Antibody Diversity', 'Antibody Repertoire', 'Antibody Response', 'Antigens', 'Area', 'B-Lymphocyte Epitopes', 'Bacteria', 'Basic Science', 'Benchmarking', 'Binding', 'Chemistry', 'Classification', 'Collaborations', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic Reagent', 'Distal', 'Docking', 'Emerging Communicable Diseases', 'Engineering', 'Epitope Mapping', 'Epitopes', 'Glycoproteins', 'Goals', 'Gray unit of radiation dose', 'Human Resources', 'Hydrogen', 'Image', 'Immune system', 'Immunology', 'Individual', 'Infectious Agent', 'Informatics', 'Length', 'Letters', 'Libraries', 'Maps', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Structure', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Outcomes Research', 'Peptoids', 'Performance', 'Pharmacologic Substance', 'Proteins', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Ricin', 'Site', 'Software Tools', 'Structure', 'Surface Antigens', 'Testing', 'Therapeutic', 'Time', 'Toxin', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Virus', 'X-Ray Crystallography', 'antibody libraries', 'base', 'biothreat', 'computerized tools', 'computing resources', 'design', 'experimental study', 'improved', 'innovation', 'insight', 'novel vaccines', 'open source', 'prevent', 'structural biology', 'tool', 'two-dimensional', 'vaccine development', 'vaccine discovery', 'volcano']",NIAID,UNIVERSITY OF KANSAS LAWRENCE,R21,2018,243366,0.06934353634805208
"3-D Imaging Flow Cytometry PROJECT SUMMARY This project aims to develop and test two innovative platforms and related software for 3-D imaging flow cytometry of fluorescent or absorbing (stained) samples. These systems will allow 3-D structural and functional imaging of many single cells at a subcellular resolution and at a scale that used to be available only in flow cytometry or recently in 2-D imaging. Thereby, the proposed methods have the potential to fundamentally change the ways cultured cells, patient-derived samples, and small experimental organisms are studied. Automated classification based on the 3-D features will enable the diagnosis of hematologic disorders at single-cell precision. Existing 3-D microscopy methods can provide the same information at higher resolution; however, by relying on a scanning mechanism they cannot be applied to suspending cells, especially in a flow configuration, which is essential for high-speed interrogation. Snapshot 3-D microscopy techniques have been developed to address this challenge, but they have insufficient spatial resolution for single-cell imaging and suffer from long data processing time. We overcome these limitations by combining two novel snapshot techniques developed by the PI with the most rigorous optical imaging theories and cutting-edge component technologies. We will use an array of lenslets, which simultaneously records many projection images corresponding with different viewing angles. The use of pupil phase masks, designed using wavefront coding and a theory of 3-D high-numerical-aperture optical imaging, will increase the resolution of each projection image to the theoretical limit given by the objective-lens numerical aperture. The target resolution is 0.5 µm, which is comparable to existing 2-D imaging flow cytometry systems. The target imaging throughputs based on current component technologies are 120 volumes/sec for fluorescence imaging and 700 volumes/sec for absorption imaging, which are higher than 100 volumes/sec of cutting-edge 3-D optical microscopy for stationary specimens. The vast amount of data acquired by these 3-D imaging systems imposes a serious challenge to data processing. The developed systems record true projection images, which obviate iterative deconvolution process, thereby allowing much faster tomographic reconstruction than in existing snapshot techniques. Using general-purpose graphics processing units and optical diffraction tomography, which includes the diffraction of light by subcellular organelles, our tomographic reconstruction algorithm will be faster yet more accurate than existing approaches. Further, we will explore the feasibility of applying a deep convolutional neural network to the images acquired by the developed systems for accurate single-cell classification based on 3-D features. PROJECT NARRATIVE This project aims to develop 3-D imaging flow cytometry platforms for fluorescent or absorbing (stained) cells at high resolution and high throughput in a flow configuration. The developed systems will be built upon two novel snapshot 3-D techniques developed by the PI in combination with most rigorous 3-D optical imaging theories and cutting-edge component technologies. The proposed methods have the potential to fundamentally change the ways that biological specimens are examined by allowing 3-D structural and functional imaging of suspending cells at a scale that used to be available only in flow cytometry or 2-D imaging.",3-D Imaging Flow Cytometry,10023268,R21GM135848,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Biological', 'Blood', 'Blood specimen', 'Cells', 'Classification', 'Code', 'Computer software', 'Cultured Cells', 'Data', 'Diagnosis', 'Dimensions', 'Flow Cytometry', 'Functional Imaging', 'Geometry', 'Hematological Disease', 'Holography', 'Image', 'Laboratory Organism', 'Leukocytes', 'Lifting', 'Lighting', 'Masks', 'Methods', 'Microscope', 'Microscopy', 'Optical Tomography', 'Optics', 'Organelles', 'Patients', 'Phase', 'Process', 'Pupil', 'Records', 'Resolution', 'Sampling', 'Scanning', 'Specimen', 'Speed', 'Stains', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Work', 'absorption', 'base', 'cellular imaging', 'commercialization', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'diffraction of light', 'digital', 'feature extraction', 'fluorescence imaging', 'imaging system', 'innovation', 'lens', 'novel', 'optical imaging', 'reconstruction', 'software development', 'targeted imaging', 'theories', 'three dimensional structure', 'tomography']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2020,155784,0.029697093517025888
"3-D Imaging Flow Cytometry PROJECT SUMMARY This project aims to develop and test two innovative platforms and related software for 3-D imaging flow cytometry of fluorescent or absorbing (stained) samples. These systems will allow 3-D structural and functional imaging of many single cells at a subcellular resolution and at a scale that used to be available only in flow cytometry or recently in 2-D imaging. Thereby, the proposed methods have the potential to fundamentally change the ways cultured cells, patient-derived samples, and small experimental organisms are studied. Automated classification based on the 3-D features will enable the diagnosis of hematologic disorders at single-cell precision. Existing 3-D microscopy methods can provide the same information at higher resolution; however, by relying on a scanning mechanism they cannot be applied to suspending cells, especially in a flow configuration, which is essential for high-speed interrogation. Snapshot 3-D microscopy techniques have been developed to address this challenge, but they have insufficient spatial resolution for single-cell imaging and suffer from long data processing time. We overcome these limitations by combining two novel snapshot techniques developed by the PI with the most rigorous optical imaging theories and cutting-edge component technologies. We will use an array of lenslets, which simultaneously records many projection images corresponding with different viewing angles. The use of pupil phase masks, designed using wavefront coding and a theory of 3-D high-numerical-aperture optical imaging, will increase the resolution of each projection image to the theoretical limit given by the objective-lens numerical aperture. The target resolution is 0.5 µm, which is comparable to existing 2-D imaging flow cytometry systems. The target imaging throughputs based on current component technologies are 120 volumes/sec for fluorescence imaging and 700 volumes/sec for absorption imaging, which are higher than 100 volumes/sec of cutting-edge 3-D optical microscopy for stationary specimens. The vast amount of data acquired by these 3-D imaging systems imposes a serious challenge to data processing. The developed systems record true projection images, which obviate iterative deconvolution process, thereby allowing much faster tomographic reconstruction than in existing snapshot techniques. Using general-purpose graphics processing units and optical diffraction tomography, which includes the diffraction of light by subcellular organelles, our tomographic reconstruction algorithm will be faster yet more accurate than existing approaches. Further, we will explore the feasibility of applying a deep convolutional neural network to the images acquired by the developed systems for accurate single-cell classification based on 3-D features. PROJECT NARRATIVE This project aims to develop 3-D imaging flow cytometry platforms for fluorescent or absorbing (stained) cells at high resolution and high throughput in a flow configuration. The developed systems will be built upon two novel snapshot 3-D techniques developed by the PI in combination with most rigorous 3-D optical imaging theories and cutting-edge component technologies. The proposed methods have the potential to fundamentally change the ways that biological specimens are examined by allowing 3-D structural and functional imaging of suspending cells at a scale that used to be available only in flow cytometry or 2-D imaging.",3-D Imaging Flow Cytometry,9877321,R21GM135848,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Biological', 'Blood', 'Blood specimen', 'Cells', 'Classification', 'Code', 'Computer software', 'Cultured Cells', 'Data', 'Diagnosis', 'Dimensions', 'Flow Cytometry', 'Functional Imaging', 'Geometry', 'Hematological Disease', 'Holography', 'Image', 'Laboratory Organism', 'Leukocytes', 'Lifting', 'Lighting', 'Masks', 'Methods', 'Microscope', 'Microscopy', 'Optical Tomography', 'Optics', 'Organelles', 'Patients', 'Phase', 'Process', 'Pupil', 'Records', 'Resolution', 'Sampling', 'Scanning', 'Specimen', 'Speed', 'Stains', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Work', 'absorption', 'base', 'cellular imaging', 'commercialization', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'diffraction of light', 'digital', 'fluorescence imaging', 'imaging system', 'innovation', 'lens', 'novel', 'optical imaging', 'reconstruction', 'software development', 'targeted imaging', 'theories', 'three dimensional structure', 'tomography']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2019,195110,0.029697093517025888
"AI platform for microscopy image restoration and virtual staining AI Platform for Microscopy Image Restoration and Virtual Staining Project Summary:  Fluorescence microscopy has enabled many major discoveries in biomedical sciences. Despite the rapid advancements in optics, lasers, probes, cameras and novel techniques, major factors such as spatial and temporal resolution, light exposure, signal-to-noise, depth of penetration and probe spectra continue to limit the types of experiments that are possible. Deep learning (DL) algorithms are well suited for image-based problems like SNR/super-resolution restoration and virtual staining, which have great enabling potentials for microscopy experiments. Previously impossible experiments could be realized such as achieving high signal-to-noise and/or spatial-temporal resolution without photobleaching/phototoxicity; simultaneously observing many image channels without interfering with native processes, etc. This could pave the way for a quantum leap forward in microscopy-based discoveries that elucidate biological functions and the mechanisms of disorders, and enable new diagnostics and therapies for human diseases.  However, these new methods have not been widely translated to new microscopy experiments. The delay is due to several practical hurdles and challenges such as required expertise, computing and trust. In order to accelerate the adoption of DL in microscopy, novel AI platform tailored for biologists are needed for training, applying and validating DL models and outputs.  The present project aims to develop an AI platform for microscopy image restoration and virtual staining called AI for Restoring and Staining (AIRS) platform. With our collaborator, Dr. Hari Shroff (National Institute of Biomedical Imaging and Bioengineering) we have successfully created DL models for SNR restoration, super-resolution restoration and virtual staining for a variety of imaging conditions and organelles in our preliminary studies. The AIRS platform intends to (1)provide a comprehensive suite of validated DL models for microscopy restoration and virtual staining applications including SNR restoration, super-resolution restoration, spatial deconvolution, spectral unmixing, prediction of 3d from 2d images, organelle virtual staining and analysis; (2)provide plug and play for common microscopy experiments; (3)provide semi-automatic update training to tailor DL models to match advanced microscopy experiments; (4)provide user friendly support for new DL model training for pioneering microscopy experiments; (5)provide confidence scores to assess the output results by a DL model, (6) provide DL models that avoid image artifact (hallucination) and allow continuous learning and evolution; (7) and be able to access the required computing infrastructure and database connection. Project Narrative Deep learning (DL) algorithms have great enabling potentials for microscopy experiments. Previously impossible experiments could now be realized. This could pave the way for a quantum leap forward in microscopy-based discoveries.  Powered by deep learning and DRVision innovations and collaborating with Dr. Hari Shroff and 7 additional labs, this project aims to create an AI platform for microscopy image restorations and virtual staining called AI for restoring and staining (AIRS). The tool will be integrated with DRVision’s flagship product Aivia for commercialization to accelerate the adoption of DL in microscopy.",AI platform for microscopy image restoration and virtual staining,9909318,U44GM136091,"['3-Dimensional', 'Active Learning', 'Adoption', 'Artificial Intelligence', 'Biological Process', 'Data', 'Databases', 'Disease', 'Evaluation', 'Evolution', 'Feedback', 'Fluorescence Microscopy', 'Government', 'Hallucinations', 'Image', 'Infrastructure', 'Lasers', 'Libraries', 'Light', 'Manuals', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'National Institute of Biomedical Imaging and Bioengineering', 'Noise', 'Optics', 'Organelles', 'Output', 'Penetration', 'Performance', 'Persons', 'Phase', 'Photobleaching', 'Phototoxicity', 'Play', 'Process', 'Resolution', 'Science', 'Signal Transduction', 'Stains', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Translating', 'Trust', 'Update', 'Validation', 'base', 'commercialization', 'deep learning', 'deep learning algorithm', 'experience', 'experimental study', 'human disease', 'improved', 'innovation', 'learning progression', 'microscopic imaging', 'novel', 'novel diagnostics', 'novel therapeutics', 'prototype', 'quantum', 'restoration', 'temporal measurement', 'tool', 'usability', 'user-friendly', 'virtual']",NIGMS,"DRVISION TECHNOLOGIES, LLC",U44,2020,172359,0.006585586340711744
"Computational Methods for Next-Generation GWAS Project Summary/Abstract  Predicting phenotypes from DNA sequence variation is a major goal for genetics with potential applications in evolutionary biology, crop breeding, and public health. A central challenge in this task is separating genetic and environmental effects on phenotypes. In natural populations breeding structure is often correlated with the environment across space such that different subpopulations experience different environments. For genome-wide association studies (GWAS) this creates a problem: genetic and environmental effects can be confounded by population structure, leading to inflated test statistics and low predictive power across populations (Bulik-Sullivan et al. 2015, Mathieson and Mcvean, 2012). Understanding when association studies are biased by population stratification and creating better methods to correct for it are thus important challenges for population genetics over the next decade.  To identify conditions under which existing methods of population stratification correction are subject to bias and develop robust new alternatives suitable for use with the continental-scale genomic datasets that are now routinely available for humans, we propose to use simulations and machine learning to separate the signals of fine-scale ancestry from polygenic phenotype association. In our first aim we will develop simulations of polygenic phenotype evolution in continuous space and use the output to evaluate existing methods of stratification control including linear mixed models, PC correction, and LD score regression. In this aim we will seek to identify the regions of parameter space – i.e. the strength of isolation by distance and the spatial distribution of environmental variation – in which existing methods can be expected to produce reliable effect size estimates, and establish guidelines for applications of GWAS to structured populations.  We will then train machine learning algorithms on real genotype data from humans and mosquitoes to describe continuous structure in large spatial samples using a variational autoencoder, a dimensionality reduction technique based on deep neural networks that can take advantage of both allele frequency and haplotype-based measures of differentiation in a single analysis and thus offer improved control of stratification inflation in GWAS relative to the now standard PCA regression approach. Last we will apply deep learning techniques to the problem of linking phenotypes and genotypes in structured samples by training neural networks on simulated phenotypes and empirical genetic data. By training our networks on empirical genetic data and incorporating contextual information about surrounding haplotype structure into the model, our networks should learn to discriminate causal associations from false positives created by population structure in the sample cohort, which will improve performance when attempting to identify associations with the real phenotype. These methods will be applied to existing genomic datasets of height in humans, tested against the current state-of-the-art approaches, and packaged as scalable software for the broader scientific community. Project Narrative Separating the signals of polygenic trait association and population structure has emerged as a major challenge for the interpretation of genome-wide association studies (GWAS). We propose to develop new simulations of populations evolving in continuous space that will allow us to rigorously benchmark existing methods of stratification control in GWAS while fully controlling the underlying demographic and selective process. We will then apply deep learning techniques to develop (1) a new method of dimensionality reduction to test as a covariate for ancestry in GWAS, and (2) a neural network that identifies genotype-phenotype connections while controlling for population structure in the sample cohort.",Computational Methods for Next-Generation GWAS,9910009,F32GM136123,"['Agriculture', 'Benchmarking', 'Biology', 'Breeding', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Culicidae', 'DNA Sequence', 'Data', 'Dimensions', 'Environment', 'Evolution', 'Gene Frequency', 'Genetic', 'Genotype', 'Geographic Locations', 'Goals', 'Guidelines', 'Haplotypes', 'Health', 'Heart Diseases', 'Height', 'Human', 'Image', 'Learning', 'Linear Models', 'Linear Regressions', 'Link', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oligogenic Traits', 'Output', 'Performance', 'Phenotype', 'Polygenic Traits', 'Population', 'Population Genetics', 'Population Heterogeneity', 'Positioning Attribute', 'Process', 'Public Health', 'Running', 'Sampling', 'Signal Transduction', 'Spatial Distribution', 'Stratification', 'Structure', 'Sum', 'Techniques', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'Variant', 'autoencoder', 'base', 'biobank', 'cohort', 'deep learning', 'deep neural network', 'diverse data', 'experience', 'genome wide association study', 'genome-wide', 'genomic data', 'human data', 'image reconstruction', 'improved', 'large scale simulation', 'learning strategy', 'machine learning algorithm', 'neural network', 'next generation', 'polygenic risk score', 'population stratification', 'simulation', 'statistics', 'supervised learning', 'tool', 'trait']",NIGMS,UNIVERSITY OF OREGON,F32,2020,19290,-0.009531947380153668
"Selective Whole Genome Amplification - Enabling Microbial Population Genomics Microbial population genetic research has been crucial for understanding pathogen dynamics, virulence, host specificity, and many other topics; in many cases uncovering unexpected and transformative biological processes. However, conventional population genetic analyses are limited by the quantity of sequence data from each sample. The temporal, spatial, and evolutionary resolution of techniques that rely on single gene sequences or multi-locus sequence typing are often insufficient to study biological processes on fine scales, precisely the scales at which many evolutionary and mechanistic process occur. Population genomics offers a vast quantity of sequence information for inferring evolutionary and ecological processes on very fine spatial and temporal scales, inferences that are critical to understanding and eventually controlling many infectious diseases. The promise of population genomics is tempered, however, by difficulties in isolating and preparing microbes for next-generation sequencing. We have developed the selective whole genome amplification (SWGA) technology to sequence microbial genomes from complex biological specimens without relying on labor-intensive laboratory culture, even if the focal microbial genome constitutes only a miniscule fraction of the natural sample. The primary hindrance to popular adoption of SWGA for microbial genomic studies is not its effectiveness in producing samples suitable for next-generation sequencing but in the upfront investment needed to develop an effective protocol to amplify the genome of a specific microbial species. Identifying an SWGA protocol that consistently results in selective and even amplification across the target genome is currently hindered by computationally-inefficient software that can evaluate a very limited set of the potentially effective solutions. Further, this software uses marginally-effective optimality criteria as there is currently only a limited understanding of the true criteria that result in highly-selective and even amplification of a target genome. As a result, SWGA protocol development is currently costly in both time and resources. A primary goal of the proposed research is to identify the criteria that result in optimal SWGA by analyzing next- generation sequencing data with advanced machine learning techniques. These optimality criteria will be integrated into a freely-available, computationally-efficient swga development program that will reduce the upfront investment in SWGA protocol development, thus allowing researchers to address medically- and biologically-important questions in any microbial species. In the near term, this project will also generate effective SWGA protocols for four microbial species which can be used immediately to address fundamental questions in evolutionary biology, disease progression, and emerging infectious disease dynamics. From a global disease perspective, this work is imperative as the majority of microbial species cannot easily be cultured and are in danger of becoming bystanders in the genomics revolution that is currently elucidating evolutionary processes and molecular mechanisms in cultivable microbial species. Addressing many of the major outstanding questions about pathogen evolution will require analyses of populations of microbial genomes. Although population genomic studies would provide the analytical resolution to investigate evolutionary and mechanistic processes on fine spatial and temporal scales – precisely the scales at which these processes occur – microbial population genomic research is currently hindered by the practicalities of obtaining sufficient quantities of genomes to analyze. We propose to develop an innovative, cost-effective, practical, and publically-available technology to collect sufficient quantities of microbial genomic DNA necessary for next-generation microbial genome sequencing.",Selective Whole Genome Amplification - Enabling Microbial Population Genomics,9507167,R21AI137433,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Biological', 'Biological Process', 'Biology', 'Characteristics', 'Communicable Diseases', 'Complex', 'Computer software', 'Coupling', 'DNA', 'Data', 'Development', 'Disease', 'Disease Progression', 'Effectiveness', 'Emerging Communicable Diseases', 'Evolution', 'Foundations', 'Genes', 'Genetic Research', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Health', 'Human', 'Investigation', 'Investments', 'Laboratory culture', 'Machine Learning', 'Medical', 'Metaphor', 'Methods', 'Microbe', 'Microbial Genome Sequencing', 'Microsatellite Repeats', 'Molecular', 'Organism', 'Population', 'Population Analysis', 'Population Genetics', 'Process', 'Program Development', 'Protocols documentation', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Shapes', 'Specificity', 'Specimen', 'System', 'Techniques', 'Technology', 'Time', 'Virulence', 'Work', 'cost', 'cost effective', 'design', 'genetic analysis', 'genetic approach', 'host-microbe interactions', 'improved', 'innovation', 'microbial', 'microbial genome', 'next generation', 'next generation sequencing', 'novel', 'pathogen', 'prevent', 'protocol development', 'vector', 'whole genome']",NIAID,UNIVERSITY OF PENNSYLVANIA,R21,2018,242837,0.007532772788093819
"Selective Whole Genome Amplification - Enabling Microbial Population Genomics Microbial population genetic research has been crucial for understanding pathogen dynamics, virulence, host specificity, and many other topics; in many cases uncovering unexpected and transformative biological processes. However, conventional population genetic analyses are limited by the quantity of sequence data from each sample. The temporal, spatial, and evolutionary resolution of techniques that rely on single gene sequences or multi-locus sequence typing are often insufficient to study biological processes on fine scales, precisely the scales at which many evolutionary and mechanistic process occur. Population genomics offers a vast quantity of sequence information for inferring evolutionary and ecological processes on very fine spatial and temporal scales, inferences that are critical to understanding and eventually controlling many infectious diseases. The promise of population genomics is tempered, however, by difficulties in isolating and preparing microbes for next-generation sequencing. We have developed the selective whole genome amplification (SWGA) technology to sequence microbial genomes from complex biological specimens without relying on labor-intensive laboratory culture, even if the focal microbial genome constitutes only a miniscule fraction of the natural sample. The primary hindrance to popular adoption of SWGA for microbial genomic studies is not its effectiveness in producing samples suitable for next-generation sequencing but in the upfront investment needed to develop an effective protocol to amplify the genome of a specific microbial species. Identifying an SWGA protocol that consistently results in selective and even amplification across the target genome is currently hindered by computationally-inefficient software that can evaluate a very limited set of the potentially effective solutions. Further, this software uses marginally-effective optimality criteria as there is currently only a limited understanding of the true criteria that result in highly-selective and even amplification of a target genome. As a result, SWGA protocol development is currently costly in both time and resources. A primary goal of the proposed research is to identify the criteria that result in optimal SWGA by analyzing next- generation sequencing data with advanced machine learning techniques. These optimality criteria will be integrated into a freely-available, computationally-efficient swga development program that will reduce the upfront investment in SWGA protocol development, thus allowing researchers to address medically- and biologically-important questions in any microbial species. In the near term, this project will also generate effective SWGA protocols for four microbial species which can be used immediately to address fundamental questions in evolutionary biology, disease progression, and emerging infectious disease dynamics. From a global disease perspective, this work is imperative as the majority of microbial species cannot easily be cultured and are in danger of becoming bystanders in the genomics revolution that is currently elucidating evolutionary processes and molecular mechanisms in cultivable microbial species. Addressing many of the major outstanding questions about pathogen evolution will require analyses of populations of microbial genomes. Although population genomic studies would provide the analytical resolution to investigate evolutionary and mechanistic processes on fine spatial and temporal scales – precisely the scales at which these processes occur – microbial population genomic research is currently hindered by the practicalities of obtaining sufficient quantities of genomes to analyze. We propose to develop an innovative, cost-effective, practical, and publically-available technology to collect sufficient quantities of microbial genomic DNA necessary for next-generation microbial genome sequencing.",Selective Whole Genome Amplification - Enabling Microbial Population Genomics,9699440,R21AI137433,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Biological', 'Biological Process', 'Biology', 'Characteristics', 'Communicable Diseases', 'Complex', 'Computer software', 'Coupling', 'DNA', 'Data', 'Development', 'Disease', 'Disease Progression', 'Effectiveness', 'Emerging Communicable Diseases', 'Evolution', 'Foundations', 'Genes', 'Genetic Research', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Health', 'Human', 'Investigation', 'Investments', 'Laboratory culture', 'Machine Learning', 'Medical', 'Metaphor', 'Methods', 'Microbe', 'Microbial Genome Sequencing', 'Microsatellite Repeats', 'Molecular', 'Organism', 'Population', 'Population Analysis', 'Population Genetics', 'Process', 'Program Development', 'Protocols documentation', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Shapes', 'Specificity', 'Specimen', 'System', 'Techniques', 'Technology', 'Time', 'Virulence', 'Work', 'cost', 'cost effective', 'design', 'genetic analysis', 'genetic approach', 'host-microbe interactions', 'improved', 'innovation', 'machine learning algorithm', 'microbial', 'microbial genome', 'next generation', 'next generation sequencing', 'novel', 'pathogen', 'prevent', 'protocol development', 'vector', 'whole genome']",NIAID,UNIVERSITY OF PENNSYLVANIA,R21,2019,186101,0.007532772788093819
"Super-multiplexed fluorescence nanoscopy for imaging-based proteomics PROJECT SUMMARY In situ immunofluorescence imaging is a powerful method to study the locations, expression levels and structures of proteins in cells and tissues. In particular, multiplexed imaging reveals the interaction networks of proteins, which allows us to understand the underlying mechanisms of many diseases. However, it has been challenging to perform multiplexed immunofluorescence imaging due to its extremely time-consuming process, high cost and lack of signal amplification. The limited spatial resolution achievable with confocal microscopy often fails to reveal complex spatial organization and to determine localizations of proteins. Here we propose super-multiplexed immunofluorescence nanoscopy that is capable of imaging more than twenty different proteins in 24 hours with nanoscale resolution. We will employ DNA-barcoded secondary nanobodies that are monovalent, open-source and designed for quantitative labeling. Repeated introduction and washing of fluorescent DNA imagers will generate highly multiplexed images. Moreover, we will develop unprecedentedly fast stimulated emission depletion (STED) microscopy that employs a parallelized line array of doughnut beams. It will feature a large imaging area and excellent optical sectioning capability. Photon reassignment, hyperspectral imaging and deep-learning will further facilitate rapid super-resolution-based protein profiling. Our new biochemical and optical tools will play crucial roles in diverse biomedical areas including brain proteomics and cancer profiling. PROJECT NARRATIVE We propose to develop highly multiplexed immunofluorescence super-resolution imaging tools. Our approach is fast, low cost and readily accessible, which will facilitate nanoscale imaging-based proteomics in cells and tissues.",Super-multiplexed fluorescence nanoscopy for imaging-based proteomics,10028050,R35GM138039,"['Area', 'Bar Codes', 'Biochemical', 'Brain', 'Cells', 'Complex', 'Confocal Microscopy', 'Consumption', 'DNA', 'Disease', 'Fluorescence', 'Hour', 'Image', 'Imaging Device', 'Immunofluorescence Immunologic', 'In Situ', 'Label', 'Location', 'Malignant Neoplasms', 'Methods', 'Microscopy', 'Nanoscopy', 'Optics', 'Photons', 'Play', 'Process', 'Proteins', 'Proteomics', 'Resolution', 'Role', 'Signal Transduction', 'Structural Protein', 'Time', 'Tissues', 'base', 'cost', 'deep learning', 'design', 'imager', 'multiplexed imaging', 'nanobodies', 'nanoscale', 'open source', 'protein profiling', 'tool']",NIGMS,UNIVERSITY OF CENTRAL FLORIDA,R35,2020,267626,0.03605888153249348
"Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry PROJECT SUMMARY  Cellular interactions with the environment form the basis of health and disease for all organisms. Exposure to nutrients, toxins, and neighboring cells trigger coordinated molecular responses that impact cell function and metabolism in a beneficial, adaptive, or detrimental manner. Although the benefits of multicellularity for the formation of complex tissue structures or the function of entire organ systems has been long appreciated, it has only recently been understood that microbial inhabitants of vertebrates also have a tremendous impact on host cell function and dysfunction. Despite this, an understanding of these interactions has not moved beyond simple associations, and there are virtually no molecular technologies available that adequately define how a complex microbial ecosystem impacts host cell function, or how the host response to microbial colonization affects the bacterial community. This gap in knowledge is striking when one considers the broad and significant impact that microbes have on human health. In this application, we propose to expressly fill this knowledge gap through development of a novel multimodal imaging pipeline that will provide 3-dimensional information on the molecular heterogeneity of microbial communities and the immune response at the host-pathogen interface.  This proposal combines our expertise in immunology, infection biology, mass spectrometry, small animal imaging, machine learning, and computer vision to develop an integrated multimodal visualization method for studying infectious disease. Our unique approach will computationally combine ultra-high speed (~50px/s) MALDI-TOF images, ultra-high mass resolution (>200,000 resolving power) MALDI FTICR IMS, metal imaging by LA-ICP-IMS, high-spatial resolution optical microscopy, and MR imaging using data-driven image fusion. This strategy will enable 3-D molecular images to be generated for thousands of elements, metabolites, lipids, and proteins with an unprecedented combination of chemical specificity and spatial fidelity more than 50x faster than is currently possible. We will use this next-generation imaging capability to (i) define the heterogeneous microbial subpopulations throughout the 3-D volume of a S. aureus community, (ii) uncover the host molecules that form the abscess and accumulate to restrict microbial growth in murine models, and (iii) elucidate molecular markers that differentiate in vivo biofilms at the host-pathogen interface, between abscesses at various stages of progression, and under distinct degrees of nutrient stress. These studies will uncover new targets for therapeutic intervention and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research. PROJECT NARRATIVE This proposal will enable detailed views of the molecular components of infectious disease with unprecedented resolution through the development of a multimodal, 3-dimensional imaging platform. The proposed technologies will improve throughput and molecular specificity, enable automated high-precision and high-accuracy image alignment, and allow for descriptions of molecular signals in 3-D through the fusion of multi-modal imaging data. These studies will uncover targets for therapeutic intervention and antibiotic development and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research.",Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry,9659850,R01AI138581,"['3-Dimensional', 'Abscess', 'Affect', 'Animal Model', 'Animals', 'Anterior nares', 'Antibiotics', 'Antibodies', 'Architecture', 'Awareness', 'Bacteria', 'Bacterial Infections', 'Bacterial Proteins', 'Behavior', 'Biology', 'Biomedical Research', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Cellular Metabolic Process', 'Chemicals', 'Communicable Diseases', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Custom', 'Data', 'Development', 'Diagnosis', 'Differentiation Antigens', 'Dimensions', 'Disease', 'Ecosystem', 'Elements', 'Environment', 'Exposure to', 'Fourier transform ion cyclotron resonance', 'Functional disorder', 'Glean', 'Growth', 'Health', 'Health Promotion', 'Heterogeneity', 'Histology', 'Human', 'Image', 'Imagery', 'Imaging technology', 'Immune', 'Immune response', 'Immunology', 'Imprisonment', 'Individual', 'Infection', 'Infectious Diseases Research', 'Integration Host Factors', 'Knowledge', 'Label', 'Lesion', 'Lipids', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mass Spectrum Analysis', 'Metals', 'Methodology', 'Methods', 'Microbe', 'Microbial Biofilms', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nutrient', 'Optics', 'Organism', 'Pathogenesis', 'Physiological', 'Population', 'Process', 'Proteins', 'Reagent', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Specificity', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Staphylococcus aureus', 'Stress', 'Structure', 'Supervision', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissues', 'Toxin', 'Vertebrates', 'Work', 'animal imaging', 'bacterial community', 'base', 'body system', 'commensal bacteria', 'experimental study', 'host colonization', 'imaging capabilities', 'imaging detection', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'innovation', 'interest', 'microbial', 'microbial colonization', 'microbial community', 'microscopic imaging', 'molecular imaging', 'molecular marker', 'mouse model', 'multimodality', 'neutrophil', 'new therapeutic target', 'next generation', 'novel', 'pathogen', 'protein expression', 'response', 'targeted treatment', 'virtual']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,593526,-0.019408628987103722
"Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry PROJECT SUMMARY  Cellular interactions with the environment form the basis of health and disease for all organisms. Exposure to nutrients, toxins, and neighboring cells trigger coordinated molecular responses that impact cell function and metabolism in a beneficial, adaptive, or detrimental manner. Although the benefits of multicellularity for the formation of complex tissue structures or the function of entire organ systems has been long appreciated, it has only recently been understood that microbial inhabitants of vertebrates also have a tremendous impact on host cell function and dysfunction. Despite this, an understanding of these interactions has not moved beyond simple associations, and there are virtually no molecular technologies available that adequately define how a complex microbial ecosystem impacts host cell function, or how the host response to microbial colonization affects the bacterial community. This gap in knowledge is striking when one considers the broad and significant impact that microbes have on human health. In this application, we propose to expressly fill this knowledge gap through development of a novel multimodal imaging pipeline that will provide 3-dimensional information on the molecular heterogeneity of microbial communities and the immune response at the host-pathogen interface.  This proposal combines our expertise in immunology, infection biology, mass spectrometry, small animal imaging, machine learning, and computer vision to develop an integrated multimodal visualization method for studying infectious disease. Our unique approach will computationally combine ultra-high speed (~50px/s) MALDI-TOF images, ultra-high mass resolution (>200,000 resolving power) MALDI FTICR IMS, metal imaging by LA-ICP-IMS, high-spatial resolution optical microscopy, and MR imaging using data-driven image fusion. This strategy will enable 3-D molecular images to be generated for thousands of elements, metabolites, lipids, and proteins with an unprecedented combination of chemical specificity and spatial fidelity more than 50x faster than is currently possible. We will use this next-generation imaging capability to (i) define the heterogeneous microbial subpopulations throughout the 3-D volume of a S. aureus community, (ii) uncover the host molecules that form the abscess and accumulate to restrict microbial growth in murine models, and (iii) elucidate molecular markers that differentiate in vivo biofilms at the host-pathogen interface, between abscesses at various stages of progression, and under distinct degrees of nutrient stress. These studies will uncover new targets for therapeutic intervention and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research. PROJECT NARRATIVE This proposal will enable detailed views of the molecular components of infectious disease with unprecedented resolution through the development of a multimodal, 3-dimensional imaging platform. The proposed technologies will improve throughput and molecular specificity, enable automated high-precision and high-accuracy image alignment, and allow for descriptions of molecular signals in 3-D through the fusion of multi-modal imaging data. These studies will uncover targets for therapeutic intervention and antibiotic development and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research.",Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry,9989025,R01AI138581,"['3-Dimensional', 'Abscess', 'Affect', 'Animal Model', 'Animals', 'Anterior nares', 'Antibiotics', 'Antibodies', 'Architecture', 'Awareness', 'Bacteria', 'Bacterial Infections', 'Bacterial Proteins', 'Behavior', 'Biology', 'Biomedical Research', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Cellular Metabolic Process', 'Chemicals', 'Communicable Diseases', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Custom', 'Data', 'Development', 'Diagnosis', 'Differentiation Antigens', 'Dimensions', 'Disease', 'Ecosystem', 'Elements', 'Environment', 'Exposure to', 'Fourier transform ion cyclotron resonance', 'Functional disorder', 'Genus staphylococcus', 'Glean', 'Growth', 'Health', 'Health Promotion', 'Heterogeneity', 'Histology', 'Human', 'Image', 'Imaging technology', 'Immune', 'Immune response', 'Immunology', 'Imprisonment', 'Individual', 'Infection', 'Infectious Diseases Research', 'Integration Host Factors', 'Knowledge', 'Label', 'Lesion', 'Lipids', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mass Spectrum Analysis', 'Metals', 'Methodology', 'Methods', 'Microbe', 'Microbial Biofilms', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nutrient', 'Optics', 'Organism', 'Pathogenesis', 'Physiological', 'Population', 'Process', 'Proteins', 'Reagent', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Specificity', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Staphylococcus aureus', 'Stress', 'Structure', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissues', 'Toxin', 'Vertebrates', 'Visualization', 'Work', 'animal imaging', 'bacterial community', 'base', 'body system', 'commensal bacteria', 'experimental study', 'host colonization', 'imaging capabilities', 'imaging detection', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'innovation', 'interest', 'microbial', 'microbial colonization', 'microbial community', 'microscopic imaging', 'molecular imaging', 'molecular marker', 'mouse model', 'multimodality', 'neutrophil', 'new therapeutic target', 'next generation', 'novel', 'pathogen', 'protein expression', 'response', 'supervised learning', 'targeted treatment', 'virtual']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,612684,-0.019408628987103722
"Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry PROJECT SUMMARY  Cellular interactions with the environment form the basis of health and disease for all organisms. Exposure to nutrients, toxins, and neighboring cells trigger coordinated molecular responses that impact cell function and metabolism in a beneficial, adaptive, or detrimental manner. Although the benefits of multicellularity for the formation of complex tissue structures or the function of entire organ systems has been long appreciated, it has only recently been understood that microbial inhabitants of vertebrates also have a tremendous impact on host cell function and dysfunction. Despite this, an understanding of these interactions has not moved beyond simple associations, and there are virtually no molecular technologies available that adequately define how a complex microbial ecosystem impacts host cell function, or how the host response to microbial colonization affects the bacterial community. This gap in knowledge is striking when one considers the broad and significant impact that microbes have on human health. In this application, we propose to expressly fill this knowledge gap through development of a novel multimodal imaging pipeline that will provide 3-dimensional information on the molecular heterogeneity of microbial communities and the immune response at the host-pathogen interface.  This proposal combines our expertise in immunology, infection biology, mass spectrometry, small animal imaging, machine learning, and computer vision to develop an integrated multimodal visualization method for studying infectious disease. Our unique approach will computationally combine ultra-high speed (~50px/s) MALDI-TOF images, ultra-high mass resolution (>200,000 resolving power) MALDI FTICR IMS, metal imaging by LA-ICP-IMS, high-spatial resolution optical microscopy, and MR imaging using data-driven image fusion. This strategy will enable 3-D molecular images to be generated for thousands of elements, metabolites, lipids, and proteins with an unprecedented combination of chemical specificity and spatial fidelity more than 50x faster than is currently possible. We will use this next-generation imaging capability to (i) define the heterogeneous microbial subpopulations throughout the 3-D volume of a S. aureus community, (ii) uncover the host molecules that form the abscess and accumulate to restrict microbial growth in murine models, and (iii) elucidate molecular markers that differentiate in vivo biofilms at the host-pathogen interface, between abscesses at various stages of progression, and under distinct degrees of nutrient stress. These studies will uncover new targets for therapeutic intervention and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research. PROJECT NARRATIVE This proposal will enable detailed views of the molecular components of infectious disease with unprecedented resolution through the development of a multimodal, 3-dimensional imaging platform. The proposed technologies will improve throughput and molecular specificity, enable automated high-precision and high-accuracy image alignment, and allow for descriptions of molecular signals in 3-D through the fusion of multi-modal imaging data. These studies will uncover targets for therapeutic intervention and antibiotic development and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research.",Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry,9788239,R01AI138581,"['3-Dimensional', 'Abscess', 'Affect', 'Animal Model', 'Animals', 'Anterior nares', 'Antibiotics', 'Antibodies', 'Architecture', 'Awareness', 'Bacteria', 'Bacterial Infections', 'Bacterial Proteins', 'Behavior', 'Biology', 'Biomedical Research', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Cellular Metabolic Process', 'Chemicals', 'Communicable Diseases', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Custom', 'Data', 'Development', 'Diagnosis', 'Differentiation Antigens', 'Dimensions', 'Disease', 'Ecosystem', 'Elements', 'Environment', 'Exposure to', 'Fourier transform ion cyclotron resonance', 'Functional disorder', 'Genus staphylococcus', 'Glean', 'Growth', 'Health', 'Health Promotion', 'Heterogeneity', 'Histology', 'Human', 'Image', 'Imagery', 'Imaging technology', 'Immune', 'Immune response', 'Immunology', 'Imprisonment', 'Individual', 'Infection', 'Infectious Diseases Research', 'Integration Host Factors', 'Knowledge', 'Label', 'Lesion', 'Lipids', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mass Spectrum Analysis', 'Metals', 'Methodology', 'Methods', 'Microbe', 'Microbial Biofilms', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nutrient', 'Optics', 'Organism', 'Pathogenesis', 'Physiological', 'Population', 'Process', 'Proteins', 'Reagent', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Specificity', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Staphylococcus aureus', 'Stress', 'Structure', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissues', 'Toxin', 'Vertebrates', 'Work', 'animal imaging', 'bacterial community', 'base', 'body system', 'commensal bacteria', 'experimental study', 'host colonization', 'imaging capabilities', 'imaging detection', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'innovation', 'interest', 'microbial', 'microbial colonization', 'microbial community', 'microscopic imaging', 'molecular imaging', 'molecular marker', 'mouse model', 'multimodality', 'neutrophil', 'new therapeutic target', 'next generation', 'novel', 'pathogen', 'protein expression', 'response', 'supervised learning', 'targeted treatment', 'virtual']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,562232,-0.019408628987103722
"Spatial Epigenomic Profiling of Immune Cell Signatures at Subcellular Resolution in Health and Disease SPATIAL EPIGENOMIC PROFILING OF IMMUNE CELL SIGNATURES AT SUBCELLULAR  RESOLUTION IN HEALTH AND DISEASE More than ten percent of childhood cancers are still incurable and need novel therapies. Epigenetic treatments deserve special attention with their specificity and reduced toxicity. Here I plan to explore epigenetic profiles of immune and cancer cells in normal development and blood cancer patients under the mentorship of Garry Nolan for single cell proteomics technology development, in collaboration with Howard Chang for implementation of epigenomic methods such as chromosome accessibility assays, and with Kara Davis for epigenetics studies of treatment resistant B cell subtypes in acute lymphoblastic leukemia (ALL). Epigenetic measurements have been limited to bulk level sequencing and ligation assays or limited number of imaging markers. To address these limitations, I will use an emerging three dimensional (3D) proteomic imaging technology in individual cells, termed as 3D Multiplexed ion beam imaging (MIBI) or 3D MIBI. Epigenetics research by 3D MIBI benefits from high degree multiplexing (up to 100 markers) and super resolution imaging capability (20 nm x-y; 5 nm z resolution), providing exciting opportunities to study genomic sites, methylated DNA, protein factors, and chromosome accessibility, all within the same experiments in single immune and aberrant (leukemic) cells. To systematically determine epigenetic states, I plan to utilize clonal B cell lines to decipher variability of epigenetic components including chromatin states, protein factors and modifiers by a fifty-marker 3D MIBI panel (Aim 1). These experiments will show distribution of epigenetic factors (linear or log-scale) in their expression levels and spatial variations (global or local) in the chromatin states. I will then perform experiments with primary B cells isolated from six different bone marrow aspirates of normal human subjects (Aim 2). I will correlate epigenetic signatures of each B cell subtype to corresponding development state (progenitor, pre, post, or mature). I will then perform an ex vivo co-culture of primary B cells on OP9 stromal cells over 1-6 weeks of culturing, which will be followed by fixation and profiling by 3D MIBI. These perturbation experiments will show how signaling events from neighboring cells drive necessary epigenetic conditions that are required for reaching a B cell subset. Finally, I will turn to primary B cells that are isolated from twenty newly diagnosed ALL patients (Aim 3). I will dissect differentiation and spatial epigenomic remodeling of responder B cell subsets and treatment resistant B cell subtypes from bone marrow aspirates using the OP9 co-culture. These will show how treatment resistance arises from a single epigenetic state or multiple distinct epigenetic signatures. I will then screen Histone deacetylase inhibitors (HDACi) on the same co-culture of B cell subtypes from ALL and stromal cells. By varying concentration and duration of inhibition conditions, I will dissect the role of epigenetic drugs in spatial chromatin remodeling toward development of epigenetic therapies in ALL. Together, these experiments will shed light on the role of epigenetic programming for cancer treatment applications from immune cell signatures in normal subjects and blood cancer patients. Public Health Relevance: Epigenetic alterations in immune and cancer cells regulate normal development and aberrant formation in humans. We reveal spatial heterogeneity and dynamic changes in epigenetic states of B cell subtypes from healthy and diseased subjects using a novel multiplex imaging mass cytometry. Deciphering the role of epigenetic perturbations in treatment resistant B cells will guide development of efficient and safe epigenetic therapies for pediatric blood cancers.",Spatial Epigenomic Profiling of Immune Cell Signatures at Subcellular Resolution in Health and Disease,9953964,K25AI140783,"['3-Dimensional', 'Acute Lymphocytic Leukemia', 'Address', 'Aspirate substance', 'Attention', 'B-Cell Development', 'B-Lymphocyte Subsets', 'B-Lymphocytes', 'Biological', 'Biological Assay', 'Bone Marrow', 'Cancer Patient', 'Catalogs', 'Cell Communication', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Child', 'Childhood Hematopoietic Neoplasm', 'Chromatin', 'Chromosomes', 'Coculture Techniques', 'Collaborations', 'Computational Technique', 'Computer Analysis', 'Cytometry', 'DNA', 'Data', 'Development', 'Disease', 'Enzymes', 'Epigenetic Process', 'Event', 'Exhibits', 'Four-dimensional', 'Future', 'Genetic Transcription', 'Genomic Segment', 'Genomics', 'Health', 'Hematopoietic Neoplasms', 'Heterogeneity', 'Histone Deacetylase Inhibitor', 'Human', 'Imaging technology', 'Immune', 'Immunotherapy', 'In Vitro', 'Individual', 'Leukemic Cell', 'Libraries', 'Ligation', 'Light', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Maps', 'Measurement', 'Medicine', 'Mentorship', 'Methods', 'Modeling', 'Multiplexed Ion Beam Imaging', 'Newly Diagnosed', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Proteins', 'Proteomics', 'Relapse', 'Research', 'Resistance', 'Resolution', 'Role', 'Sampling', 'Signal Transduction', 'Site', 'Specificity', 'Stem cell transplant', 'Stromal Cells', 'System', 'Technology', 'Toxic effect', 'Transcriptional Regulation', 'Variant', 'Visualization', 'acute lymphoblastic leukemia cell', 'base', 'cancer cell', 'cancer therapy', 'chemotherapy', 'chromatin remodeling', 'design', 'epigenetic drug', 'epigenetic therapy', 'epigenetic variation', 'epigenomics', 'experimental study', 'human subject', 'imaging approach', 'imaging biomarker', 'imaging capabilities', 'lymphoblast', 'mathematical analysis', 'multiplexed imaging', 'nanometer', 'next generation', 'novel', 'novel therapeutics', 'pediatric patients', 'progenitor', 'public health relevance', 'sample fixation', 'shape analysis', 'single cell analysis', 'success', 'technology development', 'therapy design', 'therapy resistant', 'treatment response']",NIAID,GEORGIA INSTITUTE OF TECHNOLOGY,K25,2020,107880,0.0057417770987932834
"Spatial Epigenomic Profiling of Immune Cell Signatures at Subcellular Resolution in Health and Disease SPATIAL EPIGENOMIC PROFILING OF IMMUNE CELL SIGNATURES AT SUBCELLULAR  RESOLUTION IN HEALTH AND DISEASE More than ten percent of childhood cancers are still incurable and need novel therapies. Epigenetic treatments deserve special attention with their specificity and reduced toxicity. Here I plan to explore epigenetic profiles of immune and cancer cells in normal development and blood cancer patients under the mentorship of Garry Nolan for single cell proteomics technology development, in collaboration with Howard Chang for implementation of epigenomic methods such as chromosome accessibility assays, and with Kara Davis for epigenetics studies of treatment resistant B cell subtypes in acute lymphoblastic leukemia (ALL). Epigenetic measurements have been limited to bulk level sequencing and ligation assays or limited number of imaging markers. To address these limitations, I will use an emerging three dimensional (3D) proteomic imaging technology in individual cells, termed as 3D Multiplexed ion beam imaging (MIBI) or 3D MIBI. Epigenetics research by 3D MIBI benefits from high degree multiplexing (up to 100 markers) and super resolution imaging capability (20 nm x-y; 5 nm z resolution), providing exciting opportunities to study genomic sites, methylated DNA, protein factors, and chromosome accessibility, all within the same experiments in single immune and aberrant (leukemic) cells. To systematically determine epigenetic states, I plan to utilize clonal B cell lines to decipher variability of epigenetic components including chromatin states, protein factors and modifiers by a fifty-marker 3D MIBI panel (Aim 1). These experiments will show distribution of epigenetic factors (linear or log-scale) in their expression levels and spatial variations (global or local) in the chromatin states. I will then perform experiments with primary B cells isolated from six different bone marrow aspirates of normal human subjects (Aim 2). I will correlate epigenetic signatures of each B cell subtype to corresponding development state (progenitor, pre, post, or mature). I will then perform an ex vivo co-culture of primary B cells on OP9 stromal cells over 1-6 weeks of culturing, which will be followed by fixation and profiling by 3D MIBI. These perturbation experiments will show how signaling events from neighboring cells drive necessary epigenetic conditions that are required for reaching a B cell subset. Finally, I will turn to primary B cells that are isolated from twenty newly diagnosed ALL patients (Aim 3). I will dissect differentiation and spatial epigenomic remodeling of responder B cell subsets and treatment resistant B cell subtypes from bone marrow aspirates using the OP9 co-culture. These will show how treatment resistance arises from a single epigenetic state or multiple distinct epigenetic signatures. I will then screen Histone deacetylase inhibitors (HDACi) on the same co-culture of B cell subtypes from ALL and stromal cells. By varying concentration and duration of inhibition conditions, I will dissect the role of epigenetic drugs in spatial chromatin remodeling toward development of epigenetic therapies in ALL. Together, these experiments will shed light on the role of epigenetic programming for cancer treatment applications from immune cell signatures in normal subjects and blood cancer patients. Public Health Relevance: Epigenetic alterations in immune and cancer cells regulate normal development and aberrant formation in humans. We reveal spatial heterogeneity and dynamic changes in epigenetic states of B cell subtypes from healthy and diseased subjects using a novel multiplex imaging mass cytometry. Deciphering the role of epigenetic perturbations in treatment resistant B cells will guide development of efficient and safe epigenetic therapies for pediatric blood cancers.",Spatial Epigenomic Profiling of Immune Cell Signatures at Subcellular Resolution in Health and Disease,9725907,K25AI140783,"['3-Dimensional', 'Acute Lymphocytic Leukemia', 'Address', 'Aspirate substance', 'Attention', 'B-Cell Development', 'B-Lymphocyte Subsets', 'B-Lymphocytes', 'Biological', 'Biological Assay', 'Bone Marrow', 'Cancer Patient', 'Catalogs', 'Cell Communication', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Child', 'Childhood Hematopoietic Neoplasm', 'Chromatin', 'Chromosomes', 'Coculture Techniques', 'Collaborations', 'Computational Technique', 'Computer Analysis', 'Cytometry', 'DNA', 'Data', 'Development', 'Dimensions', 'Disease', 'Enzymes', 'Epigenetic Process', 'Event', 'Exhibits', 'Four-dimensional', 'Future', 'Genetic Transcription', 'Genomic Segment', 'Genomics', 'Health', 'Hematopoietic Neoplasms', 'Heterogeneity', 'Histone Deacetylase Inhibitor', 'Human', 'Imagery', 'Imaging technology', 'Immune', 'Immunotherapy', 'In Vitro', 'Individual', 'Leukemic Cell', 'Libraries', 'Ligation', 'Light', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Maps', 'Measurement', 'Medicine', 'Mentorship', 'Methods', 'Modeling', 'Multiplexed Ion Beam Imaging', 'Newly Diagnosed', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Proteins', 'Proteomics', 'Relapse', 'Research', 'Resistance', 'Resolution', 'Role', 'Sampling', 'Signal Transduction', 'Site', 'Specificity', 'Stem cell transplant', 'Stromal Cells', 'System', 'Technology', 'Toxic effect', 'Transcriptional Regulation', 'Variant', 'acute lymphoblastic leukemia cell', 'base', 'cancer cell', 'cancer therapy', 'chemotherapy', 'chromatin remodeling', 'design', 'epigenetic drug', 'epigenetic therapy', 'epigenetic variation', 'epigenomics', 'experimental study', 'human subject', 'imaging approach', 'imaging biomarker', 'imaging capabilities', 'lymphoblast', 'mathematical analysis', 'multiplexed\xa0imaging', 'nanometer', 'next generation', 'novel', 'novel therapeutics', 'pediatric patients', 'progenitor', 'public health relevance', 'sample fixation', 'shape analysis', 'single cell analysis', 'success', 'technology development', 'therapy design', 'therapy resistant', 'treatment response']",NIAID,STANFORD UNIVERSITY,K25,2019,26384,0.0057417770987932834
"Spatial Epigenomic Profiling of Immune Cell Signatures at Subcellular Resolution in Health and Disease SPATIAL EPIGENOMIC PROFILING OF IMMUNE CELL SIGNATURES AT SUBCELLULAR  RESOLUTION IN HEALTH AND DISEASE More than ten percent of childhood cancers are still incurable and need novel therapies. Epigenetic treatments deserve special attention with their specificity and reduced toxicity. Here I plan to explore epigenetic profiles of immune and cancer cells in normal development and blood cancer patients under the mentorship of Garry Nolan for single cell proteomics technology development, in collaboration with Howard Chang for implementation of epigenomic methods such as chromosome accessibility assays, and with Kara Davis for epigenetics studies of treatment resistant B cell subtypes in acute lymphoblastic leukemia (ALL). Epigenetic measurements have been limited to bulk level sequencing and ligation assays or limited number of imaging markers. To address these limitations, I will use an emerging three dimensional (3D) proteomic imaging technology in individual cells, termed as 3D Multiplexed ion beam imaging (MIBI) or 3D MIBI. Epigenetics research by 3D MIBI benefits from high degree multiplexing (up to 100 markers) and super resolution imaging capability (20 nm x-y; 5 nm z resolution), providing exciting opportunities to study genomic sites, methylated DNA, protein factors, and chromosome accessibility, all within the same experiments in single immune and aberrant (leukemic) cells. To systematically determine epigenetic states, I plan to utilize clonal B cell lines to decipher variability of epigenetic components including chromatin states, protein factors and modifiers by a fifty-marker 3D MIBI panel (Aim 1). These experiments will show distribution of epigenetic factors (linear or log-scale) in their expression levels and spatial variations (global or local) in the chromatin states. I will then perform experiments with primary B cells isolated from six different bone marrow aspirates of normal human subjects (Aim 2). I will correlate epigenetic signatures of each B cell subtype to corresponding development state (progenitor, pre, post, or mature). I will then perform an ex vivo co-culture of primary B cells on OP9 stromal cells over 1-6 weeks of culturing, which will be followed by fixation and profiling by 3D MIBI. These perturbation experiments will show how signaling events from neighboring cells drive necessary epigenetic conditions that are required for reaching a B cell subset. Finally, I will turn to primary B cells that are isolated from twenty newly diagnosed ALL patients (Aim 3). I will dissect differentiation and spatial epigenomic remodeling of responder B cell subsets and treatment resistant B cell subtypes from bone marrow aspirates using the OP9 co-culture. These will show how treatment resistance arises from a single epigenetic state or multiple distinct epigenetic signatures. I will then screen Histone deacetylase inhibitors (HDACi) on the same co-culture of B cell subtypes from ALL and stromal cells. By varying concentration and duration of inhibition conditions, I will dissect the role of epigenetic drugs in spatial chromatin remodeling toward development of epigenetic therapies in ALL. Together, these experiments will shed light on the role of epigenetic programming for cancer treatment applications from immune cell signatures in normal subjects and blood cancer patients. Public Health Relevance: Epigenetic alterations in immune and cancer cells regulate normal development and aberrant formation in humans. We reveal spatial heterogeneity and dynamic changes in epigenetic states of B cell subtypes from healthy and diseased subjects using a novel multiplex imaging mass cytometry. Deciphering the role of epigenetic perturbations in treatment resistant B cells will guide development of efficient and safe epigenetic therapies for pediatric blood cancers.",Spatial Epigenomic Profiling of Immune Cell Signatures at Subcellular Resolution in Health and Disease,9582519,K25AI140783,"['Acute Lymphocytic Leukemia', 'Address', 'Aspirate substance', 'Attention', 'B-Cell Development', 'B-Lymphocyte Subsets', 'B-Lymphocytes', 'Biological', 'Biological Assay', 'Bone Marrow', 'Cancer Patient', 'Catalogs', 'Cell Communication', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Child', 'Childhood Hematopoietic Neoplasm', 'Chromatin', 'Chromosomes', 'Coculture Techniques', 'Collaborations', 'Computational Technique', 'Computer Analysis', 'Cytometry', 'DNA', 'Data', 'Development', 'Dimensions', 'Disease', 'Enzymes', 'Epigenetic Process', 'Event', 'Exhibits', 'Four-dimensional', 'Future', 'Genetic Transcription', 'Genomic Segment', 'Genomics', 'Health', 'Hematopoietic Neoplasms', 'Heterogeneity', 'Histone Deacetylase Inhibitor', 'Human', 'Image', 'Imagery', 'Imaging technology', 'Immune', 'Immunotherapy', 'In Vitro', 'Individual', 'Leukemic Cell', 'Libraries', 'Ligation', 'Light', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Maps', 'Measurement', 'Medicine', 'Mentorship', 'Methods', 'Modeling', 'Multiplexed Ion Beam Imaging', 'Newly Diagnosed', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Proteins', 'Proteomics', 'Relapse', 'Research', 'Resistance', 'Resolution', 'Role', 'Sampling', 'Signal Transduction', 'Site', 'Specificity', 'Stem cell transplant', 'Stromal Cells', 'System', 'Technology', 'Toxic effect', 'Transcriptional Regulation', 'Variant', 'base', 'cancer cell', 'cancer therapy', 'chemotherapy', 'chromatin remodeling', 'design', 'epigenetic drug', 'epigenetic therapy', 'epigenetic variation', 'epigenomics', 'experimental study', 'human subject', 'imaging approach', 'imaging biomarker', 'imaging capabilities', 'lymphoblast', 'mathematical analysis', 'nanometer', 'next generation', 'novel', 'novel therapeutics', 'pediatric patients', 'progenitor', 'public health relevance', 'sample fixation', 'shape analysis', 'single cell analysis', 'success', 'technology development', 'therapy design', 'therapy resistant', 'treatment response']",NIAID,STANFORD UNIVERSITY,K25,2018,107880,0.0057417770987932834
"Predictive engineering of cellular transcriptional state PROJECT SUMMARY/ABSTRACT Specific combinations of transcription factors (TFs) exhibit emergent properties when functioning together, enabling the generation of diverse cell types and behaviors. However, identifying which combinations regulate a behavior of interest requires overcoming a combinatorial explosion, as among the ~1,600 TFs in the human genome there are ~1.3 million possible pairs alone. This scaling challenge has forced past efforts at systematically mapping such genetic interactions (GIs) to rely on simple, parallelizable measures of phenotype such as growth rate. Each GI is then characterized only by a single number, obscuring the mechanistic or molecular basis for any particular interaction: put simply, there are many ways for cells to appear equally “unfit.” Finally, many human cell types are quiescent or post-mitotic, so that the growth-based measures of interaction that have been highly successful in model organisms such as yeast do not apply. Here we address these challenges by introducing a new, massively parallel method for studying GIs in human cells that combines rich phenotyping of single cells with an analytical framework for predicting which combinations are most informative to measure. We leverage the recently developed Perturb-seq screening technology, which allows pooled profiling of CRISPR-mediated genetic perturbations with single-cell RNA sequencing as the phenotypic readout. This approach allows us to overexpress many programmed combinations of TFs using CRISPR activation (CRISPRa) and obtain a direct readout of their transcriptional consequences. The resulting rich phenotypes yield insight into the biological origins of GIs, and can for example identify combinations of TFs that promote differentiation to diverse cell states. They also provide a critical “handle” to apply modern machine learning methods. Using techniques from the field of compressed sensing, we propose a predictive approach for searching combinatorial spaces of GIs that would be too large to profile exhaustively by any experimental technology. Since the transcriptome is a direct readout of TF function and TFs interact via specific mechanisms such as cooperative binding at target promoters, these large-scale experiments can also be used to study deeper questions on how GIs emerge mechanistically, and how neomorphic (i.e. entirely new or unpredictable) phenotypes are generated. Our research provides the first scalable method for simultaneously finding and characterizing GIs in any system, a technique for rapidly mapping the “levers” controlling cell fate in diverse models of development and disease, and a model for how machine learning can be used to design the large combinatorial genetics experiments made possible by Cas9. PROJECT NARRATIVE Understanding how genes work together to realize different cellular phenotypes is one of the core problems of genetics. This proposal develops a new experimental and computational approach for mapping the different states that cells can occupy, and for identifying combinations of genes that push cells into these states. This technique will help us understand how complex interactions among genes affect human health and disease.",Predictive engineering of cellular transcriptional state,10001677,DP2GM140925,"['Address', 'Affect', 'Animal Model', 'Behavior', 'Binding', 'Biological', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Complex', 'Disease', 'Exhibits', 'Explosion', 'Gene Combinations', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic study', 'Growth', 'Health', 'Human', 'Human Genome', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Mitotic', 'Modeling', 'Modernization', 'Molecular', 'Phenotype', 'Property', 'Research', 'System', 'Techniques', 'Technology', 'Work', 'Yeasts', 'base', 'cell behavior', 'cell type', 'cellular engineering', 'combinatorial', 'design', 'exhaustion', 'experimental study', 'insight', 'interest', 'machine learning method', 'model development', 'overexpression', 'promoter', 'rapid technique', 'screening', 'single-cell RNA sequencing', 'transcription factor', 'transcriptome']",NIGMS,SLOAN-KETTERING INST CAN RESEARCH,DP2,2020,2655000,0.00744504842842841
"Novel approaches to study the intersection of cellular heterogeneity and tissue microanatomy Project Summary/Abstract “Novel approaches to study the intersection of cellular heterogeneity and tissue microanatomy” Positioning of cells in tissues is intimately linked to major cellular- and organ-level processes. Appropriate localization promotes exposure of cells to specific microenvironments and stimuli that define their differentiation states and functions. Cellular positioning also determines local tissue microanatomy, as well as the global macro-architecture, allowing for proper organ function and physiology. Thus, understanding the links among cellular positioning, heterogeneity and global tissue architecture are critical for biomedical research. However, current tools for understanding such relationships are limiting. Here, we will develop novel approaches to study cells using currently existing high-content tools, but importantly while also retaining information on the precise positioning of cells within tissues (Aim 1). This will allow us to interrogate how cellular heterogeneity and function is influenced by the exposure to distinct tissue microenvironments and localized stimuli. Further, we will generate novel computational approaches to understand how cellular positioning defines global tissue architecture (Aim 2). For this, we will develop a robust analytical methodology based on machine learning algorithms to study how complex patterns of cellular spatial positioning influences tissue organization and structure. These approaches will be broadly applicable across diverse disciplines of biology for both murine and human (or other species) studies, and will be highly pertinent in clinical settings, such as for cancer diagnostics. In summary, the proposed studies are significant, as they will provide a new toolbox for studying cellular and organ physiology based on cellular tissue positioning, as well as will lead to the development of new diagnostic tools for clinical medicine. Project narrative / Relevance statement The positioning of cells in tissues is critical for shaping both the cellular identity and function, as well as the structure and physiology of the entire organ. The proposed research will generate a novel, comprehensive toolbox for interrogating the relationships among cellular spatial positioning, cell heterogeneity, as well as tissue architecture. These tools will be relevant to public health because they will promote a better fundamental understanding of cellular and organ physiology, and because the developed tools will be directly applicable to the clinic, such as for pathology and diagnostic medicine.",Novel approaches to study the intersection of cellular heterogeneity and tissue microanatomy,9873919,R21AI142667,"['3-Dimensional', 'Adoption', 'Anatomy', 'Antibodies', 'Architecture', 'Bar Codes', 'Biology', 'Biomedical Research', 'Cancer Diagnostics', 'Cell Communication', 'Cell Separation', 'Cells', 'Cellular Structures', 'Clinic', 'Clinical', 'Clinical Medicine', 'Color', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Discipline', 'Exposure to', 'Flow Cytometry', 'Gene Expression', 'Gene Expression Profiling', 'Genetic Engineering', 'Genetic Transcription', 'Goals', 'Heterogeneity', 'Higher Order Chromatin Structure', 'Human', 'Label', 'Link', 'Location', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Microanatomy', 'Molecular', 'Mouse Strains', 'Mus', 'Neighborhoods', 'Organ', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological Processes', 'Physiology', 'Population', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Public Health', 'Quantitative Microscopy', 'Reagent', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Specific qualifier value', 'Stimulus', 'Structure', 'Sum', 'Techniques', 'Technology', 'Tissues', 'analytical tool', 'base', 'fluorophore', 'genetic manipulation', 'high dimensionality', 'human tissue', 'imaging approach', 'lymphoid neoplasm', 'lymphoid organ', 'machine learning algorithm', 'mouse model', 'new technology', 'novel', 'novel diagnostics', 'novel strategies', 'organizational structure', 'patient stratification', 'protein expression', 'spatial relationship', 'tool', 'transcriptome sequencing']",NIAID,UNIVERSITY OF WASHINGTON,R21,2020,220625,0.009590092755217529
"Novel approaches to study the intersection of cellular heterogeneity and tissue microanatomy Project Summary/Abstract “Novel approaches to study the intersection of cellular heterogeneity and tissue microanatomy” Positioning of cells in tissues is intimately linked to major cellular- and organ-level processes. Appropriate localization promotes exposure of cells to specific microenvironments and stimuli that define their differentiation states and functions. Cellular positioning also determines local tissue microanatomy, as well as the global macro-architecture, allowing for proper organ function and physiology. Thus, understanding the links among cellular positioning, heterogeneity and global tissue architecture are critical for biomedical research. However, current tools for understanding such relationships are limiting. Here, we will develop novel approaches to study cells using currently existing high-content tools, but importantly while also retaining information on the precise positioning of cells within tissues (Aim 1). This will allow us to interrogate how cellular heterogeneity and function is influenced by the exposure to distinct tissue microenvironments and localized stimuli. Further, we will generate novel computational approaches to understand how cellular positioning defines global tissue architecture (Aim 2). For this, we will develop a robust analytical methodology based on machine learning algorithms to study how complex patterns of cellular spatial positioning influences tissue organization and structure. These approaches will be broadly applicable across diverse disciplines of biology for both murine and human (or other species) studies, and will be highly pertinent in clinical settings, such as for cancer diagnostics. In summary, the proposed studies are significant, as they will provide a new toolbox for studying cellular and organ physiology based on cellular tissue positioning, as well as will lead to the development of new diagnostic tools for clinical medicine. Project narrative / Relevance statement The positioning of cells in tissues is critical for shaping both the cellular identity and function, as well as the structure and physiology of the entire organ. The proposed research will generate a novel, comprehensive toolbox for interrogating the relationships among cellular spatial positioning, cell heterogeneity, as well as tissue architecture. These tools will be relevant to public health because they will promote a better fundamental understanding of cellular and organ physiology, and because the developed tools will be directly applicable to the clinic, such as for pathology and diagnostic medicine.",Novel approaches to study the intersection of cellular heterogeneity and tissue microanatomy,9647827,R21AI142667,"['3-Dimensional', 'Adoption', 'Anatomy', 'Antibodies', 'Architecture', 'Biology', 'Biomedical Research', 'Cancer Diagnostics', 'Cell Communication', 'Cell Separation', 'Cells', 'Cellular Structures', 'Clinic', 'Clinical', 'Clinical Medicine', 'Color', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Discipline', 'Exposure to', 'Flow Cytometry', 'Gene Expression', 'Gene Expression Profiling', 'Genetic Engineering', 'Genetic Transcription', 'Goals', 'Heterogeneity', 'Higher Order Chromatin Structure', 'Human', 'Label', 'Link', 'Location', 'Lymphoid', 'Machine Learning', 'Medicine', 'Methodology', 'Methods', 'Microanatomy', 'Molecular', 'Mouse Strains', 'Mus', 'Neighborhoods', 'Organ', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological Processes', 'Physiology', 'Population', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Public Health', 'Quantitative Microscopy', 'Reagent', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Specific qualifier value', 'Stimulus', 'Structure', 'Sum', 'Techniques', 'Technology', 'Tissues', 'analytical tool', 'base', 'fluorophore', 'genetic manipulation', 'high dimensionality', 'human tissue', 'imaging approach', 'machine learning algorithm', 'mouse model', 'new technology', 'novel', 'novel diagnostics', 'novel strategies', 'organizational structure', 'patient stratification', 'protein expression', 'spatial relationship', 'tool', 'transcriptome sequencing', 'tumor']",NIAID,UNIVERSITY OF WASHINGTON,R21,2019,264500,0.009590092755217529
"Discovery of genetic elements regulating intraepithelial lymphocytes PROJECT SUMMARY Intraepithelial lymphocytes (IELs) are an abundant and heterogeneous population of T cells that reside at the intestinal epithelium, a critical environmental interface between the intestinal tract and the body core. IELs are tasked with maintaining tolerance to a high volume of harmless stimuli from food and commensal microbiota while providing protective immunity against ingested pathogens. Dysregulation of this balance leads to loss of intestinal barrier integrity, susceptibility to enteric infections, and inflammatory bowel diseases. However, many key aspects of IEL development, tissue residence, and function remain unclear, and the pursuit of these questions has been hampered by a lack of genetic targeting strategies for the majority of IEL subsets. We propose to undertake a trait mapping study using the recently established Diversity Outbred and Collaborative Cross mouse cohorts to identify novel genetic factors influencing IEL maturation and tissue maintenance. Recently, we performed quantitative trait loci analysis using these cohorts and identified 78 IEL-associated genomic regions. To determine which single nucleotide polymorphisms (SNPs) within IEL-associated loci are most likely to be causative, we will take a rigorous bioinformatics approach including functional characterization of SNPs, identification of candidate target genes, text mining for published association of candidate genes with relevant ontologies and cell or tissue types, and intestinal gene expression analysis. Further, for at least one candidate IEL-associated SNP identified we will use CRISPR/Cas9 gene editing to generate SNP mutants in C57BL/6 mice, with the goal of generating genetic models of high or low IEL frequency. These mice will be used to confirm biological relevance of candidate genetic elements in vivo, and will enable extensive future research into IEL function. The proposed work may promote understanding of how IELs contribute to gut homeostasis and suggest novel therapeutic targets for gut inflammatory diseases. NARRATIVE The proposed research has significant relevance to public health because it aims at the identification of novel genetic factors associated with the development and function of Intraepithelial lymphocytes (IELs), which constitute abundant immune cells that reside at the intestinal epithelium, a critical environmental interface between the intestinal tract and the body core. The proposed work promotes understanding of how IELs contribute to gut homeostasis and may suggest novel therapeutic targets for gut inflammatory diseases.",Discovery of genetic elements regulating intraepithelial lymphocytes,9948570,R21AI144827,"['Address', 'Bioinformatics', 'Biological', 'C57BL/6 Mouse', 'CRISPR/Cas technology', 'Candidate Disease Gene', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Databases', 'Development', 'Disease', 'Epigenetic Process', 'Equilibrium', 'Exons', 'Food', 'Frequencies', 'Gene Expression', 'Gene Expression Profiling', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Recombination', 'Genetic Variation', 'Genomic Segment', 'Genotype', 'Goals', 'Hematopoietic', 'Heterogeneity', 'Homeostasis', 'House mice', 'Human', 'Immune', 'Immunity', 'Inbred Strains Mice', 'Individual', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Ingestion', 'Intestines', 'Introns', 'Investigation', 'Knock-out', 'Lymphocyte', 'Lymphocyte Function', 'Lymphocyte Subset', 'Maintenance', 'Modeling', 'Mus', 'Mutant Strains Mice', 'Ontology', 'Phenotype', 'Population', 'Population Heterogeneity', 'Predisposition', 'Public Health', 'Publishing', 'Quantitative Trait Loci', 'RNA Splicing', 'Regulatory Element', 'Research', 'Role', 'Single Nucleotide Polymorphism', 'Site', 'Small Intestines', 'Stimulus', 'T-Lymphocyte', 'Tissues', 'Untranslated RNA', 'Work', 'base', 'candidate identification', 'cohort', 'commensal microbes', 'enteric infection', 'experimental study', 'genetic element', 'genome editing', 'in vivo', 'intestinal barrier', 'intestinal epithelium', 'intraepithelial', 'knockout gene', 'mouse model', 'mutant', 'new therapeutic target', 'novel', 'pathogen', 'protein structure function', 'residence', 'text searching', 'tool', 'trait']",NIAID,ROCKEFELLER UNIVERSITY,R21,2020,211875,-0.025723290988955125
"Discovery of genetic elements regulating intraepithelial lymphocytes PROJECT SUMMARY Intraepithelial lymphocytes (IELs) are an abundant and heterogeneous population of T cells that reside at the intestinal epithelium, a critical environmental interface between the intestinal tract and the body core. IELs are tasked with maintaining tolerance to a high volume of harmless stimuli from food and commensal microbiota while providing protective immunity against ingested pathogens. Dysregulation of this balance leads to loss of intestinal barrier integrity, susceptibility to enteric infections, and inflammatory bowel diseases. However, many key aspects of IEL development, tissue residence, and function remain unclear, and the pursuit of these questions has been hampered by a lack of genetic targeting strategies for the majority of IEL subsets. We propose to undertake a trait mapping study using the recently established Diversity Outbred and Collaborative Cross mouse cohorts to identify novel genetic factors influencing IEL maturation and tissue maintenance. Recently, we performed quantitative trait loci analysis using these cohorts and identified 78 IEL-associated genomic regions. To determine which single nucleotide polymorphisms (SNPs) within IEL-associated loci are most likely to be causative, we will take a rigorous bioinformatics approach including functional characterization of SNPs, identification of candidate target genes, text mining for published association of candidate genes with relevant ontologies and cell or tissue types, and intestinal gene expression analysis. Further, for at least one candidate IEL-associated SNP identified we will use CRISPR/Cas9 gene editing to generate SNP mutants in C57BL/6 mice, with the goal of generating genetic models of high or low IEL frequency. These mice will be used to confirm biological relevance of candidate genetic elements in vivo, and will enable extensive future research into IEL function. The proposed work may promote understanding of how IELs contribute to gut homeostasis and suggest novel therapeutic targets for gut inflammatory diseases. NARRATIVE The proposed research has significant relevance to public health because it aims at the identification of novel genetic factors associated with the development and function of Intraepithelial lymphocytes (IELs), which constitute abundant immune cells that reside at the intestinal epithelium, a critical environmental interface between the intestinal tract and the body core. The proposed work promotes understanding of how IELs contribute to gut homeostasis and may suggest novel therapeutic targets for gut inflammatory diseases.",Discovery of genetic elements regulating intraepithelial lymphocytes,9836252,R21AI144827,"['Address', 'Bioinformatics', 'Biological', 'C57BL/6 Mouse', 'CRISPR/Cas technology', 'Candidate Disease Gene', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Databases', 'Development', 'Disease', 'Epigenetic Process', 'Equilibrium', 'Exons', 'Food', 'Frequencies', 'Gene Expression', 'Gene Expression Profiling', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Recombination', 'Genetic Variation', 'Genomic Segment', 'Genotype', 'Goals', 'Hematopoietic', 'Heterogeneity', 'Homeostasis', 'House mice', 'Human', 'Immune', 'Immunity', 'Inbred Strains Mice', 'Individual', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Ingestion', 'Intestines', 'Introns', 'Investigation', 'Knock-out', 'Lymphocyte', 'Lymphocyte Function', 'Lymphocyte Subset', 'Maintenance', 'Modeling', 'Mus', 'Mutant Strains Mice', 'Ontology', 'Phenotype', 'Population', 'Population Heterogeneity', 'Predisposition', 'Public Health', 'Publishing', 'Quantitative Trait Loci', 'RNA Splicing', 'Regulatory Element', 'Research', 'Role', 'Single Nucleotide Polymorphism', 'Site', 'Small Intestines', 'Stimulus', 'T-Lymphocyte', 'Tissues', 'Untranslated RNA', 'Work', 'base', 'candidate identification', 'cohort', 'commensal microbes', 'enteric infection', 'experimental study', 'genetic element', 'genome editing', 'in vivo', 'intestinal epithelium', 'intraepithelial', 'knockout gene', 'mouse model', 'mutant', 'new therapeutic target', 'novel', 'pathogen', 'protein structure function', 'residence', 'text searching', 'tool', 'trait']",NIAID,ROCKEFELLER UNIVERSITY,R21,2019,254250,-0.025723290988955125
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,9782980,UG3HL145593,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NHLBI,PURDUE UNIVERSITY,UG3,2019,375000,-0.002232322628907752
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,9659552,UG3HL145593,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NHLBI,PURDUE UNIVERSITY,UG3,2018,375000,-0.002232322628907752
"In situ transcriptome profiling in single cells Summary We have recently developed intron seqFISH (sequential Fluorescence in situ hybridization) to multiplex 10,421 genes directly in single cells. We showed that the 10,421 gene nascent transcriptome profile can identify cell types as well as capture the trajectory of the cells. We further demonstrated that we can perform mRNA seqFISH as well as immunostaining in the same cells following the 10,421 gene intron seqFISH measurement. We propose to develop this technology as a potential alternative approach to single cell RNAseq for the HuBMAP to characterize cell types directly in situ in tissues. In particular, we will adept in situ amplification methods such as hybridization chain reaction (HCR) to intron seqFISH. We had previously shown that mRNA seqFISH with HCR amplification performs exceptionally in tissues in overcoming autofluorescence background and enable robust decoding seqFISH barcodes. We will validate the integrated intron and mRNA seqFISH protocol in the mouse hippocampus in the UG3 phase of the project. Also in UG3 phase, we will develop computational tools to integrate intron seqFISH data with mRNA seqFISH as well as single cell RNAseq data. In the UH3 phase, we will translate the technology to human tissues, with a focus on human mammary tissues provided by Dr. Seewaldt at City of Hope. We will also work with the tissue mapping centers in the HuBMAP program to accelerate the translation of this technology to many tissue types. In the UH3 phase, we will generate million cell spatial atlas of human tissues containing intron profiles, mRNA profiles and protein abundances in each single cell. We will further develop computational tools to analyze for spatial enrichment of genes in the tissue and generate a pseudotime of developmental trajectories using the nascent transcriptome data. Taken together, we will develop a high throughput in situ imaging based platform to characterize cell types and future trajectories of cells using intron and mRNA seqFISH technologies. Narrative Transcriptome profiling in situ at the single cell level has transformative potential for understanding healthy versus diseased tissues in the human body. We propose an integrative approach profiling the nascent transcriptome as well as hundreds of mature transcripts in single cells in tissues. We will generate million cell spatial atlas for the mouse hippocampus as well as the human mammary tissue. We will gain unprecedented insight into the developmental of neurons in the brain as well as the duct cells in the breast. At the same time we will develop the computational tools to analyze the spatial genomics data.",In situ transcriptome profiling in single cells,9791198,UG3HL145609,"['Algorithms', 'Animals', 'Atlases', 'Biology', 'Biopsy Specimen', 'Brain', 'Breast', 'Cell Differentiation process', 'Cells', 'Cities', 'Data', 'Data Quality', 'Data Set', 'Development', 'Disease', 'Ductal Epithelial Cell', 'Epigenetic Process', 'Epithelium', 'Expression Profiling', 'Fluorescent in Situ Hybridization', 'Future', 'Gene Expression', 'Genes', 'Goals', 'Hippocampus (Brain)', 'Human', 'Human body', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'In Situ', 'Introns', 'Letters', 'Machine Learning', 'Mammary Gland Parenchyma', 'Mammary gland', 'Maps', 'Measurement', 'Messenger RNA', 'Methods', 'Mus', 'Natural regeneration', 'Neuroglia', 'Neurons', 'Nuclear Structure', 'Pattern', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Proteins', 'Protocols documentation', 'Publications', 'Publishing', 'Radial', 'Reaction', 'Role', 'Signal Transduction', 'Slice', 'Speed', 'Stains', 'Standardization', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Transcript', 'Translating', 'Translations', 'Validation', 'Weight', 'Work', 'base', 'cell type', 'combinatorial', 'computerized tools', 'dentate gyrus', 'genomic data', 'granule cell', 'human tissue', 'imaging system', 'in situ imaging', 'insight', 'internal control', 'mammary epithelium', 'markov model', 'programs', 'sample fixation', 'scale up', 'single molecule', 'tool', 'transcriptome', 'transcriptome sequencing']",NHLBI,CALIFORNIA INSTITUTE OF TECHNOLOGY,UG3,2019,375000,0.00563431317047119
"In situ transcriptome profiling in single cells Summary We have recently developed intron seqFISH (sequential Fluorescence in situ hybridization) to multiplex 10,421 genes directly in single cells. We showed that the 10,421 gene nascent transcriptome profile can identify cell types as well as capture the trajectory of the cells. We further demonstrated that we can perform mRNA seqFISH as well as immunostaining in the same cells following the 10,421 gene intron seqFISH measurement. We propose to develop this technology as a potential alternative approach to single cell RNAseq for the HuBMAP to characterize cell types directly in situ in tissues. In particular, we will adept in situ amplification methods such as hybridization chain reaction (HCR) to intron seqFISH. We had previously shown that mRNA seqFISH with HCR amplification performs exceptionally in tissues in overcoming autofluorescence background and enable robust decoding seqFISH barcodes. We will validate the integrated intron and mRNA seqFISH protocol in the mouse hippocampus in the UG3 phase of the project. Also in UG3 phase, we will develop computational tools to integrate intron seqFISH data with mRNA seqFISH as well as single cell RNAseq data. In the UH3 phase, we will translate the technology to human tissues, with a focus on human mammary tissues provided by Dr. Seewaldt at City of Hope. We will also work with the tissue mapping centers in the HuBMAP program to accelerate the translation of this technology to many tissue types. In the UH3 phase, we will generate million cell spatial atlas of human tissues containing intron profiles, mRNA profiles and protein abundances in each single cell. We will further develop computational tools to analyze for spatial enrichment of genes in the tissue and generate a pseudotime of developmental trajectories using the nascent transcriptome data. Taken together, we will develop a high throughput in situ imaging based platform to characterize cell types and future trajectories of cells using intron and mRNA seqFISH technologies. Narrative Transcriptome profiling in situ at the single cell level has transformative potential for understanding healthy versus diseased tissues in the human body. We propose an integrative approach profiling the nascent transcriptome as well as hundreds of mature transcripts in single cells in tissues. We will generate million cell spatial atlas for the mouse hippocampus as well as the human mammary tissue. We will gain unprecedented insight into the developmental of neurons in the brain as well as the duct cells in the breast. At the same time we will develop the computational tools to analyze the spatial genomics data.",In situ transcriptome profiling in single cells,9660361,UG3HL145609,"['Algorithms', 'Animals', 'Atlases', 'Biology', 'Biopsy Specimen', 'Brain', 'Breast', 'Cell Differentiation process', 'Cells', 'Cities', 'Data', 'Data Quality', 'Data Set', 'Development', 'Disease', 'Ductal Epithelial Cell', 'Epigenetic Process', 'Epithelium', 'Expression Profiling', 'Fluorescent in Situ Hybridization', 'Future', 'Gene Expression', 'Genes', 'Goals', 'Hippocampus (Brain)', 'Human', 'Human body', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'In Situ', 'Introns', 'Letters', 'Machine Learning', 'Mammary Gland Parenchyma', 'Mammary gland', 'Maps', 'Measurement', 'Messenger RNA', 'Methods', 'Mus', 'Natural regeneration', 'Neuroglia', 'Neurons', 'Nuclear Structure', 'Pattern', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Proteins', 'Protocols documentation', 'Publications', 'Publishing', 'Radial', 'Reaction', 'Role', 'Signal Transduction', 'Slice', 'Speed', 'Stains', 'Standardization', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Transcript', 'Translating', 'Translations', 'Validation', 'Weight', 'Work', 'base', 'cell type', 'combinatorial', 'computerized tools', 'dentate gyrus', 'genomic data', 'granule cell', 'human tissue', 'imaging system', 'in situ imaging', 'insight', 'internal control', 'mammary epithelium', 'markov model', 'programs', 'sample fixation', 'scale up', 'single molecule', 'tool', 'transcriptome', 'transcriptome sequencing']",NHLBI,CALIFORNIA INSTITUTE OF TECHNOLOGY,UG3,2018,375000,0.00563431317047119
"A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning SUMMARY Adaptive evolution (AE) is both a “force of good” as it can help to optimize biological processes in industry, but it is also a “force of frustration” when infectious diseases exploit AE to escape the host immune system or become resistant to drugs. It has long been assumed close to impossible to make predictions on AE due to the presumed predominating influences of random forces and events. However, the observation that evolutionary repeatability across traits and species is far more common than previously thought, suggests that AE, with the right data and approach, may become (partially) predictable. Indeed, we found through experiments with the bacterial pathogen Streptococcus pneumoniae on its response to antibiotics and the emergence of antimicrobial resistance, that in order to make AE predictable a detailed understanding of at least two aspects of the bacterial system are required: 1.) the genetic constraints of the system (i.e. the architecture of the organismal network); and 2.) where and how in the system stress is experienced and processed. We showed that by mapping out ~25% of the bacterium's network, determining phenotypic and transcriptional antibiotic responses, applying network analyses to capture and quantify the responses in a network context, and exploiting experimental evolution to pin-point adaptive mutations in the genome it becomes possible, by means of machine learning, to uncover hidden patterns in the data that make AE predictions feasible. This means that the network in interaction with the environment shapes the adaptive landscape, it limits available solutions and makes some solutions more likely than others, thereby driving repeatability and enabling predictability. In this proposal we build on these exciting developments with the goal to map out the constraints of S. pneumoniae's entire network and develop a machine learning model that can forecast adaptive evolution a priori, and on a genome-wide scale. To accomplish this, we combine in aim 1 parts of Tn-Seq, dTn-Seq and Drop-Seq to finalize a new tool Tn-Seq^2 (Tn-Seq squared) that is able to map genetic-interactions in high-throughput and genome-wide. We use Tn-Seq^2 to reconstruct the first genome-wide genetic interaction network for S. pneumoniae in the presence of 20 antibiotics. In aim 2 we create 85 HA-tagged Transcription factor induction (TFI) strains and: a) Determine with ChIP-Seq the DNA-binding sites for all 85 TFs in S. pneumoniae; b) By overexpressing each TFI strain followed by RNA- Seq we determine each TFs regulatory signature; c) Use a Transcriptional Regulator Induced Phenotype screen in the presence of 20 antibiotics to untangle environment specific links between genetic and transcriptional perturbations and their phenotypic outcomes. Lastly, in aim 3, we train and test a variety of machine learning approaches to design an optimal model that predicts which genes in the genome are most likely to adapt in the presence of a specific antibiotic. The development of this predictive AE model, will not only be useful in predicting the emergence of antibiotic resistance, but the strategy should be valuable for most any biological field for which adaptive changes are important, ranging from biological engineering to cancer. NARRATIVE Adaptive evolution (AE) is the driving force behind the emergence of antibiotic resistance and if it were possible to predict AE before it happens, it could help in preventing resistance. Here we use cutting-edge existing and newly designed genomics tools and analytical approaches to develop a machine learning model that can predict AE a priori, and on a genome-wide scale.",A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning,10049219,R01AI148470,"['Achievement', 'Affect', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Automobile Driving', 'Bacteria', 'Binding Sites', 'Biological', 'Biological Process', 'Biomass', 'ChIP-seq', 'Communicable Diseases', 'Complex', 'DNA Binding', 'Data', 'Development', 'Drug resistance', 'Engineering', 'Ensure', 'Environment', 'Escherichia coli', 'Event', 'Evolution', 'Exposure to', 'Fermentation', 'Frustration', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Immune system', 'Immunotherapeutic agent', 'Industry', 'Life', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Microfluidics', 'Modeling', 'Mutation', 'Organism', 'Outcome', 'Pathway Analysis', 'Pattern', 'Phenotype', 'Photosynthesis', 'Planet Earth', 'Process', 'Resistance', 'Shapes', 'Streptococcus pneumoniae', 'Stress', 'System', 'Testing', 'Time', 'Training', 'Yeasts', 'design', 'driving force', 'droplet sequencing', 'emerging antibiotic resistance', 'emerging antimicrobial resistance', 'experience', 'experimental study', 'genetic architecture', 'genome-wide', 'genomic tools', 'network architecture', 'novel', 'overexpression', 'pathogenic bacteria', 'predictive modeling', 'prevent', 'process optimization', 'programs', 'response', 'tool', 'trait', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transposon sequencing']",NIAID,BOSTON COLLEGE,R01,2020,391250,-0.016509445744707148
"Tools for Visualization of Geographic Structure in Population Genomic Data ﻿    DESCRIPTION (provided by applicant): Large samples sizes are increasingly common in genetics/genomics, particularly in human genetics where sample sizes must be large (>1,000s of individuals) to detect variant associations with complex disease traits. A common feature of data from large samples is that the individuals within the study have varying levels of similarity with one another that can become problematic for downstream analyses (e.g. causing spurious associations) if not understood. Thus uncovering population structure and dissecting it to understand its source is a common and important practice in large-scale studies. Here, we aim to solve challenges for visualizing population structure that regularly arise when researchers interact with large-scale population genomic data sets. In Aim 1 we will develop a software tool for visualizing population structure using principal components analysis (PCA). This tool will make straightforward several steps that are commonly reinvented by data scientists as they analyze PCA outputs from genetic data. It will also make more clear whether PCA analyses may be returning anomalous results. In Aim 2 we will develop a tool for producing geographic allele frequency maps of publicly available or user-generated allele frequency data. In Aim 3 we will develop a visualization approach for displaying geographic regions where populations show unexpectedly high or low levels of differentiation. In Aim 4 we will integrate these pieces of software into a single suite and link them to externally generated data sources and existing genome browsers. By developing these sets of tools we help to remove the need for unnecessary script generation by independent researchers and increase the pace of genomics research. Throughout the project we will pay special attention to developing user-friendly interactive data displays such as those generated by the Data Driven Documents (d3) JavaScript visualization libraries. Where possible we will use simple, yet flexible python backends and provide complementary R libraries to facilitate customizations and integration with existing analysis pipelines. While population genetic applications will motivate our work, the tools we are generating will be generally applicable to other forms of structured biomedical data. PUBLIC HEALTH RELEVANCE: This project will provide tools for visualizing large-scale genetic data with population structure. While numerous advanced algorithms for summarizing population structure exist, the human interface to the outputs of these methods is lacking and has become a time sink during the analysis of large samples. In this project we will provide user-friendly tools that lower the barrier to understanding genetic variation datasets. In particulr we will develop tools for visualizing compressed representations of genetic variation (i.e. PCA results) and how genetic diversity is distributed across geographic space in a sample.",Tools for Visualization of Geographic Structure in Population Genomic Data,9272843,U01CA198933,"['Address', 'Algorithms', 'Attention', 'Awareness', 'Big Data to Knowledge', 'Biological', 'Biological Process', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Display', 'Data Science', 'Data Set', 'Data Sources', 'Disease', 'Ensure', 'Exhibits', 'Frequencies', 'Funding', 'Gene Frequency', 'Generations', 'Genes', 'Genetic', 'Genetic Drift', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Geographic Distribution', 'Geographic Locations', 'Geography', 'Goals', 'Grant', 'Human', 'Human Genetics', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Libraries', 'Link', 'Manuscripts', 'Maps', 'Methods', 'Output', 'Paper', 'Pattern', 'Pharmacogenomics', 'Phenotype', 'Play', 'Population', 'Population Genetics', 'Preparation', 'Principal Component Analysis', 'Publications', 'Publishing', 'Pythons', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sample Size', 'Sampling', 'Sampling Studies', 'Software Tools', 'Source', 'Statistical Data Interpretation', 'Structure', 'Surface', 'Techniques', 'Time', 'Tissues', 'Uncertainty', 'Variant', 'Visualization software', 'Work', 'base', 'data visualization', 'digital', 'expectation', 'flexibility', 'genetic variant', 'genome browser', 'genome wide association study', 'genomic data', 'interest', 'migration', 'population based', 'public health relevance', 'tool', 'trait', 'transcriptome sequencing', 'user-friendly']",NCI,UNIVERSITY OF CHICAGO,U01,2017,409700,-0.04073916679322927
"Tools for Visualization of Geographic Structure in Population Genomic Data ﻿    DESCRIPTION (provided by applicant): Large samples sizes are increasingly common in genetics/genomics, particularly in human genetics where sample sizes must be large (>1,000s of individuals) to detect variant associations with complex disease traits. A common feature of data from large samples is that the individuals within the study have varying levels of similarity with one another that can become problematic for downstream analyses (e.g. causing spurious associations) if not understood. Thus uncovering population structure and dissecting it to understand its source is a common and important practice in large-scale studies. Here, we aim to solve challenges for visualizing population structure that regularly arise when researchers interact with large-scale population genomic data sets. In Aim 1 we will develop a software tool for visualizing population structure using principal components analysis (PCA). This tool will make straightforward several steps that are commonly reinvented by data scientists as they analyze PCA outputs from genetic data. It will also make more clear whether PCA analyses may be returning anomalous results. In Aim 2 we will develop a tool for producing geographic allele frequency maps of publicly available or user-generated allele frequency data. In Aim 3 we will develop a visualization approach for displaying geographic regions where populations show unexpectedly high or low levels of differentiation. In Aim 4 we will integrate these pieces of software into a single suite and link them to externally generated data sources and existing genome browsers. By developing these sets of tools we help to remove the need for unnecessary script generation by independent researchers and increase the pace of genomics research. Throughout the project we will pay special attention to developing user-friendly interactive data displays such as those generated by the Data Driven Documents (d3) JavaScript visualization libraries. Where possible we will use simple, yet flexible python backends and provide complementary R libraries to facilitate customizations and integration with existing analysis pipelines. While population genetic applications will motivate our work, the tools we are generating will be generally applicable to other forms of structured biomedical data. PUBLIC HEALTH RELEVANCE: This project will provide tools for visualizing large-scale genetic data with population structure. While numerous advanced algorithms for summarizing population structure exist, the human interface to the outputs of these methods is lacking and has become a time sink during the analysis of large samples. In this project we will provide user-friendly tools that lower the barrier to understanding genetic variation datasets. In particulr we will develop tools for visualizing compressed representations of genetic variation (i.e. PCA results) and how genetic diversity is distributed across geographic space in a sample.",Tools for Visualization of Geographic Structure in Population Genomic Data,9070657,U01CA198933,"['Address', 'Algorithms', 'Alleles', 'Attention', 'Base Sequence', 'Big Data to Knowledge', 'Biological', 'Biological Process', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Display', 'Data Science', 'Data Set', 'Data Sources', 'Disease', 'Ensure', 'Exhibits', 'Frequencies', 'Funding', 'Gene Frequency', 'Generations', 'Genes', 'Genetic', 'Genetic Drift', 'Genetic Variation', 'Genetic study', 'Genomics', 'Genotype', 'Geographic Distribution', 'Geographic Locations', 'Geography', 'Goals', 'Grant', 'Health', 'Human', 'Human Genetics', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Libraries', 'Link', 'Manuscripts', 'Maps', 'Methods', 'Output', 'Paper', 'Pattern', 'Pharmacogenomics', 'Phenotype', 'Play', 'Population', 'Population Genetics', 'Preparation', 'Principal Component Analysis', 'Printing', 'Publications', 'Publishing', 'Pythons', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sample Size', 'Sampling', 'Sampling Studies', 'Shapes', 'Software Tools', 'Source', 'Staging', 'Structure', 'Surface', 'Techniques', 'Time', 'Tissues', 'Uncertainty', 'Variant', 'Work', 'data visualization', 'digital', 'expectation', 'flexibility', 'genetic variant', 'genome browser', 'genome sequencing', 'genome wide association study', 'genomic data', 'interest', 'migration', 'population based', 'tool', 'trait', 'transcriptome sequencing', 'user-friendly']",NCI,UNIVERSITY OF CHICAGO,U01,2016,409700,-0.04073916679322927
"Tools for Visualization of Geographic Structure in Population Genomic Data ﻿    DESCRIPTION (provided by applicant): Large samples sizes are increasingly common in genetics/genomics, particularly in human genetics where sample sizes must be large (>1,000s of individuals) to detect variant associations with complex disease traits. A common feature of data from large samples is that the individuals within the study have varying levels of similarity with one another that can become problematic for downstream analyses (e.g. causing spurious associations) if not understood. Thus uncovering population structure and dissecting it to understand its source is a common and important practice in large-scale studies. Here, we aim to solve challenges for visualizing population structure that regularly arise when researchers interact with large-scale population genomic data sets. In Aim 1 we will develop a software tool for visualizing population structure using principal components analysis (PCA). This tool will make straightforward several steps that are commonly reinvented by data scientists as they analyze PCA outputs from genetic data. It will also make more clear whether PCA analyses may be returning anomalous results. In Aim 2 we will develop a tool for producing geographic allele frequency maps of publicly available or user-generated allele frequency data. In Aim 3 we will develop a visualization approach for displaying geographic regions where populations show unexpectedly high or low levels of differentiation. In Aim 4 we will integrate these pieces of software into a single suite and link them to externally generated data sources and existing genome browsers. By developing these sets of tools we help to remove the need for unnecessary script generation by independent researchers and increase the pace of genomics research. Throughout the project we will pay special attention to developing user-friendly interactive data displays such as those generated by the Data Driven Documents (d3) JavaScript visualization libraries. Where possible we will use simple, yet flexible python backends and provide complementary R libraries to facilitate customizations and integration with existing analysis pipelines. While population genetic applications will motivate our work, the tools we are generating will be generally applicable to other forms of structured biomedical data.        PUBLIC HEALTH RELEVANCE: This project will provide tools for visualizing large-scale genetic data with population structure. While numerous advanced algorithms for summarizing population structure exist, the human interface to the outputs of these methods is lacking and has become a time sink during the analysis of large samples. In this project we will provide user-friendly tools that lower the barrier to understanding genetic variation datasets. In particulr we will develop tools for visualizing compressed representations of genetic variation (i.e. PCA results) and how genetic diversity is distributed across geographic space in a sample.            ",Tools for Visualization of Geographic Structure in Population Genomic Data,8876141,U01CA198933,"['Address', 'Algorithms', 'Alleles', 'Attention', 'Base Sequence', 'Biological', 'Biological Process', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Display', 'Data Set', 'Data Sources', 'Disease', 'Ensure', 'Exhibits', 'Frequencies', 'Funding', 'Gene Frequency', 'Generations', 'Genes', 'Genetic', 'Genetic Drift', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Geographic Distribution', 'Geographic Locations', 'Geography', 'Goals', 'Grant', 'Human', 'Human Genetics', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Libraries', 'Link', 'Manuscripts', 'Maps', 'Methods', 'Output', 'Paper', 'Pattern', 'Pharmacogenomics', 'Phenotype', 'Play', 'Population', 'Population Genetics', 'Preparation', 'Principal Component Analysis', 'Printing', 'Publications', 'Publishing', 'Pythons', 'Quality Control', 'RNA Sequences', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sample Size', 'Sampling', 'Sampling Studies', 'Scientist', 'Shapes', 'Software Tools', 'Source', 'Staging', 'Structure', 'Surface', 'Techniques', 'Time', 'Tissues', 'Uncertainty', 'Variant', 'Work', 'data visualization', 'digital', 'expectation', 'flexibility', 'genetic variant', 'genome sequencing', 'genome wide association study', 'interest', 'migration', 'population based', 'public health relevance', 'tool', 'trait', 'transcriptome sequencing', 'user-friendly']",NCI,UNIVERSITY OF CHICAGO,U01,2015,360853,-0.04073916679322927
"New instrument and methods for fast, diagnostic-quality histology of un-embedded bone marrow and lymph node specimens Project Summary Over 600,000 bone marrow biopsies are performed every year in the United States, while hundreds of thousands more lymph node biospies are performed. Histological evaluation of these biopsies is a critical component of care for hematologic diseases including leukemia, lymphoma, myelodysplastic syndrome, myeloproliferative disease and non-neoplastic conditions such as viral infections and autoimmune conditions.  We have developed a platform that we consider a paradigm shift in the histologic examination of tissues. It is based on a new chemical process, imaging, and image processing approach that we have dubbed Clearing Histology with MultiPhoton microscopy (CHiMP).The CHiMP technology enables visual analysis of entire intact, un-embedded and uncut specimens within a short time-frame and with a resolution that is amenable to primary diagnosis. The significant clinical benefits include: 1) potential for same-day diagnosis, 2) labor and cost savings, 3) access to 3D perspective, 4) increased visual data from same specimen, 5) complete tissue preservation for ancillary studies such as DNA analysis and 6) inherent benefits of digital data such as reduced risk of loss, ready remote review by experts, and amenability to machine learning tools. Hematopoietic tissue evaluation would similarly benefit from these advantages, but unfortunately the systems developed thus far lack the resolution typically needed for visual examination of hematopoietic tissues.  For this Phase I SBIR proposal, an objective is to develop customized optics to improve the resolution of our current microscopes and thereby enable use in the specialized field of hematology. Commercially available objective lenses that are compatible with our immersion medium are either limited to numerical apertures (NA) that are less than one, affecting resolution and image quality, or have insufficient working distances for imaging past the coverslip and surface roughness to obtain complete sections. We will design and test a custom objective lens with high NA and long working distance, suited for our proprietary reagents. Integrating such a lens into our microscope will also require the design of a custom scan lens, custom beam conditioning optics, and a custom polygon scanner.  An associated goal is to develop a novel approach to preparing bone marrow aspiration specimens that will make them amenable to imaging with CHiMP, potentially reducing the need for core biopsies by permitting unambiguous morphologic categorization of cell subtypes in their architectural context, without the routine need for immunohistochemistry, and while preserving nucleic acids for molecular/genetic evaluation. Project Narrative Applikate Technologies has developed a powerful platform for histological evaluation of tissue called Clearing Histology with MultiPhoton Microscopy, or CHiMP. This platform has many advantages over traditional approaches, including same-day turn-around, reduced labor costs, preservation of tissue for DNA analysis, and direct-to-digital imaging for ease of consultation with remote experts. This proposal seeks to develop custom optics to enable very-high-resolution imaging of bone marrow and lymph node samples that are critical for diagnosing diseases such as leukemia and lymphoma.","New instrument and methods for fast, diagnostic-quality histology of un-embedded bone marrow and lymph node specimens",9677952,R43CA235890,"['3-Dimensional', 'Address', 'Adoption', 'Affect', 'Ancillary Study', 'Antigens', 'Architecture', 'Aspirate substance', 'Autoimmune Diseases', 'Autoimmune Process', 'Biopsy', 'Blinded', 'Bone Marrow', 'Bone Marrow Aspiration', 'Bone marrow biopsy', 'Caring', 'Cells', 'Chemicals', 'Chronic', 'Clinical', 'Clinical Data', 'Communicable Diseases', 'Consultations', 'Consumption', 'Core Biopsy', 'Cost Savings', 'Custom', 'DNA', 'DNA analysis', 'Data', 'Decalcification', 'Diagnosis', 'Diagnostic', 'Disease', 'Dysmyelopoietic Syndromes', 'Evaluation', 'Fibrosis', 'Goals', 'Hematological Disease', 'Hematology', 'Hematopathology', 'Histologic', 'Histology', 'Image', 'Imagery', 'Immersion Investigative Technique', 'Immunohistochemistry', 'Iron', 'Lateral', 'Lymph', 'Machine Learning', 'Marrow', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Molecular Genetics', 'Morphologic artifacts', 'Morphology', 'Myeloproliferative disease', 'Nucleic Acids', 'Optics', 'Pan Genus', 'Pathologist', 'Pathology', 'Phase', 'Preparation', 'Process', 'Protocols documentation', 'RNA', 'Reagent', 'Recovery', 'Resolution', 'Risk', 'Sampling', 'Scanning', 'Slice', 'Slide', 'Small Business Innovation Research Grant', 'Specimen', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Preservation', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'United States', 'Virus Diseases', 'Visual', 'Waxes', 'Work', 'base', 'bone imaging', 'conditioning', 'cost', 'design', 'digital', 'digital imaging', 'disease diagnosis', 'hematopoietic tissue', 'high resolution imaging', 'image processing', 'improved', 'instrument', 'lens', 'leukemia/lymphoma', 'lymph nodes', 'medical specialties', 'multiphoton microscopy', 'nanoparticle', 'novel', 'novel strategies', 'particle', 'pre-clinical', 'preservation', 'second harmonic', 'tool', 'whole slide imaging']",NCI,"APPLIKATE TECHNOLOGIES, LLC",R43,2019,224713,0.0003413600344878859
"Fluorescence tomography plugin unit for spatial monitoring of T cell migration Immunotherapy (IMT) is a cancer treatment that harnesses activated T cells to induce a targeted immune response against the cancer. Preclinical IMT research has been limited because there are no effective methods to longitudinally image T cell biodistribution in mouse models, including ovarian cancer. This is an urgent unmet need because the only viable methods to monitor activated T cells, the immune marker most associated with antitumor response and prognosis, immunohistochemistry and FACs, are both terminal and ex vivo. Fluorescence imaging (FLi) offers many advantages for monitoring T cell migration, including the relatively long photostability of fluorescent ligands, ease of use, and its low cost. However, FLi does not provide 3D spatial maps of fluorescent reporters due to diffuse light propagation in animal tissue. In addition, fluorescence intensities on the tissue surface also depend on the animal’s size, pose, and shape and, hence, limit quantification and reproducibility. Last, there is no anatomical reference that also provides a template for automated organ delineation along with T cell biodistribution analysis. Therefore, InVivo Analytics seeks funding to develop InVivoFLUOR, an automated data analysis tool for 3D fluorescence tomography (FLt) of mouse models. InVivoFLUOR is comprised of: a Body Conforming Animal Mold (BCAM) for multi-source transillumination FLt and spatial registration of the animal’s geometry and pose; an Organ Probability Map (OPM) for providing an organ template; and a cloud-based FLt algorithm. We will demonstrate its feasibility on an IMT example for determining the spatial biodistribution of fluorescence-labeled T cells and, in combination with bioluminescence imaging (BLi), will compare localization of ovarian cancer cells. In Aim 1 we will confirm the ability to quantitatively determine fluorescent targets inside a small animal. The spatial distribution of known fluorescent targets will be reconstructed and compared to ex vivo data. In Aim 2 we will confirm the ability to determine the in vivo T cell biodistribution at tumor sites. The fluorescence-labeled T cell distribution will be calculated and coregistered to the anatomy based on the OPM and to disseminated ovarian tumors. The ability to instantaneously quantify the T cell distribution in the same animal longitudinally, as opposed to sacrificing a different animal at every time point for T cell counting via FACS or histology, neither of which can identify sites where the activated T cells may be “hiding”, has an impact on the development of and outcome of new IMTs with high accuracy. InVivoFLUOR will enable cross-platform data comparison and analysis, eliminate operator-dependent variability, increase data reproducibility, and will facilitate the translation of new therapeutics. The successful completion of the proposed project will help to commercialize InVivoFLUOR and will find immediate application in the pharmaceutical industry for rapid development of novel IMTs. InVivo Analytics seeks funding for demonstrating the feasibility for mapping the 3D spatial biodistribution of fluorescent T cells in a small animal model of ovarian cancer. Analysis of T cell migration currently lacks the ability to obtain 3D spatial maps of T cells in the same animal in longitudinal studies. Therefore, InVivo Analytics will develop a 3D fluorescence tomography and data analysis tool, which can quantify T cell migration in the living animal, thereby allowing accurate monitoring of novel immunotherapies.",Fluorescence tomography plugin unit for spatial monitoring of T cell migration,9846612,R43CA243827,"['3-Dimensional', 'Algorithms', 'Anatomy', 'Animal Model', 'Animals', 'Antitumor Response', 'Atlases', 'Attenuated', 'Biodistribution', 'Bioluminescence', 'Biotechnology', 'Cell Count', 'Cells', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diffuse', 'Drug Industry', 'Fluorescence', 'Funding', 'Geometry', 'Goals', 'Growth', 'Histology', 'Human Resources', 'Image', 'Image Analysis', 'Immune Targeting', 'Immune response', 'Immunohistochemistry', 'Immunologic Markers', 'Immunotherapy', 'Institution', 'Knowledge', 'Label', 'Ligands', 'Light', 'Location', 'Longitudinal Studies', 'Malignant Neoplasms', 'Malignant neoplasm of ovary', 'Maps', 'Methods', 'Molds', 'Monitor', 'Mus', 'Optics', 'Organ', 'Outcome', 'Positron-Emission Tomography', 'Preclinical Testing', 'Probability', 'Property', 'Radioisotopes', 'Radiolabeled', 'Reporter', 'Reproducibility', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Site', 'Source', 'Spatial Distribution', 'Surface', 'T-Lymphocyte', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Transillumination', 'Translations', 'Treatment outcome', 'animal tissue', 'base', 'bioluminescence imaging', 'cancer cell', 'cancer therapy', 'cell motility', 'cloud based', 'commercial application', 'cost', 'digital', 'fluorescence imaging', 'fluorophore', 'imaging system', 'improved', 'in vivo', 'machine learning algorithm', 'mouse model', 'novel', 'novel therapeutics', 'optical imaging', 'outcome forecast', 'ovarian neoplasm', 'pre-clinical', 'serial imaging', 'tomography', 'tool', 'tumor']",NCI,"IN VIVO ANALYTICS, INC.",R43,2019,222435,-0.014786469064941249
"Functional Cancer Cell Maps FUNCTIONAL CANCER CELL MAPS SUMMARY I am currently an Academic Program Officer in Prof. Trey Ideker’s lab at UC San Diego. My title reflects the varied roles I play in the Ideker Lab, both scientifically and administratively, as I also serve as the Assistant Director of the Cancer Cell Map Initiative (CCMI) and the San Diego Center for Systems Biology (SDCSB). I am involved in a wide range of research projects, both within the Ideker Lab and across the various Centers. Central though to many of these efforts is the role I play supervising a number of projects using the CRISPR/Cas9­based approach to map genetic interactions in cancer cells. These functional maps can be used to identify protein complexes and pathways in cancer cells and to reveal genetic dependencies that might be therapeutically tractable. These studies will also provide us with the necessary training data to build “visible” AIs, machine learning models that not only make accurate predictions but also provide mechanistic insights. FUNCTIONAL CANCER CELL MAPS NARRATIVE Many cancers in adults are caused by mutations acquired over time. Research in both the Ideker Lab and the Cancer Cell Map Initiative seek to understand how these mutations alter the function of proteins leading to cancer using a variety of biochemical, genetic and computational approaches. We are particularly interested in understanding how combinations of mutated genes can disrupt normal cell physiology as knowing about these mechanisms can help us identify new drug targets or biomarkers.",Functional Cancer Cell Maps,10016231,R50CA243885,"['Adult', 'Biochemical Genetics', 'Biological Markers', 'CRISPR/Cas technology', 'Cell physiology', 'Data', 'Dependence', 'Genes', 'Genetic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutate', 'Mutation', 'Normal Cell', 'Pathway interactions', 'Play', 'Research', 'Research Project Grants', 'Role', 'Supervision', 'Systems Biology', 'Therapeutic', 'Time', 'Training', 'academic program', 'base', 'cancer cell', 'insight', 'interest', 'new therapeutic target', 'protein complex', 'protein function']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R50,2020,126700,-0.03591834633281236
"Functional Cancer Cell Maps FUNCTIONAL CANCER CELL MAPS SUMMARY I am currently an Academic Program Officer in Prof. Trey Ideker’s lab at UC San Diego. My title reflects the varied roles I play in the Ideker Lab, both scientifically and administratively, as I also serve as the Assistant Director of the Cancer Cell Map Initiative (CCMI) and the San Diego Center for Systems Biology (SDCSB). I am involved in a wide range of research projects, both within the Ideker Lab and across the various Centers. Central though to many of these efforts is the role I play supervising a number of projects using the CRISPR/Cas9­based approach to map genetic interactions in cancer cells. These functional maps can be used to identify protein complexes and pathways in cancer cells and to reveal genetic dependencies that might be therapeutically tractable. These studies will also provide us with the necessary training data to build “visible” AIs, machine learning models that not only make accurate predictions but also provide mechanistic insights. FUNCTIONAL CANCER CELL MAPS NARRATIVE Many cancers in adults are caused by mutations acquired over time. Research in both the Ideker Lab and the Cancer Cell Map Initiative seek to understand how these mutations alter the function of proteins leading to cancer using a variety of biochemical, genetic and computational approaches. We are particularly interested in understanding how combinations of mutated genes can disrupt normal cell physiology as knowing about these mechanisms can help us identify new drug targets or biomarkers.",Functional Cancer Cell Maps,9849989,R50CA243885,"['Adult', 'Biochemical Genetics', 'Biological Markers', 'CRISPR/Cas technology', 'Cell physiology', 'Data', 'Dependence', 'Genes', 'Genetic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Modeling', 'Mutate', 'Mutation', 'Normal Cell', 'Pathway interactions', 'Play', 'Research', 'Research Project Grants', 'Role', 'Supervision', 'Systems Biology', 'Therapeutic', 'Time', 'Training', 'academic program', 'base', 'cancer cell', 'insight', 'interest', 'new therapeutic target', 'protein complex', 'protein function']",NCI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R50,2019,126633,-0.03591834633281236
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,9893208,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human body', 'Image', 'Image Analysis', 'Imagery', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed\xa0imaging', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2019,587413,0.02195149651445417
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,10246250,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Visualization', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed imaging', 'multiscale data', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'three-dimensional visualization', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2020,750000,0.02195149651445417
"A robust platform for multiplexed, subcellular proteomic imaging in human tissue Project Summary Multiplexed Ion Beam Imaging by Time of Flight (MIBI-TOF) uses secondary ion mass spectrometry and metal conjugated primary antibodies to simultaneously visualize dozens of proteins at subcellular resolution in a single tissue section. This technology is back compatible with archival formalin fixed, paraffin embedded tissue (FFPE) and has been used in peer-reviewed work to simultaneously visualize and quantify 36 proteins in retrospective human tissue cohorts. In line with the stated goals of the HuBMAP consortium to develop both “High-sensitivity, high-resolution imaging techniques that can rapidly provide spectral data over large areas of tissue” and “Quantitative imaging analysis tools, including automated 3D image segmentation, feature extraction, and image annotation,” the work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease. To achieve this, we will validate 100 FFPE antibodies and optimize ready-to-use multiplexed staining panels in lyophilized format that will permit storage for at least two years. Protocols and reagents for multiplexed signal amplification of protein and mRNA targets will be further refined, while next generation instrumentation will increase sample throughput to permit full tissue section imaging of up to 40 proteins in 1 hour. Standardized reagents and more robust instrumentation will be accompanied by an automated computational pipeline that utilizes a standard set of segmentation markers and machine learning to accurately identify nuclei and cell borders in any non-neural human tissue. This data will be used to cluster single cell events into functionally distinct populations according to morphology, protein expression, and histological distribution. The reagents and computational pipeline proposed here synergize with existing HuBMAP-funded platforms and could be readily generalized to virtually any high dimensional imaging modality. Thus, this work will not only provide a practical, back compatible imaging platform for high throughput multiplexed imaging, but will also accelerate development of other complimentary imaging technologies as well. Project Narrative Multiplexed ion beam imaging by time of flight (MIBI-TOF) is a new technology for visualizing dozens of proteins in standard clinical tissue biopsies at high resolution. The work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease.","A robust platform for multiplexed, subcellular proteomic imaging in human tissue",9894465,UH3CA246633,"['Allergic', 'Antibodies', 'Archives', 'Area', 'Atlases', 'Back', 'Basic Science', 'Biopsy', 'Cell Nucleus', 'Cells', 'Clinical', 'Cloud Computing', 'Communities', 'Data', 'Data Set', 'Decidua', 'Development', 'Disease', 'Equipment', 'Event', 'Extramural Activities', 'Feedback', 'First Pregnancy Trimester', 'Formalin', 'Foundations', 'Freeze Drying', 'Funding', 'Goals', 'Granuloma', 'Health', 'Hippocampus (Brain)', 'Histologic', 'Hour', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Immune', 'Immunosuppression', 'Individual', 'Institutes', 'Ions', 'Letters', 'Link', 'Machine Learning', 'Medical center', 'Messenger RNA', 'Metals', 'Morphology', 'Multiplexed Ion Beam Imaging', 'Noninfiltrating Intraductal Carcinoma', 'Optics', 'Organ', 'Paraffin Embedding', 'Pathology', 'Peer Review', 'Phenotype', 'Population', 'Proteins', 'Proteomics', 'Protocols documentation', 'Pulmonary Tuberculosis', 'Readiness', 'Reagent', 'Reproducibility', 'Resolution', 'Resources', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Spectrometry, Mass, Secondary Ion', 'Stains', 'Standardization', 'Structure', 'Technology', 'Three-Dimensional Image', 'Time', 'Tissue Embedding', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Work', 'cancer immunotherapy', 'cohort', 'computational platform', 'computerized tools', 'design', 'graphical user interface', 'high dimensionality', 'high resolution imaging', 'human imaging', 'human tissue', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'insight', 'instrumentation', 'ion source', 'learning strategy', 'multiplexed\xa0imaging', 'new technology', 'next generation', 'programs', 'protein expression', 'quantitative imaging', 'reagent standardization', 'technology validation', 'tool', 'tumor microenvironment', 'user-friendly', 'virtual']",NCI,STANFORD UNIVERSITY,UH3,2019,590000,0.00041041782804408734
"A robust platform for multiplexed, subcellular proteomic imaging in human tissue Project Summary Multiplexed Ion Beam Imaging by Time of Flight (MIBI-TOF) uses secondary ion mass spectrometry and metal conjugated primary antibodies to simultaneously visualize dozens of proteins at subcellular resolution in a single tissue section. This technology is back compatible with archival formalin fixed, paraffin embedded tissue (FFPE) and has been used in peer-reviewed work to simultaneously visualize and quantify 36 proteins in retrospective human tissue cohorts. In line with the stated goals of the HuBMAP consortium to develop both “High-sensitivity, high-resolution imaging techniques that can rapidly provide spectral data over large areas of tissue” and “Quantitative imaging analysis tools, including automated 3D image segmentation, feature extraction, and image annotation,” the work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease. To achieve this, we will validate 100 FFPE antibodies and optimize ready-to-use multiplexed staining panels in lyophilized format that will permit storage for at least two years. Protocols and reagents for multiplexed signal amplification of protein and mRNA targets will be further refined, while next generation instrumentation will increase sample throughput to permit full tissue section imaging of up to 40 proteins in 1 hour. Standardized reagents and more robust instrumentation will be accompanied by an automated computational pipeline that utilizes a standard set of segmentation markers and machine learning to accurately identify nuclei and cell borders in any non-neural human tissue. This data will be used to cluster single cell events into functionally distinct populations according to morphology, protein expression, and histological distribution. The reagents and computational pipeline proposed here synergize with existing HuBMAP-funded platforms and could be readily generalized to virtually any high dimensional imaging modality. Thus, this work will not only provide a practical, back compatible imaging platform for high throughput multiplexed imaging, but will also accelerate development of other complimentary imaging technologies as well. Project Narrative Multiplexed ion beam imaging by time of flight (MIBI-TOF) is a new technology for visualizing dozens of proteins in standard clinical tissue biopsies at high resolution. The work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease.","A robust platform for multiplexed, subcellular proteomic imaging in human tissue",10231018,UH3CA246633,"['Allergic', 'Antibodies', 'Archives', 'Area', 'Back', 'Basic Science', 'Biopsy', 'Cell Nucleus', 'Cells', 'Clinical', 'Cloud Computing', 'Communities', 'Data', 'Data Set', 'Decidua', 'Development', 'Disease', 'Equipment', 'Event', 'Extramural Activities', 'Feedback', 'First Pregnancy Trimester', 'Formalin', 'Foundations', 'Freeze Drying', 'Funding', 'Goals', 'Granuloma', 'Health', 'Hippocampus (Brain)', 'Histologic', 'Hour', 'Human', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Imaging technology', 'Immune', 'Immunosuppression', 'Individual', 'Institutes', 'Ions', 'Letters', 'Link', 'Machine Learning', 'Medical center', 'Messenger RNA', 'Metals', 'Morphology', 'Multiplexed Ion Beam Imaging', 'Noninfiltrating Intraductal Carcinoma', 'Optics', 'Organ', 'Paraffin Embedding', 'Pathology', 'Peer Review', 'Phenotype', 'Population', 'Proteins', 'Proteomics', 'Protocols documentation', 'Pulmonary Tuberculosis', 'Readiness', 'Reagent', 'Reproducibility', 'Resolution', 'Resources', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Spectrometry, Mass, Secondary Ion', 'Stains', 'Standardization', 'Structure', 'Technology', 'Three-Dimensional Image', 'Time', 'Tissue Embedding', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Work', 'cancer immunotherapy', 'cohort', 'computational pipelines', 'computational platform', 'computerized tools', 'design', 'feature extraction', 'graphical user interface', 'high dimensionality', 'high resolution imaging', 'human imaging', 'human tissue', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'insight', 'instrumentation', 'ion source', 'machine learning method', 'multiplexed imaging', 'new technology', 'next generation', 'protein expression', 'quantitative imaging', 'reagent standardization', 'technology validation', 'tool', 'tumor microenvironment', 'user-friendly', 'virtual']",NCI,STANFORD UNIVERSITY,UH3,2020,700000,0.00041041782804408734
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,10026443,UH3CA255132,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NCI,PURDUE UNIVERSITY,UH3,2020,630000,-0.002232322628907752
"In situ transcriptome profiling in single cells Summary We have recently developed intron seqFISH (sequential Fluorescence in situ hybridization) to multiplex 10,421 genes directly in single cells. We showed that the 10,421 gene nascent transcriptome profile can identify cell types as well as capture the trajectory of the cells. We further demonstrated that we can perform mRNA seqFISH as well as immunostaining in the same cells following the 10,421 gene intron seqFISH measurement. We propose to develop this technology as a potential alternative approach to single cell RNAseq for the HuBMAP to characterize cell types directly in situ in tissues. In particular, we will adept in situ amplification methods such as hybridization chain reaction (HCR) to intron seqFISH. We had previously shown that mRNA seqFISH with HCR amplification performs exceptionally in tissues in overcoming autofluorescence background and enable robust decoding seqFISH barcodes. We will validate the integrated intron and mRNA seqFISH protocol in the mouse hippocampus in the UG3 phase of the project. Also in UG3 phase, we will develop computational tools to integrate intron seqFISH data with mRNA seqFISH as well as single cell RNAseq data. In the UH3 phase, we will translate the technology to human tissues, with a focus on human mammary tissues provided by Dr. Seewaldt at City of Hope. We will also work with the tissue mapping centers in the HuBMAP program to accelerate the translation of this technology to many tissue types. In the UH3 phase, we will generate million cell spatial atlas of human tissues containing intron profiles, mRNA profiles and protein abundances in each single cell. We will further develop computational tools to analyze for spatial enrichment of genes in the tissue and generate a pseudotime of developmental trajectories using the nascent transcriptome data. Taken together, we will develop a high throughput in situ imaging based platform to characterize cell types and future trajectories of cells using intron and mRNA seqFISH technologies. Narrative Transcriptome profiling in situ at the single cell level has transformative potential for understanding healthy versus diseased tissues in the human body. We propose an integrative approach profiling the nascent transcriptome as well as hundreds of mature transcripts in single cells in tissues. We will generate million cell spatial atlas for the mouse hippocampus as well as the human mammary tissue. We will gain unprecedented insight into the developmental of neurons in the brain as well as the duct cells in the breast. At the same time we will develop the computational tools to analyze the spatial genomics data.",In situ transcriptome profiling in single cells,10026445,UH3CA255134,"['Algorithms', 'Animals', 'Atlases', 'Bar Codes', 'Biology', 'Biopsy Specimen', 'Brain', 'Breast', 'Cell Differentiation process', 'Cells', 'Cities', 'Data', 'Data Set', 'Development', 'Disease', 'Ductal Epithelial Cell', 'Epigenetic Process', 'Epithelial', 'Epithelial-Stromal Communication', 'Epithelium', 'Expression Profiling', 'Fluorescent in Situ Hybridization', 'Future', 'Gene Expression', 'Genes', 'Goals', 'Hippocampus (Brain)', 'Human', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'In Situ', 'Introns', 'Letters', 'Machine Learning', 'Mammary Gland Parenchyma', 'Mammary gland', 'Maps', 'Measurement', 'Messenger RNA', 'Methods', 'Mus', 'Natural regeneration', 'Neuroglia', 'Neurons', 'Nuclear Structure', 'Pattern', 'Phase', 'Play', 'Positioning Attribute', 'Process', 'Proteins', 'Protocols documentation', 'Publications', 'Publishing', 'Radial', 'Reaction', 'Role', 'Signal Transduction', 'Slice', 'Speed', 'Stains', 'Standardization', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Transcript', 'Translating', 'Translations', 'Validation', 'Weight', 'Work', 'base', 'cell type', 'combinatorial', 'computerized tools', 'dentate gyrus', 'genomic data', 'granule cell', 'human tissue', 'imaging system', 'in situ imaging', 'insight', 'internal control', 'mammary epithelium', 'markov model', 'programs', 'sample fixation', 'scale up', 'single molecule', 'single-cell RNA sequencing', 'tool', 'transcriptome']",NCI,CALIFORNIA INSTITUTE OF TECHNOLOGY,UH3,2020,400000,0.00563431317047119
"Multimodal mass spectrometry imaging of mouse and human liver We propose to develop a multimodal mass spectrometry imaging pipeline with novel desorption sources and data integration that will enable simultaneously mapping of biomolecule abundance in 3-dimensions in biological tissues at high spatial resolution (micron to submicron) and high speed (>10 ms/pixel) in a near-native environment. This would provide previously inaccessible information on cellular and tissue organization, and how homeostasis and disease intersect at the level of tissue physiology. A major challenge for performing multi- omics using mass spectrometry imaging has been the (i) lack of universal ionization methods, (ii) limited sample preparation protocols for preserving chemical gradients, (iii) low sensitivity, and (iv) limited tools for integration of large quantities of data. Our laboratories are developing systematic MS imaging for high sensitivity and high resolution analysis of diverse tissues. We discovered that water-based gas cluster ion beams (H2O-GCIB) operating at high energy yield ionization enhancements of multiple biomolecules (e.g., metabolites, lipids, and peptides/protein fragments) with high sensitivity at 1 µm lateral resolution and without labeling or complicated sample preparation. Coupled with unique Secondary Ion Mass Spectrometry (SIMS) instrumentation and cryogenic sample handling, we have imaged biomolecules directly in cells and tissues in a near-native state (i.e., frozen-hydration) with feature resolution of 1-10 µm. Low concentration biomolecules (e.g. cardiolipin and metabolites) that were impossible to localize in single cells previously are now visible with 3-dimensional localization. Moreover, the sufficient signal per pixel, we can use automated data analysis to characterize biologically active functional sites within 1 µm2 and areas of interest in single cells. We further developed data integration methods to combine imaging data from adjacent sections to create a multi-model imaging data sets. We propose to develop a pipeline for MS imaging analysis of biomolecules, and to elucidate molecular heterogeneity in tissues using multimodal imaging. To support the multi-modal analysis pipeline, we will develop an integrated data analysis platform. Integration of multiomics remains challenging, particularly spatially localize multiple biomolecules at single cell level. The direct visualization of cellular contents provides information on biomolecular composition, interactions and functions. This network of biomolecules is the driving force of specific behavior of cells in physiological states. Despite this, a comprehensive grasp of these interactions at cellular level has not moved beyond segregated methods. Our efforts will result in an integrated multimodal imaging platform to summon the best characteristics of each image form, acquiring a complete picture the biomolecular network at spatial resolution of 1 µm. With this direct visualization, we will address how metabolism links with functional biomarkers that stem from metabolism-associated protein complexes and phase-separated membrane-less organelles at the subcellular level, and how this drive different cell death modalities, including different modes of cell death. We propose to develop a new mass spectrometry imaging pipeline that will enable mapping of biomolecules in in biological tissues at high spatial resolution. This will provide previously inaccessible information on cellular and tissue organization, and how homeostasis and disease intersect at the level of tissue physiology.",Multimodal mass spectrometry imaging of mouse and human liver,10118811,UG3CA256962,"['3-Dimensional', 'Active Sites', 'Address', 'Age', 'Algorithms', 'Apoptosis', 'Area', 'Atlases', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Blood', 'Brain', 'Cardiolipins', 'Cell Death', 'Cells', 'Characteristics', 'Chemicals', 'Chemistry', 'Computer Vision Systems', 'Coupled', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Electrospray Ionization', 'Environment', 'Eosine Yellowish', 'Freezing', 'Gases', 'Genetic Transcription', 'Health', 'Heart', 'Heterogeneity', 'Homeostasis', 'Human', 'Hydration status', 'Image', 'Immunohistochemistry', 'Individual', 'Ions', 'Kidney', 'Knowledge', 'Label', 'Laboratories', 'Lateral', 'Link', 'Lipids', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Mass Spectrum Analysis', 'Membrane', 'Messenger RNA', 'Metabolic Marker', 'Metabolism', 'Methods', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Morphology', 'Multimodal Imaging', 'Mus', 'Optics', 'Organelles', 'Peptides', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physiological', 'Physiology', 'Preparation', 'Primary carcinoma of the liver cells', 'Protein Fragment', 'Protocols documentation', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Spectrometry, Mass, Secondary Ion', 'Speed', 'Technology', 'Time', 'Tissue imaging', 'Tissues', 'Transcript', 'Visualization', 'Water', 'analysis pipeline', 'base', 'cell behavior', 'cell type', 'cryogenics', 'data analysis pipeline', 'data integration', 'data mining', 'data visualization', 'driving force', 'experimental study', 'grasp', 'high resolution imaging', 'human tissue', 'image reconstruction', 'imaging platform', 'improved', 'insight', 'instrumentation', 'interest', 'ionization', 'ionization technique', 'molecular imaging', 'multimodality', 'multiple omics', 'novel', 'preservation', 'protein complex', 'reconstruction', 'single-cell RNA sequencing', 'stem', 'submicron', 'tool', 'tumorigenesis']",NCI,COLUMBIA UNIV NEW YORK MORNINGSIDE,UG3,2020,300000,0.02514779059217513
"Support for New Bioinformatics Methods Development New bioinformatics method development support includes, image analysis for glyphosate toxicity where deep-learning based image processing tmethods were used to discriminate between normal, stressed and cell-death conditions of HepaRG cells and primary hepatocytes; Evidence tagging protocols were develop for evidence mapping for the OHAT group;  an evaluation of existing tagging methods was performed currently available in the SWIFT-Review program; Machine Learning methods were used for Document tagging activity exploring alternative to the keyword-based tagging strategy currently used in SWIFT-Review. n/a",Support for New Bioinformatics Methods Development,10281443,73201700001C,"['Bioinformatics', 'Cell Death', 'Cells', 'Chemical Exposure', 'Chemicals', 'Contractor', 'DNA Sequence', 'Development', 'Evaluation', 'Genes', 'Hepatocyte', 'Image Analysis', 'Measures', 'Methods', 'Output', 'Program Reviews', 'Programming Languages', 'Protocols documentation', 'Sampling', 'Series', 'Specific qualifier value', 'Stress', 'Toxic effect', 'base', 'bioinformatics tool', 'deep learning', 'differential expression', 'glyphosate', 'image processing', 'machine learning method', 'method development', 'programs', 'transcriptomics']",NIEHS,"SCIOME, LLC",N01,2020,210270,0.012374880401824575
"NINDS MAP PHASE II: AN INFORMATICS TOOL FOR EVALUATING THE NINDS RESEARCH PORTFO The National Institute of Neurological Disorders and Stroke (NINDS), an Institute within the National Institutes of Health (NIH), recently funded a research categorization tool that uses Topic Modeling to perform text-based categorization of NIH grants, and a large scale graphing algorithm to display these them on a map organized spatially into their best-fit categories. This interactive tool is available to the public at http://www.nihmaps.org/. This contract is for hosting service and consultation for topic modeling and mapping software application. n/a",NINDS MAP PHASE II: AN INFORMATICS TOOL FOR EVALUATING THE NINDS RESEARCH PORTFO,7977305,71200900244P,[' '],NINDS,UNIVERSITY OF SOUTHERN CALIFORNIA,N02,2009,48269,-0.0361344133143549
"MAPPING AND END USER INTERFACE FOR TOPIC MODELS OF NIH GRANTS In the fall of 2007, NINDS initiated a review of funded grants as part of a general strategic planning effort. The Institute was directed by a member of the NINDS advisory council to a web-based technique for analyzing the ~14,000 Annual Meeting abstracts of the Society for Neuroscience (http://scimaps.org/maps/neurovis/new/). This technique used a publically available topic modeling algorithm known as Latent Dirichlet Allocation to determine the topic distribution of individual SfN abstracts, and used a simulated annealing graphical layout algorithm known as VxINSITE (later incorporated into DrL - SAND2008-2936J: Sandia National Laboratories) to map the topical relationships between abstracts into a Google Maps application interface, in which users can select sets of abstracts from a two-dimensional color-coded map and access topical information regarding these abstracts via an underlying database. The team that developed this framework, Gully Burns at University of Southern California (USC), David Newman at University of California Irvine (UCI), and Bruce Herr at Indiana University (IU), agreed to apply it to a set of NIH grants in order to test its potential utility for NIH staff and extramural scientists. Subsequently the project was expanded to model and map the entire 2007 set of NIH grants, with a resulting color-coded map and topic database. The results of this work can be viewed at http://scimaps.org/maps/ninds/ and http://scimaps.org/maps/nih/2007/. For the upcoming project period, the Institute has enlisted the services of the Information Extraction and Synthesis Laboratory (IESL) at the University of Massachusetts to perform topic modeling of NIH grants. The basic grants data plus the results of the topic model analysis will be transferred to Chalklabs, which will integrate it into an interface for Topic Model Browsing and for mapping using the DrL algorithm. n/a",MAPPING AND END USER INTERFACE FOR TOPIC MODELS OF NIH GRANTS,8356039,71201100725P,"['Algorithms', 'Burn injury', 'California', 'Categories', 'Code', 'Color', 'Data', 'Databases', 'Extramural Activities', 'Funding', 'Grant', 'Indiana', 'Individual', 'Information Services', 'Institutes', 'Laboratories', 'Logic', 'Maintenance', 'Maps', 'Massachusetts', 'Modeling', 'Modification', 'NIH Program Announcements', 'National Institute of Neurological Disorders and Stroke', 'Neurosciences', 'Online Systems', 'Scientist', 'Simulate', 'Societies', 'Specific qualifier value', 'Stimulus', 'Strategic Planning', 'Study Section', 'Techniques', 'Testing', 'United States National Institutes of Health', 'Universities', 'Update', 'Work', 'abstracting', 'falls', 'meeting abstracts', 'member', 'tool', 'two-dimensional']",NINDS,"CHALKLABS, LLC",N02,2011,100000,0.022146220500089655
"CHALKLABS LLC [10-011442] In the fall of 2007, NINDS initiated a review of funded grants as part of a general strategic planning effort. The Institute was directed by a member of the NINDS advisory council to a web-based technique for analyzing the ~14,000 Annual Meeting abstracts of the Society for Neuroscience (http://scimaps.org/maps/neurovis/new/). This technique used a publically available topic modeling algorithm known as Latent Dirichlet Allocation to determine the topic distribution of individual SfN abstracts, and used a simulated annealing graphical layout algorithm known as VxINSITE (later incorporated into DrL - SAND2008-2936J: Sandia National Laboratories) to map the topical relationships between abstracts into a Google Maps application interface, in which users can select sets of abstracts from a two-dimensional color-coded map and access topical information regarding these abstracts via an underlying database. The team that developed this framework, Gully Burns at University of Southern California (USC), David Newman at University of California Irvine (UCI), and Bruce Herr at Indiana University (IU), agreed to apply it to a set of NIH grants in order to test its potential utility for NIH staff and extramural scientists. Subsequently the project was expanded to model and map the entire 2007 set of NIH grants, with a resulting color-coded map and topic database. The results of this work can be viewed at http://scimaps.org/maps/ninds/ and http://scimaps.org/maps/nih/2007/. For the upcoming project period, the Institute has enlisted the services of the Information Extraction and Synthesis Laboratory (IESL) at the University of Massachusetts to perform topic modeling of NIH grants. The basic grants data plus the results of the topic model analysis will be transferred to Chalklabs, which will integrate it into an interface for Topic Model Browsing and for mapping using the DrL algorithm. n/a",CHALKLABS LLC [10-011442],8164240,71201000701P,[' '],NINDS,"CHALKLABS, LLC",N02,2010,200000,0.019545955834559828
"MAPPING AND END USER INTERFACE FOR TOPIC MODELS OF NIH GRANTS In the fall of 2007, NINDS initiated a review of funded grants as part of a general strategic planning effort. The Institute was directed by a member of the NINDS advisory council to a web-based technique for analyzing the ~14,000 Annual Meeting abstracts of the Society for Neuroscience (http://scimaps.org/maps/neurovis/new/). This technique used a publically available topic modeling algorithm known as Latent Dirichlet Allocation to determine the topic distribution of individual SfN abstracts, and used a simulated annealing graphical layout algorithm known as VxINSITE (later incorporated into DrL - SAND2008-2936J: Sandia National Laboratories) to map the topical relationships between abstracts into a Google Maps application interface, in which users can select sets of abstracts from a two-dimensional color-coded map and access topical information regarding these abstracts via an underlying database. The team that developed this framework, Gully Burns at University of Southern California (USC), David Newman at University of California Irvine (UCI), and Bruce Herr at Indiana University (IU), agreed to apply it to a set of NIH grants in order to test its potential utility for NIH staff and extramural scientists. Subsequently the project was expanded to model and map the entire 2007 set of NIH grants, with a resulting color-coded map and topic database. The results of this work can be viewed at http://scimaps.org/maps/ninds/ and http://scimaps.org/maps/nih/2007/. For the upcoming project period, the Institute has enlisted the services of the Information Extraction and Synthesis Laboratory (IESL) at the University of Massachusetts to perform topic modeling of NIH grants. The basic grants data plus the results of the topic model analysis will be transferred to Chalklabs, which will integrate it into an interface for Topic Model Browsing and for mapping using the DrL algorithm. n/a",MAPPING AND END USER INTERFACE FOR TOPIC MODELS OF NIH GRANTS,7977349,71200900695P,[' '],NINDS,"CHALKLABS, LLC",N02,2009,115000,0.022146220500089655
