text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease. ABSTRACT More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease (LD). While the CDC conventional standard two-tier (CSTT) approach for serodiagnosis of LD has worked relatively well when used as recommended, there is plenty of room for improvement. Of a number of weaknesses associated with the supplemental immunoblot of the CSTT the most significant is low reproducibility due to the subjective visual interpretation of results. To overcome these weaknesses the CDC recently updated its recommendations based on a modified STT (MSTT) in that a second EIA can replace the immunoblot. The major goal of this project is to develop an objective, quantitative, multiplex EIA that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens to build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity. The novelty of this study relies on: 1) evaluation of B. burgdorferi antigen-specific antibody isotypes and IgG subclasses that can be correlated with Lyme disease stage; and 2) development of new diagnostic tools using machine learning techniques to train and integrate all data and produce an objective result to discriminate early Lyme from early disseminated/late Lyme disease. We expect this Phase I SBIR to allow us to develop a new EIA for serodiagnosis of Lyme disease (isoEIAplex-Ld) and to further an ongoing collaboration with DCN diagnostics for the adaptation of our biomarkers to a new rapid Lateral Flow Assay (see Letter of Support) for a follow up Phase II SBIR . NARRATIVE More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease. While the CDC conventional standard two-tier approach for serodiagnosis of Lyme disease has worked relatively well when used as recommended, there is plenty of room for improvement. We propose to develop an objective multiplex enzyme immunoassay that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens and build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity.",Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease.,10204992,R43AI155211,"['Acute', 'Acute Disease', 'Affinity', 'Antibodies', 'Antibody Response', 'Antigens', 'Arthritis', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Borrelia burgdorferi', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Collaborations', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Specificity', 'Discrimination', 'Disease', 'Early Diagnosis', 'Enzyme Immunoassay', 'Evaluation', 'GTP-Binding Protein alpha Subunits, Gs', 'Genetic Recombination', 'Goals', 'Grant', 'High Prevalence', 'Human', 'IgA1', 'IgA2', 'IgE', 'IgG1', 'IgG2', 'IgG3', 'IgG4', 'Immune response', 'Immunodominant Antigens', 'Immunoglobulin A', 'Immunoglobulin D', 'Immunoglobulin G', 'Immunoglobulin Isotypes', 'Immunoglobulin M', 'Immunoglobulins', 'Infection', 'Iowa', 'Laboratories', 'Laboratory Diagnosis', 'Lesion', 'Letters', 'Licensing', 'Lyme Arthritis', 'Lyme Disease', 'Machine Learning', 'OspC protein', 'Patients', 'Peptidoglycan', 'Performance', 'Phase', 'Proteins', 'ROC Curve', 'Recommendation', 'Reproducibility', 'Research', 'Serum', 'Small Business Innovation Research Grant', 'Specificity', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'V(D)J Recombination', 'Visual', 'Work', 'antigen binding', 'base', 'commercialization', 'disease diagnosis', 'erythema migrans', 'follow-up', 'improved', 'lateral flow assay', 'novel diagnostics', 'pathogen', 'tool']",NIAID,"IMMUNO TECHNOLOGIES, INC.",R43,2021,295514
"Rapid Comprehensive Cardiac MRI Exam for Diagnosis of Coronary Artery Disease PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) is the leading cause of death in the United States. The clinical gold standards to diagnose and guide treatment of patients with CAD are based on invasive catheter-based procedures, such as x-ray coronary angiography (XCA) for anatomic assessment or fractional flow reserve (FFR) for physiologic assessment. However, there are costs and risks associated with such invasive procedures. Such concerns are further highlighted by the fact that large studies have shown nearly two-thirds of patients referred for their initial elective invasive XCA were found to have no significant stenoses. Thus, better non-invasive diagnostic tools are needed. Cardiac MRI (CMR) is the only non-invasive imaging modality that provides a comprehensive assessment of CAD in a single examination, including an assessment of myocardial perfusion, cardiac function and viability, as well as angiographic evaluation of stenoses, without requiring ionizing radiation. These properties also allow for repeat testing as may be clinically indicated. However, despite its great potential to serve as the non- invasive gatekeeper for costly invasive procedures, lengthy examination times have prevented CMR from clinical translation. Although several accelerated imaging techniques have been proposed, these still require trade-offs between coverage, resolution and signal-to-noise ratio. In this proposal, we will develop and validate novel acquisition and reconstruction strategies to enable a highly accelerated high-resolution whole heart CMR exam for comprehensive CAD assessment in under 10 minutes. We will develop fast and low specific absorption rate outer volume suppression modules to reduce the source of aliasing artifacts from the chest and the back. This will enable higher rates for simultaneous multi-slice imaging in perfusion and cine CMR, improving coverage substantially with minimal noise amplification. For coronary MRI and viability imaging, simultaneous multi-slab imaging will be introduced to CMR, facilitating high isotropic resolution acquisitions with fast coverage. These acquisitions will be supplemented with regularized leakage-blocking and patient- specific machine learning reconstructions for further artifact and noise removal. Finally, we will implement and validate the proposed rapid comprehensive CMR exam in a cohort of suspected CAD patients, comparing our approach with conventional clinical CMR for the assessment of function, perfusion, and viability, and with invasive XCA for the assessment of coronary stenosis. Successful completion of this project has the potential to transform CMR into a leading rapid non-invasive tool for safe and accurate diagnosis of CAD, improving the healthcare of several million patients with chest pain and other CAD symptoms annually. PROJECT NARRATIVE Coronary artery disease (CAD) is the leading cause of death in the United States, accounting for one in six deaths. Cardiac MRI is a non-invasive non-ionizing technique for comprehensive evaluation of CAD, but its clinical translation is hampered by lengthy exam times. In this work, we will develop and validate techniques for rapid cardiac MRI in a short exam time for comprehensive CAD assessment.",Rapid Comprehensive Cardiac MRI Exam for Diagnosis of Coronary Artery Disease,10171902,R01HL153146,"['3-Dimensional', 'Acceleration', 'Accounting', 'Anatomy', 'Award', 'Back', 'Breathing', 'Cardiac', 'Catheters', 'Cause of Death', 'Cessation of life', 'Chest', 'Chest Pain', 'Clinical', 'Coronary', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Evaluation', 'Excision', 'Extravasation', 'Gadolinium', 'Gatekeeping', 'Gold', 'Healthcare', 'Heart', 'Image', 'Imaging Techniques', 'Ionizing radiation', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Care Costs', 'Methods', 'Morphologic artifacts', 'Myocardial perfusion', 'Noise', 'Patients', 'Perfusion', 'Physiological', 'Preparation', 'Procedures', 'Property', 'Resolution', 'Risk', 'Roentgen Rays', 'Sampling', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Source', 'Symptoms', 'Techniques', 'Testing', 'Time', 'United States', 'Work', 'absorption', 'accurate diagnosis', 'artificial neural network', 'base', 'clinical translation', 'cohort', 'cost', 'diagnosis standard', 'disease diagnosis', 'heart function', 'high resolution imaging', 'imaging modality', 'improved', 'non-invasive imaging', 'noninvasive diagnosis', 'novel', 'prevent', 'rapid technique', 'reconstruction', 'temporal measurement', 'tool']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2021,487354
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,10171859,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Models', 'Cornea', 'Corneal Diseases', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'detection sensitivity', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2021,381543
"Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance PROGRAM SUMMARY Radiological imaging is often the first step of the diagnostic pathway for many devastating diseases; thus, an erroneous assessment of “normal” can lead to death. Whereas a grayscale object in an image can be described by its first-order image statistics—such as contrast, spatial frequency, position, entropy, and orientation—none of these dimensions, by itself, indicates abnormal vs normal radiological findings. We are a highly diverse team proposing an empirical approach to determine the mixtures of the first-order statistics—the “visual textures”— that radiology experts explicitly and implicitly use to identify the locations of potential abnormalities in medical images. Our innovative approach does not rely on assumptions about which textures may or may not be im- portant to abnormality detection. Instead, we will track the oculomotor behavior of expert radiologists to deter- mine their conscious and unconscious targeting choices, and thus ascertain which textures are empirically in- formative. The ability of expert radiologists to rapidly find abnormalities suggests that they may be able to first identify them in their retinal periphery. Peripheral visual analysis skills are therefore potentially critical to radio- logic performance, despite being understudied. We will measure these skills and leverage the results to develop perceptual learning heuristics to improve peripheral abnormality texture detection. By comparing novices to ex- perts we will determine whether the first are inexpert due to a lack of sensitivity to diagnostically relevant textures (texture informativeness), or to a lack of knowledge about which textures are abnormal, or to a combined lack of both sensitivity and knowledge. Radiology also requires the acquisition of oculomotor skills through practice and optimization. Radiologic expertise thus changes the oculomotor system in predictable and detectable ways, in much the same way that an athlete’s body and brain change as a function of expertise acquisition in their sport. We will therefore analyze both the consistency between experts’ fixation choices in medical images, and the eye movement performance characteristics of experts vs novice radiologists, to create an objective oculomotor bi- omarker of radiological expertise. The differences between novices and experts will train a deep learning (DL) system, which will have human visual and oculomotor performance characteristics. Training the DL with the abnormalities identified by a panel of expert radiologists will allow it to pinpoint the possible solutions in the manner of a simulated human radiologist performing at peak accuracy, precision, and speed. The resulting rank- ordered list of possible optimal and suboptimal image-reading strategies will serve as a benchmarking tool to quantify the performance of actual clinicians and residents who read the same images, rested vs fatigued. Meas- uring the effects of both training and fatigue on radiology expertise will be a major interdisciplinary cross-cutting advance in performance assessment. Our proposal to quantify fatigue in terms of erosion of expertise represents a transformational advance towards objective fitness-for-duty and expertise measures in medicine and beyond. PROJECT NARRATIVE There are 25-32 million perceptual errors in radiological case studies worldwide each year, contributing to med- ical error, the third most common cause of death in the US. We seek to reduce detection errors in radiology with four innovations: (1) we will empirically and objectively determine the visual textures used by expert radiologists to identify abnormalities within medical images; (2) we will determine the ways in which expert radiologists use their eyes, and especially their peripheral vision, to scan images and target informative regions; (3) we will de- velop a perceptual learning paradigm to optimally train residents in both texture perception and oculomotor per- formance domains; and (4) we will construct a deep learning model bestowed with simulated human visual and oculomotor capabilities, to create a normative model of human radiological expertise. The combined results from these studies will quantify peak expert performance and be employed to track and enhance individual expertise acquisition during radiology training; thus, the proposed research will help reduce medical error and moreover provide objective fitness-for-duty measurement tools—based on quantified biomarkers—to evaluate and ame- liorate the effects of fatigue on radiologic performance.",Novel Perceptual and Oculomotor Heuristics for Enhancing Radiologic Performance,10220201,R01CA258021,"['Assessment tool', 'Benchmarking', 'Biological Markers', 'Brain', 'COVID-19', 'Cancer Detection', 'Case Study', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical/Radiologic', 'Collection', 'Conscious', 'Data', 'Data Analyses', 'Databases', 'Detection', 'Diagnostic', 'Dimensions', 'Disease', 'Elements', 'Ensure', 'Entropy', 'Exposure to', 'Eye', 'Eye Movements', 'Fatigue', 'Film', 'Foundations', 'Frequencies', 'Human', 'Image', 'Incentives', 'Individual', 'Instruction', 'Knowledge', 'Lead', 'Learning', 'Location', 'Measurement', 'Measures', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Modeling', 'Nature', 'North America', 'Outcome', 'Participant', 'Pathway interactions', 'Perception', 'Perceptual learning', 'Performance', 'Peripheral', 'Positioning Attribute', 'Radiologic Finding', 'Radiology Specialty', 'Reading', 'Research', 'Residencies', 'Resolution', 'Rest', 'Retina', 'Scanning', 'Societies', 'Speed', 'Sports', 'Stress', 'System', 'Testing', 'Texture', 'Thoracic Radiography', 'Time', 'Training', 'Unconscious State', 'Vision', 'Visual', 'Workload', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'cancer imaging', 'cohort', 'deep learning', 'design', 'experience', 'fitness', 'heuristics', 'human error', 'human model', 'improved', 'innovation', 'learning network', 'lung imaging', 'meetings', 'novel', 'oculomotor', 'oculomotor behavior', 'pandemic disease', 'patient safety', 'programs', 'radiological imaging', 'radiologist', 'sample fixation', 'shift work', 'skills', 'statistics', 'tool', 'tool development']",NCI,SUNY DOWNSTATE MEDICAL CENTER,R01,2021,646124
"Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients Esophageal adenocarcinoma (EAC) is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. Barrett’s esophagus (BE) confers elevated risk for progression to EAC. Patients diagnosed with BE undergo periodic surveillance endoscopy with biopsies to detect dysplasia which can be treated by endoscopic eradication with radiofrequency ablation before it progresses to EAC. However, the majority of diagnosed EAC patients have not had prior screening endoscopy and present with advanced lesions that limit treatment options and result in poorer survival. The development of a rapid, low cost, well tolerated, non-endoscopic BE screening technique that can be performed in unsedated patients at points of care outside the endoscopy suite would improve BE detection and reduce EAC morbidity and mortality. Our program is a multidisciplinary collaboration among investigators at the Massachusetts Institute Technology and Veteran Affairs Boston Healthcare System / Harvard Medical School that integrates novel optical imaging and software design, preclinical studies in swine, clinical studies in patients, and advanced image processing / machine learning. Aim 1 will develop an omniview tethered capsule technology that generates a map of the esophageal mucosa over a multi-centimeter length of esophagus and a series of wide angle forward views to aid navigation as the capsule is swallowed or retracted. The images will resemble endoscopic white light or narrow band imaging, but will not suffer from perspective distortion present in standard endoscopic or video capsule images. This will facilitate development of automated BE detection algorithms as well as enhance their sensitivity and specificity. This aim will also perform imaging studies in swine as a translational step toward clinical studies. Aim 2 will determine reader sensitivity and specificity for BE detection versus standard endoscopy / biopsy and prepare data for developing automated BE detection. Patients undergoing screening as well as with history of BE undergoing surveillance will be recruited and unsedated capsule imaging will be performed on the same day prior to their endoscopy. Sensitivity and specificity for detecting BE will be assessed using multiple blinded readers and data sets suitable for developing automated BE detection algorithms will be developed. Aim 3 will develop image analysis methods for automated BE detection by investigating classifiers that operate on handcrafted features (colors and textures) and modern deep convolutional neural network methods for direct classification. If successful, this program will develop a rapid, low cost and scalable method for BE screening that would not require patient sedation, endoscopy, or tissue acquisition, and which could be performed in community primary care clinics. The procedure would be much faster and many times lower cost than endoscopy. Automated BE detection would enable immediate results for patient consultation and referral to gastroenterology if indicated. Larger patient populations with expanded risk criteria could be cost effectively screened and access to screening dramatically improved, reducing EAC mortality. Esophageal adenocarcinoma is among the most lethal malignancies with a 19% five-year survival rate and its incidence has increased several fold in the last decades. The program proposes to develop an omniview tethered capsule technology, examination protocol, and automated analysis methods for low cost, rapid, well tolerated, and scalable screening in order to facilitate monitoring and timely treatment. Larger patient populations could be cost effectively screened and access to screening dramatically improved, reducing mortality.","Omniview tethered capsule for low cost, non-endoscopic Barrett's esophagus screening in unsedated patients",10210371,R01CA252216,"['Algorithmic Software', 'Algorithms', 'Back', 'Barrett Esophagus', 'Biopsy', 'Blinded', 'Blood Vessels', 'Boston', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Color', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Set', 'Deglutition', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dysplasia', 'Endoscopic Biopsy', 'Endoscopy', 'Esophageal Adenocarcinoma', 'Esophageal mucous membrane', 'Esophagus', 'Family suidae', 'Gastroenterologist', 'Gastroenterology', 'Gastroesophageal reflux disease', 'Healthcare Systems', 'Histology', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Incidence', 'Institutes', 'Interdisciplinary Study', 'Label', 'Length', 'Lesion', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Massachusetts', 'Measures', 'Methods', 'Modernization', 'Monitor', 'Morbidity - disease rate', 'Mucous Membrane', 'Nurse Practitioners', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Population', 'Primary Care Physician', 'Primary Health Care', 'Procedures', 'Protocols documentation', 'Radiofrequency Interstitial Ablation', 'Reader', 'Reading', 'Recording of previous events', 'Referral and Consultation', 'Research Personnel', 'Resolution', 'Risk', 'Screening Result', 'Sedation procedure', 'Sensitivity and Specificity', 'Series', 'Side', 'Software Design', 'Stomach', 'Surface', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Texture', 'Time', 'Tissues', 'Training', 'United States Department of Veterans Affairs', 'Validation', 'advanced disease', 'automated analysis', 'automated image analysis', 'base', 'capsule', 'clinical imaging', 'convolutional neural network', 'cost', 'design', 'graphical user interface', 'image processing', 'imaging software', 'imaging study', 'improved', 'medical schools', 'mortality', 'navigation aid', 'novel', 'optical imaging', 'patient population', 'point of care', 'preclinical study', 'programs', 'recruit', 'screening']",NCI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2021,345509
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10421230,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,138041
"Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data Abstract Eysz, Inc. is developing an algorithm and software solutions to reliably and affordably detect seizures in an ambulatory setting using existing smart glass technologies. In a proof-of-concept study, Eysz was able to detect >75% of all absence seizures longer than 10 s in duration using only oculometric variables (e.g., pupil size, pupil location, eccentricity, blink frequency) detected using off-the-shelf eye-tracking technology. Eysz seeks to build on this finding by developing and commercializing highly sensitive and specific seizure detection algorithms using eye-movement data as input, with eventual expansion to additional seizure types. This technology has the potential to transform the detection and treatment of seizures for those with epilepsy, one of the most common neurological disorders worldwide. Timely treatment can reduce the chance of additional seizures by half, making early detection and treatment critical. Unfortunately, detection and diagnosis can be difficult using current technologies, especially in types of epilepsy with few observable symptoms such as absence seizures. The gold standard for detecting and characterizing seizure activity is electroencephalogram (EEG) monitoring with video and subsequent review by a trained clinician, but this does not translate well to the outpatient setting. While attempts to develop ambulatory EEGs have been made, these have significant drawbacks, including poor patient acceptability, poor detection capability, and continued reliance on asynchronous review. Additional non-EEG- based motion detection devices are limited to tonic-clonic seizures, which are responsible for a small fraction of all seizure activity. Thus, there is a critical need to reliably detect seizures outside of the clinic to provide physicians with necessary information to guide therapeutic decision making. To address this need, Eysz is developing a digital health platform that leverages existing eye tracking technology to meet this significant unmet gap in the market and is technically feasible, capital-efficient, robust, and innovative. Eysz plans to use existing smart glass technology to export the necessary oculometric data to be analyzed by our seizure detection algorithm. We will also build out databases, software systems, and user interfaces enabling the resulting data to be stored in the cloud and visualized/analyzed by physicians. In this Phase I SBIR, Eysz will advance the development of the seizure detection algorithms by: 1) obtaining oculometric video and EEG data on ≥100 absence seizures from multiple patients, and 2) using ML and statistical methods to optimize an algorithm for identifying absence seizures using eye-tracking data, with a target sensitivity of 85% and specificity of 90%. Lessons learned from this study will be applied (with different training sets) to additional seizures types, such as focal impaired awareness (formerly called complex partial) seizures, the most prevalent seizure type in adults. This work is of critical importance to the field, as demonstrated by support from the Epilepsy Foundation and receipt of both the judges' and people's choice awards in the Epilepsy Foundation's 8th Annual Shark Tank Competition. Narrative More than 70 million people worldwide suffer from epilepsy, a debilitating, unpredictable chronic condition that results in significant disability and increased risk of morbidity and mortality. Seizure detection and characterization is critical to choosing an appropriate treatment regimen, and appropriate anticonvulsants can decrease seizures by 50%. Eysz's proposed seizure detection solution will provide unobtrusive, objective, automated detection of seizure activity in an outpatient setting in near real time, improving medical decision- making, decreasing time to treatment, reducing mortality, and ultimately improving quality of life for those with epilepsy.",Algorithm for the Real-Time Detection of Absence Seizures from Oculometric Data,10372655,R43NS119015,"['Absence Epilepsy', 'Activities of Daily Living', 'Address', 'Adult', 'Advanced Development', 'Age', 'Algorithmic Software', 'Algorithms', 'Anticonvulsants', 'Award', 'Awareness', 'Blinking', 'Capital', 'Cessation of life', 'Childhood', 'Chronic', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early treatment', 'Electrodes', 'Electroencephalogram', 'Epilepsy', 'Eye Movements', 'Focal Seizure', 'Foundations', 'Frequencies', 'Future', 'General Population', 'Glass', 'Gold', 'Impairment', 'Individual', 'Letters', 'Location', 'Machine Learning', 'Medical', 'Monitor', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'Movement', 'Outpatients', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pupil', 'Quality of life', 'Resolution', 'Risk', 'Seizures', 'Shark', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Statistical Methods', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tonic - clonic seizures', 'Training', 'Treatment Protocols', 'Work', 'algorithm development', 'base', 'commercialization', 'detection platform', 'digital health', 'disability', 'experience', 'high risk', 'improved', 'improved outcome', 'innovation', 'large datasets', 'machine learning method', 'mortality', 'mortality risk', 'nervous system disorder', 'premature', 'prospective', 'software systems', 'statistical and machine learning', 'visual tracking', 'wearable device']",NINDS,"EYSZ, INC.",R43,2021,52000
"Functional and Structural Optical Coherence Tomography for Glaucoma PROJECT SUMMARY Glaucoma is a leading cause of blindness in the US. The management of glaucoma is based on early detection, followed by careful evaluation and monitoring to identify those with rapid disease progression and high risk for vision loss. This allows for the rational use of medical, laser, and surgical treatments. Current methods of assessing glaucoma have significant limitations. Visual field (VF) testing has a low sensitivity for detecting early disease, and its reproducibility worsens in advanced stages, reducing its reliability for monitoring disease progression. Optical coherence tomography (OCT) precisely measure the peripapillary nerve fiber layer (NFL) thickness and is the most commonly used technology for objective glaucoma evaluation. However, NFL thickness has limited sensitivity in detecting early glaucoma, and reaches a floor value in moderate glaucoma, which prevents it from tracking glaucoma progress into later stages. The goal of the proposed research is to develop advanced OCT technology that will enhance detection of early glaucoma, improve the sensitivity of detecting significant disease progression, and increase the accuracy of measuring progression speed. The Specific Aims are: 1. Develop a directional high-resolution OCT and OCT angiography prototype to improve imaging of  structure and perfusion. The prototype will have real-time control of beam direction to maintain  perpendicular incidence on the NFL for accurate reflectance analysis, which has shown promise for very  sensitive detection of early glaucoma. Sensorless adaptive-optics aberration correction will enable high  transverse resolution to enhance the detection of nerve fiber bundle and capillary defects. Ultrahigh axial  resolution will enable assessment of the pentalaminar structure of the inner plexiform layer. 2. Wide-field OCT and OCT angiography analyses and visual field simulation. Wide peripapillary and  macular scans, using a next-generation commercial spectral-domain OCT system, will allow visualization of  nerve fiber and perfusion defects from the disc margin to temporal raphe, thus improving early glaucoma  detection. VF simulation will be performed to convert OCTA perfusion measurement to a VF-equivlaent dB-  scale familiar to clinicians for monitoring progression. The simulation has higher reproducibility than actual  VF, which improves detection of disease progression and measurement of progression speed. 3. Clinical studies in glaucoma diagnosis and monitoring. The clinical study will test whether the  proposed new technologies can improve the detection of pre-perimetric glaucoma, detection of disease  progression, and the accuracy of measuring the speed of progression. This research is likely to transform the clinical practice of glaucoma by developing novel objective functional and structural tests that can be practically implemented on the next generation of clinical OCT systems. This will save vision by achieving accurate diagnosis in early glacuoma and timely intervention in rapid progressors. PROJECT NARRATIVE Optical coherence tomography (OCT) is a high-resolution imaging technology that is already commonly used to diagnose and monitor glaucoma, a leading cause of blindness. The proposed research will further improve this technology so that it can detect earlier stages of glaucoma, evaluate the location and severity of glaucoma damage, and provide more accurate monitoring of disease progression. Directional OCT technology will be developed to accurately measure nerve fiber layer reflectance; sensorless adaptive-optics OCT technology will be used to improve imaging of nerve fiber bundles and capillaries; ultrahigh axial resolution will enable imaging of detailed internal retinal structures such as the lamellae of the inner plexiform layer; and capillary perfusion measurements will be used to simulate visual field function.",Functional and Structural Optical Coherence Tomography for Glaucoma,10211838,R01EY023285,"['3-Dimensional', 'Angiography', 'Blindness', 'Blood capillaries', 'Clinical', 'Clinical Research', 'Data', 'Defect', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Floor', 'Future', 'Ganglion Cell Layer', 'Glaucoma', 'Goals', 'Grant', 'Image', 'Imaging technology', 'Incidence', 'Inner Plexiform Layer', 'Intervention', 'Lasers', 'Location', 'Maps', 'Measurement', 'Measures', 'Medical', 'Methods', 'Monitor', 'Nerve Fibers', 'Nose', 'Open-Angle Glaucoma', 'Operative Surgical Procedures', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Performance', 'Perfusion', 'Questionnaires', 'Real-Time Systems', 'Reproducibility', 'Research', 'Resolution', 'Retina', 'Scanning', 'Severities', 'Severity of illness', 'Speed', 'Structure', 'System', 'Technology', 'Testing', 'Thick', 'Time', 'Variant', 'Vision', 'Visual Fields', 'Visualization', 'accurate diagnosis', 'adaptive optics', 'base', 'clinical practice', 'deep neural network', 'field study', 'high resolution imaging', 'high risk', 'improved', 'macula', 'new technology', 'next generation', 'novel', 'novel strategies', 'optic nerve disorder', 'prevent', 'prototype', 'quantitative imaging', 'simulation', 'tool']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,624917
"Malarial retinopathy screening system for improved diagnosis of cerebral malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. In 2018, malaria affected more than 213 million people in Africa alone and claimed 381,000 lives, more than 65% of whom were African children less than 5 years old. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM, incorrect treatment, and resulting mortality or neurological disability. The specificity of the current standard of care for clinical diagnosis of CM (physical symptoms, coma, and malaria parasite test such as rapid diagnostic testing) is reported around 61%. Therefore, there is a significant market need for a highly specific, low-cost, and easy-to-use test to improve CM diagnosis and save lives. Since Malarial retinopathy (MR) is greater than 95% specific to the presence of CM, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. Screening for MR in addition to the current standard of care improves the specificity of CM diagnosis from 61% to 100%. VisionQuest Biomedical has developed ASPIRE, the first fully automated MR detection software integrated with a low-cost and portable retinal camera, a system that can be operated by minimally trained personnel such as medical technician or nurse without the need of an ophthalmic specialist. We have assembled a multidisciplinary team of regulatory consultants, commercialization experts, business development specialists, and clinicians; to clinically deploy and launch ASPIRE in our target market in Africa. This team will validate and prepare ASPIRE for regulatory clearance as well as finalize the marketing and commercial rollout strategy. In Phase II-B, the research team at VisionQuest Biomedical deployed a fully-functional clinical version of ASPIRE and tested it in nine malaria clinics in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In CRP, ASPIRE will be validated for technical and clinical performance and will be brought to commercial readiness with regulatory clearance. We will accomplish this through four specific aims. In the first aim, the software system for MR detection will be validated to bring it under design controls. In the second aim, we will deploy ASPIRE at 25 clinics in Africa to demonstrate safety and efficacy as well as to promote market traction. The third aim will focus on preparing ASPIRE for regulatory submission. In the fourth aim, we will complete African healthcare market research for a startup market of 5 countries (Malawi, Zambia, Kenya, Uganda, Rwanda) and finalize marketing and rollout strategy. Within one year after CRP, our goal will be to deploy ASPIRE in more than 200 malaria clinics across 5 countries in Africa. Narrative Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection, which claims hundreds of thousands of lives of African children every year. The detection of retinal biomarkers of CM, called malarial retinopathy, can improve the diagnostic accuracy of CM. This project proposes the development, clinical deployment, and commercialization of a fully automated malarial retinopathy detection system consisting of a low-cost retinal camera and automatic malarial retinopathy detection software.",Malarial retinopathy screening system for improved diagnosis of cerebral malaria,10253474,SB1AI162452,"['5 year old', 'Affect', 'Africa', 'African', 'Artificial Intelligence', 'Biological Markers', 'Businesses', 'Cerebral Malaria', 'Cessation of life', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Coma', 'Computer software', 'Consult', 'Country', 'Detection', 'Development', 'Diagnosis', 'Diagnostic tests', 'Disease', 'Expert Systems', 'Feedback', 'Goals', 'Government', 'Grant', 'Health', 'Healthcare Market', 'Human Resources', 'Incidence', 'Institution', 'Institutional Review Boards', 'Internet', 'Kenya', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Market Research', 'Marketing', 'Medical', 'Medical Device', 'Medicine', 'Neurologic', 'Nurses', 'Parasites', 'Pathology', 'Performance', 'Pharmacy facility', 'Phase', 'Policies', 'Rapid diagnostics', 'Readiness', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Rwanda', 'Safety', 'Series', 'Software Validation', 'Specialist', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Traction', 'Training', 'Uganda', 'Validation', 'Work', 'Zambia', 'clinical Diagnosis', 'clinical research site', 'commercialization', 'cost', 'design', 'detection platform', 'diagnostic accuracy', 'disability', 'improved', 'malaria infection', 'mortality', 'multidisciplinary', 'physical symptom', 'portability', 'programs', 'research clinical testing', 'research study', 'screening', 'smartphone Application', 'software systems', 'standard of care', 'success', 'usability', 'verification and validation', 'web site']",NIAID,VISIONQUEST BIOMEDICAL INC,SB1,2021,999158
"Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria Summary Cerebral malaria (CM) is a life-threatening clinical syndrome associated with malarial infection. Annually, malaria affects more than 200 million people and claims the lives of over 440,000 people worldwide, mostly African children. As a consequence of the high incidence of CM, it is often misdiagnosed for other pathologies with similar symptoms, leading to a high false positive rate for CM and incorrect treatment. An accurate means to confirm the presence of CM or to investigate for a non-malarial illness is critically needed to improve outcomes. Since Malarial retinopathy (MR) is greater than 90% specific and sensitive to the presence of CM once clinically diagnosed, retinal screening for MR represents an effective means to assist in and improve the specificity of CM diagnosis. VisionQuest Biomedical and its collaborators have assembled a team of inter-disciplinary scientists with considerable experience in automated retinal image analysis, clinical ophthalmology with specialized research in malarial retinopathy (MR), and cerebral malaria diagnosis (CM). This team will develop and test ASPIRE, a system for detection of MR consisting of automated MR detection software integrated with a low-cost and portable retinal camera. Our proposed ASPIRE system will augment, not replace, the current CM diagnostic standard; increasing the accuracy of CM diagnoses, leading to a smaller number of false positive outcomes. In Phases I and II, the research team at VisionQuest Biomedical developed the automated MR detection software and interfaced it with a handheld retinal camera. The resulting clinical prototype of ASPIRE was tested onsite in a health-clinic in Africa, which demonstrated excellent performance and usability for detecting MR, without the need of an ophthalmic expert. In Phase II-B, the MR detection system will be refined, productized, and the resulting commercial prototype will be validated on prospective datasets. We will accomplish this through three specific aims. In the first aim, the software system for MR detection will be adapted and improved to work with low-cost and portable iNview camera. In the second aim, we will refine iNview’s driver-software and integrate the camera with MR detection software to produce the first commercial prototype. The third aim will focus on collecting the retinal image data for algorithm testing as well as for validating the commercial prototype in an observational clinical study to be conducted at nine clinical sites in Malawi, Uganda, and Zambia in Africa. Narrative Cerebral malaria is a life-threatening clinical syndrome associated with malarial infection, which affects about 200 million people annually and claims the lives of over 440,000 people worldwide, mostly African children. The presence of malarial retinopathy can provide additional insight and improve the diagnostic accuracy of CM. This project proposes the development of a fully-automated malaria retinopathy detection system consisting of a low-cost retinal camera and automatic malaria retinopathy detection software.",Malarial Retinopathy Screening System for Improved Diagnosis of Cerebral Malaria,10074515,R44AI112164,"['5 year old', 'Address', 'Affect', 'Africa', 'African', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'Caring', 'Cellular Phone', 'Cerebral Malaria', 'Child', 'Clinic', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Country', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Enrollment', 'Expert Systems', 'Foundations', 'Goals', 'Grant', 'Health', 'Health Personnel', 'Healthcare', 'Image Analysis', 'Incidence', 'Lesion', 'Letters', 'Life', 'Malaria', 'Malawi', 'Medicine', 'Ophthalmologist', 'Ophthalmology', 'Ophthalmoscopy', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Poison', 'Predictive Value', 'Price', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Safety', 'Scientist', 'Seasons', 'Series', 'Site', 'Specificity', 'Symptoms', 'Syndrome', 'System', 'Test Result', 'Testing', 'Uganda', 'Validation', 'Work', 'Zambia', 'base', 'clinical Diagnosis', 'clinical research site', 'cost', 'cost effectiveness', 'design', 'detection platform', 'diagnostic accuracy', 'experience', 'imaging capabilities', 'improved', 'improved outcome', 'innovation', 'insight', 'malaria infection', 'mortality', 'performance site', 'portability', 'programs', 'prospective', 'prototype', 'research study', 'response', 'retinal imaging', 'screening', 'smartphone Application', 'software development', 'software systems', 'success', 'usability']",NIAID,VISIONQUEST BIOMEDICAL INC,R44,2021,1000000
"Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing ABSTRACT No real-time quantitative devices are clinically used to assess oral lesions during routine examination, making in-clinic diagnostic and longitudinal monitoring challenging. Instead, lesions are evaluated through visual inspection and then histopathological analysis of tissue samples extracted during biopsy. Identifying premalignant and malignant oral lesions early is critical to ensuring effective treatment is provided to patients with malignancies. Oral cancer currently has one of the lowest 5-year survival rates (50% or less) among major cancer types, largely due to the challenges in identifying premalignant and malignant lesions early. Clearly, a real-time in-clinic device able to classify oral lesions as benign, premalignant, or malignant has the potential to provide immediate impact to patient care. Significantly different electrical property signatures have been observed between benign and malignant tissues in a variety of organs, including tongue; since the bioelectrical properties are so dependent on tissue architecture and morphology, we hypothesize that sensing and imaging these properties in the context of oral lesions will enable us to accurately characterize and classify morphologically-different benign, premalignant, and malignant oral lesions. We have developed an endoscopic electrical impedance imaging (EII) device for use in intraoperative surgical margin assessment that we aim to optimize for in-clinic oral lesion assessment. We aim to take the significant step of translating our extensive experience in impedance imaging to develop an oral lesion imaging device that can be deployed safely, and in the clinic, to provide real-time feedback regarding oral lesion classification. We propose constructing a novel chip-on-tip EII probe to sense and image at near microscopic resolution oral lesions in an effort to provide clinicians with real-time, accurate classification of oral lesion pathology that can be used for diagnostic and longitudinal monitoring purposes. The probe will be evaluated on a series of in vivo human oral lesions and compared with histopathological analysis of biopsy samples. The low-cost of a device such as this makes it an ideal technology for low-resource settings and the safety and real-time capabilities of the system make it ideal for continuously following lesions. PROJECT NARRATIVE Visual inspection of oral lesions is not sufficient for accurately classifying lesions as benign, premalignant, or malignant. The electrical properties of oral lesion have the potential to be used as a contrast mechanism to accurately classify oral lesions so that optimal treatment can be provided to patients with malignant lesions. We intend to deploy a novel small field of view chip-on-tip electrical impedance imaging (EII) probe in a cohort of patients with oral lesions to evaluate the efficacy of using EII for oral lesion classification.",Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing,10287597,R21DE031095,"['Architecture', 'Area', 'Benign', 'Biological Markers', 'Biopsy', 'Biopsy Specimen', 'Cancerous', 'Carcinoma', 'Carcinoma in Situ', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Contralateral', 'Custom', 'Data', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Dysplasia', 'Electrodes', 'Electronics', 'Ensure', 'Epithelial', 'Excision', 'Feedback', 'Frequencies', 'Hand', 'Histologic', 'Human', 'Hyperplasia', 'Image', 'Imaging Device', 'Ionizing radiation', 'Length', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Microscopic', 'Monitor', 'Morphology', 'Noise', 'Normal tissue morphology', 'Oral Characters', 'Oral cavity', 'Organ', 'Oropharyngeal', 'Pathology', 'Patient Care', 'Patients', 'Positioning Attribute', 'Procedures', 'Property', 'Research Design', 'Resolution', 'Resources', 'Safety', 'Sampling', 'Series', 'Signal Transduction', 'Site', 'Squamous Cell', 'Surgical margins', 'Survival Rate', 'System', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'Tongue', 'Translating', 'Visual', 'analog', 'base', 'bioelectricity', 'cancer type', 'cohort', 'cost', 'design', 'effective therapy', 'efficacy evaluation', 'electric impedance', 'electrical impedance tomography', 'electrical property', 'experience', 'extracellular', 'imaging probe', 'imaging properties', 'in vivo', 'interest', 'malignant mouth neoplasm', 'monitoring device', 'novel', 'optimal treatments', 'oral lesion', 'oral tissue', 'premalignant', 'pressure', 'pressure sensor', 'programs', 'response', 'soft tissue']",NIDCR,DARTMOUTH COLLEGE,R21,2021,191061
"Automated Digital Imaging for Cervical Cancer Screening Project Abstract/Summary: Cervical cancer screening programs remain essential to reduce cervical cancer in women despite the availability of human papilloma virus (HPV) vaccines. Screening is important for all women but is particularly important for women living with HIV given the high prevalence of HPV in this group and risks associated with progression notwithstanding antiretroviral therapy. Here we propose to investigate the clinical utility of a new method of automated digital imaging of the cervix on the MobileODT platform as a screen-and-treat approach. We build on a long-term collaboration between the University of Cape Town and Columbia University investigating how to strengthen cervical cancer screening and treatment in South Africa. Currently, screen-and-treat programs utilizing HPV DNA testing are recommended by the World Health Organization. We have demonstrated the safety, efficacy and cost-effectiveness of this approach for the South African setting with its high HIV prevalence in women. In this setting, we are currently completing an NCI- supported study demonstrating the feasibility and outstanding performance of an HPV DNA assay that can be used at the point-of-care for a single-visit, screen-and-treat program. Here we propose to extend this work to investigate in Specific Aim 1: the performance characteristics of automated digital imaging as a standalone, primary screening test to replace HPV DNA testing for use in the single-visit, screen-and-treat approach; Specific Aim 2: the performance characteristics of automated digital imaging as a triage test for women who test HPV DNA positive in the screen- and-treat approach; and Specific Aim 3: facility-level operational challenges and facilitators to integrating this new imaging technology into single-visit screen-and-treat programs. We propose to undertake the studies to address these aims among women living with and without HIV at clinical sites in Cape Town, South Africa. Our overall goal is to strengthen cervical cancer screening approaches to reduce cost and improve the effectiveness of screening. Project Narrative We propose to investigate the accuracy and implementation potential of a new technology that provides an automated and almost instant classification of cervical cancer precursor lesions based on a cloud-based, machine-learning algorithm of an image of the cervix. We will investigate the clinical utility of this new technology for integrating into screen-and-treat programs for women living with and without HIV in South Africa.",Automated Digital Imaging for Cervical Cancer Screening,10210372,R01CA254576,"['Acetic Acids', 'Address', 'Algorithms', 'Automobile Driving', 'Biological Assay', 'Biopsy', 'Cervical', 'Cervical Cancer Screening', 'Cervical Intraepithelial Neoplasia', 'Cervix Uteri', 'Characteristics', 'Classification', 'Clinical', 'Collaborations', 'Colposcopes', 'Colposcopy', 'Cytology', 'Data Analyses', 'Development', 'Diagnosis', 'Effectiveness', 'FDA approved', 'General Population', 'Generations', 'Goals', 'Gold', 'HIV', 'Health Services', 'High Prevalence', 'Histologic', 'Human Papilloma Virus Vaccine', 'Human Papillomavirus', 'Human papilloma virus infection', 'Image', 'Imaging technology', 'Incidence', 'India', 'Infrastructure', 'Investigation', 'Lesion', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Output', 'Performance', 'Predictive Value', 'Prevalence', 'Price', 'Primary Prevention', 'Procedures', 'Provider', 'Randomized Clinical Trials', 'Reporting', 'Resources', 'Risk', 'Safety', 'Secondary Prevention', 'Sensitivity and Specificity', 'Services', 'South Africa', 'South African', 'Specificity', 'Testing', 'Time', 'Triage', 'Universities', 'Visit', 'Visual', 'Woman', 'Women&apos', 's Group', 'Work', 'World Health Organization', 'antiretroviral therapy', 'automated visual evaluation', 'base', 'clinical research site', 'cloud based', 'cost', 'cost effective', 'cost effectiveness', 'digital', 'digital imaging', 'effectiveness study', 'high risk population', 'histological specimens', 'improved', 'low and middle-income countries', 'machine learning algorithm', 'mortality', 'new technology', 'point of care', 'programs', 'recruit', 'screening', 'screening program', 'success', 'viral DNA']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,519004
"Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence Summary / Abstract Objective — The goal of this proposal is to develop and optimize novel deep learning (DL) assisted approaches to improve diagnosis and clinical decision-making for congenital heart disease (CHD). This will be achieved by using DL, machine learning (ML), and related methods to extract diagnosis, biometric characterizations, and other information from fetal ultrasound imaging. Notably, this work includes a clinical translational evaluation of these methods in a population-wide imaging collection spanning two decades, tens of thousands of patients, and several clinical centers. Background — Despite clear and numerous benefits to prenatal detection of CHD and an ability for fetal ultrasound to detect over 90% of CHD lesions in theory, in practice the fetal CHD detection rate is closer to 50%. Prior literature suggests a key cause of this startling diagnosis gap is suboptimal acquisition and interpretation of fetal heart images. DL is a novel data science technique that is proving excellent at pattern recognition in images. DL models are a function of the design and tuning of a neural network architecture, and the curation and processing of the image data used to train the network. Preliminary Studies — We have assembled a multidisciplinary team of experts in echocardiography and CHD (Drs. Grady, Levine, and Arnaout), DL and data science (Drs. Keiser, Butte and Arnaout), and statistics and clinical research (Drs. Arnaout and Grady) and secured access to tens of thousands of multicenter (UCSF and six other centers), multimodal fetal imaging studies. We have created a scalable image processing pipeline to transform clinical studies into image data ready for computing. We have designed and trained DL models to find key cardiac views in fetal ultrasound, calculate standard and advanced fetal cardiac biometrics from those views, and distinguish between normal hearts and certain CHD lesions. Hypothesis — While DL is powerful, much work is still needed to adapt it for clinical imaging and to translate it toward clinically relevant performance in patient populations. We hypothesize that an integrated ensemble DL/ML approach can lead to vast improvements in fetal CHD diagnosis. Aims — To this end, the main Aims of this proposal are (1) to develop and optimize neural network architectures and efficient data inputs to relieve key performance bottlenecks for DL in fetal CHD; and (2) to deploy DL models population-wide to evaluate their ability to improve diagnosis, biometric characterization, and precision phenotyping over the current standard of care. Our methods include DL/ML algorithms and retrospective imaging analysis. Environment and Impact — This work will be supported in an outstanding environment for research at the crossroads of data science, cardiovascular and fetal imaging, and translational informatics. The work proposed will provide valuable tools and insight into designing and evaluating both the data and the algorithms for DL on imaging for clinically relevant goals, and will lay important groundwork for DL-assisted phenotyping for both clinical use and precision medicine research. Project Narrative Medical imaging is critical to almost every type of diagnostic and management decision, but human interpretation of medical images can lack accuracy and reproducibility. By developing machine learning methods for analyzing medical images, the work in our proposal can improve diagnostic accuracy in medical imaging, for both clinical and research uses.",Improving cardiovascular image-based phenotyping using emerging methods in artificial intelligence,10136081,R01HL150394,"['Abdomen', 'Address', 'Adult', 'Age', 'Aging', 'Apical', 'Artificial Intelligence', 'Biometry', 'Birth', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Early treatment', 'Echocardiography', 'Environment', 'Evaluation', 'Face', 'Fetal Heart', 'Goals', 'Heart', 'Heart Abnormalities', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Label', 'Lead', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phenotype', 'Physicians', 'Population', 'Pregnant Women', 'Provider', 'Psyche structure', 'Quality Control', 'Rare Diseases', 'Reproducibility', 'Research', 'Secure', 'Structure', 'Supervision', 'Surveys', 'Techniques', 'Testing', 'Time', 'Trachea', 'Training', 'Translating', 'Ultrasonography', 'Variant', 'Work', 'base', 'cardiovascular imaging', 'clinical center', 'clinical decision-making', 'clinical imaging', 'clinically relevant', 'comorbidity', 'computerized data processing', 'congenital heart disorder', 'cost', 'data curation', 'data harmonization', 'deep learning', 'deep learning algorithm', 'design', 'detection test', 'diagnostic accuracy', 'disease diagnosis', 'fetal', 'fetal diagnosis', 'heart imaging', 'image guided', 'image processing', 'imaging study', 'improved', 'insight', 'learning network', 'machine learning algorithm', 'machine learning method', 'model design', 'mortality', 'multidisciplinary', 'multimodality', 'neural network', 'neural network architecture', 'novel', 'patient population', 'precision medicine', 'prenatal', 'prevent', 'programs', 'repaired', 'screening', 'standard of care', 'statistics', 'theories', 'tool']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,821265
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,10077550,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2021,190362
"Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at managing the optimal care for individual cases due to difficulties of accurately assessing the potential progression and its speed and magnitude. These difficulties are due to a variety of causes that change over the course of the disease, including large inter-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we propose novel agnostic data-driven deep learning approaches to detect glaucoma and accurately forecast its progression that are optimized to each individual case. We will use state- of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. Instead of relying on the conventional knowledge-based approaches (e.g. quantifying tissues known to be significantly associated with glaucoma such as retinal nerve fiber layer), the proposed cutting-edge agnostic deep learning approaches determine the features responsible for future structural and functional changes out of thousands of features autonomously by learning from the provided large longitudinal dataset. This program will advance the use of structural and functional information obtained in the clinics with a substantial impact on the clinical management of subjects with glaucoma. Furthermore, the developed methods have potentials to be applied to various clinical applications beyond glaucoma and ophthalmology. Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies using agnostic deep learning approaches that will substantially improve detection of glaucoma and its progression forecasting and monitoring in order to prevent blindness.",Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes,10089451,R01EY030929,"['3-Dimensional', 'Area', 'Atlases', 'Blindness', 'Brain', 'Caring', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Management', 'Collaborations', 'Color', 'Complex', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Disease model', 'Early Diagnosis', 'Eye', 'Future', 'Glaucoma', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurable', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Ophthalmology', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Performance', 'Research', 'Research Proposals', 'Retina', 'Sampling', 'Series', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Vision', 'Visit', 'Visual Fields', 'analytical method', 'base', 'case-by-case basis', 'clinical application', 'clinical practice', 'cohort', 'computerized', 'cost', 'deep learning', 'falls', 'feature selection', 'follow-up', 'image processing', 'imaging modality', 'improved', 'in vivo', 'individual patient', 'innovation', 'insight', 'knowledge base', 'longitudinal analysis', 'longitudinal dataset', 'machine learning method', 'novel', 'ocular imaging', 'personalized approach', 'personalized medicine', 'personalized predictions', 'predictive modeling', 'preservation', 'prevent', 'programs', 'retinal nerve fiber layer', 'theories', 'tool', 'treatment planning', 'trend']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,376028
"Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging PROJECT SUMMARY/ABSTRACT There has been significant work in creating tools that leverage computer vision algorithms to automate medical image analysis. Most of these algorithms have been developed for natural images, which are usually single static images that can be treated individually. However, medical images are usually part of a study that may include various views and orientations that are considered together with other clinical data when making a diagnosis. Three dimensional convolution neural networks (CNN) can address this issue in part when images are evenly spaced, but many medical imaging modalities such as ultrasound (US), fluoroscopy, and biopsy imaging have variable orientations and irregular spacing. Graph convolutional networks (GCN) have the potential to address this issue as they generalize the assumptions of CNNs to work on arbitrarily structured graphs. Automatic thyroid nodule detection in ultrasound (US) is one application that such a graph-based approach could have a large impact. The thyroid cancer incidence rate has tripled in the past thirty years, with an estimated cost of $18-21 billon in 2019. US is the imaging modality of choice, which consists of multiple 2D images of different locations and orientations. US readings are often vague and subjective in nature, which has resulted in a steady increase in the number of biopsies performed over the past 20 years. It is estimated that about one-third of all thyroid biopsy procedures performed in the United States are medically unnecessary, leading to the unmet need for noninvasive diagnostic tests that can reliably identify which nodules require a biopsy. The research objective of this R21 is to develop a new graph-based approach to leverage spatial information contained within imaging studies that will be combined with biomarkers and other known risk factors. Our graph model will enable more complete detection of thyroid cancer, as well as the prediction of future cancer aggression, both with spatially localized explanations. GCN features will be used to predict voxel-level cancer suspicion, thereby enabling a novel method for performing “imaging biopsy.” Finally, voxel-level suspicion maps will be aggregated into patient-level quantitative imaging biomarkers and combined with clinical data to create a multimodal nomogram for performing risk stratification. PROJECT NARRATIVE Medical image analysis plays an important role in computer aided detection and diagnosis, but usually focuses on individual images in isolation. Graph convolutional networks have the ability to utilize the relationships be- tween images in a study to aggregate information and make a more accurate evaluation. The focus of this project is to implement a graph-based approach for distinguishing indolent from aggressive thyroid cancer, thus pre- venting patients from receiving unnecessary treatment and incurring associated negative functional outcomes.",Predicting the Presence of Clinically Significant Thyroid Cancer using Ultrasound Imaging,10110934,R21EB030691,"['3-Dimensional', 'Address', 'Age', 'Aggressive behavior', 'Algorithms', 'Architecture', 'Attention', 'Biological Markers', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Computer Vision Systems', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Diagnostic tests', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fluoroscopy', 'Functional disorder', 'Future', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'Indolent', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Manuals', 'Maps', 'Medical', 'Medical Imaging', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Nodule', 'Nomograms', 'Pathology', 'Patient risk', 'Patients', 'Pattern', 'Physiological', 'Play', 'Probability', 'Procedures', 'Protocols documentation', 'Reading', 'Research', 'Risk', 'Risk Factors', 'Role', 'Savings', 'Series', 'Signal Transduction', 'Structure', 'Techniques', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Tweens', 'Ultrasonography', 'United States', 'Work', 'base', 'body system', 'cancer imaging', 'cancer risk', 'clinical imaging', 'clinically significant', 'computer aided detection', 'convolutional neural network', 'cost estimate', 'deep learning', 'detection platform', 'functional outcomes', 'image registration', 'imaging biomarker', 'imaging modality', 'imaging study', 'innovation', 'mortality', 'multimodality', 'network models', 'noninvasive diagnosis', 'novel', 'patient stratification', 'predictive modeling', 'prevent', 'quantitative imaging', 'radiologist', 'risk stratification', 'tool', 'treatment planning', 'unnecessary treatment', 'ward']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,224566
"Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography Abstract Colon cancer is the second leading cause of cancer deaths for men and women in the United States, even though it could be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, the current standard of cathartic bowel preparation for CTC and optical colonoscopy (OC) is poorly tolerated by patients and has been recognized as a major barrier to colorectal examinations. Our advanced non-cathartic multi-center computer-assisted CTC trial showed that non-cathartic CTC is easily tolerated by patients and that radiologists who use computer-aided detection (CADe) can detect large polyps in size in non-cathartic CTC with high sensitivity, comparable to that of OC. However, SF6-lesions (serrated lesions, flat lesions <3 mm in height, and polyps 6 – 9 mm in size) were a significant source of false negatives in the trial. The challenges of detection and visualization of these SF6-lesions in non-cathartic CTC are caused largely by the inability of the current single-energy CTC technique to differentiate between soft tissues, fecal tagging, and their partial volumes with lumen air. We propose to employ multi-spectral CTC precision imaging and artificial intelligence (AI) to overcome these inherent limitations of non-cathartic CTC. Our goal in this project is to develop a novel deep-learning AI (DEEP-AI) scheme for multi-spectral multi-material (MUSMA) precision imaging, which will use deep super-learning of high-quality spectral CTC (spCTC) precision images to boost the diagnostic performance of non-cathartic CTC. We hypothesize that (1) high-quality MUSMA precision images can be reconstructed from ultra-low-dose (<1 mSv) spCTC scans, (2) DEEP-AI will yield a detection sensitivity for ≥6 mm SF6-lesions comparable to that of OC, and that (3) the use of DEEP-AI as first reader will significantly improve radiologists’ detection performance for SF6-lesions and reduce interpretation time compared with unaided reading, and that it will yield a detection accuracy comparable to that of OC. Our specific aims are (1) to establish a non-cathartic spCTC and MUSMA precision image database, (2) to develop a DEEP-AI Interpretation System for visualization and detection of SF6-lesions, and (3) to evaluate the clinical benefit of the DEEP-AI Interpretation System with non-cathartic spCTC cases. Successful development of the proposed DEEP-AI Interpretation System will substantially improve human readers’ performance in the detection of SF6-lesions from non-cathartic CTC examinations that address the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Although colon cancer is the second leading cause of cancer deaths for men and women in the United States, it could be prevented by early detection and removal of its precursor lesions. Successful development of the proposed deep-learning artificial intelligence scheme will substantially improve human readers’ performance in detecting colorectal polyps from non-cathartic CTC examinations that addresses the problem of patient adherence to colorectal screening guidelines. Such a scheme will make non-cathartic CTC a highly accurate and acceptable screening option for large populations, leading to an increased colorectal screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Spectral precision imaging for early diagnosis of colorectal lesions with CT colonography,10054168,R01CA212382,"['Address', 'Advisory Committees', 'Air', 'American Cancer Society', 'American College of Radiology', 'Artificial Intelligence', 'Cancer Etiology', 'Catharsis', 'Cathartics', 'Cessation of life', 'Clinical', 'Clinical Research', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Polyp', 'Computed Tomographic Colonography', 'Computer Assisted', 'Contrast Media', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Early Diagnosis', 'Enrollment', 'Excision', 'Goals', 'Height', 'Human', 'Image', 'Image Analysis', 'Insurance Carriers', 'Intestines', 'Learning', 'Lesion', 'Location', 'Medicare', 'Morphologic artifacts', 'Noise', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polyps', 'Population', 'Preparation', 'Preventive service', 'Privatization', 'Protocols documentation', 'Reader', 'Reading', 'Safety', 'Scanning', 'Scheme', 'Societies', 'Source', 'System', 'Techniques', 'Thinness', 'Time', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Visualization', 'Woman', 'X-Ray Computed Tomography', 'colorectal cancer screening', 'compliance behavior', 'computer aided detection', 'computer center', 'deep learning', 'detection sensitivity', 'image reconstruction', 'improved', 'men', 'mortality', 'novel', 'older patient', 'prevent', 'radiologist', 'radiomics', 'reconstruction', 'screening', 'screening guidelines', 'soft tissue', 'spectrograph', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,120631
"Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis Project Summary Blood culture sensitivity in neonates is poor but is the “Gold Standard” for the diagnosis of sepsis. Universal genotyping of pathogen genomic sequences using High Resolution Melt (U-HRM) provides a simple, low cost, rapid, and modern alternative to blood culture testing. By measuring the fluorescence of an intercalating dye as PCR-amplified pathogen DNA fragments are heated and disassociate, sequence defined melt curves are generated with single-nucleotide resolution in a closed-tube reaction. We have advanced U- HRM into a digital PCR format (U-dHRM), where DNA sequences that are present in mixtures are individually amplified and identified as is needed for polymicrobial infections. We have also established unique signature melt curves for 37 bacterial species that commonly infect older children and adults and automatically identify them using machine learning technology. With the goal of creating an accurate and valid test for the timely diagnosis of neonatal sepsis, we will advance this technology to identify unique fungal, viral, and bacterial HRM signatures along with antibiotic resistance genes with an accuracy of 99-100% on minimal blood volume (1mL). Our aims are: Aim 1. Optimize and assess the U-dHRM platform for neonatal bacteremia diagnosis by expand our bacterial database (13 additional bacteria) to detect causes of >99% of neonatal bacterial infections, expand our antibiotic resistance gene database to include five clinically actionable genes, and assessing the performance of the system for bacteremia diagnosis in mock and clinical whole blood samples; Aim 2. Advance the U-dHRM platform for simultaneous detection of fungal and viral pathogens by upgrading our optical system to enable expansion to fungal and viral detection in a high-throughput format, multiplexing the assay to expand to viral and fungal pathogens causing >99% non-bacterial infections, and conducting analytical validation of the multiplexed platform using mock whole blood samples; and Aim 3. Advance the machine learning algorithm for detection of emerging pathogens by developing and integrating an anomaly detection algorithm for reporting emerging pathogens that are not included in our database and validating the algorithm using data generated in Aims 1 and 2. Thus, this proposal directly addresses the funding call by applying a multidisciplinary approach to overcome the biomedical challenge of rapidly diagnosis sepsis, a hidden public health disaster. Project Narrative Digital High Resolution Melting (dHRM) of DNA combined with machine learning creates unique “fingerprints"" for microbes and antibiotic resistance, allowing for faster and more precise detection and treatment of pathogen(s) causing sepsis. This project will advance and test the clinical performance of dHRM technology in the diagnosis of neonatal sepsis. Our goal is to rapidly and accurately identify pathogens and their resistance markers to facilitate accurate antimicrobial therapy, reducing antibiotic overuse in non-infected infants.",Digital High Resolution Melt and Machine Learning for Rapid and Specific Diagnosis in Neonatal Sepsis,10151581,R01AI134982,"['Address', 'Adult', 'Algorithms', 'Antibiotic Resistance', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Biological Assay', 'Birth Weight', 'Blood', 'Blood Volume', 'Blood specimen', 'Child', 'Clinical', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disasters', 'Dyes', 'Emerging Technologies', 'Exposure to', 'Fingerprint', 'Fluorescence', 'Funding', 'Genes', 'Genome', 'Genotype', 'Goals', 'Gold', 'Hour', 'Immune response', 'Individual', 'Infection', 'Machine Learning', 'Measures', 'Microbe', 'Modernization', 'Neonatal', 'Nucleotides', 'Optics', 'Organism', 'Patients', 'Performance', 'Predisposition', 'Public Health', 'RNA', 'Reaction', 'Reporting', 'Research', 'Resistance', 'Resolution', 'Sampling', 'Sepsis', 'Symptoms', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Tube', 'United States', 'Validation', 'Variant', 'Very Low Birth Weight Infant', 'Viral', 'Whole Blood', 'Woman', 'antimicrobial', 'base', 'circulating DNA', 'clinically actionable', 'clinically relevant', 'cost', 'detection limit', 'diagnosis standard', 'digital', 'early onset', 'interdisciplinary approach', 'intrapartum', 'machine learning algorithm', 'melting', 'microbial', 'neonatal sepsis', 'neonate', 'overtreatment', 'pathogen', 'pathogen genome', 'pathogen genomics', 'pathogenic fungus', 'pathogenic virus', 'point of care', 'premature', 'rapid diagnosis', 'resistance gene', 'sample collection', 'septic', 'therapy resistant', 'viral detection']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,469594
"Focal nerve fiber layer reflectance analysis for glaucoma evaluation PROJECT SUMMARY Glaucoma is a leading cause of blindness, and effective glaucoma management requires early detection. Nerve fiber layer (NFL) thickness measurement by optical coherence tomography (OCT) is useful for confirming the diagnosis of glaucoma, but its diagnostic sensitivity is not sufficient to be used alone for population-based screening.  NFL reflectivity is reduced in glaucoma subjects, presumably due to loss of axons and axonal microtubule content. But its diagnostic value is diminished by its dependence on the incident angle of the OCT beam, which is highly variable in routine clinical imaging. We hypothesize that the diagnostic accuracy can be boosted by reducing incidence angle effects with azimuthal filtering of NFL reflectance profile, and by analysis of focal rather than average reflectance changes. The preliminary result, bases on 100 normal and glaucoma eyes, showed that the diagnostic sensitivity was significantly improved from 71% for average NFL thickness to 97% for focal NFL reflectance loss in PG eyes, at a 99% specificity cutoff. We propose to validate this result in the large Advanced Imaging for Glaucoma (AIG) study dataset that comprises 249 perimetric glaucoma (PG), 252 pre-perimetric glaucoma (PPG), and 145 normal participants. The AIG study has an average follow-up of more than 4 years, which also allows assessment of the accuracy in predicting glaucoma progression. 1. Reproduce the high diagnostic accuracy of focal NFL reflectance loss analysis using the large AIG  dataset. If we could again demonstrate high diagnostic accuracy in the AIG dataset, especially in the PPG  and early PG subgroups, this could bring OCT glaucoma evaluation into the realm of population screening.  The primary performance metric will be the diagnostic sensitivity at a fixed 99% specificity cut point. 2. Use focal NFL reflectance loss to predict visual field (VF) conversion and progression. In the AIG  study, focal thinning of the macular ganglion cell complex (GCC) and peripapillary nerve fiber layer (NFL)  were found to be the best predictors of VF conversion (development of glaucomatous VF abnormality in an  eye with normal baseline VF) and progression (significant worsening of VF). We hypothesize that focal  NFL reflectance loss would have even better predictive accuracy. Predictive accuracy will be assessed  using the area under the receiver operating curve (AROC) and logistic regression (odds ratio). 3. Combine OCT reflectance and structural maps using machine learning to improve glaucoma  diagnostic accuracy. A combination of disc, peripapillary, and macular thickness parameters had  previously been shown to be synergistic, producing higher AROC than any single parameter. We  hypothesize that the addition of the novel NFL reflectance loss map to the set of input parameters will  further enhance the diagnostic accuracy of a machine learning algorithm. PROJECT NARRATIVE Nerve fiber layer (NFL) thickness using OCT is widely used in clinic for glaucoma diagnosis, but the diagnostic sensitivity is limited. Combination of NFL reflectivity and other structural OCT information promises to improve the diagnostic accuracy to a level where population-based screening would be feasible.",Focal nerve fiber layer reflectance analysis for glaucoma evaluation,10108277,R21EY032146,"['Algorithms', 'Area', 'Axon', 'Blindness', 'Clinic', 'Clinical Management', 'Complex', 'Data Set', 'Dependence', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Sensitivity', 'Diagnostic Specificity', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Glaucoma', 'Image', 'Incidence', 'Logistic Regressions', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Nerve Fibers', 'Odds Ratio', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Performance', 'Population', 'Retina', 'Sampling', 'Scanning', 'Specificity', 'Structure', 'Subgroup', 'System', 'Thick', 'Thinness', 'Visual Fields', 'base', 'clinical imaging', 'cost', 'diagnostic accuracy', 'disorder risk', 'follow-up', 'ganglion cell', 'improved', 'machine learning algorithm', 'macula', 'novel', 'population based', 'screening']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2021,192500
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10188526,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2021,388359
