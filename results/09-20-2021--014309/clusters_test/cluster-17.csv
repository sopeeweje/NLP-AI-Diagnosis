text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Mapping Algorithmic State Space in the Human Brain Abstract Humans have a remarkable ability to flexibly interact with the environment. A compelling demonstration of this cognitive flexibility is our ability to respond correctly to novel contextual situations on the first attempt, without prior rehearsal. We refer to this ability as ‘ad hoc self-programming’: ‘ad hoc’ because these new behavioral repertoires are cobbled together on the fly, based on immediate demand, and then discarded when no longer necessary; ‘self-programming’ because the brain has to configure itself appropriately based on task demands and some combination of prior experience and/or instruction. The overall goal of our research effort is to understand the neurophysiological and computational basis for ad hoc self-programmed behavior.  Our previous U01 project (NS 108923) focused on how these programs of action are initially created. Our results thus far have revealed tantalizing notions of how the brain represents these programs and navigates through them. In this proposal, therefore, we focus on the question of how these mental programs are executed. Based on our preliminary findings and critical conceptual work, we propose that the medial temporal lobe (MTL) and ventral prefrontal cortex (vPFC) creates representations of the critical elements of these mental programs, including concepts such as ‘rules’ and ‘locations’, to allow for effective navigation through the algorithm.  These data suggest the existence of an ‘algorithmic state space’ represented in medial temporal and prefrontal regions. This proposal aims to understand the neurophysiological underpinnings of this algorithmic state space in humans. By studying humans, we will profit from our species’ powerful capacity for generalization to understand how such state spaces are constructed. We therefore leverage the unique opportunities available in human neuroscience research to record from single cells and population-level signals, as well as to use intracranial stimulation for causal testing, to address this challenging problem.  In Aim 1 we study the basic representations of algorithmic state space using a novel behavioral task that requires the immediate formation of unique plans of action. Aim 2 directly compares representations of algorithmic state space to that of physical space by juxtaposing balanced versions of spatial and algorithmic tasks in a virtual reality (VR) environment. Finally, in Aim 3, we test hypotheses regarding interactions between vPFC and MTL using intracranial stimulation. Project Narrative In our everyday lives, we frequently encounter situations we have never previously faced and yet are required to make an appropriate response on the first try. This ability to rapidly and flexibly ‘self-program’ is one of the hallmark features of human intelligence. The proposed studies leverage exciting new developments in neuroscience, neurosurgery, engineering, and artificial intelligence to understand the neuronal circuitry underlying this amazing capacity.",Mapping Algorithmic State Space in the Human Brain,10199622,U01NS121472,"['Acute', 'Address', 'Algorithms', 'Amaze', 'Anterior', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Chronic', 'Cinnamon - dietary', 'Cognitive', 'Complex', 'Computer Models', 'Data', 'Development', 'Devices', 'Elements', 'Engineering', 'Environment', 'Epilepsy', 'Etiology', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Implant', 'Individual', 'Inpatients', 'Instruction', 'Intelligence', 'Link', 'Location', 'Medial', 'Modeling', 'Monitor', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Participant', 'Patients', 'Pattern', 'Population', 'Prefrontal Cortex', 'Property', 'Psyche structure', 'Reporting', 'Research', 'Rodent', 'Role', 'Series', 'Signal Transduction', 'Structure', 'Task Performances', 'Telemetry', 'Temporal Lobe', 'Testing', 'Time', 'Variant', 'Work', 'base', 'cell cortex', 'cognitive neuroscience', 'cohort', 'computational basis', 'design', 'entorhinal cortex', 'experience', 'flexibility', 'innovation', 'mental representation', 'neuronal circuitry', 'neurophysiology', 'neurosurgery', 'novel', 'operation', 'physical state', 'predictive modeling', 'programs', 'rehearsal', 'relating to nervous system', 'response', 'virtual reality', 'virtual reality environment', 'way finding']",NINDS,BAYLOR COLLEGE OF MEDICINE,U01,2021,1509141
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,10158538,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2021,93342
"Clinical and genetic analysis of retinopathy of prematurity Project Summary The long-term goal of this project is to establish a quantitative framework for retinopathy of prematurity (ROP) care based on clinical, imaging, genetic, and informatics principles. In the previous grant period, we have developed artificial intelligence methods for ROP diagnosis, but real-world adoption has been limited by lack of prospective validation and by perception of these systems as “black boxes” that do not explain their rationale for diagnosis. Furthermore, although biomedical research data are being generated at an enormous pace, much less work has been done to integrate disparate scientific findings across the spectrum from genomics to imaging to clinical medicine. This renewal will address current gaps in knowledge in these areas. Our overall hypotheses are that developing a quantitative framework for ROP care using artificial intelligence and analytics will improve clinical disease management, that building “explainable” artificial intelligence systems will enhance clinical acceptance and educational opportunities, and that analysis of relationships among clinical, imaging, environmental, and genetic findings, in ROP will improve understanding of disease pathogenesis and risk. These hypotheses will be tested using three Specific Aims: (1) Evaluation performance of an artificial intelligence system for ROP diagnosis and screening prospectively. This will include: (a) recruit a target of over 2000 eye exams including wide-angle retinal images from 375 subjects at 5 centers, (b) optimize an image quality detection algorithm we have recently developed, and (c) analyze system accuracy for ROP diagnosis and screening (using a novel quantitative vascular severity scale). (2) Improve the interpretability of our existing artificial intelligence methods for ROP diagnosis. This will include: (a) increase “explainability” of systems by combining deep learning with traditional feature extraction methods, (b) develop neural networks to identify changes between serial images, and (c) evaluate these methods through systematic feedback by experts. (3) Develop integrated models for ROP pathogenesis and risk. This will include: (a) build and improve ROP risk prediction models based on clinical, image, and demographic features, and (b) integrate genetic, imaging, clinical, and environmental variables through genetic risk prediction by machine learning, by investigating casual relationships with genetic variants and genetic risk scores, and by incorporating SNP associations with gene expression measurements to identify functional genes of ROP. Ultimately, these studies will significantly reduce barriers to adoption of technologies such as artificial intelligence for clinicians, and will demonstrate a prototype for health information management which combines genotypic and phenotypic data. This project will be performed by a multi-disciplinary team of investigators who have worked successfully together for nearly 10 years, and who have expertise in ophthalmology, biomedical informatics, computer science, computational biology, ophthalmic genetics, genetic analysis, and statistical genetics. Project Narrative ROP is a leading cause of childhood blindness in the US and throughout the world, and the number of infants at risk for disease is increasing as the rate of premature birth rises. Rapidly-progressive changes associated with retinal vascular development may be visualized by clinical examination, captured by wide-angle imaging, and analyzed genetically. This project will develop, enhance, and validate artificial intelligence and analytic tools to help clinicians identify infants at risk for severe ROP using image analysis, genetic analysis, and integrative informatics that combines these factors – while also providing insight about disease pathogenesis.",Clinical and genetic analysis of retinopathy of prematurity,10206145,R01HD107493,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biomedical Research', 'Blindness', 'Blood Vessels', 'Caring', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Research', 'Cohort Studies', 'Computational Biology', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Environment', 'Evaluation', 'Expert Systems', 'Feedback', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Infant', 'Informatics', 'Information Management', 'International', 'Knowledge', 'Longitudinal Studies', 'Machine Learning', 'Macular degeneration', 'Measurement', 'Medical Genetics', 'Mendelian randomization', 'Methods', 'Modeling', 'Molecular Genetics', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Other Genetics', 'Paper', 'Pathogenesis', 'Peer Review', 'Perception', 'Performance', 'Phenotype', 'Predisposition', 'Premature Birth', 'Premature Infant', 'Publishing', 'Reference Standards', 'Research', 'Research Personnel', 'Retina', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Severities', 'System', 'Technology', 'Testing', 'United States', 'Validation', 'Work', 'analytical tool', 'base', 'biomedical informatics', 'care delivery', 'clinical Diagnosis', 'clinical examination', 'clinical phenotype', 'clinical risk', 'clinically significant', 'computer science', 'data access', 'data integration', 'deep learning', 'detection platform', 'diagnosis standard', 'disorder risk', 'feature extraction', 'genetic analysis', 'genetic variant', 'high risk', 'imaging genetics', 'improved', 'insight', 'multidisciplinary', 'multiple data types', 'neovascular', 'neural network', 'novel', 'phenotypic data', 'prospective', 'prototype', 'real world application', 'recruit', 'retinal imaging', 'risk prediction', 'risk prediction model', 'screening', 'serial imaging', 'supplemental oxygen']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,640901
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,10136061,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2021,579506
"AICORE-kids: Artificial Intelligence COVID-19 Risk AssEssment for kids This work is directed at characterizing pediatric COVID-19 and stratifying incoming patients by projected (future) disease severity. Such stratification has several implications: immediately improving treatment planning, and as disease mechanistic pathways are uncovered, directing treatment. Predicting future severity will inform the risks of outpatient treatment; to the patients themselves, their family, other caregivers/cohabitants, and to schools and employers. As varying levels of “reopening” are adopted across the country (and the world), such prognostication will inform policy on the handling of pediatric carriers in the community. Based on our preliminary analysis we assert that a combination of novel assays including quantitative serology inflammatory markers (cytokine/chemokine profiles, immune profiles), transcriptomics, epigenomics, longitudinal physiological monitoring, time series analysis, imaging, radiomics and clinical observation including social determinants of health, contains adequate information even at early stages of infection to stratify the disease and predict disease severity. We propose an artificial intelligence/machine learning approach to integrate this rich and heterogeneous dataset, characterize the spectrum of disease and identify biosignatures that predict severity in progressive disease. To facilitate translation of the approaches developed in this work to a wide user community, we incorporate a Translational Development function, to oversee the design-control process and ensure readiness of our methods for regulatory review. Incorporated into our timelines are appropriate regulatory milestones intended to conform with the Emergency Use Authorization (EUA) programs in effect for SARS- CoV-2 diagnostics. We propose an artificial intelligence/machine learning approach to integrate a rich and heterogeneous dataset on COVID-19 in children, characterize the spectrum of disease and identify biosignatures that predict severity in progressive disease. To facilitate translation of the approaches developed in this work to a wide user community, we incorporate a Translational Development function, to oversee the design-control process and ensure readiness of our methods for regulatory review. Incorporated into our timelines are appropriate regulatory milestones intended to conform with the Emergency Use Authorization (EUA) programs in effect for SARS-CoV-2 diagnostics.",AICORE-kids: Artificial Intelligence COVID-19 Risk AssEssment for kids,10272787,R61HD105593,"['2019-nCoV', 'Admission activity', 'Adopted', 'Adoption', 'Algorithms', 'Ambulatory Care', 'Artificial Intelligence', 'Award', 'Biological Assay', 'Blood', 'COVID-19', 'COVID-19 diagnostic', 'COVID-19 patient', 'COVID-19 severity', 'Caregivers', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Communities', 'Country', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Development', 'Diagnostic Procedure', 'Differentiation Antigens', 'Disease', 'Emergency Situation', 'Ensure', 'FDA Emergency Use Authorization', 'Family', 'Future', 'Image', 'Immune', 'Individual', 'Infection', 'Inherited', 'Laboratories', 'Machine Learning', 'Methods', 'Monitor', 'Mucocutaneous Lymph Node Syndrome', 'Multisystem Inflammatory Syndrome in Children', 'Participant', 'Pathway interactions', 'Patients', 'Pediatric Hospitals', 'Phase', 'PhenX Toolkit', 'Physiologic Monitoring', 'Policies', 'Preparation', 'Process', 'Progressive Disease', 'Psychological Transfer', 'Publishing', 'RADx Radical', 'Readiness', 'Records', 'Risk', 'Risk Assessment', 'Schools', 'Serology', 'Severities', 'Severity of illness', 'Speed', 'Spottings', 'Stratification', 'System', 'Testing', 'Texas', 'Time Series Analysis', 'TimeLine', 'Training', 'Translations', 'Validation', 'Work', 'assay development', 'base', 'biomedical referral center', 'biosignature', 'case-based', 'chemokine', 'cytokine', 'data integration', 'data standards', 'design', 'epigenomics', 'genetic variant', 'hemodynamics', 'heterogenous data', 'improved', 'inflammatory marker', 'interoperability', 'learning progression', 'learning strategy', 'machine learning algorithm', 'next generation', 'novel', 'patient population', 'pediatric patients', 'prognostic', 'programs', 'radiomics', 'repository', 'response', 'social health determinants', 'transcriptomics', 'treatment planning']",NICHD,BAYLOR COLLEGE OF MEDICINE,R61,2021,817546
"AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition ABSTRACT Dietary intake is a complex human behavior that drives disease risk and corresponding economic and healthcare burdens worldwide. Poor diet is the leading cause of death in the US and a known driver of obesity – a global epidemic. A major contributor to poor diet is food eaten away from home, such as restaurant foods. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods. Accurate approaches and tools to evaluate food and nutrient intake are essential in monitoring the nutritional status of individuals. There is a critical need for real-time data capture that minimizes burden and reduces error. While progress has been made, there is no tool available that accurately and automatically estimates foods left unconsumed in a meal. Two major limitations of existing systems is the reliance of a fiducial marker for food detection and volume estimation, and reliance on humans – either the respondent or a trained researcher – to estimate the portion of food leftover. This application leverages novel technology to remove those limitations. The long-term research goal is to utilize digital imaging (DI), artificial intelligence (AI) and computer vision (CV) techniques to develop a novel hybrid methodology for rapid, accurate measurement of dietary intake. To attain this goal, our objective in this R21 application is to refine and test a system architecture that (a) uses digital images to record dietary intake in real-time and (b) uses AI and CV techniques to identify food/beverage items and determine amounts leftover. We plan to build on our current prototype in which digital food images are captured before and after the meal, analyzed to detect the food items, a three-dimensional (3-D) virtual model constructed, and volume remaining after the meal estimated, which will be used to calculate the amount leftover based on the initial volume. Volume consumed will be converted to weight and linked to public-use nutrition information. These calorie estimates will be compared against calories those from (a) DIs coded by trained research staff and (b) weighed plate waste methodology. Our expectation is to develop a valid system architecture for rapidly estimating dietary intake. The outcome of this proposal is expected to have a significant positive impact, enabling nutrition and health researchers to collect high-quality food consumption data in real world settings, increasing knowledge of dietary patterns and improving capacity to assess dietary interventions. This work will lead to an R01 application that will expand food types and meal settings and test the utility of our system among consumers. Project Narrative Solutions to address the global obesity epidemic are urgently needed. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods, a known driver of obesity. This study integrates nutrition science, computer science, and engineering to develop and test a new method for assessing dietary intake, and if successful would yield a rapid, reliable, accurate and cost- effective tool.",AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition,10163822,R21CA250024,"['3-Dimensional', 'Address', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Behavior', 'Beverages', 'Body Weight decreased', 'Calories', 'Cause of Death', 'Cellular Phone', 'Code', 'Complex', 'Computer Vision Systems', 'Consumption', 'Data', 'Databases', 'Detection', 'Development', 'Diet Records', 'Dietary Assessment', 'Dietary Intervention', 'Dietary Practices', 'Dietary intake', 'Economics', 'Engineering', 'Epidemic', 'Food', 'Goals', 'Gold', 'Health', 'Healthcare', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Intake', 'Intervention', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Nutrient', 'Nutritional Science', 'Nutritional status', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Output', 'Participant', 'Research', 'Research Personnel', 'Research Training', 'Respondent', 'Restaurants', 'Side', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unhealthy Diet', 'Validation', 'Weight', 'Work', 'base', 'computer science', 'cost', 'cost effective', 'design', 'dietary', 'digital', 'digital imaging', 'disorder risk', 'expectation', 'food consumption', 'food quality', 'handheld mobile device', 'improved', 'knowledge base', 'new technology', 'novel', 'nutrition', 'prototype', 'success', 'system architecture', 'tool', 'virtual model', 'wasting', 'weight maintenance']",NCI,TUFTS UNIVERSITY BOSTON,R21,2021,197745
"Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics Abstract The primary objective is to develop an artificial intelligence-centric, quantitative and noninvasive software platform that can be integrated into 3D angiographic scanners (DSA, CTA or MRA) to provide guidance regarding the diagnosis and management of intracranial aneurysms (IA). Hemorrhagic stroke secondary to ruptured IAs leads to significant morbidity and mortality and affects over 35,000 patients on a yearly basis in the United States. The diagnosis of asymptomatic IAs is on the rise with the increasing use of cerebral imaging. However, guidance regarding which aneurysms should be treated has not advanced. Leveraging recent advances in computational science and technology, particularly artificial intelligence, the proposed software platform built on two enabling technologies can (1) propel automated “patient-specific” hemodynamic evaluations into the clinical workflow and (2) conduct “data-driven” risk assessments of IA rupture on an individual basis. Specific research aims are to (1) develop a clinically-oriented CFD platform that enables automated “patient-specific” hemodynamic evaluations of IAs, (2) investigate data-driven analytics toward prediction of rupture risk for IAs and (3) evaluate the data-driven analytics in a blind study. Once validated, a follow-up R01 project is planned to examine the clinical utility of the proposed software platform in a prospective clinical study as a single gateway for computer-aided evaluation of cerebral aneurysms. Public Health Relevance/Narrative This R01 proposal is to investigate the feasibility of developing an innovative, non-invasive and artificial intelligence-centric tool that can be used as a software add-on to clinical angiographic (e.g. DSA) scanners. The software can automatically select high-risk aneurysms for immediate treatments from a pool of patients with unruptured intracranial aneurysms, impacting the clinical management of intracranial aneurysms.",Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics,10121043,R01EB029570,"['3-Dimensional', 'Affect', 'Aneurysm', 'Angiography', 'Architecture', 'Artificial Intelligence', 'Benign', 'Biomedical Computing', 'Biomedical Engineering', 'Brain hemorrhage', 'Cerebral Aneurysm', 'Cerebrum', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational Geometry', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Engineering', 'Ensure', 'Evaluation', 'Genetic', 'Growth', 'Human', 'Image', 'Individual', 'Intracranial Aneurysm', 'Knowledge', 'Liquid substance', 'Machine Learning', 'Medicine', 'Methods', 'Michigan', 'Morbidity - disease rate', 'Morphology', 'Natural History', 'Neural Network Simulation', 'Outcome', 'Patients', 'Physics', 'Play', 'Research', 'Research Proposals', 'Risk', 'Risk Assessment', 'Role', 'Rupture', 'Ruptured Aneurysm', 'Secondary to', 'Smoker', 'Technology', 'TensorFlow', 'Testing', 'Training', 'Translational Research', 'United States', 'Universities', 'Wisconsin', 'Work', 'analytical method', 'base', 'blind', 'computer grid', 'convolutional neural network', 'deep learning', 'flexibility', 'follow-up', 'hemodynamics', 'high risk', 'image guided', 'innovation', 'learning strategy', 'mortality', 'neurosurgery', 'open source', 'personalized management', 'prevent', 'prospective', 'prototype', 'public health relevance', 'shear stress', 'success', 'tool']",NIBIB,MICHIGAN TECHNOLOGICAL UNIVERSITY,R01,2021,346966
"A Handheld Microchip for GC analysis of breath to screen for COVID-19 Project Summary  The COVID-19 pandemic has caused unprecedented societal suffering and economic disruption. In the United States, more than six million people have contracted COVID-19 and more than one hundred ninety thousand patients have died of this disease to date. Although current COVID-19 diagnostic testing technologies are critical for slowing the spread of the virus and preventing future outbreaks, they are not practical for field use. Current diagnostic tests are cumbersome to perform because they use aqueous solutions, require multiple steps, and hours-to-days to obtain results. Since the US began to reopen the economy in May, there has been a significant increase in the number of COVID-19 cases. Therefore, there is an urgent need to develop a diagnostic approach that is non-invasive, portable, and can rapidly provide test results.  The overall goal of the project is to develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). The handheld tool will be a closed system for trapping select volatile organic compounds (VOCs) on a microfabricated chip. The captured VOCs will be eluted with ethanol and then analyzed using a commercially available, portable GC-PID instrument. Artificial intelligence (AI) and machine learning algorithms will be applied to recognize the VOC pattern that correlates with COVID-19 infection. The central innovation is the microfabricated chip that captures carbonyl compounds in exhaled breath and thus serves as a preconcentrator, which enables analysis of carbonyl VOCs by the portable GC-PID. The hypothesis is that the carbonyl metabolome in exhaled breath is directly related to the body’s reaction to the novel coronavirus infection, and changes in the carbonyl VOC composition in exhaled breath relative to healthy controls can be used to detect both symptomatic and asymptomatic COVID-19 patients.  Three specific aims are proposed to fulfill the overall goal. Aim 1 is to build a disposable handheld breath analyzer tool for concentrating carbonyl VOCs. Aim 2 is to identify VOC patterns in the breath of COVID-19 patients by machine learning algorithms. Aim 3 is to integrate portable GC technology with the breath sampling tool for COVID-19 screening guided by an AI system. The University of Louisville is uniquely suited to rapidly transition the microchip technology to field use because of the PI and Co-PI’s experience in breath analysis and translational research, and the project team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence as well as the state-of-the-art facilities that include a MicroNano Technology Center, Biosafety Level 3 Regional Biocontainment Lab, and an NIH-funded REACH program. 8. Project Narrative  This project will develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). Artificial intelligence and machine learning algorithms will be used to analyze the detected signals of volatile organic compounds (VOCs) in exhaled breath by the portable GC for detection of COVID-19 patients. UofL is uniquely suited to develop this approach because of the PI’s expertise in breath analysis for detection of Tuberculosis and lung cancer and the team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence.",A Handheld Microchip for GC analysis of breath to screen for COVID-19,10266377,U18TR003787,"['2019-nCoV', 'Acute', 'Address', 'Artificial Intelligence', 'Biochemical Process', 'Biometry', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnostic', 'COVID-19 pandemic', 'COVID-19 patient', 'COVID-19 screening', 'COVID-19 test', 'Cancer Detection', 'Clinic', 'Collaborations', 'Collection', 'Communicable Diseases', 'Contracts', 'Coronavirus Infections', 'Detection', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Economics', 'Epithelial Cells', 'Ethanol', 'Exhalation', 'Expert Systems', 'Foundations', 'Funding', 'Future', 'Goals', 'Hour', 'Human', 'Influenza', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Malignant neoplasm of lung', 'Mass Fragmentography', 'Medical Device', 'Modeling', 'Monitor', 'Nasal Epithelium', 'Oxidative Stress', 'Patients', 'Pattern', 'Process', 'Production', 'Protocols documentation', 'Rapid screening', 'Reaction', 'Reagent', 'Research Project Grants', 'Role', 'SARS-CoV-2 infection', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Silicon', 'Sterilization', 'System', 'Technology', 'Test Result', 'Testing', 'Training', 'Translational Research', 'Tuberculosis', 'United States', 'United States National Institutes of Health', 'Universities', 'Vial device', 'Viral', 'Viral Respiratory Tract Infection', 'Virulent', 'Virus', 'Virus Diseases', 'adduct', 'aqueous', 'asymptomatic COVID-19', 'biosafety level 3 facility', 'bronchial epithelium', 'carbonyl compound', 'detection sensitivity', 'detector', 'experience', 'innovation', 'instrument', 'machine learning algorithm', 'metabolome', 'microchip', 'mobile computing', 'novel coronavirus', 'photoionization', 'point of care', 'portability', 'prevent', 'programs', 'prototype', 'reagent testing', 'tool', 'virology', 'volatile organic compound']",NCATS,UNIVERSITY OF LOUISVILLE,U18,2021,1026672
"SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN) PROJECT SUMMARY/ABSTRACT In recent years, human cognitive auditory neuroscience has made rapid strides due to advances in human neuroimaging, the advent of innovative machine learning/big data analytic approaches, and a greater mechanistic understanding of cognitive-sensory interactions in animal models. The dynamic landscape of this emergent field necessitates a highly interdisciplinary, human and translation-centric symposium that brings together expertise across academia and industry. This application requests partial funding for the Symposium on Cognitive Auditory Neuroscience (SCAN) to be hosted in Pittsburgh, PA in July 2020 and 2022, as a joint venture between Carnegie Mellon University (CMU) and University of Pittsburgh (Pitt). As a biennial meeting, SCAN aims to become the premiere intellectual and professional venue for current research in the emerging field of human cognitive auditory neuroscience. SCAN will incorporate elements typical to academic conferences (research talks, posters) as well as novel ideas that promote ‘blue sky’ thinking in this rapidly evolving field. SCAN will assiduously and innovatively work towards inclusivity and creating an atmosphere that encourages intellectual and professional engagement from women, underrepresented minorities, and individuals with disabilities. Another critical aim of the SCAN is to foster industry-academic partnerships with an eye towards translation of basic research and fostering career opportunities for trainees. Pittsburgh is uniquely situated to launch SCAN. With an enviable concentration of co-located auditory neuroscience expertise, Pittsburgh is also an intellectual hub for industries/start-ups engaged in in machine learning, natural language processing, and speech recognition. SCAN will leverage these advantages to foster growth and innovation tied to core missions of the National Institutes of Deafness and Communication Disorders. PROJECT NARRATIVE The Symposium on Cognitive Auditory Neuroscience (SCAN) has a strong connection to deafness and communication disorders through its focus on the basic science of human cognitive auditory neuroscience, and its translation. SCAN will establish an intellectual home for dissemination of cutting-edge research in human cognitive auditory neuroscience, support the development of the next generation of scientists, build a vibrant and inclusive community that engages with the grand challenges in the field, and forge new academia-industry partnerships.",SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN),10078266,R13DC018243,"['Academia', 'Acoustics', 'Address', 'Affect', 'Americas', 'Animal Model', 'Atmosphere', 'Attention', 'Auditory', 'Auditory Perception', 'BRAIN initiative', 'Base of the Brain', 'Basic Science', 'Behavioral', 'Big Data Methods', 'Brain', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communities', 'Complex', 'Development', 'Disabled Persons', 'Disease', 'Ear', 'Educational workshop', 'Elements', 'Environment', 'Eye', 'Fertilization', 'Fostering', 'Funding', 'Geographic Locations', 'Goals', 'Growth', 'Hearing', 'Home environment', 'Human', 'Industry', 'Influentials', 'Institutes', 'Joint Ventures', 'Learning', 'Life', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Mission', 'Natural Language Processing', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Otolaryngology', 'Participant', 'Perception', 'Peripheral', 'Problem Solving', 'Process', 'Request for Applications', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Seeds', 'Sensory', 'Societies', 'Speech', 'Thinking', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'analytical tool', 'base', 'career', 'cognitive neuroscience', 'deafness', 'industry partner', 'innovation', 'interest', 'meetings', 'millisecond', 'neuroimaging', 'new technology', 'next generation', 'novel', 'open data', 'posters', 'pressure', 'relating to nervous system', 'sensory input', 'sound', 'speech recognition', 'symposium', 'virtual reality']",NIDCD,CARNEGIE-MELLON UNIVERSITY,R13,2021,1766
"A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment  Unhealthy diet is strongly linked to risks of chronic diseases, such as cardiovascular diseases, diabetes and certain types of cancer. The Global Burden of Disease Study has found that, among the top 17 risk factors, poor diet is overwhelmingly the No. 1 risk factor for human diseases. Despite the strong connection between diet and health, unhealthy foods with large portion sizes are widely consumed. Currently, 68.5% of U.S. adults are overweight, among the highest in developed countries. The recent decline in U.S. life expectancy sent another alarming signal about the general health of the American people. Understanding how the diet-related risk factors affect people’s health and finding effective ways to empower them in improving lifestyle habits are among the most important tasks in public health. Unfortunately, dietary assessment in real-world settings has been exceedingly complex and inaccurate to implement. Technology is needed that allows researchers to assess dietary intake easily and accurately in real world settings so that effective intervention to manage obesity and related chronic diseases can be developed. We propose a biomedical engineering project to address the dietary assessment problem, taking advantage of advanced mathematical modeling, wearable electronics and artificial intelligence.  Our research team has been improving the ability to assess diet for over a decade. We have designed the eButton, a small wearable device pinned on clothes in front of the chest, capable of collecting image-based dietary data objectively and passively (i.e., without depending on subject’s self-report or volitional operation of the device). We have also developed algorithms to compute food volumes and nutrients from images. Since the eButton was developed, it has been used by many researchers in the U.S. and other countries for objective and passive diet-intake studies in both adults and children.  Despite the past successes, there have been two lingering critical problems associated with the objective and passive dietary assessment using wearable devices: 1) substantial manual efforts are required for researchers to visually examine image data to identify foods and estimate their volumes (portion sizes), and 2) there are privacy concerns about researchers’ viewing of participants’ real-life images. Although solving these problems could enable the eButton and other wearable devices for large-scale diet-intake studies, we were not able to find effective solutions until recently when Artificial intelligence (AI) emerged. Advanced AI systems, especially those based on deep learning, can be trained by large amounts of labeled data to produce results comparable or even superior to those produced by human in numerous fields of applications. AI technology is also a powerful tool for dietary assessment, potentially providing an ideal solution to the two previously mentioned problems. We thus propose to develop a human-mimetic AI system to recognize foods from images, estimate portion sizes, and find energy and nutrient values from a database in a fully automatic process. Using the AI approach, there will be no need for researchers to view participants’ real-life images, and the AI system well-respects individuals’ privacy because it is trained to recognizes human foods only, nothing else.  Currently, the performances of existing AI systems are limited by the extensive variety and high variability of human foods, insufficient training data, and difficulty in finding appropriate nutritional information from food databases. In this application, we propose a new strategy to personalize the AI system for each research participant using an advanced mathematical model of personal food choices. With this personalization step, the dimensionality of our envisioned AI system can be reduced drastically, and our goal of automatic, objective and passive dietary assessment can be reached realistically. We also propose to improve the electronic hardware and develop a biomimetic camera to enlarge the field of view for the eButton. Finally, we will conduct a thorough evaluation of the personalized AI system in real-world settings using human subjects. This research aims to apply advanced mathematical modeling, wearable electronics and artificial intelligence to evaluate individual’s energy and nutrient intake automatically and objectively.","A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment",10111099,R01DK127310,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'American', 'Artificial Intelligence', 'Biomedical Engineering', 'Biomimetics', 'Cardiovascular Diseases', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Chest', 'Child', 'Chronic Disease', 'Complex', 'Consumption', 'Country', 'Data', 'Databases', 'Developed Countries', 'Devices', 'Diabetes Mellitus', 'Diet', 'Dietary Assessment', 'Dietary intake', 'Dietetics', 'Dimensions', 'Eating', 'Evaluation', 'Expert Systems', 'Eye', 'Feedback', 'Food', 'Food Energy', 'Future', 'Goals', 'Gold', 'Habits', 'Health', 'Health care facility', 'Healthcare', 'Heart Diseases', 'Human', 'Image', 'Individual', 'Intake', 'Label', 'Life', 'Life Expectancy', 'Life Style', 'Link', 'Malignant Neoplasms', 'Manuals', 'Modeling', 'Nutrient', 'Nutritional', 'Nutritional Science', 'Obesity', 'Output', 'Participant', 'Patient Self-Report', 'Performance', 'Persons', 'Play', 'Privacy', 'Problem Solving', 'Process', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Shapes', 'Signal Transduction', 'System', 'Technology', 'Training', 'Unhealthy Diet', 'Update', 'Volition', 'base', 'burden of illness', 'cancer type', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'dietary', 'effective intervention', 'field study', 'good diet', 'human disease', 'human subject', 'improved', 'infancy', 'intelligent algorithm', 'mathematical model', 'mimetics', 'neural network', 'obesity management', 'operation', 'overweight adults', 'robotic system', 'success', 'tool', 'validation studies', 'wearable device']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,657303
"CounterAct Administrative Supplement to NS114020 Automated Phenotyping in Epilepsy Acute intoxication with organophosphorus (OP) pesticides is a significant public health concern and long-term neurological effects are not well understood. A major obstacle to progress towards reproducible, rigorous preclinical research in the long-term effects of OP- induced status epilepticus is that current experimental approaches often require prohibitively time and labor-intensive 24/7 video-EEG monitoring and inherently subjective scoring of seizures by human observers (like the widely used Racine scale). While algorithms for automated seizure detection in EEG are improving, the critically important behavioral manifestations of acquired epilepsy and assessment of its cognitive comorbidities remain poorly quantified. Our parent grant focuses on developing an objective, high-throughput technique to characterize epileptic phenotypes using a new method called motion sequencing (MoSeq) and apply it to automated anti-epileptic drugs (AED) screening. The central idea of MoSeq rests on the discovery that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales that are arranged according to specific rules (“grammar”) that can be detected without observer bias by artificial intelligence (AI)-assisted 3D video analysis. In this administrative supplement project, we propose to employ and refine MoSeq to address key challenges in research into the development of new medical countermeasures (MCM) against nerve agents and OP pesticides. This includes testing if it is possible to objectively study the long-term effects of OP intoxication and evaluate MCMs at scale by determine epilepsy-specific behavioral modules and associated transition probabilities in mice after acute OP exposure. In addition, given that neuroinflammation is likely to play a key role in OP-induced persistent neuronal circuit disturbance, we will test if microglial depletion can rescue the OP-induced chronic changes in behavioral syllables and transition probabilities. Together, the aims in this administrative supplement will both benefit from and contribute to our parent grant’s goal to develop a reliable, sharable tool for the research community to study seizures and cognitive comorbidities of epilepsy. There is an urgent need for medical countermeasures (MCMs) against nerve agents and organophosphorus (OP) pesticides. The project will leverage from our recent technical breakthroughs in artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to test if it is possible to objectively study the long-term effects of OP intoxication and evaluate MCMs at scale. If successful, this innovative approach is expected to have a significant and sustained impact on preclinical research by enabling objective, automated, inexpensive, reproducible assessment of epileptic phenotypes in experimental animals after acute OP intoxication to aid the testing of anti-seizure drugs and other novel therapies.",CounterAct Administrative Supplement to NS114020 Automated Phenotyping in Epilepsy,10227611,R01NS114020,"['3-Dimensional', 'Acute', 'Address', 'Administrative Supplement', 'Animal Behavior', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Cannabidiol', 'Chronic', 'Cognitive', 'Communities', 'Complex', 'Data', 'Detection', 'Development', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Exposure to', 'Goals', 'Human', 'Intoxication', 'Isoflurophate', 'Long-Term Effects', 'Longitudinal Studies', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Neurologic Effect', 'Observer Variation', 'Pesticides', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Probability', 'Public Health', 'Reproducibility', 'Research', 'Rest', 'Seizures', 'Status Epilepticus', 'Stereotyping', 'Structure', 'Techniques', 'Technology', 'Testing', 'Three-dimensional analysis', 'Time', 'acquired epilepsy', 'automated algorithm', 'comorbidity', 'improved', 'innovation', 'medical countermeasure', 'nerve agent', 'neuroinflammation', 'neuronal circuitry', 'novel therapeutics', 'parent grant', 'pre-clinical research', 'screening', 'tool', 'valproate']",NINDS,STANFORD UNIVERSITY,R01,2021,123798
"Research Symposium in Communication Sciences and Disorders The Research Symposium in Communication Sciences and Disorders supports a full day of presentations by leading scientists in areas that are having transformational effects in the communication sciences and disorders (CSD) discipline. The Research Symposium is held at the annual Convention of the American Speech-Language-Hearing Association (ASHA) and is open to all of the approximately 15,000 Convention attendees, which includes students, practitioners, and researchers. Following Convention, the Symposium content is widely disseminated through audio recordings of the presentations, which are synced with the slides and transcribed, and by making them freely accessible on the ASHA website. Additionally, each presenter submits an article based on their presentation to the Journal of Speech, Language, and Hearing Research to be published in the annual Research Symposium Forum. An innovation that will be implemented in this current funding cycle is that ASHA will make these articles freely accessible upon publication on the ASHA Journals website and will deposit them in PubMed Central without embargo. The first aim of the Research Symposium grant is to advance scientific discourse and dissemination of scientific discovery and innovation on five topics that are having transformational effects across several subareas in CSD. This will be accomplished, in part, by making the Research Symposium Forum open access and by widely promoting both the recorded and the written content across ASHA’s many communication channels. Over the next 5-year funding cycle, the Symposium will address five topics that cut across the areas of hearing, speech, language, and other aspects of cognition, including (1) Health and Healthcare Equity of People With Communication Disabilities, (2) Bilingualism, (3) Artificial Intelligence in CSD, (4) Genetics in CSD, and (5) Intervention and Implementation Clinical Trials in CSD. The second aim of the Research Symposium grant is to advance the research career development of early- career scientists focused on research in CSD. Between 2021 and 2025, the Research Mentoring- Pair Travel Award and ASHA’s in-kind contribution will provide funding to attend the Symposium and mentoring support to 130 early-career scientists in CSD. The Travel Award recipients will attend the Symposium along with a mentor and engage in mentored research activities before, during, and after each Symposium. These activities are designed to help integrate the protégés into their scientific community and encourage them to pursue a research career and become productive scholars. The scientific base of the CSD discipline will be strengthened by these scientific dissemination, research education, and mentoring activities. The Research Symposium in Communication Sciences and Disorders aims to strengthen the scientific base and increase the research capacity of the discipline, which will lead to improvements in the communication health of millions people with communication or related disorders. The Symposium presentations will advance the scientific dialogue and be broadly disseminated through freely available peer-reviewed publications and transcribed recordings. The associated Travel Award will provide funds to support 130 promising early-career scientists in attending the Research Symposium and engaging in mentored research activities before, during, after the Symposium to increase their recruitment and retention in a research career.",Research Symposium in Communication Sciences and Disorders,10070224,R13DC003383,"['Address', 'American Speech-Language-Hearing Association', 'Area', 'Artificial Intelligence', 'Award', 'Awareness', 'Clinical', 'Clinical Trials', 'Cognition', 'Communication', 'Communication Disability', 'Communities', 'Data', 'Degree program', 'Deposition', 'Dimensions', 'Discipline', 'Disease', 'Doctor&apos', 's Degree', 'Enrollment', 'Ensure', 'Event', 'Funding', 'Generations', 'Genetic', 'Grant', 'Health', 'Health Communication', 'Healthcare', 'Hearing', 'Hour', 'Intervention', 'Journals', 'Knowledge', 'Language', 'Manuscripts', 'Mentors', 'Methodology', 'Monitor', 'Outcome Measure', 'Peer Review', 'Postdoctoral Fellow', 'Preparation', 'PubMed', 'Publications', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seminal', 'Slide', 'Speech', 'Students', 'Surveys', 'Time', 'Travel', 'Work', 'base', 'bilingualism', 'career', 'career development', 'clinical trial implementation', 'design', 'dissemination research', 'doctoral student', 'education research', 'experience', 'innovation', 'knowledge base', 'meetings', 'next generation', 'online community', 'recruit', 'social media', 'stem', 'symposium', 'web site']",NIDCD,AMERICAN SPEECH-LANGUAGE-HEARING ASSN,R13,2021,39900
"Automated Phenotyping in Epilepsy There are 65 million people worldwide with epilepsy and 150,000 new cases of epilepsy are diagnosed in the US annually. However, treatment options for epilepsy remain inadequate, with many patients suffering from treatment-resistant seizures, cognitive comorbidities and the negative side effects of treatment. A major obstacle to progress towards the development of new therapies is the fact that preclinical epilepsy research typically requires labor-intensive and expensive 24/7 video-EEG monitoring of seizures that rests on the subjective scoring of seizure phenotypes by human observers (as exemplified by the widely used Racine scale of behavioral seizures). Recently, the Datta lab showed that complex animal behaviors are structured in stereotyped modules (“syllables”) at sub-second timescales and arranged according to specific rules (“grammar”). These syllables can be detected without observer bias using a method called motion sequencing (MoSeq) that employs video imaging with a 3D camera combined with artificial intelligence (AI)-assisted video analysis to characterize behavior. Through collaboration between the Soltesz and Datta labs, exciting data were obtained that demonstrated that MoSeq can be adapted for epilepsy research to perform objective, inexpensive and automated phenotyping of mice in a mouse model of chronic temporal lobe epilepsy. Here we propose to test and improve MoSeq further to address long-standing, fundamental challenges in epilepsy research. This includes the development of an objective alternative to the Racine scale, testing of MoSeq as an automated anti-epileptic drug (AED) screening method, and the development of human observer- independent behavioral biomarkers for seizures, epileptogenesis, and cognitive comorbidities. In addition, we plan to dramatically extend the epilepsy-related capabilities of MoSeq to include the automated tracking of finer-scale body parts (e.g., forelimb and facial clonus) that are not possible with the current approach. Finally, we propose to develop the analysis pipeline for MoSeq into a form that is intuitive, inexpensive, user-friendly and thus easily sharable with the research community. We anticipate that these results will have a potentially transformative effect on the field by demonstrating the feasibility and power of automated, objective, user- independent, inexpensive analysis of both acquired and genetic epilepsy phenotypes. There is an urgent need for new therapies for patients with uncontrolled epilepsy. The project will develop breakthrough technologies involving artificial intelligence (AI)-assisted analysis of 3-dimensional video data of mouse behavior to address long-standing, fundamental challenges in preclinical epilepsy research. If successful, this innovative approach is expected to have a significant and sustained impact on epilepsy research by enabling investigators to perform objective, automated, inexpensive, reproducible assessment of epilepsy in experimental animals to aid the testing of anti-seizure drugs and other novel therapies.",Automated Phenotyping in Epilepsy,10178133,R01NS114020,"['3-Dimensional', 'Address', 'Animal Behavior', 'Animal Model', 'Animals', 'Antiepileptic Agents', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological Markers', 'Body part', 'Cannabidiol', 'Carbamazepine', 'Cells', 'Chronic', 'Clonazepam', 'Clonus', 'Cognitive', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Diagnosis', 'Drug Screening', 'Electroencephalography', 'Epilepsy', 'Epileptogenesis', 'Face', 'Forelimb', 'Future', 'Genetic', 'Genetic Models', 'Head', 'Hippocampus (Brain)', 'Human', 'Image', 'Imaging Techniques', 'Intervention', 'Intuition', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Mus', 'Observer Variation', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Phenytoin', 'Pilocarpine', 'Probability', 'Reproducibility', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Rest', 'Seizures', 'Specificity', 'Stereotyping', 'Structure', 'Tail', 'Technology', 'Temporal Lobe Epilepsy', 'Testing', 'Three-dimensional analysis', 'Time', 'Treatment Side Effects', 'Valproic Acid', 'analysis pipeline', 'base', 'behavior test', 'behavioral phenotyping', 'comorbidity', 'drug use screening', 'improved', 'innovation', 'kainate', 'method development', 'mouse model', 'novel therapeutics', 'optogenetics', 'pre-clinical', 'pre-clinical research', 'selective expression', 'user-friendly']",NINDS,STANFORD UNIVERSITY,R01,2021,422740
"Preventing medication dispensing errors in pharmacy practice with interpretable machine intelligence PROJECT SUMMARY Medical errors are the 3rd leading cause of death in the United States behind cancer and cardiovascular disease. The largest proportion of medical errors involve medications. Medication errors result in 3 million outpatient medical appointments, 1 million emergency department visits, and 125,000 hospital admissions each year. Astoundingly, over 4 billion prescriptions are dispensed every year in the United States alone. Although dispensing error rates are generally low at 0.06%, the sheer volume of dispensed medications translates to 2.4 million incorrectly dispensed medications each year. In the pharmacy, dispensing errors arise when pharmacists do not detect that the medication filled inside a prescription vial is different from the medication ordered on the prescription's label. These dispensing errors can result in patient harm, added strain on the healthcare system, and costly legal action against the pharmacy. Machine intelligence (MI) can be employed to assist in the verification process to help avoid dangerous and costly pharmacy dispensing errors.4–6 However for the human-MI partnership to function optimally, the MI should be capable of conveying accurate information that encourages providers to make sound cognitive decisions such that optimal trust is maintained, and temporal and cognitive demand is reduced. Imperative to this goal is to design MI from which interpretable information can be extracted, convey this information in an effective manner and calibrate user's trust in MI as either over-trust or under-trust can lead to near miss and incident errors. This proposed project will further our knowledge for designing interpretable MI outputs and inform the development of MI models that encourage pharmacy staff to make sound clinical decisions that lead to better patient outcomes while improving work-life at lower costs of care. This study develops interpretable MI methods in the context of medication images classification and designs effective MI advice and reasoning that lead to lower cognitive demand and increased trust in the MI. Our hypothesis is that interpretable MI will lead to improved work performance and more calibrated trust compared to uninterpretable M. The objectives of this proposal are to: 1) design interpretable machine intelligence to double-check dispensed medication images in real-time; 2) evaluate changes in pharmacy staff trust due to the long-term use of interpretable machine intelligence; and 3) determine the effect of interpretable machine intelligence on long-term pharmacy staff work performance. PROJECT NARRATIVE Medical errors are the 3rd leading cause of death in the United States behind cancer and cardiovascular disease and the largest proportion of medical errors involve medications. These dispensing errors occur approximately 2,400,000 times every year in the United States alone and can result in patient safety issues and add unnecessarily to the already strained healthcare system.The objectives of this proposal are to: 1) design interpretable machine intelligence to double-check dispensed medication images in real-time; 2) evaluate changes in pharmacy staff trust due to the long-term use of interpretable machine intelligence; and 3) determine the effect of interpretable machine intelligence on long-term pharmacy staff work performance.",Preventing medication dispensing errors in pharmacy practice with interpretable machine intelligence,10183536,R01LM013624,"['Artificial Intelligence', 'Cardiovascular Diseases', 'Cause of Death', 'Classification', 'Clinical', 'Cognitive', 'Dangerousness', 'Data', 'Decision Making', 'Detection', 'Development', 'Emergency department visit', 'Evaluation', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Human', 'Image', 'Knowledge', 'Label', 'Lead', 'Legal', 'Life', 'Malignant Neoplasms', 'Measures', 'Medical Errors', 'Medication Errors', 'Methods', 'Modeling', 'Outpatients', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance at work', 'Pharmaceutical Preparations', 'Pharmacists', 'Pharmacy facility', 'Process', 'Provider', 'Research', 'Stream', 'System', 'Testing', 'Time', 'Translating', 'Trust', 'Uncertainty', 'United States', 'Vial device', 'Work', 'base', 'care costs', 'cost', 'deep learning', 'design', 'experience', 'experimental study', 'improved', 'insight', 'medical appointment', 'patient safety', 'prevent', 'sound', 'support tools', 'tool', 'visual tracking']",NLM,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,288814
