text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,9623341,R01DC012048,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'American', 'Auditory', 'Auditory Prosthesis', 'Chronic', 'Complex', 'Data', 'Environment', 'Formulation', 'Frequencies', 'Goals', 'Hearing', 'Hearing Aids', 'Individual', 'Investigation', 'Laboratories', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neural Network Simulation', 'Noise', 'Recurrence', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Intelligibility', 'Structure', 'Supervision', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'combat', 'deep learning', 'deep neural network', 'design', 'digital', 'experimental study', 'hearing impairment', 'improved', 'innovation', 'microphone', 'network architecture', 'normal hearing', 'real world application', 'segregation', 'signal processing', 'sound', 'speech in noise', 'success', 'supervised learning']",NIDCD,OHIO STATE UNIVERSITY,R01,2019,304865,0.043002042902079825
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9593020,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Computer Simulation', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Tests', 'Heritability', 'Human', 'Infrastructure', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical implementation', 'clinical phenotype', 'clinically significant', 'cohort', 'deaf', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'hard of hearing', 'hearing impairment', 'hearing loss phenotype', 'hearing preservation', 'hearing threshold', 'hereditary hearing loss', 'improved', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'precision genetics', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'tool', 'treatment guidelines']",NIDCD,UNIVERSITY OF IOWA,R01,2019,480576,0.25795196794868924
"Computational Cognitive Neuroscience of Human Auditory Cortex PROJECT SUMMARY Humans with normal hearing excel at deriving information about the world from sound. Our auditory abilities represent stunning computational feats that only recently have been replicated to any extent in machine systems. And yet our auditory abilities are highly vulnerable, being greatly compromised in listeners with hearing impairment, cochlear implants, and auditory neurodevelopmental disorders, particularly in the presence of noise. Difficulties in recognition often lead to frustration and social isolation, and are not adequately addressed by current hearing aids, implants, and remediation strategies. The long-term goal of the proposed research is to reveal the basis of auditory recognition and to provide insights that will facilitate improved prosthetic devices and therapeutic interventions. The development of more effective devices and therapies is currently limited by an incomplete understanding of the factors that underlie real-world recognition by normal-hearing listeners. In particular, although responses to sound in subcortical auditory pathways are relatively well studied, little is known about the transformations that occur within the auditory cortex to create representations of meaningful sound structure. We propose to enrich the understanding of auditory recognition with three sets of experiments that examine the cortical representation of real-world sounds in human listeners, combining functional magnetic resonance imaging (fMRI) with computational modeling of the underlying representations. Aim 1 develops artificial neural network models of speech and music processing and compares their representations to those in the auditory cortex, synthesizing and then measuring brain responses to sounds that generate the same response in a model, and probing the time scale of the auditory analysis of speech and music. Aim 2 develops and tests models of pitch perception in noise, exploring the hypothesis that pitch perception is constrained both by the statistics of natural sounds and the frequency selectivity of the cochlea. Aim 3 develops and tests models that jointly localize and recognize sounds, and probes the brain representations of sound identity and location using fMRI. The results will reveal the mechanisms underlying robust sound recognition by the healthy auditory system and will set the stage for investigations of the cortical consequences of hearing impairment and auditory developmental disorders, hopefully suggesting new strategies for remediation. PROJECT NARRATIVE: People with normal hearing are typically able to recognize, understand and localize sounds of interest, but this ability is often compromised in listeners with hearing disorders. The proposed research will enrich the understanding of the neural mechanisms underlying auditory recognition and localization in normal listeners. The results will likely provide insight into the brain processes whose alteration in hearing disorders underlies listening difficulties, potentially leading to improved remediation strategies.",Computational Cognitive Neuroscience of Human Auditory Cortex,9797408,R01DC017970,"['Address', 'Adopted', 'Auditory', 'Auditory Perception', 'Auditory area', 'Auditory system', 'Behavioral', 'Biological Assay', 'Brain', 'Brain region', 'Characteristics', 'Child', 'Cochlea', 'Cochlear Implants', 'Computer Simulation', 'Data', 'Development', 'Devices', 'Drops', 'Ear', 'Floor', 'Frequencies', 'Frustration', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing Aids', 'Hearing problem', 'Human', 'Implant', 'Investigation', 'Lead', 'Location', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Noise', 'Pathway interactions', 'Peripheral', 'Persons', 'Pitch Perception', 'Population', 'Process', 'Property', 'Prosthesis', 'Psychophysics', 'Research', 'Rest', 'Social isolation', 'Sound Localization', 'Source', 'Speech', 'Stimulus', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Visual Pathways', 'artificial neural network', 'auditory pathway', 'cognitive neuroscience', 'computational basis', 'deep learning', 'deep neural network', 'developmental disease', 'experimental study', 'hearing impairment', 'improved', 'insight', 'interest', 'network architecture', 'neural network', 'neuromechanism', 'neurophysiology', 'normal hearing', 'novel', 'relating to nervous system', 'remediation', 'response', 'sound', 'sound frequency', 'speech processing', 'statistics']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2019,337875,0.1266023978469382
"Tinnitus: Audiological measures and genetic susceptibility PROJECT SUMMARY/ABSTRACT Tinnitus, the phantom perception of sound in absence of an external sound source, is a prevalent hearing disorder. To date, the exact neural and molecular mechanisms underlying tinnitus are not known. Tinnitus is associated with a number of otological diseases and clinical conditions; however, almost 50% of tinnitus cases are not attributable to any known cause (Stouffer & Tyler, 1990). There is likely a genetic component to tinnitus (Sand et al, 2007). A critical gap in the knowledge base is how to clinically identify those who are genetically predisposed to tinnitus well before they acquire this hearing health issue. The short-term goal of this R21 Early Career Research PAR 16-057 application, entitled “Tinnitus: Audiological measures and genetic susceptibility,” is to identify detailed phenotypic and genotypic profiles of chronic tinnitus in young adults. The application is proposed by a team of researchers: The PI is Ishan Bhatt, Ph.D. in audiology (CCC-A, FAAA), who is working with Co-PI’s Jason Wilder, Ph.D. in genetics, Jin Wang, Ph.D. in statistics, and Raquel Dias, Ph.D. in Bioinformatics. This project will fill the gap in knowledge by identifying the critical variables associated with a genetic predisposition to CT. This investigation will include college-aged young participants to control for age- related confounding variables such as systemic diseases and hearing loss. According to the PI’s pilot study (Bhatt, 2017a), the estimated prevalence of chronic tinnitus (CT), acute tinnitus (AT) and no tinnitus (NT) is around 8%, 13% and 79%, respectively. To accomplish our short-term goal, we will conduct a case-control- control exonic genome-wide association study (GWAS) (N = 300) in which subjects will be divided into three groups: those with (1) CT (tinnitus for > 1 year; n=100), (2) AT (tinnitus for ≤ 1 year, presumably due to acute environmental exposure; n=100); and (3) NT (no experience of tinnitus in a lifetime; n=100). The Specific Aims are: (1) to identify associations between exonic Single Nucleotide Polymorhisms (SNPs) and tinnitus phenotype. Based on the criteria laid out in the preliminary studies (Bhatt, 2017a; Bhatt et al., 2016; Phillip et al., 2015), our working hypothesis is that causal SNPs will exhibit a higher frequency of a specific genotype for subjects with CT compared to subjects with AT and NT. (2) To identify association between selected SNPs in a candidate set of genes and audiologic measures among subjects with CT, AT and NT, Based on our preliminary studies (Bhatt et al., 2016, Phillips et al., 2015), our working hypothesis is that subjects with causal alleles for CT will exhibit pathophysiological variation in the audiometric measures. Significance: Successful completion of this project will enable us to identify phenotypic and genotypic profiles of CT. This will help us to achieve our long term goal, which is to develop a genetic Risk Profile that can be used by health-care providers, and educators (e.g., health professionals, music and industrial arts teachers) to identify individuals genetically at risk for CT. Project Narrative Tinnitus, the phantom perception of sound in absence of an external sound source, is a prevalent hearing disorder. The short-term goal of this study is to identify detailed phenotypic and genotypic profiles of chronic tinnitus in college-aged young adults. The relevance of the project to public health is reflected in the long-term goal, which is to construct a genetic risk profile which can be used by health-care providers and educators to identify individuals genetically at risk for chronic tinnitus.",Tinnitus: Audiological measures and genetic susceptibility,9655203,R21DC016704,"['Acute', 'Address', 'Adolescent', 'Age', 'Aging', 'American', 'Anxiety', 'Audiology', 'Auditory Evoked Potentials', 'Auditory Perception', 'Bioinformatics', 'Candidate Disease Gene', 'Characteristics', 'Chronic', 'Clinical', 'Complex', 'Confounding Factors (Epidemiology)', 'Development', 'Disease', 'Doctor of Philosophy', 'Education', 'Environmental Exposure', 'Environmental Risk Factor', 'Ethnic Origin', 'Exhibits', 'Exposure to', 'Family', 'Financial compensation', 'Frequencies', 'General Population', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic screening method', 'Genetic study', 'Genotype', 'Goals', 'Health', 'Health Personnel', 'Health Policy', 'Health Professional', 'Hearing', 'Hearing problem', 'Human', 'Hyperacusis', 'Impaired cognition', 'Individual', 'Industrial Arts', 'Investigation', 'Knowledge', 'Machine Learning', 'Measures', 'Mental Depression', 'Military Personnel', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Music', 'Noise', 'Nucleotides', 'Otitis Media', 'PTGS1 gene', 'PTGS2 gene', 'Participant', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physiological', 'Pilot Projects', 'Policy Maker', 'Population', 'Predisposition', 'Prevalence', 'Prevention strategy', 'Preventive Intervention', 'Prostaglandin-Endoperoxide Synthase', 'Public Health', 'Quality of life', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Sampling', 'Serotonin', 'Silicon Dioxide', 'Sleeplessness', 'Smoking', 'Sodium', 'Source', 'Systemic disease', 'Testing', 'Tinnitus', 'Variant', 'Veterans', 'age related', 'aged', 'aging population', 'base', 'career', 'case control', 'causal variant', 'clinical development', 'college', 'experience', 'gene environment interaction', 'genetic association', 'genetic variant', 'genome wide association study', 'hearing impairment', 'individualized medicine', 'innovation', 'insight', 'knowledge base', 'learning strategy', 'novel', 'otoacoustic emission', 'relating to nervous system', 'serotonin receptor', 'serotonin transporter', 'sound', 'statistics', 'teacher', 'trait', 'treatment strategy', 'voltage gated channel', 'young adult']",NIDCD,NORTHERN ARIZONA UNIVERSITY,R21,2019,151994,0.062141817174046494
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,9443223,R01DC012048,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'American', 'Auditory', 'Auricular prosthesis', 'Chronic', 'Complex', 'Data', 'Environment', 'Formulation', 'Frequencies', 'Goals', 'Hearing', 'Hearing Aids', 'Individual', 'Investigation', 'Laboratories', 'Learning', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neural Network Simulation', 'Noise', 'Recurrence', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Intelligibility', 'Structure', 'Supervision', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'combat', 'deep learning', 'deep neural network', 'design', 'digital', 'experimental study', 'hearing impairment', 'improved', 'innovation', 'network architecture', 'real world application', 'segregation', 'signal processing', 'sound', 'success']",NIDCD,OHIO STATE UNIVERSITY,R01,2018,292174,0.043002042902079825
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9393258,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Audiometry', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Computer Simulation', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Impaired Persons', 'Heritability', 'Human', 'Inherited', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Research Infrastructure', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical implementation', 'clinical phenotype', 'clinically significant', 'cohort', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'hearing impairment', 'improved', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'precision genetics', 'preservation', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'tool', 'treatment guidelines']",NIDCD,UNIVERSITY OF IOWA,R01,2018,564086,0.25795196794868924
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9748023,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Audiometry', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Computer Simulation', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Impaired Persons', 'Heritability', 'Human', 'Inherited', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Research Infrastructure', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical implementation', 'clinical phenotype', 'clinically significant', 'cohort', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'hearing impairment', 'improved', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'precision genetics', 'preservation', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'tool', 'treatment guidelines']",NIDCD,UNIVERSITY OF IOWA,R01,2018,53375,0.25795196794868924
"Individualized Signal Processing Strategy :Phase II This project describes a novel approach to automate and individualize the signal processing strategy for hearing aids (HA) that can result in improved speech intelligibility in background noise, greater user satisfaction and acceptance for HAs, and reduce barriers to affordable hearing health care. The proposed Individualized Signal Processing Strategy (ISPS) is based on individual performance on categorical perception tasks for speech stimuli. This differs from traditional methods based on sophisticated gain models built upon average perception, performance, and preference data. The ability to determine one’s ISPS automatically, rapidly and remotely can result in dramatic cost-savings and greater accessibility to hearing health care for patients who cannot afford it or for those who lack easy access to the necessary expertise. These technical achievements have the potential to radically change HA service delivery models yet can be implemented within existing business models and in concert with current practitioners. The ISPS method effectively replaces target-based HA fitting (e.g. NAL-NL2) with individualized speech-based parameter adjustment. The proposed work follows successful completion of our pilot project and builds upon the research team’s prior research on novel fitting methods for cochlear implant (CI) devices recently acquired by Cochlear, Ltd. Following the successful implementation of ISPS and integration with commercial HA software in the pilot study, we demonstrated feasibility including a field study in which performance outcomes for the ISPS method were as good as a conventional HA fitting method and only took a fraction of the time, despite ISPS having no prior knowledge of patient characteristics and no audiogram. Successful maturation and commercialization of the ISPS technology in Phase II will address several barriers identified in the previous RFA-DC-12-004 including physical, infrastructure, and knowledge barriers (by allowing remote or self-fitting HAs), economic barriers (by reducing overall costs), and cultural barriers (by providing easy access to HA fitting for patients who tend to avoid professional help). This Phase II project will develop an operational ISPS method by (1) integrating ISPS with hardware/software systems of our industry partners, (2) refine and enhance the ISPS method to improve efficiency and effectiveness of fitting hearing instruments, (3) build support for the use of ISPS in multiple marketplaces, and (4) evaluate the technology through field trials in different service delivery environments by comparing outcomes with ISPS fitting to those achieved with traditional prescriptive gain fitting within the same subjects. Following successful demonstration of these objectives, a Phase III project will focus on the transition of the technology to support remote and self-fitting of hearing instruments. This project seeks to develop, implement and test a novel automated method for fitting hearing aids based on real-time speech perception performance. This automated approach can improve hearing aid success while significant reducing costs of hearing health care. The automation of the fitting procedure can dramatically increase accessibility of hearing health care.",Individualized Signal Processing Strategy :Phase II,9472306,R44DC016249,"['Achievement', 'Address', 'Algorithms', 'Artificial Intelligence', 'Audiology', 'Audiometry', 'Auditory', 'Automation', 'Businesses', 'Categories', 'Characteristics', 'Cochlear Implants', 'Collaborations', 'Computer software', 'Cost Savings', 'Crossover Design', 'Data', 'Development', 'Devices', 'Economics', 'Effectiveness', 'Environment', 'Evaluation', 'Frequencies', 'Funding', 'Generic Drugs', 'Goals', 'Healthcare', 'Hearing', 'Hearing Aids', 'Individual', 'Instruction', 'Knowledge', 'Learning', 'Link', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Perception', 'Performance', 'Phase', 'Pilot Projects', 'Procedures', 'Process', 'Randomized', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Sensorineural Hearing Loss', 'Service delivery model', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Stimulus', 'Supervision', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'United States Department of Veterans Affairs', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'commercialization', 'cost', 'data modeling', 'experimental study', 'field study', 'graph theory', 'health care service', 'implantable device', 'improved', 'improved outcome', 'inclusion criteria', 'industry partner', 'instrument', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'preference', 'satisfaction', 'service delivery', 'signal processing', 'software systems', 'sound', 'success']",NIDCD,"SECURBORATION, INC.",R44,2018,732079,0.13355945914482617
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology No abstract available Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,9681144,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2018,58282,0.21120337194445074
"User-driven fitting of hearing aids and other assistive hearing devices Hearing aids are the principal tool today for ameliorating age-related hearing loss and its significant social, cognitive and functional costs to patients and society at large. However, many individuals who are prescribed hearing aids do not use them at all, or use them only occasionally. Most reasons behind the “hearing aid in the drawer” phenomenon relate to the characteristics of the sound produced, and could, in theory, be addressed with the correct signal processing strategy. The problem persists despite the increased complexity and power of new devices, for three reasons: (a) The hearing aid parameters, as set in the clinic, introduce distortion or render audible many sounds that the hearing impaired user had become accustomed to not hearing. The novelty is often so uncomfortable for the user as to discard the device. (b) The optimum parameters vary depending on the listening task and environment. Under some conditions, a device with parameters designed for a different condition will perform worse than no device at all. (c) The clinical fitting is derived from a non-ideal way to assess auditory function (the pure- tone audiogram). The optimum parameters for the actual impairment may be different from those of the prescribed fitting. Although it is true that the physiological mechanisms make it impossible to process sound so as to completely reverse the effect of sensorineural hearing loss, a device that delivers some benefit at all times is likely to be used all the time. The goal is to develop a hearing aid that can adaptively change its parameters to address the problems above, and will be accomplished with a novel fitting approach that rapidly presents a number of parameter settings to the user and lets the user guide the system toward the optimal settings for each listening situation. This requires the development of machine-learning algorithms to effectively search the parameter space and user interface devices and instructions that are easy for the patient to use. The focus of this Phase I proposal is the development of the algorithms and the adaptive user-driven fitting program, and to compare the proposed fitting with the traditional audiogram-based fitting across measures of functional hearing (ability to recognize speech in noise) and subjective preference. A hearing aid user is often dissatisfied with the sound quality of their device, despite its sophistication and adjustment by a trained audiologist. The problem can be mitigated by letting the user fine-tune the device for maximum comfort in everyday use. We will apply modern machine learning methods to develop a program for efficient user-driven fitting of hearing assistive devices.",User-driven fitting of hearing aids and other assistive hearing devices,9409910,R43DC016251,"['Address', 'Algorithms', 'Audiometry', 'Auditory', 'Back', 'Books', 'Cellular Phone', 'Characteristics', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Computer software', 'Development', 'Devices', 'Environment', 'Future', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Impairment', 'Individual', 'Instruction', 'Intuition', 'Knowledge', 'Likelihood Functions', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Music', 'Noise', 'Outcome', 'Patients', 'Performance', 'Phase', 'Physiological', 'Presbycusis', 'Process', 'Protocols documentation', 'Psychology', 'Psychophysics', 'Relaxation', 'Reproducibility', 'Self-Help Devices', 'Sensorineural Hearing Loss', 'Societies', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Time', 'Training', 'Update', 'base', 'cohort', 'cost', 'design', 'hearing impairment', 'improved', 'learning strategy', 'models and simulation', 'novel', 'performance tests', 'preference', 'programs', 'response', 'signal processing', 'simulation', 'social', 'sound', 'success', 'theories', 'tool', 'vector']",NIDCD,"CARAWAY SOFTWARE, INC.",R43,2017,224966,0.2220962810850413
"Multi-Measure Speech Perception in Noise (MMSPIN) Chart: More Scores, Fewer Tests Project summary. This Phase I will establish the feasibility of increasing audiological diagnostic information by carrying out word- and phoneme-level analyses of open set responses during speech audiometry and by obtaining subjective hearing measures. Speech audiometry is used in characterizing functional hearing in settings of hearing screening, diagnosis, hearing aid fitting, counseling, aural rehabilitation/training, occupational fitness, and research. A typical procedure used with word and sentence tests in background noise is to ask the client/patient to repeat back what was just said (i.e., give an open set response). Responses are then scored in terms of words or keywords correct/incorrect. This method discards potentially diagnostic information in response errors, because noise can reveal systematic phonetic feature or phoneme confusions, and with background babble, intrusions from the babble. Other response patterns attributable to cognitive or memory declines may manifest in the paucity or verbosity of response words. Specific types of phoneme perception errors are thought to be associated with extent and configuration of hearing loss; and different types of noise maskers (i.e., energetic and informational maskers) present different types of perceptual problems that vary in severity across individuals. In order to utilize response errors, computational methods are needed to establish their relationships to the stimulus. This is because response errors may incorporate incorrect stimulus-to-response phoneme substitutions, as well as insertions or deletions of phonemes or words relative to the stimulus. We have developed sequence alignment methods to mine errors during speech audiometry, which we propose to evaluate using our system (Multi-Measure SPIN Chart: MMSPIN Chart). MMSPIN chart will be further developed and installed in the George Washington University Speech & Hearing Center (Aim 1). Audiologists will use the system during QuickSin sentence and NU-6 word testing with 200 clients (18-85 years of age) who give permission to access their entire clinic records (Aim 2). Their conventional speech audiometry will be augmented by obtaining subjective hearing accuracy judgments and hearing self-efficacy measures. These subjective judgments are designed to expose discrepancies with objective performance and to reveal individual differences in social cognition associated with hearing loss, both of which may account for the large individual differences in performance and intervention outcomes not accounted for by the audiogram. Evaluation of results in Aim 3 will include developing group and individual profile models comprising objective and subjective clinical data. With our clinician partners, we will develop formats for communicating MMSPIN Chart results to clients. In Aim 4, we will present results in a public lecture for audiologists and solicit opinions about how our new results may best impact clinical practice. Our approach can deliver more informative and efficient speech audiometry using existing test materials and can pave the way to more sensitive speech audiometry, including tests that are adaptive to specific levels of speech processing difficulty. Narrative. The typical approach to speech audiometry is to elicit open set responses that are scored in terms of words/keywords correct, discarding information in response errors. This Phase I will establish the feasibility of increasing diagnostic information provided to audiologists by carrying out word- and phoneme-level analyses of open set responses and obtaining subjective hearing measures in conjunction with speech audiometry. The goal is to improve clinical efficiency and effectiveness and to improve patient outcomes.","Multi-Measure Speech Perception in Noise (MMSPIN) Chart: More Scores, Fewer Tests",9408539,R43DC015749,"['Adult', 'Age', 'Age-Years', 'Attitude to Health', 'Audiometry', 'Authorization documentation', 'Back', 'Classification', 'Client', 'Clinic', 'Clinical', 'Clinical Data', 'Computers', 'Computing Methodologies', 'Confusion', 'Counseling', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Effectiveness', 'Evaluation', 'Factor Analysis', 'Focus Groups', 'Goals', 'Hearing', 'Hearing Aids', 'Impaired cognition', 'Individual', 'Individual Differences', 'Intervention', 'Judgment', 'Machine Learning', 'Materials Testing', 'Measures', 'Memory Loss', 'Methods', 'Modeling', 'Noise', 'Occupational', 'Outcome', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Perception', 'Performance', 'Phase', 'Procedures', 'Pure-Tone Audiometry', 'Questionnaires', 'Records', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Role', 'Self Efficacy', 'Sequence Alignment', 'Severities', 'Speech', 'Speech Audiometry', 'Speech Perception', 'Stimulus', 'Supervision', 'System', 'Technology', 'Test Result', 'Testing', 'Time', 'Training', 'Universities', 'Vision', 'Voice', 'Washington', 'Work', 'clinical practice', 'comparison group', 'data modeling', 'design', 'fitness', 'hearing impairment', 'hearing screening', 'improved', 'lectures', 'permissiveness', 'phonology', 'response', 'satisfaction', 'social cognition', 'speech processing', 'speech recognition', 'touchscreen']",NIDCD,"SEEHEAR, LLC",R43,2017,147919,0.044721444365509996
"Experimental and Clinical Studies of Presbycusis DESCRIPTION (provided by applicant): The focus of this research is age-related hearing loss (presbycusis). Currently, more than 28 million Americans have impaired hearing and approximately 75% of these persons are over the age of 55. The prevalence of presbycusis will increase substantially with the aging of the population. To meet the challenges of this most common chronic condition of aging, improved diagnostic methods, treatment approaches, and prevention strategies will be of great importance. To meet these objectives, four research projects are proposed. Project 1 assesses age-related changes in human cochlear and neural function related to metabolic, sensory, and neural pathologies. Project 2 examines the impact of metabolic and sensory presbycusis and aging on brain structure and functional networks that support speech recognition. Project 3 identifies genetic variations causing an increased susceptibility to age-related hearing loss using DNA samples from older adults in our study and defines their pathological consequences in human temporal bones. Project 4 studies adult stem cell dependency on the cochlear extracellular matrix (ECM) microenvironment using animal models of metabolic presbycusis and ECM deficiency, and observations of cochlear tissues from human temporal bones. A central goal is to relate changes observed in animal models of metabolic presbycusis to declines in hearing in older humans. In parallel with this goal, results from the large battery of tests obtained from participants in our longitudinal study (Human Subjects Core) will be analyzed to further define and validate phenotypes of age-related hearing loss. Thus, four interrelated research projects, supported by large numbers of well-characterized human subjects and a detailed database of cross-sectional and longitudinal data, form a cohesive program that addresses fundamental questions on human presbycusis. The Clinical Research Center is unique in several respects, including its 25-year longitudinal study of  hearing in older persons, the diversity of basic, translational, and clinical approaches, and its focus on a disorder that contributes to poor communication abilities and reduced quality of life for millions of older adults. PUBLIC HEALTH RELEVANCE: The Clinical Research Center leverages the multidisciplinary and wide-ranging expertise in each project, and the wealth of information available in the human subject database, to generate new knowledge on the high prevalence public health problem of age-related hearing loss. Our goals are to reduce its prevalence, slow its progression, and develop new prevention, diagnostic, and treatments strategies to improve communication and quality of life of older adults.      Subproject 1  Defining Phenotypes of Age-Related Hearing Loss  Lead Investigator: Judy R. Dubno, Ph.D.    DESCRIPTION (provided by applicant): The complex genetic and environmental factors affecting human hearing over the lifespan contribute to a large variation in audiometric profiles and suprathreshold measures of auditory function. As a result, determining mechanisms of age-related hearing loss in older adults is challenging because genetic, age, noise history, injury, disease, medication, diet, and other factors can work independently and jointly to alter human auditory function. Although morphologic findings from older humans are limited to postmortem data, experimental procedures with animals of known heredity can disrupt specific cochlear systems, model certain pathologic conditions, and introduce or minimize environmental exposures, while measuring subsequent changes in auditory function. Consistent with results from animal models linking audiometric profiles to specific cochlear pathologies, such as metabolic or sensory loss, audiograms from the Clinical Research Center's human subject database (Core B) were classified into four audiometric phenotypes, which provided a means to characterize the pathophysiology of hearing loss in older humans. Audiometric phenotypes determined using supervised machine learning classifiers were consistent with expected demographic and noise history patterns that segregate with patterns of hearing loss. Project 1 will refine and further validate these phenotyping methods using suprathreshold measures of cochlear and neural function beyond the audiogram that characterize metabolic and sensory presbyacusis, and the additive effects of morphologic and functional neural loss. To meet this goal Aim 1.1 tests the hypothesis that older adults with metabolic and sensory presbyacusis differ in cochlear nonlinearities and lower frequency suprathreshold auditory function. Aim 1.2 tests the hypothesis that changes in auditory nerve activity result in unique and additive effects in older adults with metabolic and sensory presbyacusis. Thus, Project 1 will assess age- related changes in auditory function related to metabolic, sensory, and neural pathologies and link findings to Project 2, focused on central auditory and cortical changes, and to translational Projects 3 and 4, which will determine the genetic and cellular mechanisms of age-related hearing loss using humans and human tissue. With these approaches, morphologic and physiologic changes characterizing metabolic, sensory, and neural presbyacusis provide a framework for assessing and interpreting age-related changes in human auditory function.    PUBLIC HEALTH RELEVANCE: Knowledge of the variations in pathophysiology underlying human age-related hearing loss may dictate different diagnostic test batteries, hearing-aid fitting  algorithms, auditory-training regimens, and recommendations for communication strategies. This new information will lead to better diagnosis and treatments for this high-prevalence public health concern, and improved communication and quality of life for millions of older adults.",Experimental and Clinical Studies of Presbycusis,9205503,P50DC000422,"['Acoustic Nerve', 'Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'American', 'Animal Model', 'Animals', 'Audiometry', 'Auditory', 'Autopsy', 'Brain', 'Chronic', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'DNA', 'Data', 'Databases', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Diet', 'Disease', 'Doctor of Philosophy', 'Elderly', 'Environmental Exposure', 'Environmental Risk Factor', 'Extracellular Matrix', 'Frequencies', 'Functional disorder', 'Genetic', 'Genetic Variation', 'Goals', 'Hearing', 'Hearing Aids', 'Heredity', 'High Prevalence', 'Human', 'Injury', 'Knowledge', 'Lead', 'Link', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Morphology', 'Neurophysiology - biologic function', 'Noise', 'Participant', 'Pathologic', 'Pathology', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical shape', 'Physiological', 'Population', 'Predisposition', 'Presbycusis', 'Prevalence', 'Prevention', 'Prevention strategy', 'Procedures', 'Public Health', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Sensory', 'Structure', 'Supervision', 'System', 'Temporal bone structure', 'Testing', 'Training', 'Variant', 'Work', 'adult stem cell', 'age related', 'cohesion', 'experimental study', 'hearing impairment', 'human subject', 'human tissue', 'improved', 'multidisciplinary', 'programs', 'public health relevance', 'relating to nervous system', 'speech recognition', 'support network', 'treatment strategy']",NIDCD,MEDICAL UNIVERSITY OF SOUTH CAROLINA,P50,2017,2137301,0.1567506797188823
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9232830,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Audiometry', 'Biological Preservation', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Computer Simulation', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Impaired Persons', 'Hereditary Disease', 'Heritability', 'Human', 'Inherited', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Research Infrastructure', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical phenotype', 'clinically significant', 'cohort', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'hearing impairment', 'improved', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'tool']",NIDCD,UNIVERSITY OF IOWA,R01,2017,564086,0.25795196794868924
"Individualized Signal Processing Strategy :Phase II This project describes a novel approach to automate and individualize the signal processing strategy for hearing aids (HA) that can result in improved speech intelligibility in background noise, greater user satisfaction and acceptance for HAs, and reduce barriers to affordable hearing health care. The proposed Individualized Signal Processing Strategy (ISPS) is based on individual performance on categorical perception tasks for speech stimuli. This differs from traditional methods based on sophisticated gain models built upon average perception, performance, and preference data. The ability to determine one’s ISPS automatically, rapidly and remotely can result in dramatic cost-savings and greater accessibility to hearing health care for patients who cannot afford it or for those who lack easy access to the necessary expertise. These technical achievements have the potential to radically change HA service delivery models yet can be implemented within existing business models and in concert with current practitioners. The ISPS method effectively replaces target-based HA fitting (e.g. NAL-NL2) with individualized speech-based parameter adjustment. The proposed work follows successful completion of our pilot project and builds upon the research team’s prior research on novel fitting methods for cochlear implant (CI) devices recently acquired by Cochlear, Ltd. Following the successful implementation of ISPS and integration with commercial HA software in the pilot study, we demonstrated feasibility including a field study in which performance outcomes for the ISPS method were as good as a conventional HA fitting method and only took a fraction of the time, despite ISPS having no prior knowledge of patient characteristics and no audiogram. Successful maturation and commercialization of the ISPS technology in Phase II will address several barriers identified in the previous RFA-DC-12-004 including physical, infrastructure, and knowledge barriers (by allowing remote or self-fitting HAs), economic barriers (by reducing overall costs), and cultural barriers (by providing easy access to HA fitting for patients who tend to avoid professional help). This Phase II project will develop an operational ISPS method by (1) integrating ISPS with hardware/software systems of our industry partners, (2) refine and enhance the ISPS method to improve efficiency and effectiveness of fitting hearing instruments, (3) build support for the use of ISPS in multiple marketplaces, and (4) evaluate the technology through field trials in different service delivery environments by comparing outcomes with ISPS fitting to those achieved with traditional prescriptive gain fitting within the same subjects. Following successful demonstration of these objectives, a Phase III project will focus on the transition of the technology to support remote and self-fitting of hearing instruments. This project seeks to develop, implement and test a novel automated method for fitting hearing aids based on real-time speech perception performance. This automated approach can improve hearing aid success while significant reducing costs of hearing health care. The automation of the fitting procedure can dramatically increase accessibility of hearing health care.",Individualized Signal Processing Strategy :Phase II,9347562,R44DC016249,"['Achievement', 'Address', 'Algorithms', 'Artificial Intelligence', 'Audiology', 'Audiometry', 'Auditory', 'Automation', 'Businesses', 'Categories', 'Characteristics', 'Cochlear Implants', 'Collaborations', 'Computer software', 'Cost Savings', 'Crossover Design', 'Data', 'Development', 'Devices', 'Economics', 'Effectiveness', 'Environment', 'Evaluation', 'Frequencies', 'Funding', 'Generic Drugs', 'Goals', 'Healthcare', 'Hearing', 'Hearing Aids', 'Individual', 'Instruction', 'Knowledge', 'Learning', 'Link', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Perception', 'Performance', 'Phase', 'Pilot Projects', 'Procedures', 'Process', 'Randomized', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Sensorineural Hearing Loss', 'Services', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Stimulus', 'Supervision', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'United States Department of Veterans Affairs', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'commercialization', 'cost', 'data modeling', 'experimental study', 'field study', 'graph theory', 'health care service', 'implantable device', 'improved', 'improved outcome', 'inclusion criteria', 'industry partner', 'instrument', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'preference', 'satisfaction', 'signal processing', 'software systems', 'sound', 'success']",NIDCD,"SECURBORATION, INC.",R44,2017,758924,0.13355945914482617
"Micromachined microphones with in-plane and out-of-plane directivity Project Summary We aim to introduce to the hearing-assistive device industry directional microphones with high signal-to-noise ratio, and the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or “window” of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired “rocking” style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. We aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete  -axis pressure gradient sensor. Project Narrative Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the “cocktail party” effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified – making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.",Micromachined microphones with in-plane and out-of-plane directivity,9098683,R44DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Hearing', 'Hearing Aids', 'Industry', 'Laboratories', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R44,2016,490980,0.2698890769967601
"Experimental and Clinical Studies of Presbycusis DESCRIPTION (provided by applicant): The focus of this research is age-related hearing loss (presbycusis). Currently, more than 28 million Americans have impaired hearing and approximately 75% of these persons are over the age of 55. The prevalence of presbycusis will increase substantially with the aging of the population. To meet the challenges of this most common chronic condition of aging, improved diagnostic methods, treatment approaches, and prevention strategies will be of great importance. To meet these objectives, four research projects are proposed. Project 1 assesses age-related changes in human cochlear and neural function related to metabolic, sensory, and neural pathologies. Project 2 examines the impact of metabolic and sensory presbycusis and aging on brain structure and functional networks that support speech recognition. Project 3 identifies genetic variations causing an increased susceptibility to age-related hearing loss using DNA samples from older adults in our study and defines their pathological consequences in human temporal bones. Project 4 studies adult stem cell dependency on the cochlear extracellular matrix (ECM) microenvironment using animal models of metabolic presbycusis and ECM deficiency, and observations of cochlear tissues from human temporal bones. A central goal is to relate changes observed in animal models of metabolic presbycusis to declines in hearing in older humans. In parallel with this goal, results from the large battery of tests obtained from participants in our longitudinal study (Human Subjects Core) will be analyzed to further define and validate phenotypes of age-related hearing loss. Thus, four interrelated research projects, supported by large numbers of well-characterized human subjects and a detailed database of cross-sectional and longitudinal data, form a cohesive program that addresses fundamental questions on human presbycusis. The Clinical Research Center is unique in several respects, including its 25-year longitudinal study of  hearing in older persons, the diversity of basic, translational, and clinical approaches, and its focus on a disorder that contributes to poor communication abilities and reduced quality of life for millions of older adults. PUBLIC HEALTH RELEVANCE: The Clinical Research Center leverages the multidisciplinary and wide-ranging expertise in each project, and the wealth of information available in the human subject database, to generate new knowledge on the high prevalence public health problem of age-related hearing loss. Our goals are to reduce its prevalence, slow its progression, and develop new prevention, diagnostic, and treatments strategies to improve communication and quality of life of older adults.      Subproject 1  Defining Phenotypes of Age-Related Hearing Loss  Lead Investigator: Judy R. Dubno, Ph.D.    DESCRIPTION (provided by applicant): The complex genetic and environmental factors affecting human hearing over the lifespan contribute to a large variation in audiometric profiles and suprathreshold measures of auditory function. As a result, determining mechanisms of age-related hearing loss in older adults is challenging because genetic, age, noise history, injury, disease, medication, diet, and other factors can work independently and jointly to alter human auditory function. Although morphologic findings from older humans are limited to postmortem data, experimental procedures with animals of known heredity can disrupt specific cochlear systems, model certain pathologic conditions, and introduce or minimize environmental exposures, while measuring subsequent changes in auditory function. Consistent with results from animal models linking audiometric profiles to specific cochlear pathologies, such as metabolic or sensory loss, audiograms from the Clinical Research Center's human subject database (Core B) were classified into four audiometric phenotypes, which provided a means to characterize the pathophysiology of hearing loss in older humans. Audiometric phenotypes determined using supervised machine learning classifiers were consistent with expected demographic and noise history patterns that segregate with patterns of hearing loss. Project 1 will refine and further validate these phenotyping methods using suprathreshold measures of cochlear and neural function beyond the audiogram that characterize metabolic and sensory presbyacusis, and the additive effects of morphologic and functional neural loss. To meet this goal Aim 1.1 tests the hypothesis that older adults with metabolic and sensory presbyacusis differ in cochlear nonlinearities and lower frequency suprathreshold auditory function. Aim 1.2 tests the hypothesis that changes in auditory nerve activity result in unique and additive effects in older adults with metabolic and sensory presbyacusis. Thus, Project 1 will assess age- related changes in auditory function related to metabolic, sensory, and neural pathologies and link findings to Project 2, focused on central auditory and cortical changes, and to translational Projects 3 and 4, which will determine the genetic and cellular mechanisms of age-related hearing loss using humans and human tissue. With these approaches, morphologic and physiologic changes characterizing metabolic, sensory, and neural presbyacusis provide a framework for assessing and interpreting age-related changes in human auditory function.    PUBLIC HEALTH RELEVANCE: Knowledge of the variations in pathophysiology underlying human age-related hearing loss may dictate different diagnostic test batteries, hearing-aid fitting  algorithms, auditory-training regimens, and recommendations for communication strategies. This new information will lead to better diagnosis and treatments for this high-prevalence public health concern, and improved communication and quality of life for millions of older adults.",Experimental and Clinical Studies of Presbycusis,9012784,P50DC000422,"['Acoustic Nerve', 'Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'American', 'Animal Model', 'Animals', 'Audiometry', 'Auditory', 'Autopsy', 'Biological Models', 'Brain', 'Chronic', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'DNA', 'Data', 'Databases', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Diet', 'Disease', 'Doctor of Philosophy', 'Elderly', 'Environmental Exposure', 'Environmental Risk Factor', 'Extracellular Matrix', 'Frequencies', 'Functional disorder', 'Genetic', 'Genetic Variation', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Heredity', 'High Prevalence', 'Human', 'Injury', 'Knowledge', 'Lead', 'Link', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Neurophysiology - biologic function', 'Noise', 'Participant', 'Pathologic', 'Pathology', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical shape', 'Physiological', 'Predisposition', 'Presbycusis', 'Prevalence', 'Prevention', 'Prevention strategy', 'Procedures', 'Public Health', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Sensory', 'Structure', 'Temporal bone structure', 'Testing', 'Training', 'Variant', 'Work', 'adult stem cell', 'age related', 'aging population', 'hearing impairment', 'human subject', 'human tissue', 'improved', 'meetings', 'multidisciplinary', 'programs', 'relating to nervous system', 'research study', 'speech recognition', 'support network', 'treatment strategy']",NIDCD,MEDICAL UNIVERSITY OF SOUTH CAROLINA,P50,2016,2214679,0.1567506797188823
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment. In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8899486,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Massive Parallel Sequencing', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'genetic variant', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'screening', 'software systems', 'targeted sequencing', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2015,574693,0.16059646418422008
"Micromachined microphones with in-plane and out-of-plane directivity Project Summary We aim to introduce to the hearing-assistive device industry directional microphones with high signal-to-noise ratio, and the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or “window” of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired “rocking” style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. We aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete  -axis pressure gradient sensor. Project Narrative Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the “cocktail party” effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified – making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.",Micromachined microphones with in-plane and out-of-plane directivity,8981015,R44DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Hearing', 'Hearing Aids', 'Industry', 'Laboratories', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R44,2015,508997,0.2698890769967601
"Experimental and Clinical Studies of Presbycusis DESCRIPTION (provided by applicant): The focus of this research is age-related hearing loss (presbycusis). Currently, more than 28 million Americans have impaired hearing and approximately 75% of these persons are over the age of 55. The prevalence of presbycusis will increase substantially with the aging of the population. To meet the challenges of this most common chronic condition of aging, improved diagnostic methods, treatment approaches, and prevention strategies will be of great importance. To meet these objectives, four research projects are proposed. Project 1 assesses age-related changes in human cochlear and neural function related to metabolic, sensory, and neural pathologies. Project 2 examines the impact of metabolic and sensory presbycusis and aging on brain structure and functional networks that support speech recognition. Project 3 identifies genetic variations causing an increased susceptibility to age-related hearing loss using DNA samples from older adults in our study and defines their pathological consequences in human temporal bones. Project 4 studies adult stem cell dependency on the cochlear extracellular matrix (ECM) microenvironment using animal models of metabolic presbycusis and ECM deficiency, and observations of cochlear tissues from human temporal bones. A central goal is to relate changes observed in animal models of metabolic presbycusis to declines in hearing in older humans. In parallel with this goal, results from the large battery of tests obtained from participants in our longitudinal study (Human Subjects Core) will be analyzed to further define and validate phenotypes of age-related hearing loss. Thus, four interrelated research projects, supported by large numbers of well-characterized human subjects and a detailed database of cross-sectional and longitudinal data, form a cohesive program that addresses fundamental questions on human presbycusis. The Clinical Research Center is unique in several respects, including its 25-year longitudinal study of  hearing in older persons, the diversity of basic, translational, and clinical approaches, and its focus on a disorder that contributes to poor communication abilities and reduced quality of life for millions of older adults. PUBLIC HEALTH RELEVANCE: The Clinical Research Center leverages the multidisciplinary and wide-ranging expertise in each project, and the wealth of information available in the human subject database, to generate new knowledge on the high prevalence public health problem of age-related hearing loss. Our goals are to reduce its prevalence, slow its progression, and develop new prevention, diagnostic, and treatments strategies to improve communication and quality of life of older adults.      Subproject 1  Defining Phenotypes of Age-Related Hearing Loss  Lead Investigator: Judy R. Dubno, Ph.D.    DESCRIPTION (provided by applicant): The complex genetic and environmental factors affecting human hearing over the lifespan contribute to a large variation in audiometric profiles and suprathreshold measures of auditory function. As a result, determining mechanisms of age-related hearing loss in older adults is challenging because genetic, age, noise history, injury, disease, medication, diet, and other factors can work independently and jointly to alter human auditory function. Although morphologic findings from older humans are limited to postmortem data, experimental procedures with animals of known heredity can disrupt specific cochlear systems, model certain pathologic conditions, and introduce or minimize environmental exposures, while measuring subsequent changes in auditory function. Consistent with results from animal models linking audiometric profiles to specific cochlear pathologies, such as metabolic or sensory loss, audiograms from the Clinical Research Center's human subject database (Core B) were classified into four audiometric phenotypes, which provided a means to characterize the pathophysiology of hearing loss in older humans. Audiometric phenotypes determined using supervised machine learning classifiers were consistent with expected demographic and noise history patterns that segregate with patterns of hearing loss. Project 1 will refine and further validate these phenotyping methods using suprathreshold measures of cochlear and neural function beyond the audiogram that characterize metabolic and sensory presbyacusis, and the additive effects of morphologic and functional neural loss. To meet this goal Aim 1.1 tests the hypothesis that older adults with metabolic and sensory presbyacusis differ in cochlear nonlinearities and lower frequency suprathreshold auditory function. Aim 1.2 tests the hypothesis that changes in auditory nerve activity result in unique and additive effects in older adults with metabolic and sensory presbyacusis. Thus, Project 1 will assess age- related changes in auditory function related to metabolic, sensory, and neural pathologies and link findings to Project 2, focused on central auditory and cortical changes, and to translational Projects 3 and 4, which will determine the genetic and cellular mechanisms of age-related hearing loss using humans and human tissue. With these approaches, morphologic and physiologic changes characterizing metabolic, sensory, and neural presbyacusis provide a framework for assessing and interpreting age-related changes in human auditory function.    PUBLIC HEALTH RELEVANCE: Knowledge of the variations in pathophysiology underlying human age-related hearing loss may dictate different diagnostic test batteries, hearing-aid fitting  algorithms, auditory-training regimens, and recommendations for communication strategies. This new information will lead to better diagnosis and treatments for this high-prevalence public health concern, and improved communication and quality of life for millions of older adults.",Experimental and Clinical Studies of Presbycusis,8786533,P50DC000422,"['Acoustic Nerve', 'Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'American', 'Animal Model', 'Animals', 'Audiometry', 'Auditory', 'Autopsy', 'Biological Models', 'Brain', 'Chronic', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'DNA', 'Data', 'Databases', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Diet', 'Disease', 'Doctor of Philosophy', 'Elderly', 'Environmental Exposure', 'Environmental Risk Factor', 'Extracellular Matrix', 'Frequencies', 'Functional disorder', 'Genetic', 'Genetic Variation', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Heredity', 'High Prevalence', 'Human', 'Injury', 'Knowledge', 'Lead', 'Link', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Neurophysiology - biologic function', 'Noise', 'Participant', 'Pathologic', 'Pathology', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical shape', 'Physiological', 'Population', 'Predisposition', 'Presbycusis', 'Prevalence', 'Prevention', 'Prevention strategy', 'Procedures', 'Public Health', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Sensory', 'Structure', 'Temporal bone structure', 'Testing', 'Training', 'Variant', 'Work', 'adult stem cell', 'age related', 'hearing impairment', 'human subject', 'human tissue', 'improved', 'meetings', 'multidisciplinary', 'programs', 'relating to nervous system', 'research study', 'speech recognition', 'treatment strategy']",NIDCD,MEDICAL UNIVERSITY OF SOUTH CAROLINA,P50,2015,2302752,0.1567506797188823
"Video-based Speech Enhancement for Vision and Hearing Impairment     DESCRIPTION (provided by applicant):  Video-based Speech Enhancement for Persons with Hearing and Vision Loss Project Summary It is estimated that by 2030, the number of people in the United States over the age of 65 will account for over 20% of the total population.  Hearing and vision loss naturally accompanies the aging process.  Persons with hearing loss can benefit from observing the visual cues from a speaker such as the shape of the lips and facial expression to greatly improve their ability to comprehend speech.  However, persons with vision loss cannot make use of these visual cues, and have a harder time understanding speech, especially in noisy environments.  Furthermore, people with normal vision can use visual information to identify a speaker in a group, which allows them to focus on this person.  This can greatly benefit a person with hearing loss who may be using a device such as a sound amplifier or a hearing aid.  A user with vision loss, however, needs to be provided with this speaker information to make optimal use of such devices.  We propose developing a prototype device that will clean the speech signal from a target speaker and improve speech comprehension for persons with hearing and vision loss in everyday situations.  In order to accomplish this task, we need to harness the visual cues that have so far largely been ignored in the design of assistive technolo- gies for persons with hearing loss.  Our first aim is to learn speaker-independent visual cues that are associated with the target speech signal, and use these audio-visual cues to design speech enhancement algorithms that perform much better in noisy everyday environment than current methods which only utilize the audio signal.  We will utilize a video camera and computer vision methods to design advanced digital signal processing techniques to enhance the target speech signals recorded through a microphone.  Our second aim is to use the video and audio signals to detect and efficiently localize the visible speaker.  The information regarding the location of the speaker of interest can then be used to efficiently perform speaker separation, as well as be provided to the user.  Finally, we aim to implement these developed algorithms on a portable prototype system.  We will test the performance of this system and improve the user-interface through user experiments in real-world situations as well as laboratory conditions.  The end product will show the feasibility and importance of incorporating multiple modalities into sensory assistive devices, and set the stage for future research and development efforts.         PUBLIC HEALTH RELEVANCE:  It is estimated that by 2030, more than one in five people in the United States will be over the age of 65.  Age- related hearing and vision loss is considered a natural consequence of the aging process, yet current assistive technology approaches do little to address this type of sensory loss.  The proposed research will test the feasibility of incorporating visual information in hearing aids, which is expected to improve speech perception for persons with hearing and vision loss in everyday situations, greatly enhancing their ability to lead independent lives, remain employable, and maintain active participation in society.                ",Video-based Speech Enhancement for Vision and Hearing Impairment,8659442,R21EY022200,"['Accounting', 'Acoustics', 'Activities of Daily Living', 'Address', 'Adult', 'Age', 'Age-Years', 'Aging-Related Process', 'Algorithms', 'Amplifiers', 'Area', 'Auditory', 'Blindness', 'Communication', 'Comprehension', 'Computer Vision Systems', 'Cues', 'Dependence', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Effectiveness', 'Elderly', 'Environment', 'Facial Expression', 'Feedback', 'Grant', 'Hearing Aids', 'Human', 'Laboratories', 'Lead', 'Learning', 'Life', 'Lip structure', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modality', 'Modeling', 'Noise', 'Output', 'Performance', 'Persons', 'Play', 'Population', 'Presbycusis', 'Process', 'Quality of life', 'Research', 'Role', 'Self-Help Devices', 'Sensory', 'Sensory Aids', 'Shapes', 'Signal Transduction', 'Societies', 'Source', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Staging', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Vision', 'Visual', 'Visual impairment', 'Voice', 'base', 'design', 'hearing impairment', 'improved', 'interest', 'novel strategies', 'performance tests', 'prototype', 'public health relevance', 'research study', 'signal processing', 'social', 'sound', 'speech recognition', 'tool development', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2014,230945,0.09999133590729546
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics   Project Summary  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment.   In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8712451,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Massive Parallel Sequencing', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'genetic variant', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'screening', 'software systems', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2014,606168,0.16059646418422008
"Micromachined microphones with in-plane and out-of-plane directivity  Project Summary We aim to introduce to the hearing-assistive device industry the first commercialized microphone that combines all three axes of acoustic pressure gradient onto a single silicon chip. We expect the technology to empower the signal-processing community with a new tool which, when used in conjunction with a conventional omnidirectional microphone, will facilitate new features like ultra-sharp directionality adaptable in real-time by the user and/or artificial intelligence algorithms which scan for desired inputs while filtering out unwanted noise. Directional sensing and the ability to filter out undesirable background acoustic noise are important for those with hearing impairments. Hearing impairment is associated with a loss of fidelity to quiet sounds, while the threshold of pain remains the same. As such, hearing impairment causes a loss of dynamic range or ""window"" of detectable sound amplitudes. Directional sensing enables preferentially amplifying desired sounds without amplifying background noise. As the first step, we aim to accelerate the commercialization of recently introduced biologically- inspired ""rocking"" style microphones by synthesizing these designs with integrated, robust piezoelectric readout which is ideal for addressing the low-power, small-size, and high levels of integration required of the hearing-aid industry. Previous work in this field using laboratory prototypes and optical readout have demonstrated the merits of the biologically-inspired sensing approach (i.e. a simultaneous 20-dB SNR improvement and 10x reduction size improvement beyond what is achievable with present-day hearing-aid or MEMS microphones). By synthesizing a piezoelectric embodiment as an alternative to optical readout, we aim to accelerate through many of the commercialization challenges so that an impact to the hearing device industry can be made. Further, the proposed readout is better adapted towards integrating multiple microphones in the same silicon chip. In Phase II, we aim to integrate a microphone with both in-plane axis of directivity with an out-of-plane directional design to form a complete 3-axis pressure gradient sensor. PUBLIC HEALTH RELEVANCE: Studies show that today 2% of Americans wear a hearing aid, whereas at least 10% of Americans could benefit from a hearing assistive device. The major reason for this gap is patient dissatisfaction. Hearing-aid wearers suffer from what is known as the ""cocktail party"" effect. When the gain is turned up to hear the person speaking across from you, noises in the background are equally amplified - making every scenario sound like a cocktail party. This research aims to make a positive, long-term improvement to hearing-aid patient satisfaction by making commercially available directional microphones with high fidelity.            ",Micromachined microphones with in-plane and out-of-plane directivity,8648777,R43DC013746,"['Acoustics', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Client satisfaction', 'Communities', 'Devices', 'Environment', 'Goals', 'Hearing', 'Hearing Aids', 'Industry', 'Investigation', 'Laboratories', 'Microfabrication', 'Noise', 'Optics', 'Pain Threshold', 'Patients', 'Persons', 'Phase', 'Research', 'Scanning', 'Self-Help Devices', 'Signal Transduction', 'Silicon', 'Small Business Innovation Research Grant', 'Structure', 'Techniques', 'Technology', 'Time', 'Work', 'commercialization', 'design', 'empowered', 'hearing impairment', 'pressure', 'prototype', 'public health relevance', 'sensor', 'signal processing', 'sound', 'tool']",NIDCD,"SILICON AUDIO, INC.",R43,2014,149828,0.26583809689807003
"Experimental and Clinical Studies of Presbycusis DESCRIPTION (provided by applicant): The focus of this research is age-related hearing loss (presbycusis). Currently, more than 28 million Americans have impaired hearing and approximately 75% of these persons are over the age of 55. The prevalence of presbycusis will increase substantially with the aging of the population. To meet the challenges of this most common chronic condition of aging, improved diagnostic methods, treatment approaches, and prevention strategies will be of great importance. To meet these objectives, four research projects are proposed. Project 1 assesses age-related changes in human cochlear and neural function related to metabolic, sensory, and neural pathologies. Project 2 examines the impact of metabolic and sensory presbycusis and aging on brain structure and functional networks that support speech recognition. Project 3 identifies genetic variations causing an increased susceptibility to age-related hearing loss using DNA samples from older adults in our study and defines their pathological consequences in human temporal bones. Project 4 studies adult stem cell dependency on the cochlear extracellular matrix (ECM) microenvironment using animal models of metabolic presbycusis and ECM deficiency, and observations of cochlear tissues from human temporal bones. A central goal is to relate changes observed in animal models of metabolic presbycusis to declines in hearing in older humans. In parallel with this goal, results from the large battery of tests obtained from participants in our longitudinal study (Human Subjects Core) will be analyzed to further define and validate phenotypes of age-related hearing loss. Thus, four interrelated research projects, supported by large numbers of well-characterized human subjects and a detailed database of cross-sectional and longitudinal data, form a cohesive program that addresses fundamental questions on human presbycusis. The Clinical Research Center is unique in several respects, including its 25-year longitudinal study of  hearing in older persons, the diversity of basic, translational, and clinical approaches, and its focus on a disorder that contributes to poor communication abilities and reduced quality of life for millions of older adults. PUBLIC HEALTH RELEVANCE: The Clinical Research Center leverages the multidisciplinary and wide-ranging expertise in each project, and the wealth of information available in the human subject database, to generate new knowledge on the high prevalence public health problem of age-related hearing loss. Our goals are to reduce its prevalence, slow its progression, and develop new prevention, diagnostic, and treatments strategies to improve communication and quality of life of older adults.      Subproject 1  Defining Phenotypes of Age-Related Hearing Loss  Lead Investigator: Judy R. Dubno, Ph.D.    DESCRIPTION (provided by applicant): The complex genetic and environmental factors affecting human hearing over the lifespan contribute to a large variation in audiometric profiles and suprathreshold measures of auditory function. As a result, determining mechanisms of age-related hearing loss in older adults is challenging because genetic, age, noise history, injury, disease, medication, diet, and other factors can work independently and jointly to alter human auditory function. Although morphologic findings from older humans are limited to postmortem data, experimental procedures with animals of known heredity can disrupt specific cochlear systems, model certain pathologic conditions, and introduce or minimize environmental exposures, while measuring subsequent changes in auditory function. Consistent with results from animal models linking audiometric profiles to specific cochlear pathologies, such as metabolic or sensory loss, audiograms from the Clinical Research Center's human subject database (Core B) were classified into four audiometric phenotypes, which provided a means to characterize the pathophysiology of hearing loss in older humans. Audiometric phenotypes determined using supervised machine learning classifiers were consistent with expected demographic and noise history patterns that segregate with patterns of hearing loss. Project 1 will refine and further validate these phenotyping methods using suprathreshold measures of cochlear and neural function beyond the audiogram that characterize metabolic and sensory presbyacusis, and the additive effects of morphologic and functional neural loss. To meet this goal Aim 1.1 tests the hypothesis that older adults with metabolic and sensory presbyacusis differ in cochlear nonlinearities and lower frequency suprathreshold auditory function. Aim 1.2 tests the hypothesis that changes in auditory nerve activity result in unique and additive effects in older adults with metabolic and sensory presbyacusis. Thus, Project 1 will assess age- related changes in auditory function related to metabolic, sensory, and neural pathologies and link findings to Project 2, focused on central auditory and cortical changes, and to translational Projects 3 and 4, which will determine the genetic and cellular mechanisms of age-related hearing loss using humans and human tissue. With these approaches, morphologic and physiologic changes characterizing metabolic, sensory, and neural presbyacusis provide a framework for assessing and interpreting age-related changes in human auditory function.    PUBLIC HEALTH RELEVANCE: Knowledge of the variations in pathophysiology underlying human age-related hearing loss may dictate different diagnostic test batteries, hearing-aid fitting  algorithms, auditory-training regimens, and recommendations for communication strategies. This new information will lead to better diagnosis and treatments for this high-prevalence public health concern, and improved communication and quality of life for millions of older adults.",Experimental and Clinical Studies of Presbycusis,8617361,P50DC000422,"['Acoustic Nerve', 'Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'American', 'Animal Model', 'Animals', 'Audiometry', 'Auditory', 'Autopsy', 'Biological Models', 'Brain', 'Chronic', 'Clinical', 'Clinical Research', 'Communication', 'Complex', 'DNA', 'Data', 'Databases', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Diet', 'Disease', 'Doctor of Philosophy', 'Elderly', 'Environmental Exposure', 'Environmental Risk Factor', 'Extracellular Matrix', 'Frequencies', 'Functional disorder', 'Genetic', 'Genetic Variation', 'Goals', 'Health', 'Hearing', 'Hearing Aids', 'Heredity', 'High Prevalence', 'Human', 'Injury', 'Knowledge', 'Lead', 'Link', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Neurophysiology - biologic function', 'Noise', 'Participant', 'Pathologic', 'Pathology', 'Pattern', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical shape', 'Physiological', 'Population', 'Predisposition', 'Presbycusis', 'Prevalence', 'Prevention', 'Prevention strategy', 'Procedures', 'Public Health', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Regimen', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Sensory', 'Structure', 'Temporal bone structure', 'Testing', 'Training', 'Variant', 'Work', 'adult stem cell', 'age related', 'hearing impairment', 'human subject', 'human tissue', 'improved', 'meetings', 'multidisciplinary', 'programs', 'relating to nervous system', 'research study', 'speech recognition', 'treatment strategy']",NIDCD,MEDICAL UNIVERSITY OF SOUTH CAROLINA,P50,2014,2047726,0.1567506797188823
"Individualized Signal Processing Strategy to Reduce Hearing Health Care Cost/Disp  This project describes a novel approach to automate and individualize the signal processing strategy for hearing aids that can result in improved speech intelligibility in background noise, greater user satisfaction and acceptance for hearing aids, and reduce barriers to affordable hearing health care. The proposed Individualized Signal Processing Strategy (ISPS) is based upon individual performance on categorical perception tasks for speech stimuli. This differs from traditional methods based on sophisticated gain models built upon average perception, performance, and preference data. The ability to determine one's ISPS automatically, rapidly and remotely results in dramatic cost-savings and greater accessibility to hearing health care for patients who cannot afford it or for those who lack easy access to the necessary expertise. These technical achievements have the potential to radically change the hearing aid sales and delivery models yet can also be implemented within existing business models by replacing contemporary hearing aid fitting methods (e.g. adjusting to gain-frequency targets followed by subjective fine tuning) with individualized speech-based parameter adjustment. Successful implementation of the ISPS technology will impact several barriers identified in RFA-DC-12-004 including physical, infrastructure and knowledge barriers (by allowing remote or self-fitting hearing aids and minimizing the need for highly skilled expertise), economic barriers (by reducing overall costs) and cultural barriers (by providing easy access to hearing aid fitting for patients who tend to avoid seeking professional help). This Phase I project will demonstrate the feasibility for the ISPS approach by (1) implementing the ISPS on a standard personal computer, (2) integrating the ISPS with a commercially available hearing aid, and (3) completing a pilot clinical study comparing outcomes with ISPS fitting to those achieved with traditional prescriptive gain fitting within the same subjects. Following successful demonstration of these objectives, a Phase II project will be proposed to enable extension of the technology to a wide range of hearing aids, patient characteristics and listening environments, including innovations supporting the use for remote and self-fitting applications. PUBLIC HEALTH RELEVANCE: This project seeks to develop, implement and test a novel approach for fitting hearing aids using an individual's speech perception abilities. This automated approach can improved listener performance while significant reducing costs of hearing health care. The automation of the fitting procedure can dramatically increase accessibility of hearing health care.                ",Individualized Signal Processing Strategy to Reduce Hearing Health Care Cost/Disp,8626066,R43DC013623,"['Achievement', 'Acoustics', 'Artificial Intelligence', 'Audiology', 'Automation', 'Behavioral', 'Businesses', 'Canada', 'Characteristics', 'Clinical Research', 'Cochlear Implants', 'Collection', 'Computer software', 'Cost Savings', 'Crossover Design', 'Data', 'Devices', 'Economics', 'Effectiveness', 'Environment', 'Frequencies', 'Generations', 'Goals', 'Graph', 'Health Care Costs', 'Healthcare', 'Hearing', 'Hearing Aids', 'Individual', 'Knowledge', 'Learning', 'Letters', 'Manufacturer Name', 'Maps', 'Measures', 'Methods', 'Metric', 'Modeling', 'Modification', 'Noise', 'Outcome', 'Output', 'Patients', 'Pattern', 'Perception', 'Performance', 'Personal Computers', 'Persons', 'Phase', 'Pilot Projects', 'Procedures', 'Process', 'Randomized', 'Research', 'Research Infrastructure', 'Sales', 'Services', 'Solutions', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Stimulus', 'Technology', 'Testing', 'Time', 'Training', 'Translations', 'Work', 'base', 'cost', 'design', 'experience', 'implantable device', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'preference', 'public health relevance', 'satisfaction', 'signal processing', 'sound', 'success', 'theories']",NIDCD,"SECURBORATION, INC.",R43,2014,149994,0.1927103591403008
"Video-based Speech Enhancement for Persons with Vision and Hearing Loss     DESCRIPTION (provided by applicant):  Video-based Speech Enhancement for Persons with Hearing and Vision Loss Project Summary It is estimated that by 2030, the number of people in the United States over the age of 65 will account for over 20% of the total population.  Hearing and vision loss naturally accompanies the aging process.  Persons with hearing loss can benefit from observing the visual cues from a speaker such as the shape of the lips and facial expression to greatly improve their ability to comprehend speech.  However, persons with vision loss cannot make use of these visual cues, and have a harder time understanding speech, especially in noisy environments.  Furthermore, people with normal vision can use visual information to identify a speaker in a group, which allows them to focus on this person.  This can greatly benefit a person with hearing loss who may be using a device such as a sound amplifier or a hearing aid.  A user with vision loss, however, needs to be provided with this speaker information to make optimal use of such devices.  We propose developing a prototype device that will clean the speech signal from a target speaker and improve speech comprehension for persons with hearing and vision loss in everyday situations.  In order to accomplish this task, we need to harness the visual cues that have so far largely been ignored in the design of assistive technolo- gies for persons with hearing loss.  Our first aim is to learn speaker-independent visual cues that are associated with the target speech signal, and use these audio-visual cues to design speech enhancement algorithms that perform much better in noisy everyday environment than current methods which only utilize the audio signal.  We will utilize a video camera and computer vision methods to design advanced digital signal processing techniques to enhance the target speech signals recorded through a microphone.  Our second aim is to use the video and audio signals to detect and efficiently localize the visible speaker.  The information regarding the location of the speaker of interest can then be used to efficiently perform speaker separation, as well as be provided to the user.  Finally, we aim to implement these developed algorithms on a portable prototype system.  We will test the performance of this system and improve the user-interface through user experiments in real-world situations as well as laboratory conditions.  The end product will show the feasibility and importance of incorporating multiple modalities into sensory assistive devices, and set the stage for future research and development efforts.         PUBLIC HEALTH RELEVANCE:  It is estimated that by 2030, more than one in five people in the United States will be over the age of 65.  Age- related hearing and vision loss is considered a natural consequence of the aging process, yet current assistive technology approaches do little to address this type of sensory loss.  The proposed research will test the feasibility of incorporating visual information in hearing aids, which is expected to improve speech perception for persons with hearing and vision loss in everyday situations, greatly enhancing their ability to lead independent lives, remain employable, and maintain active participation in society.                ",Video-based Speech Enhancement for Persons with Vision and Hearing Loss,8443624,R21EY022200,"['Accounting', 'Acoustics', 'Activities of Daily Living', 'Address', 'Adult', 'Age', 'Age-Years', 'Aging-Related Process', 'Algorithms', 'Amplifiers', 'Area', 'Auditory', 'Blindness', 'Communication', 'Comprehension', 'Computer Vision Systems', 'Cues', 'Dependence', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Effectiveness', 'Elderly', 'Environment', 'Facial Expression', 'Feedback', 'Grant', 'Hearing Aids', 'Human', 'Laboratories', 'Lead', 'Learning', 'Life', 'Lip structure', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modality', 'Modeling', 'Noise', 'Output', 'Performance', 'Persons', 'Play', 'Population', 'Presbycusis', 'Process', 'Quality of life', 'Research', 'Role', 'Self-Help Devices', 'Sensory', 'Sensory Aids', 'Shapes', 'Signal Transduction', 'Societies', 'Source', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Staging', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Vision', 'Visual', 'Visual impairment', 'Voice', 'base', 'computerized data processing', 'design', 'hearing impairment', 'improved', 'interest', 'novel strategies', 'performance tests', 'prototype', 'public health relevance', 'research study', 'social', 'sound', 'speech recognition', 'tool development', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2013,198801,0.10078190692837499
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics   Project Summary  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment.   In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8514562,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'Sequence Analysis', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'screening', 'software systems', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2013,588237,0.16059646418422008
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics   Project Summary  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment.   In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8336850,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Screening procedure', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'Sequence Analysis', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'software systems', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2012,637782,0.16059646418422008
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics     DESCRIPTION (provided by applicant):  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment.        PUBLIC HEALTH RELEVANCE:  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.                   In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.                ",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8224101,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Screening procedure', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'Sequence Analysis', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'software systems', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2011,608130,0.153121840185992
"Computational Methods for Analysis of Mouth Shapes in Sign Languages    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hand) and by the nonmanual components (the face). These facial articulations perform significant semantic, prosodic, pragmatic, and syntactic functions. This proposal will systematically study mouth positions in ASL. Our hypothesis is that ASL mouth positions are more extensive than those used in speech. To study this hypothesis, this project is divided into three aims. In our first aim, we hypothesize that mouth positions are fundamental for the understanding of signs produced in context because they are very distinct from signs seen in isolation. To study this we have recently collected a database of ASL sentences and nonmanuals in over 3600 video clips from 20 Deaf native signers. Our experiments will use this database to identify potential mappings from visual to linguistic features. To successfully do this, our second aim is to design a set of shape analysis and discriminant analysis algorithms that can efficiently analyze the large number of frames in these video clips. The goal is to define a linguistically useful model, i.e., the smallest model that contains the main visual features from which further predictions can be made. Then, in our third aim, we will explore the hypothesis that the linguistically distinct mouth positions are also visually distinct. In particular, we will use the algorithms defined in the second aim to determine if distinct visual features are used to define different linguistic categories. This result will show whether linguistically meaningful mouth positions are not only necessary in ASL (as hypothesized in aim 1), but whether they are defined using non-overlapping visual features (as hypothesized in aim 3). These aims address a critical need. At present, the study of nonmanuals must be carried out manually, that is, the shape and position of each facial feature in each frame must be recorded by hand. Furthermore, to be able to draw conclusive results for the design of a linguistic model, it is necessary to study many video sequences of related sentences as produced by different signers. It has thus proven nearly impossible to continue this research manually. The algorithms designed in the course of this grant will facilitate this analysis of ASL nonmanuals and lead to better teaching materials.      PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.           Project Narrative Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for Analysis of Mouth Shapes in Sign Languages,8109271,R21DC011081,"['Academic achievement', 'Access to Information', 'Address', 'Adult', 'Algorithms', 'Applications Grants', 'Categories', 'Child', 'Clip', 'Communication', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Databases', 'Devices', 'Discriminant Analysis', 'Educational process of instructing', 'Emotions', 'Excision', 'Eye', 'Face', 'Funding', 'Goals', 'Grant', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Joints', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Manuals', 'Modeling', 'Oral cavity', 'Parents', 'Pattern Recognition', 'Positioning Attribute', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Shapes', 'Sign Language', 'Social Interaction', 'Specific qualifier value', 'Speech', 'Teaching Materials', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visual', 'Work', 'computerized tools', 'deafness', 'design', 'experience', 'innovation', 'instructor', 'interest', 'novel', 'prevent', 'public health relevance', 'research study', 'shape analysis', 'success', 'syntax', 'teacher', 'tool', 'visual map']",NIDCD,OHIO STATE UNIVERSITY,R21,2011,205267,0.06754823194999891
"Computational Methods for Analysis of Mouth Shapes in Sign Languages    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hand) and by the nonmanual components (the face). These facial articulations perform significant semantic, prosodic, pragmatic, and syntactic functions. This proposal will systematically study mouth positions in ASL. Our hypothesis is that ASL mouth positions are more extensive than those used in speech. To study this hypothesis, this project is divided into three aims. In our first aim, we hypothesize that mouth positions are fundamental for the understanding of signs produced in context because they are very distinct from signs seen in isolation. To study this we have recently collected a database of ASL sentences and nonmanuals in over 3600 video clips from 20 Deaf native signers. Our experiments will use this database to identify potential mappings from visual to linguistic features. To successfully do this, our second aim is to design a set of shape analysis and discriminant analysis algorithms that can efficiently analyze the large number of frames in these video clips. The goal is to define a linguistically useful model, i.e., the smallest model that contains the main visual features from which further predictions can be made. Then, in our third aim, we will explore the hypothesis that the linguistically distinct mouth positions are also visually distinct. In particular, we will use the algorithms defined in the second aim to determine if distinct visual features are used to define different linguistic categories. This result will show whether linguistically meaningful mouth positions are not only necessary in ASL (as hypothesized in aim 1), but whether they are defined using non-overlapping visual features (as hypothesized in aim 3). These aims address a critical need. At present, the study of nonmanuals must be carried out manually, that is, the shape and position of each facial feature in each frame must be recorded by hand. Furthermore, to be able to draw conclusive results for the design of a linguistic model, it is necessary to study many video sequences of related sentences as produced by different signers. It has thus proven nearly impossible to continue this research manually. The algorithms designed in the course of this grant will facilitate this analysis of ASL nonmanuals and lead to better teaching materials.      PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.           Project Narrative Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for Analysis of Mouth Shapes in Sign Languages,8101448,R21DC011081,"['Academic achievement', 'Access to Information', 'Address', 'Adult', 'Algorithms', 'Applications Grants', 'Arts', 'Categories', 'Child', 'Clip', 'Communication', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Databases', 'Devices', 'Discriminant Analysis', 'Educational process of instructing', 'Emotions', 'Excision', 'Eye', 'Face', 'Funding', 'Goals', 'Grant', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Joints', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Manuals', 'Modeling', 'Oral cavity', 'Parents', 'Pattern Recognition', 'Positioning Attribute', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Shapes', 'Sign Language', 'Social Interaction', 'Specific qualifier value', 'Speech', 'Teaching Materials', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visual', 'Work', 'computerized tools', 'deafness', 'design', 'experience', 'innovation', 'instructor', 'interest', 'novel', 'prevent', 'public health relevance', 'research study', 'shape analysis', 'success', 'syntax', 'teacher', 'tool', 'visual map']",NIDCD,OHIO STATE UNIVERSITY,R21,2010,187999,0.06754823194999891
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6985366,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2006,183324,0.07574502722892414
"Neural network model of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using radial basis function neural network (RBFNN) that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The RBFNN model will be fed training data from our existing database (chinchilla) consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals. Once trained, the model will be able to predict the auditory consequences of exposure to any noise environment characterized by ten noise metrics and five biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/histological data are available (Year 2). The training period will be an iterative process in which the RBFNN will be modified as training proceeds. The prediction model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a RBFNN to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Neural network model of noise-induced hearing loss,6941215,R03OH008175,"['artificial intelligence', 'chinchilla', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'disease /disorder model', 'environmental exposure', 'model design /development', 'noise biological effect', 'noise induced deafness']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R03,2005,71735,0.12935890155261173
"Model for prediction of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using a statistical learning machine (SLM), which includes an artificial neural network (ANN), a support vector machine (SVM), and a hybrid of ANN and SVM, that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The SLM model will be fed training data from our existing database consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals.  Once trained, the SLM model will be able to predict the auditory consequences of exposure to any noise environment characterized by the noise metrics and biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/ histological data are available (Year 2). The training period will be an iterative process in which the SLM will be modified as training proceeds. The predictions of the SLM model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a statistical learning machine to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Model for prediction of noise-induced hearing loss,6878561,R01OH007801,"['chinchilla', 'computational neuroscience', 'computer program /software', 'computer system design /evaluation', 'mathematical model', 'model design /development', 'noise induced deafness', 'noise pollution']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R01,2005,139799,0.12716333369195207
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6850297,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2005,172385,0.07574502722892414
"Neural network model of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using radial basis function neural network (RBFNN) that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The RBFNN model will be fed training data from our existing database (chinchilla) consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals. Once trained, the model will be able to predict the auditory consequences of exposure to any noise environment characterized by ten noise metrics and five biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/histological data are available (Year 2). The training period will be an iterative process in which the RBFNN will be modified as training proceeds. The prediction model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a RBFNN to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Neural network model of noise-induced hearing loss,6820323,R03OH008175,"['artificial intelligence', 'chinchilla', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'disease /disorder model', 'environmental exposure', 'model design /development', 'noise biological effect', 'noise induced deafness']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R03,2004,71000,0.12935890155261173
"Model for prediction of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using a statistical learning machine (SLM), which includes an artificial neural network (ANN), a support vector machine (SVM), and a hybrid of ANN and SVM, that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The SLM model will be fed training data from our existing database consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals.  Once trained, the SLM model will be able to predict the auditory consequences of exposure to any noise environment characterized by the noise metrics and biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/ histological data are available (Year 2). The training period will be an iterative process in which the SLM will be modified as training proceeds. The predictions of the SLM model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a statistical learning machine to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Model for prediction of noise-induced hearing loss,6753927,R01OH007801,"['chinchilla', 'computational neuroscience', 'computer program /software', 'computer system design /evaluation', 'mathematical model', 'model design /development', 'noise induced deafness', 'noise pollution']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R01,2004,138439,0.12716333369195207
"Narrow-Band Active Noise Reduction for DPOAE Measurement DESCRIPTION (provided by applicant): The aim of this project is to enable accurate acquisition of distortion product otoacoustic emission (DPOAE) measurements in relatively high noise environments for use in hearing evaluations and screening. DPOAE measurements have been shown to be an effective and efficient method for screening infant, children, and adult hearing. Environmental noise, however, has been shown to adversely affect the ability to successfully obtain DPOAE measurements, especially at frequencies below 1500 Hz.  We will achieve our aim by developing a narrow-band, adaptive active noise reduction system that will seamlessly augment existing DPOAE measurement protocols. Our innovation will supplement existing DPOAE measurement systems with both low-cost acoustic hardware and advanced signal processing techniques. By reducing background noise levels in a narrow frequency band near the DPOAE test frequencies, we will enable higher signal-to-noise ratio DPOAE measurement sequences. The increased SNR will result in the ability to obtain DPOAE measurements in relatively high noise environments such as the newborn intensive care unit and nursery, offices of pediatricians, schools without special audiology facilities, field hospitals, and remote or mobile clinics. n/a",Narrow-Band Active Noise Reduction for DPOAE Measurement,6485483,R43DC005112,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' clinical research', ' computer program /software', ' hearing tests', ' human subject', ' measurement', ' noise', ' otoacoustic emission', ' sound frequency']",NIDCD,"CREARE, INC.",R43,2002,103954,0.10114211925818901
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,9831633,R01DC012048,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'American', 'Auditory', 'Auditory Prosthesis', 'Chronic', 'Complex', 'Data', 'Environment', 'Formulation', 'Frequencies', 'Goals', 'Hearing', 'Hearing Aids', 'Individual', 'Investigation', 'Laboratories', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neural Network Simulation', 'Noise', 'Recurrence', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Intelligibility', 'Structure', 'Supervision', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'combat', 'deep learning', 'deep neural network', 'design', 'digital', 'experimental study', 'hearing impairment', 'improved', 'innovation', 'microphone', 'network architecture', 'normal hearing', 'real world application', 'segregation', 'signal processing', 'sound', 'speech in noise', 'success', 'supervised learning']",NIDCD,OHIO STATE UNIVERSITY,R01,2020,303452,0.043002042902079825
"Real-time deep learning to improve speech intelligibility in noise Project Summary/Abstract  One in eight Americans has hearing loss, and this constitutes a major health and economic burden (Blackwell et al., 2014). The primary complaint of hearing-impaired (HI) listeners is difficulty understanding speech when background noise is present (see Dillon, 2012). While hearing aids (HAs) have improved in recent years, they still provide little benefit in noisy environments. For decades, a means of improving the ability to understand speech in background noise appeared unattainable, despite substantial amounts of research by both universities and HA companies. This changed when deep learning provided the first demonstration of a single-microphone algorithm that improves intelligibly in noise for HI listeners (Healy et al., 2013, 2014, 2015). Although this algorithm provides massive intelligibility improvements (even allowing listeners to improve intelligibility from floor to ceiling levels), it is currently not implemented to operate in real time and is therefore not suitable for implementation into HAs and cochlear implants (CIs). What is needed, therefore, is a highly effective noise-reduction algorithm that is capable of operating in real time. This project aims to address this critical need.  The long-term goal of the currently proposed project is to alleviate HI listeners’ predominant hearing handicap, which is difficulty understanding speech in background noise. The first aim introduces a new algorithm, based on a novel foundational scheme, that is designed to provide substantial benefit for any HI listener in real time. This algorithm will be well suited for implementation into HAs, CIs, and other face-to-face communication applications. The effectiveness of this new algorithm will be quantified using both HI and normal-hearing (NH) listeners. The second aim expands upon this new algorithm by modifying it to accept a small amount of future time-frame information, which could improve its noise-reduction performance but will introduce a brief processing delay. The rationale is that different devices have different allowable latencies. Face-to-face communication devices (HAs, CIs, etc.) have strict low-latency requirements, but other important communication systems (e.g., telephones) have different requirements. It is possible that the addition of future time-frame information within these requirements (up to 150 ms) will result in even better speech intelligibility. But the magnitude of any potential benefit is unknown. This critical information will be established currently. Using both HI and NH listeners, we will measure intelligibility for noisy sentences that have been processed using various amounts of future time information.  This comprehensive fellowship training plan will provide individualized, mentored research training from world-class faculty in a highly supportive and productive environment. The proposed work will endow the applicant with the skills needed to transition to the next stage of his research career, transform our treatment of hearing loss, and substantially impact quality of life for millions of Americans. Project Narrative An estimated 37.5 million Americans have hearing loss, which commonly leads to difficulty understanding speech in background noise. The proposed study will test a new noise-reduction system and improve our treatment of hearing loss.",Real-time deep learning to improve speech intelligibility in noise,10155960,F32DC019314,"['Address', 'Algorithms', 'American', 'Area', 'Auditory', 'Cellular Phone', 'Characteristics', 'Cochlear Implants', 'Communication', 'Complex', 'Data', 'Devices', 'Diagnosis', 'Economic Burden', 'Effectiveness', 'Environment', 'Equilibrium', 'Etiology', 'Faculty', 'Fellowship', 'Floor', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hearing', 'Hearing Aids', 'Human', 'Implant', 'Measures', 'Mentors', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Performance', 'Phase', 'Prevention', 'Process', 'Quality of life', 'Recommendation', 'Research', 'Research Personnel', 'Research Training', 'Scheme', 'Seminal', 'Signal Transduction', 'Speech', 'Speech Intelligibility', 'Strategic Planning', 'System', 'Telephone', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Videoconferencing', 'Work', 'artificial neural network', 'base', 'career', 'communication device', 'deep learning', 'deep neural network', 'design', 'experimental study', 'health economics', 'hearing impairment', 'hearing loss treatment', 'improved', 'microphone', 'network architecture', 'neural network', 'normal hearing', 'novel', 'novel strategies', 'operation', 'skills', 'speech in noise', 'wearable device']",NIDCD,OHIO STATE UNIVERSITY,F32,2020,76840,0.11176083946067647
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9820729,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Auditory Threshold', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic Diseases', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Tests', 'Heritability', 'Human', 'Infrastructure', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical implementation', 'clinical phenotype', 'clinically significant', 'cohort', 'deaf', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'genetic testing', 'hard of hearing', 'hearing impairment', 'hearing loss phenotype', 'hearing preservation', 'hereditary hearing loss', 'improved', 'in silico', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'precision genetics', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'support vector machine', 'tool', 'treatment guidelines']",NIDCD,UNIVERSITY OF IOWA,R01,2020,508845,0.25795196794868924
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology Project Summary Listening in noise is a core problem in everyday hearing. Sound sources of interest routinely occur amid irrelevant distractors, as when you talk with someone in a bustling coffee shop. This background “noise” distorts the pattern of spikes in the auditory nerve, often to a profound degree. Thus, to recognize sources of interest, the auditory system must somehow separate or suppress the effects of the background. Typical human hearing is remarkably noise-robust, but listeners with age-related hearing loss or other forms of impaired hearing struggle in noisy environments – and are not much helped by contemporary hearing aids. Previous work on the neural basis of noise robustness has typically employed simple, synthetic noise sources, which lack the structure present in real-world sounds, and this work has focused on subcortical regions or on primary auditory cortex. Reasoning that real-world conditions might necessitate more complicated solutions, in the applicant's doctoral work, he considered everyday sources of noise, and leveraged the large-scale coverage afforded by fMRI to examine noise robustness throughout human auditory cortex. Real-world “background noise” was operationalized as a natural sound with statistical properties that are stable over time (i.e., are stationary), conveying little new information about the world (e.g., swamp insects, an air conditioner, rain on pavement). The applicant measured fMRI responses in human listeners to a broad set of natural sounds presented in quiet, as well as embedded in the real-world background noises. Primary auditory cortical responses were substantially altered by the background, but non-primary responses were substantially more robust. This effect was not seen for simple synthetic backgrounds as had been used in previous work, suggesting that becoming robust to real-world background noises require different mechanisms. The applicant's thesis work demonstrates where noise invariance arises, but understanding how will require data with finer spatial and temporal resolution, and thus the proposed postdoctoral research will consist of training in single-unit electrophysiology using marmosets. Aim 1A builds on previous work examining single- unit noise robustness in artificial conditions, extending such work to real-world noise. Aim 1B leverages texture models to probe what aspects of real-world backgrounds disrupt the encoding of foregrounds. Aim 2A deploys linear reconstruction techniques to probe population representations. Aim 2B involves optimizing deep neural networks for noise invariance tasks, and using them as an encoding model to predict single-unit responses. Furthermore, such networks will be deployed as nonlinear decoding algorithms, reconstructing stimuli from neuronal populations. Throughout all aims, the work will characterize neuronal responses in non-primary areas, and in particular in parabelt, which is understudied in primates. The proposed work may enable improvements in hearing aid algorithms or neural prosthetics. Lastly, this training will lay the groundwork for the applicant's long-term goal of developing a marmoset model for hearing loss. Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,10104430,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Quality of life', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'algorithm training', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2020,64926,0.1832092985119894
"Computational Cognitive Neuroscience of Human Auditory Cortex PROJECT SUMMARY Humans with normal hearing excel at deriving information about the world from sound. Our auditory abilities represent stunning computational feats that only recently have been replicated to any extent in machine systems. And yet our auditory abilities are highly vulnerable, being greatly compromised in listeners with hearing impairment, cochlear implants, and auditory neurodevelopmental disorders, particularly in the presence of noise. Difficulties in recognition often lead to frustration and social isolation, and are not adequately addressed by current hearing aids, implants, and remediation strategies. The long-term goal of the proposed research is to reveal the basis of auditory recognition and to provide insights that will facilitate improved prosthetic devices and therapeutic interventions. The development of more effective devices and therapies is currently limited by an incomplete understanding of the factors that underlie real-world recognition by normal-hearing listeners. In particular, although responses to sound in subcortical auditory pathways are relatively well studied, little is known about the transformations that occur within the auditory cortex to create representations of meaningful sound structure. We propose to enrich the understanding of auditory recognition with three sets of experiments that examine the cortical representation of real-world sounds in human listeners, combining functional magnetic resonance imaging (fMRI) with computational modeling of the underlying representations. Aim 1 develops artificial neural network models of speech and music processing and compares their representations to those in the auditory cortex, synthesizing and then measuring brain responses to sounds that generate the same response in a model, and probing the time scale of the auditory analysis of speech and music. Aim 2 develops and tests models of pitch perception in noise, exploring the hypothesis that pitch perception is constrained both by the statistics of natural sounds and the frequency selectivity of the cochlea. Aim 3 develops and tests models that jointly localize and recognize sounds, and probes the brain representations of sound identity and location using fMRI. The results will reveal the mechanisms underlying robust sound recognition by the healthy auditory system and will set the stage for investigations of the cortical consequences of hearing impairment and auditory developmental disorders, hopefully suggesting new strategies for remediation. PROJECT NARRATIVE: People with normal hearing are typically able to recognize, understand and localize sounds of interest, but this ability is often compromised in listeners with hearing disorders. The proposed research will enrich the understanding of the neural mechanisms underlying auditory recognition and localization in normal listeners. The results will likely provide insight into the brain processes whose alteration in hearing disorders underlies listening difficulties, potentially leading to improved remediation strategies.",Computational Cognitive Neuroscience of Human Auditory Cortex,9944496,R01DC017970,"['Address', 'Adopted', 'Auditory', 'Auditory Perception', 'Auditory area', 'Auditory system', 'Behavioral', 'Biological Assay', 'Brain', 'Brain region', 'Characteristics', 'Child', 'Cochlea', 'Cochlear Implants', 'Computer Models', 'Data', 'Development', 'Devices', 'Drops', 'Ear', 'Floor', 'Frequencies', 'Frustration', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing Aids', 'Hearing Tests', 'Hearing problem', 'Human', 'Implant', 'Investigation', 'Lead', 'Location', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Noise', 'Pathway interactions', 'Peripheral', 'Persons', 'Pitch Perception', 'Population', 'Process', 'Property', 'Prosthesis', 'Psychophysics', 'Research', 'Rest', 'Social isolation', 'Sound Localization', 'Source', 'Speech', 'Stimulus', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Visual Pathways', 'artificial neural network', 'auditory pathway', 'cognitive neuroscience', 'computational basis', 'deep learning', 'deep neural network', 'developmental disease', 'experimental study', 'hearing impairment', 'improved', 'insight', 'interest', 'network architecture', 'neural network', 'neuromechanism', 'neurophysiology', 'normal hearing', 'novel', 'relating to nervous system', 'remediation', 'response', 'sound', 'sound frequency', 'speech processing', 'statistics']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,337875,0.1266023978469382
"Tinnitus: Audiological measures and genetic susceptibility PROJECT SUMMARY/ABSTRACT Tinnitus, the phantom perception of sound in absence of an external sound source, is a prevalent hearing disorder. To date, the exact neural and molecular mechanisms underlying tinnitus are not known. Tinnitus is associated with a number of otological diseases and clinical conditions; however, almost 50% of tinnitus cases are not attributable to any known cause (Stouffer & Tyler, 1990). There is likely a genetic component to tinnitus (Sand et al, 2007). A critical gap in the knowledge base is how to clinically identify those who are genetically predisposed to tinnitus well before they acquire this hearing health issue. The short-term goal of this R21 Early Career Research PAR 16-057 application, entitled “Tinnitus: Audiological measures and genetic susceptibility,” is to identify detailed phenotypic and genotypic profiles of chronic tinnitus in young adults. The application is proposed by a team of researchers: The PI is Ishan Bhatt, Ph.D. in audiology (CCC-A, FAAA), who is working with Co-PI’s Jason Wilder, Ph.D. in genetics, Jin Wang, Ph.D. in statistics, and Raquel Dias, Ph.D. in Bioinformatics. This project will fill the gap in knowledge by identifying the critical variables associated with a genetic predisposition to CT. This investigation will include college-aged young participants to control for age- related confounding variables such as systemic diseases and hearing loss. According to the PI’s pilot study (Bhatt, 2017a), the estimated prevalence of chronic tinnitus (CT), acute tinnitus (AT) and no tinnitus (NT) is around 8%, 13% and 79%, respectively. To accomplish our short-term goal, we will conduct a case-control- control exonic genome-wide association study (GWAS) (N = 300) in which subjects will be divided into three groups: those with (1) CT (tinnitus for > 1 year; n=100), (2) AT (tinnitus for ≤ 1 year, presumably due to acute environmental exposure; n=100); and (3) NT (no experience of tinnitus in a lifetime; n=100). The Specific Aims are: (1) to identify associations between exonic Single Nucleotide Polymorhisms (SNPs) and tinnitus phenotype. Based on the criteria laid out in the preliminary studies (Bhatt, 2017a; Bhatt et al., 2016; Phillip et al., 2015), our working hypothesis is that causal SNPs will exhibit a higher frequency of a specific genotype for subjects with CT compared to subjects with AT and NT. (2) To identify association between selected SNPs in a candidate set of genes and audiologic measures among subjects with CT, AT and NT, Based on our preliminary studies (Bhatt et al., 2016, Phillips et al., 2015), our working hypothesis is that subjects with causal alleles for CT will exhibit pathophysiological variation in the audiometric measures. Significance: Successful completion of this project will enable us to identify phenotypic and genotypic profiles of CT. This will help us to achieve our long term goal, which is to develop a genetic Risk Profile that can be used by health-care providers, and educators (e.g., health professionals, music and industrial arts teachers) to identify individuals genetically at risk for CT. Project Narrative Tinnitus, the phantom perception of sound in absence of an external sound source, is a prevalent hearing disorder. The short-term goal of this study is to identify detailed phenotypic and genotypic profiles of chronic tinnitus in college-aged young adults. The relevance of the project to public health is reflected in the long-term goal, which is to construct a genetic risk profile which can be used by health-care providers and educators to identify individuals genetically at risk for chronic tinnitus.",Tinnitus: Audiological measures and genetic susceptibility,9824578,R21DC016704,"['Acute', 'Address', 'Adolescent', 'Age', 'Aging', 'American', 'Anxiety', 'Audiology', 'Auditory Evoked Potentials', 'Auditory Perception', 'Bioinformatics', 'Candidate Disease Gene', 'Characteristics', 'Chronic', 'Clinical', 'Complex', 'Confounding Factors (Epidemiology)', 'Development', 'Disease', 'Doctor of Philosophy', 'Education', 'Environmental Exposure', 'Environmental Risk Factor', 'Ethnic Origin', 'Exhibits', 'Exposure to', 'Family', 'Financial compensation', 'Frequencies', 'General Population', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic study', 'Genotype', 'Goals', 'Health', 'Health Personnel', 'Health Policy', 'Health Professional', 'Hearing', 'Hearing problem', 'Human', 'Hyperacusis', 'Impaired cognition', 'Individual', 'Industrial Arts', 'Investigation', 'Knowledge', 'Machine Learning', 'Measures', 'Mental Depression', 'Military Personnel', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Music', 'Noise', 'Nucleotides', 'Otitis Media', 'PTGS1 gene', 'PTGS2 gene', 'Participant', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physiological', 'Pilot Projects', 'Policy Maker', 'Population', 'Predisposition', 'Prevalence', 'Prevention strategy', 'Preventive Intervention', 'Prostaglandin-Endoperoxide Synthase', 'Public Health', 'Quality of life', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Sampling', 'Serotonin', 'Silicon Dioxide', 'Sleeplessness', 'Smoking', 'Sodium', 'Source', 'Systemic disease', 'Testing', 'Tinnitus', 'Variant', 'Veterans', 'age related', 'aged', 'aging population', 'base', 'career', 'case control', 'causal variant', 'clinical development', 'college', 'experience', 'gene environment interaction', 'genetic association', 'genetic testing', 'genetic variant', 'genome wide association study', 'hearing impairment', 'individualized medicine', 'innovation', 'insight', 'knowledge base', 'learning strategy', 'novel', 'otoacoustic emission', 'relating to nervous system', 'serotonin receptor', 'serotonin transporter', 'sound', 'statistics', 'teacher', 'trait', 'treatment strategy', 'voltage gated channel', 'young adult']",NIDCD,NORTHERN ARIZONA UNIVERSITY,R21,2020,151994,0.062141817174046494
