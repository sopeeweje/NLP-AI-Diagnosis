text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Human Face Representation in Deep Convolutional Neural Networks The human visual system can recognize a familiar face across wide variations of viewpoint, illumination, expression, and appearance. This remarkable computational feat is accomplished by large-­scale networks of neurons. We will test a face space theory of the representations that emerge at the top layer of deep learning convolutional neural networks (DCNNs) as a model of human visual representations of faces. Computer-based face recognition has improved in recent years due to DCNNs and the easy availability of labeled training data (faces and identities) from the web. Inspired by the primate visual system, DCNNs are feed­forward artificial neural networks that can map images of faces into representations that support recognition over widely variable images. Although the calculations executed by the simulated neurons are simple, enormous numbers of computations are used to convert an image into a representation. The end result of this processing is a highly compact representation of a face that retains image detail in an invariant, identity­-specific face code. This code is fundamentally different than any representation of faces considered in vision science. This theory we test combines key components of previous face space models (similarity, learning history) with new features (imaging conditions, personal face history) in a unitary space that represents both identity and facial appearance across variable images. We will test whether this model can account for human recognition of familiar faces, which is highly robust to image variability (pose, illumination, expression). The model will also be applied to understanding long standing difficulties humans (and machines) have with faces of other races. We aim to bridge critical gaps in our knowledge of how DCNNs work, linking psychological, neural, and computational perspectives. A fundamentally new theory of face representation will alter the questions we ask about face representations in all three fields. A new focus on understanding how we (or neural networks) “perceive” a single familiar identity in widely variable images will give rise to a search for representations that gracefully merge the properties of faces with the real-­world image conditions in which they are experienced. This project presents a unique opportunity to study, manipulate, and learn from these representations, and to apply the findings to broader questions about high-­level vision from neural and perceptual perspectives. Human recognition of familiar faces is highly robust to image variability (pose, illumination, expression)—a skill that is likely due to the quality and quantity of experience we have with the faces of people we know well. Deep convolutional neural networks are modeled after the primate visual system and have made impressive gains recently on the problem of robust face recognition. Understanding the visual nature of the face “feature” codes that emerge in these networks can give insight into long-standing questions about how the human visual system can, but does not always, represent a face in a way that generalizes across images that vary widely.",Human Face Representation in Deep Convolutional Neural Networks,10129967,R01EY029692,"['Affect', 'Appearance', 'Categories', 'Code', 'Computers', 'Data', 'Data Set', 'Face', 'Face Processing', 'Familiarity', 'Human', 'Image', 'Individual', 'Internet', 'Knowledge', 'Label', 'Learning', 'Lighting', 'Link', 'Maps', 'Methods', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurons', 'Performance', 'Persons', 'Primates', 'Property', 'Published Comment', 'Race', 'Recording of previous events', 'Space Models', 'Testing', 'Training', 'Variant', 'Vision', 'Visual', 'Visual system structure', 'Work', 'artificial neural network', 'base', 'convolutional neural network', 'deep learning', 'experience', 'feedforward neural network', 'human model', 'improved', 'insight', 'neural network', 'psychologic', 'relating to nervous system', 'representation theory', 'skills', 'theories', 'vision science']",NEI,UNIVERSITY OF TEXAS DALLAS,R01,2021,361998
"Shared and specific mechanisms of auditory and visual category learning PROJECT SUMMARY/ABSTRACT The ability to learn new perceptual categories enables some of the most complex human behaviors, from speech perception to visual object recognition. Current understanding of the mechanisms involved in perceptual category learning relies on the fundamental assumption that the processes underlying such learning are shared across the senses. However, the vast majority of this work has focused on the visual modality. As a consequence, the research regarding how humans learn to group complex auditory information into categories has relied greatly on conclusions from the research in the visual domain without testing this critical assumption. However, recent evidence from the attention literature suggests that even seemingly domain-general cognitive processes, such as working memory, are accomplished via sensory-biased regions in frontal cortex. The current investigation will directly compare the computational and neural mechanisms supporting auditory and visual category learning by training the same individuals on categories in both modalities while in an fMRI scanner. Aim #1 of this investigation will identify the shared and sensory-biased circuits supporting feedback processing during auditory and visual category learning. If the neural circuits supporting perceptual category learning are shared across the modalities, it is expected that similar regions will be recruited to a similar extent during feedback processing. If instead, the neural circuits are distinct for particular modalities, it is expected that sensory-biased regions will emerge as supporting category learning for auditory and visual modalities. Aim #2 will utilize advanced machine learning techniques (multivariate pattern classification and representational similarity analyses) to characterize the emergence of category-level neural representations over the course of learning. Aim #3 will identify the functional and structural connectivity of the circuits as they contribute to perceptual category learning. The proposed research will directly test the fundamental assumption about the nature of this complex problem that affects everyday behaviors. This research has the potential to impact understanding of cases where modality- specific learning abilities might be impaired, such as phonetic learning and language-related impairments in dyslexia, autism, and specific language impairment. The proposed research will provide the training foundation to support the PI’s long-term objective of developing theories of perceptual category learning that are constrained by neurobiology and behavior and will specify the behavioral, computational, and neural mechanisms of such learning. This project presents the opportunity to directly test a critical assumption underlying understanding of perceptual category learning. The proposed research will take place in an exceptional training environment and the PI will be mentored by a team of knowledgeable and accomplished scientists. The research will provide the PI with training in functional magnetic resonance experiment design and analysis which will prepare her well for a career as an independent scientist in computational cognitive neuroscience. PROJECT NARRATIVE The proposed research will contribute to fundamental knowledge about how seemingly general-purpose cognitive systems may demonstrate modality specificity. The goal of this investigation is to characterize the differences in cognitive processing during category learning when the information comes from the auditory or visual modalities. The findings from this work may inform mechanistic approaches to understanding modality- specific deficits in language-based disorders, such as dyslexia, autism, and specific language impairment.",Shared and specific mechanisms of auditory and visual category learning,10197776,F32DC018979,"['Affect', 'Area', 'Attention', 'Auditory', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Corpus striatum structure', 'Disease', 'Dyslexia', 'Environment', 'Esters', 'Feedback', 'Finches', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hobbies', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Magnetic Resonance', 'Mentors', 'Modality', 'Modeling', 'Nature', 'Neurobiology', 'Participant', 'Pattern', 'Process', 'Property', 'Research', 'Scientist', 'Sensory', 'Short-Term Memory', 'Specific qualifier value', 'Specificity', 'Speech', 'Speech Perception', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Training', 'Visual', 'Work', 'auditory stimulus', 'autism spectrum disorder', 'base', 'behavior measurement', 'career', 'cognitive neuroscience', 'cognitive process', 'cognitive system', 'design', 'experimental study', 'frontal lobe', 'individual variation', 'innovation', 'learning ability', 'neural circuit', 'neuromechanism', 'object recognition', 'programs', 'recruit', 'relating to nervous system', 'response', 'sound', 'specific language impairment', 'theories', 'visual learning']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F32,2021,65994
"Cortical computations underlying binocular motion integration PROJECT SUMMARY / ABSTRACT Neuroscience is highly specialized—even visual submodalities such as motion, depth, form and color processing are often studied in isolation. One disadvantage of this isolation is that results from each subfield are not brought together to constrain common underlying neural circuitry. Yet, to understand the cortical computations that support vision, it is important to unify our fragmentary models that capture isolated insights across visual submodalities so that all relevant experimental and theoretical efforts can benefit from the most powerful and robust models that can be achieved. This proposal aims to take the first concrete step in that direction by unifying models of direction selectivity, binocular disparity selectivity and 3D motion selectivity (also known as motion-in-depth) to reveal circuits and understand computations from V1 to area MT. Motion in 3D inherently bridges visual submodalities, necessitating the integration of motion and binocular processing, and we are motivated by two recent paradigm-breaking physiological studies that have shown that area MT has a robust representation of 3D motion. In Aim 1, we will create the first unified model and understanding of the relationship between pattern and 3D motion in MT. In Aim 2, we will construct the first unified model of motion and disparity processing in MT. In Aim 3, we will develop a large-scale biologically plausible model of these selectivities that represents realistic response distributions across an MT population. Having a population output that is complete enough to represent widely-used visual stimuli will amplify our ability to link to population read-out theories and to link to results from psychophysical studies of visual perception. Key elements of our approach are (1) an iterative loop between modeling and electrophysiological experiments; (2) building a set of shared models, stimuli, data and analysis tools in a cloud-based system that unifies efforts across labs, creating opportunities for deep collaboration between labs that specialize in relevant submodalities, and encouraging all interested scientists to contribute and benefit; (3) using model-driven experiments to answer open, inter-related questions that involve motion and binocular processing, including motion opponency, spatial integration, binocular integration and the timely problem of how 3D motion is represented in area MT; (4) unifying insights from filter-based models and conceptual, i.e., non-image- computable, models to generate the first large-scale spiking hierarchical circuits that predict and explain how correlated signals and noise are transformed across multiple cortical stages to carry out essential visual computations; and (5) carrying out novel simultaneous recordings across visual areas. This research also has potential long-term benefits in medicine and technology. It will build fundamental knowledge about functional cortical circuitry that someday may be useful for interpreting dysfunctions of the cortex or for helping biomedical engineers construct devices to interface to the brain. Insights gained from the visual cortex may also help to advance computer vision technology. NARRATIVE The processing of visual motion and depth information is essential for a wide variety of important human abilities, including navigating through the world, avoiding collisions, catching and grabbing objects and interpreting complex scenes. To understand how neurons in the visual cortex transform and represent the information that underlies these abilities, we aim to initiate the development of a more complete, biologically constrained and openly available computer model of motion and depth processing that will be used to guide, and to interpret and incorporate results from, primate visual neurophysiological and psychophysical experiments. Gaining an understanding of the normal function of cortical neural circuitry is an important step in building the fundamental knowledge that someday may help to improve the ability to assess dysfunctions of the cortex and may help bioengineers create devices that interface to cortical circuitry to treat disorders and overcome disabilities.",Cortical computations underlying binocular motion integration,10188534,R01EY027023,"['3-Dimensional', 'Affect', 'Architecture', 'Biological', 'Biomedical Engineering', 'Brain', 'Collaborations', 'Color', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disadvantaged', 'Discrimination', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Foundations', 'Frequencies', 'Functional disorder', 'Human', 'Joints', 'Knowledge', 'Link', 'Literature', 'Medicine', 'Modeling', 'Motion', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Pattern', 'Performance', 'Physiological', 'Physiology', 'Population', 'Primates', 'Production', 'Psychophysics', 'Reproducibility', 'Research', 'Role', 'Scientist', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Vision Disparity', 'Visual', 'Visual Cortex', 'Visual Motion', 'Visual Perception', 'area MT', 'base', 'cloud based', 'color processing', 'disability', 'experimental study', 'extrastriate visual cortex', 'fitness', 'improved', 'in vivo', 'insight', 'interest', 'neural circuit', 'neurophysiology', 'novel', 'predictive modeling', 'relating to nervous system', 'response', 'spatial integration', 'spatiotemporal', 'theories', 'tool', 'visual neuroscience', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2021,387514
"Structural and functional tests of ganglion cell damage in glaucoma This project will use a combination of structural and functional measurements to test the hypothesis that early- stage damage in human glaucoma occurs first in the inner plexiform layer (IPL) of the retina – especially its OFF sub-lamina – as suggested by murine glaucoma models. In the first Aim, we will use a novel visible-light optical coherence tomograph (VIS OCT) to study structural changes in the retina of glaucoma patients. The newly developed VIS OCT has sufficient image contrast and resolution to segment the IPL boundaries and to define sub-lamination in volumetric OCT data, something not currently possible with existing near-infrared OCT instruments. We will make comparative measurements within the IPL and between the IPL, the ganglion cell layer (GCL) and the retinal nerve fiber layer (RNFL). Because data from mouse models of glaucoma suggests that early damage occurs preferentially within the OFF sub-lamina of the IPL, we will make separate VIS OCT measurements biased for the OFF- and ON-sublaminae of the IPL and use machine learning approaches to determine whether a similar damage process can be demonstrated in human. To test whether OFF-pathway function is preferentially lost in glaucoma, we will use a novel Steady-State Visual Evoked Potential (SSVEP) paradigm that employs sawtooth increments and decrements to bias the measurement to ON vs OFF pathways, respectively, a paradigm our data suggests discriminates glaucoma from control patients. The second Aim will optimize this SSVEP measurement for testing localized areas of the visual field. The third Aim will make comparative measurements of visual-field, VIS OCT and SSVEP loss patterns in a large sample of glaucoma patients and in age- and sex-matched controls. Thickness and interface reflectivity amplitude maps derived from VIS OCT imaging of the RNFL, GCL and IPL including sublaminae will be correlated topographically with visual field defects to assess the relative sensitivity of our structural biomarkers at and near visual field locations with demonstrable losses on conventional (Humphrey) perimetry. Similarly, SSVEP responses from different locations in the visual field will be correlated topographically with visual field loss patterns and to VIS OCT losses, with special emphasis on correlating structural damage in OFF vs ON sub-laminae of the IPL with the functional correlates derived from regional decremental and incremental SSVEPs. Separately and in combination, our structural and functional measurements are designed to provide strong tests of the biological hypothesis that the OFF pathway is preferentially damaged in human glaucoma, and to reveal new biomarkers for the disease. Improving visual outcomes in glaucoma will require a better understanding of the earliest sites and processes of damage and methods to measure them quickly and accurately in patients. This project will address both needs through a combination of novel Optical Coherence Tomography and electrophysiological measurements. The new imaging and electrophysiological tests that will be developed here, either separately or together, could eventually replace conventional visual field testing which is time-consuming and unreliable.",Structural and functional tests of ganglion cell damage in glaucoma,10150874,R01EY030361,"['Address', 'Affect', 'Age', 'Animal Model', 'Area', 'Atrophic', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Clinical', 'Complex', 'Consumption', 'Data', 'Disease', 'Early Diagnosis', 'Early treatment', 'Economic Burden', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Frequencies', 'Ganglion Cell Layer', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Inner Plexiform Layer', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modification', 'Mus', 'Noise', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Perimetry', 'Process', 'Property', 'Resolution', 'Retina', 'Retinal Ganglion Cells', 'Rodent Model', 'Sampling', 'Scotoma', 'Severities', 'Signal Transduction', 'Site', 'Specificity', 'Speed', 'Structural defect', 'Structure', 'Synapses', 'Techniques', 'Testing', 'Thick', 'Time', 'Visible Radiation', 'Vision', 'Visual', 'Visual Fields', 'Visual evoked cortical potential', 'base', 'cell injury', 'comparative', 'contrast imaging', 'design', 'detection method', 'extrastriate visual cortex', 'field study', 'ganglion cell', 'improved', 'instrument', 'mouse model', 'novel', 'optic nerve disorder', 'response', 'retinal imaging', 'retinal nerve fiber layer', 'sex']",NEI,STANFORD UNIVERSITY,R01,2021,499625
"Causal role of higher-order thalamo-cortical oscillations in sustained attention PROPOSAL SUMMARY/ABSTRACT Sustained attention – the continuous allocation of cognitive resources to respond to infrequent but behaviorally relevant stimuli – is impaired in many psychiatric disorders and represents an important aspect of cognitive control. Sustained attention requires top-down control and engagement with the external world, which is linked to both frontoparietal and thalamic controlling signals on primary sensor cortices. Despite the extensive behavioral characterization of sustained attention in animal models using the five-choice serial reaction time task (5-CSRTT), very little is known about the oscillatory interaction between the dorsal attention network and thalamo-cortical dynamics and its potential as a stimulation target for enhancing sustained attention. The objective of this project is to dissect the causal role of higher-order thalamo-cortical oscillations in sustained attention via temporally-precise rhythmic stimulation. I will focus on three regions in the visual thalamo-cortical network: higher-order visual thalamus (lateral aspect of lateral posterior nucleus, LPl), posterior parietal cortex (PPC), and primary visual cortex (V1). I will test the central hypothesis that LPl-cortical theta (4-7 Hz) functional connectivity causally coordinates PPC-V1 functional connectivity to facilitate sustained attention. The rationale of this work is that the proposed temporally-precise rhythmic optogenetic perturbations will directly test the causal role of thalamo-cortical functional connectivity in sustained attention. Accordingly, the two specific aims are: (1) Delineate the functional role of higher-order thalamo-cortical oscillations in sustained attention, (2) Determine the causal role of thalamo-cortical functional connectivity in sustained attention via temporally-precise rhythmic optogenetics. This work is significant because it will causally test a convergent model in which higher-order visual thalamus coordinates the parietal top-down control signals onto visual cortex that is crucial for developing circuit- based therapies to enhance sustained attention. The work is innovative due to its integration of closed-loop optogenetics circuit interrogation, multisite electrophysiology, freely-moving sustained attention task, and machine-learning tools for the investigation of the causal role of oscillatory synchronization. The overall positive impact of the proposed study is to provide a more comprehensive map of how the higher-order visual thalamus interacts with the frontoparietal control signal to modulate V1, and thus mediates sustained attention, a transdiagnostic cognitive function that shows impairment in many psychiatric disorders including attention deficit hyperactivity disorder, bipolar disorder, and schizophrenia. The implication of this study is that it may reveal a general mechanism underlying the interaction between two higher-order processing structures signaling to lower sensory cortices during cognitive processing. PROJECT NARRATIVE Sustained attention enables us to focus our cognitive resources on an activity for a prolonged period of time, and when impaired causes profound deficits in both cognition and behavior. Sustained attention is modulated by the thalamo-cortical rhythms. The research generated in this proposal will investigate (1) what oscillatory feature in the higher-order thalamo-cortical circuit is crucial for sustained attention, and (2) how the temporally- precise enhancing or disrupting of a thalamo-cortical oscillatory feature alters the functional connectivity in the circuit and behavioral outcomes mediated by sustained attention.",Causal role of higher-order thalamo-cortical oscillations in sustained attention,10199754,F31MH118799,"['Anatomy', 'Animal Model', 'Animals', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Behavior', 'Behavioral', 'Bipolar Disorder', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communication', 'Communities', 'Computers', 'Conflict (Psychology)', 'Couples', 'Data', 'Dorsal', 'Electrophysiology (science)', 'Exhibits', 'Ferrets', 'Foundations', 'Frequencies', 'Functional disorder', 'Impairment', 'Implant', 'Impulsivity', 'Investigation', 'Lasers', 'Lateral', 'Lateral posterior nucleus of thalamus', 'Length', 'Link', 'Machine Learning', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Neurons', 'Parietal', 'Parietal Lobe', 'Performance', 'Periodicity', 'Phase', 'Physiologic pulse', 'Prefrontal Cortex', 'Process', 'Psyche structure', 'Reaction Time', 'Research', 'Resources', 'Rewards', 'Role', 'Schizophrenia', 'Signal Transduction', 'Statistical Models', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thalamic structure', 'Therapeutic', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'base', 'behavioral outcome', 'calmodulin-dependent protein kinase II', 'cognitive control', 'cognitive function', 'functional disability', 'innovation', 'neurotransmission', 'novel', 'optogenetics', 'recruit', 'relating to nervous system', 'sensor', 'sensory cortex', 'signal processing', 'sustained attention', 'theories', 'tool', 'visual stimulus']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,F31,2021,40048
"Cortical visual processing for navigation Project summary Vision plays a key role in our ability to navigate through the environment, from identifying landmarks and obstacles to determining location and heading. While studies of visual cortex have provided an understanding of properties such as orientation selectivity and object recognition, much less is known about how cortical circuitry extracts and processes features from the visual scene to support navigation. In particular, there are two challenges. First, the nature of the visual stimulus is dramatically different in navigation, where the subject's movement through the world creates a complex and dynamic visual input, in contrast to standard synthetic stimuli presented to stationary subjects. Second, the types of visual features and computations that must be performed are different in navigation than in standard detection or discrimination paradigms. Our goal in this proposal is to determine how the brain extracts relevant visual features from the rich, dynamic visual input that typiﬁes active exploration, and investigate how the neural representation of these features can support visual navigation.  We will investigate this through three parallel aims, that build up from the representation of the visual scene in V1 during freely moving navigation, to the computation of speciﬁc variables needed for navigation. In our ﬁrst aim, we will measure the visual input in freely moving mice using miniature head-mounted cameras, together with neural activity in V1, to determine how neural dynamics represent the visual scene during natural navigation. In our second aim, we will use large ﬁeld-of-view two-photon imaging of multiple cortical areas, while mice navigate in a naturalistic open-world virtual reality system, to determine how visual features are represented across visual cortical areas. In our third aim, we will use 2-photon imaging in mice in a rotational arena to determine how visual input is used to dynamically update a key navigational variable: heading direction. Together, this project bridges foundational measurements in freely moving animals with mechanistic circuit investigations, to provide insights into an important aspect of visual system function. Project Narrative This project will study how the brain processes visual information to support navigation, which is important for guiding goal-directed movement through the world. The results of this work will provide knowledge about normal visual function and insights for treating impaired vision via prosthetic or assistive devices.",Cortical visual processing for navigation,10208550,R01NS121919,"['Animals', 'Area', 'Behavior', 'Behavioral', 'Brain', 'Code', 'Complex', 'Conflict (Psychology)', 'Cues', 'Data', 'Detection', 'Discrimination', 'Electrophysiology (science)', 'Environment', 'Foundations', 'Frequencies', 'Goals', 'Head', 'Hippocampus (Brain)', 'Image', 'Investigation', 'Knowledge', 'Location', 'Measurement', 'Measures', 'Modeling', 'Motion', 'Movement', 'Mus', 'Nature', 'Neural Network Simulation', 'Play', 'Population', 'Process', 'Property', 'Prosthesis', 'Rotation', 'Sampling', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Space Models', 'Stimulus', 'Structure', 'Testing', 'Update', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Visual system structure', 'Visuospatial', 'Work', 'deep neural network', 'entorhinal cortex', 'experimental study', 'high dimensionality', 'insight', 'novel', 'object recognition', 'optic flow', 'orientation selectivity', 'relating to nervous system', 'response', 'statistics', 'synergism', 'theories', 'two-photon', 'virtual reality', 'virtual reality system', 'virtual world', 'visual information', 'visual process', 'visual processing', 'visual stimulus']",NINDS,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2021,2833387
"Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex Project Summary The use of stimuli with increasingly naturalistic properties has become critical to advance our understanding of vision. Many studies demonstrate that simple artificial stimuli (e.g. sinusoidal gratings and white noise) fail to engage nonlinearities that profoundly alter responses in the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). A recent and striking example comes from the use of naturalistic ‘flow’ stimuli, which engage robust responses in V1 that are not predicted from responses to gratings. This gap in understanding motivates the development of a stimulus ensemble and analysis framework that produces a quantitative understanding of visual processing to increasingly naturalistic stimuli and the nonlinearities that they engage. Our objective is to understand how flow stimuli are processed from retina through visual cortex. To meet this goal, we will make neural population recordings in retina (Aims 1 & 3), LGN (Aims 1 & 3) and V1 (Aim 3) using matched experimental conditions and a unified theoretical/modeling framework to map the transformations that occur across these stages of visual processing. Our central hypothesis is that V1 transforms a discrete and heavily light-level-de- pendent retinal representation of natural stimuli into a continuous (uniform) representation that is relatively in- variant to changes in the mean luminance. This invariance places a strong constraint on the class of nonlineari- ties that transform retinal responses to those observed in LGN and V1. We test this hypothesis in three aims: (1) determine early visual processing (retina & LGN) of naturalistic flow stimuli; (2) develop an encoding manifold to capture the population activity at each processing stage and transforms from one stage to the next; (3) test the ability of the manifold description to predict the impact of light adaptation on processing flow stimuli from retina to V1. Aim 1 will yield a matched experimental dataset to an interesting and novel class of ecologically-relevant stimuli. Aim 2 will yield a quantitative framework by which to understand the transformations that occur between retina, LGN, and V1. Aim 3 will provide a platform for globally perturbing the output of the retina by switching from photopic to mesopic and scotopic conditions, and thereby compare predictions of our model to measured changes in LGN and V1 activity. The primary significance of this research is that it will provide a computationally and experimentally unified framework for understanding the transformations that occur in the processing of stim- uli across multiple stages of visual processing. The major innovations are (1) presenting visual stimuli for retinal recordings that are matched to eye movements and pupil dynamics in alert animals; (2) creating a novel analysis framework that captures the responses of neurons at all three levels and the inter-level transformations to in- creasingly complex stimuli; (3) utilizing light adaptation as a method of perturbing retinal output to test our model and the stability (invariance) of LGN and V1 responses to adapting retinal signals. The expected outcome is a data-driven model of the processing from retina to LGN and V1 that generalizes from starlight to sunlight. Project Narrative Restoring vision to the blind likely requires understanding how retinal signals are communicated to the brain and how these signals are transformed in the thalamocortical pathway. This project aims to acquire an understanding of these transformations in the context of complex and more naturalistic visual stimuli.",Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex,10229447,R01EY031059,"['Affect', 'Animals', 'Brain', 'Collaborations', 'Complex', 'Cone', 'Data', 'Data Set', 'Development', 'Environment', 'Eye Movements', 'Future', 'Goals', 'Lateral Geniculate Body', 'Light', 'Light Adaptations', 'Machine Learning', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Movement', 'Mus', 'Neurons', 'Noise', 'Optics', 'Outcome', 'Output', 'Pathway interactions', 'Physiological', 'Population', 'Process', 'Property', 'Pupil', 'Research', 'Retina', 'Retinal Ganglion Cells', 'Rod', 'Signal Transduction', 'Stimulus', 'Structure', 'Sunlight', 'Techniques', 'Testing', 'Theoretical model', 'Variant', 'Vision', 'Visual Cortex', 'Visual system structure', 'Work', 'area striata', 'base', 'blind', 'cell type', 'computational neuroscience', 'experimental study', 'in vivo', 'innovation', 'luminance', 'multi-electrode arrays', 'novel', 'predictive modeling', 'receptive field', 'relating to nervous system', 'response', 'retinal neuron', 'sight restoration', 'stimulus processing', 'visual processing', 'visual stimulus']",NEI,DUKE UNIVERSITY,R01,2021,487568
"GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN PROJECT SUMMARY & ABSTRACT  Human locomotion through natural environments requires the coordination of all levels of the sensorimotor hierarchy, from the cortical areas involved in processing of visual information and high level planning to the subcortical and spinal structures involved in the regulation of the gait and posture. However, despite the complex neural bases of human locomotion, the output is highly regular and well organized around the basic physical dynamics and biomechanics that define the stability and energetic costs of moving a bipedal body through space. There is a rich and growing body of literature describing detailed knowledge each of the individual components of human locomotion, including neural mechanisms, muscular neuromechanics, and biomechanics. However, very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion through a complex and dynamic world. This lack of integrative research not only restricts the breadth of impact of research from these individual disciplines, but also limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to to fill this critical gap in our knowledge about human locomotion, it is necessary to develop an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world. In service of this general goal, this proposal outlines research projects aimed at specific unanswered questions about locomotion over different terrains. This proposal comprises three specific research and training aims on the visual control of locomotion over rough terrain. Aim 1 focuses on the behavioral task itself, Aim 2 investigates the sensory stimulus experienced during real-world locomotion, and Aim 3 examines the motor integration of visually specified goals into the ongoing gait cycle. Aim 1 investigates effects of changing environmental uncertainty and task demands on gaze allocation strategies during locomotion over real-world rough terrain. Aim 2 analyzes and models the visual stimulus experienced during locomotion over real-world rough terrain. Aim 3 determines how visually specified target footholds and targets are integrated into the ongoing preferred steady-state gait. Together these aims will significantly advance our understanding of how humans use vision to control their movement through the natural world, which greatly increase our ability to develop clinical diagnosis and treatment for loss of locomotor function. PROJECT NARRATIVE  Very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion. This lack of integrative research limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to fill this critical gap in our knowledge about human locomotion, this proposal develops an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world.",GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN,10224830,R00EY028229,"['3-Dimensional', 'Aging', 'Algorithms', 'Area', 'Attention', 'Behavior', 'Behavioral', 'Biomechanics', 'Clinical Treatment', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Development', 'Discipline', 'Environment', 'Eye', 'Gait', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Link', 'Literature', 'Locomotion', 'Measures', 'Mechanics', 'Mentors', 'Modeling', 'Motion', 'Motor', 'Movement', 'Muscle', 'Musculoskeletal', 'Nature', 'Neuromechanics', 'Output', 'Parkinson Disease', 'Pattern', 'Phase', 'Photic Stimulation', 'Positioning Attribute', 'Postdoctoral Fellow', 'Posture', 'Protocols documentation', 'Regulation', 'Research', 'Research Activity', 'Research Project Grants', 'Research Training', 'Services', 'Signal Transduction', 'Specific qualifier value', 'Spinal', 'Stroke', 'Structure', 'System', 'Training', 'Training Programs', 'Uncertainty', 'Vision', 'Visual', 'Visual Fields', 'Walking', 'Wireless Technology', 'area MST', 'area MT', 'base', 'clinical Diagnosis', 'cost', 'design', 'environmental change', 'experience', 'experimental study', 'foot', 'gaze', 'insight', 'instrument', 'kinematics', 'multidisciplinary', 'neuromechanism', 'neuromuscular', 'novel', 'optic flow', 'programs', 'relating to nervous system', 'response', 'sensory stimulus', 'skills', 'statistics', 'treadmill', 'treatment planning', 'visual control', 'visual information', 'visual processing', 'visual stimulus', 'visual-motor integration']",NEI,NORTHEASTERN UNIVERSITY,R00,2021,229062
"Early representation of 3D volumetric shape in visual object processing Project Summary The goal of this project is to test a novel theoretical framework for understanding how the ventral pathway subserves object vision. In the standard framework, a series of neural operations on 2D image data through many intermediate cortical stages, including area V4, leads to high-level perceptual representations, including representation of object identity, at the final stages of the ventral pathway. However, our preliminary microelectrode data from a fixating monkey show that many neurons in V4 represent volumetric (volume- enclosing) 3D shape, not 2D image patterns. These neurons respond to many different 2D images that convey the same 3D shape with different shape-in-depth cues, including shading, reflection, and refraction. They even respond preferentially to random dot stereograms that convey 3D volumetric shape with no 2D cues whatsoever. Moreover, our preliminary results with 2-photon functional imaging in anesthetized monkey V4 show that 3D shape signals are grouped by their similarity, and also group with isomorphic (same outline) 2D shape signals (which could contribute evidence to corresponding 3D shape inferences). We propose to capitalize on these preliminary data by demonstrating the prevalence of 3D shape tuning in area V4, analyzing the 3D shape coding strategies used by these neurons, and measuring how 2D and 3D shape signals are arranged at a microscopic level across the surface of V4. We expect these results to provide strong evidence that extraction of 3D shape fragments is a primary goal of V4 processing. This early extraction of 3D shape information, just two synapses beyond primary visual cortex, would suggest a competing framework for understanding the ventral pathway, in which the initial goal is to represent 3D physical structure, independent of the various 2D image cues used to infer it. In this framework, object recognition would be based on preceding information about 3D physical structure, which would explain why human object recognition is so robust to image changes, in a way that the best computational vision systems are not. The scientific impact of this work would be to divert vision experiments toward understanding representation of real world 3D structure (rather than 2D planar stimuli) and to encourage computational vision scientists to incorporate early 3D shape processing into the deep convolutional network models that are the current state of the art. Narrative This study will help explain how the human brain achieves such remarkably robust perception of visual objects. The results will help guide future rehabilitative and prosthetic strategies for patients with visual impairments, by elucidating neural strategies that could be used to bring computer vision prosthetics up to human performance levels, and by discovering specific neural signals for object information that could be replicated by electrode array implants in higher-level visual cortex.",Early representation of 3D volumetric shape in visual object processing,10173788,R01EY029420,"['3-Dimensional', '3D world', 'Area', 'Biological', 'Brain', 'Calcium Signaling', 'Code', 'Computer Vision Systems', 'Cues', 'Data', 'Electrodes', 'Functional Imaging', 'Future', 'Genetic Programming', 'Glass', 'Goals', 'Human', 'Image', 'Implant', 'Lead', 'Learning', 'Measures', 'Medial', 'Microelectrodes', 'Microscopic', 'Microscopy', 'Modeling', 'Monkeys', 'Network-based', 'Neurons', 'Ocular Prosthesis', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Population', 'Prevalence', 'Prosthesis', 'Rehabilitation therapy', 'Scientist', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Structure', 'Surface', 'Synapses', 'System', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'V4 neuron', 'Vision', 'Visual Cortex', 'Visual Perception', 'Visual impairment', 'Work', 'area V4', 'area striata', 'base', 'convolutional neural network', 'experimental study', 'individual response', 'network models', 'neurotransmission', 'nonhuman primate', 'novel', 'object perception', 'object recognition', 'operation', 'relating to nervous system', 'response', 'three dimensional structure', 'two-photon', 'virtual reality', 'visual object processing']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,532112
"Access to parietal action representations after stroke lesions in visual cortex PROJECT SUMMARY  The ability to recognize and use objects according to their function (e.g., fork, hammer, pencil) requires integration of visual, semantic and action knowledge across occipital, temporal and parietal areas. Left parietal regions support critical aspects of object-directed action, such as grasping and object manipulation. This research activity uses a combination of fMRI and behavioral measures in patients with ischemic strokes to early and extrastriate visual areas to test the following hypotheses: Aim 1: There is a visual pathway to the parietal grasp region (aIPS) that bypasses processing in primary visual cortex. Aim 2: Left ventral extrastriate cortex is necessary to access manipulation information for visually presented objects. Aim 3A: Ballistic grasping actions to objects in the hemianopic field are influenced by volumetric properties (size, orientation) of targets. Aim 3B: Left ventral extrastriate lesions impair object function (e.g., `scissors used to cut') and disrupt access to manipulation knowledge from visual input. The research leverages strengths of fMRI (whole brain correlational measure) and neuropsychology (causal inference) to test new hypotheses about vision and action.  `Tools' (i.e., small manipulable objects) are an excellent domain in which to address broader questions about the integration of sensory, motor and cognitive processing. This is because tool recognition and tool use require the integration of distinct sensory, motor and cognitive representations, and the neural substrates of tool processing are well described. The research program emphasizes fresh perspectives on longstanding ideas about the dorsal and ventral visual pathways, by a) undertaking the first systematic investigation of the types of information about objects that are extracted by visual pathways that bypass primary visual cortex, and by b) studying how some parietal areas depend on inputs from the ventral stream in order to access the correct action for a given object. The research activity innovates by testing hypotheses about how lesions at different stages in the cortical visual hierarchy affect downstream processing in parietal cortex, combining neural and behavioral measures to study brain damaged patients (generating causal evidence), and by combining univariate and multivariate measures to `read out' the information content of brain regions (parietal cortex) that are anatomically remote from a lesion. The research advances understanding of how lesions in one brain region disrupt computations in other parts of the brain that depend on the damaged region for their inputs, a phenomenon (`dynamic diaschisis') that applies to brain injury generally. Advancing understanding of these basic issues using causal data has broad implications for understanding how the brain selects the correct action for the correct object, and more generally for theories of conceptual organization and causal reasoning. Understanding how the brain accesses actions from visual input has implications for related fields, such as robotics, neuroprosthetics, and evidenced based approaches for rehabilitating function after brain injury. Project Narrative Functional MRI and behavioral testing are used to test hypotheses about how strokes affecting occipital and temporal cortex disrupt access to action representations in parietal cortex. This research will advance understanding of how the brain processes visual information in support of everyday actions.",Access to parietal action representations after stroke lesions in visual cortex,10130533,R01EY028535,"['Address', 'Affect', 'Alexia', 'Anatomy', 'Area', 'Ballistics', 'Behavioral Assay', 'Brain', 'Brain Injuries', 'Brain region', 'Bypass', 'Cognitive', 'Data', 'Dorsal', 'Eating', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Imaging Device', 'Impairment', 'Investigation', 'Ischemic Stroke', 'Knowledge', 'Left', 'Lesion', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Neural Pathways', 'Neuropsychology', 'Occipital lobe', 'Parahippocampal Gyrus', 'Parietal', 'Parietal Lobe', 'Participant', 'Pathway interactions', 'Patients', 'Population', 'Process', 'Property', 'Prosopagnosia', 'Reading', 'Research', 'Research Activity', 'Robotics', 'Role', 'Semantics', 'Sensory', 'Stimulus', 'Stream', 'Stroke', 'Structure of supramarginal gyrus', 'Temporal Lobe', 'Testing', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual system structure', 'Work', 'area striata', 'base', 'behavior measurement', 'behavior test', 'blind', 'cognitive development', 'evidence base', 'extrastriate', 'extrastriate visual cortex', 'fovea centralis', 'grasp', 'information processing', 'innovation', 'lens', 'multisensory', 'neuroprosthesis', 'post stroke', 'programs', 'relating to nervous system', 'sensory integration', 'theories', 'tool', 'visual information', 'visual motor', 'visual object processing', 'visual process', 'visual processing']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2021,410316
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,10169447,R01EY011787,"['3-Dimensional', 'Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Cerebral cortex', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'cell type', 'cortical visual impairment', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'mouse genetics', 'nerve supply', 'neural circuit', 'neural network', 'novel', 'novel strategies', 'novel therapeutic intervention', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2021,384357
"Perceptual integration of luminance, texture and color cues for visual boundary segmentation Project Summary One of the most essential computations performed by the visual system is segmenting images into regions corresponding to distinct surfaces. This in turn requires identifying the boundaries separating image regions, a process known as boundary segmentation. Computational analyses of natural images have revealed that many visual cues are available at region boundaries, including differences in luminance, texture, and color. It is known that these cues combine for tasks like edge localization and orientation discrimination. However, it remains unclear how these various cues are weighted and combined for boundary segmentation.  In collaborative work with Canadian colleagues at McGill University in Montreal, we have developed a novel machine learning framework for characterizing human performance on boundary segmentation tasks using naturalistic micro-pattern stimuli. Our method makes use of the Filter-Rectify-Filter (FRF) model often applied to characterizing texture boundary segmentation. The major innovation of our approach is that we fit the FRF model directly to thousands of psychophysical stimulus-response observations to estimate its major defining parameters. We have recently applied this approach to investigating spatial strategies for contrast boundary segmentation and comparing competing hypotheses of how contrast modulation is integrated across orientation channels. In this grant, we propose to apply both classical psychophysical techniques and our novel machine learning methodology to understanding the computations employed to combine luminance, texture and color cues for segmentation.  In Aim 1, we focus on modeling segmentation of luminance-defined boundaries, comparing the case where each surface has uniform luminance, giving rise to a sharp edge (luminance step), to the more naturalistic case where the two surfaces have differing proportions of dark and light micro-patterns on either side of the boundary with no sharp edge (luminance texture). We will apply our machine learning methodology to test the hypothesis that different neural mechanisms may be involved in segmenting these two different kinds of luminance boundaries. In Aim 2, we ask how observers integrate first-order (luminance) and second-order (texture) cues for boundary segmentation, and if there are differences in cue combination strategies for luminance steps and luminance textures. We will also compare models embodying competing hypotheses of the underlying neural mechanisms of cue combination. In Aim 3, we extend the analyses in Aims 1 and 2 beyond simple luminance differences to include differences in color. Finally, Aim 4 is a pedagogical aim of promoting undergraduate research. Project Narrative Segmenting natural images into regions corresponding to distinct surfaces is an essential visual task, yet the underlying computations for boundary segmentation remain poorly understood. In this project, we will apply classical psychophysical techniques and our novel machine learning methodology to understand how multiple cues, including luminance, texture, and color, combine to enable boundary segmentation. We hope to develop and test computational models of boundary segmentation, with the ultimate goal of gaining insight into the underlying neural mechanisms employed for this essential natural vision task.","Perceptual integration of luminance, texture and color cues for visual boundary segmentation",10201916,R15EY032732,"['Address', 'Biological', 'Color', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'Cues', 'Data', 'Discrimination', 'Educational process of instructing', 'Environment', 'Goals', 'Grant', 'Human', 'Image', 'Journals', 'Laboratories', 'Light', 'Literature', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Positioning Attribute', 'Process', 'Psychophysics', 'Publications', 'Research', 'Response to stimulus physiology', 'Series', 'Side', 'Source', 'Stimulus', 'Surface', 'Techniques', 'Testing', 'Texture', 'Universities', 'Vision', 'Vision research', 'Visual', 'Visual system structure', 'Work', 'computer studies', 'experience', 'innovation', 'insight', 'interest', 'laboratory curriculum', 'luminance', 'neuromechanism', 'neurophysiology', 'novel', 'pedagogy', 'undergraduate research', 'undergraduate student', 'vision science']",NEI,FLORIDA GULF COAST UNIVERSITY,R15,2021,374345
"Statistical Unsupervised Learning VF for IIHTT & ONTT Summary Current assessments of visual field testing depend on algorithms, principally developed to diagnose and monitor progression in glaucoma, or on expert descriptive categorization of deficits. The algorithms do not work well for non-glaucomatous optic neuropathies as these disorders can both improve and deteriorate. Descriptive categorizations are not readily quantifiable to assess change over time. Unsupervised statistical learning archetypal analysis is a new way to investigate glaucoma and potentially other optic neuropathies. Both idiopathic intracranial hypertension and optic neuritis are disorders that often improve and respond to therapy. Archetypal analysis of the visual fields from two NEI sponsored clinical trials on each disorder, ONTT and IIHTT, will be investigated to determine if the findings parallel the reported outcomes and effects of therapy. We will also test whether machine learning quantifiable archetypes, which are disease-associated patterns of field deficits, are similar to expert determinations, whether they are sensitive to changes in optic nerve function, and if they reveal residual optic nerve dysfunction in eyes reported to be normal by prior study criteria. Adding cases of IIH and optic neuritis from the clinic will enhance the archetypes for each disorder for use in the clinic and new studies. Narrative Analysis of the visual fields of patients with optic neuropathies using machine learning will improve the evaluation and provide objective measurement, rather than the current descriptive methods. The approach, called archetypal analysis, should improve safety monitoring during clinical trials as well as uncover residual visual field deficits not seen with other types of analyses.",Statistical Unsupervised Learning VF for IIHTT & ONTT,10192112,R21EY032522,"['Acute', 'Affect', 'Algorithms', 'Clinic', 'Clinical Trials', 'Cost Savings', 'Detection', 'Deterioration', 'Diagnosis', 'Disease', 'Evaluation', 'Event', 'Eye', 'Face', 'Frequencies', 'Functional disorder', 'Future', 'Glaucoma', 'Head', 'Injury', 'Intervention', 'Intervention Studies', 'Lead', 'Machine Learning', 'Manuals', 'Masks', 'Measurement', 'Measures', 'Methods', 'Military Personnel', 'Monitor', 'Optic Nerve', 'Optic Neuritis', 'Outcome', 'Outcome Study', 'Papilledema', 'Patients', 'Pattern', 'Perimetry', 'Physiologic Intraocular Pressure', 'Pseudotumor Cerebri', 'Reader', 'Reporting', 'Residual state', 'Safety', 'Shapes', 'Supervision', 'Testing', 'Time', 'Vision', 'Visit', 'Visual Fields', 'Weight', 'archetypal analysis', 'base', 'central visual field', 'clinical practice', 'eligible participant', 'field study', 'improved', 'longitudinal analysis', 'optic nerve disorder', 'prospective', 'response', 'statistical learning', 'successful intervention', 'treatment effect', 'treatment trial', 'trend', 'unsupervised learning']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R21,2021,331170
"Neural mechanisms of active vision in the fovea Neural mechanisms of active vision in the fovea In many ways human vision is like a camera, with a lens that forms an image on a spatially arranged sensor (the retina). However, it is unlike a camera because the sensor has uneven sampling and is constantly moving with the eyes. Recent behavioral and theoretical work suggest these eye movements serve a faciliatory role in high acuity vision – where the eye movements are part of the computations and enhance spatial resolution. However, the neurophysiological mechanisms to support this facilitation remain unknown. More broadly, little is known about the neural mechanisms that integrate across the retinal motion generated by eye movements, especially in the central visual field (the fovea). This is particularly important because over 8 million Americans suffer from central vision loss due to retinal disorders. Even if the retinal signals could be repaired, it is imperative to understand how the brain reads out foveal signals to ensure recovery of high-acuity visual processing, and fixational eye movements are a part of that process. The proposed career development plan aims to address these questions by measuring visual processing in the foveal representation of primary visual cortex (V1) during natural visual behavior. This proposal uses custom high-resolution eye-tracking, a novel visual foraging paradigm, largescale neurophysiology, and state-of-the-art machine learning to make these measurements possible. The proposed research will not only generate fundamental understanding of how eye-movements facilitate visual processing, but also will integrate the experimental and theoretical tools required to support neurophysiological studies of active visual processing without a loss of rigor or detail. The candidate has extensive expertise in awake- behaving neurophysiology and computational modeling and the training plan is designed to support his further training in statistical modeling, high-resolution eye-tracking, and modern machine-learning techniques for analyzing neural population data. The primary mentor, Dr. Daniel Butts, is a world expert in statistical models of neural activity during active vision; Co-mentor, Dr. Michele Rucci, is a world leader in high-resolution eye tracking and theoretical approaches to active vision; and Co-mentor, Dr. Jude Mitchell, is a pioneer in establishing the marmoset model of visual neuroscience and an expert in neurophysiology of visual attention. Together, they will provide the guidance to establish the candidate’s transition to a successful independent research career. The goal of this proposal is to identify the impact of fixational eye movements on neural representations in visual cortex in the central visual field. Over 9 million Americans have central vision loss from age-related macular degeneration. Results from this proposal will build a fundamental understanding of how retinal signals from the fovea are processed by visual cortex during natural visual behavior.",Neural mechanisms of active vision in the fovea,10106203,K99EY032179,"['Address', 'Age related macular degeneration', 'American', 'Behavior', 'Behavioral', 'Blindness', 'Brain', 'Callithrix', 'Code', 'Cognitive', 'Computer Models', 'Custom', 'Data', 'Data Set', 'Development', 'Development Plans', 'Disease', 'Ensure', 'Esthesia', 'Eye', 'Eye Movements', 'Foundations', 'Frequencies', 'Funding', 'Goals', 'Grant', 'Human', 'Image', 'Laboratories', 'Machine Learning', 'Measurement', 'Measures', 'Mentors', 'Modeling', 'Modernization', 'Monkeys', 'Motion', 'Neurons', 'Outcome', 'Peripheral', 'Phase', 'Physiology', 'Population', 'Positioning Attribute', 'Primates', 'Process', 'Recovery', 'Research', 'Resolution', 'Retina', 'Retinal Diseases', 'Role', 'Saccades', 'Sampling', 'Series', 'Signal Transduction', 'Statistical Models', 'Stream', 'System', 'Techniques', 'Testing', 'Training', 'Universities', 'V1 neuron', 'V4 neuron', 'Vision', 'Visual', 'Visual Acuity', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual attention', 'Work', 'active vision', 'area striata', 'awake', 'base', 'career', 'career development', 'central visual field', 'computerized tools', 'design', 'extrastriate', 'extrastriate visual cortex', 'flexibility', 'fovea centralis', 'interest', 'lens', 'neural model', 'neuromechanism', 'neurophysiology', 'new technology', 'novel', 'professor', 'receptive field', 'relating to nervous system', 'repaired', 'response', 'retinal imaging', 'sample fixation', 'sensor', 'skills', 'spatial vision', 'spatiotemporal', 'statistics', 'tool', 'visual information', 'visual neuroscience', 'visual process', 'visual processing', 'visual tracking']",NEI,"UNIV OF MARYLAND, COLLEGE PARK",K99,2021,116969
"Isolating and mitigating sequentially dependent perceptual errors in clinical visual search Project Summary When looking at an x-ray, radiologists are typically asked to localize a tumor (if present), and to classify it, judging its size, class, position and so on. Importantly, during this task, radiologists examine on a daily basis hundreds and hundreds of x-rays, seeing several images one after the other. A main underlying assumption of this task is that radiologists’ percepts and decisions on a current X-ray are completely independent of prior events. Recent results showed that this is not true: our perception and decisions are strongly biased by our past visual experience. Although serial dependencies were proposed to be a purposeful mechanism to achieve perceptual stability of our otherwise noisy visual input, serial dependencies play a crucial and deleterious role in the everyday task performed by radiologists. For example, an x-ray containing a tumor can be classified as benign depending on the content of the previously seen x-ray. Given the importance and the impact of serial dependencies in clinical tasks, in this proposal, we plan to (1) establish, (2) identify and (3) mitigate the conditions under which serial effects determine our percepts and decisions in tumor search tasks. In Aim 1, we will establish the presence of serial effects in four different clinically relevant domains: tumor detection, tumor classification, tumor position and recognition speed. In Aim 2, we plan to identify the specific boundary conditions under which visual serial dependence impacts tumor search in radiology. In Aim 3, once we will fully understand these boundary conditions in Aim 2, we will propose a series of task and stimulus manipulations to control and mitigate the deleterious effects of visual serial dependence on tumor search. As a result of these manipulations, visual search performance should improve in measurable ways (detection, classification, position, speed). Aim 3 is particularly crucial because it will allow us to propose new guidelines which will greatly improve tumor recognition in x-ray images, making this task even more effective and reliable. Taken together, the proposed studies in Aim 1, 2, and 3 will allow us to establish, identify, and mitigate the deleterious effect of serial dependencies in radiological search tasks, which could have a significant impact on the health and well-being of patients everywhere. ! ! ! Project Narrative Our proposal is designed to investigate the detrimental impact of visual serial dependencies in clinical settings. Serial dependencies significantly impact our perceptual experience, but little is known about their detrimental consequences when radiologists are asked to detect tumors in x-rays. Crucially, the final goal of our research project is to develop recommendations and guidelines to mitigate the negative effect of serial effects and, thus, improve diagnosis accuracy.",Isolating and mitigating sequentially dependent perceptual errors in clinical visual search,10137898,R01CA236793,"['Benign', 'Classification', 'Clinical', 'Computer Vision Systems', 'Data', 'Decision Making', 'Dependence', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Event', 'Goals', 'Guidelines', 'Health', 'Human', 'Image', 'Impairment', 'Judgment', 'Machine Learning', 'Measurable', 'Patients', 'Perception', 'Performance', 'Personal Satisfaction', 'Play', 'Positioning Attribute', 'Radiology Specialty', 'Reading', 'Recommendation', 'Reporting', 'Research Project Grants', 'Roentgen Rays', 'Role', 'Scanning', 'Series', 'Speed', 'Stimulus', 'Structure', 'Testing', 'Time', 'Training', 'Visual', 'Visual system structure', 'Work', 'base', 'clinically relevant', 'design', 'diagnostic accuracy', 'experience', 'improved', 'laboratory experiment', 'radiologist', 'tumor', 'visual search']",NCI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2021,311975
