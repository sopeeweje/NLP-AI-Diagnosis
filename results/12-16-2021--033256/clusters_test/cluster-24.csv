text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,10160864,R01DC018055,"['Acoustics ', ' Acoustic ', ' Adult ', ' 21+ years old ', ' Adult Human ', ' adulthood ', ' Affect ', ' Algorithms ', ' Auditory area ', ' Auditory Cortex ', ' Auditory Perception ', ' hearing perception ', ' sound perception ', ' Auditory Perceptual Disorders ', ' Acoustic Perceptual Disorder ', ' Auditory Comprehension Disorder ', ' Auditory Perceptual Diseases ', ' Auditory Processing Disorder ', ' Psychoacoustical Disorders ', ' central processing disorder ', ' Behavior ', ' Cognition Disorders ', ' cognitive disease ', ' cognitive disorder ', ' cognitive syndrome ', ' Communication ', ' Communication impairment ', ' Communication Disorders ', ' Communicative Disorders ', ' Cues ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Electrodes ', ' Electrophysiology (science) ', ' Electrophysiology ', ' Neurophysiology / Electrophysiology ', ' electrophysiological ', ' Elements ', ' Foundations ', ' Goals ', ' Hearing Aids ', ' assistive hearing device ', ' assistive listening device ', ' hearing amplification ', ' hearing assistance ', ' hearing assistive device ', ' hearing device ', ' Heart ', ' Human ', ' Modern Man ', ' Infant ', ' Language ', ' Language Development ', ' acquiring language skills ', ' language acquisition ', ' language learning ', ' Learning ', ' Longevity ', ' Length of Life ', ' life span ', ' lifespan ', ' Biological Models ', ' Biologic Models ', ' Model System ', ' Neurobiology ', ' neurobiological ', ' Neurons ', ' Nerve Cells ', ' Nerve Unit ', ' Neural Cell ', ' Neurocyte ', ' neuronal ', ' Neurosciences ', ' Perception ', ' Quality of life ', ' QOL ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Speech Sound ', ' statistics ', ' Testing ', ' Time ', ' Work ', ' Generations ', ' Superior temporal gyrus ', ' Comprehension ', ' improved ', ' Physiological ', ' Physiologic ', ' Failure ', ' Stimulus ', ' Individual ', ' Plant Roots ', ' root ', ' Starlings ', ' Sturnidae ', ' Sturnus vulgaris ', ' machine learned ', ' Machine Learning ', ' Auditory ', ' Complex ', ' Parietal ', ' Stream ', ' Sensory ', ' Pattern ', ' Techniques ', ' specific language impairment ', ' Word Blindness ', ' Dyslexia ', ' Auditory system ', ' experience ', ' speech recognition ', ' success ', ' Animal Models and Related Studies ', ' model of animal ', ' model organism ', ' Animal Model ', ' neural ', ' relating to nervous system ', ' Oscines ', ' song bird ', ' Songbirds ', ' sensory system ', ' Categories ', ' Modality ', ' Learning disability ', ' Learning Disabilities ', ' Coding System ', ' Code ', ' neural circuitry ', ' neurocircuitry ', ' synaptic circuit ', ' synaptic circuitry ', ' neural circuit ', ' Modeling ', ' response ', ' model development ', ' pattern perception ', ' Hearing Loss ', ' Hypoacuses ', ' Hypoacusis ', ' dysfunctional hearing ', ' hearing defect ', ' hearing deficit ', ' hearing difficulty ', ' hearing disability ', ' hearing dysfunction ', ' hearing impairment ', ' Autism ', ' Autistic Disorder ', ' Early Infantile Autism ', ' Infantile Autism ', "" Kanner's Syndrome "", ' autistic spectrum disorder ', ' autism spectrum disorder ', ' Data ', ' Detection ', ' Cognitive ', ' Process ', ' Grouping ', ' groupings ', ' Behavioral ', ' computer framework ', ' computational framework ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' bird song ', ' birdsong ', ' speech processing ', ' language processing ', ' spatiotemporal ', ' neurobiological mechanism ', ' learned behavior ', ' learning behavior ', ' language comprehension ', ' comprehending language ', ' signal processing ', ' cognitive process ', ' sensory input ', ' experimental study ', ' experiment ', ' experimental research ', ' auditory processing ', ' Computer Models ', ' Computerized Models ', ' computational modeling ', ' computational models ', ' computer based models ', ' computerized modeling ', ' machine learning method ', ' machine learning methodologies ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,335661
"A holistic approach to identifying functional units of tongue motion during speech PROJECT SUMMARY  Oral cancers have the seventh highest incidence, with roughly 51,540 new cases and 10,030 cancer- related deaths expected to occur in 2018. Although a variety of treatment methods are available, the death rate is higher than that for most cancers with five-year rates of about 50 percent. The most frequently used treatment method, glossectomy surgery, involves the surgical removal of tumors and surrounding tissues, and the addition of grafted tissues, often followed by radiotherapy. Although tongue cancer and its treatment have debilitating effects on speech, the impact of varying degrees of resection and reconstruction on the formation of functional units in speech has remained poorly understood. In order to produce intelligible speech, a variety of local muscle groupings of the tongue—i.e., functional units—emerge and recede rapidly and nimbly in a highly coordinated fashion. Therefore, understanding the formation of functional units that are critical for speech production can provide substantial insights into normal, pathological, and adapted motor control strategies in controls and patients with tongue cancer for novel therapeutic, surgical, and rehabilitative strategies. One of the critical challenges in pre-operative surgical and treatment planning, as well as in post- operative evaluation for tongue cancer is the difficulty in developing objective and quantitative measures and in evaluating their functional outcome predictability. To address this, in this proposal, three integrated approaches will be used in in vivo tongue motion during speech to seamlessly identify the functional units and associated quantitative measures: multimodal MRI methods, multimodal deep learning, and biomechanical simulations. This will provide a convergent approach, thereby allowing us to (1) test hypotheses about the spatiotemporal basis of muscle coordination in a consilient way, and (2) develop objective quantitative measures that are required for understanding the complex biomechanical system as well as for predicting the functional outcomes after various reconstruction methods. The first proof of concept study published by the PI and the team identified the functional units of speech tasks using the sparse non-negative matrix factorization framework, in which the magnitude and angle of displacements from tagged MRI were used as our input quantities. With these advances in place, we will further incorporate muscle fiber anatomy from diffusion MRI and motion tracking from tagged MRI into our framework to yield physiologically and anatomically meaningful functional units. In addition, we will create a completely novel and integrated way of directly relating the functional units to tongue muscle anatomy, learning joint representation via a multimodal deep learning technique, and linking them to biomechanical simulations. Furthermore, 3D and 4D atlases will be utilized to identify objective and quantitative measures based on our functional units analysis. Taken together, the successful implementation of our integrated framework will identify functional units that can be used for research on tongue motion, for surgical planning, and for diagnosis, prognosis, and rehabilitation in a range of speech-related disorders. PROJECT NARRATIVE  Tongue cancer and its treatment affect tongue structure and function, yet little is known about how the changes in tongue structure due to varying degrees of resection and reconstruction affect the formation of functional units of tongue motion during speech. We propose to use novel integrated platform tools to identify functional units seamlessly with unprecedented resolution and precision. Upon success of this proposal, our integrated framework has the potential to aid in an increased understanding of speech motor control strategies in healthy controls and the patient group, thereby benefiting patients through improved diagnosis, treatment, and rehabilitative strategies.",A holistic approach to identifying functional units of tongue motion during speech,10147030,R01DC018511,"['Acoustics ', ' Acoustic ', ' Affect ', ' Aftercare ', ' After Care ', ' After-Treatment ', ' post treatment ', ' Anatomy ', ' Anatomic ', ' Anatomic Sites ', ' Anatomic structures ', ' Anatomical Sciences ', ' Atlases ', ' Behavior ', ' Biomechanics ', ' biomechanical ', ' Malignant Neoplasms ', ' Cancers ', ' Malignant Tumor ', ' malignancy ', ' neoplasm/cancer ', ' Computing Methodologies ', ' computational methodology ', ' computational methods ', ' computer based method ', ' computer methods ', ' computing method ', ' Cessation of life ', ' Death ', ' Deglutition ', ' Swallowing ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Elements ', ' Exhibits ', ' Glossectomy ', ' Goals ', ' Incidence ', ' Joints ', ' Learning ', ' Magnetic Resonance Imaging ', ' MR Imaging ', ' MR Tomography ', ' MRI ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' NMR Imaging ', ' NMR Tomography ', ' Nuclear Magnetic Resonance Imaging ', ' Zeugmatography ', ' Maps ', ' Methods ', ' Motion ', ' Muscle ', ' Muscle Tissue ', ' muscular ', ' Patients ', ' Postoperative Period ', ' Post-Operative ', ' Postoperative ', ' Production ', ' Publishing ', ' Radiation therapy ', ' Radiotherapeutics ', ' Radiotherapy ', ' radiation treatment ', ' radio-therapy ', ' treatment with radiation ', ' Rehabilitation therapy ', ' Medical Rehabilitation ', ' Rehabilitation ', ' rehab therapy ', ' rehabilitative ', ' rehabilitative therapy ', ' Research ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Standardization ', ' Testing ', ' Time ', ' Tissues ', ' Body Tissues ', ' Tongue ', ' Weight ', ' Work ', ' Measures ', ' malignant tongue neoplasm ', ' Tongue Cancer ', ' malignant tongue tumor ', ' malignant mouth neoplasm ', ' Malignant Oral Cavity Neoplasm ', ' Malignant Oral Cavity Tumor ', ' Malignant Oral Neoplasm ', ' Mouth Cancer ', ' Oral Cancer ', ' malignant mouth tumor ', ' oral cavity cancer ', ' base ', ' improved ', ' Procedures ', ' Surface ', ' Clinical ', ' Physiological ', ' Physiologic ', ' Death Rate ', ' Link ', ' Evaluation ', ' Fiber ', ' insight ', ' Measurement ', ' Muscle Fibers ', ' Myotubes ', ' Rhabdomyocyte ', ' Skeletal Fiber ', ' Skeletal Muscle Cell ', ' Skeletal Muscle Fiber ', ' Skeletal Myocytes ', ' tool ', ' tissue grafting ', ' Tissue Grafts ', ' Knowledge ', ' Complex ', ' Techniques ', ' System ', ' 3-D ', ' 3D ', ' three dimensional ', ' 3-Dimensional ', ' Operative Procedures ', ' Surgical ', ' Surgical Interventions ', ' Surgical Procedure ', ' surgery ', ' Operative Surgical Procedures ', ' success ', ' treatment planning ', ' Proxy ', ' Structure ', ' novel ', ' holistic approach ', ' Abscission ', ' Extirpation ', ' Removal ', ' Surgical Removal ', ' resection ', ' Excision ', ' Modeling ', ' DWI (diffusion weighted imaging) ', ' DWI-MRI ', ' Diffusion MRI ', ' Diffusion Weighted MRI ', ' Diffusion weighted imaging ', ' Diffusion-weighted Magnetic Resonance Imaging ', ' dMRI ', ' diffusion tensor imaging ', ' Diffusion Magnetic Resonance Imaging ', ' Address ', ' Data ', ' Predictive Value ', ' Resolution ', ' in vivo ', ' Pathologic ', ' Grouping ', ' groupings ', ' reconstruction ', ' functional outcomes ', ' Outcome ', ' Impairment ', ' novel therapeutics ', ' new drug treatments ', ' new drugs ', ' new therapeutics ', ' new therapy ', ' next generation therapeutics ', ' novel drug treatments ', ' novel drugs ', ' novel therapy ', ' rehabilitation strategy ', ' rehab strategy ', ' tumor ', ' spatiotemporal ', ' motor control ', ' multimodality ', ' multi-modality ', ' treatment strategy ', ' clinical practice ', ' muscular structure ', ' muscle structure ', ' Geometry ', ' signal processing ', ' biomechanical model ', ' biomechanic modeling ', ' biomechanic simulation ', ' biomechanical modeling ', ' biomechanical simulation ', ' outcome prediction ', ' predictive outcomes ', ' predictors of outcomes ', ' deep learning ', ' Prognosis ', ' ']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,565453
"Single-neuron population dynamics in human speech motor cortex for a speech prosthesis PROJECT SUMMARY Augmentative and alternative communication (AAC) technology for people with severe speech and motor impairment (SSMI) continues to improve, with recent advances being made in the neural control of communication devices. In prior NIDCD-supported research, our research team developed a high-performance intracortical brain-computer interface (iBCI) that decodes arm movement intentions directly from brain activity. This technology has allowed people with SSMI to control a computer cursor with sufficient speed and accuracy to type at up to 8 words/min and has enabled full control of unmodified consumer devices using only decoded motor cortical activity. In the proposed U01 clinical research, performed as part of the multi-site BrainGate consortium, we will build upon decades of experience in studying the motor system in humans and non-human primates, with the end goal of advancing iBCI technology. The goals of this project are to study how speech is prepared and produced at the level of ensembles of single neurons in speech-related motor areas of the brain in people with amyotrophic lateral sclerosis (ALS), and to create a speech prosthesis that will allow communication at rates approaching conversational speech (120-150 words per minute). We will approach these investigations with a suite of advanced methods, including (1) newly-developed dynamical systems computational approaches that have provided fundamental insights into the function of the motor system, and (2) machine learning algorithms for decoding of movement intention and language modeling that have formed the basis of the fastest communication prosthesis yet reported. Finally, we will continue to evaluate the safety profile of Utah-array based iBCIs through the ongoing BrainGate2 pilot clinical trial. Upon completion, this project will advance both the capabilities of iBCIs for communication and our understanding of the detailed neural mechanisms of speech production. PROJECT NARRATIVE People with brainstem stroke, advanced amyotrophic lateral sclerosis (ALS, also known as Lou Gehrig’s disease), or other disorders can become unable to speak despite being awake and alert. In this project, we seek a fundamental understanding of how the brain produces speech, and to develop an intracortical brain-computer interface (iBCI) to restore communication at conversational speeds by people with paralysis.",Single-neuron population dynamics in human speech motor cortex for a speech prosthesis,10200463,U01DC019430,"['Amyotrophic Lateral Sclerosis ', ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', "" Gehrig's Disease "", ' Lou Gehrig Disease ', ' Articulators ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', "" Broca's area "", ' Clinical Research ', ' Clinical Study ', ' Clinical Trials ', ' Communication ', ' Computers ', ' Disease ', ' Disorder ', ' Electrodes ', ' Face ', ' faces ', ' facial ', ' Goals ', ' Hand ', ' Handwriting ', ' Human ', ' Modern Man ', ' Language ', ' Locked-In Syndrome ', ' Methods ', ' Microelectrodes ', ' Miniaturized Electrodes ', ' Modernization ', ' Motor Cortex ', ' Movement ', ' body movement ', ' Muscle ', ' Muscle Tissue ', ' muscular ', ' nervous system disorder ', ' Nervous System Diseases ', ' Neurologic Disorders ', ' Neurological Disorders ', ' neurological disease ', ' Neurons ', ' Nerve Cells ', ' Nerve Unit ', ' Neural Cell ', ' Neurocyte ', ' neuronal ', ' Neurosciences ', ' Population Dynamics ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Research Support ', ' Safety ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' Utah ', ' Voice ', ' Inferior frontal gyrus ', ' Inferior Frontal Convolution ', ' Precentral gyrus ', ' Custom ', ' Intention ', ' Prosthesis ', ' Prosthetic device ', ' Prosthetics ', ' base ', ' improved ', ' Dorsal ', ' Site ', ' Area ', ' Chronic ', ' Training ', ' insight ', ' awake ', ' Individual ', ' nonhuman primate ', ' non-human primate ', ' machine learned ', ' Machine Learning ', ' Functional MRI ', ' fMRI ', ' Functional Magnetic Resonance Imaging ', ' Investigation ', ' electrocorticography ', ' Electrocorticogram ', ' Dimensions ', ' Techniques ', ' System ', ' Brainstem Infarctions ', ' Brainstem Stroke ', ' Brain Stem Infarctions ', ' Palsy ', ' Plegia ', ' paralysis ', ' paralytic ', ' Paralysed ', ' Degenerative Neurologic Diseases ', ' Degenerative Neurologic Disorders ', ' Nervous System Degenerative Diseases ', ' Neural Degenerative Diseases ', ' Neural degenerative Disorders ', ' Neurodegenerative Diseases ', ' Neurologic Degenerative Conditions ', ' degenerative diseases of motor and sensory neurons ', ' degenerative neurological diseases ', ' neurodegenerative illness ', ' Neurodegenerative Disorders ', ' experience ', ' Performance ', ' neural control ', ' neural regulation ', ' neuromodulation ', ' neuromodulatory ', ' neuroregulation ', ' neural ', ' relating to nervous system ', ' kinematic model ', ' kinematics ', ' Speed ', ' Participant ', ' Devices ', ' Reporting ', ' Modeling ', ' Address ', ' AAC Device ', ' AAC Intervention ', ' Augmentative and Alternative Communication ', ' Data ', ' Motor ', ' Preparation ', ' Text ', ' Output ', ' National Institute on Deafness and Other Communication Disorders ', ' NIDCD ', ' orofacial ', ' design ', ' designing ', ' brain computer interface ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' Impairment ', ' Implant ', ' speech accuracy ', ' accurate speech ', ' motor impairment ', ' movement impairment ', ' movement limitation ', ' arm ', ' neural correlate ', ' arm movement ', ' dynamic system ', ' dynamical system ', ' communication device ', ' recurrent neural network ', ' deep learning ', ' machine learning algorithm ', ' machine learned algorithm ', ' automated speech recognition ', ' automatic speech recognition ', ' safety assessment ', ' ']",NIDCD,STANFORD UNIVERSITY,U01,2021,1050840
"SCH: INT: Collaborative Research: Exploiting Voice Assistant Systems for Early Detection of Cognitive Decline Early detection of Alzheimer’s Disease and Related Dementias (ADRD) in older adults living alone is essential for developing, planning, and initiating interventions and support systems to improve patients’ everyday function and quality of life. Conventional, clinic-based methods for early diagnosis are expensive, impractical, and time-consuming. This project aims to develop a low-cost, passive, and practical home-based assessment method using Voice Assistant Systems (VAS) for early detection of ADRD, including a set of novel data mining techniques for sparse time-series speech. The project has three specific aims: 1. Using a recurrent neural network (RNN) and a softmax regression model, we will develop a transfer learning technique to investigate the link between the speech from in-lab VAS tasks and cognitive decline and discover ADRD-related voice biomarkers. The Pitt Corpus speech database will be used to optimize the RNN parameters and thereby overcome the limited data problem of VAS. The softmax regression model will allow us to align the feature distributions from the previous speech data and in-lab VAS speech; 2. We will develop a novel “many-to- difference” prediction model with a symmetric RNN structure to predict the ADRD-related cognitive differences at two ends of a time period from the sparse time-series data. The proposed model is different from previous ones as the learning focus is shifted from the short-term pattern differences across users to the pattern difference over time for an individual user. The proposed model accommodates well for the highly dynamic nature of the inputs and maximally removes individual characteristics from the prediction result. To analyze the sparse time-series speech, a new data sampling technique will be used to address the imbalanced data problem, and a data quality metric will be developed for the proposed model; 3. The team will conduct an 18- month in-lab evaluation and a 28-month in-home evaluation with a focus on whether the VAS tasks and features from the in-lab evaluation and the repetition features of the in-home VAS data can measure and predict ADRD-related cognitive decline in the in-home participants over time. The proposed methods will be integrated into an interactive system to enable efficient communication on ADRD status among patients, caregivers, and clinicians. If successful, the outcomes of this project will provide an opportunity to provide supportive evidence to clinicians for the early detection of ADRD outside of a clinic-based setting. Project Relevance This project aims to develop a low-cost, passive, and practical cognitive assessment method using Voice Assistant Systems (VAS) for early detection of ADRD-related cognitive decline. If successful, the proposed system may be widely disseminated for the early diagnosis of ADRD to complement existing diagnostic modalities that could ultimately enable long-term patient and caregiver planning to maintain individual’s independence at home. This project aims to develop a low-cost, passive, and practical cognitive assessment method using Voice  Assistant Systems (VAS) for early detection of cognitive decline. If successful, the proposed system may  be widely disseminated for the early diagnosis of cognitive impairment to complement existing diagnostic  modalities that could ultimately enable long-term patient and caregiver planning to maintain individual's  independence at home.",SCH: INT: Collaborative Research: Exploiting Voice Assistant Systems for Early Detection of Cognitive Decline,10190783,R01AG067416,"['Age ', ' ages ', ' Elderly ', ' advanced age ', ' elders ', ' geriatric ', ' late life ', ' later life ', ' older adult ', ' older person ', ' senior citizen ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Cerebrospinal Fluid ', ' cerebral spinal fluid ', ' spinal fluid ', ' Cognition ', ' Communication ', ' Complement ', ' Complement Proteins ', ' Mental Depression ', ' depression ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Pharmacotherapy ', ' Drug Therapy ', ' drug treatment ', ' Pharmaceutical Preparations ', ' Drugs ', ' Medication ', ' Pharmaceutic Preparations ', ' drug/agent ', ' Health ', ' Healthcare Systems ', ' Health Care Systems ', ' Human ', ' Modern Man ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Learning ', ' Magnetic Resonance Imaging ', ' MR Imaging ', ' MR Tomography ', ' MRI ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' NMR Imaging ', ' NMR Tomography ', ' Nuclear Magnetic Resonance Imaging ', ' Zeugmatography ', ' Methods ', ' Persons ', ' Neuropsychology ', ' Neuropsychologies ', ' neuropsychologic ', ' Patients ', ' Public Health ', ' Quality of life ', ' QOL ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Science ', ' Speech ', ' Stress ', ' Time ', ' Psychological Transfer ', ' learning transfer ', ' training transfer ', ' Voice ', ' Wrist ', ' Measures ', ' Privacy ', ' Caregivers ', ' Care Givers ', ' Custom ', ' base ', ' sensor ', ' improved ', ' Clinical ', ' Phase ', ' Series ', ' Link ', ' Evaluation ', ' Individual ', ' Databases ', ' Data Bases ', ' data base ', ' data quality ', ' Cognitive Disturbance ', ' Cognitive Impairment ', ' Cognitive decline ', ' Cognitive function abnormal ', ' Disturbance in cognition ', ' cognitive dysfunction ', ' cognitive loss ', ' Impaired cognition ', ' Diagnostic ', ' Nature ', ' Knowledge ', ' Complex ', ' Clinic ', ' Pattern ', ' Techniques ', ' System ', ' Amentia ', ' Dementia ', ' Visit ', ' Services ', ' early detection ', ' Early Diagnosis ', ' Structure ', ' novel ', ' Participant ', ' Modality ', ' Devices ', ' Social Support System ', ' Support System ', ' intervention therapy ', ' Therapeutic Intervention ', ' Modeling ', ' Sampling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Cell Phone ', ' Cellular Telephone ', ' iPhone ', ' smart phone ', ' smartphone ', ' Cellular Phone ', ' actigraph ', ' actigraphy ', ' datamining ', ' data mining ', ' cognitive change ', ' Address ', ' Data ', ' Cognitive ', ' Monitor ', ' Characteristics ', ' Process ', ' Image ', ' imaging ', ' cost ', ' burden of illness ', ' burden of disease ', ' disease burden ', ' years of life lost to disability ', ' years of life lost to disease ', ' predictive modeling ', ' computer based prediction ', ' prediction model ', ' touchscreen ', ' touch panel ', ' touch screen ', ' touch screen panel ', ' touchscreen panel ', ' Outcome ', ' Population ', ' Consumption ', ' handheld mobile device ', ' mobile device ', ' usability ', ' Biological Markers ', ' bio-markers ', ' biologic marker ', ' biomarker ', ' screening ', ' Tablet Computer ', ' tablet device ', ' cognitive testing ', ' cognitive assessment ', ' Accelerometer ', ' accelerometry ', ' activity monitor ', ' activity tracker ', ' recurrent neural network ', ' deep learning ', ' aging in place ', ' age in place ', ' microphone ', "" Alzheimer's disease related dementia "", ' AD related dementia ', ' ADRD ', ' Alzheimer related dementia ', "" Alzheimer's disease diagnosis "", "" Alzheimer's diagnosis "", ' therapeutically effective ', ' Home ', ' ']",NIA,UNIVERSITY OF MASSACHUSETTS BOSTON,R01,2021,292596
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9841303,R01DC014498,"['Algorithms ', ' Child ', ' 0-11 years old ', ' Child Youth ', ' Children (0-21) ', ' youngster ', ' Communication ', ' Computer Vision Systems ', ' computer vision ', ' Computing Methodologies ', ' computational methodology ', ' computational methods ', ' computer based method ', ' computer methods ', ' computing method ', ' deafness ', ' Emotions ', ' Face ', ' faces ', ' facial ', ' Facial Expression ', ' face expression ', ' Facial Muscles ', ' Goals ', ' Hand ', ' Head ', ' Hearing ', ' Human ', ' Modern Man ', ' Linguistics ', ' Linguistic ', ' Logic ', ' Manuals ', ' Methods ', ' Movement ', ' body movement ', ' Parents ', ' Production ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Science ', ' Semantics ', ' Sign Language ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Computer software ', ' Software ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' base ', ' Specific qualifier value ', ' Specified ', ' Series ', ' Visual ', ' Individual ', ' Databases ', ' Data Bases ', ' data base ', ' Shapes ', ' tool ', ' machine learned ', ' Machine Learning ', ' Life ', ' System ', ' 3-D ', ' 3D ', ' three dimensional ', ' 3-Dimensional ', ' emotional expression ', ' expression of emotion ', ' showing emotion ', ' interest ', ' instructor ', ' Visual System ', ' Visual system structure ', ' experience ', ' syntactic ', ' syntax ', ' Structure ', ' Agreement ', ' Devices ', ' Academic achievement ', ' Abscission ', ' Extirpation ', ' Removal ', ' Surgical Removal ', ' resection ', ' Excision ', ' Coding System ', ' Code ', ' face perception ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' outreach to information ', ' Access to Information ', ' body position ', ' preventing ', ' prevent ', ' Address ', ' Detection ', ' Pattern Recognition ', ' Behavioral ', ' Image ', ' imaging ', ' reconstruction ', ' computerized tools ', ' computational tools ', ' design ', ' designing ', ' innovation ', ' innovate ', ' innovative ', ' Computational algorithm ', ' computer algorithm ', ' comparative ', ' public health relevance ', ' Teacher Professional Development ', ' Faculty Education ', ' Faculty Training ', ' Teacher Education ', ' Teacher Educator ', ' Teacher Preparation ', ' Teacher Training ', ' faculty development ', ' faculty professional development ', ' instructor training ', ' teacher development ', ' experimental study ', ' experiment ', ' experimental research ', ' Articulation ', ' American Sign Language ', ' machine learning algorithm ', ' machine learned algorithm ', ' deaf ', ' deafened ', ' profound hearing loss ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,317844
"Computational Speech Analysis in Alzheimer's Disease and Other Neurocognitive Disorders Abstract: Early and accurate diagnosis of neurocognitive disorders (NCDs) is critical for planning, treatment, and research referral, but demands time and expertise often unavailable to primary care providers. Speech and language are often impaired early in the disease course of several NCDs. Previous research has demonstrated the diagnostic potential of computer speech analysis (CSA), with differences between healthy controls and disorders such as mild cognitive impairment (MCI) and Alzheimer's disease. However, there are several additional steps that must be taken to make CSA a diagnostically viable screening tool. This proposal includes a career development plan providing the applicant with training, mentorship, and experience in the following areas in order to bring CSA techniques into clinical practice: 1) computational linguistics and paralinguistics, 2) longitudinal markers of disease, and 3) design of novel technology for dissemination. As part of this training, academic and professional skills, including ethics in research, will also be expanded. Uniquely qualified mentorship and advisory teams have been selected to ensure the success of the proposed training and research. The proposed study is a prospective, longitudinal, observational, cohort investigation of two distinct research groups. The first group is a highly selected and well-characterized research cohort of healthy control, Alzheimer's disease, and MCI subjects (Group A). In Group A, the performance and reproducibility of a machine learning algorithm will be improved to distinguish Alzheimer's disease and MCI from healthy controls using CSA. Multiple regression and voxel-based morphometry will be used to better understand what may drive group differences in CSA measures in Group A as well. Clinical applications of this algorithm will then be assessed in a clinic-based cohort of patients with different NCDs (Group B) in order reduce spectrum bias likely present in prior studies. As sub-aims in both groups, possible further improvement of the algorithmic outcomes with longitudinal CSA measures will also be examined. The overall objective is to develop intuitive, reliable and reproducible CSA-based clinical measures by correlating them with established neuropsychiatric and imaging markers, determining their efficacy in clinical populations, and determining how they change over time. As a result, this research will validate specific speech traits as useful diagnostic markers of neurocognitive disease and explain why those markers differ between patient groups, both of which are major steps towards the design of novel and easily implemented tools in the screening of NCDs such as Alzheimer's disease. PROJECT NARRATIVE Computational speech analysis (CSA) has shown promise as a cost-effective, rapid screening for patients with neurocognitive disorders (NCDs) by objectively and automatically quantifying speech and language use; however, critical steps must be taken before these measures can become clinically useful. I have training and experience in the neurology of speech and language, but require additional training in computational linguistics and paralinguistics, longitudinal markers of disease including neuroimaging and neuropsychological measures, and design of novel technology for dissemination in order to bring CSA into clinical practice. In this project, we propose to investigate the utility of using CSA measures in two distinct patient groups, including a highly characterized group of research participants that includes healthy controls, Alzheimer's disease patients, and mild cognitive impairment patients (Group A), and a group of consented clinic patients with different NCDs (Group B) and to follow these two groups in prospective, longitudinal studies to correlate spontaneous speech measures with standardized linguistic, neuropsychological, and biological measures.",Computational Speech Analysis in Alzheimer's Disease and Other Neurocognitive Disorders,10145566,K23AG063900,"['Adult ', ' 21+ years old ', ' Adult Human ', ' adulthood ', ' Algorithms ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Classification ', ' Systematics ', ' Clinical Trials ', ' Communities ', ' Computers ', ' Cross-Sectional Studies ', ' Cross Sectional Analysis ', ' Cross-Sectional Analyses ', ' Cross-Sectional Survey ', ' Disease Frequency Surveys ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Ethics ', ' ethical ', ' Goals ', ' Language ', ' Language Tests ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Linguistics ', ' Linguistic ', ' Longitudinal Studies ', ' long-term study ', ' longitudinal outcome studies ', ' longterm study ', ' Magnetic Resonance Imaging ', ' MR Imaging ', ' MR Tomography ', ' MRI ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' NMR Imaging ', ' NMR Tomography ', ' Nuclear Magnetic Resonance Imaging ', ' Zeugmatography ', ' Memory ', ' Mentorship ', ' Neurology ', ' Neuropsychological Tests ', ' Neuropsychologic Tests ', ' Neuropsychology ', ' Neuropsychologies ', ' neuropsychologic ', ' Patients ', ' Primary Health Care ', ' Primary Care ', ' Primary Healthcare ', ' Quality of life ', ' QOL ', ' Research ', ' Speech ', ' Standardization ', ' Technology ', ' Testing ', ' Time ', ' Measures ', ' Caregivers ', ' Care Givers ', ' Advisory Committees ', ' Task Forces ', ' advisory team ', ' base ', ' improved ', ' morphometry ', ' Area ', ' Clinical ', ' Variant ', ' Variation ', ' Biological ', ' Ensure ', ' Evaluation ', ' Screening procedure ', ' screening tools ', ' Training ', ' Intuition ', ' Individual ', ' Fostering ', ' Development Plans ', ' fluid ', ' liquid ', ' Liquid substance ', ' tool ', ' Frontal Temporal Dementia ', ' front temporal dementia ', ' frontal lobe dementia ', ' fronto-temporal dementia ', ' fronto-temporal lobar dementia ', ' frontotemporal lobar dementia ', ' frontotemporal lobe degeneration associated with dementia ', ' Frontotemporal Dementia ', ' Cognitive Disturbance ', ' Cognitive Impairment ', ' Cognitive decline ', ' Cognitive function abnormal ', ' Disturbance in cognition ', ' cognitive dysfunction ', ' cognitive loss ', ' Impaired cognition ', ' Diagnostic ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Investigation ', ' Diagnostic Method ', ' Diagnostic Technique ', ' Diagnostic Procedure ', ' Clinic ', ' Techniques ', ' Amentia ', ' Dementia ', ' Neurocognitive ', ' early detection ', ' Early Diagnosis ', ' experience ', ' Performance ', ' success ', ' cohort ', ' tech development ', ' technology development ', ' trait ', ' skills ', ' neuro-imaging ', ' neuroimaging ', ' novel ', ' Participant ', ' novel technologies ', ' new technology ', ' Position ', ' Positioning Attribute ', ' career development ', ' neuropsychiatric ', ' neuropsychiatry ', ' Accent ', ' Effectiveness ', ' Address ', ' Consent ', ' Diagnostic Sensitivity ', ' Disease Marker ', ' Reproducibility ', ' Cognitive ', ' Enrollment ', ' enroll ', ' Preparation ', ' Characteristics ', ' Development ', ' developmental ', ' Image ', ' imaging ', ' design ', ' designing ', ' Outcome ', ' cost effective ', ' Population ', ' Prevalence ', ' prospective ', ' Impairment ', ' clinical application ', ' clinical applicability ', ' novel therapeutics ', ' new drug treatments ', ' new drugs ', ' new therapeutics ', ' new therapy ', ' next generation therapeutics ', ' novel drug treatments ', ' novel drugs ', ' novel therapy ', ' novel diagnostics ', ' new diagnostics ', ' next generation diagnostics ', ' Alzheimer disease screening ', ' Alzheimer screening ', ' aging population ', ' aged population ', ' population aging ', ' healthy aging ', ' primary outcome ', ' clinical practice ', ' screening ', ' mild cognitive impairment ', ' mild cognitive disorder ', ' Computational Linguistics ', ' neurocognitive disorder ', ' accurate diagnosis ', "" Alzheimer's disease pathology "", ' AD pathology ', "" Alzheimer's pathology "", ' imaging biomarker ', ' imaging marker ', ' imaging-based biological marker ', ' imaging-based biomarker ', ' imaging-based marker ', ' diagnostic biomarker ', ' diagnostic marker ', ' recruit ', ' care providers ', ' primary care provider ', ' patient screening ', ' machine learning algorithm ', ' machine learned algorithm ', "" Alzheimer's disease diagnosis "", "" Alzheimer's diagnosis "", "" Alzheimer's disease patient "", "" Alzheimer's patient "", ' Rapid screening ', ' Dementia with Lewy Bodies ', ' ']",NIA,UNIVERSITY OF COLORADO DENVER,K23,2021,188298
"The role of amplitude modulation in perceiving speech and music Project Summary/Abstract  My career goal is to become a leading researcher on cognitive neuroscience, with a special focus on the neural mechanisms underlying auditory perception, including how humans track and perceive the fleeting audi- tory information in speech and music. In this proposal, I outline a research program to investigate the acoustic and neural distinctions between speech and music, two specialized forms of auditory signals that are closely tied to the human mind. Despite our increasingly rich understanding of the perceptual and neural mechanisms for processing speech or music, surprisingly little is known about why and how they are treated as different au- ditory signals by the human mind and brain in the first place. Investigating these distinctions is foundational for a thorough understanding of how acoustic waveforms are transformed into meaningful information. The work will provide a more solid basis for understanding cognition and communication as well as treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.  I hypothesize that the temporal structure reflected in the amplitude modulation (AM) of speech and music signals is a critical distinctive feature for the brain and engages to different processing pathways, as speech and music are known to have distinct AM rates. A series of studies, combining psychophysics, MEG (magne- toencephalography), fMRI (functional magnetic resonance imaging), and machine learning approaches, will use stimuli with AM rates across the modulation frequency ranges of speech and music to address this topic at the computational (the goals), algorithmic (the representations and operations), and implementational (neural mechanism) levels. (1) Does the AM rate of a sound affect whether it will be perceived as speech or music? (2) Does the AM rate of a stimulus optimize speech and music perceptual performance at different frequencies? (3) What are the underlying neural mechanisms and the associated brain regions implementing the differentiation of speech and music? Aim 1 investigates whether the AM rate of a sound conditions it to be processed as speech or music. By manipulating the AM rate of noise-vocoded speech and music recordings, I hypothesize that the sounds with slower or faster AM rates will likely to be perceived as music or speech, respectively, the perceptual judgment will be biased by the higher or lower spectral energy of neural oscillatory activity (meas- ured by MEG) while listening to the sounds, respectively, and the associated brain regions will be revealed by fMRI with machine learning decoding approaches. Aim 2 investigates whether the AM rate of stimuli optimizes speech and music perceptual performances at different rates. I hypothesize that the music perceptual perfor- mance is optimal at slower AM rates while the speech perceptual performance is optimal at faster AM rates, and the neural oscillatory entrainment at lower or higher frequency band has domain-specific function facilitat- ing speech or music perceptual performance. Project Narrative Speech and music are two specialized forms of auditory signal that are closely tied to human mind; however, despite our increasingly rich understanding of the perceptual and neural mechanisms of human processing of speech or music, surprisingly little is known how they are treated as different auditory signals by the human mind and brain at the first place. The current proposal aims to investigate the fundamental differences between speech and music at the acoustic, perceptual, and neural levels, by combining psychophysics, neuroimaging, and machine learning approaches. Investigating their distinctions is crucial for understanding how acoustic waveforms are transformed into meaningful information, and it will provide the basis for understanding and treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.",The role of amplitude modulation in perceiving speech and music,10118008,F32DC018205,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Aphasia ', ' Alogia ', ' Anepia ', ' Logagnosia ', ' Logamnesia ', ' Logasthenia ', ' Auditory area ', ' Auditory Cortex ', ' Auditory Perception ', ' hearing perception ', ' sound perception ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Cognition ', ' Communication ', ' Foundations ', ' Goals ', ' Human ', ' Modern Man ', ' Judgment ', ' Linguistics ', ' Linguistic ', ' Magnetoencephalography ', ' MEG imaging ', ' magnetoencephalographic imaging ', ' Music ', ' Noise ', ' Perception ', ' Periodicity ', ' Cyclicity ', ' Rhythmicity ', ' Psychophysics ', ' psychophysical ', ' Records ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Role ', ' social role ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Work ', ' Measures ', ' career ', ' Solid ', ' Series ', ' insight ', ' Stimulus ', ' machine learned ', ' Machine Learning ', ' Functional MRI ', ' fMRI ', ' Functional Magnetic Resonance Imaging ', ' programs ', ' Frequencies ', ' Auditory ', ' System ', ' Performance ', ' neural ', ' relating to nervous system ', ' Structure ', ' neuro-imaging ', ' neuroimaging ', ' Participant ', ' Brain region ', ' Address ', ' Data ', ' Process ', ' Behavioral ', ' Pathway interactions ', ' pathway ', ' Mind ', ' neuromechanism ', ' neural mechanism ', ' cognitive neuroscience ', ' speech processing ', ' operation ', ' non-invasive imaging ', ' noninvasive imaging ', ' spectral energy ', ' spectrum energy ', ' experimental study ', ' experiment ', ' experimental research ', ' auditory processing ', ' individuals with autism spectrum disorder ', ' autistic individuals ', ' individuals with ASD ', ' individuals with autism ', ' people with ASD ', ' people with autism ', ' people with autism spectrum disorder ', ' ']",NIDCD,NEW YORK UNIVERSITY,F32,2021,65994
"Algorithmic Classification of Paraphasias Project Summary This application’s parent grant, R01DC015999, is focused on the development of automated systems for identifying and categorizing paraphasic speech errors in language samples from individuals with post-stroke aphasia, both in the context of confrontation naming tests as well as in connected speech. Current approaches require that language samples be manually transcribed, which is both time-consuming and error-prone, and limits the clinical applicability of the technology. Since the parent grant was written, there have been major improvements in automatic speech recognition (ASR) technology, and it may soon be possible to automate this transcription step. This would open many new avenues for applying automated systems of the sort developed under the parent grant, both in clinical and research settings. However, these promising new ASR techniques depend on large and carefully-annotated datasets, of the sort that do not exist currently for aphasic speech. Under this administrative supplement, we propose to address this issue by performing an extensive campaign of transcription and detailed annotation of an already-existing publicly-available library of audio recordings of aphasic speech, including both structured naming tests and discourse samples. In addition to phonemic transcription of utterances themselves, we will annotate other features of aphasic speech (false starts, disfluencies, etc.) so as to support the development of automated algorithms for analyzing such speech. Our interdisciplinary team of machine learning researchers and aphasiologists will collaborate closely to produce a curated dataset of the sort needed to develop, train, and evaluate modern machine learning techniques for speech recognition. Importantly, the resulting dataset will be documented and organized in a similar manner to other large-scale ASR datasets, and will be released publicly to both the clinical and machine learning communities. In order to raise awareness of the dataset (and of this problem space in general) within the machine learning community, we further propose to organize a shared evaluation task, in which participating teams will make use of our final dataset to build automated transcription systems for naming tests, which will be compared in a “bakeoff” setting. Project Narrative Patients who have experienced a stroke or other brain injury frequently experience anomia- a condition in which they are unable to produce words when speaking. Our parent R01's goal is to create a computerized system for detecting and characterizing an individual’s anomia, which will open the door to new ways of treating anomia and reduce clinical workload. In this administrative supplement, we will prepare a new dataset for use in training these computerized systems, and organize a shared task evaluation within the speech recognition community that will use this dataset.",Algorithmic Classification of Paraphasias,10411534,R01DC015999,"['Anomia ', ' Amnesic Aphasia ', ' Anomic Aphasia ', ' Anomic Dysphasia ', ' Dysnomia ', ' Nominal Aphasia ', ' Nominal Dysphasia ', ' Aphasia ', ' Alogia ', ' Anepia ', ' Logagnosia ', ' Logamnesia ', ' Logasthenia ', ' Awareness ', ' Clinical Research ', ' Clinical Study ', ' Communities ', ' Goals ', ' Language ', ' Libraries ', ' Manuals ', ' Modernization ', ' Names ', ' Parents ', ' Patients ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Speech ', ' Stroke ', ' Apoplexy ', ' Brain Vascular Accident ', ' Cerebral Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebrovascular Stroke ', ' brain attack ', ' cerebral vascular accident ', ' cerebrovascular accident ', ' Technology ', ' Testing ', ' Time ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Workload ', ' Work Load ', ' Data Set ', ' Dataset ', ' Clinical ', ' Evaluation ', ' Training ', ' Individual ', ' Brain Injuries ', ' Acquired brain injury ', ' brain damage ', ' brain-injured ', ' machine learned ', ' Machine Learning ', ' Techniques ', ' System ', ' experience ', ' speech recognition ', ' Structure ', ' Sampling ', ' Address ', ' Administrative Supplement ', ' Development ', ' developmental ', ' post stroke ', ' after stroke ', ' poststroke ', ' computerized ', ' Consumption ', ' clinical application ', ' clinical applicability ', ' parent grant ', ' Algorithmic Analysis ', ' Algorithmic Analyses ', ' Analyses of Algorithms ', ' Analysis of Algorithms ', ' learning community ', ' automated speech recognition ', ' automatic speech recognition ', ' stroke-induced aphasia ', ' aphasia due to stroke ', ' aphasia following stroke ', ' poststroke aphasia ', ' stroke aphasia ', ' stroke survivor with aphasia ', ' classification algorithm ', ' automated algorithm ', ' automatic algorithm ', ' ']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,294197
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,10064139,R01DC012048,"['Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Environment ', ' Goals ', ' Hearing ', ' Hearing Aids ', ' assistive hearing device ', ' assistive listening device ', ' hearing amplification ', ' hearing assistance ', ' hearing assistive device ', ' hearing device ', ' Laboratories ', ' Masks ', ' Methods ', ' Modernization ', ' Noise ', ' Recurrence ', ' Recurrent ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Supervision ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Voice ', ' Work ', ' segregation ', ' Racial Segregation ', ' base ', ' improved ', ' Surface ', ' Chronic ', ' Training ', ' Individual ', ' Investigation ', ' Frequencies ', ' Auditory ', ' Complex ', ' Source ', ' Techniques ', ' System ', ' American ', ' success ', ' Structure ', ' Modeling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' Hearing Loss ', ' Hypoacuses ', ' Hypoacusis ', ' dysfunctional hearing ', ' hearing defect ', ' hearing deficit ', ' hearing difficulty ', ' hearing disability ', ' hearing dysfunction ', ' hearing impairment ', ' Address ', ' Symptoms ', ' Data ', ' digital ', ' design ', ' designing ', ' innovation ', ' innovate ', ' innovative ', ' Network-based ', ' real world application ', ' combat ', ' signal processing ', ' network architecture ', ' Formulation ', ' experimental study ', ' experiment ', ' experimental research ', ' deep neural network ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' deep learning ', ' microphone ', ' supervised learning ', ' supervised machine learning ', ' Auditory Prosthesis ', ' hearing prosthesis ', ' normal hearing ', ' good hearing ', ' healthy hearing ', ' speech in noise ', ' hearing in noise ', ' speech in background noise ', ' speech in speech recognition ', ' speech recognition in noise ', ' ']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,301954
"A Wireless micro-ECoG Prosthesis for Speech Project Summary / Abstract Patients who suffer from debilitating neuromuscular disorders (e.g. amyotrophic lateral sclerosis – ALS, Locked- in-Syndrome – LIS, and muscular dystrophies/myopathies) have difficulty or an inability to communicate through speech leading to a detrimental loss in quality of life. Current technology using eye movements and signals/spellers from electroencephalography (EEG) are slow and inconsistent. Neural prostheses offer an opportunity to produce fast and accurate communication for patients suffering from neuromuscular disorders, but success for regaining speech has been limited due to technological limitations: there is an inability to capture the high dimensionality of the brain and an inability to record in naturalistic conditions using fully implanted, wireless electrode arrays. To solve these challenges, we develop and optimize custom wireless micro- electrocorticographic (µECoG) arrays with over 1,000 channels to decode speech directly from the human brain. We will accomplish this by 1) Testing and optimizing the spatial resolution of µECoG to capture neural signals, 2) Fine-tune our machine learning algorithms to decode speech directly from the brain and 3) developing wireless technology to enable neural prosthetic usage in naturalistic settings. High-density, high channel-count neural interfaces will offer an unprecedented ability to decode speech from the human brain. This ability combined with wireless technology, will allow for a new generation of speech neural prostheses. Project Narrative This project seeks to design, test, and optimize a novel wireless recording array for a neural speech prosthetic. Patients with various types of motor disorders such as Amyotrophic lateral sclerosis (ALS) and Locked-in- Syndrome (LOS) can have difficulty or an inability to communicate. We aim to restore this ability by reading signals directly from the brain and translating them into speech. We will design and test novel high density, high channel-count electrodes to read from the brain at an unprecedented spatial scale. We will also develop wireless technology to enable this speech translation during everyday usage. With our advanced technology for reading the brain, we aim to literally give a voice to the voiceless.",A Wireless micro-ECoG Prosthesis for Speech,10375951,R01DC019498,"['Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', "" Gehrig's Disease "", ' Lou Gehrig Disease ', ' Auditory area ', ' Auditory Cortex ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Communication ', ' Electrodes ', ' Electroencephalography ', ' EEG ', ' Environment ', ' Eye Movements ', ' Family ', ' Health Personnel ', ' Health Care Providers ', ' Healthcare Providers ', ' Healthcare worker ', ' health care personnel ', ' health care worker ', ' health provider ', ' health workforce ', ' healthcare personnel ', ' medical personnel ', ' treatment provider ', ' Human ', ' Modern Man ', ' Locked-In Syndrome ', ' Maps ', ' Motor Cortex ', ' Myopathy ', ' Muscle Disease ', ' Muscle Disorders ', ' Muscular Diseases ', ' Myopathic Conditions ', ' Myopathic Diseases and Syndromes ', ' Myopathic disease or syndrome ', ' muscular disorder ', ' Muscular Dystrophies ', ' Myodystrophica ', ' Myodystrophy ', ' muscle dystrophy ', ' Neuromuscular Diseases ', ' myoneural disorder ', ' neuromuscular degenerative disorder ', ' neuromuscular disorder ', ' Patients ', ' Quality of life ', ' QOL ', ' Reading ', ' Research ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Translations ', ' Voice ', ' Work ', ' Friends ', ' Generations ', ' Measures ', ' Custom ', ' Prosthesis ', ' Prosthetic device ', ' Prosthetics ', ' density ', ' improved ', ' brain surgery ', ' Area ', ' Clinical ', ' Training ', ' motor disorder ', ' motor disease ', ' motor dysfunction ', ' machine learned ', ' Machine Learning ', ' Life ', ' Auditory ', ' Techniques ', ' Prevent infection ', ' Infection prevention ', ' Performance ', ' success ', ' neural prosthetic ', ' neural prosthesis ', ' neural ', ' relating to nervous system ', ' Nerve Impulse Transmission ', ' Nerve Transmission ', ' Neuronal Transmission ', ' axon signaling ', ' axon-glial signaling ', ' axonal signaling ', ' glia signaling ', ' glial signaling ', ' nerve signaling ', ' neural signaling ', ' neuronal signaling ', ' neurotransmission ', ' novel ', ' Regaine ', ' Rogaine ', ' Modeling ', ' Sampling ', ' Vectra ', ' liquid crystal polymer ', ' Address ', ' Data ', ' Resolution ', ' Wireless Technology ', ' wireless ', ' Development ', ' developmental ', ' reconstruction ', ' design ', ' designing ', ' Consumption ', ' Implant ', ' reading ability ', ' reading achievement ', ' reading competence ', ' reading proficiency ', ' signal processing ', ' high dimensionality ', ' machine learning algorithm ', ' machine learned algorithm ', ' infection risk ', ' ']",NIDCD,DUKE UNIVERSITY,R01,2021,655596
"CRCNS: Avian Model for Neural Activity Driven Speech Prostheses Understanding the physical, computational, and theoretical bases of human vocal communication, speech, is crucial to improved comprehension of voice, speech and language diseases and disorders, and improving their diagnosis, treatment and prevention. Meeting this challenge requires knowledge of the neural and sensorimotor mechanisms of vocal motor control. Our project will directly investigate the neural and sensorimotor mechanisms involved in the production of complex, natural, vocal communication signals. Our results will directly enhance brain-computer interface technology for communication and will accelerate the development of prostheses and other assistive/augmentative technologies for individuals with communications deficits due to injury or disease. We will develop a vocal prosthetic that directly translates neural signals in cortical sensorimotor and vocal-motor control regions into vocal communication signals output in real-time. Building on success using non-human primates for brain computer interfaces for general motor control, the prosthetic will be developed in songbirds, whose acoustically rich, learned vocalizations share many features with human speech. Because the songbird vocal apparatus is functionally and anatomically similar to the human larynx, and the cortical regions that control it are closely analogous to speech motor-control areas of the human brain, songbirds offer an ideal model for the proposed studies. Beyond the application of our work to human voice and speech, development of the vocal prosthetic will enable novel speech-relevant studies in the songbird model that can reveal fundamental mechanisms of vocal learning and production. In the first stage of the project, we collect a large data set of simultaneously recorded neural activity and vocalizations. In stage two, we will apply machine learning and artificial intelligence techniques to develop algorithms that map neural recordings to vocal output and enable us to estimate intended vocalizations directly from neural data. In stage three, we will develop computing infrastructure to run these algorithms in real-time, predicting intended vocalizations from neural activity as the animal is actively producing these vocalizations. In stage four, we will test the effectiveness of the prosthetic by substituting the bird’s own vocalization with the output from our prosthetic system. Success will set the stage for testing of these technologies in humans and translation to multiple assistive devices. In addition to our research goals, the project will engage graduate, undergraduate, and high school students through the development of novel educational modules that introduce students to brain machine interface and multidisciplinary studies that span engineering and the basic sciences. Developing a vocal prosthesis will directly enhance brain-computer interface technology for communication and accelerate the development of prostheses and other assistive/augmentative technologies for individuals with communications deficits due to injury or disease. The basic knowledge of the neural and sensorimotor mechanisms of vocal motor control that we will acquire will impact understanding of multiple voice, speech, and language diseases and disorders. The techniques developed will enabling novel future studies of vocal production and development.",CRCNS: Avian Model for Neural Activity Driven Speech Prostheses,10408524,R01DC018446,"['Acoustics ', ' Acoustic ', ' Algorithms ', ' Anatomy ', ' Anatomic ', ' Anatomic Sites ', ' Anatomic structures ', ' Anatomical Sciences ', ' Animals ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Behavior ', ' Birds ', ' Aves ', ' Avian ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Communication ', ' Communities ', ' Complement ', ' Complement Proteins ', ' Data Collection ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Engineering ', ' Limb structure ', ' Extremities ', ' Limbs ', ' Non-Trunk ', ' Future ', ' Goals ', ' Human ', ' Modern Man ', ' indexing ', ' Language ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Maps ', ' Neurons ', ' Nerve Cells ', ' Nerve Unit ', ' Neural Cell ', ' Neurocyte ', ' neuronal ', ' Neurosciences ', ' Online Systems ', ' On-Line Systems ', ' online computer ', ' web based ', ' Production ', ' Research ', ' Running ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Computer software ', ' Software ', ' Software Tools ', ' Computer Software Tools ', ' Speech ', ' Students ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Translations ', ' Voice ', ' Work ', ' Self-Examination ', ' Self evaluation ', ' Self-Surveillance ', ' Self-reflection ', ' Data Set ', ' Dataset ', ' Comprehension ', ' Prosthesis ', ' Prosthetic device ', ' Prosthetics ', ' Injury ', ' injuries ', ' base ', ' improved ', ' Area ', ' Training ', ' Stimulus ', ' Individual ', ' nonhuman primate ', ' non-human primate ', ' Educational workshop ', ' Workshop ', ' Interdisciplinary Study ', ' Interdisciplinary Research ', ' Multidisciplinary Collaboration ', ' Multidisciplinary Research ', ' Measurement ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Hour ', ' Complex ', ' Techniques ', ' System ', ' vocalization ', ' Degenerative Neurologic Diseases ', ' Degenerative Neurologic Disorders ', ' Nervous System Degenerative Diseases ', ' Neural Degenerative Diseases ', ' Neural degenerative Disorders ', ' Neurodegenerative Diseases ', ' Neurologic Degenerative Conditions ', ' degenerative diseases of motor and sensory neurons ', ' degenerative neurological diseases ', ' neurodegenerative illness ', ' Neurodegenerative Disorders ', ' meetings ', ' brain control ', ' mind control ', ' Performance ', ' success ', ' neural prosthetic ', ' neural prosthesis ', ' cohort ', ' neural ', ' relating to nervous system ', ' Neural Development ', ' neurodevelopment ', ' Oscines ', ' song bird ', ' Songbirds ', ' Nerve Impulse Transmission ', ' Nerve Transmission ', ' Neuronal Transmission ', ' axon signaling ', ' axon-glial signaling ', ' axonal signaling ', ' glia signaling ', ' glial signaling ', ' nerve signaling ', ' neural signaling ', ' neuronal signaling ', ' neurotransmission ', ' novel ', ' member ', ' Basic Research ', ' Basic Science ', ' Prevention ', ' Modeling ', ' Speech Development ', ' vocal learning ', ' Brain region ', ' Data ', ' Motor ', ' Resource Sharing ', ' Collection ', ' Validation ', ' Development ', ' developmental ', ' Behavioral ', ' Metadata ', ' meta data ', ' Output ', ' virtual ', ' design ', ' designing ', ' Visualization software ', ' visualization tool ', ' Outcome ', ' brain computer interface ', ' brain machine interface ', ' neural model ', ' multidisciplinary ', ' open source ', ' functional restoration ', ' restore function ', ' restore functionality ', ' restore lost function ', ' prototype ', ' motor control ', ' parent project ', ' data sharing ', ' software repository ', ' undergraduate student ', ' undergrad ', ' undergraduate ', ' Learning Module ', ' Education Module ', ' Educational Module ', ' Teaching Module ', ' High School Student ', ' Secondary School Student ', ' Secondary Student ', ' webinar ', ' hackathon ', ' hack day ', ' hackfest ', ' terabyte ', ' FAIR principles ', ' FAIR data ', ' FAIR guiding principles ', ' Findable, Accessible, Interoperable and Re-usable ', ' Findable, Accessible, Interoperable, and Reusable ', ' Infrastructure ', ' data tools ', ' large scale data ', ' large scale data sets ', ' large scale datasets ', ' large datasets ', ' large data sets ', ' data exploration ', ' data reuse ', ' data re-use ', ' effectiveness testing ', ' data repository ', ' Data Banks ', ' Databanks ', ' data depository ', ' TRUST principles ', ' Transparency, Responsibility, User focus, Sustainability, and Technology ', ' Border Community ', ' Border City ', ' Border Town ', ' community based research ', ' community based design ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,219319
"Biofeedback-Enhanced Treatment for Speech Sound Disorder: Randomized Controlled Trial and Delineation of Sensorimotor Subtypes Project Summary/Abstract Children with speech sound disorder show diminished accuracy and intelligibility in spoken communication and may thus be perceived as less capable or intelligent than peers, with negative consequences for both socio- emotional and socioeconomic outcomes [1]–[3]. While most speech errors resolve by the late school-age years, between 2-5% of speakers exhibit residual speech sound disorder (RSSD) that persists through adoles- cence or even adulthood [4], [5], reflecting about 6 million cases in the US. In a series of experimental studies since 2013, our research team has demonstrated that treatment incorporating technologically-enhanced feed- back can improve speech production in individuals with RSSD who have not responded to previous interven- tion [6]–[10]. The primary objective of the parent award (R01 DC017476, “Biofeedback-Enhanced Treatment for Speech Sound Disorder”) is to conduct the first well-powered randomized controlled trial comparing tradi- tional vs biofeedback intervention for the most common type of RSSD, misarticulation of the English /r/ sound.  Treatment of RSSD could also be enhanced through the development of tools incorporating artificial intelligence/machine learning (AI/ML). Applications with automated scoring of speech sounds could in principle be used to augment clinician services and achieve higher-intensity practice for faster progress. However, no computerized treatment to date has demonstrated sufficient accuracy for clinical use with children [11]. Existing systems are limited primarily by the fact that publicly available speech corpora have very little representation of either children or individuals with speech impairments. This data scarcity represents a fundamental issue hin- dering advances in clinical applications of automatic speech recognition (ASR) [12]. The proposed sup- plement will address this barrier by modifying and augmenting PERCEPT (Perceptual Error Rating for the Clin- ical Evaluation of Phonetic Targets), an existing corpus of acoustic recordings of child speech assembled through the parent award and the investigators’ previous NIH-funded research since 2013. AI/ML applications of the augmented database are expected to have a twofold scientific impact. First, we anticipate direct benefits for children with RSSD affecting /r/, whose speech samples make up the majority of the current corpus. We will use our database to train a neural network to classify novel child productions containing /r/ as correct or incor- rect. This classifier could then be incorporated into AI tools to increase the efficacy of intervention for children with RSSD. Second, we anticipate that engineers working on the broader problem of ASR for child or clinical speech will be interested in using PERCEPT for model training, especially after the corpus is augmented with more diverse data, as proposed here. We expect to show that acoustic models generated with PERCEPT can improve the performance of currently available open-access speech recognition systems (e.g., Kaldi [13]) in recognition of novel child speech stimuli. The PERCEPT database will be made publicly available through part- nership with PhonBank, an NIH-funded data-sharing platform for speech research (e.g., [14]–[16]). Project Narrative Speech sound disorder in childhood poses a barrier to academic and social participation, with potentially life- long consequences for educational and occupational outcomes. The parent award aims to meet a public health need by conducting the first randomized controlled trial comparing the efficacy and efficiency of speech inter- vention with and without real-time visual biofeedback. The proposed supplement will lay groundwork for the development of automated speech recognition tools for speech sound disorder by modifying and augmenting an existing corpus of acoustic recordings of child speech in preparation for sharing with researchers in artificial intelligence and machine learning (AI/ML).",Biofeedback-Enhanced Treatment for Speech Sound Disorder: Randomized Controlled Trial and Delineation of Sensorimotor Subtypes,10412492,R01DC017476,"['Acoustics ', ' Acoustic ', ' Adolescence ', ' 12-20 years old ', ' adolescence (12-20) ', ' Adult ', ' 21+ years old ', ' Adult Human ', ' adulthood ', ' Affect ', ' Articulation Disorders ', ' Dysarticulation Disorders ', ' Misarticulation ', ' Phonological Impairments ', ' Phonology Impairment ', ' Speech Articulation Disorders ', ' Articulators ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Award ', ' Biofeedback ', ' Child ', ' 0-11 years old ', ' Child Youth ', ' Children (0-21) ', ' youngster ', ' Clinical Research ', ' Clinical Study ', ' Communication ', ' Decision Making ', ' Disease ', ' Disorder ', ' Engineering ', ' Exhibits ', ' Feedback ', ' Foundations ', ' Recording of previous events ', ' History ', ' Intelligence ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Learning ', ' Methods ', ' United States National Institutes of Health ', ' NIH ', ' National Institutes of Health ', ' Parents ', ' Perception ', ' Production ', ' Public Health ', ' Publishing ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Social isolation ', ' sound ', ' Speech ', ' Speech Sound ', ' Surveys ', ' Survey Instrument ', ' Technology ', ' Testing ', ' Time ', ' Tweens ', ' Ultrasonography ', ' Echography ', ' Echotomography ', ' Medical Ultrasound ', ' Ultrasonic Imaging ', ' Ultrasonogram ', ' Ultrasound Diagnosis ', ' Ultrasound Medical Imaging ', ' Ultrasound Test ', ' diagnostic ultrasound ', ' sonogram ', ' sonography ', ' sound measurement ', ' ultrasound ', ' ultrasound imaging ', ' ultrasound scanning ', ' Work ', ' Measures ', ' base ', ' sensory feedback ', ' improved ', ' Procedures ', ' Clinical ', ' Residual state ', ' Residual ', ' Series ', ' Link ', ' Training ', ' Childhood ', ' pediatric ', ' insight ', ' Stimulus ', ' Visual ', ' Individual ', ' Databases ', ' Data Bases ', ' data base ', ' School-Age Population ', ' school age ', ' Funding ', ' Randomized Controlled Trials ', ' tool ', ' machine learned ', ' Machine Learning ', ' Life ', ' bully ', ' bullying ', ' Auditory ', ' Oral ', ' Sensory ', ' System ', ' Occupational ', ' interest ', ' Services ', ' preference ', ' experience ', ' Performance ', ' speech recognition ', ' trait ', ' novel ', ' Participant ', ' peer ', ' Emotional ', ' Modeling ', ' Sampling ', ' response ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Address ', ' Age-Years ', ' Data ', ' Motor ', ' predict therapeutic response ', ' predict therapy response ', ' predict treatment response ', ' therapy prediction ', ' treatment prediction ', ' treatment response prediction ', ' Prediction of Response to Therapy ', ' randomisation ', ' randomization ', ' randomly assigned ', ' Randomized ', ' research clinical testing ', ' Clinical Evaluation ', ' Clinical Testing ', ' clinical test ', ' Enrollment ', ' enroll ', ' Preparation ', ' socioeconomics ', ' socio-economic ', ' socio-economically ', ' socioeconomically ', ' Development ', ' developmental ', ' computerized ', ' predictive modeling ', ' computer based prediction ', ' prediction model ', ' Treatment Efficacy ', ' intervention efficacy ', ' therapeutic efficacy ', ' therapy efficacy ', ' Outcome ', ' Population ', ' Prevalence ', ' Individual Differences ', ' Impairment ', ' somatosensory ', ' clinical application ', ' clinical applicability ', ' speech accuracy ', ' accurate speech ', ' trial comparing ', ' tool development ', ' visual information ', ' evidence base ', ' comparative efficacy ', ' compare efficacy ', ' personalized learning ', ' predicting response ', ' prediction of response ', ' predictive response ', ' predictor of response ', ' response prediction ', ' responders and non-responders ', ' responders from non-responders ', ' responders or non-responders ', ' responders versus non-responders ', ' responders vs non-responders ', ' social engagement ', ' social involvement ', ' social participation ', ' experimental study ', ' experiment ', ' experimental research ', ' recruit ', ' Biofeedback Training ', ' Biofeedback Approach ', ' Biofeedback Therapy ', ' Biofeedback Treatment ', ' neural network ', ' automated speech recognition ', ' automatic speech recognition ', ' diverse data ', ' data diversity ', ' sharing platform ', ' ']",NIDCD,NEW YORK UNIVERSITY,R01,2021,268779
"Training program in the neurology of language and neurodegenerative aphasias This K24 grant renewal is requested to support the mentoring activities of Dr. Maria Luisa Gorno Tempini, a behavioral neurologist and cognitive neuroscientist. Dr. Gorno Tempini is a leading researcher and clinician in the fields of neurology and the neuroscience of language, with specific expertise in atypical neurodegenerative diseases that present as speech and language disorders. She mentors a talented group of clinicians and researchers to study and treat Primary Progressive Aphasia (PPA) and investigate the neural basis of language. Dr. Gorno Tempini has a proven track record of success in mentoring both clinicians and scientists in patient- oriented research (POR) related to speech and language disorders. The goals of this proposal are to support time for Dr. Gorno Tempini to mentor a growing number of increasingly diverse clinicians and researchers interested in neurodegenerative language disorders, to extend her impact as a mentor at UCSF, and to pursue novel lines of research in PPA. Leveraging the resources available at the UCSF Memory and Aging Center (MAC), the Global Brain Health Institute, and the UCSF Clinical and Translational Science Institute, she will mentor clinicians, faculty, postdoctoral scholars, and scientists with particular attention to cultivating diversity, equity, and inclusion in her laboratory, the university, and the profession at large. She will sustain her comprehensive mentoring system that features one-on-one mentoring, supervision of clinicians in patient diagnosis and care, and group mentoring activities. She will update and extend that system with opportunities for training with colleagues in speech and data science and a focus on mentoring more advanced junior colleagues as emerging mentors themselves. Dr. Gorno Tempini's experience in basic cognitive neuroscience and neurological methodologies and her increasingly nuanced leadership expertise uniquely position her to benefit a diverse group of trainees. The research project proposed here will develop automatic, efficient, and objective methods to measure speech production in PPA. The study will apply acoustic analysis scripts and automatic speech recognition to five minutes of audio recordings collected from 500 well-characterized PPA patients and employ dynamic speech MRI to identify anatomical biomarkers of vocal tract movements corresponding to speech articulation errors. This will lead to earlier detection of speech deficits; improved characterization of clinical syndromes; and more detailed, objective, and efficient outcome measures to track progression and, in the future, response to treatment. Machine learning analyses of acoustic measures and imaging data collected through other MAC projects will provide novel tools for prediction of post-mortem pathology and new knowledge on the neural basis of speech. This grant will be instrumental in supporting the pursuit of Dr. Gorno Tempini's goals to mentor the next generation of clinician scientists in the neurology of language and neurodegenerative aphasias. In our previous K24 cycle, Dr Gorno Tempini expanded and formalized her POR mentoring and undertook novel research into the susceptibility of the language system to neurodegeneration. This proposed renewal will train the next generation of clinician scientists in language disorders and neurodegenerative disease through didactics, group, and one on one mentoring sessions. The research project will develop novel automated and imaging measures of speech production impairments in PPA.",Training program in the neurology of language and neurodegenerative aphasias,10216095,K24DC015544,"['Acoustics ', ' Acoustic ', ' Aging ', ' Air ', ' Algorithms ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Anatomy ', ' Anatomic ', ' Anatomic Sites ', ' Anatomic structures ', ' Anatomical Sciences ', ' Anomia ', ' Amnesic Aphasia ', ' Anomic Aphasia ', ' Anomic Dysphasia ', ' Dysnomia ', ' Nominal Aphasia ', ' Nominal Dysphasia ', ' Aphasia ', ' Alogia ', ' Anepia ', ' Logagnosia ', ' Logamnesia ', ' Logasthenia ', ' Attention ', ' Autopsy ', ' necropsy ', ' postmortem ', ' Behavior Therapy ', ' Behavior Conditioning Therapy ', ' Behavior Modification ', ' Behavior Treatment ', ' Behavioral Conditioning Therapy ', ' Behavioral Modification ', ' Behavioral Therapy ', ' Behavioral Treatment ', ' Conditioning Therapy ', ' behavior intervention ', ' behavioral intervention ', ' Biomechanics ', ' biomechanical ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Communication ', ' Corpus striatum structure ', ' Corpus Striatum ', ' Striate Body ', ' Striatum ', ' striatal ', ' Cessation of life ', ' Death ', ' Diagnosis ', ' Differential Diagnosis ', ' Disease ', ' Disorder ', ' Faculty ', ' Future ', ' Goals ', ' Grant ', ' Institutes ', ' Laboratories ', ' Language ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Leadership ', ' Learning ', ' Magnetic Resonance Imaging ', ' MR Imaging ', ' MR Tomography ', ' MRI ', ' Medical Imaging, Magnetic Resonance / Nuclear Magnetic Resonance ', ' NMR Imaging ', ' NMR Tomography ', ' Nuclear Magnetic Resonance Imaging ', ' Zeugmatography ', ' Memory ', ' Mentors ', ' Methods ', ' Methodology ', ' Movement ', ' body movement ', ' Nerve Degeneration ', ' Neuron Degeneration ', ' neural degeneration ', ' neurodegeneration ', ' neurodegenerative ', ' neurological degeneration ', ' neuronal degeneration ', ' Neurology ', ' Neurosciences ', ' Pathology ', ' Patients ', ' Peer Review ', ' Phenotype ', ' Production ', ' Publications ', ' Scientific Publication ', ' Reading ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Resources ', ' Research Resources ', ' Semantics ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Sound ', ' Supervision ', ' Syndrome ', ' Talents ', ' Technology ', ' Time ', ' Tissues ', ' Body Tissues ', ' Training Programs ', ' Universities ', ' Measures ', ' tau Proteins ', ' MT-bound tau ', ' microtubule bound tau ', ' microtubule-bound tau ', ' tau ', ' tau factor ', ' τ Proteins ', ' Outcome Measure ', ' Caring ', ' improved ', ' Left ', ' Anterior ', ' Site ', ' Area ', ' Clinical ', ' Variant ', ' Variation ', ' Neurologic ', ' Neurological ', ' Evaluation ', ' Predisposition ', ' Susceptibility ', ' Training ', ' Neurologist ', ' Measurement ', ' Disease Progression ', ' Research Project Grants ', ' R-Series Research Projects ', ' R01 Mechanism ', ' R01 Program ', ' Research Grants ', ' Research Projects ', ' Primary Progressive Aphasia ', ' Mesulam Syndrome ', ' Shapes ', ' Atrophy ', ' Atrophic ', ' Pathologist ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Scientist ', ' Severities ', ' Parietal ', ' Pattern ', ' Techniques ', ' System ', ' Amentia ', ' Dementia ', ' Degenerative Neurologic Diseases ', ' Degenerative Neurologic Disorders ', ' Nervous System Degenerative Diseases ', ' Neural Degenerative Diseases ', ' Neural degenerative Disorders ', ' Neurodegenerative Diseases ', ' Neurologic Degenerative Conditions ', ' degenerative diseases of motor and sensory neurons ', ' degenerative neurological diseases ', ' neurodegenerative illness ', ' Neurodegenerative Disorders ', ' interest ', ' early detection ', ' Early Diagnosis ', ' experience ', ' molecular pathology ', ' success ', ' phonology ', ' cohort ', ' neural ', ' relating to nervous system ', ' Structure ', ' neuro-imaging ', ' neuroimaging ', ' novel ', ' Basic Research ', ' Basic Science ', ' Position ', ' Positioning Attribute ', ' Frontotemporal Lobar Degenerations ', ' Sampling ', ' response ', ' patient oriented study ', ' patient oriented research ', ' Pharmaceutical Agent ', ' Pharmaceuticals ', ' Pharmacological Substance ', ' Pharmacologic Substance ', ' Data ', ' Motor ', ' Clinical Sciences ', ' Cognitive ', ' Enrollment ', ' enroll ', ' Functional Imaging ', ' Physiologic Imaging ', ' physiological imaging ', ' Pharmacological Treatment ', ' Translational Research ', ' Translational Science ', ' translation research ', ' Update ', ' Pathologic ', ' Monitor ', ' Characteristics ', ' Molecular ', ' Behavioral ', ' Image ', ' imaging ', ' treatment trial ', ' shape analysis ', ' shape description ', ' next generation ', ' cognitive neuroscience ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' treatment response ', ' response to treatment ', ' therapeutic response ', ' Biological Markers ', ' bio-markers ', ' biologic marker ', ' biomarker ', ' constriction ', ' brain circuitry ', ' training opportunity ', ' Data Science ', ' brain health ', ' Articulation ', ' machine learning algorithm ', ' machine learned algorithm ', ' automated speech recognition ', ' automatic speech recognition ', ' automated analysis ', ' real-time images ', ' realtime image ', ' diversity and equity ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K24,2021,188829
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.   There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,10087511,R01DC006859,"['Acoustics ', ' Acoustic ', ' Affect ', ' Attention ', ' Communication impairment ', ' Communication Disorders ', ' Communicative Disorders ', ' Cues ', ' Dysarthria ', ' Dysarthosis ', ' Ear ', ' Goals ', ' Gold ', ' Grant ', ' Health Services Accessibility ', ' Access to Care ', ' access to health services ', ' access to services ', ' access to treatment ', ' accessibility to health services ', ' availability of services ', ' care access ', ' health service access ', ' health services availability ', ' service availability ', ' treatment access ', ' Judgment ', ' Language ', ' Learning ', ' Theoretical model ', ' Theoretic Models ', ' nervous system disorder ', ' Nervous System Diseases ', ' Neurologic Disorders ', ' Neurological Disorders ', ' neurological disease ', ' Noise ', ' Patient Monitoring ', ' Patients ', ' Perception ', ' Periodicity ', ' Cyclicity ', ' Rhythmicity ', ' Research ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech-Language Pathology ', ' Speech Perception ', ' Technology ', ' Testing ', ' Time ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Work ', ' Measures ', ' Speech Pathology ', ' Outcome Measure ', ' Caring ', ' Custom ', ' base ', ' Loudness ', ' improved ', ' Area ', ' Clinical ', ' Evaluation ', ' Training ', ' Stimulus ', ' Individual ', ' Disease Progression ', ' Educational Intervention ', ' Education for Intervention ', ' Instruction Intervention ', ' Training Intervention ', ' instructional intervention ', ' Pathologist ', ' tool ', ' Knowledge ', ' Adopted ', ' Dimensions ', ' Frequencies ', ' Severities ', ' Complex ', ' Stream ', ' Source ', ' Pattern ', ' Country ', ' phrases ', ' novel ', ' Participant ', ' Nervous System Injuries ', ' Nervous System damage ', ' Neurological Damage ', ' Neurological Injury ', ' Neurological trauma ', ' neurotrauma ', ' Nervous System Trauma ', ' Coding System ', ' Code ', ' Modeling ', ' Sampling ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' disparity in health ', ' health disparity ', ' Data ', ' Motor ', ' Clinical Assessment Tool ', ' Cognitive ', ' Update ', ' Validation ', ' Process ', ' Instruction ', ' predictive modeling ', ' computer based prediction ', ' prediction model ', ' Outcome ', ' Population ', ' lexical ', ' standard of care ', ' clinical practice ', ' signal processing ', ' outcome prediction ', ' predictive outcomes ', ' predictors of outcomes ', ' recruit ', ' optimal treatments ', ' optimal therapies ', ' machine learning algorithm ', ' machine learned algorithm ', ' speech in noise ', ' hearing in noise ', ' speech in background noise ', ' speech in speech recognition ', ' speech recognition in noise ', ' Computer Models ', ' Computerized Models ', ' computational modeling ', ' computational models ', ' computer based models ', ' computerized modeling ', ' ']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2021,305399
"A Specialized Automatic Speech Recognition and Conversational Platform to Enable Socially Assistive Robots for Persons with Mild-to-Moderate Alzheimer's Disease and Related Dementia Abstract 1 in 3 seniors in the United States dies with dementia, of which Alzheimer’s disease (AD) is the most common form. AD patients suffer from decreased ability to meaningfully communicate and interact, which causes significant stress and burden for both professional caregivers and family members. Socially assistive robots (SARs) have been designed to promote therapeutic interaction and communication. Unfortunately, artificial intelligence (AI) has long been challenged by the speech of elderly persons, who exhibit age-related voice tremors, hesitations, imprecise production of consonants, increased variability of fundamental frequency, and other barriers that can be exacerbated by the neurological changes associated with AD, further complicated by common environmental noises such as the ceiling fan, television, etc. Because of the resulting poor real-world speech and language understanding by available SAR technologies, scarce human caregivers are often required to guide AD patients through SAR interactions, limiting SARs to small deployments, mostly as part of research studies. Unlike existing approaches relying purely on AI, care.coach™ is developing a SAR-like avatar that converses with elderly and AD patients through truly natural speech. Each avatar is controlled by a 24x7 team of trained human staff who can cost-effectively monitor and engage 12 or more patients sequentially (2 simultaneously) through the audio/visual feeds from the patient’s avatar device. The staff communicate with each patient by sending text commands which are converted into the avatar’s voice through a speech synthesis engine. The staff contribute to the system their human abilities for speech and natural language processing (NLP) and for generating free-form conversational responses to help patients build personal relationships with the avatar. The staff are guided by a software-driven expert system embedded into their work interface, which is programmed with evidence-based prompting and protocols to support healthy behaviors and self-care. This SBIR Fast-Track project will leverage the unique data generated by our human- in-the-loop platform to develop new ASR capabilities, enabling fully automatic conversational protocols to engage and support AD patients without human intervention. We aim in Phase I to leverage our unique prior work dataset to train an automatic speech recognition (ASR) engine to enable the understanding of certain types of elderly and AD patient speech more successfully than any currently available engine. We aim in Phase II to incorporate this new engine along with an NLP module into our existing human-in-the-loop avatar system, recruiting a population of AD patients to further train and validate with during a 2-year human subjects study so that we can demonstrate full automation of a significant portion of our avatar conversations with mild- to-moderate level AD patients. Thus, we will improve the commercial scalability of our avatars, while validating our new ASR/NLP engine as the most accurate platform for enabling the next generation of AD-focused SARs. Narrative Artificial intelligence (AI) has long been challenged by the speech of elderly persons, and especially persons with dementia, due to age-related voice tremors, hesitations, imprecise production of consonants, increased variability of fundamental frequency, and other barriers. Unlike existing approaches to socially assistive robots (SARs) relying purely on limited AI for conversation, care.coach™ has been commercializing a SAR-like avatar that converses with elderly and AD patients through truly natural speech, powered by a 24x7 team of trained human staff. The unique data sets that our solution enables us to gather at commercial scale will be leveraged in this SBIR project to develop an automatic speech recognition (ASR) and natural language processing (NLP) engine that is best-in-class for AD applications, improving the commercial scalability of our avatars by reducing our dependence on human staff, while serving as a new AI platform for enabling the next generation of AD- focused, conversational SARs.",A Specialized Automatic Speech Recognition and Conversational Platform to Enable Socially Assistive Robots for Persons with Mild-to-Moderate Alzheimer's Disease and Related Dementia,10263325,R44AG062014,"['Age ', ' ages ', ' Elderly ', ' advanced age ', ' elders ', ' geriatric ', ' late life ', ' later life ', ' older adult ', ' older person ', ' senior citizen ', "" Alzheimer's Disease "", ' AD dementia ', ' Alzheimer ', ' Alzheimer Type Dementia ', ' Alzheimer disease ', ' Alzheimer sclerosis ', ' Alzheimer syndrome ', "" Alzheimer's "", "" Alzheimer's disease dementia "", ' Alzheimers Dementia ', ' Alzheimers disease ', ' Primary Senile Degenerative Dementia ', ' dementia of the Alzheimer type ', ' primary degenerative dementia ', ' senile dementia of the Alzheimer type ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Automation ', ' Behavior ', ' Clinical Research ', ' Clinical Study ', ' Communication ', ' Computers ', ' Delirium ', ' delirious ', ' Disease ', ' Disorder ', ' Exhibits ', ' Expert Systems ', ' Intelligent systems ', ' Family ', ' Goals ', ' Hospitals ', ' Community Hospitals ', ' Human ', ' Modern Man ', ' Hybrids ', ' Institutes ', ' Jamaica ', ' Language ', ' Loneliness ', ' lonely ', ' Manuals ', ' Persons ', ' Natural Language Processing ', ' natural language understanding ', ' Noise ', ' Patients ', ' Production ', ' Self Care ', ' personal care ', ' Semantics ', ' Social Interaction ', ' Social support ', ' social support network ', ' Computer software ', ' Software ', ' Speech ', ' Stress ', ' Technology ', ' Television ', ' Genetic Transcription ', ' Gene Transcription ', ' RNA Expression ', ' Transcription ', ' Tremor ', ' United States ', ' Universities ', ' Voice ', ' Washington ', ' Work ', ' World Health Organization ', ' Generations ', ' Measures ', ' Price ', ' pricing ', ' Caregivers ', ' Care Givers ', ' falls ', ' depressive symptoms ', ' Emotional Depression ', ' depression symptom ', ' depressive ', ' Family member ', ' Data Set ', ' Dataset ', ' Caring ', ' human subject ', ' Label ', ' improved ', ' Phase ', ' Neurologic ', ' Neurological ', ' Training ', ' Visual ', ' Individual ', ' Licensing ', ' satisfaction ', ' Therapeutic ', ' Contracting Opportunities ', ' Contracts ', ' restraint ', ' Hour ', ' Frequencies ', ' Dependence ', ' Protocol ', ' Protocols documentation ', ' Reaction ', ' Techniques ', ' System ', ' Amentia ', ' Dementia ', ' Medical center ', ' speech recognition ', ' success ', ' phrases ', ' skills ', ' research study ', ' Study Subject ', ' Devices ', ' Modeling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' response ', ' Intervention Strategies ', ' interventional strategy ', ' Intervention ', ' Feeds ', ' Data ', ' Small Business Innovation Research Grant ', ' SBIR ', ' Small Business Innovation Research ', ' Validation ', ' Monitor ', ' Text ', ' age related ', ' age dependent ', ' cost ', ' design ', ' designing ', ' next generation ', ' older patient ', ' elderly patient ', ' Population ', ' Network-based ', ' usability ', ' aging population ', ' aged population ', ' population aging ', ' evidence base ', ' human-in-the-loop ', ' recruit ', ' care providers ', ' primary care provider ', ' health plan ', ' health plans ', ' patient engagement ', ' participant engagement ', ' patient response ', ' patient specific response ', ' responsive patient ', ' deep neural network ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' speech synthesis ', "" Alzheimer's disease related dementia "", ' AD related dementia ', ' ADRD ', ' Alzheimer related dementia ', ' automated speech recognition ', ' automatic speech recognition ', ' social assistive robot ', ' social robot ', "" Alzheimer's disease patient "", "" Alzheimer's patient "", ' Home ', ' ']",NIA,CARE.COACH CORPORATION,R44,2021,1396272
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,10201558,K24DC016312,"['Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', "" Gehrig's Disease "", ' Lou Gehrig Disease ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Laryngeal Cancer ', ' Larynx Cancer ', ' Malignant Laryngeal Neoplasm ', ' Malignant Laryngeal Tumor ', ' Malignant Tumor of the Larynx ', ' Cerebral Palsy ', ' Communication ', ' Cues ', ' Disease ', ' Disorder ', ' Dysarthria ', ' Dysarthosis ', ' Electromagnetics ', ' Future ', ' Goals ', ' Jaw ', ' Laboratories ', ' Learning ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Multiple Sclerosis ', ' Disseminated Sclerosis ', ' insular sclerosis ', ' Persons ', ' Parkinson Disease ', ' Paralysis Agitans ', ' Parkinson ', "" Parkinson's disease "", ' Parkinsons disease ', ' Primary Parkinsonism ', ' Patients ', ' Play ', ' Quality of life ', ' QOL ', ' Questionnaires ', ' Records ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Running ', ' Speech ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech Sound ', ' Stroke ', ' Apoplexy ', ' Brain Vascular Accident ', ' Cerebral Stroke ', ' Cerebrovascular Apoplexy ', ' Cerebrovascular Stroke ', ' brain attack ', ' cerebral vascular accident ', ' cerebrovascular accident ', ' Surveys ', ' Survey Instrument ', ' Tablets ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Voice ', ' Work ', ' Generations ', ' Measures ', ' base ', ' improved ', ' Ensure ', ' Individual ', ' machine learned ', ' Machine Learning ', ' Severities ', ' Complex ', ' Oral ', ' Techniques ', ' System ', ' 3-D ', ' 3D ', ' three dimensional ', ' 3-Dimensional ', ' Test Result ', ' brain cell ', ' experience ', ' jaw movement ', ' Performance ', ' laptop ', ' phrases ', ' Speed ', ' Structure ', ' novel ', ' Participant ', ' Devices ', ' Bypass ', ' Deterioration ', ' Modeling ', ' oral communication ', ' portability ', ' Brain Trauma ', ' traumatic brain damage ', ' Traumatic Brain Injury ', ' Cell Phone ', ' Cellular Telephone ', ' iPhone ', ' smart phone ', ' smartphone ', ' Cellular Phone ', ' Effectiveness ', ' Address ', ' Data ', ' Motor ', ' Characteristics ', ' Modification ', ' Development ', ' developmental ', ' Output ', ' orofacial ', ' cost ', ' time use ', ' virtual ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' usability ', ' motor impairment ', ' movement impairment ', ' movement limitation ', ' spatiotemporal ', ' clear speech ', ' efficacy testing ', ' Tablet Computer ', ' tablet device ', ' experimental study ', ' experiment ', ' experimental research ', ' Articulation ', ' virtual vocal tract ', ' speech-generating device ', ' machine learning algorithm ', ' machine learned algorithm ', ' effectiveness testing ', ' ']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2021,189937
"Wearable silent speech technology to enhance impaired oral communication Project Summary/Abstract The long-term objectives of this project are to obtain a deeper understanding how articulatory movement patterns are mapped to speech particularly when there is no vocal fold vibration (silent speech) and then to develop a novel, wearable assistive technology called silent speech interface (SSI) to assist the impaired oral communication for individuals in need (e.g., individuals after laryngectomy, surgical removal of larynx to treat advanced laryngeal cancer). Designed for daily use, the SSI contains a wearable magnetic device and a small camera for tongue and lip motion tracking, respectively, and an articulation-to-speech synthesizer to output natural sounding speech that preserves the speaker’s voice characteristics. Specific Aims of the proposal include to (1) determine the articulatory patterns of normal (vocalized) and silent speech, produced by both healthy talkers and people after laryngectomy, (2) develop a wearable, wireless magnetic device for real-time tongue and lip motion tracking, and (3) synthesize speech from articulation directly. There are currently limited alternative communication options for people who have undergone laryngectomy. These options include esophageal speech, tracheo-esophageal speech, and use of an artificial larynx (or electrolarynx). These solutions are either invasive or difficult to use, and all of them result in a hoarse or mechanical/robotic sounding voice, which can be difficult to understand. In contrast, the SSI in this application is non-invasive, easy-to-use, and produces natural sounding speech and may even preserve the patient’s voice identity. We have exciting preliminary results that support the feasibility of the project including that (1) we have recently developed a wireless magnetic device for tongue motion, and (2) we have demonstrated real- time articulation-to-speech synthesis with a 90% word accuracy (judged by a human listener). In this project, we will further reduce the size of the wireless device and make it wearable and conduct articulation-to-speech algorithms by studying 30 participants after laryngectomy and 30 age- and gender-matched healthy controls. If successful, the proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broader range of other speech and voice disorders. In addition, the technology will have an impact to the speech science field by providing a fist-time-ever tool for potential large- scale tongue motion data collection and have a variety of broader implications including visual feedback-based secondary language training and speech therapy, which may benefit millions of people with motor speech deficits in the United States. Project Narrative Silent speech interfaces (SSI) is a novel assistive technology for enhancing the oral communication for people who are unable to produce speech sounds (e.g., individuals who undergo laryngectomy, removal of larynx to treat advanced laryngeal cancer). The proposed SSI is a wearable device for tongue motion tracking and produces synthesized, natural sounding speech that preserves the patient’s voice characteristics in real-time, which holds potential to enhance the speech health and quality of life of laryngectomees. The technology also has potential for a variety of broader applications including visual feedback-based secondary language training and speech therapy.",Wearable silent speech technology to enhance impaired oral communication,10218134,R01DC016621,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Algorithms ', ' Articulators ', ' Malignant neoplasm of larynx ', ' Laryngeal Cancer ', ' Larynx Cancer ', ' Malignant Laryngeal Neoplasm ', ' Malignant Laryngeal Tumor ', ' Malignant Tumor of the Larynx ', ' Communication ', ' Data Collection ', ' Mental Depression ', ' depression ', ' Electromagnetics ', ' Goals ', ' Gold ', ' Health ', ' Hoarseness ', ' Voice Hoarseness ', ' Human ', ' Modern Man ', ' language training ', ' Laryngectomy ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Laryngeal Prosthesis ', ' Artificial Larynx ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Patients ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Robotics ', ' Science ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' sound ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Sound ', ' Speech Synthesizers ', ' voice synthesizer ', ' Speech Therapy ', ' Alaryngeal Speech ', ' Alaryngeal Voice Production ', ' Esophageal Speech ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' United States ', ' vocal cord ', ' Vocal Fold ', ' Voice ', ' Voice Disorders ', ' Voice Quality ', ' Gender ', ' Measures ', ' Articular Range of Motion ', ' Joint Range of Motion ', ' range of motion ', ' base ', ' improved ', ' Individual ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Life ', ' mechanical ', ' Mechanics ', ' Msec ', ' millisecond ', ' Pattern ', ' vibration ', ' magnetic ', ' Magnetism ', ' auditory feedback ', ' Performance ', ' visual feedback ', ' kinematic model ', ' kinematics ', ' Speed ', ' novel ', ' Participant ', ' novel technologies ', ' new technology ', ' Devices ', ' social ', ' Abscission ', ' Extirpation ', ' Removal ', ' Surgical Removal ', ' resection ', ' Excision ', ' Position ', ' Positioning Attribute ', ' oral communication ', ' Enhancement Technology ', ' Data ', ' Electrolarynx ', ' Motor ', ' Laryngectomee ', ' Tracheoesophageal Speech ', ' Tracheo-Esophageal Speech ', ' Wireless Technology ', ' wireless ', ' Characteristics ', ' Tracer ', ' Development ', ' developmental ', ' Output ', ' design ', ' designing ', ' alternative communication ', ' Population ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' prototype ', ' social exclusion ', ' marginalization ', ' experimental study ', ' experiment ', ' experimental research ', ' Articulation ', ' wearable device ', ' wearable electronics ', ' wearable technology ', ' preservation ', ' machine learning algorithm ', ' machine learned algorithm ', ' speech synthesis ', ' ']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2021,581235
"Speech markers of cognitive impairment in Parkinson's disease ABSTRACT Dr. Kara Smith is a Movement Disorders neurologist at the University of Massachusetts Medical School (UMMS) whose goal is to become an independent investigator focused on early cognitive impairment in Parkinson disease (PD). Her long-term goal is to develop speech markers of cognitive impairment in PD. Cognitive impairment occurs in the majority of PD patients, leading to increased mortality and decreased quality of life. The current diagnostic tools are resource-intensive and have limited sensitivity. Treatments are often offered late in the course of cognitive decline and do not provide optimal benefit. Speech markers could improve detection, monitoring and treatment of cognitive impairment in PD. Speech markers could be monitored frequently and remotely via mobile technology, capturing sensitive, quantitative data about cognitive function in the context of patients’ daily life and in response to therapeutics. Dr. Smith’s role as a clinical movement disorders specialist ideally positions her to lead the application of advanced speech and language research to feasible, patient-oriented tools for real-life clinical practice and clinical trials. Dr. Smith has assembled an expert interdisciplinary mentorship team ideally suited for the goals of this innovative proposal. Dr. Smith and her team have previously shown that a) speech acoustic markers are associated with cognitive function in non-demented PD patients, and b) PD patients with mild cognitive impairment had linguistic deficits including pauses within utterances and grammaticality. Building on these results, Dr. Smith proposes to study speech and language more comprehensively in PD patients with and without mild cognitive impairment and controls to confirm these preliminary results and identify additional biomarkers. The aims of this study will be 1) to develop algorithms using speech acoustic markers to categorize by cognitive status, 2) to identify linguistic markers associated with mild cognitive impairment in PD, and 3) to assess on-line syntactic processing in PD subjects with mild cognitive impairment. The overall goal of the proposal is to identify speech and language markers of early cognitive dysfunction that can be further refined, validated and implemented using mobile technology into a larger scale, longitudinal R01 proposal. Further work will also address the underlying neurobiological mechanisms of these speech markers. Dr. Smith’s rigorous training plan includes a Master’s degree, linguistics and speech motor physiology courses, and experience in signal processing and speech acoustic analysis. Through her training goals, she will advance her knowledge and skills in patient-centered outcomes measures and instrument validation. She will gain experience in research leadership, presentation and dissemination of scientific work, and in grant writing, culminating in an R01 proposal. This K23 award will be critical for Dr. Smith to establish an independent career as a PD clinician-scientist at the unique intersection of speech and language science and cognitive impairment. PUBLIC HEALTH RELEVANCE: Speech markers have the potential to improve diagnosis, monitoring and treatment of cognitive impairment in Parkinson’s disease (PD). Although the majority of PD patients will develop cognitive impairment, the tools available to assess and treat this disabling complication are fraught with limitations. As a detailed and quantitative assessment tool, speech markers may increase sensitivity to early cognitive dysfunction and to changes over time compared with current measures. They may be automated and then implemented through mobile technology to increase patients’ access to cognitive symptom monitoring outside of the clinic setting. Dr. Smith’s proposed career development plan has potential to fill a major gap in PD research by making inexpensive and easy-to-use cognitive assessment tools accessible to patients in rural and international settings, and by fueling clinical trials to discover new therapeutics capable of slowing cognitive decline in PD.",Speech markers of cognitive impairment in Parkinson's disease,10115019,K23DC016656,"['Acoustics ', ' Acoustic ', ' Algorithms ', ' Award ', ' Biomedical Engineering ', ' bio-engineered ', ' bio-engineers ', ' bioengineering ', ' Clinical Trials ', ' Cognitive Therapy ', ' Cognition Therapy ', ' Cognitive Psychotherapy ', ' cognitive behavior intervention ', ' cognitive behavior modification ', ' cognitive behavior therapy ', ' cognitive behavioral intervention ', ' cognitive behavioral modification ', ' cognitive behavioral therapy ', ' cognitive behavioral treatment ', ' Complication ', ' Data Analyses ', ' Data Analysis ', ' data interpretation ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Pharmaceutical Preparations ', ' Drugs ', ' Medication ', ' Pharmaceutic Preparations ', ' drug/agent ', ' Foundations ', ' Future ', ' Patient Care ', ' Patient Care Delivery ', ' Goals ', ' Grant ', ' Health Services Accessibility ', ' Access to Care ', ' access to health services ', ' access to services ', ' access to treatment ', ' accessibility to health services ', ' availability of services ', ' care access ', ' health service access ', ' health services availability ', ' service availability ', ' treatment access ', ' Language ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Leadership ', ' Linguistics ', ' Linguistic ', ' Longitudinal Studies ', ' long-term study ', ' longitudinal outcome studies ', ' longterm study ', ' Massachusetts ', ' Mentors ', ' Mentorship ', ' Methods ', ' mortality ', ' Movement Disorders ', ' Dyskinesia Syndromes ', ' Movement Disorder Syndromes ', ' Nerve Degeneration ', ' Neuron Degeneration ', ' neural degeneration ', ' neurodegeneration ', ' neurodegenerative ', ' neurological degeneration ', ' neuronal degeneration ', ' Neurobiology ', ' neurobiological ', ' Neuropsychological Tests ', ' Neuropsychologic Tests ', ' Parkinson Disease ', ' Paralysis Agitans ', ' Parkinson ', "" Parkinson's disease "", ' Parkinsons disease ', ' Primary Parkinsonism ', ' Patients ', ' Physiology ', ' Production ', ' Quality of life ', ' QOL ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Resources ', ' Research Resources ', ' Role ', ' social role ', ' medical schools ', ' medical college ', ' school of medicine ', ' Science ', ' Speech ', ' Speech Acoustics ', ' Technology ', ' Testing ', ' Time ', ' Universities ', ' Work ', ' Writing ', ' Measures ', ' Outcome Measure ', ' Outcomes Research ', ' Specialist ', ' Comprehension ', ' career ', ' improved ', ' Area ', ' Clinical ', ' Training ', ' Individual ', ' Neurologist ', ' Rural ', ' Development Plans ', ' Therapeutic ', ' tool ', ' Cognitive Disturbance ', ' Cognitive Impairment ', ' Cognitive decline ', ' Cognitive function abnormal ', ' Disturbance in cognition ', ' cognitive dysfunction ', ' cognitive loss ', ' Impaired cognition ', ' instrument ', ' Diagnostic ', ' Nature ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Life ', ' cognitive function ', ' Scientist ', ' Severities ', ' Clinic ', ' Location ', ' Amentia ', ' Dementia ', ' Cognitive Manifestations ', ' Cognitive Symptoms ', ' Neurobehavioral Signs and Symptoms ', ' neurobehavioral symptom ', ' Neurobehavioral Manifestations ', ' American ', ' early detection ', ' Early Diagnosis ', ' experience ', ' Performance ', ' syntactic ', ' syntax ', ' Proxy ', ' skills ', ' cognitive defects ', ' Cognitive deficits ', ' novel ', ' Participant ', ' Position ', ' Positioning Attribute ', ' motor deficit ', ' Modeling ', ' career development ', ' QOC ', ' Quality of Care ', ' response ', ' cognitive change ', ' Address ', ' Symptoms ', ' Data ', ' Detection ', ' International ', "" Master's Degree "", ' K23 Award ', ' K23 Mechanism ', ' K23 Program ', ' Mentored Patient-Oriented Research Career Development Award (K23) ', ' Mentored Patient-Oriented Research Career Development Award ', ' Motor ', ' Cognitive ', ' Patient-Focused Outcomes ', ' Patient outcome ', ' Patient-Centered Outcomes ', ' Validation ', ' Monitor ', ' Characteristics ', ' Development ', ' developmental ', "" Parkinson's Dementia "", ' PD with dementia ', ' Parkinson Dementia ', ' Parkinson Disease dementia ', ' Parkinson Disease with dementia ', "" Parkinson's Disease dementia "", "" Parkinson's disease with dementia "", ' dementia in PD ', ' dementia in Parkinson disease ', ' Outcome ', ' Population ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' patient oriented ', ' patient centered ', ' language processing ', ' lexical retrieval ', ' handheld mobile device ', ' mobile device ', ' novel therapeutics ', ' new drug treatments ', ' new drugs ', ' new therapeutics ', ' new therapy ', ' next generation therapeutics ', ' novel drug treatments ', ' novel drugs ', ' novel therapy ', ' cognitive control ', ' neurobiological mechanism ', ' public health relevance ', ' Biological Markers ', ' bio-markers ', ' biologic marker ', ' biomarker ', ' clinical practice ', ' screening ', ' mild cognitive impairment ', ' mild cognitive disorder ', ' signal processing ', ' cognitive performance ', ' cognitive testing ', ' cognitive assessment ', ' clinical movement disorder ', ' Assessment tool ', ' Assessment instrument ', ' mobile computing ', ' mobile platform ', ' mobile technology ', ' non-demented ', ' nondemented ', ' common symptom ', ' Articulation ', ' recruit ', ' large scale data ', ' large scale data sets ', ' large scale datasets ', ' machine learning method ', ' machine learning methodologies ', "" cognitive impairment in Parkinson's "", "" cognitive decline in Parkinson's "", "" cognitive dysfunction in Parkinson's "", ' ']",NIDCD,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K23,2021,189216
"Wearable silent speech technology to enhance impaired oral communication Project Summary/Abstract The long-term objectives of the parent R01 project (R01DC016621, 08/15/2019 – 06/31/2024) are to obtain a deeper understanding how articulatory movement patterns are mapped to speech particularly when there is no vocal fold vibration (silent speech) and then to develop a novel, wearable assistive technology called silent speech interface (SSI) to assist the impaired oral communication for individuals in need (e.g., individuals after laryngectomy, surgical removal of larynx to treat advanced laryngeal cancer). The parent R01 project aims to (1) determine the articulatory patterns of normal (vocalized) and silent speech, produced by both healthy talkers and people after laryngectomy, (2) develop a wearable device for real-time tongue and lip motion tracking, and (3) synthesize speech from articulation directly. If successful, the proposed research will enhance human health by making an impact on individuals after laryngectomy and potentially to a broader range of other speech and voice disorders as well as visual feedback-based secondary language training and speech therapy. Through the parent R01 project, we are collecting a unique multi-modal speech dataset from patients following laryngectomy and healthy controls. This data set includes speech kinematics from multiple tracers attached on the tongue and the lips, and speech acoustics. Each tracer comprises multiple sensors that measure inertial and magnetic information that can provide additional information to assist the speech acoustic and the articulation-to-speech algorithm. Making such data ML ready for others to consume was out of scope due to required effort and complexity needed to pre-process and synchronize sampling between kinematic and acoustic data. The specific goal of this supplemental project is to make data AI/ML ready by developing the pre-processing algorithms needed to generate a set of features, along with proper formatting and labeling, that can be more easily shared through repositories and used by others to evaluate different ML algorithms. New ML models that will be tested on these ML-ready shared datasets will significantly advance our capabilities to translate articulatory motion into speech sounds, which will not only improve the quality of life for people affected by laryngectomy but also for the millions of individuals living with speech sound disorders such as Parkinson’s disease, and amyotrophic lateral sclerosis. Project Narrative The parent R01 project is to develop a wearable silent speech interface (SSI), a novel assistive technology for enhancing the oral communication for people who are unable to produce speech sounds (e.g., individuals who undergo laryngectomy, removal of larynx to treat advanced laryngeal cancer) by converting their tongue and lip motion into intelligible speech. Lack of such a publicly available AI/ML ready data set is a critical gap in this field, thus the proposed supplemental project is to make the unique, multi-modal data collected in the parent R01 project AI/ML ready. If successful, this supplement project will have high impact on the speech production affected by laryngectomy.",Wearable silent speech technology to enhance impaired oral communication,10412276,R01DC016621,"['Acceleration ', ' Acoustics ', ' Acoustic ', ' Affect ', ' Algorithms ', ' Amyotrophic Lateral Sclerosis ', ' Amyotrophic Lateral Sclerosis Motor Neuron Disease ', "" Gehrig's Disease "", ' Lou Gehrig Disease ', ' Articulators ', ' California ', ' Malignant neoplasm of larynx ', ' Laryngeal Cancer ', ' Larynx Cancer ', ' Malignant Laryngeal Neoplasm ', ' Malignant Laryngeal Tumor ', ' Malignant Tumor of the Larynx ', ' Felis catus ', ' Cats ', ' Cats Mammals ', ' Domestic Cats ', ' Feline Species ', ' Felis domestica ', ' Felis domesticus ', ' Felis sylvestris catus ', ' Communication ', ' Communities ', ' Mental Depression ', ' depression ', ' Disease ', ' Disorder ', ' Engineering ', ' Feedback ', ' Goals ', ' Health ', ' Hoarseness ', ' Voice Hoarseness ', ' Human ', ' Modern Man ', ' language training ', ' Laryngectomy ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Lip structure ', ' Lip ', ' Maps ', ' Motion ', ' Movement ', ' body movement ', ' Parents ', ' Parkinson Disease ', ' Paralysis Agitans ', ' Parkinson ', "" Parkinson's disease "", ' Parkinsons disease ', ' Primary Parkinsonism ', ' Patients ', ' Production ', ' Publishing ', ' Quality of life ', ' QOL ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Robotics ', ' Rotation ', ' Science ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Acoustics ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Intelligibility ', ' Speech Intelligibilities ', ' Speech Sound ', ' Speech Therapy ', ' Alaryngeal Speech ', ' Alaryngeal Voice Production ', ' Standardization ', ' Technology ', ' Testing ', ' Time ', ' Tongue ', ' Translating ', ' United States ', ' Universities ', ' vocal cord ', ' Vocal Fold ', ' Voice ', ' Voice Disorders ', ' Measures ', ' Data Set ', ' Dataset ', ' base ', ' community planning ', ' Label ', ' sensor ', ' improved ', ' Site ', ' Physiological ', ' Physiologic ', ' Series ', ' Ensure ', ' Individual ', ' tool ', ' Nature ', ' machine learned ', ' Machine Learning ', ' mechanical ', ' Mechanics ', ' Route ', ' Pattern ', ' vibration ', ' Best Practice Analysis ', ' Benchmarking ', ' interest ', ' magnetic ', ' Magnetism ', ' visual feedback ', ' kinematic model ', ' kinematics ', ' novel ', ' novel technologies ', ' new technology ', ' Devices ', ' Abscission ', ' Extirpation ', ' Removal ', ' Surgical Removal ', ' resection ', ' Excision ', ' Position ', ' Positioning Attribute ', ' Modeling ', ' Sampling ', ' oral communication ', ' depository ', ' repository ', ' Documentation ', ' Enhancement Technology ', ' Preparedness ', ' Readiness ', ' datamining ', ' data mining ', ' Address ', ' Data ', ' Motor ', ' Wireless Technology ', ' wireless ', ' Characteristics ', ' Process ', ' Tracer ', ' Output ', ' Consumption ', ' innovation ', ' innovate ', ' innovative ', ' Impairment ', ' multimodality ', ' multi-modality ', ' social exclusion ', ' marginalization ', ' data archive ', ' data library ', ' Articulation ', ' recruit ', ' wearable device ', ' wearable electronics ', ' wearable technology ', ' multimodal data ', ' multi-modal data ', ' multi-modal datasets ', ' multimodal datasets ', ' public repository ', ' publicly accessible repository ', ' publicly available repository ', ' archive data ', ' archiving data ', ' archived data ', ' ']",NIDCD,"UNIVERSITY OF TEXAS, AUSTIN",R01,2021,292804
"Revealing the organization and functional significance of neural timescales in auditory cortex Project Summary People are remarkably adept at making sense of the world through sound: understanding speech in a noisy restaurant, picking out the voice of a family member, or recognizing a familiar melody. Although we take these abilities for granted, they reflect impressive computational feats of biological engineering that are remarkably difficult to replicate in machine systems. The long-term goal of my research program is to develop computational and experimental methods to reverse-engineer how the brain codes natural sounds like speech and to exploit these advances to understand and aid in the treatment of hearing impairment. One of the central challenges of coding natural sounds is that they are structured at many different timescales from milliseconds to seconds and even minutes. How does the brain integrate across these diverse timescales to derive meaning from sound? Answering this question has been challenging because there are no general-purpose methods for measuring neural timescales in the brain. As a consequence, we know relatively little about how neural timescales are organized in auditory cortex and how this organization enables the coding of natural sounds. To overcome these limitations, we develop a simple experimental paradigm (the “temporal context invariance” or TCI paradigm) for estimating the temporal integration period of any sensory response: the time window during which stimuli alter the response. We apply the TCI method to human electrocorticography (ECoG) and animal physiology recordings to reveal the organization of neural timescales at both the region and single-cell level (Aim I). Pilot data from our analyses reveal that timescales are organized hierarchically, with higher-order regions showing substantially longer integration periods. To explore the functional significance of this timescale hierarchy, we couple TCI with computational techniques well-suited for characterizing natural sounds (Aim II). We test whether increased integration periods enable a more noise-robust representation of speech (Aim IIA), whether regions with longer integration periods code higher-order properties of natural sounds (Aim IIB&IIC), whether there are dedicated integration periods for important sounds categories like speech or music (Aim IID), and whether cortical integration periods can be explained by the duration of the features they respond to (Aim IIE). In the process of conducting this research, I will be trained in two critical areas: (1) ECoG, which is the only method with the spatial and temporal precision to understand how neural timescales are organized in the human brain (2) deep neural networks (DNN) which are the only models able to perform challenging perceptual tasks at human levels and predict neural responses in higher-order cortical regions. After completing this training, I will have a unique set of experimental (fMRI, ECoG, psychophysics) and computational skills (data-driven statistical modeling and hypothesis-driven DNN modeling), which will facilitate my transition to an independent investigator. Project Narrative Natural sounds like speech contain information at many different timescales (e.g. phonemes, syllables, words), but how the human brain extracts this information remains unclear. Understanding this process is critical to understanding how hearing impairment degrades speech perception. The proposed research will reveal the organization of neural timescales in the brain, and how this organization facilitates the coding of natural sounds like speech, which is a critical first step in understanding how this code is impaired by hearing loss.",Revealing the organization and functional significance of neural timescales in auditory cortex,10169404,K99DC018051,"['Animals ', ' Auditory area ', ' Auditory Cortex ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Cells ', ' Cell Body ', ' Communication ', ' Computing Methodologies ', ' computational methodology ', ' computational methods ', ' computer based method ', ' computer methods ', ' computing method ', ' Engineering ', ' Goals ', ' Grant ', ' Hearing ', ' Human ', ' Modern Man ', ' Learning ', ' Methods ', ' Statistical Models ', ' Probabilistic Models ', ' Probability Models ', ' statistical linear mixed models ', ' statistical linear models ', ' Music ', ' Neurosciences ', ' Noise ', ' Physiology ', ' Psychophysics ', ' psychophysical ', ' Reaction Time ', ' Response RT ', ' Response Time ', ' psychomotor reaction time ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Restaurants ', ' sound ', ' Speech ', ' Speech Perception ', ' Testing ', ' Voice ', ' Work ', ' Measures ', ' Family member ', ' Area ', ' Biological ', ' Training ', ' Stimulus ', ' Collaborations ', ' Functional MRI ', ' fMRI ', ' Functional Magnetic Resonance Imaging ', ' programs ', ' electrocorticography ', ' Electrocorticogram ', ' Msec ', ' millisecond ', ' Complex ', ' Sensory ', ' Techniques ', ' System ', ' experience ', ' neural ', ' relating to nervous system ', ' Structure ', ' skills ', ' Categories ', ' Coding System ', ' Code ', ' Modeling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' Property ', ' response ', ' theories ', ' Hearing Loss ', ' Hypoacuses ', ' Hypoacusis ', ' dysfunctional hearing ', ' hearing defect ', ' hearing deficit ', ' hearing difficulty ', ' hearing disability ', ' hearing dysfunction ', ' hearing impairment ', ' Address ', ' Data ', ' Research Training ', ' Computational Technique ', ' Process ', ' Population ', ' neuromechanism ', ' neural mechanism ', ' clinically significant ', ' clinical significance ', ' experimental study ', ' experiment ', ' experimental research ', ' deep neural network ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' ']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,K99,2021,125442
"Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech Project Summary/Abstract  This proposal aims to employ the recent advancement of coupling fiberoptic endoscopes with high-speed videoendoscopy (HSV) systems to obtain HSV recordings during connected speech. The goal is to study vocal mechanisms underlying dysphonia in patients with neurogenic voice disorders. The long-term goal of this line of research is to create clinically applicable quantitative methods for functional measurement of vocal fold vibration in connected speech using innovative laryngeal imaging, an approach that could advance clinical voice assessment and treatment practice. In Aim 1, HSV-based measures of vocal fold kinematics will be developed and the influence of these measures on voice audio-perceptual qualities in the patients will be determined. Image processing techniques will be developed to extract such measures from the HSV data in connected speech. The extracted measures will be given as inputs to the statistical models to determine the source of the differences between the normal controls and the patients for different speech phonetic contexts and words. This aim provides an unbiased HSV-based method to predict voice quality. Developing such HSV-based methodology for functional laryngeal examination in connected speech can enhance clinical voice assessment. In addition, better understanding the influence of phonetic context would lead to optimizing the protocols for functional voice assessment through laryngeal imaging in connected speech. In Aim 2, machine learning approaches will be employed to discover hidden physics and unknown laryngeal mechanisms of voice production in the dysphonic patients. The findings of this project will help make necessary adjustments in biomechanical or physiological characteristics of vocal folds to enhance voice quality in patients with neurogenic voice disorders. Therefore, the outcome of this research will aid clinicians in properly selecting, and developing new treatment strategies (therapeutic, medicinal, or surgical), which are based on the gained knowledge of laryngeal mechanisms of dysphonia. The proposed research is in harmony with multiple priority areas of the NIDCD, described in the 2017-2021 Strategic Plan. Both aims support Priority 3 (improve methods of diagnosis, treatment, and prevention) through developing objective HSV-based measures and predicting the voice quality. Comparing laryngeal mechanisms in normal and disordered voices addresses Priority 1 (deepen our understanding of the normal function of the systems of human communication). Both aims propose to study laryngeal mechanisms in patients with neurogenic and functional voice disorders, which addresses Priority 2 (increase our knowledge about conditions that alter or diminish communication and health). Project Narrative  The goal of this proposal is to determine laryngeal mechanisms underlying dysphonia in connected speech, which will lead to development of clinically applicable quantitative methods for functional laryngeal examination in connected speech using laryngeal imaging. This can potentially result in enhancement of clinical voice assessment and development of new clinical voice management strategies to better help people with voice disorders.",Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech,10134315,K01DC017751,"['Acoustics ', ' Acoustic ', ' Age ', ' ages ', ' Behavior ', ' Biomechanics ', ' biomechanical ', ' Communication ', ' Statistical Data Interpretation ', ' Statistical Data Analyses ', ' Statistical Data Analysis ', ' statistical analysis ', ' Diagnosis ', ' Endoscopes ', ' Goals ', ' Gold ', ' Health ', ' Human ', ' Modern Man ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Lead ', ' Pb element ', ' heavy metal Pb ', ' heavy metal lead ', ' Methods ', ' Methodology ', ' Mining ', ' Statistical Models ', ' Probabilistic Models ', ' Probability Models ', ' statistical linear mixed models ', ' statistical linear models ', ' Patients ', ' Physics ', ' Production ', ' Research ', ' Speech ', ' Testing ', ' Time ', ' Tremor ', ' vocal cord ', ' Vocal Fold ', ' Voice ', ' Voice Disorders ', ' Voice Quality ', ' Measures ', ' Outcomes Research ', ' Data Set ', ' Dataset ', ' base ', ' image processing ', ' improved ', ' Area ', ' Clinical ', ' Physiological ', ' Physiologic ', ' Series ', ' Evaluation ', ' Visual ', ' Measurement ', ' Spastic Dysphonias ', ' Laryngeal dystonia ', ' spasmodic dysphonia ', ' Functional disorder ', ' Dysfunction ', ' Physiopathology ', ' pathophysiology ', ' Therapeutic ', ' tool ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' Severities ', ' Auditory ', ' Protocol ', ' Protocols documentation ', ' Source ', ' Techniques ', ' System ', ' vibration ', ' vocalization ', ' Palsy ', ' Plegia ', ' paralysis ', ' paralytic ', ' Paralysed ', ' Operative Procedures ', ' Surgical ', ' Surgical Interventions ', ' Surgical Procedure ', ' surgery ', ' Operative Surgical Procedures ', ' cohort ', ' kinematic model ', ' kinematics ', ' Speed ', ' Categories ', ' Prevention ', ' Modeling ', ' Address ', ' Data ', ' Strategic Planning ', ' Characteristics ', ' sex ', ' Development ', ' developmental ', ' Voice Disturbances ', ' Dysphonia ', ' Phonation Disorders ', ' Image ', ' imaging ', ' National Institute on Deafness and Other Communication Disorders ', ' NIDCD ', ' time use ', ' Outcome ', ' Coupling ', ' innovation ', ' innovate ', ' innovative ', ' clinically relevant ', ' clinical relevance ', ' clinical application ', ' clinical applicability ', ' treatment strategy ', ' clinical practice ', ' flexibility ', ' flexible ', ' temporal measurement ', ' temporal resolution ', ' time measurement ', ' clinical development ', ' imaging approach ', ' imaging based approach ', ' ']",NIDCD,MICHIGAN STATE UNIVERSITY,K01,2021,137795
"Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment Project Summary The purpose of this proposal is to develop two strategies, natural language processing (NLP) and automated speech analysis (ASA), to enable automated identification of patients with cognitive impairment (CI), from mild cognitive impairment (MCI) to Alzheimer’s Disease Related Dementias (ADRD) in clinical settings. The number of older adults in the United States with MCI and ADRD is increasing and yet the ability of clinicians and researchers to identify them at scale has advanced little over recent decades and screening with clinical assessments is done inconsistently. Alternative strategies using available data, like analysis of diagnostic codes in the clinical record or insurance claims, have very low sensitivity. NLP and ASA used with machine learning are technologies that could greatly increase ability to detect MCI and ADRD in clinical contexts. NLP automatically converts text in the electronic health record (EHR) into structured concepts suitable for analysis. Thus, clinicians’ documentation of signs and symptoms or orders of tests and services that reflect or address cognitive limitations can be efficiently captured, possibly long before the clinician uses an ADRD-related diagnostic code. ASA directly measures cognition by recognizing different features of cognition captured in speech. Extracting features through both NLP and ASA could thus provide a unique measure of cognition and its impact on the individual and their caregivers. Early detection of MCI and ADRD can help researchers identify appropriate patients for research and help clinicians and health systems target patients for preventive care and care coordination. For these reasons, more efficient, highly scalable strategies are needed to identify people with MCI and ADRD. The Specific Aims of this proposal are to (1) Develop and validate a ML algorithm using features extracted from the EHR with NLP to identify patients with CI, (2) Develop and validate a ML algorithm using features extracted from ASA of audio recordings of patient-provider encounters during routine primary care visits to identify patients with CI, (3) Develop and validate a ML algorithm using both NLP and ASA extracted features to create an integrated CI diagnostic algorithm. We will develop machine learning algorithms using NLP and ASA extracted features trained against neurocognitive assessment data on 800 primary care patients in New York City and validate them in an independent sample of 200 patients in Chicago. In secondary analyses we will train ML algorithms to identify MCI and its subtypes. This project will be the most rigorous development of NLP, ASA, and ML algorithms for CI yet performed, the first to test ASA in primary care settings, and the first to test NLP and ASA feature extraction strategies in combination. The multi-disciplinary team of clinicians, health services researchers, and neurocognitive and data scientists will apply machine learning to develop these highly scalable, automated technologies for identification of MCI and ADRD. 1 Project Narrative The ability of clinicians, health systems and researchers to identify patients with mild cognitive impairment (MCI) and Alzheimer’s Disease Related Dementias (ADRD) is limited. This project will apply machine learning to natural language processing (NLP) of electronic health record data and automated speech analysis (ASA) of patient-doctor conversations during primary care visits to identify patients with MCI and ADRD using automated and scalable procedures. The analytic algorithms will be developed with neurocognitive assessment data on 800 primary care patients in New York City and validated in an independent sample of 200 patients in Chicago. 1",Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment,10144364,R01AG066471,"['Acoustics ', ' Acoustic ', ' Elderly ', ' advanced age ', ' elders ', ' geriatric ', ' late life ', ' later life ', ' older adult ', ' older person ', ' senior citizen ', ' Algorithms ', ' Mental disorders ', ' Mental health disorders ', ' Psychiatric Disease ', ' Psychiatric Disorder ', ' mental illness ', ' psychiatric illness ', ' psychological disorder ', ' Chicago ', ' Cognition ', ' Data Analyses ', ' Data Analysis ', ' data interpretation ', ' Diagnosis ', ' Patient Care ', ' Patient Care Delivery ', ' Health Services ', ' Insurance Carriers ', ' Insurers ', ' Methods ', ' Persons ', ' Natural Language Processing ', ' natural language understanding ', ' New York City ', ' Parkinson Disease ', ' Paralysis Agitans ', ' Parkinson ', "" Parkinson's disease "", ' Parkinsons disease ', ' Primary Parkinsonism ', ' Patients ', ' Physicians ', ' Primary Health Care ', ' Primary Care ', ' Primary Healthcare ', ' Reference Standards ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Risk Factors ', ' Semantics ', ' Sensitivity and Specificity ', ' Signs and Symptoms ', ' Diagnostic Findings ', ' Speech ', ' Technology ', ' Testing ', ' Time ', ' United States ', ' Measures ', ' Caregivers ', ' Care Givers ', ' falls ', ' Resource Allocation ', ' Data Set ', ' Dataset ', ' base ', ' improved ', ' Procedures ', ' Acute ', ' Clinical ', ' Training ', ' Individual ', ' mental state ', ' mental status ', ' tool ', ' Cognitive Disturbance ', ' Cognitive Impairment ', ' Cognitive decline ', ' Cognitive function abnormal ', ' Disturbance in cognition ', ' cognitive dysfunction ', ' cognitive loss ', ' Impaired cognition ', ' Diagnostic ', ' machine learned ', ' Machine Learning ', ' Psychiatric Diagnosis ', ' cognitive function ', ' Neurocognitive ', ' Visit ', ' Services ', ' early detection ', ' Early Diagnosis ', ' success ', ' Structure ', ' Study Subject ', ' Position ', ' Positioning Attribute ', ' Coding System ', ' Code ', ' Sampling ', ' Documentation ', ' Provider ', ' preventing ', ' prevent ', ' Address ', ' Health system ', ' Data ', ' Data Element ', ' Cognitive ', ' Validation ', ' Text ', ' Development ', ' developmental ', ' electronic data ', ' Electronic Health Record ', ' electronic health care record ', ' electronic healthcare record ', ' Clinical assessments ', ' Population ', ' multidisciplinary ', ' demographics ', ' aging population ', ' aged population ', ' population aging ', ' primary care setting ', ' electronic structure ', ' financial incentive ', ' financial reward ', ' monetary incentive ', ' risk mitigation ', ' screening ', ' mild cognitive impairment ', ' mild cognitive disorder ', ' cognitive testing ', ' cognitive assessment ', ' treatment choice ', ' Preventive care ', ' Preventative care ', ' secondary analysis ', ' recruit ', ' health care settings ', ' healthcare settings ', ' testing services ', ' insurance claims ', ' care coordination ', ' coordinating care ', ' deep learning ', ' machine learning algorithm ', ' machine learned algorithm ', "" Alzheimer's disease related dementia "", ' AD related dementia ', ' ADRD ', ' Alzheimer related dementia ', ' Data Scientist ', ' automated speech recognition ', ' automatic speech recognition ', ' adverse event risk ', ' structured data ', ' unstructured data ', ' feature extraction ', ' learning classifier ', ' clinical encounter ', ' ']",NIA,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,805312
"Characterizing the temporal processing of speech in the human auditory cortex Project Summary Time is the fundamental dimension of sound, and temporal integration is thus fundamental to speech perception. To recognize a complex structure such as a word in fluent speech, the brain must integrate across many different timescales spanning tens to hundreds of milliseconds. These timescales are considerably longer than the duration of responses at the auditory nerve. Therefore, the auditory cortex must integrate acoustic information over long and varied timescales to encode linguistic units. On the other hand, the nature of the intermediate units of representation between sound and meaning remains debated. Focal brain injuries have shown selective impairment at all levels of linguistic processing (phonemic, phonotactic, and semantic) but current models of spoken word recognition disagree on the existence and type of these representational levels. The neural basis of temporal and linguistic processing remains speculative partly due to the limited spatiotemporal resolution of noninvasive human neuroimaging techniques which is needed to study the encoding of fluent speech. Our multi- PI proposal overcomes these challenges by assembling a team of researchers and clinicians with complementary expertise at NYU and Columbia University. We propose to record invasively from a large number of neurosurgical patients, which provides a rare and unique opportunity to collect direct cortical recordings across several auditory regions. We propose novel experimental paradigms and analysis methods to investigate where, when, and how acoustic features of speech are integrated over time to encode linguistic units. Our experimental paradigms will determine the functional and anatomical organization of stimulus integration periods in primary and nonprimary auditory cortical regions and relate the temporal processing in these regions to the emergence of phonemic-, phonotactic-, and semantic-level representations. Finally, we will determine the nonlinear computational mechanisms that enable the auditory cortex to integrate fast features over long durations, which is essential in speech recognition. Understanding of the temporal processing of speech in primary and nonprimary auditory cortex is critical for developing complete models of speech perception in the human brain, which is essential to understanding of how these processes break down in speech and communication disorders. Project Narrative The process of mapping acoustic signals onto units of syllables, words, and phrases is essential to human communication and is also remarkably difficult to replicate in machine systems. We propose an approach that leverages novel speech paradigms, computational modeling and invasive neural measures in neurosurgical patients in order to characterize human cortical speech perception. Using these complementary approaches in tandem with high resolution recording, we will greatly advance our understanding of how speech is processed and temporal information is integrated over time in various parts of cortex in in the hopes that our findings will inform new therapeutic strategies for a range of speech communication impairments.",Characterizing the temporal processing of speech in the human auditory cortex,10211535,R01DC018805,"['Auditory area ', ' Auditory Cortex ', ' auditory pathway ', ' Behavioral Research ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Communication ', ' Communication impairment ', ' Communication Disorders ', ' Communicative Disorders ', ' Communities ', ' Implanted Electrodes ', ' Heterogeneity ', ' Human ', ' Modern Man ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Light ', ' Photoradiation ', ' Linguistics ', ' Linguistic ', ' Methods ', ' Neurobiology ', ' neurobiological ', ' neurophysiology ', ' neurophysiological ', ' New York ', ' Patients ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Semantics ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' sound ', ' Speech ', ' Speech Disorders ', ' Speech Manifestations ', ' Speech Perception ', ' Speech Sound ', ' Technology ', ' Testing ', ' Time ', ' Universities ', ' Measures ', ' Speech Pathology ', ' Custom ', ' Prosthesis ', ' Prosthetic device ', ' Prosthetics ', ' density ', ' Area ', ' Surface ', ' Link ', ' Stimulus ', ' receptive field ', ' Discipline ', ' Nature ', ' Msec ', ' millisecond ', ' Dimensions ', ' Auditory ', ' Complex ', ' Route ', ' Pattern ', ' Techniques ', ' System ', ' Focal Brain Injuries ', ' interest ', ' behavioral observation ', ' behavior observation ', ' speech recognition ', ' syntactic ', ' syntax ', ' phonology ', ' cohort ', ' neural ', ' relating to nervous system ', ' phrases ', ' Structure ', ' neuro-imaging ', ' neuroimaging ', ' novel ', ' Categories ', ' Early identification ', ' Modeling ', ' Connectionist Models ', ' Neural Network Models ', ' Perceptrons ', ' Neural Network Simulation ', ' response ', ' Address ', ' Data ', ' Resolution ', ' Scheme ', ' Process ', ' Behavioral ', ' pandemic disease ', ' pandemic ', ' design ', ' designing ', ' Impairment ', ' speech processing ', ' lexical processing ', ' lexical ', ' spatiotemporal ', ' novel therapeutic intervention ', ' new therapeutic approach ', ' new therapeutic intervention ', ' new therapeutic strategies ', ' new therapy approaches ', ' novel therapeutic approach ', ' novel therapeutic strategies ', ' novel therapy approach ', ' temporal measurement ', ' temporal resolution ', ' time measurement ', ' experimental study ', ' experiment ', ' experimental research ', ' human model ', ' model of human ', ' deep neural network ', ' deep learning based neural network ', ' deep learning neural network ', ' deep neural net ', ' Computer Models ', ' Computerized Models ', ' computational modeling ', ' computational models ', ' computer based models ', ' computerized modeling ', ' Acoustic Nerve ', ' Cranial Nerve Eight ', ' Cranial Nerve VIII ', ' Eighth Cranial Nerve ', ' VIIIth Cranial Nerve ', ' Vestibulocochlear Nerve ', ' auditory nerve ', ' Acoustics ', ' Acoustic ', ' Anatomy ', ' Anatomic ', ' Anatomic Sites ', ' Anatomic structures ', ' Anatomical Sciences ', ' ']",NIDCD,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,681122
"International Conference on Advances in Quantitative Laryngology,  Voice and Speech Research (AQL) Project Abstract This proposal requests support to convene the next three International Conferences on Advances in Quantitative Laryngology, Voice and Speech Research (AQL). During the 5 years of requested support, the 14th, 15th, and 16th AQL (2021, 2023, and 2025 respectively) will be assembled. The 14th AQL will be held in Bogota, Colombia, South America, June 9 and 10, 2021 (pre-conference workshops June 7 and 8), the 15th will be in Phoenix, AZ, USA, in April 2023, while location of the 16th AQL conference will be determined during the 2021 conference (potential locations in South Korea or Germany). AQL is a valuable scientific meeting in the field of voice research and is regarded by voice and speech science specialists as a high quality international scientific meeting. AQL fosters the exchange of theoretical, experimental, and methodological advances, thereby progressing the translational and clinical aspects of voice and speech science. This multidisciplinary conference brings together scientists, clinicians, and students from around the world in various disciplines including Engineering, Biology, Physics, Otolaryngology and Speech Pathology. This proposal will allow for conference development and continuity to ensure an equitable conference that maintains its cutting-edge focus and provide support for students and early career investigators. The continuity of support will also ensure metrics and evaluations from previous conferences to be used to guide future AQL planning. The goals of this proposal are: to promote and support the education and development of young and underrepresented investigators in the voice and speech research community, organize special sessions on emerging research areas specific to quantitative laryngology, voice and speech research, to develop and foster digital networking strategies to provide a more inclusive and equitable conference, and to establish a Steering Committee. NIH funds are requested to provide support for child/family care, conference support for students and keynote speakers, students to assist Chair/Co-Chairs with various logistic needs, before, during and after the AQL conferences, website design and management, and streaming support during the meeting. In the off- conference years, necessary activities will include: student research trainee support, maintaining AQL website, Steering Committee meetings for conference evaluation and planning. Project Narrative This proposal seeks funding for the upcoming 14th, 15th, and 16th International Conference on Advances in Quantitative Laryngology, Voice and Speech Research (AQL) and the associated workshops and pre- conference, taking place in 2021, 2023, and 2025. AQL is an important international scientific meeting specialized in translational research and methods for measurement and modeling of voice and speech. Special emphasis will be given to promoting young investigators and underrepresented populations, digital networks to support a more inclusive and equitable conference, and to develop a permanent AQL website to help disseminate AQL information.","International Conference on Advances in Quantitative Laryngology,  Voice and Speech Research (AQL)",10237766,R13DC019564,"['Award ', ' Biology ', ' Carbon ', ' Child ', ' 0-11 years old ', ' Child Youth ', ' Children (0-21) ', ' youngster ', ' Colombia ', ' Communities ', ' Education ', ' Educational aspects ', ' Engineering ', ' Environment ', ' Family ', ' Fees ', ' Future ', ' Germany ', ' Goals ', ' Disabled Persons ', ' Disabled Population ', ' Handicapped ', ' People with Disabilities ', ' Persons with Disabilities ', ' disabled ', ' disabled individual ', ' disabled people ', ' individuals with disabilities ', ' Health ', ' Recording of previous events ', ' History ', ' South Korea ', ' Republic of Korea ', ' Leadership ', ' Mentors ', ' Methodology ', ' Persons ', ' United States National Institutes of Health ', ' NIH ', ' National Institutes of Health ', ' Occupations ', ' Jobs ', ' Professional Positions ', ' Online Systems ', ' On-Line Systems ', ' online computer ', ' web based ', ' Otolaryngology ', ' otorhinolaryngology ', ' Physics ', ' Request for Proposals ', ' Research ', ' Research Personnel ', ' Investigators ', ' Researchers ', ' Safety ', ' Science ', ' South America ', ' Speech ', ' Students ', ' Travel ', ' Voice ', ' Woman ', ' Child Support ', ' Measures ', ' Speech Pathology ', ' symposium ', ' conference ', ' convention ', ' summit ', ' symposia ', ' Research Methodology ', ' Research Methods ', ' Specialist ', ' Caring ', ' career ', ' improved ', ' Area ', ' Clinical ', ' Ensure ', ' Evaluation ', ' Discipline ', ' Educational workshop ', ' Workshop ', ' Fostering ', ' Logistics ', ' Measurement ', ' Funding ', ' meeting abstracts ', ' machine learned ', ' Machine Learning ', ' posters ', ' programs ', ' Scientist ', ' Event ', ' Stream ', ' Location ', ' interest ', ' meetings ', ' expectation ', ' member ', ' outreach ', ' social ', ' Modeling ', ' International ', ' Collection ', ' Translational Research ', ' Translational Science ', ' translation research ', ' Update ', ' Development ', ' developmental ', ' web site ', ' website ', ' cost ', ' virtual ', ' digital ', ' design ', ' designing ', ' ethnic minority population ', ' ethnic minority ', ' multidisciplinary ', ' racial and ethnic ', ' ethnoracial ', ' Underrepresented Populations ', ' Underrepresented Groups ', ' under representation of groups ', ' under represented groups ', ' under represented populations ', ' underrepresentation of groups ', ' minority student ', ' recruit ', ' preservation ', ' COVID-19 pandemic ', ' COVID crisis ', ' COVID epidemic ', ' COVID pandemic ', ' COVID-19 crisis ', ' COVID-19 epidemic ', ' COVID-19 global health crisis ', ' COVID-19 global pandemic ', ' COVID-19 health crisis ', ' COVID-19 public health crisis ', ' COVID19 crisis ', ' COVID19 epidemic ', ' COVID19 global health crisis ', ' COVID19 global pandemic ', ' COVID19 health crisis ', ' COVID19 pandemic ', ' COVID19 public health crisis ', ' SARS-CoV-2 epidemic ', ' SARS-CoV-2 global health crisis ', ' SARS-CoV-2 global pandemic ', ' SARS-CoV-2 pandemic ', ' SARS-CoV2 epidemic ', ' SARS-CoV2 pandemic ', ' SARS-coronavirus-2 epidemic ', ' SARS-coronavirus-2 pandemic ', ' Severe Acute Respiratory Syndrome CoV 2 epidemic ', ' Severe Acute Respiratory Syndrome CoV 2 pandemic ', ' Severe acute respiratory syndrome coronavirus 2 epidemic ', ' Severe acute respiratory syndrome coronavirus 2 pandemic ', ' corona virus disease 2019 epidemic ', ' corona virus disease 2019 pandemic ', ' coronavirus disease 2019 crisis ', ' coronavirus disease 2019 epidemic ', ' coronavirus disease 2019 global health crisis ', ' coronavirus disease 2019 global pandemic ', ' coronavirus disease 2019 health crisis ', ' coronavirus disease 2019 pandemic ', ' coronavirus disease 2019 public health crisis ', ' coronavirus disease crisis ', ' coronavirus disease epidemic ', ' coronavirus disease pandemic ', ' severe acute respiratory syndrome coronavirus 2 global health crisis ', ' severe acute respiratory syndrome coronavirus 2 global pandemic ', ' ']",NIDCD,MAYO CLINIC ARIZONA,R13,2021,40000
"CRCNS: Avian Model for Neural Activity Driven Speech Prostheses  Understanding the physical, computational, and theoretical bases of human vocal communication, speech, is crucial to improved comprehension of voice, speech and language diseases and disorders, and improving their diagnosis, treatment and prevention. Meeting this challenge requires knowledge of the neural and sensorimotor mechanisms of vocal motor control. Our project will directly investigate the neural and sensorimotor mechanisms involved in the production of complex, natural, vocal communication signals. Our results will directly enhance brain-computer interface technology for communication and will accelerate the development of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. We will develop a vocal prosthetic that directly translates neural signals in cortical sensorimotor and vocal-motor control regions into vocal communication signals output in real-time. Building on success using non-human primates for brain computer interfaces for general motor control, the prosthetic will be developed in songbirds, whose acoustically rich, learned vocalizations share many features with human speech. Because the songbird vocal apparatus is functipnally and anatomically similar to the human larynx, and the cortical regions that control it are closely analogous to speech motor-control areas of the human brain, songbirds offer an ideal model for the proposed studies. Beyond the application of our work to human voice and speech, development of the vocal prosthetic will enable novel speech-relevant studies in the songbird model that can reveal fundamental mechanisms of vocal learning and production. In the first stage of the project, we collect a large data set of simultaneously recorded neural activity and vocalizations. In stage two, we will apply machine learning and artificial intelligence techniques to develop algorithms that map neural recordings to vocal output and enable us to estimate intended vocalizations directly from neural data. In stage three, we will develop computing infrastructure to run these algorithms in real-time, predicting intended vocalizations from neural activity as the animal is actively producing these vocalizations. In stage four, we will test the effectiveness of the prosthetic by substituting the bird's own vocalization with the output from our prosthetic system. Success will set the stage for testing of these technologies in humans and translation to multiple assistive devices. In addition to our research goals, the project will engage graduate, undergraduate, and high school students through the development of novel educational modules that introduce students to brain machine interface and multidisciplinary studies that span engineering and the basic sciences. RELEVANCE (See instructions): Developing a vocal prosthesis will directly enhance brain-computer interface technology for communication and accelerate the realization of prostheses and other assistive technologies for individuals with communications deficits due to injury or disease. The basic knowledge of the neural and sensorimotor mechanisms of vocal motor control acquired will impact understanding of multiple voice, speech, and language diseases and disorders. The techniques developed will enabling novel future studies of vocal production and development. ",CRCNS: Avian Model for Neural Activity Driven Speech Prostheses ,10216216,R01DC018446,"['axon-glial signaling ', ' axonal signaling ', ' glia signaling ', ' glial signaling ', ' nerve signaling ', ' neural signaling ', ' neuronal signaling ', ' neurotransmission ', ' novel ', ' Basic Research ', ' Basic Science ', ' graduate student ', ' Prevention ', ' Modeling ', ' response ', ' Speech Development ', ' depository ', ' repository ', ' model development ', ' Limes ', ' Membrum superius ', ' Upper Limb ', ' Upper Extremity ', ' vocal learning ', ' Data ', ' Educational Materials ', ' Motor ', ' Principal Investigator ', ' Characteristics ', ' Development ', ' developmental ', ' Behavioral ', ' Output ', ' web site ', ' website ', ' Instruction ', ' design ', ' designing ', ' Clinical assessments ', ' brain computer interface ', ' brain machine interface ', ' neural model ', ' multidisciplinary ', ' Implant ', ' bird song ', ' birdsong ', ' open source ', ' functional restoration ', ' restore function ', ' restore functionality ', ' restore lost function ', ' motor control ', ' data sharing ', ' operation ', ' undergraduate student ', ' undergrad ', ' undergraduate ', ' signal processing ', ' Learning Module ', ' Education Module ', ' Educational Module ', ' Teaching Module ', ' High School Student ', ' Secondary School Student ', ' Secondary Student ', ' Course Content ', ' course curriculum ', ' High School Outreach ', ' Data Science ', ' hackathon ', ' hack day ', ' hackfest ', ' Infrastructure ', ' machine learning algorithm ', ' machine learned algorithm ', ' functional electrical stimulation ', ' functional electrostimulation ', ' large datasets ', ' large data sets ', ' effectiveness testing ', ' Acoustics ', ' Acoustic ', ' Algorithms ', ' Anatomy ', ' Anatomic ', ' Anatomic Sites ', ' Anatomic structures ', ' Anatomical Sciences ', ' Animals ', ' Artificial Intelligence ', ' AI system ', ' Computer Reasoning ', ' Machine Intelligence ', ' Behavior ', ' Birds ', ' Aves ', ' Avian ', ' Brain ', ' Brain Nervous System ', ' Encephalon ', ' Cell Nucleus ', ' Nucleus ', ' Clinical Research ', ' Clinical Study ', ' Communication ', ' Communities ', ' Complement ', ' Complement Proteins ', ' Computers ', ' Diagnosis ', ' Disease ', ' Disorder ', ' Electrodes ', ' Engineering ', ' Limb structure ', ' Extremities ', ' Limbs ', ' Non-Trunk ', ' Feedback ', ' Future ', ' Goals ', ' Recording of previous events ', ' History ', ' Human ', ' Modern Man ', ' Language ', ' Language Disorders ', ' Language disability ', ' language deficit ', ' Larynx ', ' Laryngeal ', ' Larynx Head and Neck ', ' voice box ', ' Maps ', ' Methods ', ' Motor Cortex ', ' neurophysiology ', ' neurophysiological ', ' Neurosciences ', ' Patients ', ' Play ', ' Production ', ' Quadriplegia ', ' Quadriplegic ', ' Tetraplegia ', ' tetraplegic ', ' Research ', ' Role ', ' social role ', ' Running ', ' Self-Help Devices ', ' Assistive Technology ', ' assisted device ', ' assistive device ', ' Signal Transduction ', ' Cell Communication and Signaling ', ' Cell Signaling ', ' Intracellular Communication and Signaling ', ' Signal Transduction Systems ', ' Signaling ', ' biological signal transduction ', ' Computer software ', ' Software ', ' Speech ', ' Students ', ' Technology ', ' Testing ', ' Time ', ' Translating ', ' Translations ', ' Voice ', ' Work ', ' Generations ', ' Outcome Measure ', ' Data Set ', ' Dataset ', ' Comprehension ', ' Prosthesis ', ' Prosthetic device ', ' Prosthetics ', ' Injury ', ' injuries ', ' base ', ' human subject ', ' Computer Interface ', ' improved ', ' Area ', ' Evaluation ', ' Individual ', ' nonhuman primate ', ' non-human primate ', ' Educational workshop ', ' Workshop ', ' Space Models ', ' Finches ', ' Robot ', ' Artificial Extremities ', ' Artificial Limbs ', ' prosthetic limb ', ' Limb Prosthesis ', ' machine learned ', ' Machine Learning ', ' Knowledge ', ' programs ', ' Complex ', ' Techniques ', ' System ', ' vocalization ', ' Degenerative Neurologic Diseases ', ' Degenerative Neurologic Disorders ', ' Nervous System Degenerative Diseases ', ' Neural Degenerative Diseases ', ' Neural degenerative Disorders ', ' Neurodegenerative Diseases ', ' Neurologic Degenerative Conditions ', ' degenerative diseases of motor and sensory neurons ', ' degenerative neurological diseases ', ' neurodegenerative illness ', ' Neurodegenerative Disorders ', ' meetings ', ' auditory feedback ', ' brain control ', ' mind control ', ' Performance ', ' success ', ' neural prosthetic ', ' neural prosthesis ', ' high school ', ' Animal Models and Related Studies ', ' model of animal ', ' model organism ', ' Animal Model ', ' neural ', ' relating to nervous system ', ' Neural Development ', ' neurodevelopment ', ' Oscines ', ' song bird ', ' Songbirds ', ' Nerve Impulse Transmission ', ' Nerve Transmission ', ' Neuronal Transmission ', ' axon signaling ', ' ']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,333282
