text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision   To understand and navigate the environment, sensory systems must solve simultaneously two competing and challenging tasks: the segmentation of a sensory scene into individual objects and the grouping of elementary sensory features to build these objects. Understanding perceptual grouping and segmentation is therefore a major goal of sensory neuroscience, and it is central to advancing artificial perceptual systems that can help restore impaired vision. To make progress in understanding image segmentation and improving algorithms, this project combines two key components. First, a new experimental paradigm that allows for well-controlled measurements of perceptual segmentation of natural images. This addresses a major limitation of existing data that are either restricted to artificial stimuli, or, for natural images, rely on manual labeling and conflate perceptual, motor, and cognitive factors. Second, this project involves developing and testing a computational framework that accommodates bottom-up information about image statistics and top-down information about objects and behavioral goals. This is in contrast with the paradigmatic view of visual processing as a feedforward cascade of feature detectors, that has long dominated computer vision algorithms and our understanding of visual processing. The proposed approach builds instead on the influential theory that perception requires probabilistic inference to extract meaning from ambiguous sensory inputs. Segmentation is a prime example of inference on ambiguous inputs: the pixels of an image often cannot be labeled with certainty as grouped or segmented. This project will test the hypothesis that human visual segmentation is a process of hierarchical probabilistic inference. Specific Aim 1 will determine whether the measured variability of human segmentations reflects the uncertainty predicted by the model, as required for well-calibrated probabilistic inference. Specific Aim 2 addresses how feedforward and feedback processing in human segmentation contribute to efficient integration of visual features across different levels of complexity, from small contours to object parts. Specific Aim 3 will determine reciprocal interactions between perceptual segmentation and top-down influences including: semantic scene content; visual texture discrimination; and expectations reflecting environmental statistics. The proposed approach models these influences as Bayesian priors, and thus, if supported by the proposed experiments, will offer a unified framework to understand the integration of bottom-up and top- down influences in human segmentation of natural inputs. RELEVANCE (See instructions): This project aims to provide a unified understanding of perceptual segmentation and grouping of visual inputs encountered in the natural environment, through correct integration of the information contained in the visual inputs with top-down information about objects and behavioral goals. This understanding is central to advancing artificial perceptual systems that can help restore impaired vision in patient populations. n/a",CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision  ,9916219,R01EY031166,"['Address', 'Algorithms', 'Behavioral', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Set', 'Discrimination', 'Environment', 'Experimental Designs', 'Feedback', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Individual', 'Influentials', 'Instruction', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Motor', 'Neurodevelopmental Disorder', 'Neurons', 'Participant', 'Perception', 'Process', 'Protocols documentation', 'Recurrence', 'Semantics', 'Sensory', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Texture', 'Uncertainty', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'base', 'behavior influence', 'computer framework', 'deep learning', 'detector', 'expectation', 'experimental study', 'flexibility', 'imaging Segmentation', 'improved', 'object recognition', 'patient population', 'predictive modeling', 'sensory input', 'sensory integration', 'sensory neuroscience', 'sensory system', 'statistics', 'theories', 'vision science', 'visual processing']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2019,195245,0.06719732589234889
"Tools for modeling state-dependent sensory encoding by neural populations across spatial and temporal scales Project Summary Throughout life, humans and other animals learn statistical regularities in the natural acoustic environment. They adapt their hearing to emphasize the features of sound that are important for making behavioral decisions. Normal-hearing humans are able to perceive important sounds in crowded noisy scenes and to understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. A better understanding of the function of the healthy and impaired auditory system will support new treatments for these deficits. This project will develop computational tools to study central auditory processing. A software library will support fitting and evaluating a large number of encoding models to describe the functional relationship between a time-varying natural auditory stimulus and the corresponding neural response. Many such models have been proposed, but relatively few direct comparisons have been made between them. This project will enable their comparison, allowing identification of the key features that contribute positively to their performance. The system will have a modular design so that useful elements from different models can be combined into comprehensive models with even greater explanatory power. The software will be open source and will support data from multiple recording modalities, including small-scale single unit electrophysiological and calcium imaging data, as well as large-scale local field and magnetoencephalography data. In addition to building on existing hypotheses about neural coding, the system will support machine learning methods for fitting artificial neural network models using the same datasets. These large, data-driven models have proven valuable for wide ranging signal processing problems, but their value and relation to existing models for neural sensory processing remain to be explored. Sensory processing involves coherent activity of large neural populations. To study coding at the population level, the system will support models that characterize the simultaneous activity of multiple neural signals and identifies latent subspaces of population activity related to sound encoding. Sensory coding is also influenced by behavioral context, reflecting changes in behavioral demands and the more general environment. The system will incorporate behavioral state variables into models, where encoding properties can be modulated by changes in behavioral context. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particularly in challenging noisy environments. We seek to understand how the neural populations in the healthy brain represent complex natural sounds. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Tools for modeling state-dependent sensory encoding by neural populations across spatial and temporal scales,9774688,R01EB028155,"['Acoustics', 'Algorithms', 'Animals', 'Architecture', 'Area', 'Arousal', 'Attention', 'Auditory', 'Auditory Perceptual Disorders', 'Auditory system', 'Behavioral', 'Biological Models', 'Brain', 'Calcium', 'Calcium Signaling', 'Code', 'Communities', 'Complex', 'Computer software', 'Crowding', 'Data', 'Data Set', 'Development', 'Devices', 'Dimensions', 'Electrophysiology (science)', 'Elements', 'Environment', 'Foundations', 'Goals', 'Hearing', 'Hearing problem', 'Human', 'Image', 'Imagery', 'Impairment', 'Individual', 'Judgment', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Magnetoencephalography', 'Measurement', 'Metadata', 'Methods', 'Modality', 'Modeling', 'Motion', 'Neural Network Simulation', 'Neurons', 'Non-linear Models', 'Patients', 'Performance', 'Peripheral', 'Population', 'Problem Solving', 'Property', 'Publications', 'Publishing', 'Pythons', 'Reproducibility', 'Sensory', 'Sensory Process', 'Signal Transduction', 'Speech', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Visual system structure', 'artificial neural network', 'auditory processing', 'auditory stimulus', 'base', 'behavior influence', 'computerized tools', 'data format', 'deep neural network', 'design', 'experimental study', 'graphical user interface', 'hearing impairment', 'insight', 'learning strategy', 'nervous system disorder', 'neural model', 'neurophysiology', 'neurotransmission', 'normal hearing', 'novel', 'online repository', 'open source', 'receptive field', 'reconstruction', 'relating to nervous system', 'response', 'sensory stimulus', 'sensory system', 'signal processing', 'sound', 'tool']",NIBIB,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,794000,0.023136159808559986
"Neural representation of the geometry and functionality in a scene ﻿    DESCRIPTION (provided by applicant):  The goal of the proposed research is to investigate how the brain represents scene geometry and functionality. Recognizing the visual environment is central to our daily interactions with the world. When we walk into a new space, we rapidly recognize whether there is a path to follow, whether there are crossable boundaries, and whether there are obstacles that block our view and potential navigation. The theoretical framework of this proposal is based on evidence that there are distinct but complementary levels of scene representation across a group of scene-selective regions in the brain (Park et al., 2011; Park et al., 2014; Park & Chun, 2009; Park, Chun, & Johnson, 2010; Park, Intraub, Yi, Widders, & Chun, 2007). The PI proposes that scene geometry (e.g., spatial layout, three-dimensional scene boundary) and functionality (e.g., navigability, limitations of a boundary) are two fundamental scene properties represented in these regions. Specific Aims: Aim 1 investigates whether the brain displays acute sensitivity to the presence of vertical boundaries, and how such sensitivity is modulated by the functional impediment that a boundary presents to the viewer's potential navigation. Aim 2 investigates the neural representation of the scene navigability, and how this representation differs from representation of scene geometry. Aim 3 investigates whether the neural representation of real world scenes is modulated by acquired knowledge about the spatio-temporal context of a scene, which are important for functionality of a scene. Throughout her aims, the PI tests medial temporal lobe regions in human adults that process scene and spatial information: with particular focus on anterior and posterior parahippocampal gyri and retrosplenial cortex. Methods include univariate and multi-voxel fMRI pattern analyses (linear support vector machine classification and representational similarity analysis) in combination with both region-of-interest (ROI) based and whole-brain based (search light) approaches. Hypothesis and preliminary results throughout the proposal suggest that scene geometry is represented in the parahippocampal gyrus, while scene functionality is represented in the retrosplenial cortex. PUBLIC HEALTH RELEVANCE: The research program will establish new framework for understanding the cognitive neuroscience architecture of scene perception, with the aim of unraveling how the human brain analyzes the geometry and functionality of visual environment in order to guide our actions and navigation in the world.",Neural representation of the geometry and functionality in a scene,9694232,R01EY026042,"['3-Dimensional', '4 year old', 'Acute', 'Adult', 'Anterior', 'Architecture', 'Area', 'Base of the Brain', 'Behavioral', 'Brain', 'Categories', 'Cells', 'Characteristics', 'Child', 'Classification', 'Complement', 'Complex', 'Confusion', 'Development', 'Dimensions', 'Environment', 'Fishes', 'Floor', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Height', 'Human', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Light', 'Machine Learning', 'Medial', 'Methods', 'Modeling', 'Movement', 'Multivariate Analysis', 'Nature', 'Neurologic', 'Parahippocampal Gyrus', 'Patients', 'Pattern', 'Perception', 'Process', 'Property', 'Rattus', 'Research', 'Rodent', 'Semantics', 'Shapes', 'Temporal Lobe', 'Testing', 'Time', 'Vision', 'Visual', 'Visuospatial', 'Walking', 'Work', 'base', 'cognitive neuroscience', 'experimental study', 'extrastriate visual cortex', 'interest', 'neuroimaging', 'neurophysiology', 'novel', 'programs', 'public health relevance', 'rehabilitation strategy', 'relating to nervous system', 'spatiotemporal', 'vector']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2019,318065,0.060291664431889665
"Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning PROJECT SUMMARY/ABSTRACT Selective attention is an essential cognitive ability that permits us to effectively process and act upon relevant information while ignoring distracting events. A network involving frontal and parietal cortex for top-down attentional control, referred to as the Dorsal Attention Network (DAN), is active during both spatial and non- spatial (feature-based) attention. However, we know very little about the fine structure of attentional control activity in the DAN, how this structure changes to represent different to-be-attended stimulus features, how the connectivity within the DAN, and between the DAN and sensory cortex shifts when attending different features, or how these top-down processes and their influence in sensory cortex unfold over time. This gap in our knowledge is a critical problem for our models and theories of attention, and because attentional deficits are involved in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia. The working model guiding this research is that top-down attentional control, based on different to-be-attended stimulus attributes, is guided by a smaller-scale neural fine structure within the DAN and prefrontal cortex that makes specific connections with specialized areas of visual cortex coding the attended attributes. Moreover, the time course of activity within the DAN in relation to that in sensory cortex follows a top-down cascading model, being earliest in frontal, then parietal cortex, and finally sensory cortex for preparatory, voluntary, attentional control. To identify the functional networks for attentional control for different forms of attention, and to define their time courses, this project uses innovative simultaneous recording of electroencephalographic (EEG) and functional magnetic resonance imaging (fMRI) data. Advanced signal processing and modeling, including multivariate pattern analysis (MVPA), graph theoretic connectivity analysis, and Granger causality analysis will be used to reveal the fine functional anatomy and time course of attentional control and selection. The project includes three experiments that vary the to-be-attended stimulus attributes from spatial location to stimulus features (color and motion), and pursues three aims. Aim 1 is to reveal the fine structure of top-down preparatory attentional control for different to-be-attended stimulus features. Aim 2 is to elucidate the specific connectivity between fine structures for preparatory attentional control in the DAN and their target sensory structures in sensory cortex. Aim 3 is to reveal the time course of top-down attentional control for different to-be-attended stimulus attributes. PROJECT NARRATIVE The capacity to focus attention is at the core of human mental functioning, and therefore, elucidating the neural bases of attention remains a central challenge for neuroscience, representing an essential aim in translational efforts to ameliorate attentional deficits in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia.",Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning,9718308,R01MH117991,"['Anatomy', 'Attention', 'Attention Deficit Disorder', 'Attentional deficit', 'Brain', 'Code', 'Color', 'Cues', 'Data', 'Dementia', 'Discrimination', 'Dorsal', 'Etiology', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'Graph', 'Human', 'Inferior', 'Knowledge', 'Location', 'Machine Learning', 'Modeling', 'Motion', 'Neurosciences', 'Parietal Lobe', 'Pattern', 'Perception', 'Physiological', 'Prefrontal Cortex', 'Process', 'Property', 'Research', 'Schizophrenia', 'Sensory', 'Specific qualifier value', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Work', 'attentional control', 'autism spectrum disorder', 'base', 'cognitive ability', 'data integration', 'experimental study', 'extrastriate visual cortex', 'frontal lobe', 'indexing', 'innovation', 'mental function', 'neuropsychiatric disorder', 'predictive modeling', 'relating to nervous system', 'selective attention', 'sensory cortex', 'signal processing', 'theories', 'tool']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2019,530307,0.04131512906614843
"Natural image processing in the visual cortex Project Summary Signals from the natural environment are processed by neuronal populations in the cortex. Understanding the relationship between those signals and cortical activity is central to understanding normal cortical function and how it is impaired in psychiatric and neurodevelopmental disorders. Substantial progress has been made in elucidating cortical processing of simple, parametric stimuli, and computational technology is improving descriptions of neural responses to naturalistic stimuli. However, how cortical populations encode the complex, natural inputs received during every day perceptual experience is largely unknown. This project aims to elucidate how natural visual inputs are represented by neuronal populations in primary visual cortex (V1). Progress to date has been limited primarily by two factors. First, during natural vision, the inputs to V1 neurons are always embedded in a spatial and temporal context, but how V1 integrates this contextual information in natural visual inputs is poorly understood. Second, prior work focused almost exclusively on single-neuron firing rate, but to understand cortical representations one must consider the structure of population activity— the substantial trial-to-trial variability that is shared among neurons and evolves dynamically—as this structure influences population information and perception. The central hypothesis of this project is that cortical response structure is modulated by visual context to approximate an optimal representation of natural visual inputs. To test the hypothesis, this project combines machine learning to quantify the statistical properties of natural visual inputs, with a theory of how cortical populations should encode those images to achieve an optimal representation, to arrive at concrete, falsifiable predictions for V1 response structure. The predictions will be tested with measurements of population activity in V1 of awake monkeys viewing natural images and movies. Specific Aim 1 will determine whether modulation of V1 response structure by spatial context in static images is consistent with optimal encoding of those images, and will compare the predictive power of the proposed model to alternative models. Specific Aim 2 addresses V1 encoding of dynamic natural inputs, and will test whether modulation of V1 activity by temporal context is tuned to the temporal structure of natural sensory signals, as required for optimality. As both spatial and temporal are present simultaneously during natural vision, Specific Aim 3 will determine visual input statistics in free-viewing animals, and test space-time interactions in V1 activity evoked by those inputs. This project will provide the first test of a unified functional theory of contextual modulation in V1 encoding of natural visual inputs, and shed light on key aspects of natural vision that have been neglected to date. Project Narrative This project aims to determine how neurons in the visual cortex represent the inputs encountered during perceptual experience in the natural environment, through correct integration of visual information across space and time. In individuals with neurodevelopmental and psychiatric disorders, integration is often miscalibrated leading to perceptual impairments. Our study will advance knowledge of the relationship between natural sensory inputs and cortical activity, which is central to understanding normal cortical function and how it is impaired in patient populations.",Natural image processing in the visual cortex,9801995,R01EY030578,"['Address', 'Animal Testing', 'Area', 'Complex', 'Dependence', 'Development', 'Environment', 'Experimental Designs', 'Goals', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Light', 'Location', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Monkeys', 'Motion', 'Neurodevelopmental Disorder', 'Neurons', 'Perception', 'Population', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Sampling', 'Sensory', 'Signal Transduction', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'V1 neuron', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'base', 'computer framework', 'experience', 'experimental study', 'image processing', 'improved', 'model development', 'movie', 'neglect', 'patient population', 'relating to nervous system', 'response', 'sensory input', 'spatiotemporal', 'statistics', 'theories', 'vision science', 'visual information']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2019,417500,0.08064812085764175
"The behavioral functions of upper and lower cortical layers PROJECT SUMMARY/ABSTRACT  The cerebral cortex mediates all of human and animal cognition, encompassing a diverse set of abilities including sensation, perception, decision making, and motor planning. Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders. A major obstacle both to understanding normal behaving and to treating pathology is the high degree of complexity of cortical circuitry, which has remained largely enigmatic. The conventional view of neocortex has been that sensory processing begins in layer 4 (L4), which was identified a century ago as the principal target of thalamic axons carrying information from our sensory organs. Sensory transforms are widely believed to occur as excitation spreads serially along the densest axonal pathways (thalamus→L4→L2/3→L5/6). Recently we discovered that the cerebral cortex, rather than being a monolithic structure, may contain two entirely separate processing systems, activated by the same signals arising from the thalamus. L4 is thus not an obligatory distribution hub for cortical activity, and thalamus activates two distinct “strata” of cortex in parallel.  This proposal's goal is to identify the behavioral and computational roles of the upper (L2-4) and lower strata (L5/6) as well as the interactions between them. We will investigate the behavioral roles of these layers in the mouse whisker system. Specific layers will be optogenetically disrupted in a series of tactile behavioral tasks, in which task complexity is progressively increased. Interlaminar interactions will also be studied by recording electrophysiologically from specific layers during behavior and using novel machine learning techniques designed to identify the type of computation performed in different levels of “deep networks”. The dimensionality of the representation in a layer will be estimated under normal behaviors and when specific layers are inactivated.  Identifying fundamental functions of upper versus cortical layers will likely pave the way for future studies in other neocortical systems and in higher-order species. Moreover, as the different layers contain molecularly and biophysically distinct cell types and project to distinct downstream targets, specific neurological disorders may involve dysfunction of specific pathways, cell types, and layers. Establishing the behavioral and computational roles of these elements may contribute to development of targeted therapies. PROJECT NARRATIVE  Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders, but the behavioral and functional roles of cortical layers and cell types are unknown. Identifying the contributions of specific cortical layers to normal circuit function will lead to better treatment of pathological conditions.     ",The behavioral functions of upper and lower cortical layers,9695015,R01NS094659,"['Animals', 'Area', 'Auditory', 'Axon', 'Behavior', 'Behavioral', 'Biophysics', 'Brain', 'Cells', 'Cerebral cortex', 'Cognition', 'Complex', 'Corpus striatum structure', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Dimensions', 'Discrimination', 'Electrophysiology (science)', 'Elements', 'Esthesia', 'Functional disorder', 'Future', 'Goals', 'Halorhodopsins', 'Human', 'Individual', 'Machine Learning', 'Measures', 'Mediating', 'Mental disorders', 'Modality', 'Molecular', 'Morphology', 'Motor', 'Mus', 'Neocortex', 'Neurons', 'Organ', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Perception', 'Performance', 'Population', 'Role', 'Sensory', 'Sensory Physiology', 'Series', 'Shapes', 'Signal Transduction', 'Source', 'Spinal Cord', 'Stimulus', 'Structure', 'Synapses', 'System', 'Tactile', 'Task Performances', 'Techniques', 'Testing', 'Texture', 'Thalamic structure', 'Training', 'Vibrissae', 'biophysical properties', 'cell type', 'design', 'expectation', 'hippocampal pyramidal neuron', 'neocortical', 'nervous system disorder', 'novel', 'object shape', 'optogenetics', 'response', 'sensory discrimination', 'spatial integration', 'targeted treatment']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,350000,0.014565273175048058
"Cracking the Olfactory Code Project Summary (Overall: Cracking the Olfactory Code)  Sensation drives perception, which informs decisions and actions. Olfaction is the main sense used by most animals to interact with the environment. However, olfaction remains shrouded in mystery — we do not know which molecular odorant features matter to the olfactory system and which do not, how information about these features is recombined to create holistic odor representations within the brain, or how those representations relate to perception. As a consequence, we lack an empirical understanding of the core transformations taking place at each stage of olfactory processing, which ultimately lead to perception and behavior. In addition, we lack a clear theoretical framework for understanding how a stimulus space that is both discrete and high-dimensional yields a perceptual space that is continuous and low dimensional. Because the olfactory system is “shallow” — meaning that within two synapses information about complete odor objects is abstracted and generalized — understanding this specific circuit will also afford general insight both into architecturally-related allocortical brain regions critical to behavior (e.g., cerebellum, hippocampus), and into cortical centers that play a key role in integrating diverse sources of information (e.g., prefrontal cortex, posterior parietal cortex). Here we propose to reveal the computational logic of olfaction by collecting the first system-wide dataset of neural and perceptual responses to a large, principled set of odorants, and by applying a unified statistical and theoretical approach to its interpretation. This project will convene research groups with expertise that spans neurobiology, and will leverage recent technical advances in molecular genetics, neural imaging, electrophysiology, opto- and chemogenetics, human psychophysics, and machine learning to interrogate all levels (from peripheral receptors to cortex to perceptual and behavioral output) of the olfactory system. Taken together, these experiments will establish a reference dataset that reveals the key transformations performed by the olfactory system, test a key unifying theory for olfaction, and create a community-wide resource that will prompt new theory and experiment. This work will also have wide-ranging implications for our general understanding of how sensory information is organized in the brain to facilitate adaptive action. Project Narrative (Overall) The brain builds rich internal representations of the external world in order to support perception and behavior. Here we take advantage of the architectural simplicity of the mammalian olfactory system — and an interdisciplinary team whose expertise ranges from molecular genetics and optogenetic to machine learning and human psychophysics — to characterize how odor information is sequentially transformed by neural circuits to generate meaningful perception. This work will both address longstanding mysteries about the inner workings of the olfactory system, and reveal general principles that govern how the brain organizes and processes information.",Cracking the Olfactory Code,9814744,U19NS112953,"['Address', 'Affinity', 'Animals', 'Architecture', 'Area', 'Behavior', 'Behavioral', 'Behavioral Paradigm', 'Big Data', 'Biological', 'Brain', 'Brain region', 'Cerebellum', 'Chemicals', 'Code', 'Communities', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Decision Making', 'Development', 'Dimensions', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Frequencies', 'Hippocampus (Brain)', 'Human', 'Image', 'Lead', 'Link', 'Logic', 'Machine Learning', 'Measures', 'Modality', 'Modeling', 'Molecular', 'Molecular Genetics', 'Mus', 'Nasal Epithelium', 'Neurobiology', 'Neurons', 'Odorant Receptors', 'Odors', 'Olfactory Pathways', 'Output', 'Parietal Lobe', 'Pattern', 'Perception', 'Peripheral', 'Physiology', 'Play', 'Prefrontal Cortex', 'Process', 'Psychophysics', 'Research', 'Resources', 'Sense Organs', 'Sensory', 'Smell Perception', 'Source', 'Stimulus', 'Structural Models', 'Structure', 'Synapses', 'System', 'Testing', 'Time', 'Vision', 'Work', 'base', 'combinatorial', 'data integration', 'design', 'experimental study', 'genetic manipulation', 'high dimensionality', 'imaging approach', 'in vivo', 'information processing', 'insight', 'meetings', 'neural circuit', 'new technology', 'novel', 'olfactory bulb', 'olfactory receptor', 'olfactory stimulus', 'optogenetics', 'piriform cortex', 'receptor', 'relating to nervous system', 'response', 'sensory stimulus', 'sensory system', 'stimulus processing', 'theories', 'working group']",NINDS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,U19,2019,2774000,-0.016159525873899648
"Causal role of higher-order thalamo-cortical oscillations in sustained attention PROPOSAL SUMMARY/ABSTRACT Sustained attention – the continuous allocation of cognitive resources to respond to infrequent but behaviorally relevant stimuli – is impaired in many psychiatric disorders and represents an important aspect of cognitive control. Sustained attention requires top-down control and engagement with the external world, which is linked to both frontoparietal and thalamic controlling signals on primary sensor cortices. Despite the extensive behavioral characterization of sustained attention in animal models using the five-choice serial reaction time task (5-CSRTT), very little is known about the oscillatory interaction between the dorsal attention network and thalamo-cortical dynamics and its potential as a stimulation target for enhancing sustained attention. The objective of this project is to dissect the causal role of higher-order thalamo-cortical oscillations in sustained attention via temporally-precise rhythmic stimulation. I will focus on three regions in the visual thalamo-cortical network: higher-order visual thalamus (lateral aspect of lateral posterior nucleus, LPl), posterior parietal cortex (PPC), and primary visual cortex (V1). I will test the central hypothesis that LPl-cortical theta (4-7 Hz) functional connectivity causally coordinates PPC-V1 functional connectivity to facilitate sustained attention. The rationale of this work is that the proposed temporally-precise rhythmic optogenetic perturbations will directly test the causal role of thalamo-cortical functional connectivity in sustained attention. Accordingly, the two specific aims are: (1) Delineate the functional role of higher-order thalamo-cortical oscillations in sustained attention, (2) Determine the causal role of thalamo-cortical functional connectivity in sustained attention via temporally-precise rhythmic optogenetics. This work is significant because it will causally test a convergent model in which higher-order visual thalamus coordinates the parietal top-down control signals onto visual cortex that is crucial for developing circuit- based therapies to enhance sustained attention. The work is innovative due to its integration of closed-loop optogenetics circuit interrogation, multisite electrophysiology, freely-moving sustained attention task, and machine-learning tools for the investigation of the causal role of oscillatory synchronization. The overall positive impact of the proposed study is to provide a more comprehensive map of how the higher-order visual thalamus interacts with the frontoparietal control signal to modulate V1, and thus mediates sustained attention, a transdiagnostic cognitive function that shows impairment in many psychiatric disorders including attention deficit hyperactivity disorder, bipolar disorder, and schizophrenia. The implication of this study is that it may reveal a general mechanism underlying the interaction between two higher-order processing structures signaling to lower sensory cortices during cognitive processing. PROJECT NARRATIVE Sustained attention enables us to focus our cognitive resources on an activity for a prolonged period of time, and when impaired causes profound deficits in both cognition and behavior. Sustained attention is modulated by the thalamo-cortical rhythms. The research generated in this proposal will investigate (1) what oscillatory feature in the higher-order thalamo-cortical circuit is crucial for sustained attention, and (2) how the temporally- precise enhancing or disrupting of a thalamo-cortical oscillatory feature alters the functional connectivity in the circuit and behavioral outcomes mediated by sustained attention.",Causal role of higher-order thalamo-cortical oscillations in sustained attention,9835877,F31MH118799,"['Anatomy', 'Animal Model', 'Animals', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Behavior', 'Behavioral', 'Bipolar Disorder', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communication', 'Communities', 'Computers', 'Conflict (Psychology)', 'Couples', 'Data', 'Dorsal', 'Electrophysiology (science)', 'Exhibits', 'Ferrets', 'Foundations', 'Frequencies', 'Functional disorder', 'Impairment', 'Implant', 'Impulsivity', 'Investigation', 'Lasers', 'Lateral', 'Lateral posterior nucleus of thalamus', 'Length', 'Link', 'Machine Learning', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Neurons', 'Parietal', 'Parietal Lobe', 'Performance', 'Periodicity', 'Phase', 'Physiologic pulse', 'Prefrontal Cortex', 'Process', 'Psyche structure', 'Reaction Time', 'Research', 'Resources', 'Rewards', 'Role', 'Schizophrenia', 'Signal Transduction', 'Statistical Models', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thalamic structure', 'Therapeutic', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'base', 'behavioral outcome', 'calmodulin-dependent protein kinase II', 'cognitive control', 'cognitive function', 'functional disability', 'innovation', 'neurotransmission', 'novel', 'optogenetics', 'recruit', 'relating to nervous system', 'sensor', 'sensory cortex', 'signal processing', 'sustained attention', 'theories', 'tool', 'visual stimulus']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,F31,2019,36528,0.01890798835453119
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9803507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Simulation', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'learning strategy', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,334599,-0.03447618980600548
"Neurocognitive basis of attention and eye movement guidance in the real world scenes Summary/Abstract Real world scenes contain a wealth of information that guide where we look and help us search for things in our visual environment more efficiently. For example, if you were looking for a person in a city, you would look mostly on the sidewalk, whereas if you were looking for a car, you would concentrate your attention on the street. Despite the fact that behavioral experiments have increasingly quantified the role of object and scene knowledge in the guidance of attention and eye movements, models of these processes, particularly neural models, neglect the role of visual knowledge. The goal of this project is to determine whether regions of the brain shown to be important for object and scene recognition are involved in visual guidance in natural scenes. Prior results, including our preliminary data, show that the neural activity from object processing regions can be used to predict what object a person is going to look at next. However, critical questions that remain are: is this predictive activity influenced by scene and object knowledge and is it causally related to visual guidance? Answering these two questions are the specific goals of this proposal. Individuals undergoing neurosurgical evaluation for epilepsy provide the rare opportunity of recording directly from the human brain (intracranial electroencephalography, iEEG), which provides a superior spatial and temporal resolution measure of brain activity compared to other technique. These direct recordings also allow for electrical brain stimulation (EBS), which can provide causal evidence tying the activity in particular regions to cognitive function. Finally, these data will be supplemented by magnetoencephalography (MEG) data to examine whole brain effects in healthy individuals. iEEG and MEG data arising from regions involved in object and scene recognition will be analyzed by multivariate machine learning techniques to continually classify what subjects are viewing on a moment-to- moment basis. Furthermore, we will try to predict what object subjects will view next during free viewing and visual search in natural scenes based on their neural data. We will assess how these neural signals are modified by the presence or absence of information about typical locations of objects or people in the scene that have been shown to guide behavior. Finally, using EBS we will determine if there is a causal link between the activity in regions involved in coding for object and scene knowledge and visual guidance in natural scene vision. If successful, these studies would necessitate a substantial reshaping of models of visual attention in the human brain. The results could form the foundation of a program of research into the neural basis of attention and eye movement guidance in the real world. Attention, perception, and eye movement abnormalities are seen in a host of neurological and psychiatric disorders. Thus, these studies, and the models that arise from them, have the translational potential to advance our understanding of the neurological basis of these disorders and suggest potential neurally inspired rehabilitation strategies. Narrative Abnormalities in visual attention and eye movement guidance are seen in a host of neurological and psychiatric disorders, including visual agnosia, neglect, schizophrenia, autism, etc. The neural basis of visual attention and eye movement guidance in the real world is unknown; therefore it remains unknown how neural abnormalities in these disorders relate to real world visual deficits, which is a critical barrier to designing hypothesis-driven remediation strategies. The proposed research will take critical early steps towards understanding the neural basis of real world attention and eye movement control, which has the potential to transform our understanding of these critical visual processes. The results of this research will lead to a deeper understanding of the neurobiology of eye movement and attentional guidance, a circuit relevant to a number of disorders, and take a critical step towards developing hypotheses for remediation strategies.",Neurocognitive basis of attention and eye movement guidance in the real world scenes,9830940,R21EY030297,"['Agnosia', 'Anatomy', 'Attention', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Caring', 'Categories', 'Cities', 'Code', 'Computer Simulation', 'Computers', 'Data', 'Disease', 'Dorsal', 'Dyskinetic syndrome', 'Electrical Stimulation of the Brain', 'Electrodes', 'Electroencephalography', 'Environment', 'Epilepsy', 'Evaluation', 'Eye', 'Eye Movements', 'Foundations', 'Functional disorder', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Knowledge', 'Link', 'Literature', 'Location', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mediating', 'Mental disorders', 'Modeling', 'Monitor', 'Motivation', 'Multivariate Analysis', 'Mus', 'Neurobiology', 'Neurocognitive', 'Neurologic', 'Object Attachment', 'Operative Surgical Procedures', 'Parietal', 'Pathology', 'Perception', 'Persons', 'Play', 'Process', 'Research', 'Role', 'Saccades', 'Schizophrenia', 'Semantics', 'Site', 'Stimulus', 'Stream', 'Study models', 'Surface', 'System', 'Techniques', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual attention', 'Walking', 'attentional control', 'autism spectrum disorder', 'base', 'behavioral study', 'cognitive function', 'computer monitor', 'design', 'experimental study', 'neglect', 'nervous system disorder', 'neural circuit', 'neural model', 'neurotransmission', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'remediation', 'response', 'sample fixation', 'spatial relationship', 'temporal measurement', 'theories', 'visual process', 'visual processing', 'visual search']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2019,234750,0.08520747246444126
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9735214,R01DC015138,"['Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Behavior', 'Biological', 'Biomedical Engineering', 'Brain', 'Catalogs', 'Categories', 'Cells', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing Aids', 'Human', 'Individual', 'Industrialization', 'Inferior Colliculus', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Psychology', 'Research', 'Research Personnel', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'awake', 'base', 'computational neuroscience', 'data warehouse', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'normal hearing', 'novel', 'novel strategies', 'online repository', 'online resource', 'programs', 'relating to nervous system', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'summer internship', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2019,268961,0.027344315610890037
"Shifting auditory spatial attention: cognitive and neural mechanisms ﻿    DESCRIPTION (provided by applicant): Hearing can serve as an early warning system because it can panoramically monitor the environment for events happening at a distance or out of sight. These ecological considerations make the auditory system particularly useful for studying mechanisms for shifting spatial attention. The focus of this project is on the interplay between top-down and bottom-up spatial attention biases that govern shifting auditory attention to distractors during performance of a simple spatial attention task. The overall goal of this proposal is to use an interdisciplinary approach to better understand at the cognitive and neural levels of analysis how auditory attention is distributed over space. We will test the hypothesis that the spatial distribution of auditory attentional emerges from interactions among two basic factors. The first factor is a voluntary (top-down) attention bias that weakens with distance from the current focus of attention. Conversely, the second factor is an automatic (bottom-up) bias that is tuned to shift attention to unexpected events away from the current focus of attention. The first aim tests a computational model of top-down and bottom-up attention bias in shifting auditory spatial attention. Different aspects of the model will be quantitatively tested against findings from behavioral experiments, and observations will be used to further develop the model. The computational model will incorporate artificial intelligence methods to represent human cognitive processes. The second aim uses transcranial magnetic stimulation to test the role of key right hemisphere cortical areas in shifting of auditory spatial attention. We focus on neural mechanisms of bottom-up attentional bias. The third aim tests whether auditory attention gradients become less focused over time. This will determine how gradients relate to cognitive resources and neural blood flow measures that are known to decline with extended vigilance. This project will help advance knowledge in the field of auditory attention and cognitive hearing, and also addresses general issues in attention research such as top-down and bottom-up processes, vigilance, and their relations to neurobiological attention networks. Outcomes will have practical significance because shifting auditory attention is vital for avoiding accidents at ll ages, maintaining independent living at older ages, and is applicable to neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). PUBLIC HEALTH RELEVANCE: The project outcomes could have clinical in neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). The project will examine mechanisms of normal cognitive aging using computational modeling, which can inform the early detection, differential diagnosis, and treatment monitoring of age-related neurodegenerative disorders such as Alzheimer's disease. Knowledge from the transcranial magnetic and electrical DC stimulation experiments may have translational applications for rehabilitation following brain injuries.",Shifting auditory spatial attention: cognitive and neural mechanisms,9718188,R01DC014736,"['Accidents', 'Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Attention', 'Attention Deficit Disorder', 'Auditory', 'Auditory system', 'Behavioral', 'Blood flow', 'Brain Injuries', 'Clinical', 'Cognitive', 'Cognitive aging', 'Computer Simulation', 'Dementia', 'Differential Diagnosis', 'Diffuse', 'Dimensions', 'Early Diagnosis', 'Electroencephalography', 'Environment', 'Event', 'Goals', 'Hearing', 'Human', 'Impairment', 'Independent Living', 'Individual Differences', 'Inferior', 'Knowledge', 'Learning', 'Left', 'Location', 'Loudness', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Music', 'Neurobiology', 'Obstruction', 'Outcome', 'Parietal', 'Performance', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Probability', 'Process', 'Property', 'Reaction Time', 'Rehabilitation therapy', 'Reproduction', 'Research', 'Resources', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Site', 'Spatial Distribution', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Transcranial magnetic stimulation', 'Vision', 'Work', 'age related neurodegeneration', 'alpha-SNAP', 'attentional bias', 'attentional control', 'base', 'behavior measurement', 'cognitive process', 'cost shifting', 'experimental study', 'fighting', 'image guided', 'indexing', 'information processing', 'interdisciplinary approach', 'nervous system disorder', 'neural correlate', 'neural stimulation', 'neuroimaging', 'neuromechanism', 'normal aging', 'prefrontal lobe', 'public health relevance', 'relating to nervous system', 'response', 'sound', 'theories', 'vector', 'vigilance']",NIDCD,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2019,263449,0.018397727891417304
"Vision in Natural Tasks Summary/Abstract  In the context of natural behavior, humans make continuous sequences of sensory-motor decisions to satisfy current behavioral goals, and vision must provide the information needed to achieve those goals. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks in natural locomotion, or the requisite information, and the proposal attempts to specify these.  in the context of natural gait, the patterns of optic flow are unexpectedly complex, raising questions about its role. The patterns of motion on the retina during locomotion depend critically on both eye and body motion, and these in turn depend on behavioral goals. Our first Aim is therefore to comprehensively describe the statistics of retinal motion patterns in a variety of terrains and task contexts. We will measure binocular eye and body movements while walking in outdoor terrains of varying roughness, crossing a busy intersection, and making coffee. These contexts will induce different gaze patterns. We will provide a comprehensive description of the motion stimulus in natural locomotion and help separate out self-motion signals from externally generated motion. These data will allow a more precise specification of the response patterns in cortical motion sensitive areas. Because of the complexity of natural motion patterns, we will re-examine the influence of optic flow on walking direction in a virtual reality environment and test alternative explanations for the role of flow.  A central task in walking is foot placement, and we will focus on identifying the image properties that make a good foothold. Stereo, structure from motion, and spatial image structure are all likely contenders. We directly investigate the role of stereo in foothold selection by examining gait patterns in stereo-deficient subjects in terrains with varying degrees of roughness. Using a different strategy, we will attempt to predict gaze locations and footholds in rough terrain using convolution neural nets (CNN’s) to identify potential search templates for footholds in rough terrain. We will describe fixation patterns from crosswalk and sidewalk navigation and attempt to make inferences about their purpose, and use Modular Inverse Reinforcement Learning (MIRL) to predict direction decisions and decompose the behavior into sub-tasks.  The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists The work will be strengthened by the investigation of stereo- deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available. Project Narrative  The central goal of this work is to understand vision in its natural context. This is very important information in order to devise suitable vision aids and rehabilitation strategies for individuals with visual impairments, and it is becoming increasingly accessible because of developments in technology for monitoring eye and body movements. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks and requisite information in natural locomotion, and the proposal attempts to specify these. The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists. The work will be strengthened by the investigation of stereo-deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available.",Vision in Natural Tasks,9830977,R01EY005729,"['Affect', 'Area', 'Behavior', 'Behavioral', 'Binocular Vision', 'Cells', 'Characteristics', 'Coffee', 'Collection', 'Complex', 'Cues', 'Data', 'Data Set', 'Development', 'Distant', 'Environment', 'Eye', 'Eye Movements', 'Gait', 'Goals', 'Grant', 'Head', 'Human', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Link', 'Location', 'Locomotion', 'Machine Learning', 'Measures', 'Monitor', 'Motion', 'Motor', 'Movement', 'Pattern', 'Psychological reinforcement', 'Retina', 'Retinal', 'Rewards', 'Robot', 'Robotics', 'Role', 'Sampling', 'Seminal', 'Sensory', 'Signal Transduction', 'Speed', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Visit', 'Visual', 'Visual Fields', 'Visual impairment', 'Walkers', 'Walking', 'Work', 'base', 'convolutional neural network', 'cost', 'experimental study', 'foot', 'gaze', 'imaging properties', 'innovation', 'kinematics', 'novel', 'optic flow', 'rehabilitation strategy', 'response', 'sample fixation', 'statistics', 'virtual reality', 'vision aid', 'vision development', 'vision rehabilitation', 'visual information']",NEI,"UNIVERSITY OF TEXAS, AUSTIN",R01,2019,369009,0.03528201070397849
"Decoding parametric attributes of auditory working memories from human brain activity Decoding parametric attributes of auditory working memories from human brain activity Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Auditory WM dysfunctions are evidenced in individuals with speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as central auditory processing disorders (CAPD). Better understanding of auditory WM would help develop more precise biomarkers and targeted interventions for these deficits. Evidence for neuronal activation related to auditory WM patterns have been found in laboratory animals as well as in non- invasive human neuroimaging studies, both in auditory cortices (AC) and elsewhere in the brain. Recent human fMRI data also provide some evidence on item-specific activation patterns in ACs and frontal cortices. However, exactly where in the brain auditory WM content is stored and, more importantly, how the memorized information is represented is still unclear.  This research program pursues a better understanding of human auditory WM by attempting to infer its contents from the brain: Using state-of-the-art non-invasive neuroimaging and advanced signal-analysis methods we will search for cortical activation patterns that would predict item-specific WM information. We will examine brain function non-invasively with magneto- and electroencephalography (MEG/EEG), transcranial magnetic stimulation (TMS), and functional MRI (fMRI), and validate the findings using intracranial EEG (iEEG) measurements in presurgical patients. Recent studies suggest that, instead of persistent activation patterns, WM is supported by short-term synaptic facilitation, i.e., ""activity-silent"" population-level mechanisms. We hypothesize that these activity-silent representations could be decoded by analyzing the aftereffects of generic auditory ""impulse stimuli"" or TMS, which are utilized to ""ping"" the underlying cortical network during memory maintenance. We also hypothesize that although auditory WM likely involves co-operation of multiple brain regions, which are involved in articulatory-motor functions, perceptual categorization, or semantic processing, the retention of auditory-sensory attributes such as spectrotemporal modulation patterns critically depends on ACs. To examine WM of such auditory attributes, we will use tasks with dynamic ripple sound stimuli, which are spectrotemporally similar to human vocalizations but resist non-auditory processing strategies.  The major significance of this project is that it will increase the understanding of auditory WM, a crucial cognitive function whose neuronal bases have remained elusive. The results may also help develop more precise tools for characterizing auditory WM dysfunctions in hearing and communication deficits as well as in disorders such as dyslexia, attention deficit/hyperactivity disorder (ADHD), and schizophrenia. Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Our research program pursues a better theoretical understanding of this crucial cognitive function using advanced multimodal neuroimaging methods, validated using intracranial recordings in pre-surgical patients. Our results may also help develop more precise tools for characterizing auditory WM dysfunctions in speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as attention deficit/hyperactivity disorder (ADHD) and schizophrenia.",Decoding parametric attributes of auditory working memories from human brain activity,9654724,R01DC016915,"['Attention deficit hyperactivity disorder', 'Auditory', 'Auditory area', 'Biological Markers', 'Brain', 'Brain region', 'Central Auditory Processing Disorder', 'Cognition', 'Communication', 'Data', 'Disease', 'Dyslexia', 'Electroencephalography', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Hearing', 'Human', 'Impairment', 'Individual', 'Intervention', 'Laboratory Animals', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measurement', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Motor', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perceptual Disorders', 'Population', 'Principal Component Analysis', 'Problem Solving', 'Reading', 'Research', 'Schizophrenia', 'Sensory', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Speech Perception', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Transcranial magnetic stimulation', 'base', 'cognitive function', 'cortex mapping', 'electric field', 'experimental study', 'frontal lobe', 'multimodality', 'neuroimaging', 'operation', 'programs', 'semantic processing', 'sound', 'tool', 'vocalization']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,601029,0.01075137346929493
"Human Face Representation in Deep Convolutional Neural Networks The human visual system can recognize a familiar face across wide variations of viewpoint, illumination, expression, and appearance. This remarkable computational feat is accomplished by large-­scale networks of neurons. We will test a face space theory of the representations that emerge at the top layer of deep learning convolutional neural networks (DCNNs) as a model of human visual representations of faces. Computer-based face recognition has improved in recent years due to DCNNs and the easy availability of labeled training data (faces and identities) from the web. Inspired by the primate visual system, DCNNs are feed­forward artificial neural networks that can map images of faces into representations that support recognition over widely variable images. Although the calculations executed by the simulated neurons are simple, enormous numbers of computations are used to convert an image into a representation. The end result of this processing is a highly compact representation of a face that retains image detail in an invariant, identity­-specific face code. This code is fundamentally different than any representation of faces considered in vision science. This theory we test combines key components of previous face space models (similarity, learning history) with new features (imaging conditions, personal face history) in a unitary space that represents both identity and facial appearance across variable images. We will test whether this model can account for human recognition of familiar faces, which is highly robust to image variability (pose, illumination, expression). The model will also be applied to understanding long standing difficulties humans (and machines) have with faces of other races. We aim to bridge critical gaps in our knowledge of how DCNNs work, linking psychological, neural, and computational perspectives. A fundamentally new theory of face representation will alter the questions we ask about face representations in all three fields. A new focus on understanding how we (or neural networks) “perceive” a single familiar identity in widely variable images will give rise to a search for representations that gracefully merge the properties of faces with the real-­world image conditions in which they are experienced. This project presents a unique opportunity to study, manipulate, and learn from these representations, and to apply the findings to broader questions about high-­level vision from neural and perceptual perspectives. Human recognition of familiar faces is highly robust to image variability (pose, illumination, expression)—a skill that is likely due to the quality and quantity of experience we have with the faces of people we know well. Deep convolutional neural networks are modeled after the primate visual system and have made impressive gains recently on the problem of robust face recognition. Understanding the visual nature of the face “feature” codes that emerge in these networks can give insight into long-standing questions about how the human visual system can, but does not always, represent a face in a way that generalizes across images that vary widely.",Human Face Representation in Deep Convolutional Neural Networks,9641233,R01EY029692,"['Affect', 'Appearance', 'Categories', 'Code', 'Computers', 'Data', 'Data Set', 'Face', 'Face Processing', 'Familiarity', 'Human', 'Image', 'Individual', 'Internet', 'Knowledge', 'Label', 'Learning', 'Lighting', 'Link', 'Maps', 'Methods', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurons', 'Performance', 'Persons', 'Primates', 'Property', 'Published Comment', 'Race', 'Recording of previous events', 'Space Models', 'Testing', 'Training', 'Variant', 'Vision', 'Visual', 'Visual system structure', 'Work', 'artificial neural network', 'base', 'convolutional neural network', 'deep learning', 'experience', 'feedforward neural network', 'feeding', 'human model', 'improved', 'insight', 'neural network', 'psychologic', 'relating to nervous system', 'representation theory', 'skills', 'theories', 'vision science']",NEI,UNIVERSITY OF TEXAS DALLAS,R01,2019,387918,0.020706495481470206
"Towards a Compositional Generative Model of Human Vision Understanding object recognition has long been a central problem in vision science, because of its applied utility and computational difficulty. Progress has been slow, because of an inability to process complex natural images, where the largest challenges arise. Recently, advances in Deep Convolutional Neural Networks (DCNNs) spurred unprecedented success in natural image recognition. The general goal of this proposal is to leverage this success to test computational theories of human object recognition in natural images. However, DCNNs still markedly underperform humans when challenged with high levels of ambiguity, occlusion, and articulation. We hypothesize that humans' superior performance arises from the use of knowledge about how images and objects are structured. Preliminary evidence for this claim comes from the success of hybrid models, that combine DCNNS for identifying features and parts in images, with explicit knowledge of object and image structure. These computations occur within a hierarchy, which includes both top-down and bottom- up processing. The specific goal of the work proposed here is to strongly test whether these computational strategies, structured, hierarchical representations and bidirectional processing, are used to recognize objects in natural images. Human bodies are composed of hierarchically organized configurable parts, making them an ideal test domain. We examine the complete recognition process, from parts, to pairs of parts, to whole bodies, each in its own aim. Each aim also tests important sub-hypotheses about when and how the computational strategies are used. Aim 1 examines recognition of individual body parts, testing whether it is dependent on parsing images into more basic features and relationships, for example edges and materials. Aim 2 examines pairs of parts, testing the importance of knowledge of body connectedness relationships. Aim 3 examines perception of entire bodies, testing whether knowledge of global body structure guides bidirectional processing. In each aim, we first develop nested computer vision models that either do or do not make use of structural knowledge, to test whether it aids recognition. We then test whether human performance can be accounted for by the availability of that structural knowledge. We next measure neural activity with functional MRI to identify where and how it is used in cortex. Finally, we integrate these results to produce even stronger tests, using the nested models to predict human performance and confusion matrices as well as fMRI activity levels and confusion matrices. Altogether, this work will strongly test key theoretical accounts of object recognition in the most important domain, perception of natural images. The work, based on extensive preliminary data, measures and models the entire body recognition system. The models developed and tested here should surpass the state-of-the-art, and be useful for many real-world recognition tasks. The proposal will also lay the groundwork for future studies of recognition impaired by disease. This research uses computational, behavioral, and brain imaging methods to investigate how the visual system represents and processes information about human bodies. The studies will reveal how and when people can accurately recognize objects in natural images, how the brain supports this function, and how loss of information, similar to that that accompanies visual disease, may affect the ability to interpret everyday scenes.",Towards a Compositional Generative Model of Human Vision,9818274,R01EY029700,"['Affect', 'Area', 'Articulation', 'Behavioral', 'Body Image', 'Body part', 'Brain', 'Brain imaging', 'Complex', 'Computer Vision Systems', 'Confusion', 'Cues', 'Data', 'Development', 'Disease', 'Elbow', 'Feedback', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Human body', 'Hybrids', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Link', 'Measures', 'Modeling', 'Perception', 'Performance', 'Predictive Value', 'Process', 'Psychophysics', 'Published Comment', 'Research', 'Structure', 'System', 'Testing', 'Training', 'Vision', 'Visual', 'Visual system structure', 'Work', 'Wrist', 'base', 'convolutional neural network', 'crowdsourcing', 'human model', 'imaging modality', 'improved', 'object recognition', 'relating to nervous system', 'spatial relationship', 'success', 'theories', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2019,352996,0.04043159328319436
"Access to parietal action representations after stroke lesions in visual cortex PROJECT SUMMARY  The ability to recognize and use objects according to their function (e.g., fork, hammer, pencil) requires integration of visual, semantic and action knowledge across occipital, temporal and parietal areas. Left parietal regions support critical aspects of object-directed action, such as grasping and object manipulation. This research activity uses a combination of fMRI and behavioral measures in patients with ischemic strokes to early and extrastriate visual areas to test the following hypotheses: Aim 1: There is a visual pathway to the parietal grasp region (aIPS) that bypasses processing in primary visual cortex. Aim 2: Left ventral extrastriate cortex is necessary to access manipulation information for visually presented objects. Aim 3A: Ballistic grasping actions to objects in the hemianopic field are influenced by volumetric properties (size, orientation) of targets. Aim 3B: Left ventral extrastriate lesions impair object function (e.g., `scissors used to cut') and disrupt access to manipulation knowledge from visual input. The research leverages strengths of fMRI (whole brain correlational measure) and neuropsychology (causal inference) to test new hypotheses about vision and action.  `Tools' (i.e., small manipulable objects) are an excellent domain in which to address broader questions about the integration of sensory, motor and cognitive processing. This is because tool recognition and tool use require the integration of distinct sensory, motor and cognitive representations, and the neural substrates of tool processing are well described. The research program emphasizes fresh perspectives on longstanding ideas about the dorsal and ventral visual pathways, by a) undertaking the first systematic investigation of the types of information about objects that are extracted by visual pathways that bypass primary visual cortex, and by b) studying how some parietal areas depend on inputs from the ventral stream in order to access the correct action for a given object. The research activity innovates by testing hypotheses about how lesions at different stages in the cortical visual hierarchy affect downstream processing in parietal cortex, combining neural and behavioral measures to study brain damaged patients (generating causal evidence), and by combining univariate and multivariate measures to `read out' the information content of brain regions (parietal cortex) that are anatomically remote from a lesion. The research advances understanding of how lesions in one brain region disrupt computations in other parts of the brain that depend on the damaged region for their inputs, a phenomenon (`dynamic diaschisis') that applies to brain injury generally. Advancing understanding of these basic issues using causal data has broad implications for understanding how the brain selects the correct action for the correct object, and more generally for theories of conceptual organization and causal reasoning. Understanding how the brain accesses actions from visual input has implications for related fields, such as robotics, neuroprosthetics, and evidenced based approaches for rehabilitating function after brain injury. Project Narrative Functional MRI and behavioral testing are used to test hypotheses about how strokes affecting occipital and temporal cortex disrupt access to action representations in parietal cortex. This research will advance understanding of how the brain processes visual information in support of everyday actions.",Access to parietal action representations after stroke lesions in visual cortex,9659002,R01EY028535,"['Address', 'Affect', 'Alexia', 'Anatomy', 'Area', 'Ballistics', 'Behavioral Assay', 'Brain', 'Brain Injuries', 'Brain region', 'Bypass', 'Cognitive', 'Data', 'Dorsal', 'Eating', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Imaging Device', 'Impairment', 'Investigation', 'Ischemic Stroke', 'Knowledge', 'Left', 'Lesion', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Neural Pathways', 'Neuropsychology', 'Occipital lobe', 'Parahippocampal Gyrus', 'Parietal', 'Parietal Lobe', 'Participant', 'Pathway interactions', 'Patients', 'Population', 'Process', 'Property', 'Prosopagnosia', 'Reading', 'Research', 'Research Activity', 'Robotics', 'Role', 'Semantics', 'Sensory', 'Stimulus', 'Stream', 'Stroke', 'Structure of supramarginal gyrus', 'Temporal Lobe', 'Testing', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual system structure', 'Work', 'area striata', 'base', 'behavior measurement', 'behavior test', 'blind', 'cognitive development', 'evidence base', 'extrastriate', 'extrastriate visual cortex', 'fovea centralis', 'grasp', 'information processing', 'innovation', 'lens', 'multisensory', 'neuroprosthesis', 'post stroke', 'programs', 'relating to nervous system', 'sensory integration', 'theories', 'tool', 'visual information', 'visual motor', 'visual object processing', 'visual process', 'visual processing']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2019,439559,0.08353183835977013
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9637403,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Simulation', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'convolutional neural network', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2019,388812,0.0620740346975979
"Top-down control of auditory processing in the cortico-collicular network Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network,9634046,R01DC014950,"['Acoustics', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory Perceptual Disorders', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Non-linear Models', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory processing', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'experimental study', 'hearing impairment', 'insight', 'nervous system disorder', 'neurophysiology', 'normal hearing', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,327250,0.04035745280164657
"The cerebro-cerebellar-basal-gangliar network for visuomotor learning ABSTRACT Visual learning is critical to the lives of human and non-human primates. Visuomotor association, the assignment of an arbitrary symbol to a particular movement (like a red light to a braking movement), is a well- studied form of visual learning. This proposal tests the hypothesis that the brain accomplishes visuomotor associative learning using an anatomically defined closed-loop network, including the prefrontal cortex, the basal ganglia, and the cerebellum. In our preliminary work we have developed a task that studies how monkeys learn to associate one of two novel fractal symbols with a right hand movement, and the other symbol with a left hand movement. Every experiment begins with the monkeys responding to two overtrained symbols that they have seen hundreds of thousands of times. At an arbitrary time we change the symbols to two fractal symbols that the monkey has never seen. It takes the monkey 40 to 70 trials to learn the new associations. In our preliminary results we have discovered that Purkinje cells in the midlateral cerebellar hemisphere track the monkeys’ learning as they as they figure out the required associations. The neurons signal the result of the prior decision. Half of the neurons respond more when the prior decision was correct; the others respond more when the prior decision was wrong. The difference between the activity of these two types of neurons provides a cognitive error signal that is maximal when the monkeys are performing at a chance level, and gradually becomes not different from zero as the monkeys learn the task. The neurons do not predict the result of the impending decision. Although the neurons change their activity dramatically at the symbol switch, the kinematics of the movements do not change at all. This proposal takes this discovery as the starting point for four aims: 1) to use viral transynaptic tract tracing to discover the cortical and basal ganglia regions that project to the cerebellar visuomotor association area. 2) to record from the four nodes of the network as anatomically defined (midlateral cerebellar hemisphere, dentate nucleus, basal ganglia, prefrontal cortex), simultaneously, using multiple single neuron recordings, to see if these areas also have information about the process of visuomotor association 3) to inactivate each node, to see how their inactivation affects the monkey’s ability to learn new associations, and whether the inactivation affects the activity of the neurons at the other nodes. 4) to develop computational methods to analyze the activity of neural activity recorded simultaneously in all four nodes of the network (Aim 2) in the midlateral cerebellar cortex with regard to parameters such as prior outcome and movement, hand, symbol, and the intensity and epoch of the prior cognitive error signal. We will use dimensional reduction techniques to answer questions like whether hand or symbol can be decoded from network activity. We will model how the cerebellum simple spike cognitive error signal might propagate through the network and be used to facilitate visuomotor association learning and the processing of signals in the cerebellum, basal ganglia and cerebral cortex Project Narrative Learning that a particular object cues a particular action, as a red light makes us stop walking or brake the car, is critical for human behavior and can be degraded by human disease. This project will apply physiological, computational, and anatomical methods to investigate a brain network for visual learning. We will find the exact areas of the cerebral cortex, basal ganglia, and cerebellum that participate in this learning, and use machine learning techniques to understand how the activity of neurons recorded simultaneously in these brain areas can facilitate learning.",The cerebro-cerebellar-basal-gangliar network for visuomotor learning,9818745,R01NS113078,"['Affect', 'Agonist', 'Anatomy', 'Area', 'Association Learning', 'Basal Ganglia', 'Behavior', 'Brain', 'Cerebellar cortex structure', 'Cerebellum', 'Cerebral cortex', 'Cognition', 'Cognitive', 'Computational Technique', 'Computer Analysis', 'Computing Methodologies', 'Cues', 'Data Set', 'Dentate nucleus', 'Dimensions', 'Electronic Medical Records and Genomics Network', 'Exhibits', 'Failure', 'Fractals', 'Grant', 'Hand', 'Human', 'Injections', 'Learning', 'Left', 'Light', 'Machine Learning', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Movement', 'Muscimol', 'Neurons', 'Outcome', 'Parietal', 'Pathway Analysis', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physiological', 'Prefrontal Cortex', 'Process', 'Property', 'Purkinje Cells', 'Rabies virus', 'Reaction Time', 'Reading', 'Reflex action', 'Reporting', 'Role', 'Short-Term Memory', 'Signal Transduction', 'Site', 'Source', 'Suggestion', 'Techniques', 'Testing', 'Time', 'To specify', 'Viral', 'Virus', 'Visual', 'Walking', 'Work', 'classical conditioning', 'cognitive function', 'cognitive process', 'experimental study', 'gamma-Aminobutyric Acid', 'human disease', 'kinematics', 'motor control', 'motor learning', 'nonhuman primate', 'novel', 'relating to nervous system', 'signal processing', 'success', 'visual learning', 'visual motor']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,1164920,0.015711838883578504
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9707897,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,641907,0.0403740711791051
"Discovering the rules for the organization of macaque inferotemporal cortex. Project Summary How is the representation of complex visual objects organized in inferotemporal (IT) cortex, the large brain region responsible for object recognition? To date, areas selective for a few categories such as faces, bodies, and scenes have been found, but the vast majority of IT cortex is “wild,” lacking any known specialization. Various schemes have been proposed for parceling IT, but a comprehensive understanding of IT organization remains elusive. Here, we propose to use fMRI, microstimulation, and electrophysiology to develop a unified understanding of the organization and coding principles of macaque IT. The experiments are motivated by a major advance in computer vision and two key preliminary results from our lab. First, the advent of deep networks trained for object classification makes it possible to generate a parametric object space, providing a quantitative framework to decipher the feature selectivity of single IT cells. Second, our preliminary results suggest that a large portion of macaque IT cortex is topographically organized according to the first two principal components of object space. This topography encompasses at least four distinct networks, each with at least three hierarchical nodes of increasing view invariance, and includes the previously described face and body patch networks. Furthermore, single cells within each network are projecting incoming objects, formatted as vectors in the object space, onto specific preferred axes. Taken together, these results suggest a new hypothesis for IT organization: IT cortex is tiled by networks (i.e., sets of functionally connected nodes, where a node is a patch of IT cells) whose organization and coding principles are very similar to that of the face patch network, and the layout of these networks follows a regular topography specified by the statistical structure of object space. We propose three Specific Aims to rigorously test this hypothesis. In Aim 1, we will systematically map all networks within IT of individual animals. In Aim 2, we will record responses of cells in each identified network to a large, common set of object stimuli and determine their coding scheme. In Aim 3, we will perturb activity in each network and quantitatively assess effect on object recognition behavior. Together, these three Aims seek to build a comprehensive understanding of IT organization that bridges fMRI, single units, and behavior. Our lab has developed powerful experimental techniques to tackle each of these Aims and has previously applied them to the macaque face patch system. We believe the time is ripe to apply these techniques to the larger problem of how all objects are represented--not just faces. In the same way that Mendeleev’s arrangement of chemical elements according to their atomic mass and chemical properties helped elucidate the electronic structure of atoms, we believe systematic mapping and characterization of all networks in IT will help elucidate the fundamental neural mechanism for object recognition. Narrative This basic research application will investigate how visual objects are processed by the brain. The brain areas we will study are located in the temporal lobe, a brain region especially susceptible to neurological disease including Alzheimer’s disease and epilepsy. The planned studies will provide valuable insight into the fundamental code cells in this region use to represent visual information, and will thereby contribute to better understanding, diagnosis, and treatment of diseases targeting this part of the brain.",Discovering the rules for the organization of macaque inferotemporal cortex.,9803682,R01EY030650,"['Alzheimer&apos', 's Disease', 'Anatomy', 'Animals', 'Area', 'Basic Science', 'Behavior', 'Brain', 'Brain region', 'Categories', 'Cells', 'Chemicals', 'Classification', 'Code', 'Complex', 'Computer Vision Systems', 'Diagnosis', 'Disease', 'Electric Stimulation', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Epilepsy', 'Face', 'Functional Magnetic Resonance Imaging', 'Glean', 'Image', 'Individual', 'Macaca', 'Maps', 'Measures', 'Monkeys', 'Performance', 'Population', 'Process', 'Resolution', 'Sampling', 'Scheme', 'Signal Transduction', 'Site', 'Specific qualifier value', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Temporal Lobe', 'Testing', 'Three-Dimensional Image', 'Time', 'Training', 'Visual', 'chemical property', 'electronic structure', 'experimental study', 'inferotemporal cortex', 'insight', 'microstimulation', 'movie', 'nervous system disorder', 'neuromechanism', 'object perception', 'object recognition', 'relating to nervous system', 'response', 'vector', 'visual information']",NEI,CALIFORNIA INSTITUTE OF TECHNOLOGY,R01,2019,575750,0.061172421609527815
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,9685191,R01EY011787,"['3-Dimensional', 'Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Cerebral cortex', 'Cerebrum', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Genetic', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'area striata', 'awake', 'cell type', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'nerve supply', 'neural circuit', 'neural network', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2019,394825,0.015328554356119321
"Cortical computations underlying binocular motion integration PROJECT SUMMARY / ABSTRACT Neuroscience is highly specialized—even visual submodalities such as motion, depth, form and color processing are often studied in isolation. One disadvantage of this isolation is that results from each subfield are not brought together to constrain common underlying neural circuitry. Yet, to understand the cortical computations that support vision, it is important to unify our fragmentary models that capture isolated insights across visual submodalities so that all relevant experimental and theoretical efforts can benefit from the most powerful and robust models that can be achieved. This proposal aims to take the first concrete step in that direction by unifying models of direction selectivity, binocular disparity selectivity and 3D motion selectivity (also known as motion-in-depth) to reveal circuits and understand computations from V1 to area MT. Motion in 3D inherently bridges visual submodalities, necessitating the integration of motion and binocular processing, and we are motivated by two recent paradigm-breaking physiological studies that have shown that area MT has a robust representation of 3D motion. In Aim 1, we will create the first unified model and understanding of the relationship between pattern and 3D motion in MT. In Aim 2, we will construct the first unified model of motion and disparity processing in MT. In Aim 3, we will develop a large-scale biologically plausible model of these selectivities that represents realistic response distributions across an MT population. Having a population output that is complete enough to represent widely-used visual stimuli will amplify our ability to link to population read-out theories and to link to results from psychophysical studies of visual perception. Key elements of our approach are (1) an iterative loop between modeling and electrophysiological experiments; (2) building a set of shared models, stimuli, data and analysis tools in a cloud-based system that unifies efforts across labs, creating opportunities for deep collaboration between labs that specialize in relevant submodalities, and encouraging all interested scientists to contribute and benefit; (3) using model-driven experiments to answer open, inter-related questions that involve motion and binocular processing, including motion opponency, spatial integration, binocular integration and the timely problem of how 3D motion is represented in area MT; (4) unifying insights from filter-based models and conceptual, i.e., non-image- computable, models to generate the first large-scale spiking hierarchical circuits that predict and explain how correlated signals and noise are transformed across multiple cortical stages to carry out essential visual computations; and (5) carrying out novel simultaneous recordings across visual areas. This research also has potential long-term benefits in medicine and technology. It will build fundamental knowledge about functional cortical circuitry that someday may be useful for interpreting dysfunctions of the cortex or for helping biomedical engineers construct devices to interface to the brain. Insights gained from the visual cortex may also help to advance computer vision technology. NARRATIVE The processing of visual motion and depth information is essential for a wide variety of important human abilities, including navigating through the world, avoiding collisions, catching and grabbing objects and interpreting complex scenes. To understand how neurons in the visual cortex transform and represent the information that underlies these abilities, we aim to initiate the development of a more complete, biologically constrained and openly available computer model of motion and depth processing that will be used to guide, and to interpret and incorporate results from, primate visual neurophysiological and psychophysical experiments. Gaining an understanding of the normal function of cortical neural circuitry is an important step in building the fundamental knowledge that someday may help to improve the ability to assess dysfunctions of the cortex and may help bioengineers create devices that interface to cortical circuitry to treat disorders and overcome disabilities.",Cortical computations underlying binocular motion integration,9727981,R01EY027023,"['3-Dimensional', 'Affect', 'Architecture', 'Biological', 'Biomedical Engineering', 'Brain', 'Collaborations', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disadvantaged', 'Discrimination', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Foundations', 'Frequencies', 'Functional disorder', 'Human', 'Joints', 'Knowledge', 'Link', 'Literature', 'Medicine', 'Modeling', 'Motion', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Pattern', 'Performance', 'Physiological', 'Physiology', 'Population', 'Primates', 'Production', 'Psychophysics', 'Reproducibility', 'Research', 'Role', 'Scientist', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Vision Disparity', 'Visual', 'Visual Cortex', 'Visual Motion', 'Visual Perception', 'area MT', 'base', 'cloud based', 'color processing', 'disability', 'experimental study', 'extrastriate visual cortex', 'fitness', 'improved', 'in vivo', 'insight', 'interest', 'neural circuit', 'neurophysiology', 'novel', 'predictive modeling', 'relating to nervous system', 'response', 'spatial integration', 'spatiotemporal', 'theories', 'tool', 'visual neuroscience', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2019,399500,0.07242669388898451
"Multiple timescales of motor planning and execution in mouse cortex Project Summary/Abstract: For animals to execute complicated behaviors, successful motor planning and execution is essential. Moreover, the sequence of events leading to successful goal-based behavior takes place over a wide range of timescales. For example, when walking from home to work, one must first make an abstract, long-timescale decision to go to work, which much then be translated into a sequence of shorter-timescale right-left turning decisions, which are translated into the finely fluctuating electrical patterns that control the muscles. How motor planning and execution occur simultaneously over many timescales in populations of motor cortex neurons is not well understood. Much work in humans and nonhuman primates have shown that visual and auditory stimuli integrate over multiple timescales. This work has shown that early sensory regions, like primary visual cortex, respond to fast fluctuations in the environment. This information is integrated to longer-timescale information in secondary cortical regions, with the longest- timescale information in frontal and association areas. We therefore hypothesize that secondary motor cortex (M2) neurons control behavior over longer timescales than primary motor cortex (M1) neurons. To study this phenomenon, I have built a setup in which head-fixed mice navigate in virtual reality to a rewarded location. In this setup, I can record video from all sides of the animal for high spatiotemporal resolution measurement of motor behaviors. I have developed machine learning algorithms to extract 3D pose data from these videos. In Aim 1, I will use calcium imaging to record large numbers of neurons in mouse M1 and M2 to correlate the activity of individual neurons and populations to the animal’s ongoing pose kinematics. We will supplement with targeted silicon probe recordings to capture fast neural responses. In Aim 2, I will compare the calcium dynamics in populations of M1 and M2 neurons in mice trained to perform a virtual motor planning task versus mice that have not been trained. We hypothesize that training to plan motor actions increases the timescale of M1/M2 neural activity. In Aim 3, we will use optogenetic silencing in specific regions of cortex to perturb the animal’s motor behavior. We hypothesize that the duration of the perturbed movements will be longer when M2 is perturbed than M1. In this way, we will study how different cortical regions relate to behavior over many timescales. This proposal will broaden our knowledge of cortical processing in general, and motor planning and execution in particular. Patients with mental illness, such as ADHD, autism, and Asperger’s disorder show impaired ability to plan upcoming movements. The first step to successfully treating these illnesses is to better understand how motor planning occurs in general. Project Narrative: This proposal will elucidate how motor planning and execution take place simultaneously, over many timescales, and across brain regions. Better understanding motor planning will help generate new treatments for diseases that affect motor planning, like attention deficit hyperactivity disorder and autism.",Multiple timescales of motor planning and execution in mouse cortex,9752759,F31NS108450,"['3-Dimensional', 'Affect', 'Animal Behavior', 'Animals', 'Area', 'Asperger Syndrome', 'Attention deficit hyperactivity disorder', 'Behavior', 'Behavior Control', 'Brain region', 'Calcium', 'Code', 'Communication', 'Cues', 'Data', 'Dimensions', 'Disease', 'Ensure', 'Environment', 'Event', 'Future', 'Goals', 'Head', 'Home environment', 'Human', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Laser Scanning Microscopy', 'Lasers', 'Left', 'Light', 'Location', 'Measurement', 'Measures', 'Memory', 'Mental disorders', 'Modeling', 'Motor', 'Motor Cortex', 'Movement', 'Mus', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Population', 'Research', 'Resolution', 'Rewards', 'Running', 'Sensory', 'Short-Term Memory', 'Side', 'Silicon', 'Stereotyping', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Vision', 'Walking', 'Work', 'area striata', 'auditory stimulus', 'autism spectrum disorder', 'base', 'frontal lobe', 'kinematics', 'machine learning algorithm', 'neuromechanism', 'nonhuman primate', 'novel', 'optogenetics', 'prevent', 'relating to nervous system', 'response', 'sensory cortex', 'sensory stimulus', 'spatiotemporal', 'theories', 'two-photon', 'virtual', 'virtual reality', 'visual stimulus']",NINDS,HARVARD MEDICAL SCHOOL,F31,2019,38053,-0.012490523490472295
"Computational Cognitive Neuroscience of Human Auditory Cortex PROJECT SUMMARY Humans with normal hearing excel at deriving information about the world from sound. Our auditory abilities represent stunning computational feats that only recently have been replicated to any extent in machine systems. And yet our auditory abilities are highly vulnerable, being greatly compromised in listeners with hearing impairment, cochlear implants, and auditory neurodevelopmental disorders, particularly in the presence of noise. Difficulties in recognition often lead to frustration and social isolation, and are not adequately addressed by current hearing aids, implants, and remediation strategies. The long-term goal of the proposed research is to reveal the basis of auditory recognition and to provide insights that will facilitate improved prosthetic devices and therapeutic interventions. The development of more effective devices and therapies is currently limited by an incomplete understanding of the factors that underlie real-world recognition by normal-hearing listeners. In particular, although responses to sound in subcortical auditory pathways are relatively well studied, little is known about the transformations that occur within the auditory cortex to create representations of meaningful sound structure. We propose to enrich the understanding of auditory recognition with three sets of experiments that examine the cortical representation of real-world sounds in human listeners, combining functional magnetic resonance imaging (fMRI) with computational modeling of the underlying representations. Aim 1 develops artificial neural network models of speech and music processing and compares their representations to those in the auditory cortex, synthesizing and then measuring brain responses to sounds that generate the same response in a model, and probing the time scale of the auditory analysis of speech and music. Aim 2 develops and tests models of pitch perception in noise, exploring the hypothesis that pitch perception is constrained both by the statistics of natural sounds and the frequency selectivity of the cochlea. Aim 3 develops and tests models that jointly localize and recognize sounds, and probes the brain representations of sound identity and location using fMRI. The results will reveal the mechanisms underlying robust sound recognition by the healthy auditory system and will set the stage for investigations of the cortical consequences of hearing impairment and auditory developmental disorders, hopefully suggesting new strategies for remediation. PROJECT NARRATIVE: People with normal hearing are typically able to recognize, understand and localize sounds of interest, but this ability is often compromised in listeners with hearing disorders. The proposed research will enrich the understanding of the neural mechanisms underlying auditory recognition and localization in normal listeners. The results will likely provide insight into the brain processes whose alteration in hearing disorders underlies listening difficulties, potentially leading to improved remediation strategies.",Computational Cognitive Neuroscience of Human Auditory Cortex,9797408,R01DC017970,"['Address', 'Adopted', 'Auditory', 'Auditory Perception', 'Auditory area', 'Auditory system', 'Behavioral', 'Biological Assay', 'Brain', 'Brain region', 'Characteristics', 'Child', 'Cochlea', 'Cochlear Implants', 'Computer Simulation', 'Data', 'Development', 'Devices', 'Drops', 'Ear', 'Floor', 'Frequencies', 'Frustration', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing Aids', 'Hearing problem', 'Human', 'Implant', 'Investigation', 'Lead', 'Location', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Noise', 'Pathway interactions', 'Peripheral', 'Persons', 'Pitch Perception', 'Population', 'Process', 'Property', 'Prosthesis', 'Psychophysics', 'Research', 'Rest', 'Social isolation', 'Sound Localization', 'Source', 'Speech', 'Stimulus', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Visual Pathways', 'artificial neural network', 'auditory pathway', 'cognitive neuroscience', 'computational basis', 'deep learning', 'deep neural network', 'developmental disease', 'experimental study', 'hearing impairment', 'improved', 'insight', 'interest', 'network architecture', 'neural network', 'neuromechanism', 'neurophysiology', 'normal hearing', 'novel', 'relating to nervous system', 'remediation', 'response', 'sound', 'sound frequency', 'speech processing', 'statistics']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2019,337875,0.022445604977636247
"Millisecond resolution statistics of cortical populations Project Summary/Abstract The mammalian brain builds and transforms representations of the outside world through the concerted activity of populations of neurons, but the extent to which spike times or spike counts are coordinated within these ensembles beyond pairs is not clear. Models of neural encoding predict variable frequencies of spike pattern occurrence, and models of decoding delineate requirements for spike time precision within the population response. While considerable effort has been made toward the development and refinement of the theoretical basis of such neural coding schemes, and predictions have been tested against single cell and pairwise data, there has been relatively little experimental data beyond pairs able to differentiate between competing hypotheses of population coding. The proposed career development plan aims to marry large-scale electrophysiology in primary visual cortex with analysis of specific predictions derived from computational and theoretical neuroscience work for spike time coordination beyond pairwise interactions. The candidate has a deep background in in vivo experimental techniques and proposes to receive training in the high-dimensional computational techniques and to use experimental data collected to validate specific theoretical predictions. This training will establish the skills necessary for a successful independent research career studying the mechanisms of information representation and transfer in visual cortex, bridging the gap between experimental and computational neuroscience. The candidate will carry out the mentored phase under the guidance of Dr. Clay Reid, a world expert in multiple aspects of mammalian central visual processing including anatomy, physiology, and computation. Additional advising from Dr. Eric Shea- Brown and Dr. Christof Koch will provide guidance in the theoretical and applied mathematical approaches required to implement and assess advanced models of neural encoding and decoding. The training will utilize the strengths of the Allen Institute for Brain Science in collecting large-scale data and the didactic opportunities at the University of Washington. In the independent phase the candidate will use the newly acquired analytical and modeling skills in combination with his previous training in optogenetic techniques to better constrain population measurements. This work will help establish a unique independent research program to elucidate the mechanisms underlying cortical representation. Project Narrative Understanding how the brain uses population activity to build representations of the outside world is an important step towards understanding not only sensory but also psychiatric and other cognitive disorders. This work on the fundamental nature of the neural code will contribute to the body of knowledge required to create effective brain interfaces for motor and sensory prostheses with the potential to reduce sensory disabilities, provide treatments for cognitive disorders, and aid in recovery from central nervous system trauma.",Millisecond resolution statistics of cortical populations,9995600,R00EY028612,"['Address', 'Anatomy', 'Animals', 'Brain', 'Cells', 'Characteristics', 'Code', 'Cognition Disorders', 'Complex', 'Computational Technique', 'Data', 'Development', 'Development Plans', 'Electrophysiology (science)', 'Frequencies', 'Impaired cognition', 'Institutes', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Mentors', 'Modeling', 'Molecular', 'Motor', 'Mus', 'Nature', 'Nervous System Trauma', 'Neuraxis', 'Neurons', 'Neurosciences', 'Output', 'Pattern', 'Perception', 'Performance', 'Phase', 'Physiological', 'Physiology', 'Population', 'Population Process', 'Population Statistics', 'Property', 'Psychophysics', 'Recovery', 'Research', 'Resolution', 'Scheme', 'Science', 'Sensory', 'Sensory Disorders', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Time', 'Training', 'Universities', 'Variant', 'Visual Cortex', 'Washington', 'Work', 'area striata', 'awake', 'career', 'career development', 'clay', 'computational neuroscience', 'data resource', 'deep learning', 'deep learning algorithm', 'disability', 'extrastriate visual cortex', 'high dimensionality', 'in vivo', 'innovation', 'mathematical methods', 'millisecond', 'neural model', 'novel', 'optogenetics', 'predictive modeling', 'programs', 'relating to nervous system', 'response', 'sensory prosthesis', 'skills', 'statistics', 'theories', 'visual processing']",NEI,UNIVERSITY OF COLORADO DENVER,R00,2019,249000,0.03430954856918757
"Millisecond resolution statistics of cortical populations Project Summary/Abstract The mammalian brain builds and transforms representations of the outside world through the concerted activity of populations of neurons, but the extent to which spike times or spike counts are coordinated within these ensembles beyond pairs is not clear. Models of neural encoding predict variable frequencies of spike pattern occurrence, and models of decoding delineate requirements for spike time precision within the population response. While considerable effort has been made toward the development and refinement of the theoretical basis of such neural coding schemes, and predictions have been tested against single cell and pairwise data, there has been relatively little experimental data beyond pairs able to differentiate between competing hypotheses of population coding. The proposed career development plan aims to marry large-scale electrophysiology in primary visual cortex with analysis of specific predictions derived from computational and theoretical neuroscience work for spike time coordination beyond pairwise interactions. The candidate has a deep background in in vivo experimental techniques and proposes to receive training in the high-dimensional computational techniques and to use experimental data collected to validate specific theoretical predictions. This training will establish the skills necessary for a successful independent research career studying the mechanisms of information representation and transfer in visual cortex, bridging the gap between experimental and computational neuroscience. The candidate will carry out the mentored phase under the guidance of Dr. Clay Reid, a world expert in multiple aspects of mammalian central visual processing including anatomy, physiology, and computation. Additional advising from Dr. Eric Shea- Brown and Dr. Christof Koch will provide guidance in the theoretical and applied mathematical approaches required to implement and assess advanced models of neural encoding and decoding. The training will utilize the strengths of the Allen Institute for Brain Science in collecting large-scale data and the didactic opportunities at the University of Washington. In the independent phase the candidate will use the newly acquired analytical and modeling skills in combination with his previous training in optogenetic techniques to better constrain population measurements. This work will help establish a unique independent research program to elucidate the mechanisms underlying cortical representation. Project Narrative Understanding how the brain uses population activity to build representations of the outside world is an important step towards understanding not only sensory but also psychiatric and other cognitive disorders. This work on the fundamental nature of the neural code will contribute to the body of knowledge required to create effective brain interfaces for motor and sensory prostheses with the potential to reduce sensory disabilities, provide treatments for cognitive disorders, and aid in recovery from central nervous system trauma.",Millisecond resolution statistics of cortical populations,9752555,K99EY028612,"['Address', 'Anatomy', 'Animals', 'Brain', 'Cells', 'Characteristics', 'Code', 'Cognition Disorders', 'Complex', 'Computational Technique', 'Data', 'Development', 'Development Plans', 'Electrophysiology (science)', 'Frequencies', 'Impaired cognition', 'Institutes', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Mentors', 'Modeling', 'Molecular', 'Motor', 'Mus', 'Nature', 'Nervous System Trauma', 'Neuraxis', 'Neurons', 'Neurosciences', 'Output', 'Pattern', 'Perception', 'Performance', 'Phase', 'Physiological', 'Physiology', 'Population', 'Population Process', 'Population Statistics', 'Property', 'Psychophysics', 'Recovery', 'Research', 'Resolution', 'Scheme', 'Science', 'Sensory', 'Sensory Disorders', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Time', 'Training', 'Universities', 'Variant', 'Visual Cortex', 'Washington', 'Work', 'area striata', 'awake', 'career', 'career development', 'clay', 'computational neuroscience', 'data resource', 'deep learning', 'deep learning algorithm', 'disability', 'extrastriate visual cortex', 'high dimensionality', 'in vivo', 'innovation', 'mathematical methods', 'millisecond', 'neural model', 'novel', 'optogenetics', 'predictive modeling', 'programs', 'relating to nervous system', 'response', 'sensory prosthesis', 'skills', 'statistics', 'theories', 'visual processing']",NEI,ALLEN INSTITUTE,K99,2019,132984,0.03430954856918757
"Active Sensation during Odor-Guided Navigation in Mice PROJECT SUMMARY We often consider our movements a result of sensory processing – sensation guides behavior. However, animals selectively shape future sensory input through their own actions in a process known as active sampling. Thus, action and sensation are inextricably linked. Despite this, much of the research done on sensory processing restricts movement, most commonly via head fixation. To access sensorimotor processing during more natural behavior, we will study olfactory navigation in freely-moving mice. The olfactory system is ideal for studying sensory sampling, because of its ethological relevance for mammalian foraging and the dynamic nature of airborne odor stimuli. The proposed research will determine the sampling strategies of olfactory search and reveal the underlying circuitry that connects sensation with motion. Aim 1. It is unknown how rodents navigate dynamic plumes of odorant towards an odor source. In this aim, we will identify, analyze, and model active sensing behaviors that occur during increasingly difficult navigation tasks and with single nostrils occluded. These experiments will test the hypothesis that olfactory navigation works as a sensorimotor closed-loop system, where animals optimize sampling behaviors for the current stimulus conditions. These behavioral studies will lay the foundation for investigations of sensorimotor processing in dynamic olfactory scenes. Aim 2. To determine how sampling movements shape sensation, we will monitor neural activity during active sensory behavior. During odor tracking, we will electrophysiologically record in the olfactory bulb, a bottleneck through which all sensory input passes. We will determine the sensory history dependence of active sampling and, in doing so, reveal part of the underlying circuitry that connects motion with sensation. These experiments will test the hypothesis that sampling movements are sensory history dependent. To our knowledge, sampling movements and sensory activity have never been simultaneously recorded during olfactory navigation. This research will advance our understanding of the interplay between sensation and motion during natural behavior. PROJECT NARRATIVE Deficits in sensory motor communication are a major contributor to prevalent neurological disorders such as schizophrenia and Parkinson's disease. Our assay of olfactory navigation will model the interaction between sensation and movement and identify the circuitry through which movements are decided by sensory input. Discovering mechanisms of sensorimotor integration are the key to a better understanding of sensory processing in these disorders, since sensation and action are inextricably linked.",Active Sensation during Odor-Guided Navigation in Mice,9764342,F31DC016799,"['Animals', 'Anterior nares', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Biological Assay', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Disease', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Foundations', 'Future', 'Genetic', 'Head', 'Implant', 'Intake', 'Intervention Studies', 'Investigation', 'Link', 'Modeling', 'Monitor', 'Motion', 'Motor', 'Movement', 'Mus', 'Nature', 'Neurons', 'Nose', 'Odors', 'Olfactory Pathways', 'Output', 'Parkinson Disease', 'Pattern', 'Perception', 'Positioning Attribute', 'Process', 'Recording of previous events', 'Research', 'Respiration', 'Rewards', 'Rodent', 'Sampling', 'Schizophrenia', 'Sensory', 'Shapes', 'Smell Perception', 'Source', 'Stereotyping', 'Stimulus', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Vertebrates', 'Work', 'base', 'behavioral study', 'design', 'experimental study', 'insight', 'machine vision', 'nervous system disorder', 'olfactory bulb', 'olfactory stimulus', 'relating to nervous system', 'sample fixation', 'sensory input', 'sensory stimulus', 'sensory system', 'tool']",NIDCD,UNIVERSITY OF OREGON,F31,2019,34022,0.012621654468812209
"CRCNS: Joint coding of shape and texture in the primate brian PROJECT DESCRIPTION  Collaborating Pis and Consultant  United States  Pl: Anitha Pasupathy, Dept. of Biological Structure, University of Washington, Seattle, USA  Co-Pl: Wyeth Bair, Dept. of Biological Structure, University of Washington, Seattle, USA Japan  Pl: lsamu Motoyoshi, Dept. of Life Sciences, The University of Tokyo, Japan  Consultant: Hidehiko Komatsu, Tamagawa University, Japan  Specific Aims  Our visual system endows us with a diverse set of abilities: to recognize and manipulate  objects, avoid obstacles and danger during navigation, evaluate the quality of food, read text,  interpret facial expressions, etc. This relies on the neuronal processing of information about  form and material texture along the ventral pathway of the primate visual system (Ungerleider &  Mishkin, 1982; Felleman & Van Essen, 1991). Studies over the past several decades have  produced detailed models of how visual information is processed in V1, the earliest stage along . this pathway (Hubel & Wiesel, 1959, 1968; Movshon et al., 1978a, b; Albrecht et al., 1980), but  beyond V1 our understanding of visual processing and representation is limited. This is  particularly true with regard to our understanding of how visual representations of form and  texture jointly contribute to object perception and recognition. The broad goal of this proposal is  two-fold-to develop an experimentally-driven image-computable model for how naturalistic  visual stimuli are processed in area V4, an important intermediate stage along the ventral visual  pathway (Aim 1) and to discover how such a representation contributes to perception (Aim 2).  Past studies have shown that V4 neurons are sensitive to both the form (Desimone and Schein,  1987; Kobatake and Tanaka, 1994; Gallant et al., 1993; Pasupathy and Connor, 2001; Nandy et  al., 2013) and the surface texture of visual stimuli (Arcizet et al., 2008; Goda et al., 2014;  Okazawa et al., 2015). But, because expertise is narrow and experimental time limited,  scientists tend to focus exclusively on the encoding of form or texture and not on their joint  coding. For example, in the laboratories of the USA portion of this collaboration, we have until  now focused on form processing by carrying out neurophysiological studies using 2D shapes  with uniform surface properties to investigate how object boundaries are encoded (Oleskiw et  al., 2014; Popovkina et al., 2016). We have modeled our data by comparing the representation  of V4 neurons to that of the units in AlexNet (Pospisil et al., 2015), a prominent convolutional  neural net (CNN) trained to recognize objects (Krizhevsky et al., 2012). At the same time, the  Japanese contingent of this collaboration has investigated the encoding of surface texture and  gloss in human perception without associated form encoding (Motoyoshi et al., 2007; Sharan et  al., 2008; Motoyoshi, 2010; Motoyoshi & Matoba, 2012). Here we propose to bring our  respective expertise in studying form and texture encoding to bear on the question of how  naturalistic stimuli with both form and surface cues are encoded in area V4 and how these  representations support human visual perception. Our specific aims are:  Aim1. To build a unified image-computable model for neuronal responses to shapes and  textures in area V4  V4 responses to 2D shapes with uniform luminance/chromatic characteristics can be explained  by a hierarchical-Max (HMax) model for object recognition that emphasizes boundary features  (Cadieu et al., 2007). Such responses can also be explained by units in artificial deep  convolutional networks, in which boundary features are not explicitly emphasized (all features  are learned from initially random weights). On the other hand, V4 responses to texture patches  can be well explained by a higher-order image-statistics-based model (Okazawa et al., 2015).  Using shape data from the Pasupathy lab and texture data from the Komatsu lab (Japanese  consultant), we will ask whether responses of V4 neurons to shapes and textures can be Page 21 n/a",CRCNS: Joint coding of shape and texture in the primate brian,9765318,R01EY029997,"['Biological', 'Biological Sciences', 'Categories', 'Characteristics', 'Code', 'Collaborations', 'Computer Simulation', 'Computers', 'Cues', 'Data', 'Dimensions', 'Discrimination', 'Facial Expression', 'Goals', 'Human', 'Image', 'Individual', 'Japan', 'Japanese Population', 'Joints', 'Laboratories', 'Modeling', 'Modification', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Physiology', 'Primates', 'Process', 'Psychophysics', 'Scientist', 'Shapes', 'Stimulus', 'Structure', 'Subgroup', 'Surface', 'Surface Properties', 'Text', 'Texture', 'Time', 'Tokyo', 'Training', 'United States', 'Universities', 'V4 neuron', 'Visual', 'Visual Pathways', 'Visual Perception', 'Visual system structure', 'Washington', 'Weight', 'area V4', 'base', 'convolutional neural network', 'experimental study', 'food quality', 'human model', 'human subject', 'information processing', 'luminance', 'neurophysiology', 'novel', 'object perception', 'object recognition', 'response', 'statistics', 'visual information', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2019,230475,0.09980350581947274
"GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN PROJECT SUMMARY & ABSTRACT  Human locomotion through natural environments requires the coordination of all levels of the sensorimotor hierarchy, from the cortical areas involved in processing of visual information and high level planning to the subcortical and spinal structures involved in the regulation of the gait and posture. However, despite the complex neural bases of human locomotion, the output is highly regular and well organized around the basic physical dynamics and biomechanics that define the stability and energetic costs of moving a bipedal body through space. There is a rich and growing body of literature describing detailed knowledge each of the individual components of human locomotion, including neural mechanisms, muscular neuromechanics, and biomechanics. However, very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion through a complex and dynamic world. This lack of integrative research not only restricts the breadth of impact of research from these individual disciplines, but also limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to to fill this critical gap in our knowledge about human locomotion, it is necessary to develop an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world. In service of this general goal, this proposal outlines research projects aimed at specific unanswered questions about locomotion over different terrains. This proposal comprises three specific research and training aims on the visual control of locomotion over rough terrain. Aim 1 focuses on the behavioral task itself, Aim 2 investigates the sensory stimulus experienced during real-world locomotion, and Aim 3 examines the motor integration of visually specified goals into the ongoing gait cycle. Aim 1 investigates effects of changing environmental uncertainty and task demands on gaze allocation strategies during locomotion over real-world rough terrain. Aim 2 analyzes and models the visual stimulus experienced during locomotion over real-world rough terrain. Aim 3 determines how visually specified target footholds and targets are integrated into the ongoing preferred steady-state gait. Together these aims will significantly advance our understanding of how humans use vision to control their movement through the natural world, which greatly increase our ability to develop clinical diagnosis and treatment for loss of locomotor function. PROJECT NARRATIVE  Very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion. This lack of integrative research limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to fill this critical gap in our knowledge about human locomotion, this proposal develops an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world.",GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN,9999721,R00EY028229,"['3-Dimensional', 'Aging', 'Algorithms', 'Area', 'Attention', 'Behavior', 'Behavioral', 'Biomechanics', 'Clinical Treatment', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Development', 'Discipline', 'Environment', 'Eye', 'Gait', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Link', 'Literature', 'Locomotion', 'Measures', 'Mechanics', 'Mentors', 'Modeling', 'Motion', 'Motor', 'Movement', 'Muscle', 'Musculoskeletal', 'Nature', 'Neuromechanics', 'Output', 'Parkinson Disease', 'Pattern', 'Phase', 'Photic Stimulation', 'Positioning Attribute', 'Postdoctoral Fellow', 'Posture', 'Protocols documentation', 'Regulation', 'Research', 'Research Activity', 'Research Project Grants', 'Research Training', 'Services', 'Signal Transduction', 'Specific qualifier value', 'Spinal', 'Stroke', 'Structure', 'System', 'Training', 'Training Programs', 'Uncertainty', 'Vision', 'Visual', 'Visual Fields', 'Walking', 'Wireless Technology', 'area MST', 'area MT', 'base', 'clinical Diagnosis', 'cost', 'design', 'environmental change', 'experience', 'experimental study', 'foot', 'gaze', 'insight', 'instrument', 'kinematics', 'multidisciplinary', 'neuromechanism', 'neuromuscular', 'novel', 'optic flow', 'programs', 'relating to nervous system', 'response', 'sensory stimulus', 'skills', 'statistics', 'treadmill', 'treatment planning', 'visual control', 'visual information', 'visual processing', 'visual stimulus', 'visual-motor integration']",NEI,NORTHEASTERN UNIVERSITY,R00,2019,249000,0.05377184470026173
"Early representation of 3D volumetric shape in visual object processing Project Summary The goal of this project is to test a novel theoretical framework for understanding how the ventral pathway subserves object vision. In the standard framework, a series of neural operations on 2D image data through many intermediate cortical stages, including area V4, leads to high-level perceptual representations, including representation of object identity, at the final stages of the ventral pathway. However, our preliminary microelectrode data from a fixating monkey show that many neurons in V4 represent volumetric (volume- enclosing) 3D shape, not 2D image patterns. These neurons respond to many different 2D images that convey the same 3D shape with different shape-in-depth cues, including shading, reflection, and refraction. They even respond preferentially to random dot stereograms that convey 3D volumetric shape with no 2D cues whatsoever. Moreover, our preliminary results with 2-photon functional imaging in anesthetized monkey V4 show that 3D shape signals are grouped by their similarity, and also group with isomorphic (same outline) 2D shape signals (which could contribute evidence to corresponding 3D shape inferences). We propose to capitalize on these preliminary data by demonstrating the prevalence of 3D shape tuning in area V4, analyzing the 3D shape coding strategies used by these neurons, and measuring how 2D and 3D shape signals are arranged at a microscopic level across the surface of V4. We expect these results to provide strong evidence that extraction of 3D shape fragments is a primary goal of V4 processing. This early extraction of 3D shape information, just two synapses beyond primary visual cortex, would suggest a competing framework for understanding the ventral pathway, in which the initial goal is to represent 3D physical structure, independent of the various 2D image cues used to infer it. In this framework, object recognition would be based on preceding information about 3D physical structure, which would explain why human object recognition is so robust to image changes, in a way that the best computational vision systems are not. The scientific impact of this work would be to divert vision experiments toward understanding representation of real world 3D structure (rather than 2D planar stimuli) and to encourage computational vision scientists to incorporate early 3D shape processing into the deep convolutional network models that are the current state of the art. Narrative This study will help explain how the human brain achieves such remarkably robust perception of visual objects. The results will help guide future rehabilitative and prosthetic strategies for patients with visual impairments, by elucidating neural strategies that could be used to bring computer vision prosthetics up to human performance levels, and by discovering specific neural signals for object information that could be replicated by electrode array implants in higher-level visual cortex.",Early representation of 3D volumetric shape in visual object processing,9773064,R01EY029420,"['3-Dimensional', 'Area', 'Biological', 'Brain', 'Calcium Signaling', 'Code', 'Computer Vision Systems', 'Cues', 'Data', 'Electrodes', 'Functional Imaging', 'Future', 'Genetic Programming', 'Glass', 'Goals', 'Human', 'Image', 'Implant', 'Lead', 'Learning', 'Measures', 'Medial', 'Microelectrodes', 'Microscopic', 'Microscopy', 'Modeling', 'Monkeys', 'Network-based', 'Neurons', 'Ocular Prosthesis', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Population', 'Prevalence', 'Prosthesis', 'Rehabilitation therapy', 'Scientist', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Structure', 'Surface', 'Synapses', 'System', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'V4 neuron', 'Vision', 'Visual Cortex', 'Visual Perception', 'Visual impairment', 'Work', 'area V4', 'area striata', 'base', 'experimental study', 'individual response', 'network models', 'neurotransmission', 'nonhuman primate', 'novel', 'object perception', 'object recognition', 'operation', 'relating to nervous system', 'response', 'three dimensional structure', 'two-photon', 'virtual reality', 'visual object processing']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2019,548567,0.0868325048293395
"The nGoggle: A portable brain-based device for assessment of visual function deficits PROJECT SUMMARY Assessment of loss of visual function outside the foveal area is an essential component of the management of numerous conditions, including glaucoma, retinal and neurological disorders. Despite the significant progress achieved with the development of standard automated perimetry (SAP) many decades ago, assessment of visual field loss with SAP still has significant drawbacks. SAP testing is limited by subjectivity of patient responses and high test-retest variability, frequently requiring many tests for effective detection of change over time. Moreover, as these tests are generally conducted in clinic-based settings, limited patient availability and health care resources often result in an insufficient number of tests acquired over time, with delayed diagnosis and detection of disease progression. The requirement for highly trained technicians, cost, complexity, and lack of portability of SAP also preclude its use for screening of visual field loss in underserved populations. To address shortcomings of current methods to assess visual function, we have developed the nGoggle, a wearable device that uses a head-mounted display (HMD) integrated with wireless electroencephalography (EEG), capable of objectively assessing visual field deficits using multifocal steady-state visual-evoked potentials (mfSSVEP). As part of the funded NEI SBIR Phase I, we developed the nGoggle prototype using a modified smartphone-based HMD display and non-disposable electrodes. In our Phase I studies, we conducted benchmarking tests on signal quality of EEG acquisition, developed methods for EEG data extraction and analysis, and conducted a pilot study demonstrating the ability of the device to detect visual field loss in glaucoma, a progressive neuropathy that results in characteristic damage to the optic nerve and resulting visual field defects. We also identified limitations of current existing displays and electrodes, as well as potential avenues for enhancing test reliability and improving user interface. Based on the encouraging results from Phase I and a clear delineation of the steps needed to bring the device into its final commercial product form, we now propose a series of Phase II studies. We hypothesize that optimization of nGoggle's accuracy and repeatability in detecting visual function loss can be achieved through the development of a customized head-mounted display with front-view eye/pupil tracking cameras and disposable no-prep electrodes, as well as enhancement of the visual stimulation protocol and data analytics. The specific aims of this proposal are: 1) To develop a customized head-mounted display and enhanced no-prep electrodes for improving nGoggle's ability to acquire users' mfSSVEP with high signal-to- noise ratios (SNR) in response to visual stimulation; 2) To optimize and validate mfSSVEP stimuli design and data analytics to enhance the accuracy and repeatability of assessing visual function loss with the nGoggle. 3) Complete pivotal clinical studies to support FDA approval. PROJECT NARRATIVE NGoggle Inc. has developed the nGoggle, a wearable device that uses a head-mounted display integrated with wireless electroencephalography, capable of objectively assessing visual field deficits using multifocal steady- state visual-evoked potentials. NGoggle Inc is now proposing to optimize nGoggle's accuracy and repeatability in detecting visual function loss with the use of a customized display, adherent no-prep electrodes, optimized visual stimuli and data analytics. It will also complete pivotal clinical studies to support FDA approval.",The nGoggle: A portable brain-based device for assessment of visual function deficits,9772484,R42EY027651,"['Address', 'Area', 'Base of the Brain', 'Benchmarking', 'Blindness', 'Brain', 'Cellular Phone', 'Characteristics', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Custom', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Elastomers', 'Electrodes', 'Electroencephalography', 'Electrooculogram', 'Exhibits', 'Eye', 'Funding', 'Glaucoma', 'Head', 'Healthcare', 'Methods', 'Neuropathy', 'Noise', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Perimetry', 'Phase', 'Photic Stimulation', 'Pilot Projects', 'Protocols documentation', 'Pupil', 'Resources', 'Retinal Diseases', 'Scotoma', 'Series', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Source', 'Stimulus', 'Testing', 'Time', 'Training', 'Underserved Population', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Wireless Technology', 'base', 'cost', 'design', 'field study', 'improved', 'loss of function', 'machine learning algorithm', 'nervous system disorder', 'patient response', 'phase 1 study', 'phase 2 study', 'portability', 'prototype', 'real world application', 'relating to nervous system', 'response', 'sample fixation', 'screening', 'virtual reality', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R42,2019,648557,-0.03139082029002618
"Representation of information across the human visual cortex ﻿    DESCRIPTION (provided by applicant): The human visual system is organized as a parallel, hierarchical network, and successive stages of visual processing appear to represent increasingly complicated aspects of shape-related and semantic information. However, the way that shape-related and semantic information is represented across much of the visual hierarchy is still poorly understood. The primary goal of this proposal is to understand how information about object shape and semantic category is represented explicitly across mid- and high-level visual areas. To address this important issue we propose to undertake a series of human functional MRI (fMRI) studies, using both synthetic and natural movies. Data will be analyzed by means of a powerful voxel-wise modeling (VM) approach that has been developed in my laboratory over the past several years. In Aim 1 we propose to measure human brain activity evoked by synthetic naturalistic movies, and to use VM to evaluate and compare several competing theories of shape representation across the entire visual cortex. In Aim 2 we propose to use VM to evaluate and compare competing theories of semantic representation. In Aim 3 we propose to use machine learning and and VM to discover new aspects of shape and semantic representation. These experiments will provide fundamental new insights about the representation of visual information across visual cortex. PUBLIC HEALTH RELEVANCE: Disorders of central vision can severely affect quality of life and the design of treatments and devices for improving visual function will depend critically on understanding the organization of visual cortex. We propose to use functional MRI and sophisticated computational data analysis and modeling procedures to evaluate and compare multiple theories of visual function. The results will reveal how visual information is represented across the several dozen distinct functional areas that constitute human visual cortex.",Representation of information across the human visual cortex,9542335,R01EY019684,"['Address', 'Affect', 'Area', 'Award', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Devices', 'Dimensions', 'Disease', 'Elements', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Image', 'Individual', 'Laboratories', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motion', 'Perception', 'Procedures', 'Quality of life', 'Semantics', 'Series', 'Shapes', 'Surface', 'System', 'Testing', 'Training', 'V2 neuron', 'V4 neuron', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'area striata', 'artificial neural network', 'base', 'data modeling', 'design', 'exhaustion', 'experimental study', 'extrastriate visual cortex', 'high dimensionality', 'improved', 'innovation', 'insight', 'learning strategy', 'movie', 'novel', 'object recognition', 'object shape', 'public health relevance', 'receptive field', 'theories', 'therapy design', 'visual information', 'visual neuroscience', 'visual processing']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2018,376543,0.09263354429713333
"Neural representation of the geometry and functionality in a scene ﻿    DESCRIPTION (provided by applicant):  The goal of the proposed research is to investigate how the brain represents scene geometry and functionality. Recognizing the visual environment is central to our daily interactions with the world. When we walk into a new space, we rapidly recognize whether there is a path to follow, whether there are crossable boundaries, and whether there are obstacles that block our view and potential navigation. The theoretical framework of this proposal is based on evidence that there are distinct but complementary levels of scene representation across a group of scene-selective regions in the brain (Park et al., 2011; Park et al., 2014; Park & Chun, 2009; Park, Chun, & Johnson, 2010; Park, Intraub, Yi, Widders, & Chun, 2007). The PI proposes that scene geometry (e.g., spatial layout, three-dimensional scene boundary) and functionality (e.g., navigability, limitations of a boundary) are two fundamental scene properties represented in these regions. Specific Aims: Aim 1 investigates whether the brain displays acute sensitivity to the presence of vertical boundaries, and how such sensitivity is modulated by the functional impediment that a boundary presents to the viewer's potential navigation. Aim 2 investigates the neural representation of the scene navigability, and how this representation differs from representation of scene geometry. Aim 3 investigates whether the neural representation of real world scenes is modulated by acquired knowledge about the spatio-temporal context of a scene, which are important for functionality of a scene. Throughout her aims, the PI tests medial temporal lobe regions in human adults that process scene and spatial information: with particular focus on anterior and posterior parahippocampal gyri and retrosplenial cortex. Methods include univariate and multi-voxel fMRI pattern analyses (linear support vector machine classification and representational similarity analysis) in combination with both region-of-interest (ROI) based and whole-brain based (search light) approaches. Hypothesis and preliminary results throughout the proposal suggest that scene geometry is represented in the parahippocampal gyrus, while scene functionality is represented in the retrosplenial cortex. PUBLIC HEALTH RELEVANCE: The research program will establish new framework for understanding the cognitive neuroscience architecture of scene perception, with the aim of unraveling how the human brain analyzes the geometry and functionality of visual environment in order to guide our actions and navigation in the world.",Neural representation of the geometry and functionality in a scene,9461541,R01EY026042,"['4 year old', 'Acute', 'Adult', 'Anterior', 'Architecture', 'Area', 'Base of the Brain', 'Behavioral', 'Brain', 'Categories', 'Cells', 'Characteristics', 'Child', 'Classification', 'Complement', 'Complex', 'Confusion', 'Development', 'Dimensions', 'Environment', 'Fishes', 'Floor', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Height', 'Human', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Light', 'Machine Learning', 'Medial', 'Methods', 'Modeling', 'Movement', 'Multivariate Analysis', 'Nature', 'Neurologic', 'Parahippocampal Gyrus', 'Patients', 'Pattern', 'Perception', 'Process', 'Property', 'Rattus', 'Research', 'Rodent', 'Semantics', 'Shapes', 'Temporal Lobe', 'Testing', 'Time', 'Vision', 'Visual', 'Visuospatial', 'Walking', 'Work', 'base', 'cognitive neuroscience', 'experimental study', 'extrastriate visual cortex', 'interest', 'neuroimaging', 'neurophysiology', 'novel', 'programs', 'public health relevance', 'rehabilitation strategy', 'relating to nervous system', 'spatiotemporal', 'vector']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2018,218064,0.060291664431889665
"Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning PROJECT SUMMARY/ABSTRACT Selective attention is an essential cognitive ability that permits us to effectively process and act upon relevant information while ignoring distracting events. A network involving frontal and parietal cortex for top-down attentional control, referred to as the Dorsal Attention Network (DAN), is active during both spatial and non- spatial (feature-based) attention. However, we know very little about the fine structure of attentional control activity in the DAN, how this structure changes to represent different to-be-attended stimulus features, how the connectivity within the DAN, and between the DAN and sensory cortex shifts when attending different features, or how these top-down processes and their influence in sensory cortex unfold over time. This gap in our knowledge is a critical problem for our models and theories of attention, and because attentional deficits are involved in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia. The working model guiding this research is that top-down attentional control, based on different to-be-attended stimulus attributes, is guided by a smaller-scale neural fine structure within the DAN and prefrontal cortex that makes specific connections with specialized areas of visual cortex coding the attended attributes. Moreover, the time course of activity within the DAN in relation to that in sensory cortex follows a top-down cascading model, being earliest in frontal, then parietal cortex, and finally sensory cortex for preparatory, voluntary, attentional control. To identify the functional networks for attentional control for different forms of attention, and to define their time courses, this project uses innovative simultaneous recording of electroencephalographic (EEG) and functional magnetic resonance imaging (fMRI) data. Advanced signal processing and modeling, including multivariate pattern analysis (MVPA), graph theoretic connectivity analysis, and Granger causality analysis will be used to reveal the fine functional anatomy and time course of attentional control and selection. The project includes three experiments that vary the to-be-attended stimulus attributes from spatial location to stimulus features (color and motion), and pursues three aims. Aim 1 is to reveal the fine structure of top-down preparatory attentional control for different to-be-attended stimulus features. Aim 2 is to elucidate the specific connectivity between fine structures for preparatory attentional control in the DAN and their target sensory structures in sensory cortex. Aim 3 is to reveal the time course of top-down attentional control for different to-be-attended stimulus attributes. PROJECT NARRATIVE The capacity to focus attention is at the core of human mental functioning, and therefore, elucidating the neural bases of attention remains a central challenge for neuroscience, representing an essential aim in translational efforts to ameliorate attentional deficits in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia.",Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning,9616747,R01MH117991,"['Anatomy', 'Attention', 'Attention Deficit Disorder', 'Attentional deficit', 'Autistic Disorder', 'Brain', 'Code', 'Color', 'Cues', 'Data', 'Dementia', 'Discrimination', 'Dorsal', 'Etiology', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'Graph', 'Human', 'Inferior', 'Knowledge', 'Location', 'Machine Learning', 'Modeling', 'Motion', 'Neurosciences', 'Parietal Lobe', 'Pattern', 'Perception', 'Physiological', 'Prefrontal Cortex', 'Process', 'Property', 'Research', 'Schizophrenia', 'Sensory', 'Specific qualifier value', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Work', 'attentional control', 'base', 'cognitive ability', 'data integration', 'experimental study', 'extrastriate visual cortex', 'frontal lobe', 'indexing', 'innovation', 'mental function', 'neuropsychiatric disorder', 'predictive modeling', 'relating to nervous system', 'selective attention', 'sensory cortex', 'signal processing', 'theories', 'tool']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2018,567754,0.04131512906614843
"The behavioral functions of upper and lower cortical layers PROJECT SUMMARY/ABSTRACT  The cerebral cortex mediates all of human and animal cognition, encompassing a diverse set of abilities including sensation, perception, decision making, and motor planning. Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders. A major obstacle both to understanding normal behaving and to treating pathology is the high degree of complexity of cortical circuitry, which has remained largely enigmatic. The conventional view of neocortex has been that sensory processing begins in layer 4 (L4), which was identified a century ago as the principal target of thalamic axons carrying information from our sensory organs. Sensory transforms are widely believed to occur as excitation spreads serially along the densest axonal pathways (thalamus→L4→L2/3→L5/6). Recently we discovered that the cerebral cortex, rather than being a monolithic structure, may contain two entirely separate processing systems, activated by the same signals arising from the thalamus. L4 is thus not an obligatory distribution hub for cortical activity, and thalamus activates two distinct “strata” of cortex in parallel.  This proposal's goal is to identify the behavioral and computational roles of the upper (L2-4) and lower strata (L5/6) as well as the interactions between them. We will investigate the behavioral roles of these layers in the mouse whisker system. Specific layers will be optogenetically disrupted in a series of tactile behavioral tasks, in which task complexity is progressively increased. Interlaminar interactions will also be studied by recording electrophysiologically from specific layers during behavior and using novel machine learning techniques designed to identify the type of computation performed in different levels of “deep networks”. The dimensionality of the representation in a layer will be estimated under normal behaviors and when specific layers are inactivated.  Identifying fundamental functions of upper versus cortical layers will likely pave the way for future studies in other neocortical systems and in higher-order species. Moreover, as the different layers contain molecularly and biophysically distinct cell types and project to distinct downstream targets, specific neurological disorders may involve dysfunction of specific pathways, cell types, and layers. Establishing the behavioral and computational roles of these elements may contribute to development of targeted therapies. PROJECT NARRATIVE  Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders, but the behavioral and functional roles of cortical layers and cell types are unknown. Identifying the contributions of specific cortical layers to normal circuit function will lead to better treatment of pathological conditions.     ",The behavioral functions of upper and lower cortical layers,9483798,R01NS094659,"['Animals', 'Area', 'Auditory', 'Axon', 'Behavior', 'Behavioral', 'Biophysics', 'Brain', 'Cells', 'Cerebral cortex', 'Cognition', 'Complex', 'Corpus striatum structure', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Dimensions', 'Discrimination', 'Electrophysiology (science)', 'Elements', 'Esthesia', 'Functional disorder', 'Future', 'Goals', 'Halorhodopsins', 'Human', 'Individual', 'Machine Learning', 'Measures', 'Mediating', 'Mental disorders', 'Modality', 'Molecular', 'Morphology', 'Motor', 'Mus', 'Neocortex', 'Neurons', 'Organ', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Perception', 'Performance', 'Population', 'Role', 'Sensory', 'Sensory Physiology', 'Series', 'Shapes', 'Signal Transduction', 'Source', 'Spinal Cord', 'Stimulus', 'Structure', 'Synapses', 'System', 'Tactile', 'Task Performances', 'Techniques', 'Testing', 'Texture', 'Thalamic structure', 'Training', 'Vibrissae', 'biophysical properties', 'cell type', 'design', 'expectation', 'hippocampal pyramidal neuron', 'neocortical', 'nervous system disorder', 'novel', 'object shape', 'optogenetics', 'response', 'sensory discrimination', 'spatial integration', 'targeted treatment']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,350000,0.014565273175048058
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9526901,R01DC015138,"['Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory area', 'Auditory system', 'Behavior', 'Biological', 'Biomedical Engineering', 'Brain', 'Catalogs', 'Categories', 'Cells', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Devices', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing', 'Human', 'Individual', 'Industrialization', 'Inferior Colliculus', 'Internships', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Prosthesis', 'Psychology', 'Research', 'Research Personnel', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'awake', 'base', 'computational neuroscience', 'data warehouse', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'novel', 'novel strategies', 'online repository', 'online resource', 'programs', 'relating to nervous system', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2018,281216,0.027344315610890037
"Shifting auditory spatial attention: cognitive and neural mechanisms ﻿    DESCRIPTION (provided by applicant): Hearing can serve as an early warning system because it can panoramically monitor the environment for events happening at a distance or out of sight. These ecological considerations make the auditory system particularly useful for studying mechanisms for shifting spatial attention. The focus of this project is on the interplay between top-down and bottom-up spatial attention biases that govern shifting auditory attention to distractors during performance of a simple spatial attention task. The overall goal of this proposal is to use an interdisciplinary approach to better understand at the cognitive and neural levels of analysis how auditory attention is distributed over space. We will test the hypothesis that the spatial distribution of auditory attentional emerges from interactions among two basic factors. The first factor is a voluntary (top-down) attention bias that weakens with distance from the current focus of attention. Conversely, the second factor is an automatic (bottom-up) bias that is tuned to shift attention to unexpected events away from the current focus of attention. The first aim tests a computational model of top-down and bottom-up attention bias in shifting auditory spatial attention. Different aspects of the model will be quantitatively tested against findings from behavioral experiments, and observations will be used to further develop the model. The computational model will incorporate artificial intelligence methods to represent human cognitive processes. The second aim uses transcranial magnetic stimulation to test the role of key right hemisphere cortical areas in shifting of auditory spatial attention. We focus on neural mechanisms of bottom-up attentional bias. The third aim tests whether auditory attention gradients become less focused over time. This will determine how gradients relate to cognitive resources and neural blood flow measures that are known to decline with extended vigilance. This project will help advance knowledge in the field of auditory attention and cognitive hearing, and also addresses general issues in attention research such as top-down and bottom-up processes, vigilance, and their relations to neurobiological attention networks. Outcomes will have practical significance because shifting auditory attention is vital for avoiding accidents at ll ages, maintaining independent living at older ages, and is applicable to neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). PUBLIC HEALTH RELEVANCE: The project outcomes could have clinical in neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). The project will examine mechanisms of normal cognitive aging using computational modeling, which can inform the early detection, differential diagnosis, and treatment monitoring of age-related neurodegenerative disorders such as Alzheimer's disease. Knowledge from the transcranial magnetic and electrical DC stimulation experiments may have translational applications for rehabilitation following brain injuries.",Shifting auditory spatial attention: cognitive and neural mechanisms,9513308,R01DC014736,"['Accidents', 'Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Attention', 'Attention Deficit Disorder', 'Auditory', 'Auditory system', 'Behavioral', 'Blood flow', 'Brain Injuries', 'Clinical', 'Cognitive', 'Cognitive aging', 'Computer Simulation', 'Dementia', 'Differential Diagnosis', 'Diffuse', 'Dimensions', 'Early Diagnosis', 'Electroencephalography', 'Environment', 'Event', 'Goals', 'Hearing', 'Human', 'Impairment', 'Independent Living', 'Individual Differences', 'Inferior', 'Knowledge', 'Learning', 'Left', 'Location', 'Loudness', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Music', 'Neurobiology', 'Obstruction', 'Outcome', 'Parietal', 'Performance', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Probability', 'Process', 'Property', 'Reaction Time', 'Rehabilitation therapy', 'Reproduction', 'Research', 'Resources', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Site', 'Spatial Distribution', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Transcranial magnetic stimulation', 'Vision', 'Work', 'age related neurodegeneration', 'alpha-SNAP', 'attentional bias', 'attentional control', 'base', 'behavior measurement', 'cognitive process', 'cost shifting', 'experimental study', 'fighting', 'image guided', 'indexing', 'information processing', 'interdisciplinary approach', 'nervous system disorder', 'neural correlate', 'neural stimulation', 'neuroimaging', 'neuromechanism', 'normal aging', 'prefrontal lobe', 'public health relevance', 'relating to nervous system', 'response', 'sound', 'theories', 'vector', 'vigilance']",NIDCD,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2018,262412,0.018397727891417304
"Decoding parametric attributes of auditory working memories from human brain activity Decoding parametric attributes of auditory working memories from human brain activity Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Auditory WM dysfunctions are evidenced in individuals with speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as central auditory processing disorders (CAPD). Better understanding of auditory WM would help develop more precise biomarkers and targeted interventions for these deficits. Evidence for neuronal activation related to auditory WM patterns have been found in laboratory animals as well as in non- invasive human neuroimaging studies, both in auditory cortices (AC) and elsewhere in the brain. Recent human fMRI data also provide some evidence on item-specific activation patterns in ACs and frontal cortices. However, exactly where in the brain auditory WM content is stored and, more importantly, how the memorized information is represented is still unclear.  This research program pursues a better understanding of human auditory WM by attempting to infer its contents from the brain: Using state-of-the-art non-invasive neuroimaging and advanced signal-analysis methods we will search for cortical activation patterns that would predict item-specific WM information. We will examine brain function non-invasively with magneto- and electroencephalography (MEG/EEG), transcranial magnetic stimulation (TMS), and functional MRI (fMRI), and validate the findings using intracranial EEG (iEEG) measurements in presurgical patients. Recent studies suggest that, instead of persistent activation patterns, WM is supported by short-term synaptic facilitation, i.e., ""activity-silent"" population-level mechanisms. We hypothesize that these activity-silent representations could be decoded by analyzing the aftereffects of generic auditory ""impulse stimuli"" or TMS, which are utilized to ""ping"" the underlying cortical network during memory maintenance. We also hypothesize that although auditory WM likely involves co-operation of multiple brain regions, which are involved in articulatory-motor functions, perceptual categorization, or semantic processing, the retention of auditory-sensory attributes such as spectrotemporal modulation patterns critically depends on ACs. To examine WM of such auditory attributes, we will use tasks with dynamic ripple sound stimuli, which are spectrotemporally similar to human vocalizations but resist non-auditory processing strategies.  The major significance of this project is that it will increase the understanding of auditory WM, a crucial cognitive function whose neuronal bases have remained elusive. The results may also help develop more precise tools for characterizing auditory WM dysfunctions in hearing and communication deficits as well as in disorders such as dyslexia, attention deficit/hyperactivity disorder (ADHD), and schizophrenia. Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Our research program pursues a better theoretical understanding of this crucial cognitive function using advanced multimodal neuroimaging methods, validated using intracranial recordings in pre-surgical patients. Our results may also help develop more precise tools for characterizing auditory WM dysfunctions in speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as attention deficit/hyperactivity disorder (ADHD) and schizophrenia.",Decoding parametric attributes of auditory working memories from human brain activity,9498505,R01DC016915,"['Attention deficit hyperactivity disorder', 'Auditory', 'Auditory area', 'Biological Markers', 'Brain', 'Brain region', 'Central Auditory Processing Disorder', 'Cognition', 'Communication', 'Data', 'Disease', 'Dyslexia', 'Electroencephalography', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Generic Drugs', 'Hearing', 'Human', 'Impairment', 'Individual', 'Intervention', 'Laboratory Animals', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measurement', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Motor', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perceptual Disorders', 'Population', 'Principal Component Analysis', 'Problem Solving', 'Reading', 'Research', 'Schizophrenia', 'Sensory', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Speech Perception', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Transcranial magnetic stimulation', 'base', 'cognitive function', 'cortex mapping', 'electric field', 'experimental study', 'frontal lobe', 'multimodality', 'neuroimaging', 'operation', 'programs', 'semantic processing', 'sound', 'tool', 'vocalization']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,602418,0.01075137346929493
"Top-down control of auditory processing in the cortico-collicular network Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network,9408628,R01DC014950,"['Acoustics', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Disease', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Income', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Non-linear Models', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory processing', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'experimental study', 'hearing impairment', 'insight', 'nervous system disorder', 'neurophysiology', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,327250,0.04035745280164657
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9455331,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Simulation', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2018,388993,0.0620740346975979
"The nGoggle: A portable brain-based device for assessment of visual function deficits PROJECT SUMMARY Assessment of loss of visual function outside the foveal area is an essential component of the management of numerous conditions, including glaucoma, retinal and neurological disorders. Despite the significant progress achieved with the development of standard automated perimetry (SAP) many decades ago, assessment of visual field loss with SAP still has significant drawbacks. SAP testing is limited by subjectivity of patient responses and high test-retest variability, frequently requiring many tests for effective detection of change over time. Moreover, as these tests are generally conducted in clinic-based settings, limited patient availability and health care resources often result in an insufficient number of tests acquired over time, with delayed diagnosis and detection of disease progression. The requirement for highly trained technicians, cost, complexity, and lack of portability of SAP also preclude its use for screening of visual field loss in underserved populations. To address shortcomings of current methods to assess visual function, we have developed the nGoggle, a wearable device that uses a head-mounted display (HMD) integrated with wireless electroencephalography (EEG), capable of objectively assessing visual field deficits using multifocal steady-state visual-evoked potentials (mfSSVEP). As part of the funded NEI SBIR Phase I, we developed the nGoggle prototype using a modified smartphone-based HMD display and non-disposable electrodes. In our Phase I studies, we conducted benchmarking tests on signal quality of EEG acquisition, developed methods for EEG data extraction and analysis, and conducted a pilot study demonstrating the ability of the device to detect visual field loss in glaucoma, a progressive neuropathy that results in characteristic damage to the optic nerve and resulting visual field defects. We also identified limitations of current existing displays and electrodes, as well as potential avenues for enhancing test reliability and improving user interface. Based on the encouraging results from Phase I and a clear delineation of the steps needed to bring the device into its final commercial product form, we now propose a series of Phase II studies. We hypothesize that optimization of nGoggle's accuracy and repeatability in detecting visual function loss can be achieved through the development of a customized head-mounted display with front-view eye/pupil tracking cameras and disposable no-prep electrodes, as well as enhancement of the visual stimulation protocol and data analytics. The specific aims of this proposal are: 1) To develop a customized head-mounted display and enhanced no-prep electrodes for improving nGoggle's ability to acquire users' mfSSVEP with high signal-to- noise ratios (SNR) in response to visual stimulation; 2) To optimize and validate mfSSVEP stimuli design and data analytics to enhance the accuracy and repeatability of assessing visual function loss with the nGoggle. 3) Complete pivotal clinical studies to support FDA approval. PROJECT NARRATIVE NGoggle Inc. has developed the nGoggle, a wearable device that uses a head-mounted display integrated with wireless electroencephalography, capable of objectively assessing visual field deficits using multifocal steady- state visual-evoked potentials. NGoggle Inc is now proposing to optimize nGoggle's accuracy and repeatability in detecting visual function loss with the use of a customized display, adherent no-prep electrodes, optimized visual stimuli and data analytics. It will also complete pivotal clinical studies to support FDA approval.",The nGoggle: A portable brain-based device for assessment of visual function deficits,9559052,R42EY027651,"['Address', 'Algorithms', 'Area', 'Base of the Brain', 'Benchmarking', 'Blindness', 'Brain', 'Cellular Phone', 'Characteristics', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Custom', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Elastomers', 'Electrodes', 'Electroencephalography', 'Electrooculogram', 'Exhibits', 'Eye', 'Funding', 'Glaucoma', 'Head', 'Healthcare', 'Machine Learning', 'Methods', 'Neuropathy', 'Noise', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Perimetry', 'Phase', 'Photic Stimulation', 'Pilot Projects', 'Protocols documentation', 'Pupil', 'Resources', 'Retinal Diseases', 'Scotoma', 'Series', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Source', 'Stimulus', 'Testing', 'Time', 'Training', 'Underserved Population', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Wireless Technology', 'base', 'cost', 'design', 'field study', 'improved', 'loss of function', 'nervous system disorder', 'patient response', 'phase 1 study', 'phase 2 study', 'portability', 'prototype', 'real world application', 'relating to nervous system', 'response', 'sample fixation', 'screening', 'virtual reality', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R42,2018,849367,-0.03139082029002618
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9504668,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2018,727051,0.0403740711791051
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,9524027,R01EY011787,"['Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Cells', 'Cerebral cortex', 'Cerebrum', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Genetic', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'area striata', 'awake', 'cell type', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'nerve supply', 'neural circuit', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2018,394146,0.015328554356119321
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,9775855,R01EY011787,"['Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Cells', 'Cerebral cortex', 'Cerebrum', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Genetic', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'area striata', 'awake', 'cell type', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'nerve supply', 'neural circuit', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2018,405000,0.015328554356119321
"Post-natal development of high-level visual representation in primates View-invariant object recognition is a complex cognitive task that is critical to everyday functioning. A key neural correlate of high-level object recognition is inferior temporal (IT) cortex, a brain area present in both humans and non-human primates. Recent advances in visual systems neuroscience have begun to uncover how images are encoded in the adult IT object representation, however the learning rules by which high level visual areas (especially IT) develop remain mysterious, with both the magnitude and qualitative nature of developmental changes remaining almost completely unknown — in part because, over the last thirty years, there have been practically no studies of spiking neural responses in the higher ventral cortical areas of developing primates. There is thus a significant gap in our understanding of how visual development proceeds.  This exploratory proposal aims to characterize how representation in higher primate visual cortex changes during development. We first aim (Aim 1) to implant chronic electrode arrays to record hundreds of IT neuronal sites in response to thousands of image stimuli in awake behaving juvenile macaques. These data will comprise a snapshot of the developing primate visual representation, and will be particularly powerful because we have already extensively measured adult monkey IT using the same stimuli and methods. By comparing juvenile and adult neuronal responses at both single site and population levels, we will obtain a unprecedentedly large-scale and detailed picture of the neural correlates of high-level visual development (Aim 2).  Aims 1 and 2 are exploratory, but potentially transformative – they will result in publicly available neuronal IT development benchmarks against which any proposed model of high level visual development can be rigorously tested, and will spur the development of those models in our lab and others. In that context, we will also seek (Aim 3) to improve known semi- and un-supervised learning rules from the computer vision and computational neuroscience literature, and to compare them to both recent high-performing (but biologically implausible) supervised models as well to the rich developmental measurements obtained in Aims 1 and 2.  Establishing experimental and surgical procedures for juvenile array recordings will create the future opportunity to observe changes in high level neural visual representations while experience is manipulated in early development, and will enable experiments in other sensory, motor, or decision making domains. If successful, the proposed work will yield a deeper understanding of the principles underlying visual cortex development, understanding which will in turn be helpful for treating neurodevelopmental disorders that implicate cortical circuits, including amblyopia and autism. Project narrative  Visual object recognition is fundamental to our everyday functioning. While the brain is remarkably good at accomplishing these challenging tasks, we do not yet know how it learns this ability during development. The goal of these experiments is to develop new experimental and computational tools to discover the neural learning principles that underlie that visual ability.",Post-natal development of high-level visual representation in primates,9455686,R21EY025863,"['Adolescent', 'Adult', 'Amblyopia', 'Animals', 'Area', 'Autistic Disorder', 'Behavioral', 'Benchmarking', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Chronic', 'Collaborations', 'Complex', 'Computer Vision Systems', 'Conflict (Psychology)', 'Data', 'Data Set', 'Decision Making', 'Development', 'Electrodes', 'Exhibits', 'Eye', 'Face', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Head', 'Human', 'Image', 'Implant', 'Inferior', 'Learning', 'Literature', 'Macaca', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monkeys', 'Motivation', 'Motor', 'Nature', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Performance', 'Population', 'Primates', 'Procedures', 'Process', 'Research', 'Rewards', 'Sensory', 'Site', 'Stimulus', 'Stream', 'Supervision', 'System', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'awake', 'base', 'cognitive task', 'computational neuroscience', 'computerized tools', 'experience', 'experimental study', 'extrastriate visual cortex', 'improved', 'juvenile animal', 'learning network', 'mature animal', 'multi-electrode arrays', 'network models', 'neural correlate', 'nonhuman primate', 'novel', 'object recognition', 'postnatal', 'predictive modeling', 'receptive field', 'relating to nervous system', 'response', 'statistics', 'vision development']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2018,232050,0.08851836462626217
"Cortical computations underlying binocular motion integration PROJECT SUMMARY / ABSTRACT Neuroscience is highly specialized—even visual submodalities such as motion, depth, form and color processing are often studied in isolation. One disadvantage of this isolation is that results from each subfield are not brought together to constrain common underlying neural circuitry. Yet, to understand the cortical computations that support vision, it is important to unify our fragmentary models that capture isolated insights across visual submodalities so that all relevant experimental and theoretical efforts can benefit from the most powerful and robust models that can be achieved. This proposal aims to take the first concrete step in that direction by unifying models of direction selectivity, binocular disparity selectivity and 3D motion selectivity (also known as motion-in-depth) to reveal circuits and understand computations from V1 to area MT. Motion in 3D inherently bridges visual submodalities, necessitating the integration of motion and binocular processing, and we are motivated by two recent paradigm-breaking physiological studies that have shown that area MT has a robust representation of 3D motion. In Aim 1, we will create the first unified model and understanding of the relationship between pattern and 3D motion in MT. In Aim 2, we will construct the first unified model of motion and disparity processing in MT. In Aim 3, we will develop a large-scale biologically plausible model of these selectivities that represents realistic response distributions across an MT population. Having a population output that is complete enough to represent widely-used visual stimuli will amplify our ability to link to population read-out theories and to link to results from psychophysical studies of visual perception. Key elements of our approach are (1) an iterative loop between modeling and electrophysiological experiments; (2) building a set of shared models, stimuli, data and analysis tools in a cloud-based system that unifies efforts across labs, creating opportunities for deep collaboration between labs that specialize in relevant submodalities, and encouraging all interested scientists to contribute and benefit; (3) using model-driven experiments to answer open, inter-related questions that involve motion and binocular processing, including motion opponency, spatial integration, binocular integration and the timely problem of how 3D motion is represented in area MT; (4) unifying insights from filter-based models and conceptual, i.e., non-image- computable, models to generate the first large-scale spiking hierarchical circuits that predict and explain how correlated signals and noise are transformed across multiple cortical stages to carry out essential visual computations; and (5) carrying out novel simultaneous recordings across visual areas. This research also has potential long-term benefits in medicine and technology. It will build fundamental knowledge about functional cortical circuitry that someday may be useful for interpreting dysfunctions of the cortex or for helping biomedical engineers construct devices to interface to the brain. Insights gained from the visual cortex may also help to advance computer vision technology. NARRATIVE The processing of visual motion and depth information is essential for a wide variety of important human abilities, including navigating through the world, avoiding collisions, catching and grabbing objects and interpreting complex scenes. To understand how neurons in the visual cortex transform and represent the information that underlies these abilities, we aim to initiate the development of a more complete, biologically constrained and openly available computer model of motion and depth processing that will be used to guide, and to interpret and incorporate results from, primate visual neurophysiological and psychophysical experiments. Gaining an understanding of the normal function of cortical neural circuitry is an important step in building the fundamental knowledge that someday may help to improve the ability to assess dysfunctions of the cortex and may help bioengineers create devices that interface to cortical circuitry to treat disorders and overcome disabilities.",Cortical computations underlying binocular motion integration,9567839,R01EY027023,"['Affect', 'Architecture', 'Biological', 'Biomedical Engineering', 'Brain', 'Collaborations', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disadvantaged', 'Discrimination', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Foundations', 'Frequencies', 'Functional disorder', 'Human', 'Joints', 'Knowledge', 'Link', 'Literature', 'Medicine', 'Modeling', 'Motion', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Pattern', 'Performance', 'Physiological', 'Physiology', 'Population', 'Primates', 'Production', 'Psychophysics', 'Reproducibility', 'Research', 'Role', 'Scientist', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Vision Disparity', 'Visual', 'Visual Cortex', 'Visual Motion', 'Visual Perception', 'area MT', 'base', 'cloud based', 'color processing', 'disability', 'experimental study', 'extrastriate visual cortex', 'fitness', 'improved', 'in vivo', 'insight', 'interest', 'neural circuit', 'neurophysiology', 'novel', 'predictive modeling', 'relating to nervous system', 'response', 'spatial integration', 'spatiotemporal', 'theories', 'tool', 'visual neuroscience', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2018,413375,0.07242669388898451
"GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN PROJECT SUMMARY & ABSTRACT  Human locomotion through natural environments requires the coordination of all levels of the sensorimotor hierarchy, from the cortical areas involved in processing of visual information and high level planning to the subcortical and spinal structures involved in the regulation of the gait and posture. However, despite the complex neural bases of human locomotion, the output is highly regular and well organized around the basic physical dynamics and biomechanics that define the stability and energetic costs of moving a bipedal body through space. There is a rich and growing body of literature describing detailed knowledge each of the individual components of human locomotion, including neural mechanisms, muscular neuromechanics, and biomechanics. However, very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion through a complex and dynamic world. This lack of integrative research not only restricts the breadth of impact of research from these individual disciplines, but also limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to to fill this critical gap in our knowledge about human locomotion, it is necessary to develop an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world. In service of this general goal, this proposal outlines research projects aimed at specific unanswered questions about locomotion over different terrains. This proposal comprises three specific research and training aims on the visual control of locomotion over rough terrain. Aim 1 focuses on the behavioral task itself, Aim 2 investigates the sensory stimulus experienced during real-world locomotion, and Aim 3 examines the motor integration of visually specified goals into the ongoing gait cycle. Aim 1 investigates effects of changing environmental uncertainty and task demands on gaze allocation strategies during locomotion over real-world rough terrain. Aim 2 analyzes and models the visual stimulus experienced during locomotion over real-world rough terrain. Aim 3 determines how visually specified target footholds and targets are integrated into the ongoing preferred steady-state gait. Together these aims will significantly advance our understanding of how humans use vision to control their movement through the natural world, which greatly increase our ability to develop clinical diagnosis and treatment for loss of locomotor function. PROJECT NARRATIVE  Very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion. This lack of integrative research limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to fill this critical gap in our knowledge about human locomotion, this proposal develops an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world.",GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN,9527525,K99EY028229,"['Aging', 'Algorithms', 'Area', 'Attention', 'Behavior', 'Behavioral', 'Biomechanics', 'Body Image', 'Clinical Treatment', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Development', 'Discipline', 'Environment', 'Eye', 'Gait', 'Goals', 'Human', 'Individual', 'Knowledge', 'Link', 'Literature', 'Locomotion', 'Measures', 'Mechanics', 'Mentors', 'Modeling', 'Motion', 'Motor', 'Movement', 'Muscle', 'Musculoskeletal', 'Nature', 'Neuromechanics', 'Output', 'Parkinson Disease', 'Pattern', 'Phase', 'Photic Stimulation', 'Positioning Attribute', 'Postdoctoral Fellow', 'Posture', 'Protocols documentation', 'Regulation', 'Research', 'Research Activity', 'Research Project Grants', 'Research Training', 'Services', 'Signal Transduction', 'Specific qualifier value', 'Spinal', 'Stroke', 'Structure', 'System', 'Training', 'Training Programs', 'Uncertainty', 'Vision', 'Visual', 'Visual Fields', 'Walking', 'Wireless Technology', 'area MST', 'area MT', 'base', 'clinical Diagnosis', 'cost', 'design', 'environmental change', 'experience', 'experimental study', 'foot', 'gaze', 'insight', 'instrument', 'kinematics', 'multidisciplinary', 'neuromechanism', 'neuromuscular', 'novel', 'optic flow', 'programs', 'relating to nervous system', 'response', 'sensory stimulus', 'skills', 'statistics', 'treadmill', 'treatment planning', 'visual control', 'visual information', 'visual processing', 'visual stimulus', 'visual-motor integration']",NEI,"UNIVERSITY OF TEXAS, AUSTIN",K99,2018,121770,0.05377184470026173
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology No abstract available Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,9681144,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2018,58282,-0.0007586660655749098
"CRCNS: Joint coding of shape and texture in the primate brian PROJECT DESCRIPTION  Collaborating Pis and Consultant  United States  Pl: Anitha Pasupathy, Dept. of Biological Structure, University of Washington, Seattle, USA  Co-Pl: Wyeth Bair, Dept. of Biological Structure, University of Washington, Seattle, USA Japan  Pl: lsamu Motoyoshi, Dept. of Life Sciences, The University of Tokyo, Japan  Consultant: Hidehiko Komatsu, Tamagawa University, Japan  Specific Aims  Our visual system endows us with a diverse set of abilities: to recognize and manipulate  objects, avoid obstacles and danger during navigation, evaluate the quality of food, read text,  interpret facial expressions, etc. This relies on the neuronal processing of information about  form and material texture along the ventral pathway of the primate visual system (Ungerleider &  Mishkin, 1982; Felleman & Van Essen, 1991). Studies over the past several decades have  produced detailed models of how visual information is processed in V1, the earliest stage along . this pathway (Hubel & Wiesel, 1959, 1968; Movshon et al., 1978a, b; Albrecht et al., 1980), but  beyond V1 our understanding of visual processing and representation is limited. This is  particularly true with regard to our understanding of how visual representations of form and  texture jointly contribute to object perception and recognition. The broad goal of this proposal is  two-fold-to develop an experimentally-driven image-computable model for how naturalistic  visual stimuli are processed in area V4, an important intermediate stage along the ventral visual  pathway (Aim 1) and to discover how such a representation contributes to perception (Aim 2).  Past studies have shown that V4 neurons are sensitive to both the form (Desimone and Schein,  1987; Kobatake and Tanaka, 1994; Gallant et al., 1993; Pasupathy and Connor, 2001; Nandy et  al., 2013) and the surface texture of visual stimuli (Arcizet et al., 2008; Goda et al., 2014;  Okazawa et al., 2015). But, because expertise is narrow and experimental time limited,  scientists tend to focus exclusively on the encoding of form or texture and not on their joint  coding. For example, in the laboratories of the USA portion of this collaboration, we have until  now focused on form processing by carrying out neurophysiological studies using 2D shapes  with uniform surface properties to investigate how object boundaries are encoded (Oleskiw et  al., 2014; Popovkina et al., 2016). We have modeled our data by comparing the representation  of V4 neurons to that of the units in AlexNet (Pospisil et al., 2015), a prominent convolutional  neural net (CNN) trained to recognize objects (Krizhevsky et al., 2012). At the same time, the  Japanese contingent of this collaboration has investigated the encoding of surface texture and  gloss in human perception without associated form encoding (Motoyoshi et al., 2007; Sharan et  al., 2008; Motoyoshi, 2010; Motoyoshi & Matoba, 2012). Here we propose to bring our  respective expertise in studying form and texture encoding to bear on the question of how  naturalistic stimuli with both form and surface cues are encoded in area V4 and how these  representations support human visual perception. Our specific aims are:  Aim1. To build a unified image-computable model for neuronal responses to shapes and  textures in area V4  V4 responses to 2D shapes with uniform luminance/chromatic characteristics can be explained  by a hierarchical-Max (HMax) model for object recognition that emphasizes boundary features  (Cadieu et al., 2007). Such responses can also be explained by units in artificial deep  convolutional networks, in which boundary features are not explicitly emphasized (all features  are learned from initially random weights). On the other hand, V4 responses to texture patches  can be well explained by a higher-order image-statistics-based model (Okazawa et al., 2015).  Using shape data from the Pasupathy lab and texture data from the Komatsu lab (Japanese  consultant), we will ask whether responses of V4 neurons to shapes and textures can be Page 21 n/a",CRCNS: Joint coding of shape and texture in the primate brian,9692119,R01EY029997,"['Biological', 'Biological Sciences', 'Categories', 'Characteristics', 'Code', 'Collaborations', 'Computer Simulation', 'Computers', 'Cues', 'Data', 'Dimensions', 'Discrimination', 'Facial Expression', 'Goals', 'Human', 'Image', 'Individual', 'Japan', 'Japanese Population', 'Joints', 'Laboratories', 'Modeling', 'Modification', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Physiology', 'Primates', 'Process', 'Psychophysics', 'Scientist', 'Shapes', 'Stimulus', 'Structure', 'Subgroup', 'Surface', 'Surface Properties', 'Text', 'Texture', 'Time', 'Tokyo', 'Training', 'United States', 'Universities', 'V4 neuron', 'Visual', 'Visual Pathways', 'Visual Perception', 'Visual system structure', 'Washington', 'Weight', 'area V4', 'base', 'experimental study', 'food quality', 'human model', 'human subject', 'information processing', 'luminance', 'neurophysiology', 'novel', 'object perception', 'object recognition', 'relating to nervous system', 'response', 'statistics', 'visual information', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2018,263433,0.09980350581947274
"The role of area V4 in the perception and recognition of visual objects ﻿    DESCRIPTION (provided by applicant): The human visual system parses the information that reaches our eyes into a meaningful arrangement of regions and objects. This process, called image segmentation, is one of the most challenging computations accomplished by the primate brain. To discover its neural basis we will study neuronal processes in two brain areas in the macaque monkey-V4, a fundamental stage of form processing along the occipito-temporal pathway, and the prefrontal cortex (PFC), important for executive control. Dysfunctions of both areas impair shape discrimination behavior in displays that require the identification of segmented objects, strongly suggesting that they are important for image segmentation. Our experimental techniques will include single and multielectrode recordings, behavioral manipulations, perturbation methods and computer models. In Aim 1 we will identify the neural signals that reflect segmentation in visual cortex. Using a variety of parametric stimuli with occlusion, clutter and shadows-stimulus features known to challenge segmentation in natural vision-we will evaluate whether segmentation is achieved by grouping regions with similar surface properties, such as surface color, texture and depth, or by grouping contour segments that are likely to form the boundary of an object or some interplay between these two strategies. We will test the hypothesis that contour grouping mechanisms are most effective under low clutter and close to the fovea. In Aim 2, we will investigate how feedback from PFC modulates shape responses in V4 and facilitates segmentation: we will test the longstanding hypothesis that object recognition in higher cortical stages precedes and facilitates segmentation in the midlevels of visual form processing. We will simultaneously study populations of V4 and PFC neurons while animals engage in shape discrimination behavior. We will use single-trial decoding methods and correlation analyses to relate the content and timing of neuronal responses in the two areas. To causally test the role of feedback from PFC, we will reversibly inactivate PFC by cooling and study V4 neurons. Our results will provide the first detailed, analytical models of V4 neuronal response dynamics in the presence of occlusion and clutter and advance our understanding of how complex visual scenes are processed in area V4. They will also reveal how V4 and PFC together mediate performance on a complex shape discrimination task, how executive function and midlevel vision may be coordinated during behavior and how feedback is used in cortical computation. Object recognition is impaired in visual agnosia, a dysfunction of the occipito-temporal pathway, and in dysfunctions of the PFC (e.g. schizophrenia). Results from these experiments will constitute a major advance in our understanding of the brain computations that underlie segmentation and object recognition and will bring us closer to devising strategies to alleviate and treat brain disorders in which these capacities are impaired. PUBLIC HEALTH RELEVANCE: A fundamental capacity of the primate visual system is its ability to segment visual scenes into component objects and then recognize those objects regardless of partial occlusions and clutter. Using a combination of primate neurophysiology experiments, computational modeling, animal behavior and reversible inactivation methods, we hope to achieve a new level of understanding about visual processing in the context of object recognition; these findings will ultimately bring us closer to devising strategies to alleviate and treat brain disorders of impaired object recognition resulting from dysfunctions in the occipito-temporal pathway (e.g. agnosia) and the prefrontal cortex (e.g. schizophrenia).",The role of area V4 in the perception and recognition of visual objects,9462122,R01EY018839,"['Agnosia', 'Animal Behavior', 'Animals', 'Area', 'Back', 'Behavior', 'Behavior Control', 'Behavioral', 'Brain', 'Brain Diseases', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Custom', 'Data', 'Discrimination', 'Eye', 'Feedback', 'Functional disorder', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Lesion', 'Macaca', 'Mediating', 'Methods', 'Modeling', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Play', 'Population', 'Prefrontal Cortex', 'Primates', 'Process', 'Property', 'Psychology', 'Psychophysics', 'Role', 'Schizophrenia', 'Shapes', 'Signal Transduction', 'Stimulus', 'Stream', 'Surface', 'Surface Properties', 'Techniques', 'Testing', 'Texture', 'Time', 'V4 neuron', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual system structure', 'area V4', 'awake', 'base', 'design', 'executive function', 'experimental study', 'fovea centralis', 'imaging Segmentation', 'impaired capacity', 'neurophysiology', 'neurotransmission', 'object recognition', 'public health relevance', 'relating to nervous system', 'response', 'stereoscopic', 'study population', 'visual processing']",NEI,UNIVERSITY OF WASHINGTON,R01,2018,510463,0.10865748464048915
"Active Sensation during Odor-Guided Navigation in Mice PROJECT SUMMARY We often consider our movements a result of sensory processing – sensation guides behavior. However, animals selectively shape future sensory input through their own actions in a process known as active sampling. Thus, action and sensation are inextricably linked. Despite this, much of the research done on sensory processing restricts movement, most commonly via head fixation. To access sensorimotor processing during more natural behavior, we will study olfactory navigation in freely-moving mice. The olfactory system is ideal for studying sensory sampling, because of its ethological relevance for mammalian foraging and the dynamic nature of airborne odor stimuli. The proposed research will determine the sampling strategies of olfactory search and reveal the underlying circuitry that connects sensation with motion. Aim 1. It is unknown how rodents navigate dynamic plumes of odorant towards an odor source. In this aim, we will identify, analyze, and model active sensing behaviors that occur during increasingly difficult navigation tasks and with single nostrils occluded. These experiments will test the hypothesis that olfactory navigation works as a sensorimotor closed-loop system, where animals optimize sampling behaviors for the current stimulus conditions. These behavioral studies will lay the foundation for investigations of sensorimotor processing in dynamic olfactory scenes. Aim 2. To determine how sampling movements shape sensation, we will monitor neural activity during active sensory behavior. During odor tracking, we will electrophysiologically record in the olfactory bulb, a bottleneck through which all sensory input passes. We will determine the sensory history dependence of active sampling and, in doing so, reveal part of the underlying circuitry that connects motion with sensation. These experiments will test the hypothesis that sampling movements are sensory history dependent. To our knowledge, sampling movements and sensory activity have never been simultaneously recorded during olfactory navigation. This research will advance our understanding of the interplay between sensation and motion during natural behavior. PROJECT NARRATIVE Deficits in sensory motor communication are a major contributor to prevalent neurological disorders such as schizophrenia and Parkinson's disease. Our assay of olfactory navigation will model the interaction between sensation and movement and identify the circuitry through which movements are decided by sensory input. Discovering mechanisms of sensorimotor integration are the key to a better understanding of sensory processing in these disorders, since sensation and action are inextricably linked.",Active Sensation during Odor-Guided Navigation in Mice,9563948,F31DC016799,"['Animals', 'Anterior nares', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Biological Assay', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Disease', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Foundations', 'Future', 'Genetic', 'Head', 'Implant', 'Intake', 'Intervention Studies', 'Investigation', 'Link', 'Modeling', 'Monitor', 'Motion', 'Motor', 'Movement', 'Mus', 'Nature', 'Neurons', 'Nose', 'Odors', 'Olfactory Pathways', 'Output', 'Parkinson Disease', 'Pattern', 'Perception', 'Positioning Attribute', 'Process', 'Recording of previous events', 'Research', 'Respiration', 'Rewards', 'Rodent', 'Sampling', 'Schizophrenia', 'Sensory', 'Shapes', 'Smell Perception', 'Source', 'Stereotyping', 'Stimulus', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Vertebrates', 'Vision', 'Work', 'base', 'behavioral study', 'design', 'experimental study', 'insight', 'nervous system disorder', 'olfactory bulb', 'olfactory stimulus', 'relating to nervous system', 'sample fixation', 'sensory input', 'sensory stimulus', 'sensory system', 'tool']",NIDCD,UNIVERSITY OF OREGON,F31,2018,33530,0.012621654468812209
"Early representation of 3D volumetric shape in visual object processing Project Summary The goal of this project is to test a novel theoretical framework for understanding how the ventral pathway subserves object vision. In the standard framework, a series of neural operations on 2D image data through many intermediate cortical stages, including area V4, leads to high-level perceptual representations, including representation of object identity, at the final stages of the ventral pathway. However, our preliminary microelectrode data from a fixating monkey show that many neurons in V4 represent volumetric (volume- enclosing) 3D shape, not 2D image patterns. These neurons respond to many different 2D images that convey the same 3D shape with different shape-in-depth cues, including shading, reflection, and refraction. They even respond preferentially to random dot stereograms that convey 3D volumetric shape with no 2D cues whatsoever. Moreover, our preliminary results with 2-photon functional imaging in anesthetized monkey V4 show that 3D shape signals are grouped by their similarity, and also group with isomorphic (same outline) 2D shape signals (which could contribute evidence to corresponding 3D shape inferences). We propose to capitalize on these preliminary data by demonstrating the prevalence of 3D shape tuning in area V4, analyzing the 3D shape coding strategies used by these neurons, and measuring how 2D and 3D shape signals are arranged at a microscopic level across the surface of V4. We expect these results to provide strong evidence that extraction of 3D shape fragments is a primary goal of V4 processing. This early extraction of 3D shape information, just two synapses beyond primary visual cortex, would suggest a competing framework for understanding the ventral pathway, in which the initial goal is to represent 3D physical structure, independent of the various 2D image cues used to infer it. In this framework, object recognition would be based on preceding information about 3D physical structure, which would explain why human object recognition is so robust to image changes, in a way that the best computational vision systems are not. The scientific impact of this work would be to divert vision experiments toward understanding representation of real world 3D structure (rather than 2D planar stimuli) and to encourage computational vision scientists to incorporate early 3D shape processing into the deep convolutional network models that are the current state of the art. Narrative This study will help explain how the human brain achieves such remarkably robust perception of visual objects. The results will help guide future rehabilitative and prosthetic strategies for patients with visual impairments, by elucidating neural strategies that could be used to bring computer vision prosthetics up to human performance levels, and by discovering specific neural signals for object information that could be replicated by electrode array implants in higher-level visual cortex.",Early representation of 3D volumetric shape in visual object processing,9579566,R01EY029420,"['Area', 'Biological', 'Brain', 'Calcium Signaling', 'Code', 'Computer Vision Systems', 'Cues', 'Data', 'Electrodes', 'Functional Imaging', 'Future', 'Genetic Programming', 'Glass', 'Goals', 'Human', 'Image', 'Implant', 'Lead', 'Learning', 'Measures', 'Medial', 'Microelectrodes', 'Microscopic', 'Microscopy', 'Modeling', 'Monkeys', 'Network-based', 'Neurons', 'Ocular Prosthesis', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Population', 'Prevalence', 'Prosthesis', 'Rehabilitation therapy', 'Scientist', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Structure', 'Surface', 'Synapses', 'System', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'V4 neuron', 'Vision', 'Visual Cortex', 'Visual Perception', 'Visual impairment', 'Work', 'area V4', 'area striata', 'base', 'experimental study', 'individual response', 'network models', 'neurotransmission', 'nonhuman primate', 'novel', 'object perception', 'object recognition', 'operation', 'relating to nervous system', 'response', 'three dimensional structure', 'two-photon', 'virtual reality', 'visual object processing']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2018,548567,0.0868325048293395
"Millisecond resolution statistics of cortical populations Project Summary/Abstract The mammalian brain builds and transforms representations of the outside world through the concerted activity of populations of neurons, but the extent to which spike times or spike counts are coordinated within these ensembles beyond pairs is not clear. Models of neural encoding predict variable frequencies of spike pattern occurrence, and models of decoding delineate requirements for spike time precision within the population response. While considerable effort has been made toward the development and refinement of the theoretical basis of such neural coding schemes, and predictions have been tested against single cell and pairwise data, there has been relatively little experimental data beyond pairs able to differentiate between competing hypotheses of population coding. The proposed career development plan aims to marry large-scale electrophysiology in primary visual cortex with analysis of specific predictions derived from computational and theoretical neuroscience work for spike time coordination beyond pairwise interactions. The candidate has a deep background in in vivo experimental techniques and proposes to receive training in the high-dimensional computational techniques and to use experimental data collected to validate specific theoretical predictions. This training will establish the skills necessary for a successful independent research career studying the mechanisms of information representation and transfer in visual cortex, bridging the gap between experimental and computational neuroscience. The candidate will carry out the mentored phase under the guidance of Dr. Clay Reid, a world expert in multiple aspects of mammalian central visual processing including anatomy, physiology, and computation. Additional advising from Dr. Eric Shea- Brown and Dr. Christof Koch will provide guidance in the theoretical and applied mathematical approaches required to implement and assess advanced models of neural encoding and decoding. The training will utilize the strengths of the Allen Institute for Brain Science in collecting large-scale data and the didactic opportunities at the University of Washington. In the independent phase the candidate will use the newly acquired analytical and modeling skills in combination with his previous training in optogenetic techniques to better constrain population measurements. This work will help establish a unique independent research program to elucidate the mechanisms underlying cortical representation. Project Narrative Understanding how the brain uses population activity to build representations of the outside world is an important step towards understanding not only sensory but also psychiatric and other cognitive disorders. This work on the fundamental nature of the neural code will contribute to the body of knowledge required to create effective brain interfaces for motor and sensory prostheses with the potential to reduce sensory disabilities, provide treatments for cognitive disorders, and aid in recovery from central nervous system trauma.",Millisecond resolution statistics of cortical populations,9598640,K99EY028612,"['Address', 'Algorithms', 'Anatomy', 'Animals', 'Brain', 'Cells', 'Characteristics', 'Code', 'Cognition Disorders', 'Complex', 'Computational Technique', 'Data', 'Development', 'Development Plans', 'Electrophysiology (science)', 'Frequencies', 'Impaired cognition', 'Institutes', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Mentors', 'Modeling', 'Molecular', 'Motor', 'Mus', 'Nature', 'Nervous System Trauma', 'Neuraxis', 'Neurons', 'Neurosciences', 'Output', 'Pattern', 'Perception', 'Performance', 'Phase', 'Physiological', 'Physiology', 'Population', 'Population Process', 'Population Statistics', 'Property', 'Psychophysics', 'Recovery', 'Research', 'Resolution', 'Scheme', 'Science', 'Sensory', 'Sensory Disorders', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Time', 'Training', 'Universities', 'Variant', 'Visual Cortex', 'Washington', 'Work', 'area striata', 'awake', 'career', 'career development', 'clay', 'computational neuroscience', 'data resource', 'deep learning', 'disability', 'extrastriate visual cortex', 'high dimensionality', 'in vivo', 'innovation', 'mathematical methods', 'millisecond', 'neural model', 'novel', 'optogenetics', 'predictive modeling', 'programs', 'relating to nervous system', 'response', 'sensory prosthesis', 'skills', 'statistics', 'theories', 'visual processing']",NEI,ALLEN INSTITUTE,K99,2018,132984,0.03430954856918757
"Auditory brain-computer interface for communication No abstract available Project Narrative Brain-computer interfaces enable motor-impaired individuals to communicate using an effector such as a neural cursor or a robotic arm. The successful completion of the proposed project will develop a unique technology that enables a real-time auditory-reliant BCI for communication in severely paralyzed individuals resulting from stroke, amyotrophic lateral sclerosis and severe brain injuries. Study results will advance our knowledge of developing neurotechnologies that leverage non-visual sensory modalities, as well as provide much insight into the cortical neural activities that underpin motor intention and movement.",Auditory brain-computer interface for communication,9668360,F32MH118709,"['Adult', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Auditory', 'Auditory system', 'Base of the Brain', 'Brain Injuries', 'Brain Stem Infarctions', 'Clinical Trials', 'Communication', 'Computers', 'Cues', 'Data', 'Development', 'Devices', 'Eye Movements', 'Family Caregiver', 'Fatigue', 'Feedback', 'Frequencies', 'Functional disorder', 'Future Generations', 'Goals', 'Human', 'Impairment', 'Individual', 'Institution', 'Intention', 'Joystick', 'Knowledge', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Manuals', 'Measures', 'Modality', 'Motor', 'Movement', 'Mus', 'Neurologic', 'Ophthalmopareses', 'Paralysed', 'Participant', 'Pathologic Nystagmus', 'Pathway interactions', 'Patients', 'Performance', 'Positioning Attribute', 'Psyche structure', 'Quadriplegia', 'Quality of life', 'Research', 'Research Infrastructure', 'Resources', 'Robotics', 'Sensory', 'Signal Transduction', 'Social Interaction', 'Sound Localization', 'Speech', 'Spinal cord injury', 'Stroke', 'System', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Traumatic Brain Injury', 'Universities', 'User-Computer Interface', 'Vision', 'Visual', 'Visual Fields', 'Visual impairment', 'Workload', 'Writing', 'arm', 'auditory feedback', 'base', 'brain computer interface', 'engineering design', 'improved', 'insight', 'motor impairment', 'neurotechnology', 'neurotransmission', 'novel', 'oculomotor', 'relating to nervous system', 'spelling', 'success', 'usability', 'virtual', 'visual feedback', 'way finding']",NIMH,BROWN UNIVERSITY,F32,2018,68154,-0.016412662937262328
"Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing ﻿    DESCRIPTION (provided by applicant): The long-term goal of this research is to understand how the brain decides where we look in the real world. Many factors influence our eye movements (saccades). For instance, we are more likely to look at salient objects (i.e. those that are conspicuous), such as a bright red balloon in a blue sky. We are also more likely to look at goal-dependent objects (i.e. those that share features with our goals), such as a yellow object when searching for a banana. For several decades, researchers in computer vision have been developing models based on these factors to predict the locations to which we move our eyes. Researchers in neurobiology have also been studying saccade selection, and have suggested the frontal eye field (FEF) plays a large role, as the FEF encodes both visual features and eye movements. But because the FEF encodes both visual features and saccades, it is very difficult to parse FEF activity during natural viewing. For this reason, past experiments have primarily investigated the FEF using simple, constrained tasks with artificial stimuli. In this project, I wil use images of natural scenes, which better approximate the complexity of the real world. I will record with extracellular electrodes from the FEF of awake, behaving rhesus monkeys, while they view natural scenes. In order to determine the FEF's role in the decision of where to saccade next in natural scenes, I will investigate how the FEF encodes visual features that predict saccades. In my two aims, I will test how the FEF encodes salience (Aim 1) and goal-dependence (Aim 2). I will build a model that explains neural activity using visual features (salience and goal-dependence) along with eye movements, which are a confounding source of neural activity. This model will take advantage of computer vision and machine learning algorithms in order to look at the effects of large numbers of correlates and visual features in these natural scenes. The neural data analysis methods developed for these aims will allow researchers that study many brain areas to more easily use natural scenes. Additionally, understanding how the brain chooses where to saccade in natural scenes have important consequences for neurologic and psychiatric health and disease. Several diseases including schizophrenia, autism, and Parkinson's impair the choice of saccades. A better understanding of the link between visual features, eye movements, and FEF activity promises to increase understanding of these diseases and allow the development of novel diagnostic tools. PUBLIC HEALTH RELEVANCE: This research aims to understand how the frontal eye field cortex helps determine where we look. In particular, it will investigate how the frontal eye field cortex encodes visual stimuli that drive eye movements, such as salient and important objects. Eye movement decisions are impaired in many diseases, including schizophrenia, autism, and Parkinson's, and this research could help lead to a greater understanding of these diseases and the development of novel diagnostic tools.",Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing,9266417,F31EY025532,"['Affect', 'Algorithms', 'Area', 'Autistic Disorder', 'Banana', 'Behavior', 'Brain', 'Brain region', 'Complex', 'Computer Vision Systems', 'Crowding', 'Data', 'Data Analyses', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Goals', 'Health', 'Image', 'Impairment', 'Lead', 'Link', 'Location', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Neurobiology', 'Neurologic', 'Neurons', 'Parkinson Disease', 'Play', 'Research', 'Research Personnel', 'Role', 'Running', 'Saccades', 'Schizophrenia', 'Site', 'Source', 'Stimulus', 'Testing', 'Visual', 'Visual Pathways', 'Visual attention', 'Work', 'awake', 'base', 'design', 'experience', 'experimental study', 'extracellular', 'frontal eye fields', 'nervous system disorder', 'neural model', 'neuromechanism', 'novel diagnostics', 'public health relevance', 'receptive field', 'relating to nervous system', 'response', 'tool', 'undergraduate student', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY AT CHICAGO,F31,2017,35657,0.07595208116440545
"Representation of information across the human visual cortex ﻿    DESCRIPTION (provided by applicant): The human visual system is organized as a parallel, hierarchical network, and successive stages of visual processing appear to represent increasingly complicated aspects of shape-related and semantic information. However, the way that shape-related and semantic information is represented across much of the visual hierarchy is still poorly understood. The primary goal of this proposal is to understand how information about object shape and semantic category is represented explicitly across mid- and high-level visual areas. To address this important issue we propose to undertake a series of human functional MRI (fMRI) studies, using both synthetic and natural movies. Data will be analyzed by means of a powerful voxel-wise modeling (VM) approach that has been developed in my laboratory over the past several years. In Aim 1 we propose to measure human brain activity evoked by synthetic naturalistic movies, and to use VM to evaluate and compare several competing theories of shape representation across the entire visual cortex. In Aim 2 we propose to use VM to evaluate and compare competing theories of semantic representation. In Aim 3 we propose to use machine learning and and VM to discover new aspects of shape and semantic representation. These experiments will provide fundamental new insights about the representation of visual information across visual cortex. PUBLIC HEALTH RELEVANCE: Disorders of central vision can severely affect quality of life and the design of treatments and devices for improving visual function will depend critically on understanding the organization of visual cortex. We propose to use functional MRI and sophisticated computational data analysis and modeling procedures to evaluate and compare multiple theories of visual function. The results will reveal how visual information is represented across the several dozen distinct functional areas that constitute human visual cortex.",Representation of information across the human visual cortex,9254553,R01EY019684,"['Address', 'Affect', 'Area', 'Award', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Device Designs', 'Dimensions', 'Disease', 'Elements', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Image', 'Individual', 'Laboratories', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motion', 'Perception', 'Procedures', 'Quality of life', 'Semantics', 'Series', 'Shapes', 'Surface', 'System', 'Testing', 'Training', 'V2 neuron', 'V4 neuron', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'area V1', 'area striata', 'base', 'data modeling', 'design', 'exhaustion', 'experimental study', 'extrastriate visual cortex', 'high dimensionality', 'improved', 'innovation', 'insight', 'learning strategy', 'movie', 'novel', 'object recognition', 'object shape', 'public health relevance', 'receptive field', 'theories', 'therapy design', 'visual information', 'visual neuroscience', 'visual processing']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2017,377994,0.09263354429713333
"Neural representation of the geometry and functionality in a scene ﻿    DESCRIPTION (provided by applicant):  The goal of the proposed research is to investigate how the brain represents scene geometry and functionality. Recognizing the visual environment is central to our daily interactions with the world. When we walk into a new space, we rapidly recognize whether there is a path to follow, whether there are crossable boundaries, and whether there are obstacles that block our view and potential navigation. The theoretical framework of this proposal is based on evidence that there are distinct but complementary levels of scene representation across a group of scene-selective regions in the brain (Park et al., 2011; Park et al., 2014; Park & Chun, 2009; Park, Chun, & Johnson, 2010; Park, Intraub, Yi, Widders, & Chun, 2007). The PI proposes that scene geometry (e.g., spatial layout, three-dimensional scene boundary) and functionality (e.g., navigability, limitations of a boundary) are two fundamental scene properties represented in these regions. Specific Aims: Aim 1 investigates whether the brain displays acute sensitivity to the presence of vertical boundaries, and how such sensitivity is modulated by the functional impediment that a boundary presents to the viewer's potential navigation. Aim 2 investigates the neural representation of the scene navigability, and how this representation differs from representation of scene geometry. Aim 3 investigates whether the neural representation of real world scenes is modulated by acquired knowledge about the spatio-temporal context of a scene, which are important for functionality of a scene. Throughout her aims, the PI tests medial temporal lobe regions in human adults that process scene and spatial information: with particular focus on anterior and posterior parahippocampal gyri and retrosplenial cortex. Methods include univariate and multi-voxel fMRI pattern analyses (linear support vector machine classification and representational similarity analysis) in combination with both region-of-interest (ROI) based and whole-brain based (search light) approaches. Hypothesis and preliminary results throughout the proposal suggest that scene geometry is represented in the parahippocampal gyrus, while scene functionality is represented in the retrosplenial cortex. PUBLIC HEALTH RELEVANCE: The research program will establish new framework for understanding the cognitive neuroscience architecture of scene perception, with the aim of unraveling how the human brain analyzes the geometry and functionality of visual environment in order to guide our actions and navigation in the world.",Neural representation of the geometry and functionality in a scene,9245696,R01EY026042,"['4 year old', 'Acute', 'Adult', 'Anterior', 'Architecture', 'Area', 'Base of the Brain', 'Behavioral', 'Brain', 'Categories', 'Cells', 'Characteristics', 'Child', 'Classification', 'Complement', 'Complex', 'Confusion', 'Development', 'Dimensions', 'Environment', 'Fishes', 'Floor', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Height', 'Human', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Light', 'Machine Learning', 'Medial', 'Methods', 'Modeling', 'Movement', 'Multivariate Analysis', 'Nature', 'Neurologic', 'Parahippocampal Gyrus', 'Patients', 'Pattern', 'Perception', 'Process', 'Property', 'Rattus', 'Research', 'Rodent', 'Semantics', 'Shapes', 'Temporal Lobe', 'Testing', 'Time', 'Vision', 'Visual', 'Visuospatial', 'Walking', 'Work', 'base', 'cognitive neuroscience', 'experimental study', 'extrastriate visual cortex', 'interest', 'neuroimaging', 'neurophysiology', 'novel', 'programs', 'public health relevance', 'rehabilitation strategy', 'relating to nervous system', 'spatiotemporal', 'vector']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2017,318064,0.060291664431889665
"Thalamic and Cortical Mechanisms of Itch ﻿    DESCRIPTION (provided by applicant): Itch is a common clinical problem that is often difficult to treat. There is currently little understanding of the mechanism used in the CNS to produce itch and this likely contributes to the inability to treat itch. In recent years it have become cler that information related to itch is carried in the periphery and spinal cord by neurons that are also activated by noxious stimuli. This suggests that information necessary for the production of itch in the brain must be extracted from the responses of polysensory neurons in a process called decoding. The proposed studies, will for the first time, use single unit electrophysiologica techniques to determine the areas in the thalamus and cortex where processing of pruriceptive information occurs. The responses of single neurons in the thalamus to various itch-and pain-producing stimuli will be determined. The cortical areas to which pruriceptive thalamic neurons project will be determined using antidromic activation methods. In addition, responses of individual cortical neurons to pruritogens and pain-producing stimuli will be determined. The proposed studies will determine the thalamic nuclei and cortical areas in which processing of information related to itch and pain occur. In addition, using a Machine Learning approach, we will determine the contributions of the intensity and pattern of action potentials within responses to differential coding of itch and pain related responses. The proposed studies will considerably expand our understanding of the CNS mechanisms that produce itch and pain.        RELEVANCE: Very little is known about the neural systems in the thalamus and cerebral cortex that underlie production of the sensation of itch. This lack of understanding likely contributes to the paucity of effective treatments for the majority of types of chronic itch. The proposed studies will determine the areas in the thalamus and cortex in which single neurons process and transmit information about itch and pain. Project Narrative/Relevance Very little is known about the neural systems in the thalamus and cerebral cortex that underlie production of the sensation of itch. This lack of understanding likely contributes to the paucity of effective treatments for the majority of types of chronic itch. The proposed studies will determine the areas in the thalamus and cortex in which single neurons process and transmit information about itch and pain.",Thalamic and Cortical Mechanisms of Itch,9309093,R01NS089647,"['Action Potentials', 'Address', 'Affective', 'Amygdaloid structure', 'Anatomy', 'Anterior', 'Anxiety', 'Area', 'Attention', 'Axon', 'Brain', 'Cell Nucleus', 'Cells', 'Cerebral cortex', 'Characteristics', 'Clinical', 'Code', 'Complex', 'Data', 'Dimensions', 'Electrophysiology (science)', 'Esthesia', 'Feeling suicidal', 'Frequencies', 'Goals', 'Individual', 'Insula of Reil', 'Machine Learning', 'Mechanics', 'Medial', 'Mental Depression', 'Methods', 'Molecular', 'Neurons', 'Nociception', 'Nociceptive Stimulus', 'Pain', 'Pattern', 'Population Sizes', 'Prevalence', 'Process', 'Production', 'Prosencephalon', 'Pruritus', 'Rattus', 'Sensory', 'Spinal Cord', 'Spinothalamic Tracts', 'Stimulus', 'System', 'Systemic disease', 'TRP channel', 'Techniques', 'Thalamic Nuclei', 'Thalamic structure', 'Time', 'chronic itch', 'cingulate gyrus', 'effective therapy', 'experience', 'imaging study', 'improved', 'information processing', 'pruriceptive neurons', 'relating to nervous system', 'response', 'skin disorder', 'spinal tract', 'time use']",NINDS,UNIVERSITY OF MINNESOTA,R01,2017,332500,-0.06337949059895838
"The behavioral functions of upper and lower cortical layers PROJECT SUMMARY/ABSTRACT  The cerebral cortex mediates all of human and animal cognition, encompassing a diverse set of abilities including sensation, perception, decision making, and motor planning. Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders. A major obstacle both to understanding normal behaving and to treating pathology is the high degree of complexity of cortical circuitry, which has remained largely enigmatic. The conventional view of neocortex has been that sensory processing begins in layer 4 (L4), which was identified a century ago as the principal target of thalamic axons carrying information from our sensory organs. Sensory transforms are widely believed to occur as excitation spreads serially along the densest axonal pathways (thalamus→L4→L2/3→L5/6). Recently we discovered that the cerebral cortex, rather than being a monolithic structure, may contain two entirely separate processing systems, activated by the same signals arising from the thalamus. L4 is thus not an obligatory distribution hub for cortical activity, and thalamus activates two distinct “strata” of cortex in parallel.  This proposal's goal is to identify the behavioral and computational roles of the upper (L2-4) and lower strata (L5/6) as well as the interactions between them. We will investigate the behavioral roles of these layers in the mouse whisker system. Specific layers will be optogenetically disrupted in a series of tactile behavioral tasks, in which task complexity is progressively increased. Interlaminar interactions will also be studied by recording electrophysiologically from specific layers during behavior and using novel machine learning techniques designed to identify the type of computation performed in different levels of “deep networks”. The dimensionality of the representation in a layer will be estimated under normal behaviors and when specific layers are inactivated.  Identifying fundamental functions of upper versus cortical layers will likely pave the way for future studies in other neocortical systems and in higher-order species. Moreover, as the different layers contain molecularly and biophysically distinct cell types and project to distinct downstream targets, specific neurological disorders may involve dysfunction of specific pathways, cell types, and layers. Establishing the behavioral and computational roles of these elements may contribute to development of targeted therapies. PROJECT NARRATIVE  Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders, but the behavioral and functional roles of cortical layers and cell types are unknown. Identifying the contributions of specific cortical layers to normal circuit function will lead to better treatment of pathological conditions.     ",The behavioral functions of upper and lower cortical layers,9313955,R01NS094659,"['Animals', 'Area', 'Auditory', 'Axon', 'Behavior', 'Behavioral', 'Biophysics', 'Brain', 'Cells', 'Cerebral cortex', 'Cognition', 'Complex', 'Corpus striatum structure', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Dimensions', 'Discrimination', 'Electrophysiology (science)', 'Elements', 'Esthesia', 'Functional disorder', 'Future', 'Goals', 'Halorhodopsins', 'Human', 'Individual', 'Machine Learning', 'Measures', 'Mediating', 'Mental disorders', 'Modality', 'Molecular', 'Morphology', 'Motor', 'Mus', 'Neocortex', 'Neurons', 'Organ', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Perception', 'Performance', 'Population', 'Role', 'Sensory', 'Sensory Physiology', 'Series', 'Shapes', 'Signal Transduction', 'Source', 'Spinal Cord', 'Stimulus', 'Structure', 'Synapses', 'System', 'Tactile', 'Task Performances', 'Techniques', 'Testing', 'Texture', 'Thalamic structure', 'Training', 'Vibrissae', 'biophysical properties', 'cell type', 'design', 'expectation', 'hippocampal pyramidal neuron', 'neocortical', 'nervous system disorder', 'novel', 'object shape', 'optogenetics', 'response', 'sensory discrimination', 'spatial integration', 'targeted treatment']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2017,350000,0.014565273175048058
"The behavioral functions of upper and lower cortical layers PROJECT SUMMARY/ABSTRACT  The cerebral cortex mediates all of human and animal cognition, encompassing a diverse set of abilities including sensation, perception, decision making, and motor planning. Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders. A major obstacle both to understanding normal behaving and to treating pathology is the high degree of complexity of cortical circuitry, which has remained largely enigmatic. The conventional view of neocortex has been that sensory processing begins in layer 4 (L4), which was identified a century ago as the principal target of thalamic axons carrying information from our sensory organs. Sensory transforms are widely believed to occur as excitation spreads serially along the densest axonal pathways (thalamus→L4→L2/3→L5/6). Recently we discovered that the cerebral cortex, rather than being a monolithic structure, may contain two entirely separate processing systems, activated by the same signals arising from the thalamus. L4 is thus not an obligatory distribution hub for cortical activity, and thalamus activates two distinct “strata” of cortex in parallel.  This proposal's goal is to identify the behavioral and computational roles of the upper (L2-4) and lower strata (L5/6) as well as the interactions between them. We will investigate the behavioral roles of these layers in the mouse whisker system. Specific layers will be optogenetically disrupted in a series of tactile behavioral tasks, in which task complexity is progressively increased. Interlaminar interactions will also be studied by recording electrophysiologically from specific layers during behavior and using novel machine learning techniques designed to identify the type of computation performed in different levels of “deep networks”. The dimensionality of the representation in a layer will be estimated under normal behaviors and when specific layers are inactivated.  Identifying fundamental functions of upper versus cortical layers will likely pave the way for future studies in other neocortical systems and in higher-order species. Moreover, as the different layers contain molecularly and biophysically distinct cell types and project to distinct downstream targets, specific neurological disorders may involve dysfunction of specific pathways, cell types, and layers. Establishing the behavioral and computational roles of these elements may contribute to development of targeted therapies. PROJECT NARRATIVE  Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders, but the behavioral and functional roles of cortical layers and cell types are unknown. Identifying the contributions of specific cortical layers to normal circuit function will lead to better treatment of pathological conditions.     ",The behavioral functions of upper and lower cortical layers,9495029,R01NS094659,"['Animals', 'Area', 'Auditory', 'Axon', 'Behavior', 'Behavioral', 'Biophysics', 'Brain', 'Cells', 'Cerebral cortex', 'Cognition', 'Complex', 'Corpus striatum structure', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Dimensions', 'Discrimination', 'Electrophysiology (science)', 'Elements', 'Esthesia', 'Functional disorder', 'Future', 'Goals', 'Halorhodopsins', 'Human', 'Individual', 'Machine Learning', 'Measures', 'Mediating', 'Mental disorders', 'Modality', 'Molecular', 'Morphology', 'Motor', 'Mus', 'Neocortex', 'Neurons', 'Organ', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Perception', 'Performance', 'Population', 'Role', 'Sensory', 'Sensory Physiology', 'Series', 'Shapes', 'Signal Transduction', 'Source', 'Spinal Cord', 'Stimulus', 'Structure', 'Synapses', 'System', 'Tactile', 'Task Performances', 'Techniques', 'Testing', 'Texture', 'Thalamic structure', 'Training', 'Vibrissae', 'biophysical properties', 'cell type', 'design', 'expectation', 'hippocampal pyramidal neuron', 'neocortical', 'nervous system disorder', 'novel', 'object shape', 'optogenetics', 'response', 'sensory discrimination', 'spatial integration', 'targeted treatment']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2017,80000,0.014565273175048058
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9301514,R01DC015138,"['Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory area', 'Auditory system', 'Behavior', 'Biological', 'Biomedical Engineering', 'Brain', 'Catalogs', 'Categories', 'Cells', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Devices', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing', 'Human', 'Individual', 'Industrialization', 'Inferior Colliculus', 'Internships', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Prosthesis', 'Psychology', 'Research', 'Research Personnel', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'awake', 'base', 'computational neuroscience', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'novel', 'novel strategies', 'online repository', 'online resource', 'programs', 'relating to nervous system', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2017,293470,0.027344315610890037
"Crossmodal Correspondences Between Visual and Auditory Features ﻿    DESCRIPTION (provided by applicant): We live in a multisensory world, in which stimuli of various types constantly compete for our attention. Information about objects or events typically appears on more than one sensory channel, so that integrating inputs across sensory systems (e.g. vision and hearing) can enhance the signal-to-noise ratio and lead to more efficient perception and action. There is increasing interest in studying how stimulus properties in one sensory modality (e.g. vision) correspond to those in another modality (e.g. hearing). For instance, sounds of high pitch are linked to small-sized visual objects whereas sounds of low pitch are linked with large objects; sounds of high/low pitch are associated with, respectively, visual stimuli of high/low elevation; and even aspects of linguistic stimuli such as vowel quality are associated with visual properties such as object size. Such crossmodal correspondences are important factors in multisensory binding. While information has exploded on the kinds of stimulus features that are reliably associated by human observers across modalities, currently there is little neural evidence to allow a mechanistic account of how crossmodal correspondences arise, or how they relate to synesthesia, a phenomenon in which some individuals experience unusual percepts (e.g. colors) triggered by particular stimuli (e.g. letters. Our goal is to address these important gaps in knowledge, by using functional magnetic resonance imaging (fMRI) in humans to investigate the neural mechanisms underlying crossmodal and synesthetic correspondences and thus to distinguish between alternative explanations that have been offered. A number of possible mechanisms have been entertained for crossmodal correspondences. These include: Hypothesis A - learned associations due to statistical co-occurrences, which would predict that the correspondences are based in multisensory or even classic unisensory regions; Hypothesis B - semantic mediation (e.g. the common word ""high"" may mediate the link between high pitch and high elevation); and Hypothesis C - conceptual linking via a high-level property such as magnitude. In a series of eight experiments that comprise three Specific Aims, we propose to examine these competing accounts, recognizing that some or all of them may be operative, and that the mechanisms may vary between different types of crossmodal correspondences. PUBLIC HEALTH RELEVANCE: The proposed systematic study of the brain basis of correspondences between stimulus properties across sensory systems will allow critical insights into the multisensory processing involved in perception and action, illuminate the multisensory basis of language and music, and expand understanding of the phenomenon of synesthesia in relation to normal experience. From a practical standpoint, the proposed work will make significant contributions to the design of sensory substitution approaches for people with visual, auditory and other sensory deficits, and the rehabilitation of individuals with multisensory processing abnormalities, including developmental (autism, dyslexia), neurological (neglect) and psychiatric (schizophrenia) disorders.",Crossmodal Correspondences Between Visual and Auditory Features,9334867,R01EY025978,"['Activation Analysis', 'Address', 'Attention', 'Auditory', 'Auditory pitch', 'Autistic Disorder', 'Behavioral', 'Binding', 'Brain', 'Color', 'Data', 'Development', 'Dimensions', 'Disease', 'Dyslexia', 'Event', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing', 'Human', 'Individual', 'Judgment', 'Knowledge', 'Language', 'Lead', 'Letters', 'Linguistics', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Modality', 'Multivariate Analysis', 'Music', 'Neurologic', 'Noise', 'Pattern', 'Perception', 'Process', 'Property', 'Regression Analysis', 'Rehabilitation therapy', 'Research Personnel', 'Rest', 'Schizophrenia', 'Semantics', 'Sensory', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Time', 'Vision', 'Visual', 'Work', 'base', 'design', 'experience', 'experimental study', 'insight', 'interest', 'multisensory', 'neglect', 'neuroimaging', 'neuromechanism', 'neurophysiology', 'public health relevance', 'relating to nervous system', 'sensory system', 'sound', 'vector', 'visual stimulus']",NEI,EMORY UNIVERSITY,R01,2017,620264,0.08868752373461206
"Shifting auditory spatial attention: cognitive and neural mechanisms ﻿    DESCRIPTION (provided by applicant): Hearing can serve as an early warning system because it can panoramically monitor the environment for events happening at a distance or out of sight. These ecological considerations make the auditory system particularly useful for studying mechanisms for shifting spatial attention. The focus of this project is on the interplay between top-down and bottom-up spatial attention biases that govern shifting auditory attention to distractors during performance of a simple spatial attention task. The overall goal of this proposal is to use an interdisciplinary approach to better understand at the cognitive and neural levels of analysis how auditory attention is distributed over space. We will test the hypothesis that the spatial distribution of auditory attentional emerges from interactions among two basic factors. The first factor is a voluntary (top-down) attention bias that weakens with distance from the current focus of attention. Conversely, the second factor is an automatic (bottom-up) bias that is tuned to shift attention to unexpected events away from the current focus of attention. The first aim tests a computational model of top-down and bottom-up attention bias in shifting auditory spatial attention. Different aspects of the model will be quantitatively tested against findings from behavioral experiments, and observations will be used to further develop the model. The computational model will incorporate artificial intelligence methods to represent human cognitive processes. The second aim uses transcranial magnetic stimulation to test the role of key right hemisphere cortical areas in shifting of auditory spatial attention. We focus on neural mechanisms of bottom-up attentional bias. The third aim tests whether auditory attention gradients become less focused over time. This will determine how gradients relate to cognitive resources and neural blood flow measures that are known to decline with extended vigilance. This project will help advance knowledge in the field of auditory attention and cognitive hearing, and also addresses general issues in attention research such as top-down and bottom-up processes, vigilance, and their relations to neurobiological attention networks. Outcomes will have practical significance because shifting auditory attention is vital for avoiding accidents at ll ages, maintaining independent living at older ages, and is applicable to neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). PUBLIC HEALTH RELEVANCE: The project outcomes could have clinical in neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). The project will examine mechanisms of normal cognitive aging using computational modeling, which can inform the early detection, differential diagnosis, and treatment monitoring of age-related neurodegenerative disorders such as Alzheimer's disease. Knowledge from the transcranial magnetic and electrical DC stimulation experiments may have translational applications for rehabilitation following brain injuries.",Shifting auditory spatial attention: cognitive and neural mechanisms,9285756,R01DC014736,"['Accidents', 'Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Attention', 'Attention Deficit Disorder', 'Auditory', 'Auditory system', 'Behavioral', 'Blood flow', 'Brain Injuries', 'Clinical', 'Cognitive', 'Cognitive aging', 'Computer Simulation', 'Dementia', 'Differential Diagnosis', 'Diffuse', 'Dimensions', 'Early Diagnosis', 'Electroencephalography', 'Environment', 'Event', 'Goals', 'Hearing', 'Human', 'Impairment', 'Independent Living', 'Individual Differences', 'Inferior', 'Knowledge', 'Learning', 'Left', 'Location', 'Loudness', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Music', 'Neurobiology', 'Neurodegenerative Disorders', 'Obstruction', 'Outcome', 'Parietal', 'Performance', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Probability', 'Process', 'Property', 'Reaction Time', 'Rehabilitation therapy', 'Reproduction', 'Research', 'Resources', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Site', 'Spatial Distribution', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Transcranial magnetic stimulation', 'Vision', 'Work', 'age related', 'alpha-SNAP', 'attentional bias', 'attentional control', 'base', 'behavior measurement', 'cognitive process', 'cost shifting', 'experimental study', 'fighting', 'image guided', 'indexing', 'information processing', 'interdisciplinary approach', 'nervous system disorder', 'neural correlate', 'neural stimulation', 'neuroimaging', 'neuromechanism', 'normal aging', 'prefrontal lobe', 'public health relevance', 'relating to nervous system', 'response', 'sound', 'theories', 'vector', 'vigilance']",NIDCD,UNIVERSITY OF TEXAS SAN ANTONIO,R01,2017,237742,0.018397727891417304
"Characterizing and Modeling Infants' Self-Generated Object Views: Implications for Object Recognition and Language Learning PROJECT SUMMARY/ABSTRACT Human visual object recognition is foundational to many achievements—from object name learning to tool use to real world problem solving. Understanding the developmental processes that underlie visual object recognition is of critical importance because the individual differences that characterize early visual object recognition have clinical, educational, and societal implications. For instance, toddlers with poor visual object recognition skills are more likely to have below-average vocabulary sizes. Toddlers with smaller vocabularies have a greater likelihood of developing language impairments and are more likely to lag in pre-literacy and literacy skills. Deficits in visual object recognition and word learning have also been exhibited by individuals with Autism Spectrum Disorders (ADSs). The overarching goal of the proposed project is to better understand the sensory-motor mechanisms that support visual object recognition. Considerable evidence suggests that active object manipulation relates to better visual object recognition, however little is known about the mechanisms through which object manipulation connects to visual object processing during development. The proposed research tests the hypothesis that one major route through which object manipulation matters is that it generates many different views of the same object, and that the variation within multiple visual instances of the same object facilitates visual object recognition by building more generalizable representations for recognizing unseen instances. This hypothesis is tested by (1) characterizing the properties of object information generated by infants during free play and by (2) evaluating the information in those generated visual streams by feeding them to convolutional neural networks (CNNs) – the first computational models of vision capable of human-like visual recognition. Two additional lines of research motivate the approach. First is evidence showing infants learn from statistical regularities in visual inputs presented briefly in a laboratory setting. Second is research using head-mounted cameras suggesting that object views generated by infant manipulation have unique properties, including views dominated by a single object. What we do not yet know are the visual statistics of the views infants generate in everyday toy play or their value for a statistical learner such as CNNs. The proposed research will address these gaps in the literature by characterizing the visual object inputs infants generate and how these inputs may facilitate visual object recognition. The proposed research will also determine how differences in visual inputs may be linked with individual differences in infant object name learning. This research will lead to a deeper understanding of the early development of visual object recognition, and may also provide a crucial missing link in our understanding of the developmental trajectory of other cognitive functions, including object name learning. Moreover, the knowledge to be gained from the proposed research has the potential to inform (1) individual differences in learning, (2) strategies for identifying learning delays, and (3) construction of interventions to remediate learning delays. PROJECT NARRATIVE The proposed research aims to characterize the nature of infants' early visual experiences of objects and their relation to object manipulation, language abilities, and computational models of object recognition. The period of development to be studied – 18 to 24 months – is a period in which delays in visual object recognition and in vocabulary learning have been connected to future development of language impairments and diagnoses of Autism Spectrum Disorders (ASDs). The proposed research is highly relevant to public health as it will elucidate sources of individual differences in early object recognition and word learning, laying the foundation for aiding diagnosis of early language delay and ASDs, as well as the development of future object recognition and vocabulary/language intervention programs.",Characterizing and Modeling Infants' Self-Generated Object Views: Implications for Object Recognition and Language Learning,9395459,F32HD093280,"['Achievement', 'Address', 'Biological Neural Networks', 'Characteristics', 'Clinical', 'Computer Simulation', 'Data', 'Development', 'Developmental Process', 'Diagnosis', 'Early Diagnosis', 'Exhibits', 'Foundations', 'Future', 'Gap Junctions', 'Goals', 'Head', 'Human', 'Individual', 'Individual Differences', 'Infant', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Modeling', 'Motor', 'Names', 'Nature', 'Parents', 'Persons', 'Play', 'Problem Solving', 'Property', 'Public Health', 'Recording of previous events', 'Research', 'Role', 'Route', 'Sampling', 'Sensory', 'Shapes', 'Source', 'Specific qualifier value', 'Stream', 'Testing', 'Toddler', 'Toy', 'Training', 'Variant', 'Vision', 'Visual', 'Vocabulary', 'autism spectrum disorder', 'base', 'cognitive function', 'developmental disease', 'experience', 'feeding', 'intervention program', 'language impairment', 'literacy', 'novel', 'object recognition', 'skills', 'statistics', 'tool', 'vision development', 'visual object processing', 'word learning']",NICHD,INDIANA UNIVERSITY BLOOMINGTON,F32,2017,57066,0.044746782277035095
"Learning and updating internal visual models ﻿    DESCRIPTION (provided by applicant): In line with the strategic plan of the NEI, this project is focused on filling a profound gap in our understanding of neural mechanisms of visual perception. Specifically, we aim to understand how the adaptation of visual cortical circuits contributes to perception. Adaptation is a ubiquitous process by which neural processing and perception are dramatically influenced by recent visual inputs. However, the functional purpose of adaptation is poorly understood. Based on preliminary data, this project tests the hypothesis that visual adaptation instantiates a form of predictive coding, which is used to make unexpected events salient. We posit that cortical circuits learn the statistical structure of visua input in a manner that extends beyond previous fatigue- based descriptions of adaptation effects. This learning is used to discount expected features and signal novel ones. Our project will test this hypothesis through the collaborative effort of three investigators with expertise in human EEG, animal neurophysiology, and computational modeling. Aim 1 will assess the ability of cortical circuits to adapt to temporal sequences of input and to signal deviations from expected sequences. Aim 2 will evaluate the effect of stimulus uncertainty on adaptation and responses to novel events. Aim 3 will determine how adaptation dynamics and responses to novel stimuli are influenced by the temporal constancy of stimulus statistics. Each of these aims involves an experimental manipulation that yields distinct behavior from fatigue- based and predictive coding mechanisms. Thus, together our aims will provide a robust test of our core hypothesis, and provide a much richer understanding of the adaptive properties of cortical circuits. Results from our project will contribute to answering one of the continuing puzzles in visual research, which is to understand the functional purpose of adaptive mechanisms in visual perception. PUBLIC HEALTH RELEVANCE: . This research is relevant to public health because it aims to uncover the function of visual adaptation, a fundamental aspect of visual perception. This work is thus essential to the mission of NEI because it will provide a more detailed understanding of how visual cortical circuits underlie visual perception, which is necessary for developing treatment strategies for individuals with visual processing deficits and for the development of effective prosthetic devices.",Learning and updating internal visual models,9334881,R01EY024858,"['Affect', 'Animals', 'Area', 'Autistic Disorder', 'Behavior', 'Biological', 'Brain', 'Code', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Disease', 'Electroencephalography', 'Elements', 'Environment', 'Event', 'Fatigue', 'Goals', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Machine Learning', 'Mission', 'Modeling', 'Monkeys', 'Neurons', 'Pattern', 'Perception', 'Process', 'Property', 'Prosthesis', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Scheme', 'Schizophrenia', 'Sensory', 'Signal Transduction', 'Stimulus', 'Strategic Planning', 'Structure', 'Testing', 'Time', 'Uncertainty', 'Update', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Work', 'area V4', 'area striata', 'awake', 'base', 'brain machine interface', 'cognitive neuroscience', 'computational neuroscience', 'design', 'discount', 'expectation', 'extrastriate visual cortex', 'human subject', 'improved', 'neuromechanism', 'neurophysiology', 'novel', 'phenomenological models', 'prevent', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'treatment strategy', 'visual adaptation', 'visual processing']",NEI,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2017,447745,0.041823824635546306
"Top-down control of auditory processing in the cortico-collicular network (Administrative Supplement) Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network (Administrative Supplement),9385957,R01DC014950,"['Acoustics', 'Administrative Supplement', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Disease', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Income', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Non-linear Models', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory processing', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'experimental study', 'hearing impairment', 'insight', 'nervous system disorder', 'neurophysiology', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,131801,0.03981794015607553
"Top-down control of auditory processing in the cortico-collicular network Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network,9207441,R01DC014950,"['Acoustics', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Disease', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Income', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Non-linear Models', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory processing', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'experimental study', 'hearing impairment', 'insight', 'nervous system disorder', 'neurophysiology', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,327250,0.04035745280164657
"Neural mechanisms of auditory temporal pattern perception Project Summary/Abstract: Processing acoustic communication signals is among the most difficult, yet vital capabilities that the auditory system must achieve. These abilities lie at the heart of language and speech processing, and their success or failure can have profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, as well as improving diagnoses and treatments for learning disabilities and communication disorders such as auditory processing disorder, dyslexia, and specific language impairment. While much has been learned about the loci of language-related processing using non-invasive neuroscience techniques in humans, these techniques cannot answer how individual neurons and neural circuits implement language-relevant computations. As a result, the explicit cellular circuit-level and neuro-computational mechanisms that support acoustic communication signal processing are poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language, in particular the processing of temporal patterns within communication signals. The experiments outlined in this proposal investigate the neural mechanisms of auditory temporal pattern processing. In humans, the transition statistics between adjacent speech sounds (phonemes) can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Sensitivity to transition statistics is not exclusive to speech signals however, but reflects general auditory processes shared by many animals. In Aim 1 we investigate the categorical perception of complex auditory objects in populations of cortical neurons in an animal model, and ask how these neural representations are effected by temporal context. In addition to which elements occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Studies in Aim 2 focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. In Aim 3, we propose a basic circuit in which population level representations of auditory objects could be differentially modulated by patterning rules, and test this proposed pattern processing circuit using direct, casual manipulations. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Neural mechanisms of auditory temporal pattern perception,9527903,R56DC016408,"['Acoustics', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Biological Assay', 'Biological Models', 'Birds', 'Categories', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computational Technique', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrophysiology (science)', 'Elements', 'Environment', 'Failure', 'Foundations', 'Goals', 'Heart', 'Human', 'Individual', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Nuclear', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Population Dynamics', 'Process', 'Property', 'Quality of life', 'Research', 'Role', 'Services', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Structure', 'Sturnus vulgaris', 'Superior temporal gyrus', 'System', 'Systems Development', 'Techniques', 'Testing', 'Time', 'Training', 'Transition Elements', 'Work', 'auditory processing', 'bird song', 'cognitive process', 'experimental study', 'hearing impairment', 'improved', 'language processing', 'microstimulation', 'model development', 'neural circuit', 'neural patterning', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R56,2017,363607,-0.042494634736350435
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9277595,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2017,825202,0.0403740711791051
"Post-natal development of high-level visual representation in primates View-invariant object recognition is a complex cognitive task that is critical to everyday functioning. A key neural correlate of high-level object recognition is inferior temporal (IT) cortex, a brain area present in both humans and non-human primates. Recent advances in visual systems neuroscience have begun to uncover how images are encoded in the adult IT object representation, however the learning rules by which high level visual areas (especially IT) develop remain mysterious, with both the magnitude and qualitative nature of developmental changes remaining almost completely unknown — in part because, over the last thirty years, there have been practically no studies of spiking neural responses in the higher ventral cortical areas of developing primates. There is thus a significant gap in our understanding of how visual development proceeds.  This exploratory proposal aims to characterize how representation in higher primate visual cortex changes during development. We first aim (Aim 1) to implant chronic electrode arrays to record hundreds of IT neuronal sites in response to thousands of image stimuli in awake behaving juvenile macaques. These data will comprise a snapshot of the developing primate visual representation, and will be particularly powerful because we have already extensively measured adult monkey IT using the same stimuli and methods. By comparing juvenile and adult neuronal responses at both single site and population levels, we will obtain a unprecedentedly large-scale and detailed picture of the neural correlates of high-level visual development (Aim 2).  Aims 1 and 2 are exploratory, but potentially transformative – they will result in publicly available neuronal IT development benchmarks against which any proposed model of high level visual development can be rigorously tested, and will spur the development of those models in our lab and others. In that context, we will also seek (Aim 3) to improve known semi- and un-supervised learning rules from the computer vision and computational neuroscience literature, and to compare them to both recent high-performing (but biologically implausible) supervised models as well to the rich developmental measurements obtained in Aims 1 and 2.  Establishing experimental and surgical procedures for juvenile array recordings will create the future opportunity to observe changes in high level neural visual representations while experience is manipulated in early development, and will enable experiments in other sensory, motor, or decision making domains. If successful, the proposed work will yield a deeper understanding of the principles underlying visual cortex development, understanding which will in turn be helpful for treating neurodevelopmental disorders that implicate cortical circuits, including amblyopia and autism. Project narrative  Visual object recognition is fundamental to our everyday functioning. While the brain is remarkably good at accomplishing these challenging tasks, we do not yet know how it learns this ability during development. The goal of these experiments is to develop new experimental and computational tools to discover the neural learning principles that underlie that visual ability.",Post-natal development of high-level visual representation in primates,9316254,R21EY025863,"['Adolescent', 'Adult', 'Amblyopia', 'Animals', 'Area', 'Autistic Disorder', 'Behavioral', 'Benchmarking', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Chronic', 'Collaborations', 'Complex', 'Computer Vision Systems', 'Conflict (Psychology)', 'Data', 'Data Set', 'Decision Making', 'Development', 'Electrodes', 'Exhibits', 'Eye', 'Face', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Head', 'Human', 'Image', 'Implant', 'Inferior', 'Learning', 'Literature', 'Macaca', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monkeys', 'Motivation', 'Motor', 'Nature', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Performance', 'Population', 'Primates', 'Procedures', 'Process', 'Research', 'Rewards', 'Sensory', 'Site', 'Stimulus', 'Stream', 'Supervision', 'System', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'awake', 'base', 'cognitive task', 'computational neuroscience', 'computerized tools', 'experience', 'experimental study', 'extrastriate visual cortex', 'improved', 'juvenile animal', 'learning network', 'mature animal', 'multi-electrode arrays', 'network models', 'neural correlate', 'nonhuman primate', 'novel', 'object recognition', 'postnatal', 'receptive field', 'relating to nervous system', 'response', 'statistics', 'vision development']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2017,193375,0.08851836462626217
"Cortical computations underlying binocular motion integration PROJECT SUMMARY / ABSTRACT Neuroscience is highly specialized—even visual submodalities such as motion, depth, form and color processing are often studied in isolation. One disadvantage of this isolation is that results from each subfield are not brought together to constrain common underlying neural circuitry. Yet, to understand the cortical computations that support vision, it is important to unify our fragmentary models that capture isolated insights across visual submodalities so that all relevant experimental and theoretical efforts can benefit from the most powerful and robust models that can be achieved. This proposal aims to take the first concrete step in that direction by unifying models of direction selectivity, binocular disparity selectivity and 3D motion selectivity (also known as motion-in-depth) to reveal circuits and understand computations from V1 to area MT. Motion in 3D inherently bridges visual submodalities, necessitating the integration of motion and binocular processing, and we are motivated by two recent paradigm-breaking physiological studies that have shown that area MT has a robust representation of 3D motion. In Aim 1, we will create the first unified model and understanding of the relationship between pattern and 3D motion in MT. In Aim 2, we will construct the first unified model of motion and disparity processing in MT. In Aim 3, we will develop a large-scale biologically plausible model of these selectivities that represents realistic response distributions across an MT population. Having a population output that is complete enough to represent widely-used visual stimuli will amplify our ability to link to population read-out theories and to link to results from psychophysical studies of visual perception. Key elements of our approach are (1) an iterative loop between modeling and electrophysiological experiments; (2) building a set of shared models, stimuli, data and analysis tools in a cloud-based system that unifies efforts across labs, creating opportunities for deep collaboration between labs that specialize in relevant submodalities, and encouraging all interested scientists to contribute and benefit; (3) using model-driven experiments to answer open, inter-related questions that involve motion and binocular processing, including motion opponency, spatial integration, binocular integration and the timely problem of how 3D motion is represented in area MT; (4) unifying insights from filter-based models and conceptual, i.e., non-image- computable, models to generate the first large-scale spiking hierarchical circuits that predict and explain how correlated signals and noise are transformed across multiple cortical stages to carry out essential visual computations; and (5) carrying out novel simultaneous recordings across visual areas. This research also has potential long-term benefits in medicine and technology. It will build fundamental knowledge about functional cortical circuitry that someday may be useful for interpreting dysfunctions of the cortex or for helping biomedical engineers construct devices to interface to the brain. Insights gained from the visual cortex may also help to advance computer vision technology. NARRATIVE The processing of visual motion and depth information is essential for a wide variety of important human abilities, including navigating through the world, avoiding collisions, catching and grabbing objects and interpreting complex scenes. To understand how neurons in the visual cortex transform and represent the information that underlies these abilities, we aim to initiate the development of a more complete, biologically constrained and openly available computer model of motion and depth processing that will be used to guide, and to interpret and incorporate results from, primate visual neurophysiological and psychophysical experiments. Gaining an understanding of the normal function of cortical neural circuitry is an important step in building the fundamental knowledge that someday may help to improve the ability to assess dysfunctions of the cortex and may help bioengineers create devices that interface to cortical circuitry to treat disorders and overcome disabilities.",Cortical computations underlying binocular motion integration,9380854,R01EY027023,"['Affect', 'Architecture', 'Biological', 'Biomedical Engineering', 'Brain', 'Collaborations', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disadvantaged', 'Discrimination', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Foundations', 'Frequencies', 'Functional disorder', 'Human', 'Joints', 'Knowledge', 'Link', 'Literature', 'Medicine', 'Modeling', 'Motion', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Pattern', 'Performance', 'Physiological', 'Physiology', 'Population', 'Primates', 'Production', 'Psychophysics', 'Reproducibility', 'Research', 'Role', 'Scientist', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Vision Disparity', 'Visual', 'Visual Cortex', 'Visual Motion', 'Visual Perception', 'area MT', 'base', 'cloud based', 'color processing', 'disability', 'experimental study', 'extrastriate visual cortex', 'fitness', 'improved', 'in vivo', 'insight', 'interest', 'neural circuit', 'neurophysiology', 'novel', 'relating to nervous system', 'response', 'spatial integration', 'spatiotemporal', 'theories', 'tool', 'visual neuroscience', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2017,403479,0.07242669388898451
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks. PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,9327009,R00HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Anatomy', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical center', 'Memory', 'Methods', 'Modality', 'Near-Infrared Spectroscopy', 'Neonatology', 'Neural Pathways', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'Syndrome', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'aged', 'awake', 'base', 'behavioral outcome', 'cognitive development', 'comparison group', 'developmental disease', 'early experience', 'experience', 'experimental study', 'hemodynamics', 'high risk', 'high risk population', 'infancy', 'neural correlate', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'predicting response', 'programs', 'public health relevance', 'relating to nervous system', 'response', 'sensory cortex', 'sensory input', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,PRINCETON UNIVERSITY,R00,2017,242522,0.04245675714815772
"The role of area V4 in the perception and recognition of visual objects ﻿    DESCRIPTION (provided by applicant): The human visual system parses the information that reaches our eyes into a meaningful arrangement of regions and objects. This process, called image segmentation, is one of the most challenging computations accomplished by the primate brain. To discover its neural basis we will study neuronal processes in two brain areas in the macaque monkey-V4, a fundamental stage of form processing along the occipito-temporal pathway, and the prefrontal cortex (PFC), important for executive control. Dysfunctions of both areas impair shape discrimination behavior in displays that require the identification of segmented objects, strongly suggesting that they are important for image segmentation. Our experimental techniques will include single and multielectrode recordings, behavioral manipulations, perturbation methods and computer models. In Aim 1 we will identify the neural signals that reflect segmentation in visual cortex. Using a variety of parametric stimuli with occlusion, clutter and shadows-stimulus features known to challenge segmentation in natural vision-we will evaluate whether segmentation is achieved by grouping regions with similar surface properties, such as surface color, texture and depth, or by grouping contour segments that are likely to form the boundary of an object or some interplay between these two strategies. We will test the hypothesis that contour grouping mechanisms are most effective under low clutter and close to the fovea. In Aim 2, we will investigate how feedback from PFC modulates shape responses in V4 and facilitates segmentation: we will test the longstanding hypothesis that object recognition in higher cortical stages precedes and facilitates segmentation in the midlevels of visual form processing. We will simultaneously study populations of V4 and PFC neurons while animals engage in shape discrimination behavior. We will use single-trial decoding methods and correlation analyses to relate the content and timing of neuronal responses in the two areas. To causally test the role of feedback from PFC, we will reversibly inactivate PFC by cooling and study V4 neurons. Our results will provide the first detailed, analytical models of V4 neuronal response dynamics in the presence of occlusion and clutter and advance our understanding of how complex visual scenes are processed in area V4. They will also reveal how V4 and PFC together mediate performance on a complex shape discrimination task, how executive function and midlevel vision may be coordinated during behavior and how feedback is used in cortical computation. Object recognition is impaired in visual agnosia, a dysfunction of the occipito-temporal pathway, and in dysfunctions of the PFC (e.g. schizophrenia). Results from these experiments will constitute a major advance in our understanding of the brain computations that underlie segmentation and object recognition and will bring us closer to devising strategies to alleviate and treat brain disorders in which these capacities are impaired. PUBLIC HEALTH RELEVANCE: A fundamental capacity of the primate visual system is its ability to segment visual scenes into component objects and then recognize those objects regardless of partial occlusions and clutter. Using a combination of primate neurophysiology experiments, computational modeling, animal behavior and reversible inactivation methods, we hope to achieve a new level of understanding about visual processing in the context of object recognition; these findings will ultimately bring us closer to devising strategies to alleviate and treat brain disorders of impaired object recognition resulting from dysfunctions in the occipito-temporal pathway (e.g. agnosia) and the prefrontal cortex (e.g. schizophrenia).",The role of area V4 in the perception and recognition of visual objects,9248377,R01EY018839,"['Agnosia', 'Animal Behavior', 'Animals', 'Area', 'Back', 'Behavior', 'Behavior Control', 'Behavioral', 'Brain', 'Brain Diseases', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Custom', 'Data', 'Discrimination', 'Eye', 'Feedback', 'Functional disorder', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Lesion', 'Macaca', 'Mediating', 'Methods', 'Modeling', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Play', 'Population', 'Prefrontal Cortex', 'Primates', 'Process', 'Property', 'Psychology', 'Psychophysics', 'Role', 'Schizophrenia', 'Shapes', 'Signal Transduction', 'Stimulus', 'Stream', 'Surface', 'Surface Properties', 'Techniques', 'Testing', 'Texture', 'Time', 'V4 neuron', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual system structure', 'area V4', 'awake', 'base', 'design', 'executive function', 'experimental study', 'fovea centralis', 'imaging Segmentation', 'impaired capacity', 'neurophysiology', 'neurotransmission', 'object recognition', 'public health relevance', 'relating to nervous system', 'response', 'stereoscopic', 'study population', 'visual processing']",NEI,UNIVERSITY OF WASHINGTON,R01,2017,479409,0.10865748464048915
"Active Sensation during Odor-Guided Navigation in Mice PROJECT SUMMARY We often consider our movements a result of sensory processing – sensation guides behavior. However, animals selectively shape future sensory input through their own actions in a process known as active sampling. Thus, action and sensation are inextricably linked. Despite this, much of the research done on sensory processing restricts movement, most commonly via head fixation. To access sensorimotor processing during more natural behavior, we will study olfactory navigation in freely-moving mice. The olfactory system is ideal for studying sensory sampling, because of its ethological relevance for mammalian foraging and the dynamic nature of airborne odor stimuli. The proposed research will determine the sampling strategies of olfactory search and reveal the underlying circuitry that connects sensation with motion. Aim 1. It is unknown how rodents navigate dynamic plumes of odorant towards an odor source. In this aim, we will identify, analyze, and model active sensing behaviors that occur during increasingly difficult navigation tasks and with single nostrils occluded. These experiments will test the hypothesis that olfactory navigation works as a sensorimotor closed-loop system, where animals optimize sampling behaviors for the current stimulus conditions. These behavioral studies will lay the foundation for investigations of sensorimotor processing in dynamic olfactory scenes. Aim 2. To determine how sampling movements shape sensation, we will monitor neural activity during active sensory behavior. During odor tracking, we will electrophysiologically record in the olfactory bulb, a bottleneck through which all sensory input passes. We will determine the sensory history dependence of active sampling and, in doing so, reveal part of the underlying circuitry that connects motion with sensation. These experiments will test the hypothesis that sampling movements are sensory history dependent. To our knowledge, sampling movements and sensory activity have never been simultaneously recorded during olfactory navigation. This research will advance our understanding of the interplay between sensation and motion during natural behavior. PROJECT NARRATIVE Deficits in sensory motor communication are a major contributor to prevalent neurological disorders such as schizophrenia and Parkinson's disease. Our assay of olfactory navigation will model the interaction between sensation and movement and identify the circuitry through which movements are decided by sensory input. Discovering mechanisms of sensorimotor integration are the key to a better understanding of sensory processing in these disorders, since sensation and action are inextricably linked.",Active Sensation during Odor-Guided Navigation in Mice,9470632,F31DC016799,"['Animals', 'Anterior nares', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Biological Assay', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Disease', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Foundations', 'Future', 'Genetic', 'Head', 'Implant', 'Intake', 'Intervention Studies', 'Investigation', 'Link', 'Modeling', 'Monitor', 'Motion', 'Motor', 'Movement', 'Mus', 'Nature', 'Neurons', 'Nose', 'Odors', 'Olfactory Pathways', 'Output', 'Parkinson Disease', 'Pattern', 'Perception', 'Positioning Attribute', 'Process', 'Recording of previous events', 'Research', 'Respiration', 'Rewards', 'Rodent', 'Sampling', 'Schizophrenia', 'Sensory', 'Shapes', 'Smell Perception', 'Source', 'Stereotyping', 'Stimulus', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Vertebrates', 'Vision', 'Work', 'base', 'behavioral study', 'design', 'experimental study', 'insight', 'nervous system disorder', 'olfactory bulb', 'olfactory stimulus', 'relating to nervous system', 'sample fixation', 'sensory input', 'sensory stimulus', 'sensory system', 'tool']",NIDCD,UNIVERSITY OF OREGON,F31,2017,33050,0.012621654468812209
"The role of area V4 in the perception and recognition of visual objects ﻿    DESCRIPTION (provided by applicant): The human visual system parses the information that reaches our eyes into a meaningful arrangement of regions and objects. This process, called image segmentation, is one of the most challenging computations accomplished by the primate brain. To discover its neural basis we will study neuronal processes in two brain areas in the macaque monkey-V4, a fundamental stage of form processing along the occipito-temporal pathway, and the prefrontal cortex (PFC), important for executive control. Dysfunctions of both areas impair shape discrimination behavior in displays that require the identification of segmented objects, strongly suggesting that they are important for image segmentation. Our experimental techniques will include single and multielectrode recordings, behavioral manipulations, perturbation methods and computer models. In Aim 1 we will identify the neural signals that reflect segmentation in visual cortex. Using a variety of parametric stimuli with occlusion, clutter and shadows-stimulus features known to challenge segmentation in natural vision-we will evaluate whether segmentation is achieved by grouping regions with similar surface properties, such as surface color, texture and depth, or by grouping contour segments that are likely to form the boundary of an object or some interplay between these two strategies. We will test the hypothesis that contour grouping mechanisms are most effective under low clutter and close to the fovea. In Aim 2, we will investigate how feedback from PFC modulates shape responses in V4 and facilitates segmentation: we will test the longstanding hypothesis that object recognition in higher cortical stages precedes and facilitates segmentation in the midlevels of visual form processing. We will simultaneously study populations of V4 and PFC neurons while animals engage in shape discrimination behavior. We will use single-trial decoding methods and correlation analyses to relate the content and timing of neuronal responses in the two areas. To causally test the role of feedback from PFC, we will reversibly inactivate PFC by cooling and study V4 neurons. Our results will provide the first detailed, analytical models of V4 neuronal response dynamics in the presence of occlusion and clutter and advance our understanding of how complex visual scenes are processed in area V4. They will also reveal how V4 and PFC together mediate performance on a complex shape discrimination task, how executive function and midlevel vision may be coordinated during behavior and how feedback is used in cortical computation. Object recognition is impaired in visual agnosia, a dysfunction of the occipito-temporal pathway, and in dysfunctions of the PFC (e.g. schizophrenia). Results from these experiments will constitute a major advance in our understanding of the brain computations that underlie segmentation and object recognition and will bring us closer to devising strategies to alleviate and treat brain disorders in which these capacities are impaired. PUBLIC HEALTH RELEVANCE: A fundamental capacity of the primate visual system is its ability to segment visual scenes into component objects and then recognize those objects regardless of partial occlusions and clutter. Using a combination of primate neurophysiology experiments, computational modeling, animal behavior and reversible inactivation methods, we hope to achieve a new level of understanding about visual processing in the context of object recognition; these findings will ultimately bring us closer to devising strategies to alleviate and treat brain disorders of impaired object recognition resulting from dysfunctions in the occipito-temporal pathway (e.g. agnosia) and the prefrontal cortex (e.g. schizophrenia).",The role of area V4 in the perception and recognition of visual objects,9535536,R01EY018839,"['Agnosia', 'Animal Behavior', 'Animals', 'Area', 'Back', 'Behavior', 'Behavior Control', 'Behavioral', 'Brain', 'Brain Diseases', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Custom', 'Data', 'Discrimination', 'Eye', 'Feedback', 'Functional disorder', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Lesion', 'Macaca', 'Mediating', 'Methods', 'Modeling', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Play', 'Population', 'Prefrontal Cortex', 'Primates', 'Process', 'Property', 'Psychology', 'Psychophysics', 'Role', 'Schizophrenia', 'Shapes', 'Signal Transduction', 'Stimulus', 'Stream', 'Surface', 'Surface Properties', 'Techniques', 'Testing', 'Texture', 'Time', 'V4 neuron', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual system structure', 'area V4', 'awake', 'base', 'design', 'executive function', 'experimental study', 'fovea centralis', 'imaging Segmentation', 'impaired capacity', 'neurophysiology', 'neurotransmission', 'object recognition', 'public health relevance', 'relating to nervous system', 'response', 'stereoscopic', 'study population', 'visual processing']",NEI,UNIVERSITY OF WASHINGTON,R01,2017,21050,0.10865748464048915
"Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing ﻿    DESCRIPTION (provided by applicant): The long-term goal of this research is to understand how the brain decides where we look in the real world. Many factors influence our eye movements (saccades). For instance, we are more likely to look at salient objects (i.e. those that are conspicuous), such as a bright red balloon in a blue sky. We are also more likely to look at goal-dependent objects (i.e. those that share features with our goals), such as a yellow object when searching for a banana. For several decades, researchers in computer vision have been developing models based on these factors to predict the locations to which we move our eyes. Researchers in neurobiology have also been studying saccade selection, and have suggested the frontal eye field (FEF) plays a large role, as the FEF encodes both visual features and eye movements. But because the FEF encodes both visual features and saccades, it is very difficult to parse FEF activity during natural viewing. For this reason, past experiments have primarily investigated the FEF using simple, constrained tasks with artificial stimuli. In this project, I wil use images of natural scenes, which better approximate the complexity of the real world. I will record with extracellular electrodes from the FEF of awake, behaving rhesus monkeys, while they view natural scenes. In order to determine the FEF's role in the decision of where to saccade next in natural scenes, I will investigate how the FEF encodes visual features that predict saccades. In my two aims, I will test how the FEF encodes salience (Aim 1) and goal-dependence (Aim 2). I will build a model that explains neural activity using visual features (salience and goal-dependence) along with eye movements, which are a confounding source of neural activity. This model will take advantage of computer vision and machine learning algorithms in order to look at the effects of large numbers of correlates and visual features in these natural scenes. The neural data analysis methods developed for these aims will allow researchers that study many brain areas to more easily use natural scenes. Additionally, understanding how the brain chooses where to saccade in natural scenes have important consequences for neurologic and psychiatric health and disease. Several diseases including schizophrenia, autism, and Parkinson's impair the choice of saccades. A better understanding of the link between visual features, eye movements, and FEF activity promises to increase understanding of these diseases and allow the development of novel diagnostic tools.         PUBLIC HEALTH RELEVANCE: This research aims to understand how the frontal eye field cortex helps determine where we look. In particular, it will investigate how the frontal eye field cortex encodes visual stimuli that drive eye movements, such as salient and important objects. Eye movement decisions are impaired in many diseases, including schizophrenia, autism, and Parkinson's, and this research could help lead to a greater understanding of these diseases and the development of novel diagnostic tools.                ",Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing,9087008,F31EY025532,"['Affect', 'Algorithms', 'Area', 'Autistic Disorder', 'Banana', 'Behavior', 'Brain', 'Brain region', 'Complex', 'Computer Vision Systems', 'Crowding', 'Data', 'Data Analyses', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Goals', 'Health', 'Image', 'Lead', 'Link', 'Location', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Neurobiology', 'Neurologic', 'Neurons', 'Parkinson Disease', 'Play', 'Research', 'Research Personnel', 'Role', 'Running', 'Saccades', 'Schizophrenia', 'Site', 'Source', 'Stimulus', 'Testing', 'Visual', 'Visual Pathways', 'Visual attention', 'Work', 'awake', 'base', 'design', 'experience', 'extracellular', 'frontal eye fields', 'nervous system disorder', 'neural model', 'neuromechanism', 'novel diagnostics', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'tool', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY AT CHICAGO,F31,2016,37176,0.07595208116440545
"Representation of information across the human visual cortex ﻿    DESCRIPTION (provided by applicant): The human visual system is organized as a parallel, hierarchical network, and successive stages of visual processing appear to represent increasingly complicated aspects of shape-related and semantic information. However, the way that shape-related and semantic information is represented across much of the visual hierarchy is still poorly understood. The primary goal of this proposal is to understand how information about object shape and semantic category is represented explicitly across mid- and high-level visual areas. To address this important issue we propose to undertake a series of human functional MRI (fMRI) studies, using both synthetic and natural movies. Data will be analyzed by means of a powerful voxel-wise modeling (VM) approach that has been developed in my laboratory over the past several years. In Aim 1 we propose to measure human brain activity evoked by synthetic naturalistic movies, and to use VM to evaluate and compare several competing theories of shape representation across the entire visual cortex. In Aim 2 we propose to use VM to evaluate and compare competing theories of semantic representation. In Aim 3 we propose to use machine learning and and VM to discover new aspects of shape and semantic representation. These experiments will provide fundamental new insights about the representation of visual information across visual cortex. PUBLIC HEALTH RELEVANCE: Disorders of central vision can severely affect quality of life and the design of treatments and devices for improving visual function will depend critically on understanding the organization of visual cortex. We propose to use functional MRI and sophisticated computational data analysis and modeling procedures to evaluate and compare multiple theories of visual function. The results will reveal how visual information is represented across the several dozen distinct functional areas that constitute human visual cortex.",Representation of information across the human visual cortex,9040948,R01EY019684,"['Address', 'Affect', 'Area', 'Award', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disease', 'Elements', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Health', 'Human', 'Image', 'Individual', 'Laboratories', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motion', 'Perception', 'Procedures', 'Quality of life', 'Semantics', 'Series', 'Shapes', 'Space Perception', 'Staging', 'Surface', 'System', 'Testing', 'Training', 'V2 neuron', 'V4 neuron', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'abstracting', 'area V1', 'area striata', 'base', 'data modeling', 'design', 'extrastriate visual cortex', 'improved', 'innovation', 'insight', 'learning strategy', 'movie', 'novel', 'object recognition', 'object shape', 'receptive field', 'research study', 'theories', 'therapy design', 'visual information', 'visual neuroscience', 'visual process', 'visual processing']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2016,379313,0.09263354429713333
"Neural representation of the geometry and functionality in a scene ﻿    DESCRIPTION (provided by applicant):  The goal of the proposed research is to investigate how the brain represents scene geometry and functionality. Recognizing the visual environment is central to our daily interactions with the world. When we walk into a new space, we rapidly recognize whether there is a path to follow, whether there are crossable boundaries, and whether there are obstacles that block our view and potential navigation. The theoretical framework of this proposal is based on evidence that there are distinct but complementary levels of scene representation across a group of scene-selective regions in the brain (Park et al., 2011; Park et al., 2014; Park & Chun, 2009; Park, Chun, & Johnson, 2010; Park, Intraub, Yi, Widders, & Chun, 2007). The PI proposes that scene geometry (e.g., spatial layout, three-dimensional scene boundary) and functionality (e.g., navigability, limitations of a boundary) are two fundamental scene properties represented in these regions. Specific Aims: Aim 1 investigates whether the brain displays acute sensitivity to the presence of vertical boundaries, and how such sensitivity is modulated by the functional impediment that a boundary presents to the viewer's potential navigation. Aim 2 investigates the neural representation of the scene navigability, and how this representation differs from representation of scene geometry. Aim 3 investigates whether the neural representation of real world scenes is modulated by acquired knowledge about the spatio-temporal context of a scene, which are important for functionality of a scene. Throughout her aims, the PI tests medial temporal lobe regions in human adults that process scene and spatial information: with particular focus on anterior and posterior parahippocampal gyri and retrosplenial cortex. Methods include univariate and multi-voxel fMRI pattern analyses (linear support vector machine classification and representational similarity analysis) in combination with both region-of-interest (ROI) based and whole-brain based (search light) approaches. Hypothesis and preliminary results throughout the proposal suggest that scene geometry is represented in the parahippocampal gyrus, while scene functionality is represented in the retrosplenial cortex.          PUBLIC HEALTH RELEVANCE: The research program will establish new framework for understanding the cognitive neuroscience architecture of scene perception, with the aim of unraveling how the human brain analyzes the geometry and functionality of visual environment in order to guide our actions and navigation in the world.            ",Neural representation of the geometry and functionality in a scene,9006938,R01EY026042,"['4 year old', 'Acute', 'Adult', 'Anterior', 'Architecture', 'Area', 'Base of the Brain', 'Behavioral', 'Brain', 'Categories', 'Cells', 'Characteristics', 'Child', 'Classification', 'Complement', 'Complex', 'Confusion', 'Development', 'Environment', 'Fishes', 'Floor', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Height', 'Human', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Light', 'Machine Learning', 'Medial', 'Methods', 'Modeling', 'Movement', 'Multivariate Analysis', 'Nature', 'Neurologic', 'Parahippocampal Gyrus', 'Patients', 'Pattern', 'Perception', 'Process', 'Property', 'Rattus', 'Research', 'Rodent', 'Semantics', 'Shapes', 'Temporal Lobe', 'Testing', 'Time', 'Visual', 'Visuospatial', 'Walking', 'Work', 'base', 'cognitive neuroscience', 'extrastriate visual cortex', 'interest', 'neuroimaging', 'neurophysiology', 'novel', 'programs', 'public health relevance', 'rehabilitation strategy', 'relating to nervous system', 'research study', 'vector']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2016,366529,0.060291664431889665
"The neural workings of self-initiated and quasi-automatic movements ﻿    DESCRIPTION (provided by applicant): Uncovering the principles behind the generation of voluntary movements is a necessary first step in the development of technologies and treatments aimed at restoring motor abilities lost to neurological disease or trauma. The aim of this project is to shed light on the neural mechanisms of voluntary movement initiation. An essential component of voluntary movement is the choice of when to act. Under normal circumstances this decision can be time consuming usually taking up to a few hundreds of milliseconds, longer that the known delays in the nervous system. The area of the brain most associated with generating movements, the motor cortex, becomes very active just before and during the movement, however what exactly is happening during this time is still not well understood. Indeed, while much is known about the neural basis of generating movements, several open questions remain: does a movement generated deliberately with no time pressure, like a reach made to grab an object from a table, share the same neural underpinnings with a very fast reach to catch a falling object? Will the motor cortex be just as active before a quasi-automatic reach when time is of the essence? Or is pre-movement activity only present when there is enough time to deliberately plan the movement? During movement itself, is motor cortex involved in generating quasi-automatic reaches or is there is some reflex mechanism that bypasses motor cortex to generate urgent reaches? To begin answering these questions we have trained two monkeys to initiate a reach under three very different circumstances: sometimes monkeys move at a time of their own choosing with no imposed time constraints, other times monkeys must intercept a rapidly moving target on a screen, which elicits very short-latency reaches. In yet another set of trials monkeys must withhold a reach until given a go cue. The first aim of this project is to determine if these three movements (self-initiated, quasi-automatic and cue-initiated) share a common neural mechanism that does not depend on how the movement is initiated. To do this we will record the responses from a number of neurons in two key regions of the motor cortex: the primary motor and dorsal premotor cortex. In order to understand and interpret these responses, we will employ cutting edge machine learning techniques that will allow us to visualize and quantify the how neural activity evolves in time. Being able to visualize the evolution of neural activity is a key component in understanding the principles that govern how the neural activity translates to movement. The second aim of this project is to elucidate the role that higher cortical areas play in the generation of voluntar movements. We will record neural activity from areas upstream of motor cortex (supplementary motor area), which is heavily interconnected with the motor cortex and is suspected to play crucial a role in determining when a movement should be initiated. We will test record neural activity from this area and characterize its properties using the same cutting edge techniques developed in the first part of this project.         PUBLIC HEALTH RELEVANCE: Uncovering the principles behind the generation of voluntary movements is a necessary first step in the development of technologies and treatments aimed at restoring motor abilities lost to neurological disease or trauma. Arguably, one of the fundamental features of voluntary movement is that one chooses when to move. The main goal of the proposed project is to shed light on the neural mechanisms responsible for voluntary movement initiation.                ",The neural workings of self-initiated and quasi-automatic movements,9148079,F32NS092350,"['Area', 'Behavioral', 'Brain', 'Bypass', 'Cues', 'Data', 'Dependence', 'Dorsal', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Goals', 'Intercept', 'Life', 'Light', 'Link', 'Machine Learning', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Nervous system structure', 'Neurons', 'Pattern', 'Play', 'Population', 'Population Dynamics', 'Preparation', 'Process', 'Property', 'Property Rights', 'Reflex action', 'Role', 'Signal Transduction', 'Source', 'Staging', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'base', 'falls', 'grasp', 'millisecond', 'motor control', 'nervous system disorder', 'neuromechanism', 'pressure', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2016,21140,-0.016003818636046722
"Thalamic and Cortical Mechanisms of Itch ﻿    DESCRIPTION (provided by applicant): Itch is a common clinical problem that is often difficult to treat. There is currently little understanding of the mechanism used in the CNS to produce itch and this likely contributes to the inability to treat itch. In recent years it have become cler that information related to itch is carried in the periphery and spinal cord by neurons that are also activated by noxious stimuli. This suggests that information necessary for the production of itch in the brain must be extracted from the responses of polysensory neurons in a process called decoding. The proposed studies, will for the first time, use single unit electrophysiologica techniques to determine the areas in the thalamus and cortex where processing of pruriceptive information occurs. The responses of single neurons in the thalamus to various itch-and pain-producing stimuli will be determined. The cortical areas to which pruriceptive thalamic neurons project will be determined using antidromic activation methods. In addition, responses of individual cortical neurons to pruritogens and pain-producing stimuli will be determined. The proposed studies will determine the thalamic nuclei and cortical areas in which processing of information related to itch and pain occur. In addition, using a Machine Learning approach, we will determine the contributions of the intensity and pattern of action potentials within responses to differential coding of itch and pain related responses. The proposed studies will considerably expand our understanding of the CNS mechanisms that produce itch and pain.        RELEVANCE: Very little is known about the neural systems in the thalamus and cerebral cortex that underlie production of the sensation of itch. This lack of understanding likely contributes to the paucity of effective treatments for the majority of types of chronic itch. The proposed studies will determine the areas in the thalamus and cortex in which single neurons process and transmit information about itch and pain. Project Narrative/Relevance Very little is known about the neural systems in the thalamus and cerebral cortex that underlie production of the sensation of itch. This lack of understanding likely contributes to the paucity of effective treatments for the majority of types of chronic itch. The proposed studies will determine the areas in the thalamus and cortex in which single neurons process and transmit information about itch and pain.",Thalamic and Cortical Mechanisms of Itch,9066811,R01NS089647,"['Action Potentials', 'Address', 'Affective', 'Amygdaloid structure', 'Anterior', 'Anxiety', 'Area', 'Attention', 'Axon', 'Brain', 'Cell Nucleus', 'Cells', 'Cerebral cortex', 'Characteristics', 'Clinical', 'Code', 'Complex', 'Data', 'Dimensions', 'Electrophysiology (science)', 'Esthesia', 'Feeling suicidal', 'Frequencies', 'Goals', 'Image', 'Individual', 'Insula of Reil', 'Machine Learning', 'Mechanics', 'Medial', 'Mental Depression', 'Methods', 'Molecular', 'Neurons', 'Nociception', 'Nociceptive Stimulus', 'Pain', 'Pattern', 'Population', 'Prevalence', 'Process', 'Production', 'Prosencephalon', 'Pruritus', 'Rattus', 'Sensory', 'Spinal Cord', 'Spinothalamic Tracts', 'Stimulus', 'System', 'Systemic disease', 'TRP channel', 'Techniques', 'Thalamic Nuclei', 'Thalamic structure', 'Time', 'Ventral Posterior Nucleus', 'chronic itch', 'cingulate gyrus', 'effective therapy', 'experience', 'improved', 'information processing', 'relating to nervous system', 'response', 'skin disorder', 'spinal tract', 'time use']",NINDS,UNIVERSITY OF MINNESOTA,R01,2016,332500,-0.06337949059895838
"Spontaneous activity in gustatory cortex DESCRIPTION (provided by applicant): The PI is a faculty member of the Department of Neurobiology and Behavior at Stony Brook. His research focuses on spontaneous and evoked neural activity in the gustatory cortex. The candidate recently transitioned to neuroscience from a theoretical physics background. This award will provide the necessary five-year protected period for the candidate to receive training in systems and theoretical neuroscience and electrophysiological techniques, under the supervision of the proposed mentorship committee. By the end of the termed period, the candidate will achieve his long term career goals of successfully applying for independent research funding and becoming an independent investigator in the field of theoretical neuroscience. The goal of the proposed research plan is elucidating the relation between spontaneous and evoked activity in the gustatory cortex, and its modulation by anticipatory cues. Spontaneous neural activity in sensory cortices, traditionally regarded as a noisy baseline, is increasingly drawing attention: it can predict trial to trial variability; it contains information on the functional architecture of neural networks; and it was characterized as either a ""repertoire"" of possible network activities or a storage of expectations of sensory stimuli, shaped by development. In the context of taste processing, however, it has received little to no attention. The aim of this proposal is to elucidate the properties of spontaneous activity in the gustatory cortex. This is an ideal system, due to the rich temporal dynamics of responses to taste stimuli, represented in terms of taste-specific sequences of patterns of activity, synchronized across the whole neural population. The first goal of the proposed plan is to employ state-of-the-art machine learning techniques to elucidate the features of spontaneous activity in relation to evoked activity. This will provide new analytical tools for the characterization of spontaneous activity and reconcile within a single framework the different views currently held in the literature, by introducing the new feature of temporal dynamics. As a second goal of the proposed project, the role played by anticipatory cues in modulating the relation between spontaneous and evoked activity will be elucidated, and the dependence of reaction times on spontaneous activity will be clarified. A biologically plausible model of spontaneous activity in the gustatory cortex will be introduced, based on networks of spiking neurons. This model will yield a mechanistic understanding of the feature of spontaneous activity as revealed by the analysis of electrophysiological data. PUBLIC HEALTH RELEVANCE: The proposed research is designed to uncover the dynamical features of spontaneous neural activity in the gustatory cortex and to elucidate its role in modulating the processing of taste---related information under different behavioral contexts. The relation between spontaneous and stimulus---evoked activities is the active subject of debate in the neuroscience literature; this project will develop novel analytical and modeling tools aimed at clarifying the extent to which spontaneous and evoked activity are intertwined. The results of this effort will provide a new perspective on the cortical mechanism underlying taste processing in normal conditions, and bears important implications on issues related to public health, such as the role played by attention in food consumption disorders.",Spontaneous activity in gustatory cortex,9089992,K25DC013557,"['Amygdaloid structure', 'Architecture', 'Attention', 'Award', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Cell Nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Evolution', 'Faculty', 'Funding', 'Goals', 'Health', 'Length', 'Link', 'Literature', 'Machine Learning', 'Mental Health', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Pattern', 'Physics', 'Play', 'Population', 'Property', 'Public Health', 'Randomized', 'Rattus', 'Reaction Time', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Speed', 'Stimulus', 'Study Subject', 'Supervision', 'System', 'Taste Perception', 'Techniques', 'Testing', 'Thalamic structure', 'Training', 'Ursidae Family', 'Vertebrates', 'analytical tool', 'awake', 'base', 'career', 'design', 'dynamic system', 'expectation', 'food consumption', 'markov model', 'member', 'millisecond', 'neural correlate', 'novel', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory stimulus', 'stem', 'taste stimuli', 'tool']",NIDCD,STATE UNIVERSITY NEW YORK STONY BROOK,K25,2016,167410,0.006428141278598198
"The behavioral functions of upper and lower cortical layers PROJECT SUMMARY/ABSTRACT  The cerebral cortex mediates all of human and animal cognition, encompassing a diverse set of abilities including sensation, perception, decision making, and motor planning. Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders. A major obstacle both to understanding normal behaving and to treating pathology is the high degree of complexity of cortical circuitry, which has remained largely enigmatic. The conventional view of neocortex has been that sensory processing begins in layer 4 (L4), which was identified a century ago as the principal target of thalamic axons carrying information from our sensory organs. Sensory transforms are widely believed to occur as excitation spreads serially along the densest axonal pathways (thalamus→L4→L2/3→L5/6). Recently we discovered that the cerebral cortex, rather than being a monolithic structure, may contain two entirely separate processing systems, activated by the same signals arising from the thalamus. L4 is thus not an obligatory distribution hub for cortical activity, and thalamus activates two distinct “strata” of cortex in parallel.  This proposal's goal is to identify the behavioral and computational roles of the upper (L2-4) and lower strata (L5/6) as well as the interactions between them. We will investigate the behavioral roles of these layers in the mouse whisker system. Specific layers will be optogenetically disrupted in a series of tactile behavioral tasks, in which task complexity is progressively increased. Interlaminar interactions will also be studied by recording electrophysiologically from specific layers during behavior and using novel machine learning techniques designed to identify the type of computation performed in different levels of “deep networks”. The dimensionality of the representation in a layer will be estimated under normal behaviors and when specific layers are inactivated.  Identifying fundamental functions of upper versus cortical layers will likely pave the way for future studies in other neocortical systems and in higher-order species. Moreover, as the different layers contain molecularly and biophysically distinct cell types and project to distinct downstream targets, specific neurological disorders may involve dysfunction of specific pathways, cell types, and layers. Establishing the behavioral and computational roles of these elements may contribute to development of targeted therapies. PROJECT NARRATIVE  Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders, but the behavioral and functional roles of cortical layers and cell types are unknown. Identifying the contributions of specific cortical layers to normal circuit function will lead to better treatment of pathological conditions.     ",The behavioral functions of upper and lower cortical layers,9185649,R01NS094659,"['Animals', 'Area', 'Auditory', 'Axon', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Cerebral cortex', 'Cognition', 'Complex', 'Corpus striatum structure', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Discrimination', 'Electrophysiology (science)', 'Elements', 'Esthesia', 'Functional disorder', 'Future', 'Goals', 'Halorhodopsins', 'Human', 'Individual', 'Lead', 'Machine Learning', 'Measures', 'Mediating', 'Mental disorders', 'Modality', 'Motor', 'Mus', 'Neocortex', 'Neurons', 'Organ', 'Output', 'Pathology', 'Pathway interactions', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Role', 'Sensory', 'Sensory Physiology', 'Sensory Process', 'Series', 'Shapes', 'Signal Transduction', 'Source', 'Spinal Cord', 'Stimulus', 'Structure', 'Synapses', 'System', 'Tactile', 'Task Performances', 'Techniques', 'Testing', 'Texture', 'Thalamic structure', 'Training', 'Vibrissae', 'Work', 'cell type', 'design', 'driving behavior', 'expectation', 'hippocampal pyramidal neuron', 'neocortical', 'nervous system disorder', 'novel', 'object shape', 'optogenetics', 'response', 'sensory discrimination', 'sensory input', 'spatial integration', 'targeted treatment']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2016,350000,0.014565273175048058
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9090040,R01DC015138,"['Accounting', 'Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory area', 'Auditory system', 'Behavior', 'Biomedical Engineering', 'Brain', 'Cataloging', 'Catalogs', 'Categories', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Devices', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing', 'Human', 'Individual', 'Inferior Colliculus', 'Internships', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Neurosciences', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Process', 'Prosthesis', 'Psychology', 'Reading', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'Work', 'awake', 'base', 'computational neuroscience', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'novel', 'novel strategies', 'online repository', 'programs', 'relating to nervous system', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2016,293470,0.027344315610890037
"Neural mechanisms of attentional priority for visual features and objects DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions. Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.",Neural mechanisms of attentional priority for visual features and objects,9099855,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'support network', 'sustained attention', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2016,368557,0.06262221066995347
"Crossmodal Correspondences Between Visual and Auditory Features ﻿    DESCRIPTION (provided by applicant): We live in a multisensory world, in which stimuli of various types constantly compete for our attention. Information about objects or events typically appears on more than one sensory channel, so that integrating inputs across sensory systems (e.g. vision and hearing) can enhance the signal-to-noise ratio and lead to more efficient perception and action. There is increasing interest in studying how stimulus properties in one sensory modality (e.g. vision) correspond to those in another modality (e.g. hearing). For instance, sounds of high pitch are linked to small-sized visual objects whereas sounds of low pitch are linked with large objects; sounds of high/low pitch are associated with, respectively, visual stimuli of high/low elevation; and even aspects of linguistic stimuli such as vowel quality are associated with visual properties such as object size. Such crossmodal correspondences are important factors in multisensory binding. While information has exploded on the kinds of stimulus features that are reliably associated by human observers across modalities, currently there is little neural evidence to allow a mechanistic account of how crossmodal correspondences arise, or how they relate to synesthesia, a phenomenon in which some individuals experience unusual percepts (e.g. colors) triggered by particular stimuli (e.g. letters. Our goal is to address these important gaps in knowledge, by using functional magnetic resonance imaging (fMRI) in humans to investigate the neural mechanisms underlying crossmodal and synesthetic correspondences and thus to distinguish between alternative explanations that have been offered. A number of possible mechanisms have been entertained for crossmodal correspondences. These include: Hypothesis A - learned associations due to statistical co-occurrences, which would predict that the correspondences are based in multisensory or even classic unisensory regions; Hypothesis B - semantic mediation (e.g. the common word ""high"" may mediate the link between high pitch and high elevation); and Hypothesis C - conceptual linking via a high-level property such as magnitude. In a series of eight experiments that comprise three Specific Aims, we propose to examine these competing accounts, recognizing that some or all of them may be operative, and that the mechanisms may vary between different types of crossmodal correspondences. PUBLIC HEALTH RELEVANCE: The proposed systematic study of the brain basis of correspondences between stimulus properties across sensory systems will allow critical insights into the multisensory processing involved in perception and action, illuminate the multisensory basis of language and music, and expand understanding of the phenomenon of synesthesia in relation to normal experience. From a practical standpoint, the proposed work will make significant contributions to the design of sensory substitution approaches for people with visual, auditory and other sensory deficits, and the rehabilitation of individuals with multisensory processing abnormalities, including developmental (autism, dyslexia), neurological (neglect) and psychiatric (schizophrenia) disorders.",Crossmodal Correspondences Between Visual and Auditory Features,9137687,R01EY025978,"['Accounting', 'Address', 'Association Learning', 'Attention', 'Auditory', 'Auditory pitch', 'Autistic Disorder', 'Base of the Brain', 'Behavioral', 'Binding', 'Color', 'Data', 'Development', 'Dimensions', 'Disease', 'Dyslexia', 'Event', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Hearing', 'Human', 'Individual', 'Judgment', 'Knowledge', 'Language', 'Lead', 'Letters', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Modality', 'Multivariate Analysis', 'Music', 'Neurologic', 'Noise', 'Pattern', 'Perception', 'Process', 'Property', 'Regression Analysis', 'Rehabilitation therapy', 'Research Personnel', 'Rest', 'Schizophrenia', 'Semantics', 'Sensory', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Time', 'Vision', 'Visual', 'Work', 'base', 'design', 'experience', 'insight', 'interest', 'multisensory', 'neglect', 'neuroimaging', 'neuromechanism', 'relating to nervous system', 'research study', 'sensory system', 'sound', 'vector', 'visual stimulus']",NEI,EMORY UNIVERSITY,R01,2016,565302,0.08868752373461206
"Learning and updating internal visual models ﻿    DESCRIPTION (provided by applicant): In line with the strategic plan of the NEI, this project is focused on filling a profound gap in our understanding of neural mechanisms of visual perception. Specifically, we aim to understand how the adaptation of visual cortical circuits contributes to perception. Adaptation is a ubiquitous process by which neural processing and perception are dramatically influenced by recent visual inputs. However, the functional purpose of adaptation is poorly understood. Based on preliminary data, this project tests the hypothesis that visual adaptation instantiates a form of predictive coding, which is used to make unexpected events salient. We posit that cortical circuits learn the statistical structure of visua input in a manner that extends beyond previous fatigue- based descriptions of adaptation effects. This learning is used to discount expected features and signal novel ones. Our project will test this hypothesis through the collaborative effort of three investigators with expertise in human EEG, animal neurophysiology, and computational modeling. Aim 1 will assess the ability of cortical circuits to adapt to temporal sequences of input and to signal deviations from expected sequences. Aim 2 will evaluate the effect of stimulus uncertainty on adaptation and responses to novel events. Aim 3 will determine how adaptation dynamics and responses to novel stimuli are influenced by the temporal constancy of stimulus statistics. Each of these aims involves an experimental manipulation that yields distinct behavior from fatigue- based and predictive coding mechanisms. Thus, together our aims will provide a robust test of our core hypothesis, and provide a much richer understanding of the adaptive properties of cortical circuits. Results from our project will contribute to answering one of the continuing puzzles in visual research, which is to understand the functional purpose of adaptive mechanisms in visual perception. PUBLIC HEALTH RELEVANCE: . This research is relevant to public health because it aims to uncover the function of visual adaptation, a fundamental aspect of visual perception. This work is thus essential to the mission of NEI because it will provide a more detailed understanding of how visual cortical circuits underlie visual perception, which is necessary for developing treatment strategies for individuals with visual processing deficits and for the development of effective prosthetic devices.",Learning and updating internal visual models,9147600,R01EY024858,"['Affect', 'Animals', 'Area', 'Autistic Disorder', 'Behavior', 'Biological', 'Brain', 'Code', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Disease', 'Electroencephalography', 'Elements', 'Environment', 'Event', 'Fatigue', 'Goals', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Machine Learning', 'Mission', 'Modeling', 'Monkeys', 'Neurons', 'Pattern', 'Perception', 'Process', 'Property', 'Prosthesis', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Scheme', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Signal Transduction', 'Stimulus', 'Strategic Planning', 'Structure', 'Testing', 'Time', 'Uncertainty', 'Update', 'Visual', 'Visual Cortex', 'Visual Perception', 'Work', 'area V4', 'area striata', 'awake', 'base', 'brain machine interface', 'cognitive neuroscience', 'computational neuroscience', 'design', 'discount', 'expectation', 'extrastriate visual cortex', 'human subject', 'improved', 'meetings', 'neuromechanism', 'neurophysiology', 'novel', 'phenomenological models', 'prevent', 'relating to nervous system', 'response', 'statistics', 'treatment strategy', 'visual adaptation', 'visual process', 'visual processing']",NEI,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2016,561513,0.041823824635546306
"Crowd coding in the brain:3D imaging and control of collective neuronal dynamics ﻿    DESCRIPTION (provided by applicant): The cortex is a laminated structure that is thought to underlie sequential information processing. Sensory input enters layer 4 (L4) from which activity quickly spreads to superficial layers 2/3 (L2/3) and deep layers 5/6 (L5/6) and other cortical areas eventually leading to appropriate motor responses. Sensory responses themselves depend on ongoing, i.e. spontaneous cortical activity, usually in the form of reverberating activit from within or distant cortical regions, as well as the state and behavioral context of the animal. Receptive field properties of neurons can rapidly and adaptively be reshaped when an animal is engaged in a behavioral task, indicating that encoding of stimuli is dependent on task- or context-dependent state. Responses also depend on ongoing cortical dynamics in a lamina-dependent fashion and differ between the awake and anesthetized state. The intricate neuronal interplay between behavioral context, ongoing activity, and sensory stimulus underlying cortical representations is unknown.  Specifically, we do not know how neuronal circuits shape these emergent dynamics within and between laminae, and we do not know which neurons encode which aspect of a sensory stimulus. One shortcoming of all prior studies of sensory processing is that only a few neurons are sampled, and thus information about the interactions between neurons, and between neuron and global brain state is lacking.  Here we address these challenges by developing new in vivo 2-photon imaging technology that allows rapid imaging and stimulation in multiple focal planes and new computational and information theoretic techniques to extract network dynamics at the single neuron and population level. These measures go beyond paired measures and take synergistic interactions between neurons into account. We use these new techniques to investigate the 3D single cell and population activity patterns in the auditory cortex in mice. We investigate the influence of single neurons relative to the synergistic influence of specific groups of neurons (the crowd) on network dynamics and ultimately behavior of the animal. PUBLIC HEALTH RELEVANCE: Functioning of the normal, healthy brain, such as in sensory processing and motor actions, depends on the precise interactions of millions of nerve cells.  Brain diseases are increasingly linked to changes in these complex interactions between large populations of nerve cells.   The current project develops novel imaging tools and analysis concepts to simultaneously study large groups of nerve cells in the awake brain with high temporal and cellular resolution, and will lay the groundwork for deeper insights into how the brain processes information and may provide mechanistic insights into brain disorders such as cerebral palsy, epilepsy, autism, and schizophrenia.",Crowd coding in the brain:3D imaging and control of collective neuronal dynamics,9118355,U01NS090569,"['Accounting', 'Action Potentials', 'Address', 'Algorithms', 'Animal Behavior', 'Animals', 'Area', 'Auditory area', 'Autistic Disorder', 'Behavioral', 'Binding', 'Brain', 'Brain Diseases', 'Cells', 'Cerebral Palsy', 'Cerebral cortex', 'Code', 'Communication', 'Complex', 'Crowding', 'Decision Making', 'Disease', 'Distant', 'Engineering', 'Epilepsy', 'Functional disorder', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Individual', 'Language', 'Light', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microscope', 'Monitor', 'Motor', 'Mus', 'Neurons', 'Outcome Study', 'Pathology', 'Pattern', 'Physiological', 'Population', 'Population Dynamics', 'Population Process', 'Process', 'Property', 'Publishing', 'Research', 'Resolution', 'Rest', 'Sampling', 'Scanning', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Use of New Techniques', 'Work', 'analytical tool', 'auditory discrimination', 'awake', 'base', 'behavioral outcome', 'cell type', 'density', 'graph theory', 'in vivo', 'information processing', 'insight', 'millisecond', 'neuronal circuitry', 'novel', 'receptive field', 'response', 'sensory input', 'sensory stimulus', 'spatiotemporal', 'temporal measurement', 'tool', 'two-photon']",NINDS,"UNIV OF MARYLAND, COLLEGE PARK",U01,2016,75000,-0.00746910052272644
"Crowd coding in the brain:3D imaging and control of collective neuronal dynamics ﻿    DESCRIPTION (provided by applicant): The cortex is a laminated structure that is thought to underlie sequential information processing. Sensory input enters layer 4 (L4) from which activity quickly spreads to superficial layers 2/3 (L2/3) and deep layers 5/6 (L5/6) and other cortical areas eventually leading to appropriate motor responses. Sensory responses themselves depend on ongoing, i.e. spontaneous cortical activity, usually in the form of reverberating activit from within or distant cortical regions, as well as the state and behavioral context of the animal. Receptive field properties of neurons can rapidly and adaptively be reshaped when an animal is engaged in a behavioral task, indicating that encoding of stimuli is dependent on task- or context-dependent state. Responses also depend on ongoing cortical dynamics in a lamina-dependent fashion and differ between the awake and anesthetized state. The intricate neuronal interplay between behavioral context, ongoing activity, and sensory stimulus underlying cortical representations is unknown.  Specifically, we do not know how neuronal circuits shape these emergent dynamics within and between laminae, and we do not know which neurons encode which aspect of a sensory stimulus. One shortcoming of all prior studies of sensory processing is that only a few neurons are sampled, and thus information about the interactions between neurons, and between neuron and global brain state is lacking.  Here we address these challenges by developing new in vivo 2-photon imaging technology that allows rapid imaging and stimulation in multiple focal planes and new computational and information theoretic techniques to extract network dynamics at the single neuron and population level. These measures go beyond paired measures and take synergistic interactions between neurons into account. We use these new techniques to investigate the 3D single cell and population activity patterns in the auditory cortex in mice. We investigate the influence of single neurons relative to the synergistic influence of specific groups of neurons (the crowd) on network dynamics and ultimately behavior of the animal. PUBLIC HEALTH RELEVANCE: Functioning of the normal, healthy brain, such as in sensory processing and motor actions, depends on the precise interactions of millions of nerve cells.  Brain diseases are increasingly linked to changes in these complex interactions between large populations of nerve cells.   The current project develops novel imaging tools and analysis concepts to simultaneously study large groups of nerve cells in the awake brain with high temporal and cellular resolution, and will lay the groundwork for deeper insights into how the brain processes information and may provide mechanistic insights into brain disorders such as cerebral palsy, epilepsy, autism, and schizophrenia.",Crowd coding in the brain:3D imaging and control of collective neuronal dynamics,9268816,U01NS090569,"['Accounting', 'Action Potentials', 'Address', 'Algorithms', 'Animal Behavior', 'Animals', 'Area', 'Auditory area', 'Autistic Disorder', 'Behavioral', 'Binding', 'Brain', 'Brain Diseases', 'Cells', 'Cerebral Palsy', 'Cerebral cortex', 'Code', 'Communication', 'Complex', 'Crowding', 'Decision Making', 'Disease', 'Distant', 'Engineering', 'Epilepsy', 'Functional disorder', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Individual', 'Language', 'Light', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microscope', 'Monitor', 'Motor', 'Mus', 'Neurons', 'Outcome Study', 'Pathology', 'Pattern', 'Physiological', 'Population', 'Population Dynamics', 'Population Process', 'Process', 'Property', 'Publishing', 'Research', 'Resolution', 'Rest', 'Sampling', 'Scanning', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Use of New Techniques', 'Work', 'analytical tool', 'auditory discrimination', 'awake', 'base', 'behavioral outcome', 'cell type', 'density', 'graph theory', 'in vivo', 'information processing', 'insight', 'millisecond', 'neuronal circuitry', 'novel', 'receptive field', 'response', 'sensory input', 'sensory stimulus', 'spatiotemporal', 'temporal measurement', 'tool', 'two-photon']",NINDS,"UNIV OF MARYLAND, COLLEGE PARK",U01,2016,152000,-0.00746910052272644
"Top-down control of auditory processing in the cortico-collicular network Project Summary Throughout life, humans and other animals learn statistical regularities in the acoustic environment and adapt their hearing to emphasize the elements of sound that are important for behavioral decisions. Using these abilities, normal-hearing humans are able to perceive important sounds in crowded noisy environments and understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings, even when sound is amplified above perceptual threshold. This study seeks to characterize how two major areas in the brain's auditory network, auditory cortex and midbrain inferior colliculus, establish an interface between incoming auditory signals and the internal brain states that select information appropriate to the current behavioral context. Single-unit neural activity will be recorded from both of these brain areas in awake ferrets during the presentation of complex naturalistic sounds that mimic the acoustic environment encountered in the real world. Internal brain state will be controlled by selective attention to specific sound features in these complex stimuli. Changes in stimulus-evoked neural activity as attention shifts among sound features will be measured to identify interactions between internal state and incoming sensory signals in these different areas. Previous work has identified a large corticofugal projection from auditory cortex to inferior colliculus that could produce task-dependent changes in selectivity in inferior colliculus. This study will test the role of these corticofugal projections by optogenetic inactivation of auditory cortex during recordings from inferior colliculus. Selective inactivation of specific pathways will characterize how the network of brain areas works together to produce effective auditory behaviors. Computational modeling tools will be used to determine, from an algorithmic perspective, how neurons encode information about the natural stimuli and how this encoding changes as attention is shifted between features. Data collected during behavior will be used to develop models that combine bottom-up sensory processing and top-down behavioral control. This computational approach builds on classic characterizations of neural stimulus-response relationships using spectro-temporal receptive field models. New models will be developed that incorporate behavioral state variables and nonlinear biological circuit elements into established model frameworks. Together, these studies will provide new insight into the computational strategies used by the behaving brain to process complex sounds in real-world contexts. Project Narrative Patients with hearing impairments and central neurological disorders have difficulty processing and making accurate judgments about auditory stimuli, particular in challenging noisy environments. We seek to understand how the healthy brain learns to extract useful information from sounds in order to guide effective behavior. These experiments will provide novel insight into how the brain solves problems that can be used to develop new devices and treatments for these debilitating conditions.",Top-down control of auditory processing in the cortico-collicular network,9005185,R01DC014950,"['Accounting', 'Acoustics', 'Algorithms', 'Animals', 'Area', 'Attention', 'Auditory', 'Auditory area', 'Auditory system', 'Auricular prosthesis', 'Behavior', 'Behavior Control', 'Behavioral', 'Biological', 'Brain', 'Central Auditory Processing Disorder', 'Code', 'Complex', 'Computer Simulation', 'Crowding', 'Data', 'Detection', 'Devices', 'Disease', 'Elements', 'Environment', 'Feedback', 'Ferrets', 'Functional disorder', 'Hearing', 'Hearing problem', 'Human', 'Individual', 'Inferior Colliculus', 'Judgment', 'Learning', 'Life', 'Link', 'Machine Learning', 'Mammals', 'Measures', 'Midbrain structure', 'Modeling', 'Neurons', 'Noise', 'Pathway interactions', 'Patients', 'Peripheral', 'Problem Solving', 'Process', 'Research', 'Response to stimulus physiology', 'Rewards', 'Role', 'Sensory', 'Sensory Process', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Stream', 'Structure', 'Synaptic plasticity', 'System', 'Testing', 'Time', 'Work', 'auditory stimulus', 'awake', 'base', 'behavior influence', 'expectation', 'hearing impairment', 'insight', 'meetings', 'nervous system disorder', 'neurophysiology', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'research study', 'response', 'selective attention', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2016,327250,0.04035745280164657
"CRCNS: Model-driven single-neuron studies of cortical mapping DESCRIPTION (provided by applicant): During natural vision humans and non-human primates make several saccadic eye movements each second that result in large changes in the retinal input. Despite these often dramatic changes, our visual percept remains remarkably stable and we can readily attend to and direct motor actions towards objects in our visual environment. This project will use a model-driven approach to investigate the neural circuits linking vision, attention and oculomotor planning that stabilize perceptual and attentional representations during natural vision. Experimental data will be collected and used to design a detailed computational model of the visual and oculomotor areas involved in saccade compensation. The proposed collaboration between a computational (DE) and experimental neurophysiological (US) laboratories leverages the power of both disciplines. Biologically accurate models of visually guided behavior and trans-saccadic integration developed in the Hamker lab will guide the design of and interpretation of data obtained from neurophysiological experiments in awake, behaving primates performed in the Mazer lab in an iterative fashion, with experimental results informing model revisions and new model predictions altering experimental designs. The proposed studies will characterize both dorsal and ventral stream visual area contributions to stabilizing visual and attentional representations in the primate brai. Data obtained from these experiments will identify the neural circuits responsible for integrating oculomotor commands, bottom-up visual inputs and top-down attention signals. This approach will yield novel insights into interactions between the dorsal and ventral streams during natural vision and facilitate our understanding of goal-directed, active visual perception, a defining feature of human and non-human primate natural vision. A critical component of this project is the highly collaborative nature of the planned research. We expect great benefits from this interdisciplinary approach, which depends critically on computational models that strictly adhere to the known physiological and anatomical constraints to guide our neurophysiological experiments.     1. Training. The proposal includes a detailed training plan intended to facilitate international training of future modelers and neurophysiologists. Specifically, we will train students and post-doctoral researchers to be experts in both experimental and theoretical approaches in order to advance the field using the hybrid approach outlined in the proposal.    2. Education and Outreach. We plan to organize two in-depth workshops on attention and eye movements. These events (one in Germany and one in the US) will bring together investigators from other institutions and related scientific disciplines to advance the field. In addition investigators will organize and chair 1-2 workshops/symposia at annual meetings (e.g., SFN and COSYNE) during the funding period. Finally, we will participate in science education for underrepresented groups through Yale's STARS program by providing training, research and mentoring opportunities in the Mazer lab.    3. Data Sharing. The software tools generated and behavioral and neurophysiological data collected during this project will be distributed to the neuroscience community to facilitate data mining and secondary analyses of experimental data.    4. Impact in other scientific fields. Efficient allocation of limited sensor resources is also a important problem faced by computer vision and robotics researchers. Understanding how the primate brain efficiently allocates visual resources using an active-sensing approach will guide development of biologically inspired computer vision algorithms and humanoid cognitive robots.    5. Translational Implications. Although the proposed research is not translational, there is a growing body of evidence suggesting that several clinically important conditions, including Autism Spectrum Disorder, Attention Deficit Hyperactivity Disorder and Schizophrenia, are associated with impaired behavioral links between saccade planning and visual attention. The proposed basic science studies could have significant implications for future translational research potentially leading to improved understanding disease etiology, development of early diagnostic tools and possible interventional strategies. n/a",CRCNS: Model-driven single-neuron studies of cortical mapping,9308612,R01EY025103,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Cognitive', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Dorsal', 'Education and Outreach', 'Educational workshop', 'Electrophysiology (science)', 'Environment', 'Etiology', 'Event', 'Experimental Designs', 'Eye Movements', 'Financial compensation', 'Funding', 'Future', 'Germany', 'Goals', 'Human', 'Hybrids', 'Institution', 'International', 'Intervention', 'Laboratories', 'Link', 'Mentors', 'Modeling', 'Monkeys', 'Motor', 'Nature', 'Neurons', 'Neurosciences', 'Performance', 'Physiological', 'Postdoctoral Fellow', 'Primates', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Retinal', 'Robot', 'Robotics', 'Saccades', 'Schizophrenia', 'Signal Transduction', 'Software Tools', 'Stream', 'Testing', 'Training', 'Translational Research', 'Underrepresented Groups', 'Update', 'Vision', 'Visual', 'Visual Perception', 'Visual attention', 'Work', 'area V4', 'autism spectrum disorder', 'awake', 'base', 'cell type', 'computer framework', 'cortex mapping', 'data mining', 'data sharing', 'design', 'extrastriate visual cortex', 'improved', 'insight', 'interdisciplinary approach', 'meetings', 'model building', 'neural circuit', 'neurophysiology', 'nonhuman primate', 'novel', 'oculomotor', 'programs', 'relating to nervous system', 'research study', 'science education', 'sensor', 'simulation', 'spatiotemporal', 'student training', 'symposium', 'tool', 'vector', 'visual motor']",NEI,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2016,180000,0.04115755826962929
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9177620,R01NS095251,"['Accounting', 'Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Investments', 'Learning', 'Left', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Records Controls', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'relating to nervous system', 'research study', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2016,891206,0.0403740711791051
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks. PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,9111024,R00HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Health', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Near-Infrared Spectroscopy', 'Neonatology', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Population', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Williams Syndrome', 'aged', 'awake', 'base', 'behavioral outcome', 'cognitive development', 'comparison group', 'developmental disease', 'early experience', 'experience', 'hemodynamics', 'high risk', 'infancy', 'neural correlate', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'predicting response', 'programs', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory input', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,PRINCETON UNIVERSITY,R00,2016,186761,0.04245675714815772
"The role of area V4 in the perception and recognition of visual objects ﻿    DESCRIPTION (provided by applicant): The human visual system parses the information that reaches our eyes into a meaningful arrangement of regions and objects. This process, called image segmentation, is one of the most challenging computations accomplished by the primate brain. To discover its neural basis we will study neuronal processes in two brain areas in the macaque monkey-V4, a fundamental stage of form processing along the occipito-temporal pathway, and the prefrontal cortex (PFC), important for executive control. Dysfunctions of both areas impair shape discrimination behavior in displays that require the identification of segmented objects, strongly suggesting that they are important for image segmentation. Our experimental techniques will include single and multielectrode recordings, behavioral manipulations, perturbation methods and computer models. In Aim 1 we will identify the neural signals that reflect segmentation in visual cortex. Using a variety of parametric stimuli with occlusion, clutter and shadows-stimulus features known to challenge segmentation in natural vision-we will evaluate whether segmentation is achieved by grouping regions with similar surface properties, such as surface color, texture and depth, or by grouping contour segments that are likely to form the boundary of an object or some interplay between these two strategies. We will test the hypothesis that contour grouping mechanisms are most effective under low clutter and close to the fovea. In Aim 2, we will investigate how feedback from PFC modulates shape responses in V4 and facilitates segmentation: we will test the longstanding hypothesis that object recognition in higher cortical stages precedes and facilitates segmentation in the midlevels of visual form processing. We will simultaneously study populations of V4 and PFC neurons while animals engage in shape discrimination behavior. We will use single-trial decoding methods and correlation analyses to relate the content and timing of neuronal responses in the two areas. To causally test the role of feedback from PFC, we will reversibly inactivate PFC by cooling and study V4 neurons. Our results will provide the first detailed, analytical models of V4 neuronal response dynamics in the presence of occlusion and clutter and advance our understanding of how complex visual scenes are processed in area V4. They will also reveal how V4 and PFC together mediate performance on a complex shape discrimination task, how executive function and midlevel vision may be coordinated during behavior and how feedback is used in cortical computation. Object recognition is impaired in visual agnosia, a dysfunction of the occipito-temporal pathway, and in dysfunctions of the PFC (e.g. schizophrenia). Results from these experiments will constitute a major advance in our understanding of the brain computations that underlie segmentation and object recognition and will bring us closer to devising strategies to alleviate and treat brain disorders in which these capacities are impaired. PUBLIC HEALTH RELEVANCE: A fundamental capacity of the primate visual system is its ability to segment visual scenes into component objects and then recognize those objects regardless of partial occlusions and clutter. Using a combination of primate neurophysiology experiments, computational modeling, animal behavior and reversible inactivation methods, we hope to achieve a new level of understanding about visual processing in the context of object recognition; these findings will ultimately bring us closer to devising strategies to alleviate and treat brain disorders of impaired object recognition resulting from dysfunctions in the occipito-temporal pathway (e.g. agnosia) and the prefrontal cortex (e.g. schizophrenia).",The role of area V4 in the perception and recognition of visual objects,9039081,R01EY018839,"['Agnosia', 'Animal Behavior', 'Animals', 'Area', 'Back', 'Behavior', 'Behavior Control', 'Behavioral', 'Brain', 'Brain Diseases', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Custom', 'Data Analyses', 'Discrimination', 'Eye', 'Feedback', 'Functional disorder', 'Goals', 'Grouping', 'Health', 'Human', 'Image', 'Lead', 'Lesion', 'Macaca', 'Mediating', 'Methods', 'Modeling', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Play', 'Population', 'Prefrontal Cortex', 'Primates', 'Process', 'Property', 'Psychology', 'Psychophysics', 'Role', 'Schizophrenia', 'Shapes', 'Signal Transduction', 'Staging', 'Stimulus', 'Stream', 'Surface', 'Surface Properties', 'Techniques', 'Testing', 'Texture', 'Time', 'V4 neuron', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual system structure', 'area V4', 'awake', 'base', 'design', 'executive function', 'feeding', 'fovea centralis', 'imaging Segmentation', 'impaired capacity', 'neurophysiology', 'neurotransmission', 'object recognition', 'relating to nervous system', 'research study', 'response', 'stereoscopic', 'study population', 'visual process', 'visual processing']",NEI,UNIVERSITY OF WASHINGTON,R01,2016,498062,0.10865748464048915
"Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing ﻿    DESCRIPTION (provided by applicant): The long-term goal of this research is to understand how the brain decides where we look in the real world. Many factors influence our eye movements (saccades). For instance, we are more likely to look at salient objects (i.e. those that are conspicuous), such as a bright red balloon in a blue sky. We are also more likely to look at goal-dependent objects (i.e. those that share features with our goals), such as a yellow object when searching for a banana. For several decades, researchers in computer vision have been developing models based on these factors to predict the locations to which we move our eyes. Researchers in neurobiology have also been studying saccade selection, and have suggested the frontal eye field (FEF) plays a large role, as the FEF encodes both visual features and eye movements. But because the FEF encodes both visual features and saccades, it is very difficult to parse FEF activity during natural viewing. For this reason, past experiments have primarily investigated the FEF using simple, constrained tasks with artificial stimuli. In this project, I wil use images of natural scenes, which better approximate the complexity of the real world. I will record with extracellular electrodes from the FEF of awake, behaving rhesus monkeys, while they view natural scenes. In order to determine the FEF's role in the decision of where to saccade next in natural scenes, I will investigate how the FEF encodes visual features that predict saccades. In my two aims, I will test how the FEF encodes salience (Aim 1) and goal-dependence (Aim 2). I will build a model that explains neural activity using visual features (salience and goal-dependence) along with eye movements, which are a confounding source of neural activity. This model will take advantage of computer vision and machine learning algorithms in order to look at the effects of large numbers of correlates and visual features in these natural scenes. The neural data analysis methods developed for these aims will allow researchers that study many brain areas to more easily use natural scenes. Additionally, understanding how the brain chooses where to saccade in natural scenes have important consequences for neurologic and psychiatric health and disease. Several diseases including schizophrenia, autism, and Parkinson's impair the choice of saccades. A better understanding of the link between visual features, eye movements, and FEF activity promises to increase understanding of these diseases and allow the development of novel diagnostic tools.         PUBLIC HEALTH RELEVANCE: This research aims to understand how the frontal eye field cortex helps determine where we look. In particular, it will investigate how the frontal eye field cortex encodes visual stimuli that drive eye movements, such as salient and important objects. Eye movement decisions are impaired in many diseases, including schizophrenia, autism, and Parkinson's, and this research could help lead to a greater understanding of these diseases and the development of novel diagnostic tools.                ",Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing,8909502,F31EY025532,"['Affect', 'Algorithms', 'Area', 'Autistic Disorder', 'Banana', 'Behavior', 'Brain', 'Brain region', 'Complex', 'Computer Vision Systems', 'Crowding', 'Data', 'Data Analyses', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Goals', 'Health', 'Image', 'Lead', 'Link', 'Location', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Neurobiology', 'Neurologic', 'Neurons', 'Parkinson Disease', 'Play', 'Research', 'Research Personnel', 'Role', 'Running', 'Saccades', 'Schizophrenia', 'Site', 'Source', 'Stimulus', 'Testing', 'Visual', 'Visual Pathways', 'Visual attention', 'Work', 'awake', 'base', 'design', 'experience', 'extracellular', 'frontal eye fields', 'nervous system disorder', 'neural model', 'neuromechanism', 'novel diagnostics', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'tool', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY AT CHICAGO,F31,2015,36487,0.07595208116440545
"Representation of information across the human visual cortex ﻿    DESCRIPTION (provided by applicant): The human visual system is organized as a parallel, hierarchical network, and successive stages of visual processing appear to represent increasingly complicated aspects of shape-related and semantic information. However, the way that shape-related and semantic information is represented across much of the visual hierarchy is still poorly understood. The primary goal of this proposal is to understand how information about object shape and semantic category is represented explicitly across mid- and high-level visual areas. To address this important issue we propose to undertake a series of human functional MRI (fMRI) studies, using both synthetic and natural movies. Data will be analyzed by means of a powerful voxel-wise modeling (VM) approach that has been developed in my laboratory over the past several years. In Aim 1 we propose to measure human brain activity evoked by synthetic naturalistic movies, and to use VM to evaluate and compare several competing theories of shape representation across the entire visual cortex. In Aim 2 we propose to use VM to evaluate and compare competing theories of semantic representation. In Aim 3 we propose to use machine learning and and VM to discover new aspects of shape and semantic representation. These experiments will provide fundamental new insights about the representation of visual information across visual cortex.         PUBLIC HEALTH RELEVANCE: Disorders of central vision can severely affect quality of life and the design of treatments and devices for improving visual function will depend critically on understanding the organization of visual cortex. We propose to use functional MRI and sophisticated computational data analysis and modeling procedures to evaluate and compare multiple theories of visual function. The results will reveal how visual information is represented across the several dozen distinct functional areas that constitute human visual cortex.                ",Representation of information across the human visual cortex,8888120,R01EY019684,"['Address', 'Affect', 'Area', 'Award', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disease', 'Elements', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Image', 'Individual', 'Laboratories', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motion', 'Perception', 'Procedures', 'Quality of life', 'Semantics', 'Series', 'Shapes', 'Space Perception', 'Staging', 'Surface', 'System', 'Testing', 'Training', 'V2 neuron', 'V4 neuron', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'abstracting', 'area V1', 'area striata', 'base', 'data modeling', 'design', 'extrastriate visual cortex', 'improved', 'innovation', 'insight', 'movie', 'novel', 'object recognition', 'object shape', 'public health relevance', 'receptive field', 'research study', 'theories', 'therapy design', 'visual information', 'visual neuroscience', 'visual process', 'visual processing']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2015,368851,0.09263354429713333
"Thalamic and Cortical Mechanisms of Itch ﻿    DESCRIPTION (provided by applicant): Itch is a common clinical problem that is often difficult to treat. There is currently little understanding of the mechanism used in the CNS to produce itch and this likely contributes to the inability to treat itch. In recent years it have become cler that information related to itch is carried in the periphery and spinal cord by neurons that are also activated by noxious stimuli. This suggests that information necessary for the production of itch in the brain must be extracted from the responses of polysensory neurons in a process called decoding. The proposed studies, will for the first time, use single unit electrophysiologica techniques to determine the areas in the thalamus and cortex where processing of pruriceptive information occurs. The responses of single neurons in the thalamus to various itch-and pain-producing stimuli will be determined. The cortical areas to which pruriceptive thalamic neurons project will be determined using antidromic activation methods. In addition, responses of individual cortical neurons to pruritogens and pain-producing stimuli will be determined. The proposed studies will determine the thalamic nuclei and cortical areas in which processing of information related to itch and pain occur. In addition, using a Machine Learning approach, we will determine the contributions of the intensity and pattern of action potentials within responses to differential coding of itch and pain related responses. The proposed studies will considerably expand our understanding of the CNS mechanisms that produce itch and pain.        RELEVANCE: Very little is known about the neural systems in the thalamus and cerebral cortex that underlie production of the sensation of itch. This lack of understanding likely contributes to the paucity of effective treatments for the majority of types of chronic itch. The proposed studies will determine the areas in the thalamus and cortex in which single neurons process and transmit information about itch and pain.                 Project Narrative/Relevance Very little is known about the neural systems in the thalamus and cerebral cortex that underlie production of the sensation of itch. This lack of understanding likely contributes to the paucity of effective treatments for the majority of types of chronic itch. The proposed studies will determine the areas in the thalamus and cortex in which single neurons process and transmit information about itch and pain.",Thalamic and Cortical Mechanisms of Itch,8958565,R01NS089647,"['Action Potentials', 'Address', 'Affective', 'Amygdaloid structure', 'Anterior', 'Anxiety', 'Area', 'Ascending Spinal Cord Tract', 'Attention', 'Axon', 'Brain', 'Cell Nucleus', 'Cells', 'Cerebral cortex', 'Characteristics', 'Chronic', 'Clinical', 'Code', 'Complex', 'Cutaneous', 'Data', 'Dimensions', 'Disease', 'Esthesia', 'Feeling suicidal', 'Frequencies', 'Goals', 'Image', 'Individual', 'Insula of Reil', 'Machine Learning', 'Mechanics', 'Medial', 'Mental Depression', 'Methods', 'Molecular', 'Neurons', 'Nociception', 'Nociceptive Stimulus', 'Pain', 'Pattern', 'Population', 'Prevalence', 'Process', 'Production', 'Prosencephalon', 'Rattus', 'Sensory', 'Spinal Cord', 'Spinothalamic Tracts', 'Stimulus', 'System', 'TRP channel', 'Techniques', 'Thalamic Nuclei', 'Thalamic structure', 'Time', 'Ventral Posterior Nucleus', 'cingulate gyrus', 'effective therapy', 'experience', 'improved', 'information processing', 'relating to nervous system', 'response', 'time use']",NINDS,UNIVERSITY OF MINNESOTA,R01,2015,332500,-0.06337949059895838
"The neural workings of self-initiated and quasi-automatic movements ﻿    DESCRIPTION (provided by applicant): Uncovering the principles behind the generation of voluntary movements is a necessary first step in the development of technologies and treatments aimed at restoring motor abilities lost to neurological disease or trauma. The aim of this project is to shed light on the neural mechanisms of voluntary movement initiation. An essential component of voluntary movement is the choice of when to act. Under normal circumstances this decision can be time consuming usually taking up to a few hundreds of milliseconds, longer that the known delays in the nervous system. The area of the brain most associated with generating movements, the motor cortex, becomes very active just before and during the movement, however what exactly is happening during this time is still not well understood. Indeed, while much is known about the neural basis of generating movements, several open questions remain: does a movement generated deliberately with no time pressure, like a reach made to grab an object from a table, share the same neural underpinnings with a very fast reach to catch a falling object? Will the motor cortex be just as active before a quasi-automatic reach when time is of the essence? Or is pre-movement activity only present when there is enough time to deliberately plan the movement? During movement itself, is motor cortex involved in generating quasi-automatic reaches or is there is some reflex mechanism that bypasses motor cortex to generate urgent reaches? To begin answering these questions we have trained two monkeys to initiate a reach under three very different circumstances: sometimes monkeys move at a time of their own choosing with no imposed time constraints, other times monkeys must intercept a rapidly moving target on a screen, which elicits very short-latency reaches. In yet another set of trials monkeys must withhold a reach until given a go cue. The first aim of this project is to determine if these three movements (self-initiated, quasi-automatic and cue-initiated) share a common neural mechanism that does not depend on how the movement is initiated. To do this we will record the responses from a number of neurons in two key regions of the motor cortex: the primary motor and dorsal premotor cortex. In order to understand and interpret these responses, we will employ cutting edge machine learning techniques that will allow us to visualize and quantify the how neural activity evolves in time. Being able to visualize the evolution of neural activity is a key component in understanding the principles that govern how the neural activity translates to movement. The second aim of this project is to elucidate the role that higher cortical areas play in the generation of voluntar movements. We will record neural activity from areas upstream of motor cortex (supplementary motor area), which is heavily interconnected with the motor cortex and is suspected to play crucial a role in determining when a movement should be initiated. We will test record neural activity from this area and characterize its properties using the same cutting edge techniques developed in the first part of this project.         PUBLIC HEALTH RELEVANCE: Uncovering the principles behind the generation of voluntary movements is a necessary first step in the development of technologies and treatments aimed at restoring motor abilities lost to neurological disease or trauma. Arguably, one of the fundamental features of voluntary movement is that one chooses when to move. The main goal of the proposed project is to shed light on the neural mechanisms responsible for voluntary movement initiation.                ",The neural workings of self-initiated and quasi-automatic movements,9051023,F32NS092350,"['Area', 'Behavioral', 'Brain', 'Bypass', 'Cues', 'Data', 'Dependence', 'Dorsal', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Goals', 'Intercept', 'Life', 'Light', 'Link', 'Machine Learning', 'Modeling', 'Monkeys', 'Motor', 'Motor Cortex', 'Movement', 'Nervous System Trauma', 'Nervous system structure', 'Neurons', 'Pattern', 'Play', 'Population', 'Population Dynamics', 'Preparation', 'Process', 'Property', 'Property Rights', 'Reflex action', 'Role', 'Signal Transduction', 'Source', 'Staging', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'base', 'falls', 'grasp', 'millisecond', 'motor control', 'nervous system disorder', 'neuromechanism', 'pressure', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2015,57962,-0.016003818636046722
"Spontaneous activity in gustatory cortex DESCRIPTION (provided by applicant): The PI is a faculty member of the Department of Neurobiology and Behavior at Stony Brook. His research focuses on spontaneous and evoked neural activity in the gustatory cortex. The candidate recently transitioned to neuroscience from a theoretical physics background. This award will provide the necessary five-year protected period for the candidate to receive training in systems and theoretical neuroscience and electrophysiological techniques, under the supervision of the proposed mentorship committee. By the end of the termed period, the candidate will achieve his long term career goals of successfully applying for independent research funding and becoming an independent investigator in the field of theoretical neuroscience. The goal of the proposed research plan is elucidating the relation between spontaneous and evoked activity in the gustatory cortex, and its modulation by anticipatory cues. Spontaneous neural activity in sensory cortices, traditionally regarded as a noisy baseline, is increasingly drawing attention: it can predict trial to trial variability; it contains information on the functional architecture of neural networks; and it was characterized as either a ""repertoire"" of possible network activities or a storage of expectations of sensory stimuli, shaped by development. In the context of taste processing, however, it has received little to no attention. The aim of this proposal is to elucidate the properties of spontaneous activity in the gustatory cortex. This is an ideal system, due to the rich temporal dynamics of responses to taste stimuli, represented in terms of taste-specific sequences of patterns of activity, synchronized across the whole neural population. The first goal of the proposed plan is to employ state-of-the-art machine learning techniques to elucidate the features of spontaneous activity in relation to evoked activity. This will provide new analytical tools for the characterization of spontaneous activity and reconcile within a single framework the different views currently held in the literature, by introducing the new feature of temporal dynamics. As a second goal of the proposed project, the role played by anticipatory cues in modulating the relation between spontaneous and evoked activity will be elucidated, and the dependence of reaction times on spontaneous activity will be clarified. A biologically plausible model of spontaneous activity in the gustatory cortex will be introduced, based on networks of spiking neurons. This model will yield a mechanistic understanding of the feature of spontaneous activity as revealed by the analysis of electrophysiological data. PUBLIC HEALTH RELEVANCE: The proposed research is designed to uncover the dynamical features of spontaneous neural activity in the gustatory cortex and to elucidate its role in modulating the processing of taste---related information under different behavioral contexts. The relation between spontaneous and stimulus---evoked activities is the active subject of debate in the neuroscience literature; this project will develop novel analytical and modeling tools aimed at clarifying the extent to which spontaneous and evoked activity are intertwined. The results of this effort will provide a new perspective on the cortical mechanism underlying taste processing in normal conditions, and bears important implications on issues related to public health, such as the role played by attention in food consumption disorders.",Spontaneous activity in gustatory cortex,8890825,K25DC013557,"['Amygdaloid structure', 'Architecture', 'Attention', 'Award', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Cell Nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Electrodes', 'Evolution', 'Faculty', 'Funding', 'Goals', 'Health', 'Length', 'Link', 'Literature', 'Machine Learning', 'Mental Health', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Pattern', 'Physics', 'Play', 'Population', 'Process', 'Property', 'Public Health', 'Randomized', 'Rattus', 'Reaction Time', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Speed', 'Stimulus', 'Study Subject', 'Supervision', 'System', 'Taste Perception', 'Techniques', 'Testing', 'Thalamic structure', 'Training', 'Ursidae Family', 'Vertebrates', 'analytical tool', 'awake', 'base', 'career', 'design', 'expectation', 'food consumption', 'markov model', 'member', 'millisecond', 'neural correlate', 'novel', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory stimulus', 'stem', 'taste stimuli', 'tool']",NIDCD,STATE UNIVERSITY NEW YORK STONY BROOK,K25,2015,166288,0.006428141278598198
"The gist of the space: A space centered approach to visual scene perception Project Summary  Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology. Narrative The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.",The gist of the space: A space centered approach to visual scene perception,8788527,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2015,405502,0.06931210621217854
"CRCNS: The role of sound statistics for discrimination and coding of sounds ﻿    DESCRIPTION (provided by applicant): Humans and other animals can discriminate and recognize sounds despite substantial acoustic variability in real-world sounds. This ability depends partly on the auditory system's ability to detect and utilize high-order statistical regularities that are present in the acoustic environment. Despite numerous advances in signal processing, assistive listening devices and speech recognition technologies lack biologically realistic strategies to dynamically deal with such acoustic variability. Thus, a comprehensive theory for how the central nervous system encodes and utilizes statistical structure in sounds is essential to develop processing strategies for sound recognition, coding and compression, and to assist individuals with hearing loss.     This proposal presents a novel approach towards addressing the question of how the auditory system deals with and exploits statistical regularities for identification and discrimination of sounds in two critical mammalian auditory structures (inferior colliculus, IC; auditory cortex, AC) Aim 1 is to develop a catalogue of natural and man-made sounds and their associated high-order statistics. Cluster analysis and machine learning will be applied to the sound ensembles to identify salient statistical features that can be used to identify and categorize sounds from a computational perspective. Using information theoretic and correlation based methods, Aim 2 tests the hypothesis that statistical sound regularities are encoded in neural response statistics, including firing rate and spike-timing statistics of IC and AC neurons. Aim 3 will determine neurometric response functions and addresses the hypothesis that high-order statistical regularities in sounds can be discriminated based on temporal pattern and firing rate statistics of single neurons in IC and AC. Aim 4 will employ multi-site recording electrode arrays to tests the hypothesis that neural populations in IC and AC use high-order statistics for sound discrimination and that statistical regularities are encoded by regionally distributed differences n the strength and timing of neural responses or neuron-to-neuron correlations.     The study will provide the groundwork for developing a general theory for how the brain encodes and discriminates sounds based on high-order statistical features. A catalogue of neural responses from single cells, neural ensembles, and high-level statistical features that differentiate real world sounds will be developed and deployed as an on-line resource. The role high-order statics play for sound recognition and discrimination will be identified both from a computational and neural coding perspective, including identifying transformations across neural structures, spatial and temporal scales.     The project will foster collaborations between psychology, electrical engineering, and biomedical engineering departments at the UConn. Graduate, undergraduate and a post-doctoral student, including women and minorities, will participate in the research and will receive interdisciplinary training in areas of neurophysiology, computation neuroscience, and engineering. Drs. Read and Escabi regularly host summer interns in their labs and expect that 1-2 undergraduate students will be hosted per year. Graduate students will be enrolled in biomedical, electrical engineering, and psychology programs. Project findings will be integrated in graduate computational neuroscience and biomedical engineering coursework.     The findings could lead to a host of new sound recognition technologies that make use of high-order statistical regularities to recognize and differentiate amongst sounds. Understanding how high-order statistics are represented in the brain could guide the development of optimal algorithms for detecting a target sound (e.g., speech) in variable/noisy conditions. Such sound recognition systems are also applicable in industrial applications: for instance, identifying fault machine systems from machine generated sounds. Knowledge of the statistical distributions in real world sounds and music will be useful for sound compression (e.g., mpeg coding) and to develop efficient sound processing algorithms. Finally, the findings can be incorporated in auditory prosthetics that mimic normal hearing physiology and make use of high-order sound statistics to remove background noise or enhance intelligibility. n/a",CRCNS: The role of sound statistics for discrimination and coding of sounds,9047911,R01DC015138,"['Accounting', 'Acoustics', 'Address', 'Algorithms', 'Animals', 'Area', 'Auditory', 'Auditory area', 'Auditory system', 'Behavior', 'Biomedical Engineering', 'Brain', 'Cataloging', 'Catalogs', 'Categories', 'Classification', 'Cluster Analysis', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Data', 'Databases', 'Development', 'Devices', 'Discrimination', 'Electrical Engineering', 'Electrodes', 'Engineering', 'Engineering Psychology', 'Enrollment', 'Environment', 'Fostering', 'Future', 'Hearing', 'Human', 'Individual', 'Inferior Colliculus', 'Knowledge', 'Laboratories', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Minority', 'Modeling', 'Music', 'Neuraxis', 'Neurons', 'Neurosciences', 'Noise', 'Oryctolagus cuniculus', 'Pattern', 'Physiology', 'Play', 'Population', 'Postdoctoral Fellow', 'Process', 'Prosthesis', 'Psychology', 'Reading', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Signal Detection Analysis', 'Site', 'Speech', 'Statistical Distributions', 'Structure', 'System', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Variant', 'Woman', 'Work', 'awake', 'base', 'computational neuroscience', 'doctoral student', 'graduate student', 'hearing impairment', 'man', 'neurophysiology', 'novel', 'novel strategies', 'programs', 'relating to nervous system', 'repository', 'response', 'signal processing', 'sound', 'speech recognition', 'statistics', 'theories', 'trait', 'undergraduate student', 'web site']",NIDCD,UNIVERSITY OF CONNECTICUT STORRS,R01,2015,311320,0.027344315610890037
"Neural mechanisms of attentional priority for visual features and objects DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions. Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.",Neural mechanisms of attentional priority for visual features and objects,8893998,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'sustained attention', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2015,318059,0.06262221066995347
"Shifting auditory spatial attention: cognitive and neural mechanisms ﻿    DESCRIPTION (provided by applicant): Hearing can serve as an early warning system because it can panoramically monitor the environment for events happening at a distance or out of sight. These ecological considerations make the auditory system particularly useful for studying mechanisms for shifting spatial attention. The focus of this project is on the interplay between top-down and bottom-up spatial attention biases that govern shifting auditory attention to distractors during performance of a simple spatial attention task. The overall goal of this proposal is to use an interdisciplinary approach to better understand at the cognitive and neural levels of analysis how auditory attention is distributed over space. We will test the hypothesis that the spatial distribution of auditory attentional emerges from interactions among two basic factors. The first factor is a voluntary (top-down) attention bias that weakens with distance from the current focus of attention. Conversely, the second factor is an automatic (bottom-up) bias that is tuned to shift attention to unexpected events away from the current focus of attention. The first aim tests a computational model of top-down and bottom-up attention bias in shifting auditory spatial attention. Different aspects of the model will be quantitatively tested against findings from behavioral experiments, and observations will be used to further develop the model. The computational model will incorporate artificial intelligence methods to represent human cognitive processes. The second aim uses transcranial magnetic stimulation to test the role of key right hemisphere cortical areas in shifting of auditory spatial attention. We focus on neural mechanisms of bottom-up attentional bias. The third aim tests whether auditory attention gradients become less focused over time. This will determine how gradients relate to cognitive resources and neural blood flow measures that are known to decline with extended vigilance. This project will help advance knowledge in the field of auditory attention and cognitive hearing, and also addresses general issues in attention research such as top-down and bottom-up processes, vigilance, and their relations to neurobiological attention networks. Outcomes will have practical significance because shifting auditory attention is vital for avoiding accidents at ll ages, maintaining independent living at older ages, and is applicable to neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia).         PUBLIC HEALTH RELEVANCE: The project outcomes could have clinical in neurological and psychiatric disorders having attentional impairments (e.g. PTSD, attention deficit disorder, schizophrenia, stroke, dementia). The project will examine mechanisms of normal cognitive aging using computational modeling, which can inform the early detection, differential diagnosis, and treatment monitoring of age-related neurodegenerative disorders such as Alzheimer's disease. Knowledge from the transcranial magnetic and electrical DC stimulation experiments may have translational applications for rehabilitation following brain injuries.                ",Shifting auditory spatial attention: cognitive and neural mechanisms,8946229,R01DC014736,"['Accidents', 'Address', 'Affect', 'Age', 'Alzheimer&apos', 's Disease', 'Area', 'Artificial Intelligence', 'Attention', 'Attention Deficit Disorder', 'Auditory', 'Auditory system', 'Behavioral', 'Blood flow', 'Brain Injuries', 'Clinical', 'Cognitive', 'Cognitive aging', 'Computer Simulation', 'Dementia', 'Differential Diagnosis', 'Diffuse', 'Early Diagnosis', 'Electroencephalography', 'Environment', 'Event', 'Goals', 'Hearing', 'Human', 'Impairment', 'Independent Living', 'Individual Differences', 'Inferior', 'Knowledge', 'Learning', 'Left', 'Location', 'Loudness', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Measures', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Music', 'Neurobiology', 'Neurodegenerative Disorders', 'Obstruction', 'Outcome', 'Parietal', 'Performance', 'Positioning Attribute', 'Post-Traumatic Stress Disorders', 'Probability', 'Process', 'Property', 'Reaction Time', 'Rehabilitation therapy', 'Relative (related person)', 'Reproduction', 'Research', 'Resources', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Site', 'Spatial Distribution', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Transcranial magnetic stimulation', 'Vision', 'Work', 'age related', 'attentional bias', 'base', 'behavior measurement', 'cognitive process', 'cost shifting', 'fighting', 'image guided', 'indexing', 'information processing', 'interdisciplinary approach', 'nervous system disorder', 'neural correlate', 'neural stimulation', 'neuroimaging', 'neuromechanism', 'normal aging', 'prefrontal lobe', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'sound', 'theories', 'vector', 'vigilance']",NIDCD,TULANE UNIVERSITY OF LOUISIANA,R01,2015,283560,0.018397727891417304
"Crossmodal Correspondences Between Visual and Auditory Features ﻿    DESCRIPTION (provided by applicant): We live in a multisensory world, in which stimuli of various types constantly compete for our attention. Information about objects or events typically appears on more than one sensory channel, so that integrating inputs across sensory systems (e.g. vision and hearing) can enhance the signal-to-noise ratio and lead to more efficient perception and action. There is increasing interest in studying how stimulus properties in one sensory modality (e.g. vision) correspond to those in another modality (e.g. hearing). For instance, sounds of high pitch are linked to small-sized visual objects whereas sounds of low pitch are linked with large objects; sounds of high/low pitch are associated with, respectively, visual stimuli of high/low elevation; and even aspects of linguistic stimuli such as vowel quality are associated with visual properties such as object size. Such crossmodal correspondences are important factors in multisensory binding. While information has exploded on the kinds of stimulus features that are reliably associated by human observers across modalities, currently there is little neural evidence to allow a mechanistic account of how crossmodal correspondences arise, or how they relate to synesthesia, a phenomenon in which some individuals experience unusual percepts (e.g. colors) triggered by particular stimuli (e.g. letters. Our goal is to address these important gaps in knowledge, by using functional magnetic resonance imaging (fMRI) in humans to investigate the neural mechanisms underlying crossmodal and synesthetic correspondences and thus to distinguish between alternative explanations that have been offered. A number of possible mechanisms have been entertained for crossmodal correspondences. These include: Hypothesis A - learned associations due to statistical co-occurrences, which would predict that the correspondences are based in multisensory or even classic unisensory regions; Hypothesis B - semantic mediation (e.g. the common word ""high"" may mediate the link between high pitch and high elevation); and Hypothesis C - conceptual linking via a high-level property such as magnitude. In a series of eight experiments that comprise three Specific Aims, we propose to examine these competing accounts, recognizing that some or all of them may be operative, and that the mechanisms may vary between different types of crossmodal correspondences.         PUBLIC HEALTH RELEVANCE: The proposed systematic study of the brain basis of correspondences between stimulus properties across sensory systems will allow critical insights into the multisensory processing involved in perception and action, illuminate the multisensory basis of language and music, and expand understanding of the phenomenon of synesthesia in relation to normal experience. From a practical standpoint, the proposed work will make significant contributions to the design of sensory substitution approaches for people with visual, auditory and other sensory deficits, and the rehabilitation of individuals with multisensory processing abnormalities, including developmental (autism, dyslexia), neurological (neglect) and psychiatric (schizophrenia) disorders.                ",Crossmodal Correspondences Between Visual and Auditory Features,8988153,R01EY025978,"['Accounting', 'Address', 'Association Learning', 'Attention', 'Auditory', 'Auditory pitch', 'Autistic Disorder', 'Base of the Brain', 'Behavioral', 'Binding', 'Color', 'Data', 'Development', 'Dimensions', 'Disease', 'Dyslexia', 'Event', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing', 'Human', 'Individual', 'Judgment', 'Knowledge', 'Language', 'Lead', 'Letters', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Modality', 'Multivariate Analysis', 'Music', 'Neurologic', 'Noise', 'Pattern', 'Perception', 'Process', 'Property', 'Regression Analysis', 'Rehabilitation therapy', 'Research Personnel', 'Rest', 'Schizophrenia', 'Semantics', 'Sensory', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Time', 'Vision', 'Visual', 'Work', 'base', 'design', 'experience', 'insight', 'interest', 'multisensory', 'neglect', 'neuroimaging', 'neuromechanism', 'public health relevance', 'relating to nervous system', 'research study', 'sensory system', 'sound', 'vector', 'visual stimulus']",NEI,EMORY UNIVERSITY,R01,2015,586366,0.08868752373461206
"Learning and updating internal visual models ﻿    DESCRIPTION (provided by applicant): In line with the strategic plan of the NEI, this project is focused on filling a profound gap in our understanding of neural mechanisms of visual perception. Specifically, we aim to understand how the adaptation of visual cortical circuits contributes to perception. Adaptation is a ubiquitous process by which neural processing and perception are dramatically influenced by recent visual inputs. However, the functional purpose of adaptation is poorly understood. Based on preliminary data, this project tests the hypothesis that visual adaptation instantiates a form of predictive coding, which is used to make unexpected events salient. We posit that cortical circuits learn the statistical structure of visua input in a manner that extends beyond previous fatigue- based descriptions of adaptation effects. This learning is used to discount expected features and signal novel ones. Our project will test this hypothesis through the collaborative effort of three investigators with expertise in human EEG, animal neurophysiology, and computational modeling. Aim 1 will assess the ability of cortical circuits to adapt to temporal sequences of input and to signal deviations from expected sequences. Aim 2 will evaluate the effect of stimulus uncertainty on adaptation and responses to novel events. Aim 3 will determine how adaptation dynamics and responses to novel stimuli are influenced by the temporal constancy of stimulus statistics. Each of these aims involves an experimental manipulation that yields distinct behavior from fatigue- based and predictive coding mechanisms. Thus, together our aims will provide a robust test of our core hypothesis, and provide a much richer understanding of the adaptive properties of cortical circuits. Results from our project will contribute to answering one of the continuing puzzles in visual research, which is to understand the functional purpose of adaptive mechanisms in visual perception.         PUBLIC HEALTH RELEVANCE: . This research is relevant to public health because it aims to uncover the function of visual adaptation, a fundamental aspect of visual perception. This work is thus essential to the mission of NEI because it will provide a more detailed understanding of how visual cortical circuits underlie visual perception, which is necessary for developing treatment strategies for individuals with visual processing deficits and for the development of effective prosthetic devices.            ",Learning and updating internal visual models,8990935,R01EY024858,"['Affect', 'Animals', 'Area', 'Autistic Disorder', 'Behavior', 'Biological', 'Brain', 'Code', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Disease', 'Electroencephalography', 'Elements', 'Environment', 'Event', 'Fatigue', 'Goals', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Machine Learning', 'Mission', 'Modeling', 'Monkeys', 'Neurons', 'Pattern', 'Perception', 'Process', 'Property', 'Prosthesis', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Scheme', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Signal Transduction', 'Stimulus', 'Strategic Planning', 'Structure', 'Testing', 'Time', 'Uncertainty', 'Update', 'Visual', 'Visual Cortex', 'Visual Perception', 'Work', 'area V4', 'area striata', 'awake', 'base', 'brain machine interface', 'cognitive neuroscience', 'computational neuroscience', 'design', 'discount', 'expectation', 'extrastriate visual cortex', 'human subject', 'improved', 'meetings', 'neuromechanism', 'neurophysiology', 'novel', 'phenomenological models', 'prevent', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'treatment strategy', 'visual adaptation', 'visual process', 'visual processing']",NEI,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2015,575253,0.041823824635546306
"Crowd coding in the brain:3D imaging and control of collective neuronal dynamics ﻿    DESCRIPTION (provided by applicant): The cortex is a laminated structure that is thought to underlie sequential information processing. Sensory input enters layer 4 (L4) from which activity quickly spreads to superficial layers 2/3 (L2/3) and deep layers 5/6 (L5/6) and other cortical areas eventually leading to appropriate motor responses. Sensory responses themselves depend on ongoing, i.e. spontaneous cortical activity, usually in the form of reverberating activit from within or distant cortical regions, as well as the state and behavioral context of the animal. Receptive field properties of neurons can rapidly and adaptively be reshaped when an animal is engaged in a behavioral task, indicating that encoding of stimuli is dependent on task- or context-dependent state. Responses also depend on ongoing cortical dynamics in a lamina-dependent fashion and differ between the awake and anesthetized state. The intricate neuronal interplay between behavioral context, ongoing activity, and sensory stimulus underlying cortical representations is unknown.  Specifically, we do not know how neuronal circuits shape these emergent dynamics within and between laminae, and we do not know which neurons encode which aspect of a sensory stimulus. One shortcoming of all prior studies of sensory processing is that only a few neurons are sampled, and thus information about the interactions between neurons, and between neuron and global brain state is lacking.  Here we address these challenges by developing new in vivo 2-photon imaging technology that allows rapid imaging and stimulation in multiple focal planes and new computational and information theoretic techniques to extract network dynamics at the single neuron and population level. These measures go beyond paired measures and take synergistic interactions between neurons into account. We use these new techniques to investigate the 3D single cell and population activity patterns in the auditory cortex in mice. We investigate the influence of single neurons relative to the synergistic influence of specific groups of neurons (the crowd) on network dynamics and ultimately behavior of the animal. PUBLIC HEALTH RELEVANCE: Functioning of the normal, healthy brain, such as in sensory processing and motor actions, depends on the precise interactions of millions of nerve cells.  Brain diseases are increasingly linked to changes in these complex interactions between large populations of nerve cells.   The current project develops novel imaging tools and analysis concepts to simultaneously study large groups of nerve cells in the awake brain with high temporal and cellular resolution, and will lay the groundwork for deeper insights into how the brain processes information and may provide mechanistic insights into brain disorders such as cerebral palsy, epilepsy, autism, and schizophrenia.",Crowd coding in the brain:3D imaging and control of collective neuronal dynamics,9074031,U01NS090569,"['Accounting', 'Action Potentials', 'Address', 'Algorithms', 'Animal Behavior', 'Animals', 'Area', 'Auditory area', 'Autistic Disorder', 'Behavioral', 'Binding', 'Brain', 'Brain Diseases', 'Cells', 'Cerebral Palsy', 'Cerebral cortex', 'Code', 'Communication', 'Complex', 'Crowding', 'Decision Making', 'Disease', 'Distant', 'Engineering', 'Epilepsy', 'Functional disorder', 'Goals', 'Graph', 'Health', 'Human', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Individual', 'Language', 'Light', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microscope', 'Monitor', 'Motor', 'Mus', 'Neurons', 'Outcome Study', 'Pathology', 'Pattern', 'Physiological', 'Plastics', 'Population', 'Population Dynamics', 'Population Process', 'Process', 'Property', 'Publishing', 'Relative (related person)', 'Research', 'Resolution', 'Rest', 'Sampling', 'Scanning', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Use of New Techniques', 'Work', 'analytical tool', 'auditory discrimination', 'awake', 'base', 'behavioral outcome', 'cell type', 'density', 'in vivo', 'information processing', 'insight', 'millisecond', 'neuronal circuitry', 'novel', 'receptive field', 'response', 'sensory input', 'sensory stimulus', 'spatiotemporal', 'temporal measurement', 'theories', 'tool', 'two-photon']",NINDS,"UNIV OF MARYLAND, COLLEGE PARK",U01,2015,73000,-0.00746910052272644
"Crowd coding in the brain:3D imaging and control of collective neuronal dynamics ﻿    DESCRIPTION (provided by applicant): The cortex is a laminated structure that is thought to underlie sequential information processing. Sensory input enters layer 4 (L4) from which activity quickly spreads to superficial layers 2/3 (L2/3) and deep layers 5/6 (L5/6) and other cortical areas eventually leading to appropriate motor responses. Sensory responses themselves depend on ongoing, i.e. spontaneous cortical activity, usually in the form of reverberating activit from within or distant cortical regions, as well as the state and behavioral context of the animal. Receptive field properties of neurons can rapidly and adaptively be reshaped when an animal is engaged in a behavioral task, indicating that encoding of stimuli is dependent on task- or context-dependent state. Responses also depend on ongoing cortical dynamics in a lamina-dependent fashion and differ between the awake and anesthetized state. The intricate neuronal interplay between behavioral context, ongoing activity, and sensory stimulus underlying cortical representations is unknown.  Specifically, we do not know how neuronal circuits shape these emergent dynamics within and between laminae, and we do not know which neurons encode which aspect of a sensory stimulus. One shortcoming of all prior studies of sensory processing is that only a few neurons are sampled, and thus information about the interactions between neurons, and between neuron and global brain state is lacking.  Here we address these challenges by developing new in vivo 2-photon imaging technology that allows rapid imaging and stimulation in multiple focal planes and new computational and information theoretic techniques to extract network dynamics at the single neuron and population level. These measures go beyond paired measures and take synergistic interactions between neurons into account. We use these new techniques to investigate the 3D single cell and population activity patterns in the auditory cortex in mice. We investigate the influence of single neurons relative to the synergistic influence of specific groups of neurons (the crowd) on network dynamics and ultimately behavior of the animal. PUBLIC HEALTH RELEVANCE: Functioning of the normal, healthy brain, such as in sensory processing and motor actions, depends on the precise interactions of millions of nerve cells.  Brain diseases are increasingly linked to changes in these complex interactions between large populations of nerve cells.   The current project develops novel imaging tools and analysis concepts to simultaneously study large groups of nerve cells in the awake brain with high temporal and cellular resolution, and will lay the groundwork for deeper insights into how the brain processes information and may provide mechanistic insights into brain disorders such as cerebral palsy, epilepsy, autism, and schizophrenia.",Crowd coding in the brain:3D imaging and control of collective neuronal dynamics,8935976,U01NS090569,"['Accounting', 'Action Potentials', 'Address', 'Algorithms', 'Animal Behavior', 'Animals', 'Area', 'Auditory area', 'Autistic Disorder', 'Behavioral', 'Binding', 'Brain', 'Brain Diseases', 'Cells', 'Cerebral Palsy', 'Cerebral cortex', 'Code', 'Communication', 'Complex', 'Crowding', 'Decision Making', 'Disease', 'Distant', 'Engineering', 'Epilepsy', 'Functional disorder', 'Goals', 'Graph', 'Health', 'Human', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Individual', 'Language', 'Light', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microscope', 'Monitor', 'Motor', 'Mus', 'Neurons', 'Outcome Study', 'Pathology', 'Pattern', 'Physiological', 'Plastics', 'Population', 'Population Dynamics', 'Population Process', 'Process', 'Property', 'Publishing', 'Relative (related person)', 'Research', 'Resolution', 'Rest', 'Sampling', 'Scanning', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Use of New Techniques', 'Work', 'analytical tool', 'auditory discrimination', 'awake', 'base', 'behavioral outcome', 'cell type', 'density', 'in vivo', 'information processing', 'insight', 'millisecond', 'neuronal circuitry', 'novel', 'receptive field', 'response', 'sensory input', 'sensory stimulus', 'spatiotemporal', 'temporal measurement', 'theories', 'tool', 'two-photon']",NINDS,"UNIV OF MARYLAND, COLLEGE PARK",U01,2015,250000,-0.00746910052272644
"CRCNS: Model-driven single-neuron studies of cortical remapping DESCRIPTION (provided by applicant): During natural vision humans and non-human primates make several saccadic eye movements each second that result in large changes in the retinal input. Despite these often dramatic changes, our visual percept remains remarkably stable and we can readily attend to and direct motor actions towards objects in our visual environment. This project will use a model-driven approach to investigate the neural circuits linking vision, attention and oculomotor planning that stabilize perceptual and attentional representations during natural vision. Experimental data will be collected and used to design a detailed computational model of the visual and oculomotor areas involved in saccade compensation. The proposed collaboration between a computational (DE) and experimental neurophysiological (US) laboratories leverages the power of both disciplines. Biologically accurate models of visually guided behavior and trans-saccadic integration developed in the Hamker lab will guide the design of and interpretation of data obtained from neurophysiological experiments in awake, behaving primates performed in the Mazer lab in an iterative fashion, with experimental results informing model revisions and new model predictions altering experimental designs. The proposed studies will characterize both dorsal and ventral stream visual area contributions to stabilizing visual and attentional representations in the primate brai. Data obtained from these experiments will identify the neural circuits responsible for integrating oculomotor commands, bottom-up visual inputs and top-down attention signals. This approach will yield novel insights into interactions between the dorsal and ventral streams during natural vision and facilitate our understanding of goal-directed, active visual perception, a defining feature of human and non-human primate natural vision. A critical component of this project is the highly collaborative nature of the planned research. We expect great benefits from this interdisciplinary approach, which depends critically on computational models that strictly adhere to the known physiological and anatomical constraints to guide our neurophysiological experiments.     1. Training. The proposal includes a detailed training plan intended to facilitate international training of future modelers and neurophysiologists. Specifically, we will train students and post-doctoral researchers to be experts in both experimental and theoretical approaches in order to advance the field using the hybrid approach outlined in the proposal.    2. Education and Outreach. We plan to organize two in-depth workshops on attention and eye movements. These events (one in Germany and one in the US) will bring together investigators from other institutions and related scientific disciplines to advance the field. In addition investigators will organize and chair 1-2 workshops/symposia at annual meetings (e.g., SFN and COSYNE) during the funding period. Finally, we will participate in science education for underrepresented groups through Yale's STARS program by providing training, research and mentoring opportunities in the Mazer lab.    3. Data Sharing. The software tools generated and behavioral and neurophysiological data collected during this project will be distributed to the neuroscience community to facilitate data mining and secondary analyses of experimental data.    4. Impact in other scientific fields. Efficient allocation of limited sensor resources is also a important problem faced by computer vision and robotics researchers. Understanding how the primate brain efficiently allocates visual resources using an active-sensing approach will guide development of biologically inspired computer vision algorithms and humanoid cognitive robots.    5. Translational Implications. Although the proposed research is not translational, there is a growing body of evidence suggesting that several clinically important conditions, including Autism Spectrum Disorder, Attention Deficit Hyperactivity Disorder and Schizophrenia, are associated with impaired behavioral links between saccade planning and visual attention. The proposed basic science studies could have significant implications for future translational research potentially leading to improved understanding disease etiology, development of early diagnostic tools and possible interventional strategies. n/a",CRCNS: Model-driven single-neuron studies of cortical remapping,8928626,R01EY025103,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Cognitive', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Dorsal', 'Education and Outreach', 'Educational workshop', 'Environment', 'Etiology', 'Event', 'Experimental Designs', 'Eye Movements', 'Financial compensation', 'Funding', 'Future', 'Germany', 'Goals', 'Human', 'Hybrids', 'Institution', 'International', 'Intervention', 'Laboratories', 'Link', 'Mentors', 'Modeling', 'Monkeys', 'Motor', 'Nature', 'Neurons', 'Neurosciences', 'Performance', 'Physiological', 'Postdoctoral Fellow', 'Primates', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Retinal', 'Robot', 'Robotics', 'Saccades', 'Schizophrenia', 'Signal Transduction', 'Software Tools', 'Stream', 'Students', 'Testing', 'Training', 'Translational Research', 'Underrepresented Minority', 'Update', 'Vision', 'Visual', 'Visual Perception', 'Visual attention', 'Work', 'area V4', 'autism spectrum disorder', 'awake', 'base', 'cell type', 'computer framework', 'data mining', 'data sharing', 'design', 'extrastriate visual cortex', 'improved', 'insight', 'interdisciplinary approach', 'meetings', 'model building', 'neural circuit', 'neurophysiology', 'nonhuman primate', 'novel', 'oculomotor', 'programs', 'relating to nervous system', 'research study', 'science education', 'sensor', 'simulation', 'spatiotemporal', 'symposium', 'tool', 'vector', 'visual motor']",NEI,YALE UNIVERSITY,R01,2015,203962,0.04119741398304851
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.        This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8895328,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'cognitive process', 'cognitive task', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2015,347803,0.08378857585764227
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks. PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,8849468,K99HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Health', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Near-Infrared Spectroscopy', 'Neonatology', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Population', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Williams Syndrome', 'aged', 'awake', 'base', 'behavioral outcome', 'cognitive development', 'comparison group', 'developmental disease', 'early experience', 'experience', 'hemodynamics', 'high risk', 'infancy', 'neural correlate', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'programs', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory input', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,UNIVERSITY OF ROCHESTER,K99,2015,82417,0.04245675714815772
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks. PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,9085979,R00HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Health', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Near-Infrared Spectroscopy', 'Neonatology', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Population', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Williams Syndrome', 'aged', 'awake', 'base', 'behavioral outcome', 'cognitive development', 'comparison group', 'developmental disease', 'early experience', 'experience', 'hemodynamics', 'high risk', 'infancy', 'neural correlate', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'programs', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory input', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,PRINCETON UNIVERSITY,R00,2015,249000,0.04245675714815772
"Neural Basis of Shape from Texture DESCRIPTION (provided by applicant): People often need to judge the shapes and movements of 3-D objects from a distance. Images on the retinae are 2-D, but pattern and motion information contain cues about 3-D shapes. Building on our previous work we expect to make significant progress in understanding 3-D shape perception from these cues, and thus offer a prototype for how the brain extracts information from the world to infer environmental properties. When surfaces have texture patterns, deformations of these patterns in retinal images provide clues for the brain to judge 3-D shape. When signals from the eyes reach the first cortical area V1, they are processed by neurons that are selectively tuned to orientations and spatial frequencies. We parsed texture deformations into orientation flows and spatial frequency gradients, to show that particular orientation flows evoke percepts of specific 3-D shapes, whereas frequency gradients provide cues to relative depth. These results led to models of how later cortical neurons could extract texture patterns and signal 3-D shapes. We now propose to extend our approach beyond static objects. When objects change shape (e.g. by bending, coiling, or contracting) as they move (e.g. walk, tumble, crawl, hop, slide, or swim), changes in the retinal image create patterns of local velocities that provide additional cues to 3-D shape. Since any retinal image can result from projections of many different 3-D objects, the brain relies on prior assumptions to infer the correct shape. Previous studies have only looked at rigid objects and used shape inference models based either on the brain assuming that the object is rigid or that faster points are nearer. We will use novel stimuli that put these prior assumptions in conflict, and thus examine how the brain potentiates a prior. This section will culminate in a model for choosing between conflicting assumptions, something that is often required in perception and cognition. Next, we will use randomly deforming non-rigid 3-D waves to examine how global shape properties, e.g. symmetry, influence perceived object motions by selectively combining disparate outputs of motion sensitive neurons. These results will unveil interactions between the form and motion cortical systems. Finally, we will examine observers' percepts of dynamic shape changes that require more sophisticated analyses of retinal velocity patterns. Neurons in the motion sensitive cortical area MT respond to 1-D motion shear and compression/divergence, so we will extract these qualities and combine them into 2-D velocity patterns of divergence, rotation, and deformation. Neural filters formed by these patterns will be used to explain perceived changes in 3-D shapes. We will base our filters on responses of MT and later cortical neurons to our stimuli, measured in a parallel project. We will thus present the first neural model that can explain observers' percepts of both rigid and non-rigid textured objects. The performance of our model will be compared against the best computer-vision models on motion-capture data from real deforming objects. We expect this project to introduce new ideas, methods and results for understanding visual perception of 3-D shapes and its deficits in neurological patients. Shape is probably the most important cue for recognizing objects, so neurological disorders related to shape- perception would severely impair the ability of such patients to function autonomously. This project will identify how the brain constructs correct and incorrect shape percepts of 3-D objects from texture and motion information. In addition, people with amblyopia, strabismus and convergence-insufficiency often have deficient stereo vision, so they find texture and motion information to be particularly useful in perceiving 3-D shapes, hence our work on separating velocity information into object motion, object shape, and shape deformation may be particularly useful to these people.",Neural Basis of Shape from Texture,8843856,R01EY013312,"['3-Dimensional', 'Amblyopia', 'Attention', 'Bayesian Analysis', 'Biological', 'Brain', 'Cognition', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conflict (Psychology)', 'Contracts', 'Convergence Insufficiency', 'Cues', 'Data', 'Development', 'Discrimination', 'Eye', 'Eye Movements', 'Frequencies', 'Geometry', 'Head Movements', 'Image', 'Learning', 'Light', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Neurologic', 'Neurons', 'Output', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Property', 'Psychophysics', 'Relative (related person)', 'Resolution', 'Retina', 'Retinal', 'Rotation', 'Shapes', 'Signal Transduction', 'Slide', 'Space Perception', 'Staging', 'Stimulus', 'Strabismus', 'Stream', 'Surface', 'Swimming', 'System', 'Testing', 'Texture', 'Translating', 'Variant', 'Vision', 'Visual', 'Visual Perception', 'Walking', 'Work', 'analog', 'area MT', 'area V1', 'base', 'design', 'movie', 'nervous system disorder', 'neural model', 'novel', 'object motion', 'object shape', 'prototype', 'relating to nervous system', 'research study', 'response', 'sample fixation']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2015,354693,0.06465365986902079
"A Visual Assessment System for Retinal Function/Drug Discovery ﻿    DESCRIPTION (provided by applicant): Preclinical evaluation of treatment strategies for retinal neurodegenerative diseases is highly dependent on mouse models. Classical methods to assess the visual function of animals, such as electroretinogram (ERG), which measures electrical responses in the retina, do not address connections between the eye and brain or visual perception by the visual system. This often raises concerns regarding the functional relevance of the therapeutic benefit. Difficulty in assessing visual perception and related behavior in mice and rats, largely due to their subtle visual behavior cues and the lack of adequate measuring devices, presents a critical barrier to the application of mouse models for evaluating treatment efficacy of new drugs, and for scaling up for behavior phenotyping to screen genetic vision defects. Pupillary light reflex (PLR) and optokinetic reflex (OKR) tests are useful methods in clinics for assessing human visual responses and perception. However, such tests have been difficult to conduct in rodents because current rodent visual testing methods or devices either do not allow accurate quantitative assessment for PLR or OKR or use subjective measures to score visual responses. To address these challenges, we propose to advance the technology by designing an easy-to-use automated platform that employs an eye/pupil tracking device equipped with a computer vision system (chiefly the interactive tracking system) for unambiguous objective scoring of visual responses. Our proposed new device will allow real-time quantitative and accurate assessment of rodent visual function including light responses, visual acuity and contrast sensitivity. The novelty of our system also lies in that it does not require complicated calibration procedures needed in commonly used human eye tracking. Rather than precisely measuring the extent of eye turning (or orientation), we propose to detect the signature eye movement in accordance with the speed and direction of visual stimuli. The system will be validated using normal wildtype mice and mouse models of retinal neurodegeneration known to develop visual behavior changes in the parameters mentioned above. Although rodent eye tracking has been investigated before, this proposed visual assessment system would be the first commercially viable product that uses an eye/pupil tracking device to automatically assess visual perception in rodents. The combined PLR and OKR tests and vastly simplified and automated quantification methods will also provide the first scalable behavior platform for phenotyping and drug discovery in the vision research area. In the future, this technology has the potential of being expanded to measure responses from various visual stimuli. This may translate into broader applications for evaluating brain diseases that afflict the visual pathways. This platform for mouse visual behavior assessment will therefore greatly facilitate drug discovery and development aimed at preventing and slowing vision loss or restoring sight, helping to combat devastating blinding conditions such as age-related macular degeneration (AMD) and glaucoma.         PUBLIC HEALTH RELEVANCE: The objective of the current proposal is to design and develop an automated system for the measure of rodent (mice and rats) light response, visual acuity, and contrast sensitivity. The system will apply human eye/pupil tracking techniques for objective and unambiguous evaluation of light response and visual perception. This platform will provide a powerful tool for phenotypic studies as well as for discovery of new drugs that can prevent or restore sight caused by blinding conditions such as age-related macular degeneration and glaucoma.                ",A Visual Assessment System for Retinal Function/Drug Discovery,8980787,R41EY025913,"['Address', 'Age related macular degeneration', 'Algorithms', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Behavior assessment', 'Behavior monitoring', 'Behavioral', 'Biological Assay', 'Blindness', 'Brain', 'Brain Diseases', 'Calibration', 'Clinic', 'Collaborations', 'Coma', 'Computer Vision Systems', 'Contrast Sensitivity', 'Cues', 'Data Analyses', 'Defect', 'Development', 'Devices', 'Disease', 'Electroretinography', 'Evaluation', 'Eye', 'Eye Movements', 'Eye diseases', 'Funding', 'Future', 'Genetic Screening', 'Glaucoma', 'Head', 'Head Movements', 'Human', 'Image', 'Impairment', 'Laboratory Animals', 'Lead', 'Light', 'Marketing', 'Measurement', 'Measures', 'Medical', 'Methods', 'Mus', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Patients', 'Pattern', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Photic Stimulation', 'Preclinical Drug Evaluation', 'Procedures', 'Pupil', 'Pupil light reflex', 'Rattus', 'Reflex action', 'Research Institute', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Rodent', 'Small Business Technology Transfer Research', 'Speed', 'System', 'Techniques', 'Technology', 'Technology Transfer', 'Testing', 'Therapeutic', 'Time', 'Training', 'Transgenic Mice', 'Translating', 'Translations', 'Treatment Efficacy', 'Vision', 'Vision research', 'Visual', 'Visual Acuity', 'Visual Pathways', 'Visual Perception', 'Visual system structure', 'approach behavior', 'base', 'behavior change', 'combat', 'commercialization', 'computer generated', 'data acquisition', 'design', 'drug development', 'drug discovery', 'genetic approach', 'innovation', 'instrument', 'liquid crystal', 'mouse model', 'new technology', 'performance tests', 'photoreceptor degeneration', 'preclinical evaluation', 'prevent', 'prototype', 'public health relevance', 'response', 'scale up', 'success', 'tool', 'touchscreen', 'treatment strategy', 'visual performance', 'visual stimulus']",NEI,"AFASCI, INC.",R41,2015,233235,0.0006976233209679039
"Neural Mechanisms of Fixation Choice while Searching Natural Scenes The overall goal of these experiments is to understand how the brain controls where we look. To accomplish this, it is important to study brain activity and behavior under conditions that closely approximate those in the real world. All of the experiments we propose to do will use awake behaving rhesus monkeys as subjects. In prior work, we have studied activity in the cortical frontal eye field while monkeys looked at images of natural scenes. The frontal eye field (FEF) is closely involved in the control of purposive voluntary eye movements. While the monkey searched for a target hidden in the images of natural scenes, the activity of FEF neurons consisted of combinations of activity related to planning upcoming eye movements, as well as activity that was sensitive to salient visual features of the image. In parallel with the development of our understanding of how the brain controls eye movements, there have been substantial advances in our understanding of the features of natural images that guide both human and monkey eye movements. These behavioral studies are at the advanced level of being able to accurately predict patterns of eye movements. Our goal in this proposal is to take advantage of these advancements in predicting patterns of eye movements in natural environments to help us understand the brain events that are responsible for this behavior. We will focus upon neuron activity in the FEF due to its essential role in the control of voluntary eye movements. The proposal has 3 Aims each focused upon a different factor that is known to guide eye movements under natural conditions. Salience describes how different a small part of a visual scene is from the remainder of the scene based upon stimulus features such as color, contrast, shape, and orientation. Our first aim will define the effects that salience has upon FEF activity. In our second aim, we'll quantify the effects of relevance. Relevance refers to the importance of visual features for the task at hand; for example, if we're looking for a red target, the red items in the image will be more likely to attract our attention and ultimately be the target for an eye movement. Knowing the broad composition of a scene, a quality that is called scene gist, can tell us the places where an object is more likely to be found. For example, if we are looking for a bicycle, we are more likely to search the sidewalks and roadways of a street scene and ignore other places where bicycles are unlikely to be found. Our final aim will look for the effects of scene gist upon monkey behavior and the FEF activity driving that behavior. In addition to the brain recording experiments outlined above, a large part of our effort will be devoted to mathematical analysis and modeling of the behavioral and neuronal data we obtain. Our ultimate goal is to provide a model that predicts the contributions of salience, relevance, and gist to the activity of FEF neurons. The successful model will be a mathematical representation that predicts search-related activity in the FEF for both artificial and real world conditions. Due to the known and expected similarities between monkey and human eye movement systems, these experiments provide a model for the functional organization of frontal eye field cortex in humans. The ability to make appropriate eye movements is a function that can be damaged by a number of diseases, including cerebral stroke, Alzheimer's, Parkinson's, and Schizophrenia. More specifically, deficits in the proper control of fixation during search of complex visual stimuli have been described in patients suffering from simultanagnosia, as well as in individuals with a diagnosis of autism spectrum disorder.",Neural Mechanisms of Fixation Choice while Searching Natural Scenes,8822295,R01EY021579,"['Accounting', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Appetitive Behavior', 'Area', 'Attention', 'Auditory area', 'Banana', 'Behavior', 'Behavioral', 'Bicycling', 'Brain', 'Color', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Elements', 'Environment', 'Event', 'Eye Movements', 'Financial compensation', 'Goals', 'Gray unit of radiation dose', 'Human', 'Image', 'Individual', 'Location', 'Macaca mulatta', 'Maps', 'Measures', 'Modeling', 'Monkeys', 'Nervous system structure', 'Neurons', 'Parkinson Disease', 'Patients', 'Pattern', 'Positioning Attribute', 'Primates', 'Property', 'Research', 'Rest', 'Retina', 'Role', 'Saccades', 'Schizophrenia', 'Shapes', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Trees', 'Visual', 'Visual Acuity', 'Visual Cortex', 'Visual system structure', 'Weight', 'Work', 'autism spectrum disorder', 'awake', 'base', 'behavioral study', 'driving behavior', 'expectation', 'frontal eye fields', 'image guided', 'interest', 'mathematical analysis', 'mathematical model', 'mind control', 'neuromechanism', 'research study', 'sample fixation', 'visual motor', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY,R01,2015,376478,0.05358535072597154
"The role of area V4 in the perception and recognition of visual objects ﻿    DESCRIPTION (provided by applicant): The human visual system parses the information that reaches our eyes into a meaningful arrangement of regions and objects. This process, called image segmentation, is one of the most challenging computations accomplished by the primate brain. To discover its neural basis we will study neuronal processes in two brain areas in the macaque monkey-V4, a fundamental stage of form processing along the occipito-temporal pathway, and the prefrontal cortex (PFC), important for executive control. Dysfunctions of both areas impair shape discrimination behavior in displays that require the identification of segmented objects, strongly suggesting that they are important for image segmentation. Our experimental techniques will include single and multielectrode recordings, behavioral manipulations, perturbation methods and computer models. In Aim 1 we will identify the neural signals that reflect segmentation in visual cortex. Using a variety of parametric stimuli with occlusion, clutter and shadows-stimulus features known to challenge segmentation in natural vision-we will evaluate whether segmentation is achieved by grouping regions with similar surface properties, such as surface color, texture and depth, or by grouping contour segments that are likely to form the boundary of an object or some interplay between these two strategies. We will test the hypothesis that contour grouping mechanisms are most effective under low clutter and close to the fovea. In Aim 2, we will investigate how feedback from PFC modulates shape responses in V4 and facilitates segmentation: we will test the longstanding hypothesis that object recognition in higher cortical stages precedes and facilitates segmentation in the midlevels of visual form processing. We will simultaneously study populations of V4 and PFC neurons while animals engage in shape discrimination behavior. We will use single-trial decoding methods and correlation analyses to relate the content and timing of neuronal responses in the two areas. To causally test the role of feedback from PFC, we will reversibly inactivate PFC by cooling and study V4 neurons. Our results will provide the first detailed, analytical models of V4 neuronal response dynamics in the presence of occlusion and clutter and advance our understanding of how complex visual scenes are processed in area V4. They will also reveal how V4 and PFC together mediate performance on a complex shape discrimination task, how executive function and midlevel vision may be coordinated during behavior and how feedback is used in cortical computation. Object recognition is impaired in visual agnosia, a dysfunction of the occipito-temporal pathway, and in dysfunctions of the PFC (e.g. schizophrenia). Results from these experiments will constitute a major advance in our understanding of the brain computations that underlie segmentation and object recognition and will bring us closer to devising strategies to alleviate and treat brain disorders in which these capacities are impaired.         PUBLIC HEALTH RELEVANCE: A fundamental capacity of the primate visual system is its ability to segment visual scenes into component objects and then recognize those objects regardless of partial occlusions and clutter. Using a combination of primate neurophysiology experiments, computational modeling, animal behavior and reversible inactivation methods, we hope to achieve a new level of understanding about visual processing in the context of object recognition; these findings will ultimately bring us closer to devising strategies to alleviate and treat brain disorders of impaired object recognition resulting from dysfunctions in the occipito-temporal pathway (e.g. agnosia) and the prefrontal cortex (e.g. schizophrenia).                ",The role of area V4 in the perception and recognition of visual objects,8893671,R01EY018839,"['Agnosia', 'Animal Behavior', 'Animals', 'Area', 'Back', 'Behavior', 'Behavior Control', 'Behavioral', 'Brain', 'Brain Diseases', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Custom', 'Data Analyses', 'Discrimination', 'Eye', 'Feedback', 'Functional disorder', 'Goals', 'Grouping', 'Human', 'Image', 'Lead', 'Lesion', 'Macaca', 'Mediating', 'Methods', 'Modeling', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Play', 'Population', 'Population Study', 'Prefrontal Cortex', 'Primates', 'Process', 'Property', 'Psychology', 'Psychophysics', 'Relative (related person)', 'Role', 'Schizophrenia', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Staging', 'Stimulus', 'Stream', 'Surface', 'Surface Properties', 'Techniques', 'Testing', 'Texture', 'Time', 'V4 neuron', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual system structure', 'area V4', 'awake', 'base', 'design', 'executive function', 'feeding', 'fovea centralis', 'imaging Segmentation', 'impaired capacity', 'neurophysiology', 'neurotransmission', 'object recognition', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'stereoscopic', 'visual process', 'visual processing']",NEI,UNIVERSITY OF WASHINGTON,R01,2015,479568,0.10865748464048915
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8731899,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'undergraduate student', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2014,354773,0.09801998419373847
"Spontaneous activity in gustatory cortex     DESCRIPTION (provided by applicant): The PI is a faculty member of the Department of Neurobiology and Behavior at Stony Brook. His research focuses on spontaneous and evoked neural activity in the gustatory cortex. The candidate recently transitioned to neuroscience from a theoretical physics background. This award will provide the necessary five-year protected period for the candidate to receive training in systems and theoretical neuroscience and electrophysiological techniques, under the supervision of the proposed mentorship committee. By the end of the termed period, the candidate will achieve his long term career goals of successfully applying for independent research funding and becoming an independent investigator in the field of theoretical neuroscience. The goal of the proposed research plan is elucidating the relation between spontaneous and evoked activity in the gustatory cortex, and its modulation by anticipatory cues. Spontaneous neural activity in sensory cortices, traditionally regarded as a noisy baseline, is increasingly drawing attention: it can predict trial to trial variability; it contains information on the functional architecture of neural networks; and it was characterized as either a ""repertoire"" of possible network activities or a storage of expectations of sensory stimuli, shaped by development. In the context of taste processing, however, it has received little to no attention. The aim of this proposal is to elucidate the properties of spontaneous activity in the gustatory cortex. This is an ideal system, due to the rich temporal dynamics of responses to taste stimuli, represented in terms of taste-specific sequences of patterns of activity, synchronized across the whole neural population. The first goal of the proposed plan is to employ state-of-the-art machine learning techniques to elucidate the features of spontaneous activity in relation to evoked activity. This will provide new analytical tools for the characterization of spontaneous activity and reconcile within a single framework the different views currently held in the literature, by introducing the new feature of temporal dynamics. As a second goal of the proposed project, the role played by anticipatory cues in modulating the relation between spontaneous and evoked activity will be elucidated, and the dependence of reaction times on spontaneous activity will be clarified. A biologically plausible model of spontaneous activity in the gustatory cortex will be introduced, based on networks of spiking neurons. This model will yield a mechanistic understanding of the feature of spontaneous activity as revealed by the analysis of electrophysiological data.          PUBLIC HEALTH RELEVANCE: The proposed research is designed to uncover the dynamical features of spontaneous neural activity in the gustatory cortex and to elucidate its role in modulating the processing of taste---related information under different behavioral contexts. The relation between spontaneous and stimulus---evoked activities is the active subject of debate in the neuroscience literature; this project will develop novel analytical and modeling tools aimed at clarifying the extent to which spontaneous and evoked activity are intertwined. The results of this effort will provide a new perspective on the cortical mechanism underlying taste processing in normal conditions, and bears important implications on issues related to public health, such as the role played by attention in food consumption disorders.                ",Spontaneous activity in gustatory cortex,8766158,K25DC013557,"['Amygdaloid structure', 'Architecture', 'Attention', 'Award', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Cell Nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Electrodes', 'Evolution', 'Faculty', 'Funding', 'Goals', 'Length', 'Link', 'Literature', 'Machine Learning', 'Mental Health', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Pattern', 'Physics', 'Play', 'Population', 'Process', 'Property', 'Public Health', 'Randomized', 'Rattus', 'Reaction Time', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Speed', 'Stimulus', 'Study Subject', 'Supervision', 'System', 'Taste Perception', 'Techniques', 'Testing', 'Thalamic structure', 'Training', 'Ursidae Family', 'Vertebrates', 'analytical tool', 'awake', 'base', 'career', 'design', 'expectation', 'food consumption', 'markov model', 'member', 'millisecond', 'novel', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory stimulus', 'stem', 'tool']",NIDCD,STATE UNIVERSITY NEW YORK STONY BROOK,K25,2014,167410,0.006428141278598198
"The Neural Bases of he Semantic Structure of Words and Concepts    DESCRIPTION (provided by applicant): This project proposes to discover the neural representation of some simple words and concepts. It uses newly developed machine learning techniques and dimension reduction methods applied to fMRI brain activation data that will be acquired in new experimental paradigms. This research approach has for the first time succeeded in identifying the content of individual human thoughts based on the pattern of brain activity. The initial published studies have demonstrated this capability in the case of concrete nouns and physical objects. This project proposes to expand the approach to a much larger set of different types of concepts and to examine the effect of the way the concept is presented (e.g. a written or spoken word, or a picture). The goal is to develop a comprehensive theory of how neural representations of meaning arise from the various brain systems that are used in interacting or considering the concept. An important secondary goal is to determine the degree of commonality of the neural representations across people.  The studies propose to examine the neural dimensions of meaning in three domains: (a) physical objects; (b) human traits, emotions, and interpersonal interactions; and (c) small numerical quantities. This set of semantic domains is expected to provide sufficient breadth to reveal some of the principle neural bases of semantic representation.  In contrast to the field of ""semantics"" (the study of the relation between words and their meanings), this project will help establish a new research area, neurosemantics, which is the study of the relation between words, thoughts, and their neural representations. The key assumption is that the underlying dimensions of meaning representation in the human brain are derived from basic neural systems. For example, one of the dimensions of representation of a physical object is how one physically interacts with or handles it. This dimension of representation is underpinned by a network of cortical areas that co-activate when one thinks about a physical object, and also when one actually handles the physical object. Other dimensions of neural representation similarly emerge when the concept is encountered. The studies will collectively identify the major dimensions of concept representation and relate them to networks of co-activating brain areas.  The cumulative knowledge from the completed project will provide the framework of a theory of how brain systems map onto the representation of the meaning of concepts. The theory will be applicable to understanding and designing therapies for neurological conditions in which the meanings of concepts are distorted, such as Alzheimer's Disease, Pick's Disease, semantic dementia, and autism. The resulting theory will be foundational in relating the representation of meaning to brain function.        The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.            ",The Neural Bases of he Semantic Structure of Words and Concepts,8681523,R01MH029617,"['Accounting', 'Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Anomia', 'Area', 'Autistic Disorder', 'Brain', 'Brain Diseases', 'Characteristics', 'Conceptions', 'Data', 'Dimensions', 'Disease', 'Emotions', 'Factor Analysis', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Individual', 'Interpersonal Relations', 'Knowledge', 'Language', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Neurologic', 'Pattern', 'Personality Traits', 'Pick Disease of the Brain', 'Publishing', 'Research', 'Semantic Dementias', 'Semantics', 'Social Concepts', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'To specify', 'Writing', 'base', 'design', 'nervous system disorder', 'novel strategies', 'relating to nervous system', 'research study', 'sound', 'theories', 'therapy design', 'trait']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2014,337001,0.025448452930973888
"The gist of the space: A space centered approach to visual scene perception  Project Summary  Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.  Narrative The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.",The gist of the space: A space centered approach to visual scene perception,8599464,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2014,402592,0.06931210621217854
"Neural mechanisms of attentional priority for visual features and objects     DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions.          Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.                ",Neural mechanisms of attentional priority for visual features and objects,8675258,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2014,360448,0.06262221066995347
"Crowd coding in the brain:3D imaging and control of collective neuronal dynamics ﻿    DESCRIPTION (provided by applicant): The cortex is a laminated structure that is thought to underlie sequential information processing. Sensory input enters layer 4 (L4) from which activity quickly spreads to superficial layers 2/3 (L2/3) and deep layers 5/6 (L5/6) and other cortical areas eventually leading to appropriate motor responses. Sensory responses themselves depend on ongoing, i.e. spontaneous cortical activity, usually in the form of reverberating activit from within or distant cortical regions, as well as the state and behavioral context of the animal. Receptive field properties of neurons can rapidly and adaptively be reshaped when an animal is engaged in a behavioral task, indicating that encoding of stimuli is dependent on task- or context-dependent state. Responses also depend on ongoing cortical dynamics in a lamina-dependent fashion and differ between the awake and anesthetized state. The intricate neuronal interplay between behavioral context, ongoing activity, and sensory stimulus underlying cortical representations is unknown.  Specifically, we do not know how neuronal circuits shape these emergent dynamics within and between laminae, and we do not know which neurons encode which aspect of a sensory stimulus. One shortcoming of all prior studies of sensory processing is that only a few neurons are sampled, and thus information about the interactions between neurons, and between neuron and global brain state is lacking.  Here we address these challenges by developing new in vivo 2-photon imaging technology that allows rapid imaging and stimulation in multiple focal planes and new computational and information theoretic techniques to extract network dynamics at the single neuron and population level. These measures go beyond paired measures and take synergistic interactions between neurons into account. We use these new techniques to investigate the 3D single cell and population activity patterns in the auditory cortex in mice. We investigate the influence of single neurons relative to the synergistic influence of specific groups of neurons (the crowd) on network dynamics and ultimately behavior of the animal.         PUBLIC HEALTH RELEVANCE: Functioning of the normal, healthy brain, such as in sensory processing and motor actions, depends on the precise interactions of millions of nerve cells.  Brain diseases are increasingly linked to changes in these complex interactions between large populations of nerve cells.   The current project develops novel imaging tools and analysis concepts to simultaneously study large groups of nerve cells in the awake brain with high temporal and cellular resolution, and will lay the groundwork for deeper insights into how the brain processes information and may provide mechanistic insights into brain disorders such as cerebral palsy, epilepsy, autism, and schizophrenia.                ",Crowd coding in the brain:3D imaging and control of collective neuronal dynamics,8827121,U01NS090569,"['Accounting', 'Action Potentials', 'Address', 'Algorithms', 'Animal Behavior', 'Animals', 'Area', 'Auditory area', 'Autistic Disorder', 'Behavioral', 'Binding', 'Brain', 'Brain Diseases', 'Cells', 'Cerebral Palsy', 'Cerebral cortex', 'Code', 'Communication', 'Complex', 'Crowding', 'Decision Making', 'Disease', 'Distant', 'Engineering', 'Epilepsy', 'Functional disorder', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Individual', 'Language', 'Light', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Microscope', 'Monitor', 'Motor', 'Mus', 'Neurons', 'Outcome', 'Outcome Study', 'Pathology', 'Pattern', 'Physiological', 'Plastics', 'Population', 'Population Dynamics', 'Population Process', 'Property', 'Publishing', 'Relative (related person)', 'Research', 'Resolution', 'Rest', 'Sampling', 'Scanning', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Use of New Techniques', 'Work', 'analytical tool', 'auditory discrimination', 'awake', 'base', 'cell type', 'density', 'in vivo', 'information processing', 'insight', 'millisecond', 'novel', 'public health relevance', 'receptive field', 'response', 'sensory stimulus', 'spatiotemporal', 'theories', 'tool', 'two-photon']",NINDS,"UNIV OF MARYLAND, COLLEGE PARK",U01,2014,250000,-0.00746910052272644
"CRCNS: Model-driven single-neuron studies of cortical remapping     DESCRIPTION (provided by applicant): During natural vision humans and non-human primates make several saccadic eye movements each second that result in large changes in the retinal input. Despite these often dramatic changes, our visual percept remains remarkably stable and we can readily attend to and direct motor actions towards objects in our visual environment. This project will use a model-driven approach to investigate the neural circuits linking vision, attention and oculomotor planning that stabilize perceptual and attentional representations during natural vision. Experimental data will be collected and used to design a detailed computational model of the visual and oculomotor areas involved in saccade compensation. The proposed collaboration between a computational (DE) and experimental neurophysiological (US) laboratories leverages the power of both disciplines. Biologically accurate models of visually guided behavior and trans-saccadic integration developed in the Hamker lab will guide the design of and interpretation of data obtained from neurophysiological experiments in awake, behaving primates performed in the Mazer lab in an iterative fashion, with experimental results informing model revisions and new model predictions altering experimental designs. The proposed studies will characterize both dorsal and ventral stream visual area contributions to stabilizing visual and attentional representations in the primate brai. Data obtained from these experiments will identify the neural circuits responsible for integrating oculomotor commands, bottom-up visual inputs and top-down attention signals. This approach will yield novel insights into interactions between the dorsal and ventral streams during natural vision and facilitate our understanding of goal-directed, active visual perception, a defining feature of human and non-human primate natural vision. A critical component of this project is the highly collaborative nature of the planned research. We expect great benefits from this interdisciplinary approach, which depends critically on computational models that strictly adhere to the known physiological and anatomical constraints to guide our neurophysiological experiments.     1. Training. The proposal includes a detailed training plan intended to facilitate international training of future modelers and neurophysiologists. Specifically, we will train students and post-doctoral researchers to be experts in both experimental and theoretical approaches in order to advance the field using the hybrid approach outlined in the proposal.    2. Education and Outreach. We plan to organize two in-depth workshops on attention and eye movements. These events (one in Germany and one in the US) will bring together investigators from other institutions and related scientific disciplines to advance the field. In addition investigators will organize and chair 1-2 workshops/symposia at annual meetings (e.g., SFN and COSYNE) during the funding period. Finally, we will participate in science education for underrepresented groups through Yale?s STARS program by providing training, research and mentoring opportunities in the Mazer lab.    3. Data Sharing. The software tools generated and behavioral and neurophysiological data collected during this project will be distributed to the neuroscience community to facilitate data mining and secondary analyses of experimental data.    4. Impact in other scientific fields. Efficient allocation of limited sensor resources is also a important problem faced by computer vision and robotics researchers. Understanding how the primate brain efficiently allocates visual resources using an active-sensing approach will guide development of biologically inspired computer vision algorithms and humanoid cognitive robots.    5. Translational Implications. Although the proposed research is not translational, there is a growing body of evidence suggesting that several clinically important conditions, including Autism Spectrum Disorder, Attention Deficit Hyperactivity Disorder and Schizophrenia, are associated with impaired behavioral links between saccade planning and visual attention. The proposed basic science studies could have significant implications for future translational research potentially leading to improved understanding disease etiology, development of early diagnostic tools and possible interventional strategies.              n/a",CRCNS: Model-driven single-neuron studies of cortical remapping,8837252,R01EY025103,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Cognitive', 'Collaborations', 'Communities', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Dorsal', 'Education and Outreach', 'Educational workshop', 'Environment', 'Etiology', 'Event', 'Experimental Designs', 'Eye Movements', 'Financial compensation', 'Funding', 'Future', 'Germany', 'Goals', 'Human', 'Hybrids', 'Institution', 'International', 'Intervention', 'Laboratories', 'Link', 'Mentors', 'Modeling', 'Monkeys', 'Motor', 'Nature', 'Neurons', 'Neurosciences', 'Performance', 'Physiological', 'Postdoctoral Fellow', 'Primates', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Retinal', 'Robot', 'Robotics', 'Saccades', 'Schizophrenia', 'Signal Transduction', 'Simulate', 'Software Tools', 'Stream', 'Students', 'Testing', 'Training', 'Translational Research', 'Underrepresented Minority', 'Update', 'Vision', 'Visual', 'Visual Perception', 'Visual attention', 'Work', 'area V4', 'autism spectrum disorder', 'awake', 'base', 'cell type', 'computer framework', 'data mining', 'data sharing', 'design', 'extrastriate visual cortex', 'improved', 'insight', 'interdisciplinary approach', 'meetings', 'neural circuit', 'neurophysiology', 'nonhuman primate', 'novel', 'oculomotor', 'programs', 'relating to nervous system', 'research study', 'science education', 'sensor', 'simulation', 'spatiotemporal', 'symposium', 'tool', 'vector', 'visual motor']",NEI,YALE UNIVERSITY,R01,2014,249750,0.040968688927859126
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.        This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8708870,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2014,348504,0.08378857585764227
"Visual Summary-Statistic Processing in Infancy     DESCRIPTION (provided by applicant): Part of the NICHD's mission is to support basic research in human development. The Developmental Cognitive Psychology, Behavioral Neuroscience, and Psychobiology program supports research to identify links between the developing brain and the environment. The proposed research has been designed to help us understand how the visual environment shapes infants' use of summary statistics to describe the things they see. A growing body of research suggests that adults summarize a great deal of visual information by describing the world with texture-like measurements - instead of measuring exactly what we saw and where we saw it, we often pool information together over large areas by measuring how simple features co-occur and forgetting about exactly where they came from. For some tasks, these kinds of descriptions are useful. In other cases, like recognizing a single object in clutter, they don't work well at all. Understanding the limits of these summary statistic descriptions of our visual world has given us insights into why adults sometimes find visual search difficult (Rosenholtz et al., 2012), why it's hard to recognize single objects in clutter (Balas et al., 2009), and may help us understand conditions like amblyopia or macular degeneration, where we think these kinds of summaries may be nearly all the visual system has to work with. In these studies, we will work with infants and adults to understand how summary-statistic descriptions are shaped by the visual environment. We will use computer graphics techniques to create artificial textures that are matched to natural textures using a model of the early visual system. Our goal is to determine how different artificial textures need to be from natural textures for infants to tell them apart. By using a computer graphics model, we can carefully control what information is available to tell the images apart, which will help us understand what measurements contribute to infants' summary-statistic descriptions as they get older. Further, we plan to measure how well infants can tell real textures apart from artificial ones by measuring how their brain responds to those images. We will use EEG to measure how the brain responds to different kinds of natural and artificial textures. Different neural response reflect different kinds of processing in the brain, and we plan to use the location and the timing of the differences we see in infants' brains to help us understand how summary statistics are applied. These studies support the NICHD's mission and will help us understand the perceptual difficulties that some children and adults have due to visual impairments that force summary statistics to be used all the time.         PUBLIC HEALTH RELEVANCE: The human visual system summarizes a great deal of what we see by measuring what we saw, but forgetting exactly where we saw it. This strategy is good for recognizing textures like wood or stone, but makes it difficult to recognize individual objects that have lots of clutter around them. We plan to study how infants recognize textures so we can understand how their visual system learns to summarize information this way, which will help us, understand some visual impairment that result from the visual system being forced to use summaries like this all the time.            ",Visual Summary-Statistic Processing in Infancy,8687212,R15EY024375,"['Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Algorithms', 'Amblyopia', 'Appearance', 'Area', 'Basic Science', 'Behavior', 'Behavioral', 'Behavioral Paradigm', 'Biological Models', 'Brain', 'Calculi', 'Characteristics', 'Child', 'Childhood', 'Cognitive Science', 'Complement', 'Computer Graphics', 'Computer Simulation', 'Crowding', 'Data', 'Development', 'Discrimination', 'Elderly', 'Electroencephalography', 'Environment', 'Event-Related Potentials', 'Exhibits', 'Exposure to', 'Face', 'Goals', 'Human', 'Human Development', 'Image', 'Individual', 'Infant', 'Learning', 'Life', 'Link', 'Location', 'Machine Learning', 'Macular degeneration', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Nature', 'Neurophysiology - biologic function', 'Neurosciences', 'Paired Comparison', 'Parents', 'Participant', 'Pattern', 'Pattern Recognition', 'Performance', 'Play', 'Process', 'Race', 'Relative (related person)', 'Research', 'Research Support', 'Role', 'Shapes', 'Signal Transduction', 'Stimulus', 'Techniques', 'Testing', 'Texture', 'Time', 'To specify', 'Variant', 'Visual', 'Visual Psychophysics', 'Visual impairment', 'Visual system structure', 'Vocabulary', 'Wood material', 'Work', 'base', 'design', 'deviant', 'experience', 'forgetting', 'infancy', 'insight', 'preference', 'programs', 'psychobiology', 'public health relevance', 'relating to nervous system', 'response', 'shape analysis', 'spatial integration', 'statistics', 'vision development', 'visual information', 'visual process', 'visual processing', 'visual search']",NEI,NORTH DAKOTA STATE UNIVERSITY,R15,2014,408066,-0.011274486628196813
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development     DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks.         PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.                ",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,8634272,K99HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Cognitive', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Near-Infrared Spectroscopy', 'Neonatology', 'Neural Pathways', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Population', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Williams Syndrome', 'aged', 'awake', 'base', 'comparison group', 'developmental disease', 'early experience', 'experience', 'hemodynamics', 'high risk', 'infancy', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,UNIVERSITY OF ROCHESTER,K99,2014,82417,0.04245675714815772
"Neural Basis of Shape from Texture     DESCRIPTION (provided by applicant): People often need to judge the shapes and movements of 3-D objects from a distance. Images on the retinae are 2-D, but pattern and motion information contain cues about 3-D shapes. Building on our previous work we expect to make significant progress in understanding 3-D shape perception from these cues, and thus offer a prototype for how the brain extracts information from the world to infer environmental properties. When surfaces have texture patterns, deformations of these patterns in retinal images provide clues for the brain to judge 3-D shape. When signals from the eyes reach the first cortical area V1, they are processed by neurons that are selectively tuned to orientations and spatial frequencies. We parsed texture deformations into orientation flows and spatial frequency gradients, to show that particular orientation flows evoke percepts of specific 3-D shapes, whereas frequency gradients provide cues to relative depth. These results led to models of how later cortical neurons could extract texture patterns and signal 3-D shapes. We now propose to extend our approach beyond static objects. When objects change shape (e.g. by bending, coiling, or contracting) as they move (e.g. walk, tumble, crawl, hop, slide, or swim), changes in the retinal image create patterns of local velocities that provide additional cues to 3-D shape. Since any retinal image can result from projections of many different 3-D objects, the brain relies on prior assumptions to infer the correct shape. Previous studies have only looked at rigid objects and used shape inference models based either on the brain assuming that the object is rigid or that faster points are nearer. We will use novel stimuli that put these prior assumptions in conflict, and thus examine how the brain potentiates a prior. This section will culminate in a model for choosing between conflicting assumptions, something that is often required in perception and cognition. Next, we will use randomly deforming non-rigid 3-D waves to examine how global shape properties, e.g. symmetry, influence perceived object motions by selectively combining disparate outputs of motion sensitive neurons. These results will unveil interactions between the form and motion cortical systems. Finally, we will examine observers' percepts of dynamic shape changes that require more sophisticated analyses of retinal velocity patterns. Neurons in the motion sensitive cortical area MT respond to 1-D motion shear and compression/divergence, so we will extract these qualities and combine them into 2-D velocity patterns of divergence, rotation, and deformation. Neural filters formed by these patterns will be used to explain perceived changes in 3-D shapes. We will base our filters on responses of MT and later cortical neurons to our stimuli, measured in a parallel project. We will thus present the first neural model that can explain observers' percepts of both rigid and non-rigid textured objects. The performance of our model will be compared against the best computer-vision models on motion-capture data from real deforming objects. We expect this project to introduce new ideas, methods and results for understanding visual perception of 3-D shapes and its deficits in neurological patients.          Shape is probably the most important cue for recognizing objects, so neurological disorders related to shape- perception would severely impair the ability of such patients to function autonomously. This project will identify how the brain constructs correct and incorrect shape percepts of 3-D objects from texture and motion information. In addition, people with amblyopia, strabismus and convergence-insufficiency often have deficient stereo vision, so they find texture and motion information to be particularly useful in perceiving 3-D shapes, hence our work on separating velocity information into object motion, object shape, and shape deformation may be particularly useful to these people.                ",Neural Basis of Shape from Texture,8658075,R01EY013312,"['3-Dimensional', 'Amblyopia', 'Attention', 'Bayesian Analysis', 'Biological', 'Brain', 'Cognition', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conflict (Psychology)', 'Contracts', 'Convergence Insufficiency', 'Cues', 'Data', 'Development', 'Discrimination', 'Eye', 'Eye Movements', 'Frequencies', 'Geometry', 'Head Movements', 'Image', 'Learning', 'Light', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Neurologic', 'Neurons', 'Output', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Property', 'Psychophysics', 'Relative (related person)', 'Resolution', 'Retina', 'Retinal', 'Rotation', 'Shapes', 'Signal Transduction', 'Simulate', 'Slide', 'Space Perception', 'Staging', 'Stimulus', 'Strabismus', 'Stream', 'Surface', 'Swimming', 'System', 'Testing', 'Texture', 'Translating', 'Variant', 'Vision', 'Visual', 'Visual Perception', 'Walking', 'Work', 'analog', 'area MT', 'area V1', 'base', 'design', 'movie', 'nervous system disorder', 'neural model', 'novel', 'object motion', 'object shape', 'prototype', 'relating to nervous system', 'research study', 'response', 'sample fixation']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2014,354693,0.06465365986902079
"Object Concepts Project Summary What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally. Narrative Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.",Object Concepts,8894845,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2014,70173,0.0522459238970067
"Object Concepts  Project Summary What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally.  Narrative Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.",Object Concepts,8723219,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2014,386042,0.0522459238970067
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.        PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8723146,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2014,341462,0.044237118220615566
"Neural Mechanisms of Fixation Choice while Searching Natural Scenes  The overall goal of these experiments is to understand how the brain controls where we look. To accomplish this, it is important to study brain activity and behavior under conditions that closely approximate those in the real world. All of the experiments we propose to do will use awake behaving rhesus monkeys as subjects. In prior work, we have studied activity in the cortical frontal eye field while monkeys looked at images of natural scenes. The frontal eye field (FEF) is closely involved in the control of purposive voluntary eye movements. While the monkey searched for a target hidden in the images of natural scenes, the activity of FEF neurons consisted of combinations of activity related to planning upcoming eye movements, as well as activity that was sensitive to salient visual features of the image. In parallel with the development of our understanding of how the brain controls eye movements, there have been substantial advances in our understanding of the features of natural images that guide both human and monkey eye movements. These behavioral studies are at the advanced level of being able to accurately predict patterns of eye movements. Our goal in this proposal is to take advantage of these advancements in predicting patterns of eye movements in natural environments to help us understand the brain events that are responsible for this behavior. We will focus upon neuron activity in the FEF due to its essential role in the control of voluntary eye movements. The proposal has 3 Aims each focused upon a different factor that is known to guide eye movements under natural conditions. Salience describes how different a small part of a visual scene is from the remainder of the scene based upon stimulus features such as color, contrast, shape, and orientation. Our first aim will define the effects that salience has upon FEF activity. In our second aim, we'll quantify the effects of relevance. Relevance refers to the importance of visual features for the task at hand; for example, if we're looking for a red target, the red items in the image will be more likely to attract our attention and ultimately be the target for an eye movement. Knowing the broad composition of a scene, a quality that is called scene gist, can tell us the places where an object is more likely to be found. For example, if we are looking for a bicycle, we are more likely to search the sidewalks and roadways of a street scene and ignore other places where bicycles are unlikely to be found. Our final aim will look for the effects of scene gist upon monkey behavior and the FEF activity driving that behavior. In addition to the brain recording experiments outlined above, a large part of our effort will be devoted to mathematical analysis and modeling of the behavioral and neuronal data we obtain. Our ultimate goal is to provide a model that predicts the contributions of salience, relevance, and gist to the activity of FEF neurons. The successful model will be a mathematical representation that predicts search-related activity in the FEF for both artificial and real world conditions.  Due to the known and expected similarities between monkey and human eye movement systems, these experiments provide a model for the functional organization of frontal eye field cortex in humans. The ability to make appropriate eye movements is a function that can be damaged by a number of diseases, including cerebral stroke, Alzheimer's, Parkinson's, and Schizophrenia. More specifically, deficits in the proper control of fixation during search of complex visual stimuli have been described in patients suffering from simultanagnosia, as well as in individuals with a diagnosis of autism spectrum disorder.",Neural Mechanisms of Fixation Choice while Searching Natural Scenes,8634100,R01EY021579,"['Accounting', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Appetitive Behavior', 'Area', 'Attention', 'Auditory area', 'Banana', 'Behavior', 'Behavioral', 'Bicycling', 'Brain', 'Color', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Elements', 'Environment', 'Event', 'Eye Movements', 'Financial compensation', 'Goals', 'Gray unit of radiation dose', 'Human', 'Image', 'Individual', 'Location', 'Macaca mulatta', 'Maps', 'Measures', 'Modeling', 'Monkeys', 'Nervous system structure', 'Neurons', 'Parkinson Disease', 'Patients', 'Pattern', 'Positioning Attribute', 'Primates', 'Property', 'Research', 'Rest', 'Retina', 'Role', 'Saccades', 'Schizophrenia', 'Shapes', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Trees', 'Visual', 'Visual Acuity', 'Visual Cortex', 'Visual system structure', 'Weight', 'Work', 'autism spectrum disorder', 'awake', 'base', 'driving behavior', 'expectation', 'frontal eye fields', 'interest', 'mathematical analysis', 'mathematical model', 'mind control', 'neuromechanism', 'research study', 'sample fixation', 'visual motor', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY,R01,2014,376478,0.05358535072597154
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8535775,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'undergraduate student', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2013,343780,0.09801998419373847
"CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation Interacting with the physical environment and manipulating objects is an essential part of daily life. This ability is lost in upper-limb amputees as well as patients with spinal cord injury, stroke, ALS and other movement disorders. These people know what they want to do as well as how they would do it if their arms were functional. If such knowledge is decoded and sent to a prosthetic arm (or to the patient's own arm fitted with functional electric stimulators) the lost motor function could be restored. The decoding is unlikely to be perfect however the brain can adapt to an imperfect decoder using real-time feedback. Several groups including ours have recently demonstrated that at least in principle this can be achieved. However, as is often the case in science, the initial work has been done in idealized conditions and its applicability to real-world usage scenarios remains an open question. The goal of this project is to bring movement control brain-machine interfaces (BMIs) closer to helping the people who need them, and at the same time exploit the rich datasets we collect in order to advance our understanding of sensorimotor control and learning. This will be accomplished by creating hybrid BMIs which exploit information from multiple sources, combined with modern algorithms from machine learning and automatic control. RELEVANCE (See instructions): Being able to interact with the physical environment and manipulate objects is an essential part of daily life. Brain-machine interfaces are one way to restore this ability to patients who have lost it. The proposed project will bring brain-machine interfaces closer to helping patients in real-worid object manipulation tasks.  n/a",CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8507287,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2013,240369,0.011129499872850196
"The Neural Bases of he Semantic Structure of Words and Concepts    DESCRIPTION (provided by applicant): This project proposes to discover the neural representation of some simple words and concepts. It uses newly developed machine learning techniques and dimension reduction methods applied to fMRI brain activation data that will be acquired in new experimental paradigms. This research approach has for the first time succeeded in identifying the content of individual human thoughts based on the pattern of brain activity. The initial published studies have demonstrated this capability in the case of concrete nouns and physical objects. This project proposes to expand the approach to a much larger set of different types of concepts and to examine the effect of the way the concept is presented (e.g. a written or spoken word, or a picture). The goal is to develop a comprehensive theory of how neural representations of meaning arise from the various brain systems that are used in interacting or considering the concept. An important secondary goal is to determine the degree of commonality of the neural representations across people.  The studies propose to examine the neural dimensions of meaning in three domains: (a) physical objects; (b) human traits, emotions, and interpersonal interactions; and (c) small numerical quantities. This set of semantic domains is expected to provide sufficient breadth to reveal some of the principle neural bases of semantic representation.  In contrast to the field of ""semantics"" (the study of the relation between words and their meanings), this project will help establish a new research area, neurosemantics, which is the study of the relation between words, thoughts, and their neural representations. The key assumption is that the underlying dimensions of meaning representation in the human brain are derived from basic neural systems. For example, one of the dimensions of representation of a physical object is how one physically interacts with or handles it. This dimension of representation is underpinned by a network of cortical areas that co-activate when one thinks about a physical object, and also when one actually handles the physical object. Other dimensions of neural representation similarly emerge when the concept is encountered. The studies will collectively identify the major dimensions of concept representation and relate them to networks of co-activating brain areas.  The cumulative knowledge from the completed project will provide the framework of a theory of how brain systems map onto the representation of the meaning of concepts. The theory will be applicable to understanding and designing therapies for neurological conditions in which the meanings of concepts are distorted, such as Alzheimer's Disease, Pick's Disease, semantic dementia, and autism. The resulting theory will be foundational in relating the representation of meaning to brain function.       PUBLIC HEALTH RELEVANCE: The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.            ",The Neural Bases of he Semantic Structure of Words and Concepts,8502360,R01MH029617,"['Accounting', 'Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Anomia', 'Area', 'Autistic Disorder', 'Brain', 'Brain Diseases', 'Characteristics', 'Conceptions', 'Data', 'Dimensions', 'Disease', 'Emotions', 'Factor Analysis', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Individual', 'Interpersonal Relations', 'Knowledge', 'Language', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Neurologic', 'Pattern', 'Personality Traits', 'Pick Disease of the Brain', 'Publishing', 'Research', 'Semantic Dementias', 'Semantics', 'Social Concepts', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'To specify', 'Writing', 'base', 'design', 'nervous system disorder', 'novel strategies', 'public health relevance', 'relating to nervous system', 'research study', 'sound', 'theories', 'therapy design', 'trait']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2013,323520,0.025309503805065105
"The gist of the space: A space centered approach to visual scene perception  Project Summary  Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.  Narrative The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.",The gist of the space: A space centered approach to visual scene perception,8416357,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2013,389686,0.06931210621217854
"Neural mechanisms of attentional priority for visual features and objects     DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions.          Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.                ",Neural mechanisms of attentional priority for visual features and objects,8502510,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2013,347698,0.06262221066995347
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.        This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8515424,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2013,337678,0.08378857585764227
"Neural Basis of Shape from Texture     DESCRIPTION (provided by applicant): People often need to judge the shapes and movements of 3-D objects from a distance. Images on the retinae are 2-D, but pattern and motion information contain cues about 3-D shapes. Building on our previous work we expect to make significant progress in understanding 3-D shape perception from these cues, and thus offer a prototype for how the brain extracts information from the world to infer environmental properties. When surfaces have texture patterns, deformations of these patterns in retinal images provide clues for the brain to judge 3-D shape. When signals from the eyes reach the first cortical area V1, they are processed by neurons that are selectively tuned to orientations and spatial frequencies. We parsed texture deformations into orientation flows and spatial frequency gradients, to show that particular orientation flows evoke percepts of specific 3-D shapes, whereas frequency gradients provide cues to relative depth. These results led to models of how later cortical neurons could extract texture patterns and signal 3-D shapes. We now propose to extend our approach beyond static objects. When objects change shape (e.g. by bending, coiling, or contracting) as they move (e.g. walk, tumble, crawl, hop, slide, or swim), changes in the retinal image create patterns of local velocities that provide additional cues to 3-D shape. Since any retinal image can result from projections of many different 3-D objects, the brain relies on prior assumptions to infer the correct shape. Previous studies have only looked at rigid objects and used shape inference models based either on the brain assuming that the object is rigid or that faster points are nearer. We will use novel stimuli that put these prior assumptions in conflict, and thus examine how the brain potentiates a prior. This section will culminate in a model for choosing between conflicting assumptions, something that is often required in perception and cognition. Next, we will use randomly deforming non-rigid 3-D waves to examine how global shape properties, e.g. symmetry, influence perceived object motions by selectively combining disparate outputs of motion sensitive neurons. These results will unveil interactions between the form and motion cortical systems. Finally, we will examine observers' percepts of dynamic shape changes that require more sophisticated analyses of retinal velocity patterns. Neurons in the motion sensitive cortical area MT respond to 1-D motion shear and compression/divergence, so we will extract these qualities and combine them into 2-D velocity patterns of divergence, rotation, and deformation. Neural filters formed by these patterns will be used to explain perceived changes in 3-D shapes. We will base our filters on responses of MT and later cortical neurons to our stimuli, measured in a parallel project. We will thus present the first neural model that can explain observers' percepts of both rigid and non-rigid textured objects. The performance of our model will be compared against the best computer-vision models on motion-capture data from real deforming objects. We expect this project to introduce new ideas, methods and results for understanding visual perception of 3-D shapes and its deficits in neurological patients.          Shape is probably the most important cue for recognizing objects, so neurological disorders related to shape- perception would severely impair the ability of such patients to function autonomously. This project will identify how the brain constructs correct and incorrect shape percepts of 3-D objects from texture and motion information. In addition, people with amblyopia, strabismus and convergence-insufficiency often have deficient stereo vision, so they find texture and motion information to be particularly useful in perceiving 3-D shapes, hence our work on separating velocity information into object motion, object shape, and shape deformation may be particularly useful to these people.                ",Neural Basis of Shape from Texture,8461562,R01EY013312,"['3-Dimensional', 'Amblyopia', 'Attention', 'Bayesian Analysis', 'Biological', 'Brain', 'Cognition', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conflict (Psychology)', 'Contracts', 'Convergence Insufficiency', 'Cues', 'Data', 'Development', 'Discrimination', 'Eye', 'Eye Movements', 'Frequencies', 'Head Movements', 'Humulus', 'Image', 'Learning', 'Light', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Neurologic', 'Neurons', 'Output', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Property', 'Psychophysics', 'Relative (related person)', 'Resolution', 'Retina', 'Retinal', 'Rotation', 'Shapes', 'Signal Transduction', 'Simulate', 'Slide', 'Space Perception', 'Staging', 'Stimulus', 'Strabismus', 'Stream', 'Surface', 'Swimming', 'System', 'Testing', 'Texture', 'Translating', 'Variant', 'Vision', 'Visual', 'Visual Perception', 'Walking', 'Work', 'analog', 'area MT', 'area V1', 'base', 'design', 'movie', 'nervous system disorder', 'neural model', 'novel', 'object motion', 'object shape', 'prototype', 'relating to nervous system', 'research study', 'response', 'sample fixation']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2013,342751,0.06465365986902079
"Object Concepts  Project Summary What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally.  Narrative Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.",Object Concepts,8537463,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2013,374225,0.0522459238970067
"Coding of auditory space in the avian brain DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding. The proposed research will test hypotheses based on human models, of how the auditory system computes  sound direction. This approach has the potential of providing new avenues for better understanding disorders  of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering,  mathematical formulations of brain processes can advance technology related to artificial intelligence and  neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea  could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8521234,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2013,324389,0.042318579551458575
"Neural Mechanisms of Fixation Choice while Searching Natural Scenes  The overall goal of these experiments is to understand how the brain controls where we look. To accomplish this, it is important to study brain activity and behavior under conditions that closely approximate those in the real world. All of the experiments we propose to do will use awake behaving rhesus monkeys as subjects. In prior work, we have studied activity in the cortical frontal eye field while monkeys looked at images of natural scenes. The frontal eye field (FEF) is closely involved in the control of purposive voluntary eye movements. While the monkey searched for a target hidden in the images of natural scenes, the activity of FEF neurons consisted of combinations of activity related to planning upcoming eye movements, as well as activity that was sensitive to salient visual features of the image. In parallel with the development of our understanding of how the brain controls eye movements, there have been substantial advances in our understanding of the features of natural images that guide both human and monkey eye movements. These behavioral studies are at the advanced level of being able to accurately predict patterns of eye movements. Our goal in this proposal is to take advantage of these advancements in predicting patterns of eye movements in natural environments to help us understand the brain events that are responsible for this behavior. We will focus upon neuron activity in the FEF due to its essential role in the control of voluntary eye movements. The proposal has 3 Aims each focused upon a different factor that is known to guide eye movements under natural conditions. Salience describes how different a small part of a visual scene is from the remainder of the scene based upon stimulus features such as color, contrast, shape, and orientation. Our first aim will define the effects that salience has upon FEF activity. In our second aim, we'll quantify the effects of relevance. Relevance refers to the importance of visual features for the task at hand; for example, if we're looking for a red target, the red items in the image will be more likely to attract our attention and ultimately be the target for an eye movement. Knowing the broad composition of a scene, a quality that is called scene gist, can tell us the places where an object is more likely to be found. For example, if we are looking for a bicycle, we are more likely to search the sidewalks and roadways of a street scene and ignore other places where bicycles are unlikely to be found. Our final aim will look for the effects of scene gist upon monkey behavior and the FEF activity driving that behavior. In addition to the brain recording experiments outlined above, a large part of our effort will be devoted to mathematical analysis and modeling of the behavioral and neuronal data we obtain. Our ultimate goal is to provide a model that predicts the contributions of salience, relevance, and gist to the activity of FEF neurons. The successful model will be a mathematical representation that predicts search-related activity in the FEF for both artificial and real world conditions.  Due to the known and expected similarities between monkey and human eye movement systems, these experiments provide a model for the functional organization of frontal eye field cortex in humans. The ability to make appropriate eye movements is a function that can be damaged by a number of diseases, including cerebral stroke, Alzheimer's, Parkinson's, and Schizophrenia. More specifically, deficits in the proper control of fixation during search of complex visual stimuli have been described in patients suffering from simultanagnosia, as well as in individuals with a diagnosis of autism spectrum disorder.",Neural Mechanisms of Fixation Choice while Searching Natural Scenes,8451290,R01EY021579,"['Accounting', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Appetitive Behavior', 'Area', 'Attention', 'Auditory area', 'Banana', 'Behavior', 'Behavioral', 'Behavioral Model', 'Bicycling', 'Brain', 'Color', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Elements', 'Environment', 'Event', 'Eye Movements', 'Financial compensation', 'Goals', 'Gray unit of radiation dose', 'Human', 'Image', 'Individual', 'Location', 'Macaca mulatta', 'Maps', 'Measures', 'Modeling', 'Monkeys', 'Nervous system structure', 'Neurons', 'Parkinson Disease', 'Patients', 'Pattern', 'Positioning Attribute', 'Primates', 'Property', 'Research', 'Rest', 'Retina', 'Role', 'Saccades', 'Schizophrenia', 'Shapes', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Trees', 'Visual', 'Visual Acuity', 'Visual Cortex', 'Visual system structure', 'Weight', 'Work', 'autism spectrum disorder', 'awake', 'base', 'driving behavior', 'expectation', 'frontal eye fields', 'interest', 'mind control', 'neuromechanism', 'research study', 'sample fixation', 'visual motor', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY,R01,2013,364955,0.05358535072597154
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8535310,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'undergraduate student', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2012,104373,0.09801998419373847
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8312499,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'undergraduate student', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2012,357385,0.09801998419373847
"CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation Interacting with the physical environment and manipulating objects is an essential part of daily life. This ability is lost in upper-limb amputees as well as patients with spinal cord injury, stroke, ALS and other movement disorders. These people know what they want to do as well as how they would do it if their arms were functional. If such knowledge is decoded and sent to a prosthetic arm (or to the patient's own arm fitted with functional electric stimulators) the lost motor function could be restored. The decoding is unlikely to be perfect however the brain can adapt to an imperfect decoder using real-time feedback. Several groups including ours have recently demonstrated that at least in principle this can be achieved. However, as is often the case in science, the initial work has been done in idealized conditions and its applicability to real-world usage scenarios remains an open question. The goal of this project is to bring movement control brain-machine interfaces (BMIs) closer to helping the people who need them, and at the same time exploit the rich datasets we collect in order to advance our understanding of sensorimotor control and learning. This will be accomplished by creating hybrid BMIs which exploit information from multiple sources, combined with modern algorithms from machine learning and automatic control. RELEVANCE (See instructions): Being able to interact with the physical environment and manipulate objects is an essential part of daily life. Brain-machine interfaces are one way to restore this ability to patients who have lost it. The proposed project will bring brain-machine interfaces closer to helping patients in real-worid object manipulation tasks.  n/a",CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8288148,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2012,250764,0.011129499872850196
"The Neural Bases of he Semantic Structure of Words and Concepts    DESCRIPTION (provided by applicant): This project proposes to discover the neural representation of some simple words and concepts. It uses newly developed machine learning techniques and dimension reduction methods applied to fMRI brain activation data that will be acquired in new experimental paradigms. This research approach has for the first time succeeded in identifying the content of individual human thoughts based on the pattern of brain activity. The initial published studies have demonstrated this capability in the case of concrete nouns and physical objects. This project proposes to expand the approach to a much larger set of different types of concepts and to examine the effect of the way the concept is presented (e.g. a written or spoken word, or a picture). The goal is to develop a comprehensive theory of how neural representations of meaning arise from the various brain systems that are used in interacting or considering the concept. An important secondary goal is to determine the degree of commonality of the neural representations across people.  The studies propose to examine the neural dimensions of meaning in three domains: (a) physical objects; (b) human traits, emotions, and interpersonal interactions; and (c) small numerical quantities. This set of semantic domains is expected to provide sufficient breadth to reveal some of the principle neural bases of semantic representation.  In contrast to the field of ""semantics"" (the study of the relation between words and their meanings), this project will help establish a new research area, neurosemantics, which is the study of the relation between words, thoughts, and their neural representations. The key assumption is that the underlying dimensions of meaning representation in the human brain are derived from basic neural systems. For example, one of the dimensions of representation of a physical object is how one physically interacts with or handles it. This dimension of representation is underpinned by a network of cortical areas that co-activate when one thinks about a physical object, and also when one actually handles the physical object. Other dimensions of neural representation similarly emerge when the concept is encountered. The studies will collectively identify the major dimensions of concept representation and relate them to networks of co-activating brain areas.  The cumulative knowledge from the completed project will provide the framework of a theory of how brain systems map onto the representation of the meaning of concepts. The theory will be applicable to understanding and designing therapies for neurological conditions in which the meanings of concepts are distorted, such as Alzheimer's Disease, Pick's Disease, semantic dementia, and autism. The resulting theory will be foundational in relating the representation of meaning to brain function.      PUBLIC HEALTH RELEVANCE: The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.              PROJECT NARRATIVE - RELEVANCE  The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.",The Neural Bases of he Semantic Structure of Words and Concepts,8269647,R01MH029617,"['Accounting', 'Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Anomia', 'Area', 'Autistic Disorder', 'Brain', 'Brain Diseases', 'Characteristics', 'Conceptions', 'Data', 'Dimensions', 'Disease', 'Emotions', 'Factor Analysis', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Individual', 'Interpersonal Relations', 'Knowledge', 'Language', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Neurologic', 'Pattern', 'Personality Traits', 'Pick Disease of the Brain', 'Publishing', 'Research', 'Semantic Dementias', 'Semantics', 'Social Concepts', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'To specify', 'Writing', 'base', 'design', 'nervous system disorder', 'novel strategies', 'public health relevance', 'relating to nervous system', 'research study', 'sound', 'theories', 'therapy design', 'trait']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2012,337001,0.019842864795372187
"The gist of the space: A space centered approach to visual scene perception  Project Summary  Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.  Narrative The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.",The gist of the space: A space centered approach to visual scene perception,8206519,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2012,409600,0.06931210621217854
"Neural mechanisms of attentional priority for visual features and objects     DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions.        PUBLIC HEALTH RELEVANCE: Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.                  Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.                ",Neural mechanisms of attentional priority for visual features and objects,8346020,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2012,360389,0.057256452494021004
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.       PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8305642,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2012,341462,0.044237118220615566
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.        This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8306867,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2012,355624,0.08378857585764227
"Perceptual Learning: Human vs. Optimal Bayesian Neural plasticity and perceptual learning are fundamental in the developmental stages of vision,  in attaining expertise in specialized perceptual tasks, and in recovery from brain injuries and low-  vision disorders. One important process in perceptual learning is the improvement in humans'  ability to use task-relevant (signal) information. Although there have been advances in the  understanding of the dynamics and algorithms mediating how humans optimize the selection of  task relevant visual information, little is known about how eye movement patterns vary with  practice and their impact in optimizing perceptual performance. Yet, in real world environments,  eye movements are a critical component of active vision as humans explore the visual scene to  make perceptual judgments. Understanding perceptual learning in human daily life requires  studying the mechanisms mediating the changes in the planning of eye movements with learning  and their contributions to optimizing perceptual performance. We hypothesize that two new  experimental paradigms with digitally designed visual stimuli, in conjunction with eye position  recording, and a newly developed foveated ideal observer and Bayesian learner will help  elucidate how humans learn to strategize their eye movements and the contributions of the  optimized sampling of the images to improvements in perceptual learning. The proposed work  will address the following questions: 1) Do humans use learned information about the statistical  properties of the visual stimuli and the requirements of the task at hand to strategize their eye  movements to optimize the foveal sampling of the visual scene and perceptual performance?; 2)  Do humans use knowledge of the varying resolution of their foveated visual system to optimally  learn to plan eye movements for a given set of visual stimuli and task?; 3) What are the  contributions of learning to strategize eye movements to the overall improvements in perceptual  performance in ecologically important tasks such as face recognition, object identification and  visual search?; 4) How do human fixation patterns and performance benefits from strategizing  eye movements compare to an optimal foveated observer and learner? The proposed work will  improve our understanding of the human neural algorithms mediating the dynamics of adult  perceptual learning during active vision for ecologically important tasks. The proposed  experimental protocols and theoretical developments will also provide a novel, powerful and  flexible framework with which other researchers can study eye movements and learning of  humans undergoing visual loss recovery as well as patients with learning disabilities. PUBLIC HEALTH RELEVANCE  The proposed work benefits public health by increasing our understanding of how  humans learn to move their eyes to potentially informative regions of the visual scene in  important daily tasks such as identifying faces or searching for objects. Thorough  understanding of these mechanisms in normal humans will allow identification of  learning anomalies in patients recovering from visual-loss or learning disabilities and  potentially develop tests to assess treatments.",Perceptual Learning: Human vs. Optimal Bayesian,8323947,R01EY015925,"['Accounting', 'Address', 'Adult', 'Algorithms', 'Amblyopia', 'Animals', 'Area', 'Behavior', 'Blindness', 'Brain Injuries', 'Brain imaging', 'Cells', 'Chin', 'Complex', 'Data', 'Detection', 'Development', 'Discrimination', 'Emotional', 'Emotions', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Frequencies', 'Funding', 'Goals', 'Gold', 'Health', 'Human', 'Image', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Learning', 'Learning Disabilities', 'Life', 'Literature', 'Location', 'Machine Learning', 'Macular degeneration', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Monitor', 'Nature', 'Neuronal Plasticity', 'Nose', 'Oral cavity', 'Patients', 'Pattern', 'Perceptual learning', 'Performance', 'Positioning Attribute', 'Process', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysiology', 'Public Health', 'Recording of previous events', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Retinal', 'Retinitis Pigmentosa', 'Role', 'Sampling', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Staging', 'Stimulus', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Work', 'active vision', 'area striata', 'design', 'experience', 'flexibility', 'gaze', 'ideal observer (Bayesian)', 'improved', 'interest', 'neurophysiology', 'novel', 'object recognition', 'oculomotor', 'prevent', 'relating to nervous system', 'sample fixation', 'tumor', 'visual information', 'visual performance', 'visual process', 'visual processing', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2012,281126,0.05712370826386495
"Neural Basis of Shape from Texture     DESCRIPTION (provided by applicant): People often need to judge the shapes and movements of 3-D objects from a distance. Images on the retinae are 2-D, but pattern and motion information contain cues about 3-D shapes. Building on our previous work we expect to make significant progress in understanding 3-D shape perception from these cues, and thus offer a prototype for how the brain extracts information from the world to infer environmental properties. When surfaces have texture patterns, deformations of these patterns in retinal images provide clues for the brain to judge 3-D shape. When signals from the eyes reach the first cortical area V1, they are processed by neurons that are selectively tuned to orientations and spatial frequencies. We parsed texture deformations into orientation flows and spatial frequency gradients, to show that particular orientation flows evoke percepts of specific 3-D shapes, whereas frequency gradients provide cues to relative depth. These results led to models of how later cortical neurons could extract texture patterns and signal 3-D shapes. We now propose to extend our approach beyond static objects. When objects change shape (e.g. by bending, coiling, or contracting) as they move (e.g. walk, tumble, crawl, hop, slide, or swim), changes in the retinal image create patterns of local velocities that provide additional cues to 3-D shape. Since any retinal image can result from projections of many different 3-D objects, the brain relies on prior assumptions to infer the correct shape. Previous studies have only looked at rigid objects and used shape inference models based either on the brain assuming that the object is rigid or that faster points are nearer. We will use novel stimuli that put these prior assumptions in conflict, and thus examine how the brain potentiates a prior. This section will culminate in a model for choosing between conflicting assumptions, something that is often required in perception and cognition. Next, we will use randomly deforming non-rigid 3-D waves to examine how global shape properties, e.g. symmetry, influence perceived object motions by selectively combining disparate outputs of motion sensitive neurons. These results will unveil interactions between the form and motion cortical systems. Finally, we will examine observers' percepts of dynamic shape changes that require more sophisticated analyses of retinal velocity patterns. Neurons in the motion sensitive cortical area MT respond to 1-D motion shear and compression/divergence, so we will extract these qualities and combine them into 2-D velocity patterns of divergence, rotation, and deformation. Neural filters formed by these patterns will be used to explain perceived changes in 3-D shapes. We will base our filters on responses of MT and later cortical neurons to our stimuli, measured in a parallel project. We will thus present the first neural model that can explain observers' percepts of both rigid and non-rigid textured objects. The performance of our model will be compared against the best computer-vision models on motion-capture data from real deforming objects. We expect this project to introduce new ideas, methods and results for understanding visual perception of 3-D shapes and its deficits in neurological patients.        PUBLIC HEALTH RELEVANCE: Shape is probably the most important cue for recognizing objects, so neurological disorders related to shape- perception would severely impair the ability of such patients to function autonomously. This project will identify how the brain constructs correct and incorrect shape percepts of 3-D objects from texture and motion information. In addition, people with amblyopia, strabismus and convergence-insufficiency often have deficient stereo vision, so they find texture and motion information to be particularly useful in perceiving 3-D shapes, hence our work on separating velocity information into object motion, object shape, and shape deformation may be particularly useful to these people.                  Shape is probably the most important cue for recognizing objects, so neurological disorders related to shape- perception would severely impair the ability of such patients to function autonomously. This project will identify how the brain constructs correct and incorrect shape percepts of 3-D objects from texture and motion information. In addition, people with amblyopia, strabismus and convergence-insufficiency often have deficient stereo vision, so they find texture and motion information to be particularly useful in perceiving 3-D shapes, hence our work on separating velocity information into object motion, object shape, and shape deformation may be particularly useful to these people.                ",Neural Basis of Shape from Texture,8293820,R01EY013312,"['3-Dimensional', 'Amblyopia', 'Attention', 'Bayesian Analysis', 'Biological', 'Brain', 'Cognition', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Conflict (Psychology)', 'Contracts', 'Convergence Insufficiency', 'Cues', 'Data', 'Development', 'Discrimination', 'Eye', 'Eye Movements', 'Frequencies', 'Head Movements', 'Humulus', 'Image', 'Learning', 'Light', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Movement', 'Neurologic', 'Neurons', 'Output', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Property', 'Psychophysiology', 'Relative (related person)', 'Resolution', 'Retina', 'Retinal', 'Rotation', 'Shapes', 'Signal Transduction', 'Simulate', 'Slide', 'Space Perception', 'Staging', 'Stimulus', 'Strabismus', 'Stream', 'Surface', 'Swimming', 'System', 'Testing', 'Texture', 'Translating', 'Variant', 'Vision', 'Visual', 'Visual Perception', 'Walking', 'Work', 'analog', 'area MT', 'area V1', 'base', 'design', 'movie', 'nervous system disorder', 'neural model', 'novel', 'object motion', 'object shape', 'prototype', 'relating to nervous system', 'research study', 'response', 'sample fixation']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2012,361932,0.06554863440421098
"Object Concepts  Project Summary What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally.  Narrative Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.",Object Concepts,8312494,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2012,393921,0.0522459238970067
"Neural Mechanisms of Fixation Choice while Searching Natural Scenes     DESCRIPTION (provided by applicant): The overall goal of these experiments is to understand how the brain controls where we look. To accomplish this, it is important to study brain activity and behavior under conditions that closely approximate those in the real world. All of the experiments we propose to do will use awake behaving rhesus monkeys as subjects. In prior work, we have studied activity in the cortical frontal eye field while monkeys looked at images of natural scenes. The frontal eye field (FEF) is closely involved in the control of purposive voluntary eye movements. While the monkey searched for a target hidden in the images of natural scenes, the activity of FEF neurons consisted of combinations of activity related to planning upcoming eye movements, as well as activity that was sensitive to salient visual features of the image. In parallel with the development of our understanding of how the brain controls eye movements, there have been substantial advances in our understanding of the features of natural images that guide both human and monkey eye movements. These behavioral studies are at the advanced level of being able to accurately predict patterns of eye movements. Our goal in this proposal is to take advantage of these advancements in predicting patterns of eye movements in natural environments to help us understand the brain events that are responsible for this behavior. We will focus upon neuron activity in the FEF due to its essential role in the control of voluntary eye movements. The proposal has 3 Aims each focused upon a different factor that is known to guide eye movements under natural conditions. Salience describes how different a small part of a visual scene is from the remainder of the scene based upon stimulus features such as color, contrast, shape, and orientation. Our first aim will define the effects that salience has upon FEF activity. In our second aim, we'll quantify the effects of relevance. Relevance refers to the importance of visual features for the task at hand; for example, if we're looking for a red target, the red items in the image will be more likely to attrat our attention and ultimately be the target for an eye movement. Knowing the broad composition of a scene, a quality that is called scene gist, can tell us the places where an object is more likely to be found. For example, if we are looking for a bicycle, we are more likely to search the sidewalks and roadways of a street scene and ignore other places where bicycles are unlikely to be found. Our final aim will look for the effects of scene gist upon monkey behavior and the FEF activity driving that behavior. In addition to the brain recording experiments outlined above, a large part of our effort will be devoted to mathematical analysis and modeling of the behavioral and neuronal data we obtain. Our ultimate goal is to provide a model that predicts the contributions of salience, relevance, and gist to the activity of FEF neurons. The successful model will be a mathematical representation that predicts search-related activity in the FEF for both artificial and real world conditions.        PUBLIC HEALTH RELEVANCE: Due to the known and expected similarities between monkey and human eye movement systems, these experiments provide a model for the functional organization of frontal eye field cortex in humans. The ability to make appropriate eye movements is a function that can be damaged by a number of diseases, including cerebral stroke, Alzheimer's, Parkinson's, and Schizophrenia. More specifically, deficits in the proper control of fixation during search of complex visual stimuli have been described in patients suffering from simultanagnosia, as well as in individuals with a diagnosis of autism spectrum disorder.                  Due to the known and expected similarities between monkey and human eye movement systems, these experiments provide a model for the functional organization of frontal eye field cortex in humans. The ability to make appropriate eye movements is a function that can be damaged by a number of diseases, including cerebral stroke, Alzheimer's, Parkinson's, and Schizophrenia. More specifically, deficits in the proper control of fixation during search of complex visual stimuli have been described in patients suffering from simultanagnosia, as well as in individuals with a diagnosis of autism spectrum disorder.                ",Neural Mechanisms of Fixation Choice while Searching Natural Scenes,8297707,R01EY021579,"['Accounting', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Appetitive Behavior', 'Area', 'Attention', 'Auditory area', 'Banana', 'Behavior', 'Behavioral', 'Behavioral Model', 'Bicycling', 'Brain', 'Color', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Elements', 'Environment', 'Event', 'Eye Movements', 'Financial compensation', 'Goals', 'Gray unit of radiation dose', 'Human', 'Image', 'Individual', 'Location', 'Macaca mulatta', 'Maps', 'Measures', 'Modeling', 'Monkeys', 'Nervous system structure', 'Neurons', 'Parkinson Disease', 'Patients', 'Pattern', 'Positioning Attribute', 'Primates', 'Property', 'Research', 'Rest', 'Retina', 'Role', 'Saccades', 'Schizophrenia', 'Shapes', 'Stimulus', 'Stroke', 'System', 'Testing', 'Time', 'Trees', 'Visual', 'Visual Acuity', 'Visual Cortex', 'Visual system structure', 'Weight', 'Work', 'autism spectrum disorder', 'awake', 'base', 'driving behavior', 'expectation', 'frontal eye fields', 'interest', 'mind control', 'neuromechanism', 'research study', 'sample fixation', 'visual motor', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY,R01,2012,397787,0.05287915703306454
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8255663,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'Students', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2011,372452,0.09801998419373847
"Cue Reliability and Depth Calibration During Space Perception    DESCRIPTION (provided by applicant): The long-term objective of the proposed work is to understand how learning by the visual system helps it to represent the immediate environment during perception. Because perception is accurate, we can know spatial layout: the shapes, orientations, sizes, and spatial locations of the objects and surfaces around us. But this accuracy requires that the visual system learn over time how best to interpret visual ""cues"". These cues are the signals from the environment that the visual system extracts from the retinal images that are informative about spatial layout. Known cues include binocular disparity, texture gradients, occlusion relations, motion parallax, and familiar size, to name a few. How do these cues come to be interpreted correctly? A fundamental problem is that visual cues are ambiguous. Even if cues could be measured exactly (which they cannot, the visual system being a physical device) there would still be different possible 3D interpretations for a given set of cues. As a result, the visual system is forced to operate probabilistically: the way things ""look"" to us reflects an implicit guess as to which interpretation of the cues is most likely to be correct. Each additional cue helps improve the guess. For example, the retinal image of a door could be interpreted as a vertical rectangle or as some other quadrilateral at a non-vertical orientation in space, and the shadow cues at the bottom of the door helps the system know that it's a vertical rectangle. What mechanisms do the visual system use to discern which cues are available for interpreting images correctly? The proposed work aims to answer this fundamental question about perceptual learning. It was recently shown that the visual system can detect and start using new cues for perception. This phenomenon can be studied in the laboratory using classical conditioning procedures that were previously developed to study learning in animals. In the proposed experiments, a model system is used to understand details about when this learning occurs and what is learned. The data will be compared to predictions based on older, analogous studies in the animal learning literature, and interpreted in the context of Bayesian statistical inference, especially machine learning theory. The proposed work benefits public health by characterizing the brain mechanisms that keep visual perception accurate. These mechanisms are at work in the many months during which a person with congenital cataracts learns to use vision after the cataracts are removed, and it is presumably these mechanisms that go awry when an individual with a family history of synesthesia or autism develops anomalous experience-dependent perceptual responses. Neurodegenerative diseases may disrupt visual learning, in which case visual learning tests could be used to detect disease; understanding the learning of new cues in human vision could lead to better computerized aids for the visually impaired; and knowing what causes a new cue to be learned could lead to new technologies for training people to perceive accurately in novel work environments.          n/a",Cue Reliability and Depth Calibration During Space Perception,8139754,R01EY013988,"['Address', 'Adult', 'Animal Behavior', 'Animals', 'Appearance', 'Autistic Disorder', 'Binocular Vision', 'Biological Models', 'Brain', 'Calibration', 'Cataract', 'Computer Vision Systems', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Family history of', 'Food', 'Funding', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Learning Disabilities', 'Literature', 'Location', 'Longevity', 'Machine Learning', 'Measures', 'Memory', 'Motion', 'Motion Perception', 'Names', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathology', 'Perception', 'Perceptual learning', 'Persons', 'Positioning Attribute', 'Primates', 'Procedures', 'Process', 'Public Health', 'Recruitment Activity', 'Research', 'Retinal', 'Reversal Learning', 'Rotation', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Source', 'Space Perception', 'Stimulus', 'Surface', 'System', 'Testing', 'Texture', 'Time', 'Training', 'Translations', 'Trust', 'Ursidae Family', 'Vision', 'Vision Disparity', 'Visual', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'Workplace', 'area MT', 'base', 'classical conditioning', 'clinical application', 'computerized', 'congenital cataract', 'design', 'devices for the visually impaired', 'experience', 'improved', 'meetings', 'neuromechanism', 'new technology', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'stereoscopic', 'theories', 'tool', 'visual information', 'visual learning', 'visual process', 'visual processing']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2011,219694,0.05263797747146718
"The Neural Bases of he Semantic Structure of Words and Concepts    DESCRIPTION (provided by applicant): This project proposes to discover the neural representation of some simple words and concepts. It uses newly developed machine learning techniques and dimension reduction methods applied to fMRI brain activation data that will be acquired in new experimental paradigms. This research approach has for the first time succeeded in identifying the content of individual human thoughts based on the pattern of brain activity. The initial published studies have demonstrated this capability in the case of concrete nouns and physical objects. This project proposes to expand the approach to a much larger set of different types of concepts and to examine the effect of the way the concept is presented (e.g. a written or spoken word, or a picture). The goal is to develop a comprehensive theory of how neural representations of meaning arise from the various brain systems that are used in interacting or considering the concept. An important secondary goal is to determine the degree of commonality of the neural representations across people.  The studies propose to examine the neural dimensions of meaning in three domains: (a) physical objects; (b) human traits, emotions, and interpersonal interactions; and (c) small numerical quantities. This set of semantic domains is expected to provide sufficient breadth to reveal some of the principle neural bases of semantic representation.  In contrast to the field of ""semantics"" (the study of the relation between words and their meanings), this project will help establish a new research area, neurosemantics, which is the study of the relation between words, thoughts, and their neural representations. The key assumption is that the underlying dimensions of meaning representation in the human brain are derived from basic neural systems. For example, one of the dimensions of representation of a physical object is how one physically interacts with or handles it. This dimension of representation is underpinned by a network of cortical areas that co-activate when one thinks about a physical object, and also when one actually handles the physical object. Other dimensions of neural representation similarly emerge when the concept is encountered. The studies will collectively identify the major dimensions of concept representation and relate them to networks of co-activating brain areas.  The cumulative knowledge from the completed project will provide the framework of a theory of how brain systems map onto the representation of the meaning of concepts. The theory will be applicable to understanding and designing therapies for neurological conditions in which the meanings of concepts are distorted, such as Alzheimer's Disease, Pick's Disease, semantic dementia, and autism. The resulting theory will be foundational in relating the representation of meaning to brain function.      PUBLIC HEALTH RELEVANCE: The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.              PROJECT NARRATIVE - RELEVANCE  The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.",The Neural Bases of he Semantic Structure of Words and Concepts,8150376,R01MH029617,"['Accounting', 'Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Anomia', 'Area', 'Autistic Disorder', 'Brain', 'Brain Diseases', 'Characteristics', 'Conceptions', 'Data', 'Dimensions', 'Disease', 'Emotions', 'Factor Analysis', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Individual', 'Interpersonal Relations', 'Knowledge', 'Language', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Neurologic', 'Pattern', 'Personality Traits', 'Pick Disease of the Brain', 'Publishing', 'Research', 'Semantic Dementias', 'Semantics', 'Social Concepts', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'To specify', 'Writing', 'base', 'design', 'nervous system disorder', 'novel strategies', 'public health relevance', 'relating to nervous system', 'research study', 'sound', 'theories', 'therapy design', 'trait']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2011,337001,0.019842864795372187
"The gist of the space: A space centered approach to visual scene perception    DESCRIPTION (provided by applicant): Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.      PUBLIC HEALTH RELEVANCE: The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.           The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.         ",The gist of the space: A space centered approach to visual scene perception,8039320,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2011,404890,0.06533703166863117
"Perceptual Learning: Human vs. Optimal Bayesian    DESCRIPTION (provided by applicant): Neural plasticity and perceptual learning are fundamental in the developmental stages of vision, in attaining expertise in specialized perceptual tasks, and in recovery from brain injuries and low- vision disorders. One important process in perceptual learning is the improvement in humans' ability to use task-relevant (signal) information. Although there have been advances in the understanding of the dynamics and algorithms mediating how humans optimize the selection of task relevant visual information, little is known about how eye movement patterns vary with practice and their impact in optimizing perceptual performance. Yet, in real world environments, eye movements are a critical component of active vision as humans explore the visual scene to make perceptual judgments. Understanding perceptual learning in human daily life requires studying the mechanisms mediating the changes in the planning of eye movements with learning and their contributions to optimizing perceptual performance. We hypothesize that two new experimental paradigms with digitally designed visual stimuli, in conjunction with eye position recording, and a newly developed foveated ideal observer and Bayesian learner will help elucidate how humans learn to strategize their eye movements and the contributions of the optimized sampling of the images to improvements in perceptual learning. The proposed work will address the following questions: 1) Do humans use learned information about the statistical properties of the visual stimuli and the requirements of the task at hand to strategize their eye movements to optimize the foveal sampling of the visual scene and perceptual performance?; 2) Do humans use knowledge of the varying resolution of their foveated visual system to optimally learn to plan eye movements for a given set of visual stimuli and task?; 3) What are the contributions of learning to strategize eye movements to the overall improvements in perceptual performance in ecologically important tasks such as face recognition, object identification and visual search?; 4) How do human fixation patterns and performance benefits from strategizing eye movements compare to an optimal foveated observer and learner? The proposed work will improve our understanding of the human neural algorithms mediating the dynamics of adult perceptual learning during active vision for ecologically important tasks. The proposed experimental protocols and theoretical developments will also provide a novel, powerful and flexible framework with which other researchers can study eye movements and learning of humans undergoing visual loss recovery as well as patients with learning disabilities.      PUBLIC HEALTH RELEVANCE: The proposed work benefits public health by increasing our understanding of how humans learn to move their eyes to potentially informative regions of the visual scene in important daily tasks such as identifying faces or searching for objects. Thorough understanding of these mechanisms in normal humans will allow identification of learning anomalies in patients recovering from visual-loss or learning disabilities and potentially develop tests to assess treatments.          PUBLIC HEALTH RELEVANCE  The proposed work benefits public health by increasing our understanding of how  humans learn to move their eyes to potentially informative regions of the visual scene in  important daily tasks such as identifying faces or searching for objects. Thorough  understanding of these mechanisms in normal humans will allow identification of  learning anomalies in patients recovering from visual-loss or learning disabilities and  potentially develop tests to assess treatments.",Perceptual Learning: Human vs. Optimal Bayesian,8123224,R01EY015925,"['Accounting', 'Address', 'Adult', 'Algorithms', 'Amblyopia', 'Animals', 'Area', 'Behavior', 'Blindness', 'Brain Injuries', 'Brain imaging', 'Cells', 'Chin', 'Complex', 'Data', 'Detection', 'Development', 'Discrimination', 'Emotional', 'Emotions', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Frequencies', 'Funding', 'Goals', 'Gold', 'Human', 'Image', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Learning', 'Learning Disabilities', 'Life', 'Literature', 'Location', 'Machine Learning', 'Macular degeneration', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Monitor', 'Nature', 'Neuronal Plasticity', 'Nose', 'Oral cavity', 'Patients', 'Pattern', 'Perceptual learning', 'Performance', 'Positioning Attribute', 'Process', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysiology', 'Public Health', 'Recording of previous events', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Retinal', 'Retinitis Pigmentosa', 'Role', 'Sampling', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Staging', 'Stimulus', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Work', 'active vision', 'area striata', 'design', 'experience', 'flexibility', 'gaze', 'ideal observer (Bayesian)', 'improved', 'interest', 'neurophysiology', 'novel', 'object recognition', 'oculomotor', 'prevent', 'public health relevance', 'relating to nervous system', 'sample fixation', 'tumor', 'visual information', 'visual performance', 'visual process', 'visual processing', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2011,281126,0.05961380212434013
"CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories    DESCRIPTION (provided by applicant): For over half a century, vision scientists have been decomposing visual scenes into simple, more tractable components in an attempt to understand how the brain accomplishes vision. Although this endeavor has revealed much about the specialized subsystems of vision, surprisingly little is know about how, or even where in the brain, we process scenes as a whole. How is it, for instance, that the brain determines whether it is looking at a forest or a city skyline? One reason for the paucity of research on this topic may be that the neural representation of a scene is likely to be highly distributed, a coding scheme not easily identified by many traditional neuroscience methods. The objective of the proposed research is to use a new method of analyzing functional magnetic resonance imaging (fMRI) data that is designed to leverage activity patterns across the brain, in order to better understand how the brain categorizes natural scenes. In particular, the project combines expertise from computer vision and neuroimaging by applying statistical pattern recognition algorithms to fMRI data to understand how the brain distinguishes between different categories of natural scene (e.g., a beach versus a highway). The proposed project will use and develop a statistical pattern recognition approach to fMRI analysis to accomplish three more specific objectives: (i) to identify the neural representation of natural scene categories, (ii) to identify the computational principles for forming and using the neural representation of natural scene categories, and (iii) to explore the effects of attention and expectation on natural scene categorization. The insights gained from these experiments will be verified in a computational model of natural scene perception, which in turn will generate predictions for future experiments. Intellectual Merit of the Proposed Activity: Although previous research has shown that humans can quickly and effortless categorize natural scenes, there is very little understanding of how this is accomplished in the brain. The research proposed here will significantly advance our understanding of how natural scenes are represented in the brain and begin to uncover the computational strategies the brain employs in quickly and accurately extracting the gist of a scene. Broader Impacts of the Proposed Activity: The highly interdisciplinary nature of the proposed research requires intense interactions among psychologists, neuroscientists, and computer vision researchers. As such, the project not only promises to increase communication among very different disciplines but it will also to provide doctoral students with truly interdisciplinary training. The PIs are committed to providing a highly interactive research environment, mentoring students across disciplines, and fostering the interdisciplinary approach to science in general. Moreover, two of the three PIs are women working in fields in which women are traditionally underrepresented and are committed to improving the representation and visibility of women in science. Finally, the principles derived from this project are likely to have implications beyond the domain of natural scene perception. By refining the pattern recognition algorithms and their application to fMRI data, the project will expand the set of tools available to neuroscientists wishing to study a whole host of complex human behaviors that likely depend on subtle but distributed patterns of activity in the brain.           n/a",CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories,8142855,R01EY019429,"['Algorithms', 'Attention', 'Behavior', 'Brain', 'Categories', 'Cities', 'Code', 'Commit', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Discipline', 'Environment', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Future', 'Human', 'Image Analysis', 'Location', 'Mentors', 'Methods', 'Nature', 'Neurosciences', 'Pattern', 'Pattern Recognition', 'Perception', 'Process', 'Psychologist', 'Research', 'Research Personnel', 'Scheme', 'Science', 'Scientist', 'Statistical Methods', 'Students', 'Training', 'Vision', 'Visual', 'Woman', 'Working Women', 'design', 'expectation', 'forest', 'improved', 'insight', 'interdisciplinary approach', 'neuroimaging', 'relating to nervous system', 'research study', 'tool', 'vision science']",NEI,STANFORD UNIVERSITY,R01,2011,311026,0.03373681191528414
CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation No abstract available n/a,CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8089310,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2011,252290,0.017483954520117948
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.       PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8196019,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2011,24900,0.044237118220615566
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.       PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8265019,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2011,341462,0.044237118220615566
"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",A Wireless Multiscale Distributed Interface to the Cortex,8110556,R01NS062031,"['Address', 'Advanced Development', 'Algorithms', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cavia', 'Cell physiology', 'Characteristics', 'Communication', 'Computer software', 'Custom', 'Data', 'Devices', 'Discipline', 'Disease', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Health', 'Human', 'Imaging technology', 'Implant', 'In Vitro', 'Investigation', 'Learning', 'Machine Learning', 'Mediating', 'Microelectrodes', 'Monitor', 'Motor', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Outcome', 'Paralysed', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Rattus', 'Research', 'Retinal', 'Rodent', 'Rodent Model', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Slice', 'Stimulus', 'Stream', 'System', 'Telemetry', 'Testing', 'Time', 'Wireless Technology', 'awake', 'base', 'brain cell', 'brain machine interface', 'clinical application', 'computerized data processing', 'data acquisition', 'data exchange', 'density', 'design', 'disability', 'implantation', 'improved', 'in vivo', 'information processing', 'microsystems', 'nervous system disorder', 'neural circuit', 'operation', 'prototype', 'quantum', 'relating to nervous system', 'response', 'subcutaneous', 'tool']",NINDS,MICHIGAN STATE UNIVERSITY,R01,2011,508860,-0.003928126135706011
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.      PUBLIC HEALTH RELEVANCE: This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.           This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8162573,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2011,362154,0.0866414797218023
"Object Concepts    DESCRIPTION (provided by applicant): What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally.      PUBLIC HEALTH RELEVANCE: Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.           Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.         ",Object Concepts,8130384,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2011,393921,0.05234872576557895
"Cue Reliability and Depth Calibration During Space Perception    DESCRIPTION (provided by applicant): The long-term objective of the proposed work is to understand how learning by the visual system helps it to represent the immediate environment during perception. Because perception is accurate, we can know spatial layout: the shapes, orientations, sizes, and spatial locations of the objects and surfaces around us. But this accuracy requires that the visual system learn over time how best to interpret visual ""cues"". These cues are the signals from the environment that the visual system extracts from the retinal images that are informative about spatial layout. Known cues include binocular disparity, texture gradients, occlusion relations, motion parallax, and familiar size, to name a few. How do these cues come to be interpreted correctly? A fundamental problem is that visual cues are ambiguous. Even if cues could be measured exactly (which they cannot, the visual system being a physical device) there would still be different possible 3D interpretations for a given set of cues. As a result, the visual system is forced to operate probabilistically: the way things ""look"" to us reflects an implicit guess as to which interpretation of the cues is most likely to be correct. Each additional cue helps improve the guess. For example, the retinal image of a door could be interpreted as a vertical rectangle or as some other quadrilateral at a non-vertical orientation in space, and the shadow cues at the bottom of the door helps the system know that it's a vertical rectangle. What mechanisms do the visual system use to discern which cues are available for interpreting images correctly? The proposed work aims to answer this fundamental question about perceptual learning. It was recently shown that the visual system can detect and start using new cues for perception. This phenomenon can be studied in the laboratory using classical conditioning procedures that were previously developed to study learning in animals. In the proposed experiments, a model system is used to understand details about when this learning occurs and what is learned. The data will be compared to predictions based on older, analogous studies in the animal learning literature, and interpreted in the context of Bayesian statistical inference, especially machine learning theory. The proposed work benefits public health by characterizing the brain mechanisms that keep visual perception accurate. These mechanisms are at work in the many months during which a person with congenital cataracts learns to use vision after the cataracts are removed, and it is presumably these mechanisms that go awry when an individual with a family history of synesthesia or autism develops anomalous experience-dependent perceptual responses. Neurodegenerative diseases may disrupt visual learning, in which case visual learning tests could be used to detect disease; understanding the learning of new cues in human vision could lead to better computerized aids for the visually impaired; and knowing what causes a new cue to be learned could lead to new technologies for training people to perceive accurately in novel work environments.          n/a",Cue Reliability and Depth Calibration During Space Perception,7911700,R01EY013988,"['Address', 'Adult', 'Animal Behavior', 'Animals', 'Appearance', 'Autistic Disorder', 'Binocular Vision', 'Biological Models', 'Brain', 'Calibration', 'Cataract', 'Computer Vision Systems', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Family history of', 'Food', 'Funding', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Learning Disabilities', 'Literature', 'Location', 'Longevity', 'Machine Learning', 'Measures', 'Memory', 'Motion', 'Motion Perception', 'Names', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathology', 'Perception', 'Perceptual learning', 'Persons', 'Positioning Attribute', 'Primates', 'Procedures', 'Process', 'Public Health', 'Recruitment Activity', 'Research', 'Retinal', 'Reversal Learning', 'Rotation', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Source', 'Space Perception', 'Stimulus', 'Surface', 'System', 'Testing', 'Texture', 'Time', 'Training', 'Translations', 'Trust', 'Ursidae Family', 'Vision', 'Vision Disparity', 'Visual', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'Workplace', 'area MT', 'base', 'classical conditioning', 'clinical application', 'computerized', 'congenital cataract', 'design', 'devices for the visually impaired', 'experience', 'improved', 'meetings', 'neuromechanism', 'new technology', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'stereoscopic', 'theories', 'tool', 'visual information', 'visual learning', 'visual process', 'visual processing']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2010,226559,0.05263797747146718
"The Neural Bases of he Semantic Structure of Words and Concepts    DESCRIPTION (provided by applicant): This project proposes to discover the neural representation of some simple words and concepts. It uses newly developed machine learning techniques and dimension reduction methods applied to fMRI brain activation data that will be acquired in new experimental paradigms. This research approach has for the first time succeeded in identifying the content of individual human thoughts based on the pattern of brain activity. The initial published studies have demonstrated this capability in the case of concrete nouns and physical objects. This project proposes to expand the approach to a much larger set of different types of concepts and to examine the effect of the way the concept is presented (e.g. a written or spoken word, or a picture). The goal is to develop a comprehensive theory of how neural representations of meaning arise from the various brain systems that are used in interacting or considering the concept. An important secondary goal is to determine the degree of commonality of the neural representations across people.  The studies propose to examine the neural dimensions of meaning in three domains: (a) physical objects; (b) human traits, emotions, and interpersonal interactions; and (c) small numerical quantities. This set of semantic domains is expected to provide sufficient breadth to reveal some of the principle neural bases of semantic representation.  In contrast to the field of ""semantics"" (the study of the relation between words and their meanings), this project will help establish a new research area, neurosemantics, which is the study of the relation between words, thoughts, and their neural representations. The key assumption is that the underlying dimensions of meaning representation in the human brain are derived from basic neural systems. For example, one of the dimensions of representation of a physical object is how one physically interacts with or handles it. This dimension of representation is underpinned by a network of cortical areas that co-activate when one thinks about a physical object, and also when one actually handles the physical object. Other dimensions of neural representation similarly emerge when the concept is encountered. The studies will collectively identify the major dimensions of concept representation and relate them to networks of co-activating brain areas.  The cumulative knowledge from the completed project will provide the framework of a theory of how brain systems map onto the representation of the meaning of concepts. The theory will be applicable to understanding and designing therapies for neurological conditions in which the meanings of concepts are distorted, such as Alzheimer's Disease, Pick's Disease, semantic dementia, and autism. The resulting theory will be foundational in relating the representation of meaning to brain function.      PUBLIC HEALTH RELEVANCE: The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.              PROJECT NARRATIVE - RELEVANCE  The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.",The Neural Bases of he Semantic Structure of Words and Concepts,8041788,R01MH029617,"['Accounting', 'Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Anomia', 'Area', 'Autistic Disorder', 'Brain', 'Brain Diseases', 'Characteristics', 'Conceptions', 'Data', 'Dimensions', 'Disease', 'Emotions', 'Factor Analysis', 'Functional Magnetic Resonance Imaging', 'Goals', 'Human', 'Individual', 'Interpersonal Relations', 'Knowledge', 'Language', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Neurologic', 'Pattern', 'Personality Traits', 'Pick Disease of the Brain', 'Publishing', 'Research', 'Semantic Dementias', 'Semantics', 'Social Concepts', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Thinking', 'Time', 'To specify', 'Writing', 'base', 'design', 'nervous system disorder', 'novel strategies', 'public health relevance', 'relating to nervous system', 'research study', 'sound', 'theories', 'therapy design', 'trait']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2010,340405,0.019842864795372187
"Towards cortical visual prosthetics    Description (provided by applicant): Visual object recognition is crucial for most everyday tasks including face identification, reading and navigation. In spite of the massive increase in computational power over the last two decades, a 3-year-old still outperforms the most sophisticated algorithms even in simple recognition tasks. Understanding the computations performed by the human visual system to recognize objects will have profound implications not only to understand the functions (and malfunction) of the cerebral cortex but also for developing visual prosthetic devices for the visually impaired. We combine neurophysiology, electrical stimulation and tools from machine learning to further our understanding of the neuronal circuits, algorithms and computations performed by the human visual system to perform visual pattern recognition. In the vast majority of visually impaired or blind people, the problems originate at the level of the retina while the visual cortex remains unimpaired. Our proposal constitutes a proof- of-principle approach towards developing visual prosthetic devices that rely on electrical stimulation of visual cortex. The specific aims of this proposal are designed to test the possibility of decoding and recoding information in visual cortex: (1) Read-out of visual information from human visual cortex on line (2) Write-in of visual information in human visual cortex. We take advantage of a rare opportunity to study the human brain at high spatial and temporal resolution by studying patients who have electrodes implanted for clinical reasons. Our electrophysiological recordings provide us with a unique view of the human temporal lobe circuitry and allow us to test the feasibility of cortical visual prosthetics in behaving human subjects. PUBLIC HEALTH RELEVANCE: Towards cortical visual prosthetics one of the key challenges for the visually impaired and blind people is the lack of visual object recognition capabilities. Visual recognition is crucial for most everyday tasks including navigation and face identification. Our proposal is a proof-of-principle approach towards the development of visual prosthetics devices based on electrical stimulation in visual cortex.           7. Project Narrative: Towards cortical visual prosthetics  One of the key challenges for the visually impaired and blind people is the lack of visual object recognition capabilities. Visual recognition is crucial for most everyday tasks including navigation and face identification. Our proposal is a proof-of-principle approach towards the development of visual prosthetics devices based on electrical stimulation in visual cortex.",Towards cortical visual prosthetics,7903931,R21EY019710,"['3 year old', 'Action Potentials', 'Algorithms', 'Animals', 'Auditory', 'Brain', 'Categories', 'Cerebral cortex', 'Clinical', 'Code', 'Computer software', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Electric Stimulation', 'Electrodes', 'Epilepsy', 'Face', 'Goals', 'Human', 'Implanted Electrodes', 'Inferior', 'Limb structure', 'Macaca', 'Machine Learning', 'Methodology', 'Methods', 'Monkeys', 'Neurons', 'Output', 'Patients', 'Perception', 'Physiological', 'Prosthesis', 'Reading', 'Recording of previous events', 'Reporting', 'Research Personnel', 'Resolution', 'Retina', 'Sensory', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Visual Pattern Recognition', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Wireless Technology', 'Writing', 'base', 'brain machine interface', 'design', 'devices for the visually impaired', 'human data', 'human subject', 'improved', 'interest', 'neural prosthesis', 'neurophysiology', 'object recognition', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'retinal prosthesis', 'tool', 'vision development', 'visual information']",NEI,BOSTON CHILDREN'S HOSPITAL,R21,2010,212644,0.09425713520841181
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7798636,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'disease diagnosis', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2010,35821,0.00223129673381824
"CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories    DESCRIPTION (provided by applicant): For over half a century, vision scientists have been decomposing visual scenes into simple, more tractable components in an attempt to understand how the brain accomplishes vision. Although this endeavor has revealed much about the specialized subsystems of vision, surprisingly little is know about how, or even where in the brain, we process scenes as a whole. How is it, for instance, that the brain determines whether it is looking at a forest or a city skyline? One reason for the paucity of research on this topic may be that the neural representation of a scene is likely to be highly distributed, a coding scheme not easily identified by many traditional neuroscience methods. The objective of the proposed research is to use a new method of analyzing functional magnetic resonance imaging (fMRI) data that is designed to leverage activity patterns across the brain, in order to better understand how the brain categorizes natural scenes. In particular, the project combines expertise from computer vision and neuroimaging by applying statistical pattern recognition algorithms to fMRI data to understand how the brain distinguishes between different categories of natural scene (e.g., a beach versus a highway). The proposed project will use and develop a statistical pattern recognition approach to fMRI analysis to accomplish three more specific objectives: (i) to identify the neural representation of natural scene categories, (ii) to identify the computational principles for forming and using the neural representation of natural scene categories, and (iii) to explore the effects of attention and expectation on natural scene categorization. The insights gained from these experiments will be verified in a computational model of natural scene perception, which in turn will generate predictions for future experiments. Intellectual Merit of the Proposed Activity: Although previous research has shown that humans can quickly and effortless categorize natural scenes, there is very little understanding of how this is accomplished in the brain. The research proposed here will significantly advance our understanding of how natural scenes are represented in the brain and begin to uncover the computational strategies the brain employs in quickly and accurately extracting the gist of a scene. Broader Impacts of the Proposed Activity: The highly interdisciplinary nature of the proposed research requires intense interactions among psychologists, neuroscientists, and computer vision researchers. As such, the project not only promises to increase communication among very different disciplines but it will also to provide doctoral students with truly interdisciplinary training. The PIs are committed to providing a highly interactive research environment, mentoring students across disciplines, and fostering the interdisciplinary approach to science in general. Moreover, two of the three PIs are women working in fields in which women are traditionally underrepresented and are committed to improving the representation and visibility of women in science. Finally, the principles derived from this project are likely to have implications beyond the domain of natural scene perception. By refining the pattern recognition algorithms and their application to fMRI data, the project will expand the set of tools available to neuroscientists wishing to study a whole host of complex human behaviors that likely depend on subtle but distributed patterns of activity in the brain.           n/a",CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories,7903878,R01EY019429,"['Algorithms', 'Attention', 'Behavior', 'Brain', 'Categories', 'Cities', 'Code', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Functional Magnetic Resonance Imaging', 'Goals', 'Human', 'Image', 'Image Analysis', 'Instruction', 'Life', 'Location', 'Methods', 'Neurosciences', 'Pattern', 'Pattern Recognition', 'Perception', 'Principal Investigator', 'Process', 'Research', 'Scheme', 'Scientist', 'Statistical Methods', 'Vision', 'Visual', 'Visual attention', 'Visual impairment', 'base', 'design', 'expectation', 'forest', 'neural prosthesis', 'neuroimaging', 'programs', 'relating to nervous system', 'tool', 'vision science', 'visual process', 'visual processing']",NEI,STANFORD UNIVERSITY,R01,2010,329525,0.03373681191528414
CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation No abstract available n/a,CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8055745,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Arts', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2010,256288,0.017483954520117948
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    IQ Engines' mobile visual search technology will enable the visually impaired to access real-time information about physical objects using their mobile phone camera. The mobile phone provides a visually-driven hyperlink between the physical and digital world: point the camera at an object and get information (for example product information or navigation information). The mobile phone camera is a powerful yet underutilized tool for the visually impaired. Our proposal has two specific aims. Working directly with the visually impaired community, we will build a prototype mobile visual search application that meets their accessibility and use requirements. Our second aim is to improve upon the state of the art for 3D object recognition. We will investigate a novel combination of sparse image representation, feature matching algorithm, and geometric verification in order to advance the performance of 3D object matching. While state-of-the-art image intelligence is robust enough to enable rapid and accurate image search of flat feature-rich objects, current computer vision pales in comparison to the abilities of biological vision systems to recognize 3-dimensional objects. Our underlying goal is to bring inspiration from recent advances in theoretical neuroscience and apply them to image and video search solutions.      PUBLIC HEALTH RELEVANCE:    Mobile visual search, using a cell phone camera to retrieve object information, enables a mobile phone camera to become an artificial 'eye' with object recognition intelligence. Implemented on a cell phone, a mobile visual search tool can be a low cost visual aid for the blind.           Mobile visual search, using a cell phone camera to retrieve object information, enables a mobile phone camera to become an artificial 'eye' with object recognition intelligence. Implemented on a cell phone, a mobile visual search tool can be a low cost visual aid for the blind.",Mobile Search for the Visually Impaired,7909025,R43EY019790,"['3-Dimensional', 'Algorithms', 'Arts', 'Biological', 'Breathing', 'Car Phone', 'Cellular Phone', 'Color', 'Communities', 'Computer Vision Systems', 'Databases', 'Feedback', 'Funding', 'Future', 'Goals', 'Image', 'Intelligence', 'Internet', 'Letters', 'Modeling', 'Neurosciences', 'Ocular Prosthesis', 'Performance', 'Research', 'Solutions', 'Speech Synthesizers', 'System', 'Technology', 'Text', 'Time', 'Vision', 'Visual', 'Visual Aid', 'Visual impairment', 'Work', 'base', 'blind', 'cost', 'digital', 'improved', 'meetings', 'novel', 'object recognition', 'prototype', 'public health relevance', 'technology development', 'tool', 'visual search']",NEI,"IQ ENGINES, INC.",R43,2010,138770,0.020560300938783527
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7765534,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2010,324963,0.02521857316422415
"Coding of auditory space in the avian brain    DESCRIPTION (provided by applicant): All auditory information used for sound localization ascends through the brainstem auditory nuclei. We will use physiological and theoretical approaches to understand how multidimensional features of sound, relevant to sound localization, are processed and encoded in the avian auditory brainstem. A primary advantage of using barn owls for the exploration of auditory processing is the substantial body of behavioral, anatomical and neurophysiological work that has elucidated the mechanisms of sound localization. The main cues owls use to compute sound direction are the interaural level difference (ILD) and the interaural time difference (ITD). Unlike mammals, owls use ILD to determine the vertical coordinate of the sound source and ITD to determine the horizontal coordinate. Two independent brainstem pathways process ITD and ILD and converge in the midbrain, where a spatiotopic map of auditory space emerges. Activity of neurons in the map precedes, and stimulation evokes, a head-orienting response towards the sound source. Thus, in barn owls, the neural algorithm for sound localization can be viewed as a system in which two input variables (ITD and ILD) are processed in parallel in order to control two output variables (horizontal and vertical coordinates of head saccades). We have used theoretical models to describe the neural responses that encode spatial information in the owl's auditory system. This approach has guided our experiments and aided the interpretation of our findings. Behavioral experiments in humans have used a similar approach to sound localization. However, due to a lack of neural data in humans, the predictive power of models of sound localization with regard to the neural bases of behavior has been a persistent question. Our studies in barn owls address this issue by investigating the mechanism of neural computations that are fundamental to models developed for human sound localization. This proposal is organized around three primary questions: 1) What are the computational primitives of auditory-space processing in the owl's brainstem? 2) How is spectrotemporal information encoded, transmitted and processed in parallel with spatial information? 3) What fundamental changes in information coding occur at the crossroads between the auditory midbrain and forebrain? We will address these questions using a wide range of strategies and techniques - intracellular in vivo recordings, cell-attached recording in vivo, multi-neuron tetrode recording, and modeling - which will make our approach interdisciplinary and of broad scope. Our research seeks to understand the function of the auditory brainstem and midbrain. In doing so, we will identify the types of information that are available to upstream nuclei and show how this information is encoded. A comprehensive approach to information processing in the auditory brainstem has the potential to provide new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to robotics and neural prosthetics. Cochlear implants that provide encoding of stimuli in ways that are more biologically relevant can be built, while devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves. By its differences and similarities with other species, the avian brain provides an excellent model system to define fundamental properties of neural processing and neural coding.       PUBLIC HEALTH RELEVANCE: The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.           The proposed research will test hypotheses based on human models, of how the auditory system computes sound direction. This approach has the potential of providing new avenues for better understanding disorders of the central auditory system and cognitive impairments involving hearing. By linking biology and engineering, mathematical formulations of brain processes can advance technology related to artificial intelligence and neural prosthetics; smarter cochlear implants can be built, as well as devices acting downstream of the cochlea could aid patients with compromised or non-functional auditory nerves.",Coding of auditory space in the avian brain,8040464,R01DC007690,"['Acoustic Nerve', 'Acoustics', 'Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Auditory', 'Auditory Physiology', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biological Models', 'Biology', 'Birds', 'Brain', 'Brain Stem', 'Cell Nucleus', 'Cells', 'Cochlea', 'Cochlear Implants', 'Cochlear nucleus', 'Code', 'Complex', 'Cues', 'Data', 'Devices', 'Dimensions', 'Disease', 'Drug Formulations', 'Ear', 'Engineering', 'Frequencies', 'Goals', 'Head', 'Hearing', 'Human', 'Impaired cognition', 'Inferior Colliculus', 'Lateral', 'Left', 'Link', 'Location', 'Mammals', 'Maps', 'Midbrain structure', 'Modeling', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Physiological', 'Population', 'Process', 'Property', 'Prosencephalon', 'Research', 'Robotics', 'Saccades', 'Scheme', 'Signal Transduction', 'Sound Localization', 'Source', 'Specialist', 'Staging', 'Stimulus', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thalamic Nuclei', 'Thalamic structure', 'Theoretical model', 'Time', 'Work', 'auditory nuclei', 'auditory pathway', 'base', 'in vivo', 'information processing', 'interdisciplinary approach', 'neural prosthesis', 'neuromechanism', 'neurophysiology', 'operation', 'receptive field', 'relating to nervous system', 'research study', 'response', 'sound', 'theories']",NIDCD,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2010,352750,0.044237118220615566
"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",A Wireless Multiscale Distributed Interface to the Cortex,7903986,R01NS062031,"['Address', 'Advanced Development', 'Algorithms', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cavia', 'Cell physiology', 'Characteristics', 'Communication', 'Computer software', 'Custom', 'Data', 'Devices', 'Discipline', 'Disease', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Imaging technology', 'Implant', 'In Vitro', 'Investigation', 'Learning', 'Machine Learning', 'Mediating', 'Microelectrodes', 'Monitor', 'Motor', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Outcome', 'Paralysed', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Rattus', 'Research', 'Retinal', 'Rodent', 'Rodent Model', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Slice', 'Stimulus', 'Stream', 'System', 'Telemetry', 'Testing', 'Time', 'Wireless Technology', 'awake', 'base', 'brain cell', 'brain machine interface', 'clinical application', 'computerized data processing', 'data acquisition', 'data exchange', 'density', 'design', 'disability', 'implantation', 'improved', 'in vivo', 'information processing', 'microsystems', 'nervous system disorder', 'neural circuit', 'operation', 'prototype', 'public health relevance', 'quantum', 'relating to nervous system', 'response', 'subcutaneous', 'tool']",NINDS,MICHIGAN STATE UNIVERSITY,R01,2010,511198,-0.003928126135706011
"Origins of Object Knowledge    DESCRIPTION (provided by applicant): Twelve experiments investigate the early development, in human infants, of perception of the unity of partly occluded surfaces. The experiments focus on a time during ontogeny when there may be evidence of visual sensitivity to information specifying object properties, but limited ability to perceive occlusion, with the goal of observing real-time processes by which the infant assembles visible parts of a stimulus into a coherent whole. This approach stipulates that onset of sensitivity to motion and orientation information, development of the oculomotor system, and experience viewing objects undergoing occlusion and disocclusion, play a direct, foundational role in the ontogeny of object perception. That is, there is an hypothesized period, 2 to 4 months of age, during which infants come to use newly-emerged visual skills to perceive objects accurately.   The experiments follow a similar strategy: explorations of individual and group differences in both basic visual processing skills and perception of the unity of partly occluded surfaces. Infant perception is assessed with two methods: (a) recording of eye movements, to measure improvements in pickup of important visual .information, and (b) habituation/dishabituation, to ascertain perception of object unity as well as to determine the extent of sensitivity to available visual information. It is expected that the detailed analysis of individual differences afforded by this approach provide the opportunity for exceptionally sensitive measures of the emergence of visual skills and object knowledge.   The short-term objectives of the present proposal are to elucidate fundamental developmental mechanisms in the context of the classic nature-nurture debate. The long-term goals are to shed light on the larger question of how knowledge is acquired and structured in the human, and how perceptual skills impact knowledge acquisition and structure. In the future, such understanding may aid in the formulation of diagnostics and treatments for some developmental disorders.         n/a",Origins of Object Knowledge,7783780,R01HD040432,"['Academy', 'Adult', 'Age', 'Age-Months', 'Birth', 'Budgets', 'Categories', 'Child Development', 'Cognition', 'Cognitive', 'Cognitive Science', 'Corpus striatum structure', 'Dependence', 'Dependency', 'Detection', 'Development', 'Diagnostic', 'Drug Formulations', 'Elderly', 'Event', 'Exhibits', 'Eye', 'Eye Movements', 'Failure', 'Fostering', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Growth', 'Heart', 'Human', 'Individual', 'Individual Differences', 'Infant', 'Infant Development', 'Investigation', 'Journals', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Learning', 'Legal patent', 'Light', 'Link', 'Literature', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Methods', 'Motion', 'Nature', 'Neurobiology', 'Pattern', 'Perception', 'Performance', 'Plant Roots', 'Play', 'Preparation', 'Process', 'Process Measure', 'Property', 'Psychology', 'Relative (related person)', 'Reporting', 'Research', 'Research Support', 'Resources', 'Role', 'Rotation', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Side', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Suggestion', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Vision', 'Visual', 'Visual attention', 'Visual system structure', 'Work', 'Writing', 'abstracting', 'base', 'developmental disease', 'experience', 'gaze', 'graduate student', 'indexing', 'infancy', 'information processing', 'meter', 'object perception', 'oculomotor', 'psychologic', 'research study', 'sequence learning', 'skills', 'spatiotemporal', 'symposium', 'theories', 'tool', 'trend', 'visual information', 'visual process', 'visual processing']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2010,270932,0.014245737840728134
"A Texture Analysis/Synthesis Model of Visual Crowding    DESCRIPTION (provided by applicant): Identifying a visual stimulus can be substantially impaired by the mere presence of additional stimuli in the immediate vicinity. This phenomenon is called ""crowding,"" and it powerfully limits visual perception in many circumstances, especially in the peripheral visual field. There is a rich body of literature detailing the phenomenology of crowding, but we do not know why crowding occurs. We lack a computational model that can predict what information will be available to an observer in an arbitrary crowded display. A popular hypothesis is that crowding results from obligatory ""texture processing,"" but there have been few efforts to formalize and test what this might mean, despite broad agreement that crowding reflects some form of ""excessive integration."" Dr. Rosenholtz has extensive experience with computational models of texture processing, which are a powerful means of defining the exact nature of ""texture processing"" and testing the ability of such models to explain and predict visual behavior. The proposed research has 3 aims: (1) To clarify and formalize the hypothesis that crowding is due to a ""texture"" - i.e. statistical -- representation of the crowded stimuli. (2) To collect behavioral data from a wider variety of displays and tasks than is typically studied in crowding. (3) To develop and validate the first general-purpose model of visual crowding. To achieve these aims, Dr. Rosenholtz will apply state-of-the-art computational tools for texture synthesis to ""crowded"" stimuli. ""Texturizing"" crowded arrays of stimuli affords a tool for visualizing the information available in a crowded display and a vocabulary for describing its representational content. Thus, Dr. Rosenholtz will attack the problem of crowding through a useful synthesis of computer graphics, computer vision, and psychophysics. PUBLIC HEALTH RELEVANCE: Understanding crowding, besides elucidating representations and performance of normal human vision, is crucial for disorders like age-related macular degeneration, for which, without foveal vision, virtually all perception is essentially crowded. In addition, percepts under crowding may be related to percepts under other visual dysfunctions where there is ""excessive integration"", such as amblyopia and simultagnosia. Successfully predicting crowding severity would also advance the design of low-vision aids for older adults and improve our ability to design for the visually-impaired.            Understanding crowding, besides elucidating representations and performance of normal human vision, is crucial for disorders like age-related macular degeneration, for which, without foveal vision, virtually all perception is essentially crowded. In addition, percepts under crowding may be related to percepts under other visual dysfunctions where there is ""excessive integration"", such as amblyopia and simultagnosia. Successfully predicting crowding severity would also advance the design of low-vision aids for older adults and improve our ability to design for the visually-impaired.",A Texture Analysis/Synthesis Model of Visual Crowding,7903934,R21EY019366,"['Age related macular degeneration', 'Agreement', 'Amblyopia', 'Area', 'Arts', 'Attention', 'Behavior', 'Behavioral', 'Binding', 'Cells', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Crowding', 'Data', 'Databases', 'Discrimination', 'Disease', 'Elderly', 'Eye Movements', 'Face', 'Failure', 'Functional disorder', 'Gender', 'Goals', 'Gray unit of radiation dose', 'Human', 'Imagery', 'Individual', 'Joints', 'Lesion', 'Letters', 'Literature', 'Location', 'Masks', 'Methods', 'Modeling', 'Nature', 'Patients', 'Perception', 'Performance', 'Peripheral', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Resolution', 'Saccades', 'Severities', 'Stimulus', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Vocabulary', 'Work', 'base', 'clinically significant', 'computerized tools', 'design', 'experience', 'improved', 'neglect', 'novel', 'object recognition', 'public health relevance', 'research study', 'response', 'statistics', 'theories', 'tool', 'vision aid', 'visual information', 'visual search', 'visual stimulus']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2010,166320,0.04948201679345376
"Perceptual Learning: Human vs. Optimal Bayesian    DESCRIPTION (provided by applicant): Neural plasticity and perceptual learning are fundamental in the developmental stages of vision, in attaining expertise in specialized perceptual tasks, and in recovery from brain injuries and low- vision disorders. One important process in perceptual learning is the improvement in humans' ability to use task-relevant (signal) information. Although there have been advances in the understanding of the dynamics and algorithms mediating how humans optimize the selection of task relevant visual information, little is known about how eye movement patterns vary with practice and their impact in optimizing perceptual performance. Yet, in real world environments, eye movements are a critical component of active vision as humans explore the visual scene to make perceptual judgments. Understanding perceptual learning in human daily life requires studying the mechanisms mediating the changes in the planning of eye movements with learning and their contributions to optimizing perceptual performance. We hypothesize that two new experimental paradigms with digitally designed visual stimuli, in conjunction with eye position recording, and a newly developed foveated ideal observer and Bayesian learner will help elucidate how humans learn to strategize their eye movements and the contributions of the optimized sampling of the images to improvements in perceptual learning. The proposed work will address the following questions: 1) Do humans use learned information about the statistical properties of the visual stimuli and the requirements of the task at hand to strategize their eye movements to optimize the foveal sampling of the visual scene and perceptual performance?; 2) Do humans use knowledge of the varying resolution of their foveated visual system to optimally learn to plan eye movements for a given set of visual stimuli and task?; 3) What are the contributions of learning to strategize eye movements to the overall improvements in perceptual performance in ecologically important tasks such as face recognition, object identification and visual search?; 4) How do human fixation patterns and performance benefits from strategizing eye movements compare to an optimal foveated observer and learner? The proposed work will improve our understanding of the human neural algorithms mediating the dynamics of adult perceptual learning during active vision for ecologically important tasks. The proposed experimental protocols and theoretical developments will also provide a novel, powerful and flexible framework with which other researchers can study eye movements and learning of humans undergoing visual loss recovery as well as patients with learning disabilities.      PUBLIC HEALTH RELEVANCE: The proposed work benefits public health by increasing our understanding of how humans learn to move their eyes to potentially informative regions of the visual scene in important daily tasks such as identifying faces or searching for objects. Thorough understanding of these mechanisms in normal humans will allow identification of learning anomalies in patients recovering from visual-loss or learning disabilities and potentially develop tests to assess treatments.          PUBLIC HEALTH RELEVANCE  The proposed work benefits public health by increasing our understanding of how  humans learn to move their eyes to potentially informative regions of the visual scene in  important daily tasks such as identifying faces or searching for objects. Thorough  understanding of these mechanisms in normal humans will allow identification of  learning anomalies in patients recovering from visual-loss or learning disabilities and  potentially develop tests to assess treatments.",Perceptual Learning: Human vs. Optimal Bayesian,7988249,R01EY015925,"['Accounting', 'Address', 'Adult', 'Algorithms', 'Amblyopia', 'Animals', 'Area', 'Behavior', 'Blindness', 'Brain Injuries', 'Brain imaging', 'Cells', 'Chin', 'Complex', 'Data', 'Detection', 'Development', 'Discrimination', 'Emotional', 'Emotions', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Frequencies', 'Funding', 'Goals', 'Gold', 'Hand', 'Human', 'Image', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Learning', 'Learning Disabilities', 'Life', 'Literature', 'Location', 'Machine Learning', 'Macular degeneration', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Monitor', 'Nature', 'Neuronal Plasticity', 'Nose', 'Oral cavity', 'Patients', 'Pattern', 'Perceptual learning', 'Performance', 'Positioning Attribute', 'Process', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysiology', 'Public Health', 'Recording of previous events', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Retinal', 'Retinitis Pigmentosa', 'Role', 'Sampling', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Staging', 'Stimulus', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Work', 'active vision', 'area striata', 'design', 'experience', 'flexibility', 'gaze', 'ideal observer (Bayesian)', 'improved', 'interest', 'neurophysiology', 'novel', 'object recognition', 'oculomotor', 'prevent', 'public health relevance', 'relating to nervous system', 'sample fixation', 'tumor', 'visual information', 'visual performance', 'visual process', 'visual processing', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2010,277974,0.05961380212434013
"Perceptual bases of visual concepts    DESCRIPTION (provided by applicant): Our general aim is to discover how the brain processes visual information, how neural activity is related to visual perception, and how visual processing interacts with other brain systems underlying cognition. Our specific aim is to elucidate how pigeons recognize and conceptualize visual stimuli. By studying the pigeon-a highly visual animal which can readily learn, but which does not have language or a mammalian neocortex and whose history can be carefully controlled and systematically varied-the processes of visual recognition and conceptualization may be more quickly and readily discovered. If the visual discrimination behavior of pigeons resembles that of humans, then the processes of conceptualization may be mediated by common neurobiological mechanisms which do not depend on linguistic competence or the human brain. The pigeon may become a powerful model system for both behavioral and biological studies of complex visual processing. Our proposal aims to see whether the perceptual processes of recognition and conceptualization are similar in humans and pigeons. Pigeons will be trained with several different operant conditioning procedures to discriminate line drawings and computer renderings of natural and artificial stimuli. The pigeons will later be tested with stimuli that: (1) degrade the training stimuli, (2) rearrange its parts, and (3) rotate the image in depth. These test stimuli produce highly specific effects in humans, which encourage the idea that object recognition is mediated by a structural description specifying a neural representation of the object's parts and the relations among those parts. If people and pigeons similarly process these various visual stimuli, then the results of our experiments with pigeons should parallel those with people. Empirical convergence would attest to the economy of nature and to the superfluity of language for visual recognition and conceptualization. Empirical divergence would imply that different neurobiological or linguistic mechanisms mediate visual recognition and conceptualization in people and pigeons. In either case, the results of this research project should shed considerable light on the basic mechanisms of visual recognition and conceptualization. Beyond the scientific significance of our proposed research, its health relevancy is considerable. Developing sound animal models of object recognition and conceptualization might better enable us to understand the behavioral and biological mechanisms of the human visual system in both health and disease. Effective animal models may also help pave the way for devising nonverbal diagnostic tests for assessing visual performance. In addition, comparing how pigeons and people recognize objects could provide new insights for computer and cognitive scientists to construct artificial devices which can recognize complex stimuli in the real world. Discovering how different biological systems accomplish the same adaptive feat might greatly help those attempting to create different artificial and prosthetic systems of object recognition. PUBLIC HEALTH RELEVANCE: The development of animal models of object recognition and visual conceptualization might better enable us to understand the behavioral and biological mechanisms of the human visual system in both health and disease. Effective animal models may also help pave the way for devising practical diagnostic tests for assessing visual performance; particularly important here is the fact that verbal behavior need not participate in such performance assessments, making nonverbal tests especially useful with infants, young children, and clinical populations. Our results should also advance our understanding of how the visual system develops and how to promote its regeneration after disease or injury.           Relevance to Public Health The development of animal models of object recognition and visual conceptualization might better enable us to understand the behavioral and biological mechanisms of the human visual system in both health and disease. Effective animal models may also help pave the way for devising practical diagnostic tests for assessing visual performance; particularly important here is the fact that verbal behavior need not participate in such performance assessments, making nonverbal tests especially useful with infants, young children, and clinical populations. Our results should also advance our understanding of how the visual system develops and how to promote its regeneration after disease or injury.",Perceptual bases of visual concepts,7924548,R01EY019781,"['Adaptive Behaviors', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Binding', 'Biological', 'Biological Models', 'Brain', 'Categories', 'Child', 'Classification', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Columbidae', 'Communities', 'Competence', 'Complex', 'Computer Vision Systems', 'Computers', 'Concept Formation', 'Development', 'Devices', 'Diagnostic tests', 'Discrimination', 'Discrimination Learning', 'Disease', 'Expert Systems', 'Health', 'Human', 'Image', 'Infant', 'Injury', 'Investigation', 'Iowa', 'Knowledge', 'Language', 'Learning', 'Light', 'Linguistics', 'Mediating', 'Methods', 'Natural regeneration', 'Nature', 'Neocortex', 'Neurobiology', 'Operant Conditioning', 'Organism', 'Perception', 'Performance', 'Phylogeny', 'Play', 'Population', 'Primates', 'Procedures', 'Process', 'Prosthesis', 'Psychological reinforcement', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Retinal', 'Role', 'Scientist', 'Shapes', 'Specific qualifier value', 'Stimulus', 'Stress', 'System', 'Teaching Method', 'Technology', 'Testing', 'Training', 'Universities', 'Variant', 'Verbal Behavior', 'Visual', 'Visual Perception', 'Visual system structure', 'Work', 'animal model development', 'base', 'biological systems', 'cognitive neuroscience', 'cooking', 'coping', 'experience', 'information processing', 'innovation', 'insight', 'member', 'neurobiological mechanism', 'novel', 'object recognition', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'sound', 'theories', 'two-dimensional', 'visual information', 'visual performance', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF IOWA,R01,2010,330471,0.09739712657590928
"Causal Perceptual Processing    DESCRIPTION (provided by applicant): The broad, long-term objectives of this research are to make original contributions to scientific understanding of biological perception. The specific aims are to: 1) develop and test a causal model of touch sensations' integration with visual sensations for perception, and to generalize this model for application to a broader class of sensory integration phenomena, 2) apply causal models to investigate how humans perceive cause-and-effect events, 3) increase the applicant's technical proficiency with causal modeling and applied machine learning methods. The proposal includes two main projects; the first will measure how humans judge the size of objects when their distances are uncertain. Specifically the first project examines the theory that human perception uses knowledge about how size and distance sensations are caused to integrate related sensations. Human experimental participants will view objects while touching them and report their perceptions of the objects' sizes, which will be used to evaluate theoretical predictions. The second project investigates how humans perceive cause-and-effect chains of events by examining the theory that the brain uses built-in knowledge of rudimentary physical behaviors, like momentum in collisions, to interpret such simple events. Human experimental participants will view colliding objects and report what occurred, which will again be used to evaluate theoretical predictions. PUBLIC HEALTH RELEVANCE: The public health relevance of this research is to increase scientific and medical understanding of the neural communication and processing strategies the brain employs to create perceptual experiences, so that people with perceptual impairments can be provided with effective rehabilitation programs and biotechnological substitutes for diminished capabilities. Specific impairments include blindness and low-vision, traumatic brain and nervous system injuries, and strokes. In particular, modern sensory prostheses are now using computerized components that can interface with neural pathways to more comprehensively and effectively restore normal abilities in patients, and whose development faces significant obstacles establishing effective communication channels with the biological nervous system.          n/a",Causal Perceptual Processing,7778287,F32EY019228,"['Algorithms', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological', 'Biological Process', 'Blindness', 'Brain', 'Cognition', 'Cognitive', 'Cognitive Science', 'Communication', 'Complex', 'Computational Technique', 'Computer Simulation', 'Decision Making', 'Development', 'Distance Perception', 'Economics', 'Elements', 'Esthesia', 'Etiology', 'Event', 'Face', 'Glass', 'Goals', 'Human', 'Image', 'Impairment', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Lifting', 'Machine Learning', 'Masks', 'Measures', 'Medical', 'Memory', 'Methods', 'Modeling', 'Nature', 'Nervous System Trauma', 'Nervous system structure', 'Neural Pathways', 'Neurosciences', 'Participant', 'Patients', 'Pattern', 'Perception', 'Plague', 'Preparation', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Science', 'Scientific Advances and Accomplishments', 'Semantics', 'Sensory', 'Sorting - Cell Movement', 'Space Perception', 'Stimulus', 'Stroke', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual impairment', 'Water', 'Work', 'abstracting', 'analytical method', 'computer monitor', 'computer science', 'computerized', 'experience', 'falls', 'haptics', 'insight', 'object perception', 'phrases', 'predictive modeling', 'programs', 'public health relevance', 'relating to nervous system', 'sensory integration', 'sensory prosthesis', 'skills', 'statistics', 'theories', 'tool']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2009,47210,0.041383902901998615
"Cue Reliability and Depth Calibration During Space Perception    DESCRIPTION (provided by applicant): The long-term objective of the proposed work is to understand how learning by the visual system helps it to represent the immediate environment during perception. Because perception is accurate, we can know spatial layout: the shapes, orientations, sizes, and spatial locations of the objects and surfaces around us. But this accuracy requires that the visual system learn over time how best to interpret visual ""cues"". These cues are the signals from the environment that the visual system extracts from the retinal images that are informative about spatial layout. Known cues include binocular disparity, texture gradients, occlusion relations, motion parallax, and familiar size, to name a few. How do these cues come to be interpreted correctly? A fundamental problem is that visual cues are ambiguous. Even if cues could be measured exactly (which they cannot, the visual system being a physical device) there would still be different possible 3D interpretations for a given set of cues. As a result, the visual system is forced to operate probabilistically: the way things ""look"" to us reflects an implicit guess as to which interpretation of the cues is most likely to be correct. Each additional cue helps improve the guess. For example, the retinal image of a door could be interpreted as a vertical rectangle or as some other quadrilateral at a non-vertical orientation in space, and the shadow cues at the bottom of the door helps the system know that it's a vertical rectangle. What mechanisms do the visual system use to discern which cues are available for interpreting images correctly? The proposed work aims to answer this fundamental question about perceptual learning. It was recently shown that the visual system can detect and start using new cues for perception. This phenomenon can be studied in the laboratory using classical conditioning procedures that were previously developed to study learning in animals. In the proposed experiments, a model system is used to understand details about when this learning occurs and what is learned. The data will be compared to predictions based on older, analogous studies in the animal learning literature, and interpreted in the context of Bayesian statistical inference, especially machine learning theory. The proposed work benefits public health by characterizing the brain mechanisms that keep visual perception accurate. These mechanisms are at work in the many months during which a person with congenital cataracts learns to use vision after the cataracts are removed, and it is presumably these mechanisms that go awry when an individual with a family history of synesthesia or autism develops anomalous experience-dependent perceptual responses. Neurodegenerative diseases may disrupt visual learning, in which case visual learning tests could be used to detect disease; understanding the learning of new cues in human vision could lead to better computerized aids for the visually impaired; and knowing what causes a new cue to be learned could lead to new technologies for training people to perceive accurately in novel work environments.          n/a",Cue Reliability and Depth Calibration During Space Perception,7692268,R01EY013988,"['Address', 'Adult', 'Animal Behavior', 'Animals', 'Appearance', 'Autistic Disorder', 'Binocular Vision', 'Biological Models', 'Brain', 'Calibration', 'Cataract', 'Computer Vision Systems', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Family history of', 'Food', 'Funding', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Learning Disabilities', 'Literature', 'Location', 'Longevity', 'Machine Learning', 'Measures', 'Memory', 'Motion', 'Motion Perception', 'Names', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathology', 'Perception', 'Perceptual learning', 'Persons', 'Positioning Attribute', 'Primates', 'Procedures', 'Process', 'Public Health', 'Recruitment Activity', 'Research', 'Retinal', 'Reversal Learning', 'Rotation', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Source', 'Space Perception', 'Stimulus', 'Surface', 'System', 'Testing', 'Texture', 'Time', 'Training', 'Translations', 'Trust', 'Ursidae Family', 'Vision', 'Vision Disparity', 'Visual', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'Workplace', 'area MT', 'base', 'classical conditioning', 'clinical application', 'computerized', 'congenital cataract', 'design', 'devices for the visually impaired', 'experience', 'improved', 'meetings', 'neuromechanism', 'new technology', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'stereoscopic', 'theories', 'tool', 'visual information', 'visual learning', 'visual process', 'visual processing']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2009,228847,0.05263797747146718
"Towards cortical visual prosthetics    Description (provided by applicant): Visual object recognition is crucial for most everyday tasks including face identification, reading and navigation. In spite of the massive increase in computational power over the last two decades, a 3-year-old still outperforms the most sophisticated algorithms even in simple recognition tasks. Understanding the computations performed by the human visual system to recognize objects will have profound implications not only to understand the functions (and malfunction) of the cerebral cortex but also for developing visual prosthetic devices for the visually impaired. We combine neurophysiology, electrical stimulation and tools from machine learning to further our understanding of the neuronal circuits, algorithms and computations performed by the human visual system to perform visual pattern recognition. In the vast majority of visually impaired or blind people, the problems originate at the level of the retina while the visual cortex remains unimpaired. Our proposal constitutes a proof- of-principle approach towards developing visual prosthetic devices that rely on electrical stimulation of visual cortex. The specific aims of this proposal are designed to test the possibility of decoding and recoding information in visual cortex: (1) Read-out of visual information from human visual cortex on line (2) Write-in of visual information in human visual cortex. We take advantage of a rare opportunity to study the human brain at high spatial and temporal resolution by studying patients who have electrodes implanted for clinical reasons. Our electrophysiological recordings provide us with a unique view of the human temporal lobe circuitry and allow us to test the feasibility of cortical visual prosthetics in behaving human subjects. PUBLIC HEALTH RELEVANCE: Towards cortical visual prosthetics one of the key challenges for the visually impaired and blind people is the lack of visual object recognition capabilities. Visual recognition is crucial for most everyday tasks including navigation and face identification. Our proposal is a proof-of-principle approach towards the development of visual prosthetics devices based on electrical stimulation in visual cortex.           7. Project Narrative: Towards cortical visual prosthetics  One of the key challenges for the visually impaired and blind people is the lack of visual object recognition capabilities. Visual recognition is crucial for most everyday tasks including navigation and face identification. Our proposal is a proof-of-principle approach towards the development of visual prosthetics devices based on electrical stimulation in visual cortex.",Towards cortical visual prosthetics,7701276,R21EY019710,"['3 year old', 'Action Potentials', 'Algorithms', 'Animals', 'Auditory', 'Brain', 'Categories', 'Cerebral cortex', 'Clinical', 'Code', 'Computer software', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Electric Stimulation', 'Electrodes', 'Epilepsy', 'Face', 'Goals', 'Human', 'Implanted Electrodes', 'Inferior', 'Limb structure', 'Macaca', 'Machine Learning', 'Methodology', 'Methods', 'Monkeys', 'Neurons', 'Output', 'Patients', 'Perception', 'Physiological', 'Prosthesis', 'Reading', 'Recording of previous events', 'Reporting', 'Research Personnel', 'Resolution', 'Retina', 'Sensory', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Visual Pattern Recognition', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Wireless Technology', 'Writing', 'base', 'brain machine interface', 'design', 'devices for the visually impaired', 'human data', 'human subject', 'improved', 'interest', 'neural prosthesis', 'neurophysiology', 'object recognition', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'retinal prosthesis', 'tool', 'vision development', 'visual information']",NEI,BOSTON CHILDREN'S HOSPITAL,R21,2009,247290,0.09425713520841181
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7616408,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'disease diagnosis', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2009,35821,0.00223129673381824
"CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories    DESCRIPTION (provided by applicant): For over half a century, vision scientists have been decomposing visual scenes into simple, more tractable components in an attempt to understand how the brain accomplishes vision. Although this endeavor has revealed much about the specialized subsystems of vision, surprisingly little is know about how, or even where in the brain, we process scenes as a whole. How is it, for instance, that the brain determines whether it is looking at a forest or a city skyline? One reason for the paucity of research on this topic may be that the neural representation of a scene is likely to be highly distributed, a coding scheme not easily identified by many traditional neuroscience methods. The objective of the proposed research is to use a new method of analyzing functional magnetic resonance imaging (fMRI) data that is designed to leverage activity patterns across the brain, in order to better understand how the brain categorizes natural scenes. In particular, the project combines expertise from computer vision and neuroimaging by applying statistical pattern recognition algorithms to fMRI data to understand how the brain distinguishes between different categories of natural scene (e.g., a beach versus a highway). The proposed project will use and develop a statistical pattern recognition approach to fMRI analysis to accomplish three more specific objectives: (i) to identify the neural representation of natural scene categories, (ii) to identify the computational principles for forming and using the neural representation of natural scene categories, and (iii) to explore the effects of attention and expectation on natural scene categorization. The insights gained from these experiments will be verified in a computational model of natural scene perception, which in turn will generate predictions for future experiments. Intellectual Merit of the Proposed Activity: Although previous research has shown that humans can quickly and effortless categorize natural scenes, there is very little understanding of how this is accomplished in the brain. The research proposed here will significantly advance our understanding of how natural scenes are represented in the brain and begin to uncover the computational strategies the brain employs in quickly and accurately extracting the gist of a scene. Broader Impacts of the Proposed Activity: The highly interdisciplinary nature of the proposed research requires intense interactions among psychologists, neuroscientists, and computer vision researchers. As such, the project not only promises to increase communication among very different disciplines but it will also to provide doctoral students with truly interdisciplinary training. The PIs are committed to providing a highly interactive research environment, mentoring students across disciplines, and fostering the interdisciplinary approach to science in general. Moreover, two of the three PIs are women working in fields in which women are traditionally underrepresented and are committed to improving the representation and visibility of women in science. Finally, the principles derived from this project are likely to have implications beyond the domain of natural scene perception. By refining the pattern recognition algorithms and their application to fMRI data, the project will expand the set of tools available to neuroscientists wishing to study a whole host of complex human behaviors that likely depend on subtle but distributed patterns of activity in the brain.           n/a",CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories,8034955,R01EY019429,"['Algorithms', 'Attention', 'Behavior', 'Brain', 'Categories', 'Cities', 'Code', 'Commit', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Discipline', 'Environment', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Future', 'Human', 'Image Analysis', 'Location', 'Mentors', 'Methods', 'Nature', 'Neurosciences', 'Pattern', 'Pattern Recognition', 'Perception', 'Process', 'Psychologist', 'Research', 'Research Personnel', 'Scheme', 'Science', 'Scientist', 'Statistical Methods', 'Students', 'Training', 'Vision', 'Visual', 'Woman', 'Working Women', 'design', 'expectation', 'forest', 'improved', 'insight', 'interdisciplinary approach', 'neuroimaging', 'relating to nervous system', 'research study', 'tool', 'vision science']",NEI,STANFORD UNIVERSITY,R01,2009,329608,0.03373681191528414
"CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories    DESCRIPTION (provided by applicant): For over half a century, vision scientists have been decomposing visual scenes into simple, more tractable components in an attempt to understand how the brain accomplishes vision. Although this endeavor has revealed much about the specialized subsystems of vision, surprisingly little is know about how, or even where in the brain, we process scenes as a whole. How is it, for instance, that the brain determines whether it is looking at a forest or a city skyline? One reason for the paucity of research on this topic may be that the neural representation of a scene is likely to be highly distributed, a coding scheme not easily identified by many traditional neuroscience methods. The objective of the proposed research is to use a new method of analyzing functional magnetic resonance imaging (fMRI) data that is designed to leverage activity patterns across the brain, in order to better understand how the brain categorizes natural scenes. In particular, the project combines expertise from computer vision and neuroimaging by applying statistical pattern recognition algorithms to fMRI data to understand how the brain distinguishes between different categories of natural scene (e.g., a beach versus a highway). The proposed project will use and develop a statistical pattern recognition approach to fMRI analysis to accomplish three more specific objectives: (i) to identify the neural representation of natural scene categories, (ii) to identify the computational principles for forming and using the neural representation of natural scene categories, and (iii) to explore the effects of attention and expectation on natural scene categorization. The insights gained from these experiments will be verified in a computational model of natural scene perception, which in turn will generate predictions for future experiments. Intellectual Merit of the Proposed Activity: Although previous research has shown that humans can quickly and effortless categorize natural scenes, there is very little understanding of how this is accomplished in the brain. The research proposed here will significantly advance our understanding of how natural scenes are represented in the brain and begin to uncover the computational strategies the brain employs in quickly and accurately extracting the gist of a scene. Broader Impacts of the Proposed Activity: The highly interdisciplinary nature of the proposed research requires intense interactions among psychologists, neuroscientists, and computer vision researchers. As such, the project not only promises to increase communication among very different disciplines but it will also to provide doctoral students with truly interdisciplinary training. The PIs are committed to providing a highly interactive research environment, mentoring students across disciplines, and fostering the interdisciplinary approach to science in general. Moreover, two of the three PIs are women working in fields in which women are traditionally underrepresented and are committed to improving the representation and visibility of women in science. Finally, the principles derived from this project are likely to have implications beyond the domain of natural scene perception. By refining the pattern recognition algorithms and their application to fMRI data, the project will expand the set of tools available to neuroscientists wishing to study a whole host of complex human behaviors that likely depend on subtle but distributed patterns of activity in the brain.           n/a",CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories,7667248,R01EY019429,"['Algorithms', 'Attention', 'Behavior', 'Brain', 'Categories', 'Cities', 'Code', 'Commit', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Discipline', 'Environment', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Future', 'Human', 'Image Analysis', 'Location', 'Mentors', 'Methods', 'Nature', 'Neurosciences', 'Pattern', 'Pattern Recognition', 'Perception', 'Process', 'Psychologist', 'Research', 'Research Personnel', 'Scheme', 'Science', 'Scientist', 'Statistical Methods', 'Students', 'Training', 'Vision', 'Visual', 'Woman', 'Working Women', 'design', 'expectation', 'forest', 'improved', 'insight', 'interdisciplinary approach', 'neuroimaging', 'relating to nervous system', 'research study', 'tool', 'vision science']",NEI,PRINCETON UNIVERSITY,R01,2009,1,0.03373681191528414
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7583948,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2009,328593,0.02521857316422415
"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",A Wireless Multiscale Distributed Interface to the Cortex,7670296,R01NS062031,"['Address', 'Advanced Development', 'Algorithms', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cavia', 'Cell physiology', 'Characteristics', 'Communication', 'Computer software', 'Custom', 'Data', 'Devices', 'Discipline', 'Disease', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Imaging technology', 'Implant', 'In Vitro', 'Investigation', 'Learning', 'Machine Learning', 'Mediating', 'Microelectrodes', 'Monitor', 'Motor', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Outcome', 'Paralysed', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Rattus', 'Research', 'Retinal', 'Rodent', 'Rodent Model', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Slice', 'Stimulus', 'Stream', 'System', 'Telemetry', 'Testing', 'Time', 'Wireless Technology', 'awake', 'base', 'brain cell', 'brain machine interface', 'clinical application', 'computerized data processing', 'data acquisition', 'data exchange', 'density', 'design', 'disability', 'implantation', 'improved', 'in vivo', 'information processing', 'microsystems', 'nervous system disorder', 'neural circuit', 'prototype', 'public health relevance', 'quantum', 'relating to nervous system', 'response', 'subcutaneous', 'tool']",NINDS,MICHIGAN STATE UNIVERSITY,R01,2009,515852,-0.003928126135706011
"A Texture Analysis/Synthesis Model of Visual Crowding    DESCRIPTION (provided by applicant): Identifying a visual stimulus can be substantially impaired by the mere presence of additional stimuli in the immediate vicinity. This phenomenon is called ""crowding,"" and it powerfully limits visual perception in many circumstances, especially in the peripheral visual field. There is a rich body of literature detailing the phenomenology of crowding, but we do not know why crowding occurs. We lack a computational model that can predict what information will be available to an observer in an arbitrary crowded display. A popular hypothesis is that crowding results from obligatory ""texture processing,"" but there have been few efforts to formalize and test what this might mean, despite broad agreement that crowding reflects some form of ""excessive integration."" Dr. Rosenholtz has extensive experience with computational models of texture processing, which are a powerful means of defining the exact nature of ""texture processing"" and testing the ability of such models to explain and predict visual behavior. The proposed research has 3 aims: (1) To clarify and formalize the hypothesis that crowding is due to a ""texture"" - i.e. statistical -- representation of the crowded stimuli. (2) To collect behavioral data from a wider variety of displays and tasks than is typically studied in crowding. (3) To develop and validate the first general-purpose model of visual crowding. To achieve these aims, Dr. Rosenholtz will apply state-of-the-art computational tools for texture synthesis to ""crowded"" stimuli. ""Texturizing"" crowded arrays of stimuli affords a tool for visualizing the information available in a crowded display and a vocabulary for describing its representational content. Thus, Dr. Rosenholtz will attack the problem of crowding through a useful synthesis of computer graphics, computer vision, and psychophysics. PUBLIC HEALTH RELEVANCE: Understanding crowding, besides elucidating representations and performance of normal human vision, is crucial for disorders like age-related macular degeneration, for which, without foveal vision, virtually all perception is essentially crowded. In addition, percepts under crowding may be related to percepts under other visual dysfunctions where there is ""excessive integration"", such as amblyopia and simultagnosia. Successfully predicting crowding severity would also advance the design of low-vision aids for older adults and improve our ability to design for the visually-impaired.            Understanding crowding, besides elucidating representations and performance of normal human vision, is crucial for disorders like age-related macular degeneration, for which, without foveal vision, virtually all perception is essentially crowded. In addition, percepts under crowding may be related to percepts under other visual dysfunctions where there is ""excessive integration"", such as amblyopia and simultagnosia. Successfully predicting crowding severity would also advance the design of low-vision aids for older adults and improve our ability to design for the visually-impaired.",A Texture Analysis/Synthesis Model of Visual Crowding,7740891,R21EY019366,"['Age related macular degeneration', 'Agreement', 'Amblyopia', 'Area', 'Arts', 'Attention', 'Behavior', 'Behavioral', 'Binding', 'Cells', 'Classification', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Crowding', 'Data', 'Databases', 'Discrimination', 'Disease', 'Elderly', 'Eye Movements', 'Face', 'Failure', 'Functional disorder', 'Gender', 'Goals', 'Gray unit of radiation dose', 'Human', 'Imagery', 'Individual', 'Joints', 'Lesion', 'Letters', 'Literature', 'Location', 'Masks', 'Methods', 'Modeling', 'Nature', 'Patients', 'Perception', 'Performance', 'Peripheral', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Resolution', 'Saccades', 'Severities', 'Stimulus', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Vocabulary', 'Work', 'base', 'clinically significant', 'computerized tools', 'design', 'experience', 'improved', 'neglect', 'novel', 'object recognition', 'public health relevance', 'research study', 'response', 'statistics', 'theories', 'tool', 'vision aid', 'visual information', 'visual search', 'visual stimulus']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2009,168000,0.04948201679345376
"Perceptual bases of visual concepts    DESCRIPTION (provided by applicant): Our general aim is to discover how the brain processes visual information, how neural activity is related to visual perception, and how visual processing interacts with other brain systems underlying cognition. Our specific aim is to elucidate how pigeons recognize and conceptualize visual stimuli. By studying the pigeon-a highly visual animal which can readily learn, but which does not have language or a mammalian neocortex and whose history can be carefully controlled and systematically varied-the processes of visual recognition and conceptualization may be more quickly and readily discovered. If the visual discrimination behavior of pigeons resembles that of humans, then the processes of conceptualization may be mediated by common neurobiological mechanisms which do not depend on linguistic competence or the human brain. The pigeon may become a powerful model system for both behavioral and biological studies of complex visual processing. Our proposal aims to see whether the perceptual processes of recognition and conceptualization are similar in humans and pigeons. Pigeons will be trained with several different operant conditioning procedures to discriminate line drawings and computer renderings of natural and artificial stimuli. The pigeons will later be tested with stimuli that: (1) degrade the training stimuli, (2) rearrange its parts, and (3) rotate the image in depth. These test stimuli produce highly specific effects in humans, which encourage the idea that object recognition is mediated by a structural description specifying a neural representation of the object's parts and the relations among those parts. If people and pigeons similarly process these various visual stimuli, then the results of our experiments with pigeons should parallel those with people. Empirical convergence would attest to the economy of nature and to the superfluity of language for visual recognition and conceptualization. Empirical divergence would imply that different neurobiological or linguistic mechanisms mediate visual recognition and conceptualization in people and pigeons. In either case, the results of this research project should shed considerable light on the basic mechanisms of visual recognition and conceptualization. Beyond the scientific significance of our proposed research, its health relevancy is considerable. Developing sound animal models of object recognition and conceptualization might better enable us to understand the behavioral and biological mechanisms of the human visual system in both health and disease. Effective animal models may also help pave the way for devising nonverbal diagnostic tests for assessing visual performance. In addition, comparing how pigeons and people recognize objects could provide new insights for computer and cognitive scientists to construct artificial devices which can recognize complex stimuli in the real world. Discovering how different biological systems accomplish the same adaptive feat might greatly help those attempting to create different artificial and prosthetic systems of object recognition. PUBLIC HEALTH RELEVANCE: The development of animal models of object recognition and visual conceptualization might better enable us to understand the behavioral and biological mechanisms of the human visual system in both health and disease. Effective animal models may also help pave the way for devising practical diagnostic tests for assessing visual performance; particularly important here is the fact that verbal behavior need not participate in such performance assessments, making nonverbal tests especially useful with infants, young children, and clinical populations. Our results should also advance our understanding of how the visual system develops and how to promote its regeneration after disease or injury.           Relevance to Public Health The development of animal models of object recognition and visual conceptualization might better enable us to understand the behavioral and biological mechanisms of the human visual system in both health and disease. Effective animal models may also help pave the way for devising practical diagnostic tests for assessing visual performance; particularly important here is the fact that verbal behavior need not participate in such performance assessments, making nonverbal tests especially useful with infants, young children, and clinical populations. Our results should also advance our understanding of how the visual system develops and how to promote its regeneration after disease or injury.",Perceptual bases of visual concepts,7727727,R01EY019781,"['Adaptive Behaviors', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Binding', 'Biological', 'Biological Models', 'Brain', 'Categories', 'Child', 'Classification', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Columbidae', 'Communities', 'Competence', 'Complex', 'Computer Vision Systems', 'Computers', 'Concept Formation', 'Development', 'Devices', 'Diagnostic tests', 'Discrimination', 'Discrimination Learning', 'Disease', 'Expert Systems', 'Health', 'Human', 'Image', 'Infant', 'Injury', 'Investigation', 'Iowa', 'Knowledge', 'Language', 'Learning', 'Light', 'Linguistics', 'Mediating', 'Methods', 'Natural regeneration', 'Nature', 'Neocortex', 'Neurobiology', 'Operant Conditioning', 'Organism', 'Perception', 'Performance', 'Phylogeny', 'Play', 'Population', 'Primates', 'Procedures', 'Process', 'Prosthesis', 'Psychological reinforcement', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Retinal', 'Role', 'Scientist', 'Shapes', 'Specific qualifier value', 'Stimulus', 'Stress', 'System', 'Teaching Method', 'Technology', 'Testing', 'Training', 'Universities', 'Variant', 'Verbal Behavior', 'Visual', 'Visual Perception', 'Visual system structure', 'Work', 'animal model development', 'base', 'biological systems', 'cognitive neuroscience', 'cooking', 'coping', 'experience', 'information processing', 'innovation', 'insight', 'member', 'neurobiological mechanism', 'novel', 'object recognition', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'sound', 'theories', 'two-dimensional', 'visual information', 'visual performance', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF IOWA,R01,2009,328156,0.09739712657590928
"Causal Perceptual Processing    DESCRIPTION (provided by applicant): The broad, long-term objectives of this research are to make original contributions to scientific understanding of biological perception. The specific aims are to: 1) develop and test a causal model of touch sensations' integration with visual sensations for perception, and to generalize this model for application to a broader class of sensory integration phenomena, 2) apply causal models to investigate how humans perceive cause-and-effect events, 3) increase the applicant's technical proficiency with causal modeling and applied machine learning methods. The proposal includes two main projects; the first will measure how humans judge the size of objects when their distances are uncertain. Specifically the first project examines the theory that human perception uses knowledge about how size and distance sensations are caused to integrate related sensations. Human experimental participants will view objects while touching them and report their perceptions of the objects' sizes, which will be used to evaluate theoretical predictions. The second project investigates how humans perceive cause-and-effect chains of events by examining the theory that the brain uses built-in knowledge of rudimentary physical behaviors, like momentum in collisions, to interpret such simple events. Human experimental participants will view colliding objects and report what occurred, which will again be used to evaluate theoretical predictions. PUBLIC HEALTH RELEVANCE: The public health relevance of this research is to increase scientific and medical understanding of the neural communication and processing strategies the brain employs to create perceptual experiences, so that people with perceptual impairments can be provided with effective rehabilitation programs and biotechnological substitutes for diminished capabilities. Specific impairments include blindness and low-vision, traumatic brain and nervous system injuries, and strokes. In particular, modern sensory prostheses are now using computerized components that can interface with neural pathways to more comprehensively and effectively restore normal abilities in patients, and whose development faces significant obstacles establishing effective communication channels with the biological nervous system.          n/a",Causal Perceptual Processing,7545242,F32EY019228,"['Algorithms', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological', 'Biological Process', 'Blindness', 'Brain', 'Class', 'Cognition', 'Cognitive', 'Cognitive Science', 'Communication', 'Complex', 'Computational Technique', 'Computer Simulation', 'Decision Making', 'Development', 'Distance Perception', 'Economics', 'Elements', 'Esthesia', 'Etiology', 'Event', 'Face', 'Glass', 'Goals', 'Human', 'Image', 'Impairment', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Lifting', 'Machine Learning', 'Masks', 'Measures', 'Medical', 'Memory', 'Methods', 'Modeling', 'Nature', 'Nervous System Trauma', 'Nervous system structure', 'Neural Pathways', 'Neurosciences', 'Participant', 'Patients', 'Pattern', 'Perception', 'Plague', 'Preparation', 'Process', 'Property', 'Psychologist', 'Psychology', 'Public Health', 'Rehabilitation therapy', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Science', 'Scientific Advances and Accomplishments', 'Semantics', 'Sensory', 'Sorting - Cell Movement', 'Space Perception', 'Stimulus', 'Stroke', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual impairment', 'Water', 'Work', 'abstracting', 'analytical method', 'computer monitor', 'computer science', 'computerized', 'experience', 'falls', 'haptics', 'insight', 'object perception', 'predictive modeling', 'programs', 'relating to nervous system', 'sensory integration', 'sensory prosthesis', 'size', 'skills', 'statistics', 'theories', 'tool']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2008,44846,0.041383902901998615
"Cue Reliability and Depth Calibration During Space Perception    DESCRIPTION (provided by applicant): The long-term objective of the proposed work is to understand how learning by the visual system helps it to represent the immediate environment during perception. Because perception is accurate, we can know spatial layout: the shapes, orientations, sizes, and spatial locations of the objects and surfaces around us. But this accuracy requires that the visual system learn over time how best to interpret visual ""cues"". These cues are the signals from the environment that the visual system extracts from the retinal images that are informative about spatial layout. Known cues include binocular disparity, texture gradients, occlusion relations, motion parallax, and familiar size, to name a few. How do these cues come to be interpreted correctly? A fundamental problem is that visual cues are ambiguous. Even if cues could be measured exactly (which they cannot, the visual system being a physical device) there would still be different possible 3D interpretations for a given set of cues. As a result, the visual system is forced to operate probabilistically: the way things ""look"" to us reflects an implicit guess as to which interpretation of the cues is most likely to be correct. Each additional cue helps improve the guess. For example, the retinal image of a door could be interpreted as a vertical rectangle or as some other quadrilateral at a non-vertical orientation in space, and the shadow cues at the bottom of the door helps the system know that it's a vertical rectangle. What mechanisms do the visual system use to discern which cues are available for interpreting images correctly? The proposed work aims to answer this fundamental question about perceptual learning. It was recently shown that the visual system can detect and start using new cues for perception. This phenomenon can be studied in the laboratory using classical conditioning procedures that were previously developed to study learning in animals. In the proposed experiments, a model system is used to understand details about when this learning occurs and what is learned. The data will be compared to predictions based on older, analogous studies in the animal learning literature, and interpreted in the context of Bayesian statistical inference, especially machine learning theory. The proposed work benefits public health by characterizing the brain mechanisms that keep visual perception accurate. These mechanisms are at work in the many months during which a person with congenital cataracts learns to use vision after the cataracts are removed, and it is presumably these mechanisms that go awry when an individual with a family history of synesthesia or autism develops anomalous experience-dependent perceptual responses. Neurodegenerative diseases may disrupt visual learning, in which case visual learning tests could be used to detect disease; understanding the learning of new cues in human vision could lead to better computerized aids for the visually impaired; and knowing what causes a new cue to be learned could lead to new technologies for training people to perceive accurately in novel work environments.          n/a",Cue Reliability and Depth Calibration During Space Perception,7388324,R01EY013988,"['Address', 'Adult', 'Animal Behavior', 'Animals', 'Appearance', 'Autistic Disorder', 'Binocular Vision', 'Biological Models', 'Brain', 'Calibration', 'Cataract', 'Computer Vision Systems', 'Condition', 'Cues', 'Data', 'Depth', 'Devices', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Family history of', 'Food', 'Funding', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Learning Disabilities', 'Literature', 'Location', 'Longevity', 'Machine Learning', 'Measures', 'Memory', 'Motion', 'Motion Perception', 'Names', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathology', 'Perception', 'Perceptual learning', 'Persons', 'Positioning Attribute', 'Primates', 'Procedures', 'Process', 'Public Health', 'Rate', 'Recruitment Activity', 'Research', 'Retinal', 'Reversal Learning', 'Rotation', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Source', 'Space Perception', 'Stimulus', 'Surface', 'System', 'Testing', 'Texture', 'Time', 'Training', 'Translations', 'Trust', 'Ursidae Family', 'Vision', 'Vision Disparity', 'Visual', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'Workplace', 'area MT', 'base', 'classical conditioning', 'clinical application', 'computerized', 'concept', 'congenital cataract', 'design', 'devices for the visually impaired', 'experience', 'improved', 'neuromechanism', 'new technology', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'size', 'stereoscopic', 'theories', 'tool', 'visual information', 'visual learning', 'visual process', 'visual processing']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2008,228847,0.05263797747146718
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7392804,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease regression', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Numbers', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2008,35821,0.00223129673381824
"Population analysis of shape representation in V4    DESCRIPTION (provided by applicant): The perception of shape is essential for object identification and visually guided action. The neural represenation of shape is mediated by a hierarchical system of brain areas known collectively as the ventral stream. Damage to ventral stream areas may lead to visual agnosias that can severely compromise quality of life. It is therefore important to achieve an understanding of how shape representation is generated. We will examine the neural representation of shape in V4, a brain region that is situated at an intermediate level on the ventral stream hierarchy. Our stategy will be to construct quantitative models of the relationship between neurophysiological activity and visual input at both the single cell and population levels. Our approach to constructing these models will be distinguished by the use of advanced non-linear statistical techniques, complex visual stimuli that simulates natural viewing conditions, and the use of multi-electrode arrays to record populations of neurons simultaneously. Interpretation and analysis of these models will allow us adress two specific questions: 1) what are the independent stimulus dimensions to which V4 neurons are tuned?; 2) how is the distributed activity of V4 cell populations combined to represent shape?           n/a",Population analysis of shape representation in V4,7483599,F32EY016941,"['Affect', 'Animals', 'Area', 'Attention', 'Behavior', 'Brain', 'Brain region', 'Cells', 'Classification', 'Code', 'Complex', 'Condition', 'Data', 'Devices', 'Dimensions', 'Discrimination', 'Electrodes', 'Environment', 'Evaluation', 'Goals', 'Image', 'Imagery', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Mediating', 'Modeling', 'Neurons', 'Perception', 'Performance', 'Population', 'Population Analysis', 'Positioning Attribute', 'Procedures', 'Property', 'Quality of life', 'Sampling', 'Shapes', 'Simulate', 'Stimulus', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'V4 neuron', 'Visual', 'Visual Agnosias', 'Visual system structure', 'Work', 'area V4', 'base', 'extrastriate visual cortex', 'neurophysiology', 'receptive field', 'relating to nervous system', 'response', 'success', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,F32,2008,50428,0.05914077517092693
"CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories    DESCRIPTION (provided by applicant): For over half a century, vision scientists have been decomposing visual scenes into simple, more tractable components in an attempt to understand how the brain accomplishes vision. Although this endeavor has revealed much about the specialized subsystems of vision, surprisingly little is know about how, or even where in the brain, we process scenes as a whole. How is it, for instance, that the brain determines whether it is looking at a forest or a city skyline? One reason for the paucity of research on this topic may be that the neural representation of a scene is likely to be highly distributed, a coding scheme not easily identified by many traditional neuroscience methods. The objective of the proposed research is to use a new method of analyzing functional magnetic resonance imaging (fMRI) data that is designed to leverage activity patterns across the brain, in order to better understand how the brain categorizes natural scenes. In particular, the project combines expertise from computer vision and neuroimaging by applying statistical pattern recognition algorithms to fMRI data to understand how the brain distinguishes between different categories of natural scene (e.g., a beach versus a highway). The proposed project will use and develop a statistical pattern recognition approach to fMRI analysis to accomplish three more specific objectives: (i) to identify the neural representation of natural scene categories, (ii) to identify the computational principles for forming and using the neural representation of natural scene categories, and (iii) to explore the effects of attention and expectation on natural scene categorization. The insights gained from these experiments will be verified in a computational model of natural scene perception, which in turn will generate predictions for future experiments. Intellectual Merit of the Proposed Activity: Although previous research has shown that humans can quickly and effortless categorize natural scenes, there is very little understanding of how this is accomplished in the brain. The research proposed here will significantly advance our understanding of how natural scenes are represented in the brain and begin to uncover the computational strategies the brain employs in quickly and accurately extracting the gist of a scene. Broader Impacts of the Proposed Activity: The highly interdisciplinary nature of the proposed research requires intense interactions among psychologists, neuroscientists, and computer vision researchers. As such, the project not only promises to increase communication among very different disciplines but it will also to provide doctoral students with truly interdisciplinary training. The PIs are committed to providing a highly interactive research environment, mentoring students across disciplines, and fostering the interdisciplinary approach to science in general. Moreover, two of the three PIs are women working in fields in which women are traditionally underrepresented and are committed to improving the representation and visibility of women in science. Finally, the principles derived from this project are likely to have implications beyond the domain of natural scene perception. By refining the pattern recognition algorithms and their application to fMRI data, the project will expand the set of tools available to neuroscientists wishing to study a whole host of complex human behaviors that likely depend on subtle but distributed patterns of activity in the brain.           n/a",CRCNS: fMRI Pattern Analysis of Neural Correlates of Natural Scene Categories,7615848,R01EY019429,"['Algorithms', 'Attention', 'Behavior', 'Brain', 'Categories', 'Cities', 'Code', 'Commit', 'Communication', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Discipline', 'Environment', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Future', 'Human', 'Image Analysis', 'Location', 'Magnetic Resonance Imaging', 'Mentors', 'Methods', 'Nature', 'Neurosciences', 'Pattern', 'Pattern Recognition', 'Perception', 'Process', 'Psychologist', 'Research', 'Research Personnel', 'Scheme', 'Science', 'Scientist', 'Statistical Methods', 'Students', 'Training', 'Vision', 'Visual', 'Woman', 'Working Women', 'day', 'design', 'expectation', 'forest', 'improved', 'insight', 'interdisciplinary approach', 'neuroimaging', 'relating to nervous system', 'research study', 'tool', 'vision science']",NEI,PRINCETON UNIVERSITY,R01,2008,316386,0.03373681191528414
"Shape representation and attention DESCRIPTION (provided by applicant): This proposal addresses the way the visual system processes complex shape. We focus on two intermediate visual areas, V2 and V4, located in the ventral processing stream immediately beyond primary visual cortex (area VI). These areas serve as the major input stages for higher-order shape processing areas in the temporal cortex. We propose neurophysiological experiments to investigate the way that shape is represented in these areas and the way that attention modulates these representations. Shape is difficult to describe and parameterize, so previous neurophysiological studies of shape processing have utilized simple, regular shapes that are experimentally convenient. However, intermediate shape processing is highly nonlinear, so results obtained with reduced stimulus sets may not generalize to other stimuli. We therefore propose to use both complex, natural stimuli and simpler stimuli such as gratings. To facilitate this, we are developing novel nonlinear regression algorithms to estimate the stimulus-response mapping functions of neurons in V2 and V4. The underlying shape dimensions represented therein can then be determined by applying visualization algorithms (developed in our laboratory) to the stimulus-response mapping functions estimated for single neurons. In another series of experiments we plan to investigate how extrastriate visual areas integrate information from earlier sensory areas. Finally, we propose to examine how visual attention affects shape representations in V2 and V4. We will accomplish this by quantifying the effects of selective attention to a specific shape (feature attention) and attention directed toward a specific location in space (spatial attention) on neuronal tuning curves. Successful completion of these projects will provide critical information to aid in development of quantitative computational models of shape processing in intermediate vision. n/a",Shape representation and attention,7386606,R01EY012241,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Animals', 'Area', 'Attention', 'Automobile Driving', 'Award', 'Biological Neural Networks', 'Cells', 'Complex', 'Computer Simulation', 'Conflict (Psychology)', 'Cues', 'Data Set', 'Development', 'Dimensions', 'Disease regression', 'Elements', 'Exhibits', 'Frequencies', 'Goals', 'Image', 'Imagery', 'Laboratories', 'Location', 'Machine Learning', 'Maps', 'Modeling', 'Nature', 'Neurons', 'Noise', 'Operative Surgical Procedures', 'Pathway Analysis', 'Population', 'Positioning Attribute', 'Procedures', 'Process', 'Reporting', 'Research Personnel', 'Response to stimulus physiology', 'Rotation', 'Sampling', 'Sensory', 'Series', 'Shapes', 'Space Perception', 'Staging', 'Stimulus', 'Stream', 'System', 'Techniques', 'Temporal Lobe', 'Training', 'V4 neuron', 'Validation', 'Vision', 'Visual attention', 'Visual system structure', 'Width', 'area V2', 'area striata', 'directed attention', 'extrastriate', 'extrastriate visual cortex', 'improved', 'movie', 'neurophysiology', 'novel', 'programs', 'receptive field', 'research study', 'response', 'selective attention', 'visual process', 'visual processing', 'visual search']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2008,355274,0.07383954625705183
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7350139,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Condition', 'Count', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Numbers', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Rate', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'size', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2008,322249,0.02521857316422415
"Probing neural feature selectivity with natural stimuli DESCRIPTION (provided by applicant): The candidate seeks to become independent as a neuroscientist and to work at the interface between neuroscience and physics. The Sloan-Swartz Center at UCSF provides a unique opportunity to become immersed in neuroscience at its cutting edge. While the majority of her time will be spent in research, she will attend a range of systems neuroscience and computer vision courses. The immediate goals of her research are to develop an information-theoretic method that allows for a rigorous statistical analysis of neural responses to natural stimuli, which are non- Gaussian and have strong spatiotemporal correlations; and to use this method to analyze the responses of visual cortical neurons to natural time-varying images. There are numerous indications that the responses of neurons to natural stimuli cannot be completely predicted from their responses to stimuli with simple statistical properties, such as white noise ensembles. However, existing methods for analyzing single neuron responses may be rigorously applied only to Gaussian ensembles. The information-theoretic method involves finding the stimulus dimensions that carry the most information about the neuron's response. The stimulus ensemble is not assumed to be Gaussian. The only assumption made is that the neuron is selective for a small number of stimulus dimensions out of the high-dimensional stimulus space: responses with respect to the relevant dimensions might be arbitrarily nonlinear. After testing the method on model neurons and verifying that it gives reasonable results for cortical neurons probed by natural scenes, the method will be used to test the categorical distinction between simple and complex cells in the primary visual cortex. The method will then be modified so that a large set of directions related to each other via certain symmetry operations, such as translation or scaling, can be simultaneously found, with the goal of systematically probing neurons in extrastriate areas with natural scenes. n/a",Probing neural feature selectivity with natural stimuli,7418710,K25MH068904,"['Accidents', 'Accounting', 'Acoustics', 'Afferent Neurons', 'Area', 'Area Analyses', 'Auditory', 'Bypass', 'Cells', 'Characteristics', 'Complex', 'Computer Vision Systems', 'Condition', 'Data', 'Dimensions', 'Discrimination', 'Drug Formulations', 'Ear', 'Felis catus', 'Fire - disasters', 'Frequencies', 'Goals', 'Image', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Non-linear Models', 'Numbers', 'Operative Surgical Procedures', 'Output', 'Physics', 'Probability', 'Process', 'Property', 'Range', 'Rate', 'Research', 'Response to stimulus physiology', 'Rotation', 'Sensory', 'Shapes', 'Stimulus', 'System', 'Testing', 'Time', 'Training', 'Translations', 'Visual', 'Visual Cortex', 'Visual Fields', 'Work', 'area striata', 'base', 'extrastriate visual cortex', 'indium arsenide', 'interest', 'receptive field', 'relating to nervous system', 'response', 'size', 'sound', 'spatiotemporal', 'vector', 'voltage']",NIMH,SALK INSTITUTE FOR BIOLOGICAL STUDIES,K25,2008,97809,0.05319537874959727
"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",A Wireless Multiscale Distributed Interface to the Cortex,7533930,R01NS062031,"['Address', 'Advanced Development', 'Algorithms', 'Animal Behavior', 'Animal Model', 'Animals', 'Area', 'Behavior', 'Benchmarking', 'Brain', 'Brain imaging', 'Cavia', 'Cell physiology', 'Characteristics', 'Communication', 'Computer information processing', 'Computer software', 'Custom', 'Data', 'Devices', 'Discipline', 'Disease', 'Electrodes', 'Electronics', 'Engineering', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Imaging technology', 'Implant', 'In Vitro', 'Investigation', 'Learning', 'Machine Learning', 'Mediating', 'Microelectrodes', 'Monitor', 'Motor', 'Nervous system structure', 'Neurobiology', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Outcome', 'Paralysed', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Public Health', 'Rattus', 'Research', 'Retinal', 'Rodent', 'Rodent Model', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Slice', 'Stimulus', 'Stream', 'System', 'Telemetry', 'Testing', 'Time', 'Wireless Technology', 'awake', 'base', 'brain cell', 'brain machine interface', 'clinical application', 'computerized data processing', 'data acquisition', 'density', 'design', 'desire', 'disability', 'implantation', 'improved', 'in vivo', 'microsystems', 'nervous system disorder', 'neural circuit', 'prototype', 'quantum', 'relating to nervous system', 'response', 'size', 'subcutaneous', 'tool']",NINDS,MICHIGAN STATE UNIVERSITY,R01,2008,527963,-0.003928126135706011
"Origins of Object Knowledge    DESCRIPTION (provided by applicant): Twelve experiments investigate the early development, in human infants, of perception of the unity of partly occluded surfaces. The experiments focus on a time during ontogeny when there may be evidence of visual sensitivity to information specifying object properties, but limited ability to perceive occlusion, with the goal of observing real-time processes by which the infant assembles visible parts of a stimulus into a coherent whole. This approach stipulates that onset of sensitivity to motion and orientation information, development of the oculomotor system, and experience viewing objects undergoing occlusion and disocclusion, play a direct, foundational role in the ontogeny of object perception. That is, there is an hypothesized period, 2 to 4 months of age, during which infants come to use newly-emerged visual skills to perceive objects accurately. The experiments follow a similar strategy: explorations of individual and group differences in both basic visual processing skills and perception of the unity of partly occluded surfaces. Infant perception is assessed with two methods: (a) recording of eye movements, to measure improvements in pickup of important visual .information, and (b) habituation/dishabituation, to ascertain perception of object unity as well as to determine the extent of sensitivity to available visual information. It is expected that the detailed analysis of individual differences afforded by this approach provide the opportunity for exceptionally sensitive measures of the emergence of visual skills and object knowledge. The short-term objectives of the present proposal are to elucidate fundamental developmental mechanisms in the context of the classic nature-nurture debate. The long-term goals are to shed light on the larger question of how knowledge is acquired and structured in the human, and how perceptual skills impact knowledge acquisition and structure. In the future, such understanding may aid in the formulation of diagnostics and treatments for some developmental disorders.         n/a",Origins of Object Knowledge,7355592,R01HD040432,"['Academy', 'Adult', 'Age', 'Age-Months', 'Birth', 'Budgets', 'Categories', 'Child Development', 'Cognition', 'Cognitive', 'Cognitive Science', 'Computer information processing', 'Condition', 'Corpus striatum structure', 'Dependence', 'Dependency', 'Detection', 'Development', 'Diagnostic', 'Drug Formulations', 'Elderly', 'Event', 'Exhibits', 'Eye', 'Eye Movements', 'Failure', 'Fostering', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Growth', 'Heart', 'Human', 'Individual', 'Individual Differences', 'Infant', 'Infant Development', 'Investigation', 'Journals', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Learning', 'Legal patent', 'Light', 'Link', 'Literature', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Methods', 'Motion', 'Nature', 'Neurobiology', 'None or Not Applicable', 'Pattern', 'Perception', 'Performance', 'Plant Roots', 'Play', 'Preparation', 'Process', 'Process Measure', 'Property', 'Psychology', 'Range', 'Relative (related person)', 'Reporting', 'Research', 'Resources', 'Role', 'Rotation', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Side', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Students', 'Suggestion', 'Support of Research', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Vision', 'Visual', 'Visual attention', 'Visual system structure', 'Work', 'Writing', 'abstracting', 'base', 'concept', 'developmental disease', 'experience', 'follow-up', 'gaze', 'indexing', 'infancy', 'meter', 'object perception', 'oculomotor', 'psychologic', 'research study', 'sequence learning', 'size', 'skills', 'spatiotemporal', 'symposium', 'theories', 'tool', 'trend', 'visual information', 'visual process', 'visual processing']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2008,269804,0.014245737840728134
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7269518,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease regression', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Numbers', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2007,35821,0.00223129673381824
"Population analysis of shape representation in V4    DESCRIPTION (provided by applicant): The perception of shape is essential for object identification and visually guided action. The neural represenation of shape is mediated by a hierarchical system of brain areas known collectively as the ventral stream. Damage to ventral stream areas may lead to visual agnosias that can severely compromise quality of life. It is therefore important to achieve an understanding of how shape representation is generated. We will examine the neural representation of shape in V4, a brain region that is situated at an intermediate level on the ventral stream hierarchy. Our stategy will be to construct quantitative models of the relationship between neurophysiological activity and visual input at both the single cell and population levels. Our approach to constructing these models will be distinguished by the use of advanced non-linear statistical techniques, complex visual stimuli that simulates natural viewing conditions, and the use of multi-electrode arrays to record populations of neurons simultaneously. Interpretation and analysis of these models will allow us adress two specific questions: 1) what are the independent stimulus dimensions to which V4 neurons are tuned?; 2) how is the distributed activity of V4 cell populations combined to represent shape?           n/a",Population analysis of shape representation in V4,7232722,F32EY016941,"['Affect', 'Animals', 'Area', 'Attention', 'Behavior', 'Brain', 'Brain region', 'Cells', 'Classification', 'Code', 'Complex', 'Condition', 'Data', 'Devices', 'Dimensions', 'Discrimination', 'Electrodes', 'Environment', 'Evaluation', 'Goals', 'Image', 'Imagery', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Mediating', 'Modeling', 'Neurons', 'Perception', 'Performance', 'Population', 'Population Analysis', 'Positioning Attribute', 'Procedures', 'Property', 'Quality of life', 'Sampling', 'Shapes', 'Simulate', 'Stimulus', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'V4 neuron', 'Visual', 'Visual Agnosias', 'Visual system structure', 'Work', 'area V4', 'base', 'extrastriate visual cortex', 'neurophysiology', 'receptive field', 'relating to nervous system', 'response', 'success', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,F32,2007,48796,0.05914077517092693
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,7194202,R01EY015888,"['Agnosia', 'Area', 'Awareness', 'Color', 'Communication', 'Computer Vision Systems', 'Condition', 'Conscious', 'Cues', 'Development', 'Disease', 'Distant', 'Dyslexia', 'Elements', 'Goals', 'Grouping', 'Image', 'Lateral', 'Lead', 'Literature', 'Location', 'Measurable', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Nature', 'Neighborhoods', 'Paint', 'Perception', 'Process', 'Rate', 'Research', 'Research Personnel', 'Source', 'Staging', 'Stimulus', 'Structure', 'Textbooks', 'Texture', 'Time', 'Vision', 'Visual', 'Visual Fields', 'Visual system structure', 'base', 'design', 'interest', 'millisecond', 'neurophysiology', 'novel', 'perceptual organization', 'receptive field', 'relating to nervous system', 'research study', 'visual process', 'visual processing']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2007,216928,0.0570082980302183
"Shape representation and attention DESCRIPTION (provided by applicant): This proposal addresses the way the visual system processes complex shape. We focus on two intermediate visual areas, V2 and V4, located in the ventral processing stream immediately beyond primary visual cortex (area VI). These areas serve as the major input stages for higher-order shape processing areas in the temporal cortex. We propose neurophysiological experiments to investigate the way that shape is represented in these areas and the way that attention modulates these representations. Shape is difficult to describe and parameterize, so previous neurophysiological studies of shape processing have utilized simple, regular shapes that are experimentally convenient. However, intermediate shape processing is highly nonlinear, so results obtained with reduced stimulus sets may not generalize to other stimuli. We therefore propose to use both complex, natural stimuli and simpler stimuli such as gratings. To facilitate this, we are developing novel nonlinear regression algorithms to estimate the stimulus-response mapping functions of neurons in V2 and V4. The underlying shape dimensions represented therein can then be determined by applying visualization algorithms (developed in our laboratory) to the stimulus-response mapping functions estimated for single neurons. In another series of experiments we plan to investigate how extrastriate visual areas integrate information from earlier sensory areas. Finally, we propose to examine how visual attention affects shape representations in V2 and V4. We will accomplish this by quantifying the effects of selective attention to a specific shape (feature attention) and attention directed toward a specific location in space (spatial attention) on neuronal tuning curves. Successful completion of these projects will provide critical information to aid in development of quantitative computational models of shape processing in intermediate vision. n/a",Shape representation and attention,7189021,R01EY012241,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Animals', 'Area', 'Attention', 'Automobile Driving', 'Award', 'Biological Neural Networks', 'Cells', 'Complex', 'Computer Simulation', 'Conflict (Psychology)', 'Cues', 'Data Set', 'Development', 'Dimensions', 'Disease regression', 'Elements', 'Exhibits', 'Frequencies', 'Goals', 'Image', 'Imagery', 'Laboratories', 'Location', 'Machine Learning', 'Maps', 'Modeling', 'Nature', 'Neurons', 'Noise', 'Operative Surgical Procedures', 'Pathway Analysis', 'Population', 'Positioning Attribute', 'Procedures', 'Process', 'Reporting', 'Research Personnel', 'Response to stimulus physiology', 'Rotation', 'Sampling', 'Sensory', 'Series', 'Shapes', 'Space Perception', 'Staging', 'Stimulus', 'Stream', 'System', 'Techniques', 'Temporal Lobe', 'Training', 'V4 neuron', 'Validation', 'Vision', 'Visual attention', 'Visual system structure', 'Width', 'area V2', 'area striata', 'directed attention', 'extrastriate', 'extrastriate visual cortex', 'improved', 'movie', 'neurophysiology', 'novel', 'programs', 'receptive field', 'research study', 'response', 'selective attention', 'visual process', 'visual processing', 'visual search']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2007,363113,0.07383954625705183
"Probing neural feature selectivity with natural stimuli DESCRIPTION (provided by applicant): The candidate seeks to become independent as a neuroscientist and to work at the interface between neuroscience and physics. The Sloan-Swartz Center at UCSF provides a unique opportunity to become immersed in neuroscience at its cutting edge. While the majority of her time will be spent in research, she will attend a range of systems neuroscience and computer vision courses. The immediate goals of her research are to develop an information-theoretic method that allows for a rigorous statistical analysis of neural responses to natural stimuli, which are non- Gaussian and have strong spatiotemporal correlations; and to use this method to analyze the responses of visual cortical neurons to natural time-varying images. There are numerous indications that the responses of neurons to natural stimuli cannot be completely predicted from their responses to stimuli with simple statistical properties, such as white noise ensembles. However, existing methods for analyzing single neuron responses may be rigorously applied only to Gaussian ensembles. The information-theoretic method involves finding the stimulus dimensions that carry the most information about the neuron's response. The stimulus ensemble is not assumed to be Gaussian. The only assumption made is that the neuron is selective for a small number of stimulus dimensions out of the high-dimensional stimulus space: responses with respect to the relevant dimensions might be arbitrarily nonlinear. After testing the method on model neurons and verifying that it gives reasonable results for cortical neurons probed by natural scenes, the method will be used to test the categorical distinction between simple and complex cells in the primary visual cortex. The method will then be modified so that a large set of directions related to each other via certain symmetry operations, such as translation or scaling, can be simultaneously found, with the goal of systematically probing neurons in extrastriate areas with natural scenes. n/a",Probing neural feature selectivity with natural stimuli,7227037,K25MH068904,"['Accidents', 'Accounting', 'Acoustics', 'Afferent Neurons', 'Area', 'Area Analyses', 'Auditory', 'Bypass', 'Cells', 'Characteristics', 'Complex', 'Computer Vision Systems', 'Condition', 'Data', 'Dimensions', 'Discrimination', 'Drug Formulations', 'Ear', 'Felis catus', 'Fire - disasters', 'Frequencies', 'Goals', 'Image', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Non-linear Models', 'Numbers', 'Operative Surgical Procedures', 'Output', 'Physics', 'Probability', 'Process', 'Property', 'Range', 'Rate', 'Research', 'Response to stimulus physiology', 'Rotation', 'Sensory', 'Shapes', 'Stimulus', 'System', 'Testing', 'Time', 'Training', 'Translations', 'Visual', 'Visual Cortex', 'Visual Fields', 'Work', 'area striata', 'base', 'extrastriate visual cortex', 'indium arsenide', 'interest', 'receptive field', 'relating to nervous system', 'response', 'size', 'sound', 'spatiotemporal', 'vector', 'voltage']",NIMH,SALK INSTITUTE FOR BIOLOGICAL STUDIES,K25,2007,94960,0.05319537874959727
"A General Model of Saccadic Selectivity in Visual Search    DESCRIPTION (provided by applicant): Many of our everyday tasks, such as spotting a friend in a crowd or picking a bottle of soda from the refrigerator, require us to perform visual search. Due to this ubiquity of visual search, its study promises to shed light on the fundamental processes that control our visual attention so efficiently in natural tasks. To quantitatively assess search behavior, previous research using simple, artificial displays has employed eye-movement recording to analyze saccadic selectivity, that is, the bias of saccadic endpoints (""landing points"" of eye movements) towards display items that share certain features with the search target. Recently, saccadic selectivity in natural, complex displays has been examined as well (Pomplun, 2006), giving a first insight into eye-movement control as it is performed during everyday tasks. The aim of this project is to devise, implement, and evaluate a general, computational model of saccadic selectivity in visual search tasks. Due to its quantitative nature, absence of freely adjustable parameters, and support from empirical research results, the Area Activation Model (Pomplun, Shen, & Reingold, 2003) is a promising starting point for developing such a model. Its basic assumption is that eye movements in visual search tasks tend to target display areas that provide a maximum amount of task-relevant information for processing. To advance this model towards a general model of saccadic selectivity in visual search, additional eye-movement studies are performed to provide detailed information on the influence of color and target size on saccadic selectivity. Based on the data obtained, various aspects of the influence of display and target features on eye- movement patterns are quantified. These data are used to devise the advanced version of the Area Activation Model. The crucial improvements include the elimination of required empirical a-priori information, the consideration of bottom-up activation, and the applicability of the model to search displays beyond artificial images with discrete items and features. Ideally, the resulting model will be straightforward, consistent with natural principles, and carefully avoiding any freely adjustable model parameters to qualify it as a streamlined and general approach to eye-movement control in visual search. Such a model will be important for understanding the functionality of the visual system and will also have significant impact on the fields of computer vision, human-computer interaction, and cognitive modeling. The project will deepen our understanding of visual attention in general and the visual factors underlying saccade programming in particular. Such understanding will advance the possibilities for surgical and therapeutic treatment of visual illnesses. Moreover, the results of the study can directly be applied to improve current human-computer interfaces for computer-assisted surgery and x-ray image analysis.          n/a",A General Model of Saccadic Selectivity in Visual Search,7305151,R15EY017988,"['Appetitive Behavior', 'Area', 'Attention', 'Cognitive', 'Collection', 'Color', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer information processing', 'Computer-Assisted Surgery', 'Crowding', 'Data', 'Data Analyses', 'Dimensions', 'Empirical Research', 'End Point', 'Eye Movements', 'Frequencies', 'Friends', 'Image', 'Image Analysis', 'Light', 'Measurement', 'Modeling', 'Modification', 'Nature', 'Numbers', 'Operative Surgical Procedures', 'Pattern', 'Performance', 'Personal Satisfaction', 'Pliability', 'Positioning Attribute', 'Process', 'Qualifying', 'Research', 'Resources', 'Saccades', 'Scanning', 'Spottings', 'Stimulus', 'Testing', 'Therapeutic', 'User-Computer Interface', 'Visual', 'Visual attention', 'Visual system structure', 'Work', 'base', 'computer human interaction', 'design', 'improved', 'insight', 'programs', 'sample fixation', 'size', 'visual process', 'visual processing', 'visual search']",NEI,UNIVERSITY OF MASSACHUSETTS BOSTON,R15,2007,209463,0.048075828633085994
"Origins of Object Knowledge    DESCRIPTION (provided by applicant): Twelve experiments investigate the early development, in human infants, of perception of the unity of partly occluded surfaces. The experiments focus on a time during ontogeny when there may be evidence of visual sensitivity to information specifying object properties, but limited ability to perceive occlusion, with the goal of observing real-time processes by which the infant assembles visible parts of a stimulus into a coherent whole. This approach stipulates that onset of sensitivity to motion and orientation information, development of the oculomotor system, and experience viewing objects undergoing occlusion and disocclusion, play a direct, foundational role in the ontogeny of object perception. That is, there is an hypothesized period, 2 to 4 months of age, during which infants come to use newly-emerged visual skills to perceive objects accurately. The experiments follow a similar strategy: explorations of individual and group differences in both basic visual processing skills and perception of the unity of partly occluded surfaces. Infant perception is assessed with two methods: (a) recording of eye movements, to measure improvements in pickup of important visual .information, and (b) habituation/dishabituation, to ascertain perception of object unity as well as to determine the extent of sensitivity to available visual information. It is expected that the detailed analysis of individual differences afforded by this approach provide the opportunity for exceptionally sensitive measures of the emergence of visual skills and object knowledge. The short-term objectives of the present proposal are to elucidate fundamental developmental mechanisms in the context of the classic nature-nurture debate. The long-term goals are to shed light on the larger question of how knowledge is acquired and structured in the human, and how perceptual skills impact knowledge acquisition and structure. In the future, such understanding may aid in the formulation of diagnostics and treatments for some developmental disorders.         n/a",Origins of Object Knowledge,7212153,R01HD040432,"['Academy', 'Adult', 'Age', 'Age-Months', 'Birth', 'Budgets', 'Categories', 'Child Development', 'Cognition', 'Cognitive', 'Cognitive Science', 'Computer information processing', 'Condition', 'Corpus striatum structure', 'Dependence', 'Dependency', 'Detection', 'Development', 'Diagnostic', 'Drug Formulations', 'Elderly', 'Event', 'Exhibits', 'Eye', 'Eye Movements', 'Failure', 'Fostering', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Growth', 'Heart', 'Human', 'Individual', 'Individual Differences', 'Infant', 'Infant Development', 'Investigation', 'Journals', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Learning', 'Legal patent', 'Light', 'Link', 'Literature', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Methods', 'Motion', 'Nature', 'Neurobiology', 'None or Not Applicable', 'Pattern', 'Perception', 'Performance', 'Plant Roots', 'Play', 'Preparation', 'Process', 'Process Measure', 'Property', 'Psychology', 'Range', 'Relative (related person)', 'Reporting', 'Research', 'Resources', 'Role', 'Rotation', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Side', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Students', 'Suggestion', 'Support of Research', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Vision', 'Visual', 'Visual attention', 'Visual system structure', 'Work', 'Writing', 'abstracting', 'base', 'concept', 'developmental disease', 'experience', 'follow-up', 'gaze', 'indexing', 'infancy', 'meter', 'object perception', 'oculomotor', 'psychologic', 'research study', 'sequence learning', 'size', 'skills', 'spatiotemporal', 'symposium', 'theories', 'tool', 'trend', 'visual information', 'visual process', 'visual processing']",NICHD,NEW YORK UNIVERSITY,R01,2007,272700,0.014245737840728134
"Perceptual Organization and Attention: Behavior & fMRI    DESCRIPTION (provided by applicant): Visual perception is selective, and visual attention is the mechanism by which salient or high-priority objects are prioritized for awareness and action. Recent work has shown that attentional selection often operates on perceptual objects and not simply on spatial locations. In a multi-object scene involving partial occlusion, image regions must be grouped into coherent object representations prior to attentional deployment. The visual system employs a set of heuristics that serve to constrain object recognition based on principles of perceptual organization. Despite their importance to human navigation and behavior, knowledge of these heuristics and the neural mechanisms that underlie this process remain poorly understood. The proposed project will examine the grouping principles that are critical to object-based attentional selection, and will enumerate the dominance relations among these principles when they are consistent with competing groupings within a scene. The project also explores the neural implementation of these processes to extend our knowledge of the constraints built into the object recognition and visual attention systems. The combination of behavioral and neuroimaging methods outlined in this application will result in a better understanding of the neural circuitry that is responsible for efficient, goal-directed object recognition.           n/a",Perceptual Organization and Attention: Behavior & fMRI,7112773,F31NS055664,"['artificial intelligence', 'attention', 'behavior', 'clinical research', 'cues', 'visual perception']",NINDS,JOHNS HOPKINS UNIVERSITY,F31,2006,37861,0.09064748604012973
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,7037390,R01EY015888,"['clinical research', 'computational neuroscience', 'cues', 'form /pattern perception', 'human subject', 'mathematical model', 'mental process', 'motion perception', 'neural information processing', 'neuropsychological tests', 'neuropsychology', 'psychophysics', 'space perception', 'statistics /biometry', 'time perception', 'vision tests', 'visual depth perception', 'visual stimulus', 'visual tracking']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2006,215583,0.0570082980302183
"Probing neural feature selectivity with natural stimuli DESCRIPTION (provided by applicant): The candidate seeks to become independent as a neuroscientist and to work at the interface between neuroscience and physics. The Sloan-Swartz Center at UCSF provides a unique opportunity to become immersed in neuroscience at its cutting edge. While the majority of her time will be spent in research, she will attend a range of systems neuroscience and computer vision courses. The immediate goals of her research are to develop an information-theoretic method that allows for a rigorous statistical analysis of neural responses to natural stimuli, which are non- Gaussian and have strong spatiotemporal correlations; and to use this method to analyze the responses of visual cortical neurons to natural time-varying images. There are numerous indications that the responses of neurons to natural stimuli cannot be completely predicted from their responses to stimuli with simple statistical properties, such as white noise ensembles. However, existing methods for analyzing single neuron responses may be rigorously applied only to Gaussian ensembles. The information-theoretic method involves finding the stimulus dimensions that carry the most information about the neuron's response. The stimulus ensemble is not assumed to be Gaussian. The only assumption made is that the neuron is selective for a small number of stimulus dimensions out of the high-dimensional stimulus space: responses with respect to the relevant dimensions might be arbitrarily nonlinear. After testing the method on model neurons and verifying that it gives reasonable results for cortical neurons probed by natural scenes, the method will be used to test the categorical distinction between simple and complex cells in the primary visual cortex. The method will then be modified so that a large set of directions related to each other via certain symmetry operations, such as translation or scaling, can be simultaneously found, with the goal of systematically probing neurons in extrastriate areas with natural scenes. n/a",Probing neural feature selectivity with natural stimuli,7035246,K25MH068904,"['biophysics', 'cats', 'information theory', 'mathematics', 'method development', 'neural information processing', 'neural transmission', 'neurophysiology', 'statistics /biometry', 'stimulus /response', 'visual cortex', 'visual stimulus']",NIMH,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,K25,2006,92195,0.05319537874959727
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7125904,R01MH066990,"['bioinformatics', 'computational neuroscience', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'information system analysis', 'mathematical model', 'model design /development', 'neural information processing', 'neurophysiology', 'sensory feedback', 'sensory mechanism', 'statistics /biometry']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2006,36891,0.00223129673381824
"Corticofugal Modulation of Tactile Sensory Processing   DESCRIPTION: In every mammalian sensory system, descending corticothalamic           projections, which originate in multiple cortical areas and reach several            thalamic relay nuclei, far outnumber the terminals of parallel feedforward           projections that carry information from the periphery to the same thalamic           structures. Despite numerous studies and a series of theories which have             attempted to illuminate the role of these massive descending feedback                projections in sensory information processing, the functional relevance of           these pathways remains largely unknown. Here, we propose to investigate the          physiological contribution of somatosensory corticothalamic projections to the       tactile responses of neurons located in the main thalamic relay nucleus of the       trigeminal system, the ventral posterior medial nucleus. Based on extensive          preliminary data, we propose that, by providing both excitatory and inhibitory       influences to the somatosensory thalamus, corticofugal projections endow             thalamic neurons with the ability to enhance the differences between orthogonal      tactile stimuli and modify the type of information transmitted to the cortex         according to the behavioral state of the animal. The functional roles of             cortical feedback projections will be assessed by a series of experiments that       combine simultaneous multi-site neural ensemble recordings and reversible            cortical inactivation, in behaving animals. The activity of large populations        of single cortical and thalamic neurons will be simultaneously recorded in the       same rat, while its facial whiskers are stimulated with complex tactile stimuli      generated either passively or during an active behavioral whisker-dependant          discrimination task. Focal regions of the primary somatosensory cortex will be       reversibly inactivated during these simultaneous thalamocortical recordings.         This will allow us to evaluate how cortical projections contribute to the            generation of thalamic sensory responses to complex tactile stimuli. We predict      that in rats cortical feedback facilitates the thalamic responses to a whisker       column stimulus, while suppressing responses to a whisker row. Modifications in      the balance of these contrasting influences should also account for the              observation that VPM neurons become capable of integrating rapid sequences of        whisker column stimuli generated during active whisker exploration. n/a",Corticofugal Modulation of Tactile Sensory Processing,6857150,R01DE013810,"['artificial intelligence', 'body movement', 'corticofugal system', 'electrodes', 'electronic recording system', 'laboratory rat', 'neural information processing', 'neurons', 'neuroregulation', 'sensory discrimination', 'solitary tract nucleus', 'somesthetic sensory cortex', 'stimulus /response', 'thalamic nuclei', 'touch', 'trigeminal nerve', 'vibrissae', 'wakefulness']",NIDCR,DUKE UNIVERSITY,R01,2005,358050,0.041587338084667906
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,6924971,R01EY015888,"['clinical research', 'computational neuroscience', 'cues', 'form /pattern perception', 'human subject', 'mathematical model', 'mental process', 'motion perception', 'neural information processing', 'neuropsychological tests', 'neuropsychology', 'psychophysics', 'space perception', 'statistics /biometry', 'time perception', 'vision tests', 'visual depth perception', 'visual stimulus', 'visual tracking']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2005,222488,0.0570082980302183
"Probing neural feature selectivity with natural stimuli DESCRIPTION (provided by applicant): The candidate seeks to become independent as a neuroscientist and to work at the interface between neuroscience and physics. The Sloan-Swartz Center at UCSF provides a unique opportunity to become immersed in neuroscience at its cutting edge. While the majority of her time will be spent in research, she will attend a range of systems neuroscience and computer vision courses. The immediate goals of her research are to develop an information-theoretic method that allows for a rigorous statistical analysis of neural responses to natural stimuli, which are non- Gaussian and have strong spatiotemporal correlations; and to use this method to analyze the responses of visual cortical neurons to natural time-varying images. There are numerous indications that the responses of neurons to natural stimuli cannot be completely predicted from their responses to stimuli with simple statistical properties, such as white noise ensembles. However, existing methods for analyzing single neuron responses may be rigorously applied only to Gaussian ensembles. The information-theoretic method involves finding the stimulus dimensions that carry the most information about the neuron's response. The stimulus ensemble is not assumed to be Gaussian. The only assumption made is that the neuron is selective for a small number of stimulus dimensions out of the high-dimensional stimulus space: responses with respect to the relevant dimensions might be arbitrarily nonlinear. After testing the method on model neurons and verifying that it gives reasonable results for cortical neurons probed by natural scenes, the method will be used to test the categorical distinction between simple and complex cells in the primary visual cortex. The method will then be modified so that a large set of directions related to each other via certain symmetry operations, such as translation or scaling, can be simultaneously found, with the goal of systematically probing neurons in extrastriate areas with natural scenes. n/a",Probing neural feature selectivity with natural stimuli,6881439,K25MH068904,"['biophysics', 'cats', 'information theory', 'mathematics', 'method development', 'neural information processing', 'neural transmission', 'neurophysiology', 'statistics /biometry', 'stimulus /response', 'visual cortex', 'visual stimulus']",NIMH,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,K25,2005,89509,0.05319537874959727
"Corticofugal Modulation of Tactile Sensory Processing   DESCRIPTION: In every mammalian sensory system, descending corticothalamic           projections, which originate in multiple cortical areas and reach several            thalamic relay nuclei, far outnumber the terminals of parallel feedforward           projections that carry information from the periphery to the same thalamic           structures. Despite numerous studies and a series of theories which have             attempted to illuminate the role of these massive descending feedback                projections in sensory information processing, the functional relevance of           these pathways remains largely unknown. Here, we propose to investigate the          physiological contribution of somatosensory corticothalamic projections to the       tactile responses of neurons located in the main thalamic relay nucleus of the       trigeminal system, the ventral posterior medial nucleus. Based on extensive          preliminary data, we propose that, by providing both excitatory and inhibitory       influences to the somatosensory thalamus, corticofugal projections endow             thalamic neurons with the ability to enhance the differences between orthogonal      tactile stimuli and modify the type of information transmitted to the cortex         according to the behavioral state of the animal. The functional roles of             cortical feedback projections will be assessed by a series of experiments that       combine simultaneous multi-site neural ensemble recordings and reversible            cortical inactivation, in behaving animals. The activity of large populations        of single cortical and thalamic neurons will be simultaneously recorded in the       same rat, while its facial whiskers are stimulated with complex tactile stimuli      generated either passively or during an active behavioral whisker-dependant          discrimination task. Focal regions of the primary somatosensory cortex will be       reversibly inactivated during these simultaneous thalamocortical recordings.         This will allow us to evaluate how cortical projections contribute to the            generation of thalamic sensory responses to complex tactile stimuli. We predict      that in rats cortical feedback facilitates the thalamic responses to a whisker       column stimulus, while suppressing responses to a whisker row. Modifications in      the balance of these contrasting influences should also account for the              observation that VPM neurons become capable of integrating rapid sequences of        whisker column stimuli generated during active whisker exploration. n/a",Corticofugal Modulation of Tactile Sensory Processing,6708002,R01DE013810,"['artificial intelligence', 'body movement', 'corticofugal system', 'electrodes', 'electronic recording system', 'laboratory rat', 'neural information processing', 'neurons', 'neuroregulation', 'sensory discrimination', 'solitary tract nucleus', 'somesthetic sensory cortex', 'stimulus /response', 'thalamic nuclei', 'touch', 'trigeminal nerve', 'vibrissae', 'wakefulness']",NIDCR,DUKE UNIVERSITY,R01,2004,358050,0.041587338084667906
"Probing neural feature selectivity with natural stimuli DESCRIPTION (provided by applicant): The candidate seeks to become independent as a neuroscientist and to work at the interface between neuroscience and physics. The Sloan-Swartz Center at UCSF provides a unique opportunity to become immersed in neuroscience at its cutting edge. While the majority of her time will be spent in research, she will attend a range of systems neuroscience and computer vision courses. The immediate goals of her research are to develop an information-theoretic method that allows for a rigorous statistical analysis of neural responses to natural stimuli, which are non- Gaussian and have strong spatiotemporal correlations; and to use this method to analyze the responses of visual cortical neurons to natural time-varying images. There are numerous indications that the responses of neurons to natural stimuli cannot be completely predicted from their responses to stimuli with simple statistical properties, such as white noise ensembles. However, existing methods for analyzing single neuron responses may be rigorously applied only to Gaussian ensembles. The information-theoretic method involves finding the stimulus dimensions that carry the most information about the neuron's response. The stimulus ensemble is not assumed to be Gaussian. The only assumption made is that the neuron is selective for a small number of stimulus dimensions out of the high-dimensional stimulus space: responses with respect to the relevant dimensions might be arbitrarily nonlinear. After testing the method on model neurons and verifying that it gives reasonable results for cortical neurons probed by natural scenes, the method will be used to test the categorical distinction between simple and complex cells in the primary visual cortex. The method will then be modified so that a large set of directions related to each other via certain symmetry operations, such as translation or scaling, can be simultaneously found, with the goal of systematically probing neurons in extrastriate areas with natural scenes. n/a",Probing neural feature selectivity with natural stimuli,6774651,K25MH068904,"['biophysics', 'cats', 'information theory', 'mathematics', 'method development', 'neural information processing', 'neural transmission', 'neurophysiology', 'statistics /biometry', 'stimulus /response', 'visual cortex', 'visual stimulus']",NIMH,UNIVERSITY OF CALIFORNIA SAN FRANCISCO,K25,2004,110194,0.05319537874959727
"Corticofugal Modulation of Tactile Sensory Processing   DESCRIPTION: In every mammalian sensory system, descending corticothalamic           projections, which originate in multiple cortical areas and reach several            thalamic relay nuclei, far outnumber the terminals of parallel feedforward           projections that carry information from the periphery to the same thalamic           structures. Despite numerous studies and a series of theories which have             attempted to illuminate the role of these massive descending feedback                projections in sensory information processing, the functional relevance of           these pathways remains largely unknown. Here, we propose to investigate the          physiological contribution of somatosensory corticothalamic projections to the       tactile responses of neurons located in the main thalamic relay nucleus of the       trigeminal system, the ventral posterior medial nucleus. Based on extensive          preliminary data, we propose that, by providing both excitatory and inhibitory       influences to the somatosensory thalamus, corticofugal projections endow             thalamic neurons with the ability to enhance the differences between orthogonal      tactile stimuli and modify the type of information transmitted to the cortex         according to the behavioral state of the animal. The functional roles of             cortical feedback projections will be assessed by a series of experiments that       combine simultaneous multi-site neural ensemble recordings and reversible            cortical inactivation, in behaving animals. The activity of large populations        of single cortical and thalamic neurons will be simultaneously recorded in the       same rat, while its facial whiskers are stimulated with complex tactile stimuli      generated either passively or during an active behavioral whisker-dependant          discrimination task. Focal regions of the primary somatosensory cortex will be       reversibly inactivated during these simultaneous thalamocortical recordings.         This will allow us to evaluate how cortical projections contribute to the            generation of thalamic sensory responses to complex tactile stimuli. We predict      that in rats cortical feedback facilitates the thalamic responses to a whisker       column stimulus, while suppressing responses to a whisker row. Modifications in      the balance of these contrasting influences should also account for the              observation that VPM neurons become capable of integrating rapid sequences of        whisker column stimuli generated during active whisker exploration. n/a",Corticofugal Modulation of Tactile Sensory Processing,6634690,R01DE013810,"['artificial intelligence', ' body movement', ' corticofugal system', ' electrodes', ' electronic recording system', ' laboratory rat', ' neural information processing', ' neurons', ' neuroregulation', ' sensory discrimination', ' solitary tract nucleus', ' somesthetic sensory cortex', ' stimulus /response', ' thalamic nuclei', ' touch', ' trigeminal nerve', ' vibrissae', ' wakefulness']",NIDCR,DUKE UNIVERSITY,R01,2003,358050,0.041587338084667906
Structure Based Visual Access to Biomedical Information No abstract available n/a,Structure Based Visual Access to Biomedical Information,6538203,R01LM006316,"['DVD /CD ROM', ' anatomy', ' artificial intelligence', ' computer human interaction', ' computer system design /evaluation', ' information retrieval', ' information systems']",NLM,UNIVERSITY OF WASHINGTON,R01,2002,375228,-0.013478150043470319
"Corticofugal Modulation of Tactile Sensory Processing   DESCRIPTION: In every mammalian sensory system, descending corticothalamic           projections, which originate in multiple cortical areas and reach several            thalamic relay nuclei, far outnumber the terminals of parallel feedforward           projections that carry information from the periphery to the same thalamic           structures. Despite numerous studies and a series of theories which have             attempted to illuminate the role of these massive descending feedback                projections in sensory information processing, the functional relevance of           these pathways remains largely unknown. Here, we propose to investigate the          physiological contribution of somatosensory corticothalamic projections to the       tactile responses of neurons located in the main thalamic relay nucleus of the       trigeminal system, the ventral posterior medial nucleus. Based on extensive          preliminary data, we propose that, by providing both excitatory and inhibitory       influences to the somatosensory thalamus, corticofugal projections endow             thalamic neurons with the ability to enhance the differences between orthogonal      tactile stimuli and modify the type of information transmitted to the cortex         according to the behavioral state of the animal. The functional roles of             cortical feedback projections will be assessed by a series of experiments that       combine simultaneous multi-site neural ensemble recordings and reversible            cortical inactivation, in behaving animals. The activity of large populations        of single cortical and thalamic neurons will be simultaneously recorded in the       same rat, while its facial whiskers are stimulated with complex tactile stimuli      generated either passively or during an active behavioral whisker-dependant          discrimination task. Focal regions of the primary somatosensory cortex will be       reversibly inactivated during these simultaneous thalamocortical recordings.         This will allow us to evaluate how cortical projections contribute to the            generation of thalamic sensory responses to complex tactile stimuli. We predict      that in rats cortical feedback facilitates the thalamic responses to a whisker       column stimulus, while suppressing responses to a whisker row. Modifications in      the balance of these contrasting influences should also account for the              observation that VPM neurons become capable of integrating rapid sequences of        whisker column stimuli generated during active whisker exploration. n/a",Corticofugal Modulation of Tactile Sensory Processing,6516620,R01DE013810,"['artificial intelligence', ' body movement', ' corticofugal system', ' electrodes', ' electronic recording system', ' laboratory rat', ' neural information processing', ' neurons', ' neuroregulation', ' sensory discrimination', ' solitary tract nucleus', ' somesthetic sensory cortex', ' stimulus /response', ' thalamic nuclei', ' touch', ' trigeminal nerve', ' vibrissae', ' wakefulness']",NIDCR,DUKE UNIVERSITY,R01,2002,358050,0.041587338084667906
"Artificial Neural Network modelling for studying posture A major challenge with the application of artificial neural network (ANN) modeling in examining the motor-sensory relation in postural control is that the neural synaptic weights that relate the inputs to the outputs of the ANN are chaotic in nature. In an earlier study through theoretical analysis, numerical simulations and experimental tests, the PI and her colleague have found that these weights are interdependent. The product of these weights is a statistically stable variable and can be used to quantify the input-output relation of the ANN, called Q value. The objective of this proposed research is to extend the above work to the area of human postural control. Specifically, we will explore whether or not a Q value concept in an ANN can be used to quantify the motor-sensory relation in a classical postural control task - maintaining upright balance when the supporting base is suddenly rotated in a toes up direction. We will construct an ANN model that includes two outputs and seven inputs. The two outputs are the EMG signals from ankle dorsiflexor and plantartlexor in response to the onset of the supporting base rotation. The seven inputs are average eye-target distance (distance from eye center to a visual target), head acceleration (both linear and angular), ankle joint rotation, ankle joint rotation speed, and ground reaction forces (both normal and shear) under feet. These inputs represent the mechanical stimulation to the visual, vestibular, and somatosensory systems, respectively. These inputs and outputs variables will be measured directly from two groups of elderly subjects: peripherally neuropathic and normal, non-peripherally neuropathic. We will then determine the weights in the ANN model by a backward-propagation training routine, and the corresponding Q values relating each output to each of the inputs. We will statistically compare the Q values among the multiple sensory inputs within each group. We hypothesize that under this experimental condition, the Q values relating postural muscle activities to the somatosensory inputs would be: (1) significantly higher than the Q values relating to other sensory inputs (such as visual and vestibular inputs) in normal, non-neuropathic subjects; and (2) significantly lower than the Q values relating to other sensory inputs in neuropathic subjects. It is hoped that this study will contribute to our understanding of how sensory information is used to control postural muscle activities, and how a modification in the motor-sensory relation can result in increased postural stability or falls.  n/a",Artificial Neural Network modelling for studying posture,6400894,R03AG019872,"['artificial intelligence', ' balance', ' mathematical model', ' model design /development', ' posture', ' psychomotor function', ' somesthetic sensory cortex', ' vestibular pathway', ' visual pathways']",NIA,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,R03,2001,75500,0.014699565479266272
Structure Based Visual Access to Biomedical Information No abstract available n/a,Structure Based Visual Access to Biomedical Information,6331366,R01LM006316,"['DVD /CD ROM', ' anatomy', ' artificial intelligence', ' computer human interaction', ' computer system design /evaluation', ' information retrieval', ' information systems']",NLM,UNIVERSITY OF WASHINGTON,R01,2001,376150,-0.013478150043470319
"Corticofugal Modulation of Tactile Sensory Processing   DESCRIPTION: In every mammalian sensory system, descending corticothalamic           projections, which originate in multiple cortical areas and reach several            thalamic relay nuclei, far outnumber the terminals of parallel feedforward           projections that carry information from the periphery to the same thalamic           structures. Despite numerous studies and a series of theories which have             attempted to illuminate the role of these massive descending feedback                projections in sensory information processing, the functional relevance of           these pathways remains largely unknown. Here, we propose to investigate the          physiological contribution of somatosensory corticothalamic projections to the       tactile responses of neurons located in the main thalamic relay nucleus of the       trigeminal system, the ventral posterior medial nucleus. Based on extensive          preliminary data, we propose that, by providing both excitatory and inhibitory       influences to the somatosensory thalamus, corticofugal projections endow             thalamic neurons with the ability to enhance the differences between orthogonal      tactile stimuli and modify the type of information transmitted to the cortex         according to the behavioral state of the animal. The functional roles of             cortical feedback projections will be assessed by a series of experiments that       combine simultaneous multi-site neural ensemble recordings and reversible            cortical inactivation, in behaving animals. The activity of large populations        of single cortical and thalamic neurons will be simultaneously recorded in the       same rat, while its facial whiskers are stimulated with complex tactile stimuli      generated either passively or during an active behavioral whisker-dependant          discrimination task. Focal regions of the primary somatosensory cortex will be       reversibly inactivated during these simultaneous thalamocortical recordings.         This will allow us to evaluate how cortical projections contribute to the            generation of thalamic sensory responses to complex tactile stimuli. We predict      that in rats cortical feedback facilitates the thalamic responses to a whisker       column stimulus, while suppressing responses to a whisker row. Modifications in      the balance of these contrasting influences should also account for the              observation that VPM neurons become capable of integrating rapid sequences of        whisker column stimuli generated during active whisker exploration. n/a",Corticofugal Modulation of Tactile Sensory Processing,6331594,R01DE013810,"['artificial intelligence', ' body movement', ' corticofugal system', ' electrodes', ' electronic recording system', ' laboratory rat', ' neural information processing', ' neurons', ' neuroregulation', ' sensory discrimination', ' solitary tract nucleus', ' somesthetic sensory cortex', ' stimulus /response', ' thalamic nuclei', ' touch', ' trigeminal nerve', ' vibrissae', ' wakefulness']",NIDCR,DUKE UNIVERSITY,R01,2001,358050,0.041587338084667906
"RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION The goal of the proposed research is to develop and test a computational theory for the human ability to recognize objects under variable illumination (including extreme shadowing) and viewpoint changes. The ability to recognize objects is of fundamental importance in everyday life and the loss of this ability, due to a stroke or Alzheimer's disease, is a serious handicap to the person involved. The computational theory is based on a new paradigm for object representation --generative modeling - - in which an image-based model of an object is ""generated"" from a small set of training images. This theory has been demonstrated to successfully recognize objects from real images under extreme lighting variations. This gives a reality check on the theory and can be thought of as making it an ecological theory (in the sense that it yields good results on the types of images that humans encounter in the real world and not just on the visual stimuli occurring in laboratories). We have assembled a team of researchers with interdisciplinary skills in computer and biological vision. who will divide their efforts on the project based on their expertise. It is our explicit intent that the algorithms and psychophysical studies develop in tandem, with each group verifying the other's results. Indeed, as reviewed below, the computer vision theory, when applied to human performance, makes a number of predictions. some of which have already been partially confirmed by our preliminary experimental work. Our proposal is organized into three main areas. The psychophysical work parallels the computational issues in three series of experiments in which we investigate: (I) How human observers learn and recognize objects, given variable lighting conditions, from a single fixed viewpoint. (II) How illumination and viewpoint interact in human object recognition. (III) The role of class-specific knowledge in recognition.  n/a",RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION,6384831,R01EY012691,"['computer simulation', ' form /pattern perception', ' human subject', ' light intensity', ' psychophysics', ' visual perception']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2001,356485,0.05050784758530451
"VISUAL OBJECT RECOGNITION OF CATEGORIES AND EXEMPLARS Fundamental to visual object recognition is the ability to recognize abstract categories of objects (e.g., cups versus pens) as well as specific exemplars within those categories (e.g., individual pens).  Interestingly, this ability poses a dilemma for the visual system: How can it recognize that two shapes should be considered the same (i.e., belong to the same abstract category) yet also different (i.e., correspond to different exemplars)?  The aim of the proposed work is to investigate how the human brain may implement a solution to this problems.  In particular, the goal is to uncover the architecture of functionally defined, neurally dissociable subsystems that underlie object recognition, and to determine whether this architecture reflects a solution to the abstract/specific dilemma.  Understanding the structure of component subsystems has primary importance, as it must be addressed before satisfactory answers can be offered for contemporary questions in this field; different answers may apply to different subsystems.  Preliminary studies indicate that dissociable subsystems learn to operate in parallel to accomplish abstract-category and specific-exemplar recognition of visual objects.  However, it is difficult to produce fail-safe dissociations of functionally specified subsystems, and other architectures remain viable as alternative theories (e.g., dissociable subsystems operating in sequence, a single general-purpose mechanism, attention to different information within a single subsystem).  Thus, the proposed research will further test and refine these theories, using a converging evidence attack to draw strong conclusions.  The research will integrate analyses of the goals of the visual system with evidence of the neural implementation of dissociable subsystems to constrain such theories.  Divided-visual-field studies will test whether abstract-category and specific-exemplar recognition subsystems operate in parallel (rather than in sequence) and with different relative efficiencies in the left and right cerebral hemispheres.  They also will test the particular levels of categorization performed by abstract and specific subsystems, whether stimulus and task demands influence the relative contributions of these subsystems in predictable ways, as well as whether these subsystems utilize contradictory processing strategies (e.g., features-based versus whole-based processing).  Overall, should evidence for dissociable parallel subsystems be observed, object recognition theories that attempt to account for performance through different architectures would have to be significantly revised.  In any case, this research should lead to a greater understanding of the component subsystems underlying visual object recognition, with implications for addressing why neurological damage can produce selective visual recognition impairments and for suggesting useful architectures in computer vision systems.  n/a",VISUAL OBJECT RECOGNITION OF CATEGORIES AND EXEMPLARS,6392656,R03MH060442,"['behavioral /social science research tag', ' classification', ' clinical research', ' human subject', ' neural information processing', ' vision', ' visual perception']",NIMH,UNIVERSITY OF MINNESOTA TWIN CITIES,R03,2001,67221,0.07485498710164006
"RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION The goal of the proposed research is to develop and test a computational theory for the human ability to recognize objects under variable illumination (including extreme shadowing) and viewpoint changes. The ability to recognize objects is of fundamental importance in everyday life and the loss of this ability, due to a stroke or Alzheimer's disease, is a serious handicap to the person involved. The computational theory is based on a new paradigm for object representation --generative modeling - - in which an image-based model of an object is ""generated"" from a small set of training images. This theory has been demonstrated to successfully recognize objects from real images under extreme lighting variations. This gives a reality check on the theory and can be thought of as making it an ecological theory (in the sense that it yields good results on the types of images that humans encounter in the real world and not just on the visual stimuli occurring in laboratories). We have assembled a team of researchers with interdisciplinary skills in computer and biological vision. who will divide their efforts on the project based on their expertise. It is our explicit intent that the algorithms and psychophysical studies develop in tandem, with each group verifying the other's results. Indeed, as reviewed below, the computer vision theory, when applied to human performance, makes a number of predictions. some of which have already been partially confirmed by our preliminary experimental work. Our proposal is organized into three main areas. The psychophysical work parallels the computational issues in three series of experiments in which we investigate: (I) How human observers learn and recognize objects, given variable lighting conditions, from a single fixed viewpoint. (II) How illumination and viewpoint interact in human object recognition. (III) The role of class-specific knowledge in recognition.  n/a",RECOGNITION OF OBJECTS UNDER VARIABLE ILLUMINATION,6179288,R01EY012691,"['computer simulation', ' form /pattern perception', ' human subject', ' light intensity', ' psychophysics', ' visual perception']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2000,332626,0.05050784758530451
"VISUAL OBJECT RECOGNITION OF CATEGORIES AND EXEMPLARS Fundamental to visual object recognition is the ability to recognize abstract categories of objects (e.g., cups versus pens) as well as specific exemplars within those categories (e.g., individual pens).  Interestingly, this ability poses a dilemma for the visual system: How can it recognize that two shapes should be considered the same (i.e., belong to the same abstract category) yet also different (i.e., correspond to different exemplars)?  The aim of the proposed work is to investigate how the human brain may implement a solution to this problems.  In particular, the goal is to uncover the architecture of functionally defined, neurally dissociable subsystems that underlie object recognition, and to determine whether this architecture reflects a solution to the abstract/specific dilemma.  Understanding the structure of component subsystems has primary importance, as it must be addressed before satisfactory answers can be offered for contemporary questions in this field; different answers may apply to different subsystems.  Preliminary studies indicate that dissociable subsystems learn to operate in parallel to accomplish abstract-category and specific-exemplar recognition of visual objects.  However, it is difficult to produce fail-safe dissociations of functionally specified subsystems, and other architectures remain viable as alternative theories (e.g., dissociable subsystems operating in sequence, a single general-purpose mechanism, attention to different information within a single subsystem).  Thus, the proposed research will further test and refine these theories, using a converging evidence attack to draw strong conclusions.  The research will integrate analyses of the goals of the visual system with evidence of the neural implementation of dissociable subsystems to constrain such theories.  Divided-visual-field studies will test whether abstract-category and specific-exemplar recognition subsystems operate in parallel (rather than in sequence) and with different relative efficiencies in the left and right cerebral hemispheres.  They also will test the particular levels of categorization performed by abstract and specific subsystems, whether stimulus and task demands influence the relative contributions of these subsystems in predictable ways, as well as whether these subsystems utilize contradictory processing strategies (e.g., features-based versus whole-based processing).  Overall, should evidence for dissociable parallel subsystems be observed, object recognition theories that attempt to account for performance through different architectures would have to be significantly revised.  In any case, this research should lead to a greater understanding of the component subsystems underlying visual object recognition, with implications for addressing why neurological damage can produce selective visual recognition impairments and for suggesting useful architectures in computer vision systems.  n/a",VISUAL OBJECT RECOGNITION OF CATEGORIES AND EXEMPLARS,6131974,R03MH060442,"['behavioral /social science research tag', ' classification', ' clinical research', ' human subject', ' neural information processing', ' vision', ' visual perception']",NIMH,UNIVERSITY OF MINNESOTA TWIN CITIES,R03,2000,67687,0.07485498710164006
"Structure and Function of a Cubic Millimeter of Cortex: Crowdsourcing for Proofreading and Discovery At the end of 2020, the IARPA MICrONS program will conclude with an automated reconstruction of all neurons in a cubic millimeter of mouse visual cortex, along with the neurons’ synaptic connectivity and calcium-imaged responses to video stimuli. We believe that this dataset could become the most widely used resource in the field of cortical circuits, but more work is required to realize this potential. We propose to create an online community called Pyr (pronounced “peer”) that takes the result of MICrONS as its starting point. We propose to detect and correct the remaining errors in the automated segmentation through automated algorithms and human proofreading working in tandem. Automated error detection and correction will utilize hand-designed heuristics as well as deep learning and deep metric learning. Proofreading will be crowdsourced to nonscientist volunteers, a concept pioneered by Eyewire, but updated to handle a 1000x larger dataset and far more accurate artificial intelligence. We expect that Pyr will generate more cortical connections than any previous study, by orders of magnitude. This information will be accompanied by calcium-imaged visual responses of 80,000 neurons. With such an enormous and rich dataset, the primary bottleneck will become scientific discovery. We propose to crowdsource discovery by assembling a community of researchers who collaborate with Pyr and each other. Discovery infrastructure will include a “Science API” that allows programmatic access to the primary and derived data through Python functions, an automated system for “materializing” the connectome that makes the result of proofreading available to researchers with essentially zero delay, and a versioning system will insure that analyses are reproducible. We will create a framework enabling the community to contribute their own kinds of annotations, which will be included in materialization. Finally, we will build interactive discovery tools that couple Science API queries with visualization. We envision a community of researchers who will build upon the above discovery infrastructure, creating and sharing analysis tools of their own. They will investigate diverse questions about cortical structure and function, including many that we cannot foresee at all. In the future, Pyr could incorporate other cortical datasets as they become available, with much less engineering effort than the original MICrONS dataset. As with MICrONS, software will be developed in the open in public github repos. This software could be reused by others to build systems similar to Pyr. This project will create Pyr, an online community that makes scientific discoveries about cortical structure and function by reconstructing and analyzing the connections between neurons in a cubic millimeter of mouse cortex along with the activity of the same neurons. Pyr will provide fundamental knowledge about normal function of the cortex, which is expected to be useful when studying mouse models of mental disorders.",Structure and Function of a Cubic Millimeter of Cortex: Crowdsourcing for Proofreading and Discovery,10025901,RF1MH123400,"['3-Dimensional', 'Area', 'Artificial Intelligence', 'Brain', 'Calcium', 'Caring', 'Cellular biology', 'Classification', 'Code', 'Communities', 'Computer software', 'Continuing Education', 'Data', 'Data Set', 'Dependence', 'Detection', 'Educational workshop', 'Electron Microscopy', 'Engineering', 'Event', 'Funding', 'Future', 'Hand', 'Human', 'Image', 'Infrastructure', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Mental disorders', 'Mus', 'Neuroglia', 'Neurons', 'Pythons', 'Reproducibility', 'Research Personnel', 'Resources', 'Science', 'Source', 'Stimulus', 'Structure', 'Synapses', 'System', 'Training', 'Update', 'Visual', 'Visual Cortex', 'Visualization', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'cell type', 'cognitive load', 'connectome', 'crowdsourcing', 'deep learning', 'design', 'heuristics', 'imaging Segmentation', 'improved', 'large datasets', 'microscopic imaging', 'millimeter', 'mouse model', 'online community', 'peer', 'programs', 'reconstruction', 'recruit', 'response', 'tool', 'visual coding', 'volunteer']",NIMH,PRINCETON UNIVERSITY,RF1,2020,6000000,0.0019558852558634147
"CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision   To understand and navigate the environment, sensory systems must solve simultaneously two competing and challenging tasks: the segmentation of a sensory scene into individual objects and the grouping of elementary sensory features to build these objects. Understanding perceptual grouping and segmentation is therefore a major goal of sensory neuroscience, and it is central to advancing artificial perceptual systems that can help restore impaired vision. To make progress in understanding image segmentation and improving algorithms, this project combines two key components. First, a new experimental paradigm that allows for well-controlled measurements of perceptual segmentation of natural images. This addresses a major limitation of existing data that are either restricted to artificial stimuli, or, for natural images, rely on manual labeling and conflate perceptual, motor, and cognitive factors. Second, this project involves developing and testing a computational framework that accommodates bottom-up information about image statistics and top-down information about objects and behavioral goals. This is in contrast with the paradigmatic view of visual processing as a feedforward cascade of feature detectors, that has long dominated computer vision algorithms and our understanding of visual processing. The proposed approach builds instead on the influential theory that perception requires probabilistic inference to extract meaning from ambiguous sensory inputs. Segmentation is a prime example of inference on ambiguous inputs: the pixels of an image often cannot be labeled with certainty as grouped or segmented. This project will test the hypothesis that human visual segmentation is a process of hierarchical probabilistic inference. Specific Aim 1 will determine whether the measured variability of human segmentations reflects the uncertainty predicted by the model, as required for well-calibrated probabilistic inference. Specific Aim 2 addresses how feedforward and feedback processing in human segmentation contribute to efficient integration of visual features across different levels of complexity, from small contours to object parts. Specific Aim 3 will determine reciprocal interactions between perceptual segmentation and top-down influences including: semantic scene content; visual texture discrimination; and expectations reflecting environmental statistics. The proposed approach models these influences as Bayesian priors, and thus, if supported by the proposed experiments, will offer a unified framework to understand the integration of bottom-up and top- down influences in human segmentation of natural inputs. RELEVANCE (See instructions): This project aims to provide a unified understanding of perceptual segmentation and grouping of visual inputs encountered in the natural environment, through correct integration of the information contained in the visual inputs with top-down information about objects and behavioral goals. This understanding is central to advancing artificial perceptual systems that can help restore impaired vision in patient populations. n/a",CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision  ,10018924,R01EY031166,"['Address', 'Algorithms', 'Behavioral', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Set', 'Discrimination', 'Environment', 'Experimental Designs', 'Feedback', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Individual', 'Influentials', 'Instruction', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Motor', 'Neurodevelopmental Disorder', 'Neurons', 'Participant', 'Perception', 'Process', 'Protocols documentation', 'Recurrence', 'Semantics', 'Sensory', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Texture', 'Uncertainty', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'base', 'behavior influence', 'computer framework', 'deep learning', 'detector', 'expectation', 'experimental study', 'flexibility', 'imaging Segmentation', 'improved', 'object recognition', 'patient population', 'predictive modeling', 'segmentation algorithm', 'sensory input', 'sensory integration', 'sensory neuroscience', 'sensory system', 'statistics', 'theories', 'vision science', 'visual processing']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,190044,0.06719732589234889
"CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision   To understand and navigate the environment, sensory systems must solve simultaneously two competing and challenging tasks: the segmentation of a sensory scene into individual objects and the grouping of elementary sensory features to build these objects. Understanding perceptual grouping and segmentation is therefore a major goal of sensory neuroscience, and it is central to advancing artificial perceptual systems that can help restore impaired vision. To make progress in understanding image segmentation and improving algorithms, this project combines two key components. First, a new experimental paradigm that allows for well-controlled measurements of perceptual segmentation of natural images. This addresses a major limitation of existing data that are either restricted to artificial stimuli, or, for natural images, rely on manual labeling and conflate perceptual, motor, and cognitive factors. Second, this project involves developing and testing a computational framework that accommodates bottom-up information about image statistics and top-down information about objects and behavioral goals. This is in contrast with the paradigmatic view of visual processing as a feedforward cascade of feature detectors, that has long dominated computer vision algorithms and our understanding of visual processing. The proposed approach builds instead on the influential theory that perception requires probabilistic inference to extract meaning from ambiguous sensory inputs. Segmentation is a prime example of inference on ambiguous inputs: the pixels of an image often cannot be labeled with certainty as grouped or segmented. This project will test the hypothesis that human visual segmentation is a process of hierarchical probabilistic inference. Specific Aim 1 will determine whether the measured variability of human segmentations reflects the uncertainty predicted by the model, as required for well-calibrated probabilistic inference. Specific Aim 2 addresses how feedforward and feedback processing in human segmentation contribute to efficient integration of visual features across different levels of complexity, from small contours to object parts. Specific Aim 3 will determine reciprocal interactions between perceptual segmentation and top-down influences including: semantic scene content; visual texture discrimination; and expectations reflecting environmental statistics. The proposed approach models these influences as Bayesian priors, and thus, if supported by the proposed experiments, will offer a unified framework to understand the integration of bottom-up and top- down influences in human segmentation of natural inputs. RELEVANCE (See instructions): This project aims to provide a unified understanding of perceptual segmentation and grouping of visual inputs encountered in the natural environment, through correct integration of the information contained in the visual inputs with top-down information about objects and behavioral goals. This understanding is central to advancing artificial perceptual systems that can help restore impaired vision in patient populations. n/a",CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision  ,10135248,R01EY031166,"['Address', 'Algorithms', 'Behavioral', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Set', 'Discrimination', 'Environment', 'Experimental Designs', 'Feedback', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Individual', 'Influentials', 'Instruction', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Motor', 'Neurodevelopmental Disorder', 'Neurons', 'Participant', 'Perception', 'Process', 'Protocols documentation', 'Recurrence', 'Semantics', 'Sensory', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Texture', 'Uncertainty', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'base', 'behavior influence', 'computer framework', 'deep learning', 'detector', 'expectation', 'experimental study', 'flexibility', 'imaging Segmentation', 'improved', 'object recognition', 'patient population', 'predictive modeling', 'segmentation algorithm', 'sensory input', 'sensory integration', 'sensory neuroscience', 'sensory system', 'statistics', 'theories', 'vision science', 'visual processing']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,7300,0.06719732589234889
"Guiding Attention in Real-World Scenes Project Summary Real-world scenes contain far more information than we can perceive at any given moment. Scene perception therefore requires attentional selection of relevant scene regions for prioritized processing. How are those aspects of the world that should receive priority selected? Although much past research has focused on how attention is guided by the visual properties of a scene, new evidence from meaning maps, developed in the previous funding period, established that the distribution of meaning across a scene plays a central and often dominant role in guiding attention. This surprising finding raises many important new questions about the nature of scene meaning and its specific role in attentional guidance. The overarching goal of this project is to understand in detail how the semantic features of a scene’s objects and functional spaces influence the guidance of visual attention in complex real-world scenes. The specific aims are: (1) To determine the role of object semantics in attentional guidance in scenes; (2) To determine the role of functional spaces in attentional guidance in scenes; (3) To determine how viewing task interacts with scene semantics in guiding attention. The project is innovative in expanding the traditional study of attention to explicitly consider the role of meaning. To this end, new semantic maps capitalizing on the meaning map concept will be used capture local region meaning continuously over a scene, allowing for direct investigation of the relationships of different types of meaning with attention. The project is innovative in (1) expanding the traditional study of visual attention to explicitly consider the role of semantics; (2) focusing on the semantics of both scene content (objects) and scene structure (space); (3) considering the role of meaning in attentional guidance in the context of viewing task; (4) integrating the use of a wide variety of cognitive science methods marshalled in the service of understanding the influence of meaning on visual attention in real-world scenes, including eyetracking, large-scale crowd-sourcing, computational image processing, computational semantic modeling, and deep convolutional neural networks. The project is significant in challenging current models of visual attention to account for the role of scene meaning. Because the proposed studies test competing models, the results will lead to the development of integrative theoretical frameworks that advance the field regardless of the outcome. While focused on basic science, the studies have potentially important translational implications by providing a more complete characterization of the processes associated with visual attention. The proposed studies may ultimately lead to the development of rehabilitation strategies for visual attention as it operates in the real world, better capitalizing on the use of a viewer’s knowledge to offset disrupted functions in those with attention and vision deficits. Project Narrative The visual world presents us with far more information than we can process at any given moment. How does the brain select those aspects of the world that should receive priority for visual analysis? This project investigates how we select and attend to meaningful information the natural environment given what we are currently trying to accomplish. The studies combine high-resolution eyetracking with models of meaning based on crowd-sourced human ratings, computer vision models of image processing, deep learning models of scene recognition and attention, and hybrid artificial intelligence models of complex concepts. The role of meaning in guiding attention is contrasted with the role of pre-semantic image features. The knowledge gained will increase our theoretical understanding of how visual attention and perception operate in complex meaningful scenes, assist in the identification of individuals with deficits in visual attention, and may ultimately lead to the development of targeted rehabilitation strategies for the real world.",Guiding Attention in Real-World Scenes,10049970,R01EY027792,"['Address', 'Artificial Intelligence', 'Attention', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Cognition', 'Cognitive Science', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Environment', 'Esthetics', 'Evaluation', 'Funding', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Individual', 'Investigation', 'Judgment', 'Knowledge', 'Lead', 'Maps', 'Marshal', 'Methods', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurologic', 'Outcome', 'Perception', 'Play', 'Population', 'Process', 'Property', 'Quality of life', 'Research', 'Resolution', 'Role', 'Semantics', 'Services', 'Spatial Distribution', 'Structure', 'Testing', 'Ursidae Family', 'Vision', 'Visual', 'Visual Perception', 'Visual attention', 'Work', 'base', 'behavior test', 'concept mapping', 'convolutional neural network', 'crowdsourcing', 'deep learning', 'digital imaging', 'experimental study', 'grasp', 'image processing', 'imaging properties', 'innovation', 'insight', 'model development', 'rehabilitation strategy', 'visual information', 'visual search']",NEI,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2020,381403,0.0793562281140096
"Markerless Tracking of 3D Posture to Reveal the Sensory Origins of Body Schema The goal of this proposed research is to reveal the sensory origins underlying the body schema representation. Body schema is the brain's internal model of the body's spatial configuration. This internal representation is critical for sensorimotor processing, movement control, and self-awareness, and is continuously updated during movement. Body schema representations are disrupted when somatosensory input is lost. The first step toward discover the neural correlates of body schema is to uncover neural mechanisms that generate body posture representation. We hypothesize that sensory inputs from primary somatosensory cortex (S1) and secondary somatosensory cortex (S2) to the posterior parietal cortex (PPC) are transformed to construct a body posture representation.  To delineate the mechanisms underlying the neural coding of body posture, this project will utilize large- scale monitoring, apply interventional tools, develop new data analysis tools, and integrate new approaches. Our approach is to perform large-scale electrophysiological recording and novel markerless tracking of 3D posture in freely moving mice. To track posture, the first aim is to adapt a markerless tracking pipeline comprised of a deep 3D convolutional neural network to process high-speed videography of mouse behavior from multiple cameras. The second aim is to perform large-scale recording of neurons in S1, S2, and PPC and use advanced computational approaches to determine which postural features best explain the activity of neurons in these cortical areas. Finally, the third aim is to use optogenetic and projection-specific manipulations to address the causal impact of proprioceptive inputs from S1 and S2 on coding of posture in PPC. This research promises to uncover how sensory inputs are involved in generating the body schema representation and guiding behavior.  Extensive training will be required to carry out this project and achieve my goal of earning a tenure-track professor position. The rigorous methodological and intellectual environment in Dr. Fan Wang’s lab and the Duke Neurobiology community will advance my conceptual knowledge and technical skills. I will implement deep learning techniques through training and collaboration with specialists. I will learn new techniques by attending Neuropixel and computational neuroscience courses. Finally, I will develop my professional skills by frequent attendance of seminars, workshops, and meeting with a postdoctoral mentorship committee.  The proposed project will be conducted in the Department of Neurobiology at the Duke University Medical Campus. This interdisciplinary community at Duke will bolster the research and training included in this application through frequent interaction with talented and collaborative faculty, organization of seminars and symposia, numerous opportunities to practice research talks and receive valuable feedback, formation of a personalized postdoctoral mentorship committee, extensive career and professional training, and invaluable support from the postdoctoral association. Project Narrative Body schema, the brain’s internal model of the spatial configuration of its body parts, is normally updated during movement, but can be disrupted following amputation, stroke, or deafferentation. Understanding how neural circuits generate body schema representation in health and disease could pave the way for improvements in surgical practice, stroke recovery therapy, brain-machine interface technology, and prosthetic limb engineering. Furthermore, sustaining an internal model of the body is a key element of awareness of one’s own body and the body of others, so findings on the sensory origins underlying body schema will have implications ranging from sensorimotor processing, motor control, interpersonal representations, and social cognition.",Markerless Tracking of 3D Posture to Reveal the Sensory Origins of Body Schema,9987939,F32MH122995,"['3-Dimensional', 'Address', 'Affect', 'Amputation', 'Anatomy', 'Animals', 'Area', 'Awareness', 'Behavior', 'Behavioral', 'Body part', 'Brain', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Computer Analysis', 'Computer Vision Systems', 'Data Analyses', 'Deafferentation procedure', 'Disease', 'Educational workshop', 'Electrophysiology (science)', 'Elements', 'Engineering', 'Environment', 'Excision', 'Experimental Models', 'Faculty', 'Feedback', 'Goals', 'Head', 'Health', 'Human', 'Individual', 'Intervention', 'Knowledge', 'Label', 'Learning', 'Limb Prosthesis', 'Limb structure', 'Locomotion', 'Machine Learning', 'Maintenance', 'Medical', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement', 'Mus', 'Neurobiology', 'Neurons', 'Operative Surgical Procedures', 'Parietal Lobe', 'Positioning Attribute', 'Posture', 'Process', 'Proxy', 'Reporting', 'Research', 'Research Training', 'Self Perception', 'Sensory', 'Somatosensory Cortex', 'Specialist', 'Speed', 'Stroke', 'System', 'Tactile', 'Talents', 'Technical Expertise', 'Techniques', 'Technology', 'Testing', 'Touch sensation', 'Training', 'Universities', 'Update', 'Vertebral column', 'base', 'brain machine interface', 'career', 'computational neuroscience', 'convolutional neural network', 'deep learning', 'design', 'experimental study', 'meetings', 'motor control', 'neural circuit', 'neural correlate', 'neuromechanism', 'novel', 'novel strategies', 'optogenetics', 'professor', 'relating to nervous system', 'research to practice', 'sensory input', 'skills', 'social cognition', 'somatosensory', 'stroke recovery', 'symposium', 'tenure track', 'tool']",NIMH,DUKE UNIVERSITY,F32,2020,37289,-0.0064541730544119364
"Predicting Human Olfactory Perception from Molecular Structure PROJECT SUMMARY Modern technology makes it possible to capture a visual scene as a photograph, alter it, send it to another country nearly instantaneously, and store it without concern for degradation. None of this is currently possible in olfaction. Although perfumers and flavorists are adept at mixing odorous molecules to produce a desired perceptual effect, the rules underlying this process are poorly understood at a quantitative level. Current methods for displaying odors to a subject are akin to requiring a Polaroid of every visual stimulus of interest. A more efficient method for probing the olfactory system would be to use a set of 'primary odors'—some limited number of odors from which all other complex odors could be reproduced by appropriate mixtures. Both auditory and visual stimuli have been digitized, and this will eventually be possible in olfaction as well. Predicting odor from chemical structure has been a problem in the field since its inception, but recent advances in machine learning algorithms have made great progress in analogous problems, such as facial recognition. The research proposed here will combine these machine learning techniques with high quality human psychophysics to understand how to predict the smell of a molecule or mixture of odorants, which will ultimately help improve our understanding of disease diagnosis using odors as well as eating-related health and illness. HEALTH RELEVANCE The sense of smell plays a critical role in preferences and aversions for specific foods. The proposed research will combine machine learning techniques with high quality human psychophysics to create a model that can predict the smell of odorous molecules. This model will allow us to describe and control odors, which will increase our understanding of food preference and eating-related health and wellness.",Predicting Human Olfactory Perception from Molecular Structure,9887973,R01DC017757,"['Algorithms', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Code', 'Collection', 'Color', 'Communities', 'Complex', 'Complex Mixtures', 'Country', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Eating', 'Enrollment', 'Face', 'Food', 'Food Preferences', 'Frequencies', 'Health', 'Human', 'Ligands', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Molecular Structure', 'Neurosciences', 'Non-linear Models', 'Numerical value', 'Odors', 'Olfactory Pathways', 'Perception', 'Play', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Role', 'Smell Perception', 'Stimulus', 'Techniques', 'Technology', 'Training', 'Translating', 'Vision', 'Visual', 'Vocabulary', 'Work', 'auditory stimulus', 'base', 'computer monitor', 'disease diagnosis', 'experience', 'high dimensionality', 'improved', 'in silico', 'interest', 'machine learning algorithm', 'member', 'novel', 'physical property', 'predictive modeling', 'predictive test', 'preference', 'receptor', 'relating to nervous system', 'single molecule', 'visual stimulus']",NIDCD,MONELL CHEMICAL SENSES CENTER,R01,2020,496911,0.023628270489660656
"Neural representation of the geometry and functionality in a scene ﻿    DESCRIPTION (provided by applicant):  The goal of the proposed research is to investigate how the brain represents scene geometry and functionality. Recognizing the visual environment is central to our daily interactions with the world. When we walk into a new space, we rapidly recognize whether there is a path to follow, whether there are crossable boundaries, and whether there are obstacles that block our view and potential navigation. The theoretical framework of this proposal is based on evidence that there are distinct but complementary levels of scene representation across a group of scene-selective regions in the brain (Park et al., 2011; Park et al., 2014; Park & Chun, 2009; Park, Chun, & Johnson, 2010; Park, Intraub, Yi, Widders, & Chun, 2007). The PI proposes that scene geometry (e.g., spatial layout, three-dimensional scene boundary) and functionality (e.g., navigability, limitations of a boundary) are two fundamental scene properties represented in these regions. Specific Aims: Aim 1 investigates whether the brain displays acute sensitivity to the presence of vertical boundaries, and how such sensitivity is modulated by the functional impediment that a boundary presents to the viewer's potential navigation. Aim 2 investigates the neural representation of the scene navigability, and how this representation differs from representation of scene geometry. Aim 3 investigates whether the neural representation of real world scenes is modulated by acquired knowledge about the spatio-temporal context of a scene, which are important for functionality of a scene. Throughout her aims, the PI tests medial temporal lobe regions in human adults that process scene and spatial information: with particular focus on anterior and posterior parahippocampal gyri and retrosplenial cortex. Methods include univariate and multi-voxel fMRI pattern analyses (linear support vector machine classification and representational similarity analysis) in combination with both region-of-interest (ROI) based and whole-brain based (search light) approaches. Hypothesis and preliminary results throughout the proposal suggest that scene geometry is represented in the parahippocampal gyrus, while scene functionality is represented in the retrosplenial cortex. PUBLIC HEALTH RELEVANCE: The research program will establish new framework for understanding the cognitive neuroscience architecture of scene perception, with the aim of unraveling how the human brain analyzes the geometry and functionality of visual environment in order to guide our actions and navigation in the world.",Neural representation of the geometry and functionality in a scene,9910403,R01EY026042,"['3-Dimensional', '4 year old', 'Acute', 'Adult', 'Anterior', 'Architecture', 'Area', 'Base of the Brain', 'Behavioral', 'Brain', 'Categories', 'Cells', 'Characteristics', 'Child', 'Classification', 'Complement', 'Complex', 'Confusion', 'Development', 'Environment', 'Fishes', 'Floor', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Height', 'Human', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Light', 'Medial', 'Methods', 'Modeling', 'Movement', 'Multivariate Analysis', 'Nature', 'Neurologic', 'Parahippocampal Gyrus', 'Patients', 'Pattern', 'Perception', 'Process', 'Property', 'Rattus', 'Research', 'Rodent', 'Semantics', 'Shapes', 'Temporal Lobe', 'Testing', 'Time', 'Vision', 'Visual', 'Visuospatial', 'Walking', 'Work', 'base', 'cognitive neuroscience', 'experimental study', 'extrastriate visual cortex', 'interest', 'neuroimaging', 'neurophysiology', 'novel', 'programs', 'public health relevance', 'rehabilitation strategy', 'relating to nervous system', 'spatiotemporal', 'support vector machine', 'vector']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2020,306185,0.060291664431889665
"Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning PROJECT SUMMARY/ABSTRACT Selective attention is an essential cognitive ability that permits us to effectively process and act upon relevant information while ignoring distracting events. A network involving frontal and parietal cortex for top-down attentional control, referred to as the Dorsal Attention Network (DAN), is active during both spatial and non- spatial (feature-based) attention. However, we know very little about the fine structure of attentional control activity in the DAN, how this structure changes to represent different to-be-attended stimulus features, how the connectivity within the DAN, and between the DAN and sensory cortex shifts when attending different features, or how these top-down processes and their influence in sensory cortex unfold over time. This gap in our knowledge is a critical problem for our models and theories of attention, and because attentional deficits are involved in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia. The working model guiding this research is that top-down attentional control, based on different to-be-attended stimulus attributes, is guided by a smaller-scale neural fine structure within the DAN and prefrontal cortex that makes specific connections with specialized areas of visual cortex coding the attended attributes. Moreover, the time course of activity within the DAN in relation to that in sensory cortex follows a top-down cascading model, being earliest in frontal, then parietal cortex, and finally sensory cortex for preparatory, voluntary, attentional control. To identify the functional networks for attentional control for different forms of attention, and to define their time courses, this project uses innovative simultaneous recording of electroencephalographic (EEG) and functional magnetic resonance imaging (fMRI) data. Advanced signal processing and modeling, including multivariate pattern analysis (MVPA), graph theoretic connectivity analysis, and Granger causality analysis will be used to reveal the fine functional anatomy and time course of attentional control and selection. The project includes three experiments that vary the to-be-attended stimulus attributes from spatial location to stimulus features (color and motion), and pursues three aims. Aim 1 is to reveal the fine structure of top-down preparatory attentional control for different to-be-attended stimulus features. Aim 2 is to elucidate the specific connectivity between fine structures for preparatory attentional control in the DAN and their target sensory structures in sensory cortex. Aim 3 is to reveal the time course of top-down attentional control for different to-be-attended stimulus attributes. PROJECT NARRATIVE The capacity to focus attention is at the core of human mental functioning, and therefore, elucidating the neural bases of attention remains a central challenge for neuroscience, representing an essential aim in translational efforts to ameliorate attentional deficits in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia.",Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning,9878145,R01MH117991,"['Anatomy', 'Attention', 'Attention Deficit Disorder', 'Attentional deficit', 'Brain', 'Code', 'Color', 'Cues', 'Data', 'Dementia', 'Discrimination', 'Dorsal', 'Etiology', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'Graph', 'Human', 'Inferior', 'Knowledge', 'Location', 'Machine Learning', 'Modeling', 'Motion', 'Neurosciences', 'Parietal Lobe', 'Pattern', 'Perception', 'Physiological', 'Prefrontal Cortex', 'Process', 'Property', 'Research', 'Schizophrenia', 'Sensory', 'Specific qualifier value', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Work', 'attentional control', 'autism spectrum disorder', 'base', 'cognitive ability', 'data integration', 'experimental study', 'extrastriate visual cortex', 'frontal lobe', 'indexing', 'innovation', 'mental function', 'neuropsychiatric disorder', 'predictive modeling', 'relating to nervous system', 'selective attention', 'sensory cortex', 'signal processing', 'theories', 'tool']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2020,530307,0.04131512906614843
"Human Face Representation in Deep Convolutional Neural Networks The human visual system can recognize a familiar face across wide variations of viewpoint, illumination, expression, and appearance. This remarkable computational feat is accomplished by large-­scale networks of neurons. We will test a face space theory of the representations that emerge at the top layer of deep learning convolutional neural networks (DCNNs) as a model of human visual representations of faces. Computer-based face recognition has improved in recent years due to DCNNs and the easy availability of labeled training data (faces and identities) from the web. Inspired by the primate visual system, DCNNs are feed­forward artificial neural networks that can map images of faces into representations that support recognition over widely variable images. Although the calculations executed by the simulated neurons are simple, enormous numbers of computations are used to convert an image into a representation. The end result of this processing is a highly compact representation of a face that retains image detail in an invariant, identity­-specific face code. This code is fundamentally different than any representation of faces considered in vision science. This theory we test combines key components of previous face space models (similarity, learning history) with new features (imaging conditions, personal face history) in a unitary space that represents both identity and facial appearance across variable images. We will test whether this model can account for human recognition of familiar faces, which is highly robust to image variability (pose, illumination, expression). The model will also be applied to understanding long standing difficulties humans (and machines) have with faces of other races. We aim to bridge critical gaps in our knowledge of how DCNNs work, linking psychological, neural, and computational perspectives. A fundamentally new theory of face representation will alter the questions we ask about face representations in all three fields. A new focus on understanding how we (or neural networks) “perceive” a single familiar identity in widely variable images will give rise to a search for representations that gracefully merge the properties of faces with the real-­world image conditions in which they are experienced. This project presents a unique opportunity to study, manipulate, and learn from these representations, and to apply the findings to broader questions about high-­level vision from neural and perceptual perspectives. Human recognition of familiar faces is highly robust to image variability (pose, illumination, expression)—a skill that is likely due to the quality and quantity of experience we have with the faces of people we know well. Deep convolutional neural networks are modeled after the primate visual system and have made impressive gains recently on the problem of robust face recognition. Understanding the visual nature of the face “feature” codes that emerge in these networks can give insight into long-standing questions about how the human visual system can, but does not always, represent a face in a way that generalizes across images that vary widely.",Human Face Representation in Deep Convolutional Neural Networks,9873959,R01EY029692,"['Affect', 'Appearance', 'Categories', 'Code', 'Computers', 'Data', 'Data Set', 'Face', 'Face Processing', 'Familiarity', 'Human', 'Image', 'Individual', 'Internet', 'Knowledge', 'Label', 'Learning', 'Lighting', 'Link', 'Maps', 'Methods', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurons', 'Performance', 'Persons', 'Primates', 'Property', 'Published Comment', 'Race', 'Recording of previous events', 'Space Models', 'Testing', 'Training', 'Variant', 'Vision', 'Visual', 'Visual system structure', 'Work', 'artificial neural network', 'base', 'convolutional neural network', 'deep learning', 'experience', 'feedforward neural network', 'human model', 'improved', 'insight', 'neural network', 'psychologic', 'relating to nervous system', 'representation theory', 'skills', 'theories', 'vision science']",NEI,UNIVERSITY OF TEXAS DALLAS,R01,2020,385203,0.020706495481470206
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9939507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Models', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'machine learning method', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,334688,-0.03447618980600548
"Natural image processing in the visual cortex Project Summary Signals from the natural environment are processed by neuronal populations in the cortex. Understanding the relationship between those signals and cortical activity is central to understanding normal cortical function and how it is impaired in psychiatric and neurodevelopmental disorders. Substantial progress has been made in elucidating cortical processing of simple, parametric stimuli, and computational technology is improving descriptions of neural responses to naturalistic stimuli. However, how cortical populations encode the complex, natural inputs received during every day perceptual experience is largely unknown. This project aims to elucidate how natural visual inputs are represented by neuronal populations in primary visual cortex (V1). Progress to date has been limited primarily by two factors. First, during natural vision, the inputs to V1 neurons are always embedded in a spatial and temporal context, but how V1 integrates this contextual information in natural visual inputs is poorly understood. Second, prior work focused almost exclusively on single-neuron firing rate, but to understand cortical representations one must consider the structure of population activity— the substantial trial-to-trial variability that is shared among neurons and evolves dynamically—as this structure influences population information and perception. The central hypothesis of this project is that cortical response structure is modulated by visual context to approximate an optimal representation of natural visual inputs. To test the hypothesis, this project combines machine learning to quantify the statistical properties of natural visual inputs, with a theory of how cortical populations should encode those images to achieve an optimal representation, to arrive at concrete, falsifiable predictions for V1 response structure. The predictions will be tested with measurements of population activity in V1 of awake monkeys viewing natural images and movies. Specific Aim 1 will determine whether modulation of V1 response structure by spatial context in static images is consistent with optimal encoding of those images, and will compare the predictive power of the proposed model to alternative models. Specific Aim 2 addresses V1 encoding of dynamic natural inputs, and will test whether modulation of V1 activity by temporal context is tuned to the temporal structure of natural sensory signals, as required for optimality. As both spatial and temporal are present simultaneously during natural vision, Specific Aim 3 will determine visual input statistics in free-viewing animals, and test space-time interactions in V1 activity evoked by those inputs. This project will provide the first test of a unified functional theory of contextual modulation in V1 encoding of natural visual inputs, and shed light on key aspects of natural vision that have been neglected to date. Project Narrative This project aims to determine how neurons in the visual cortex represent the inputs encountered during perceptual experience in the natural environment, through correct integration of visual information across space and time. In individuals with neurodevelopmental and psychiatric disorders, integration is often miscalibrated leading to perceptual impairments. Our study will advance knowledge of the relationship between natural sensory inputs and cortical activity, which is central to understanding normal cortical function and how it is impaired in patient populations.",Natural image processing in the visual cortex,10018026,R01EY030578,"['Address', 'Animal Testing', 'Area', 'Complex', 'Dependence', 'Development', 'Environment', 'Experimental Designs', 'Goals', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Light', 'Location', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Monkeys', 'Motion', 'Neurodevelopmental Disorder', 'Neurons', 'Perception', 'Population', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Sampling', 'Sensory', 'Signal Transduction', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'V1 neuron', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'base', 'computer framework', 'experience', 'experimental study', 'image processing', 'improved', 'model development', 'movie', 'neglect', 'patient population', 'relating to nervous system', 'response', 'sensory input', 'spatiotemporal', 'statistics', 'theories', 'vision science', 'visual information']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,417500,0.08064812085764175
"Towards a Compositional Generative Model of Human Vision Understanding object recognition has long been a central problem in vision science, because of its applied utility and computational difficulty. Progress has been slow, because of an inability to process complex natural images, where the largest challenges arise. Recently, advances in Deep Convolutional Neural Networks (DCNNs) spurred unprecedented success in natural image recognition. The general goal of this proposal is to leverage this success to test computational theories of human object recognition in natural images. However, DCNNs still markedly underperform humans when challenged with high levels of ambiguity, occlusion, and articulation. We hypothesize that humans' superior performance arises from the use of knowledge about how images and objects are structured. Preliminary evidence for this claim comes from the success of hybrid models, that combine DCNNS for identifying features and parts in images, with explicit knowledge of object and image structure. These computations occur within a hierarchy, which includes both top-down and bottom- up processing. The specific goal of the work proposed here is to strongly test whether these computational strategies, structured, hierarchical representations and bidirectional processing, are used to recognize objects in natural images. Human bodies are composed of hierarchically organized configurable parts, making them an ideal test domain. We examine the complete recognition process, from parts, to pairs of parts, to whole bodies, each in its own aim. Each aim also tests important sub-hypotheses about when and how the computational strategies are used. Aim 1 examines recognition of individual body parts, testing whether it is dependent on parsing images into more basic features and relationships, for example edges and materials. Aim 2 examines pairs of parts, testing the importance of knowledge of body connectedness relationships. Aim 3 examines perception of entire bodies, testing whether knowledge of global body structure guides bidirectional processing. In each aim, we first develop nested computer vision models that either do or do not make use of structural knowledge, to test whether it aids recognition. We then test whether human performance can be accounted for by the availability of that structural knowledge. We next measure neural activity with functional MRI to identify where and how it is used in cortex. Finally, we integrate these results to produce even stronger tests, using the nested models to predict human performance and confusion matrices as well as fMRI activity levels and confusion matrices. Altogether, this work will strongly test key theoretical accounts of object recognition in the most important domain, perception of natural images. The work, based on extensive preliminary data, measures and models the entire body recognition system. The models developed and tested here should surpass the state-of-the-art, and be useful for many real-world recognition tasks. The proposal will also lay the groundwork for future studies of recognition impaired by disease. This research uses computational, behavioral, and brain imaging methods to investigate how the visual system represents and processes information about human bodies. The studies will reveal how and when people can accurately recognize objects in natural images, how the brain supports this function, and how loss of information, similar to that that accompanies visual disease, may affect the ability to interpret everyday scenes.",Towards a Compositional Generative Model of Human Vision,10018020,R01EY029700,"['Affect', 'Area', 'Articulation', 'Behavioral', 'Body Image', 'Body part', 'Brain', 'Brain imaging', 'Complex', 'Computer Vision Systems', 'Confusion', 'Cues', 'Data', 'Development', 'Disease', 'Elbow', 'Feedback', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Human body', 'Hybrids', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Link', 'Measures', 'Modeling', 'Perception', 'Performance', 'Predictive Value', 'Process', 'Psychophysics', 'Published Comment', 'Research', 'Structure', 'System', 'Testing', 'Training', 'Vision', 'Visual', 'Visual system structure', 'Work', 'Wrist', 'base', 'convolutional neural network', 'crowdsourcing', 'human model', 'imaging modality', 'improved', 'object recognition', 'relating to nervous system', 'spatial relationship', 'success', 'theories', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2020,332870,0.04043159328319436
"The behavioral functions of upper and lower cortical layers PROJECT SUMMARY/ABSTRACT  The cerebral cortex mediates all of human and animal cognition, encompassing a diverse set of abilities including sensation, perception, decision making, and motor planning. Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders. A major obstacle both to understanding normal behaving and to treating pathology is the high degree of complexity of cortical circuitry, which has remained largely enigmatic. The conventional view of neocortex has been that sensory processing begins in layer 4 (L4), which was identified a century ago as the principal target of thalamic axons carrying information from our sensory organs. Sensory transforms are widely believed to occur as excitation spreads serially along the densest axonal pathways (thalamus→L4→L2/3→L5/6). Recently we discovered that the cerebral cortex, rather than being a monolithic structure, may contain two entirely separate processing systems, activated by the same signals arising from the thalamus. L4 is thus not an obligatory distribution hub for cortical activity, and thalamus activates two distinct “strata” of cortex in parallel.  This proposal's goal is to identify the behavioral and computational roles of the upper (L2-4) and lower strata (L5/6) as well as the interactions between them. We will investigate the behavioral roles of these layers in the mouse whisker system. Specific layers will be optogenetically disrupted in a series of tactile behavioral tasks, in which task complexity is progressively increased. Interlaminar interactions will also be studied by recording electrophysiologically from specific layers during behavior and using novel machine learning techniques designed to identify the type of computation performed in different levels of “deep networks”. The dimensionality of the representation in a layer will be estimated under normal behaviors and when specific layers are inactivated.  Identifying fundamental functions of upper versus cortical layers will likely pave the way for future studies in other neocortical systems and in higher-order species. Moreover, as the different layers contain molecularly and biophysically distinct cell types and project to distinct downstream targets, specific neurological disorders may involve dysfunction of specific pathways, cell types, and layers. Establishing the behavioral and computational roles of these elements may contribute to development of targeted therapies. PROJECT NARRATIVE  Dysfunctions of the cerebral cortex are thought to underlie numerous neurological and psychiatric disorders, but the behavioral and functional roles of cortical layers and cell types are unknown. Identifying the contributions of specific cortical layers to normal circuit function will lead to better treatment of pathological conditions.     ",The behavioral functions of upper and lower cortical layers,9914374,R01NS094659,"['Animals', 'Area', 'Auditory', 'Axon', 'Behavior', 'Behavioral', 'Biophysics', 'Brain', 'Cells', 'Cerebral cortex', 'Cognition', 'Complex', 'Corpus striatum structure', 'Data Analyses', 'Decision Making', 'Detection', 'Development', 'Dimensions', 'Discrimination', 'Electrophysiology (science)', 'Elements', 'Esthesia', 'Functional disorder', 'Future', 'Goals', 'Halorhodopsins', 'Human', 'Individual', 'Machine Learning', 'Measures', 'Mediating', 'Mental disorders', 'Modality', 'Molecular', 'Morphology', 'Motor', 'Mus', 'Neocortex', 'Neurons', 'Organ', 'Output', 'Pathologic', 'Pathology', 'Pathway interactions', 'Perception', 'Performance', 'Population', 'Role', 'Sensory', 'Sensory Physiology', 'Series', 'Shapes', 'Signal Transduction', 'Source', 'Spinal Cord', 'Stimulus', 'Structure', 'Synapses', 'System', 'Tactile', 'Task Performances', 'Techniques', 'Testing', 'Texture', 'Thalamic structure', 'Training', 'Vibrissae', 'biophysical properties', 'cell type', 'design', 'expectation', 'hippocampal pyramidal neuron', 'neocortical', 'nervous system disorder', 'novel', 'object shape', 'optogenetics', 'response', 'sensory discrimination', 'spatial integration', 'targeted treatment']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,350000,0.014565273175048058
"Shared and specific mechanisms of auditory and visual category learning PROJECT SUMMARY/ABSTRACT The ability to learn new perceptual categories enables some of the most complex human behaviors, from speech perception to visual object recognition. Current understanding of the mechanisms involved in perceptual category learning relies on the fundamental assumption that the processes underlying such learning are shared across the senses. However, the vast majority of this work has focused on the visual modality. As a consequence, the research regarding how humans learn to group complex auditory information into categories has relied greatly on conclusions from the research in the visual domain without testing this critical assumption. However, recent evidence from the attention literature suggests that even seemingly domain-general cognitive processes, such as working memory, are accomplished via sensory-biased regions in frontal cortex. The current investigation will directly compare the computational and neural mechanisms supporting auditory and visual category learning by training the same individuals on categories in both modalities while in an fMRI scanner. Aim #1 of this investigation will identify the shared and sensory-biased circuits supporting feedback processing during auditory and visual category learning. If the neural circuits supporting perceptual category learning are shared across the modalities, it is expected that similar regions will be recruited to a similar extent during feedback processing. If instead, the neural circuits are distinct for particular modalities, it is expected that sensory-biased regions will emerge as supporting category learning for auditory and visual modalities. Aim #2 will utilize advanced machine learning techniques (multivariate pattern classification and representational similarity analyses) to characterize the emergence of category-level neural representations over the course of learning. Aim #3 will identify the functional and structural connectivity of the circuits as they contribute to perceptual category learning. The proposed research will directly test the fundamental assumption about the nature of this complex problem that affects everyday behaviors. This research has the potential to impact understanding of cases where modality- specific learning abilities might be impaired, such as phonetic learning and language-related impairments in dyslexia, autism, and specific language impairment. The proposed research will provide the training foundation to support the PI’s long-term objective of developing theories of perceptual category learning that are constrained by neurobiology and behavior and will specify the behavioral, computational, and neural mechanisms of such learning. This project presents the opportunity to directly test a critical assumption underlying understanding of perceptual category learning. The proposed research will take place in an exceptional training environment and the PI will be mentored by a team of knowledgeable and accomplished scientists. The research will provide the PI with training in functional magnetic resonance experiment design and analysis which will prepare her well for a career as an independent scientist in computational cognitive neuroscience. PROJECT NARRATIVE The proposed research will contribute to fundamental knowledge about how seemingly general-purpose cognitive systems may demonstrate modality specificity. The goal of this investigation is to characterize the differences in cognitive processing during category learning when the information comes from the auditory or visual modalities. The findings from this work may inform mechanistic approaches to understanding modality- specific deficits in language-based disorders, such as dyslexia, autism, and specific language impairment.",Shared and specific mechanisms of auditory and visual category learning,10064815,F32DC018979,"['Affect', 'Area', 'Attention', 'Auditory', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Corpus striatum structure', 'Disease', 'Dyslexia', 'Environment', 'Esters', 'Feedback', 'Finches', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hobbies', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Magnetic Resonance', 'Mentors', 'Modality', 'Modeling', 'Nature', 'Neurobiology', 'Participant', 'Pattern', 'Process', 'Property', 'Research', 'Scientist', 'Sensory', 'Short-Term Memory', 'Specific qualifier value', 'Specificity', 'Speech', 'Speech Perception', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Training', 'Visual', 'Work', 'auditory stimulus', 'autism spectrum disorder', 'base', 'behavior measurement', 'career', 'cognitive neuroscience', 'cognitive process', 'cognitive system', 'design', 'experimental study', 'frontal lobe', 'individual variation', 'innovation', 'learning ability', 'neural circuit', 'neuromechanism', 'object recognition', 'programs', 'recruit', 'relating to nervous system', 'response', 'sound', 'specific language impairment', 'theories', 'visual learning']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F32,2020,64554,0.0071539359622389675
"Discovering the rules for the organization of macaque inferotemporal cortex. Project Summary How is the representation of complex visual objects organized in inferotemporal (IT) cortex, the large brain region responsible for object recognition? To date, areas selective for a few categories such as faces, bodies, and scenes have been found, but the vast majority of IT cortex is “wild,” lacking any known specialization. Various schemes have been proposed for parceling IT, but a comprehensive understanding of IT organization remains elusive. Here, we propose to use fMRI, microstimulation, and electrophysiology to develop a unified understanding of the organization and coding principles of macaque IT. The experiments are motivated by a major advance in computer vision and two key preliminary results from our lab. First, the advent of deep networks trained for object classification makes it possible to generate a parametric object space, providing a quantitative framework to decipher the feature selectivity of single IT cells. Second, our preliminary results suggest that a large portion of macaque IT cortex is topographically organized according to the first two principal components of object space. This topography encompasses at least four distinct networks, each with at least three hierarchical nodes of increasing view invariance, and includes the previously described face and body patch networks. Furthermore, single cells within each network are projecting incoming objects, formatted as vectors in the object space, onto specific preferred axes. Taken together, these results suggest a new hypothesis for IT organization: IT cortex is tiled by networks (i.e., sets of functionally connected nodes, where a node is a patch of IT cells) whose organization and coding principles are very similar to that of the face patch network, and the layout of these networks follows a regular topography specified by the statistical structure of object space. We propose three Specific Aims to rigorously test this hypothesis. In Aim 1, we will systematically map all networks within IT of individual animals. In Aim 2, we will record responses of cells in each identified network to a large, common set of object stimuli and determine their coding scheme. In Aim 3, we will perturb activity in each network and quantitatively assess effect on object recognition behavior. Together, these three Aims seek to build a comprehensive understanding of IT organization that bridges fMRI, single units, and behavior. Our lab has developed powerful experimental techniques to tackle each of these Aims and has previously applied them to the macaque face patch system. We believe the time is ripe to apply these techniques to the larger problem of how all objects are represented--not just faces. In the same way that Mendeleev’s arrangement of chemical elements according to their atomic mass and chemical properties helped elucidate the electronic structure of atoms, we believe systematic mapping and characterization of all networks in IT will help elucidate the fundamental neural mechanism for object recognition. Narrative This basic research application will investigate how visual objects are processed by the brain. The brain areas we will study are located in the temporal lobe, a brain region especially susceptible to neurological disease including Alzheimer’s disease and epilepsy. The planned studies will provide valuable insight into the fundamental code cells in this region use to represent visual information, and will thereby contribute to better understanding, diagnosis, and treatment of diseases targeting this part of the brain.",Discovering the rules for the organization of macaque inferotemporal cortex.,10006884,R01EY030650,"['Alzheimer&apos', 's Disease', 'Anatomy', 'Animals', 'Area', 'Basic Science', 'Behavior', 'Brain', 'Brain region', 'Categories', 'Cells', 'Chemicals', 'Classification', 'Code', 'Complex', 'Computer Vision Systems', 'Diagnosis', 'Disease', 'Electric Stimulation', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Epilepsy', 'Face', 'Functional Magnetic Resonance Imaging', 'Glean', 'Image', 'Individual', 'Macaca', 'Maps', 'Measures', 'Monkeys', 'Performance', 'Population', 'Process', 'Resolution', 'Sampling', 'Scheme', 'Signal Transduction', 'Site', 'Specific qualifier value', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Temporal Lobe', 'Testing', 'Three-Dimensional Image', 'Time', 'Training', 'Visual', 'chemical property', 'electronic structure', 'experimental study', 'inferotemporal cortex', 'insight', 'microstimulation', 'movie', 'nervous system disorder', 'neuromechanism', 'object perception', 'object recognition', 'relating to nervous system', 'response', 'vector', 'visual information']",NEI,CALIFORNIA INSTITUTE OF TECHNOLOGY,R01,2020,575750,0.061172421609527815
"Cracking the Olfactory Code Project Summary (Overall: Cracking the Olfactory Code)  Sensation drives perception, which informs decisions and actions. Olfaction is the main sense used by most animals to interact with the environment. However, olfaction remains shrouded in mystery — we do not know which molecular odorant features matter to the olfactory system and which do not, how information about these features is recombined to create holistic odor representations within the brain, or how those representations relate to perception. As a consequence, we lack an empirical understanding of the core transformations taking place at each stage of olfactory processing, which ultimately lead to perception and behavior. In addition, we lack a clear theoretical framework for understanding how a stimulus space that is both discrete and high-dimensional yields a perceptual space that is continuous and low dimensional. Because the olfactory system is “shallow” — meaning that within two synapses information about complete odor objects is abstracted and generalized — understanding this specific circuit will also afford general insight both into architecturally-related allocortical brain regions critical to behavior (e.g., cerebellum, hippocampus), and into cortical centers that play a key role in integrating diverse sources of information (e.g., prefrontal cortex, posterior parietal cortex). Here we propose to reveal the computational logic of olfaction by collecting the first system-wide dataset of neural and perceptual responses to a large, principled set of odorants, and by applying a unified statistical and theoretical approach to its interpretation. This project will convene research groups with expertise that spans neurobiology, and will leverage recent technical advances in molecular genetics, neural imaging, electrophysiology, opto- and chemogenetics, human psychophysics, and machine learning to interrogate all levels (from peripheral receptors to cortex to perceptual and behavioral output) of the olfactory system. Taken together, these experiments will establish a reference dataset that reveals the key transformations performed by the olfactory system, test a key unifying theory for olfaction, and create a community-wide resource that will prompt new theory and experiment. This work will also have wide-ranging implications for our general understanding of how sensory information is organized in the brain to facilitate adaptive action. Project Narrative (Overall) The brain builds rich internal representations of the external world in order to support perception and behavior. Here we take advantage of the architectural simplicity of the mammalian olfactory system — and an interdisciplinary team whose expertise ranges from molecular genetics and optogenetic to machine learning and human psychophysics — to characterize how odor information is sequentially transformed by neural circuits to generate meaningful perception. This work will both address longstanding mysteries about the inner workings of the olfactory system, and reveal general principles that govern how the brain organizes and processes information.",Cracking the Olfactory Code,10001592,U19NS112953,"['Address', 'Affinity', 'Animals', 'Architecture', 'Area', 'Behavior', 'Behavioral', 'Behavioral Paradigm', 'Big Data', 'Biological', 'Brain', 'Brain region', 'Cerebellum', 'Chemicals', 'Code', 'Communities', 'Computer Models', 'Data', 'Data Analyses', 'Data Science Core', 'Data Set', 'Decision Making', 'Development', 'Dimensions', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Frequencies', 'Hippocampus (Brain)', 'Human', 'Image', 'Lead', 'Link', 'Logic', 'Machine Learning', 'Measures', 'Modality', 'Modeling', 'Molecular', 'Molecular Genetics', 'Mus', 'Nasal Epithelium', 'Neurobiology', 'Neurons', 'Odorant Receptors', 'Odors', 'Olfactory Pathways', 'Output', 'Parietal Lobe', 'Pattern', 'Perception', 'Peripheral', 'Physiology', 'Play', 'Prefrontal Cortex', 'Process', 'Psychophysics', 'Research', 'Resources', 'Sense Organs', 'Sensory', 'Smell Perception', 'Source', 'Stimulus', 'Structural Models', 'Structure', 'Synapses', 'System', 'Testing', 'Time', 'Vision', 'Work', 'base', 'combinatorial', 'data integration', 'design', 'experimental study', 'genetic manipulation', 'high dimensionality', 'imaging approach', 'in vivo', 'information processing', 'insight', 'meetings', 'neural circuit', 'new technology', 'novel', 'olfactory bulb', 'olfactory receptor', 'olfactory stimulus', 'optogenetics', 'piriform cortex', 'receptor', 'relating to nervous system', 'response', 'sensory stimulus', 'sensory system', 'stimulus processing', 'theories', 'working group']",NINDS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,U19,2020,2773998,-0.016159525873899648
"Cortical computations underlying binocular motion integration PROJECT SUMMARY / ABSTRACT Neuroscience is highly specialized—even visual submodalities such as motion, depth, form and color processing are often studied in isolation. One disadvantage of this isolation is that results from each subfield are not brought together to constrain common underlying neural circuitry. Yet, to understand the cortical computations that support vision, it is important to unify our fragmentary models that capture isolated insights across visual submodalities so that all relevant experimental and theoretical efforts can benefit from the most powerful and robust models that can be achieved. This proposal aims to take the first concrete step in that direction by unifying models of direction selectivity, binocular disparity selectivity and 3D motion selectivity (also known as motion-in-depth) to reveal circuits and understand computations from V1 to area MT. Motion in 3D inherently bridges visual submodalities, necessitating the integration of motion and binocular processing, and we are motivated by two recent paradigm-breaking physiological studies that have shown that area MT has a robust representation of 3D motion. In Aim 1, we will create the first unified model and understanding of the relationship between pattern and 3D motion in MT. In Aim 2, we will construct the first unified model of motion and disparity processing in MT. In Aim 3, we will develop a large-scale biologically plausible model of these selectivities that represents realistic response distributions across an MT population. Having a population output that is complete enough to represent widely-used visual stimuli will amplify our ability to link to population read-out theories and to link to results from psychophysical studies of visual perception. Key elements of our approach are (1) an iterative loop between modeling and electrophysiological experiments; (2) building a set of shared models, stimuli, data and analysis tools in a cloud-based system that unifies efforts across labs, creating opportunities for deep collaboration between labs that specialize in relevant submodalities, and encouraging all interested scientists to contribute and benefit; (3) using model-driven experiments to answer open, inter-related questions that involve motion and binocular processing, including motion opponency, spatial integration, binocular integration and the timely problem of how 3D motion is represented in area MT; (4) unifying insights from filter-based models and conceptual, i.e., non-image- computable, models to generate the first large-scale spiking hierarchical circuits that predict and explain how correlated signals and noise are transformed across multiple cortical stages to carry out essential visual computations; and (5) carrying out novel simultaneous recordings across visual areas. This research also has potential long-term benefits in medicine and technology. It will build fundamental knowledge about functional cortical circuitry that someday may be useful for interpreting dysfunctions of the cortex or for helping biomedical engineers construct devices to interface to the brain. Insights gained from the visual cortex may also help to advance computer vision technology. NARRATIVE The processing of visual motion and depth information is essential for a wide variety of important human abilities, including navigating through the world, avoiding collisions, catching and grabbing objects and interpreting complex scenes. To understand how neurons in the visual cortex transform and represent the information that underlies these abilities, we aim to initiate the development of a more complete, biologically constrained and openly available computer model of motion and depth processing that will be used to guide, and to interpret and incorporate results from, primate visual neurophysiological and psychophysical experiments. Gaining an understanding of the normal function of cortical neural circuitry is an important step in building the fundamental knowledge that someday may help to improve the ability to assess dysfunctions of the cortex and may help bioengineers create devices that interface to cortical circuitry to treat disorders and overcome disabilities.",Cortical computations underlying binocular motion integration,9969438,R01EY027023,"['3-Dimensional', 'Affect', 'Architecture', 'Biological', 'Biomedical Engineering', 'Brain', 'Collaborations', 'Color', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disadvantaged', 'Discrimination', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Foundations', 'Frequencies', 'Functional disorder', 'Human', 'Joints', 'Knowledge', 'Link', 'Literature', 'Medicine', 'Modeling', 'Motion', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Pattern', 'Performance', 'Physiological', 'Physiology', 'Population', 'Primates', 'Production', 'Psychophysics', 'Reproducibility', 'Research', 'Role', 'Scientist', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Vision Disparity', 'Visual', 'Visual Cortex', 'Visual Motion', 'Visual Perception', 'area MT', 'base', 'cloud based', 'color processing', 'disability', 'experimental study', 'extrastriate visual cortex', 'fitness', 'improved', 'in vivo', 'insight', 'interest', 'neural circuit', 'neurophysiology', 'novel', 'predictive modeling', 'relating to nervous system', 'response', 'spatial integration', 'spatiotemporal', 'theories', 'tool', 'visual neuroscience', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2020,399500,0.07242669388898451
"Causal role of higher-order thalamo-cortical oscillations in sustained attention PROPOSAL SUMMARY/ABSTRACT Sustained attention – the continuous allocation of cognitive resources to respond to infrequent but behaviorally relevant stimuli – is impaired in many psychiatric disorders and represents an important aspect of cognitive control. Sustained attention requires top-down control and engagement with the external world, which is linked to both frontoparietal and thalamic controlling signals on primary sensor cortices. Despite the extensive behavioral characterization of sustained attention in animal models using the five-choice serial reaction time task (5-CSRTT), very little is known about the oscillatory interaction between the dorsal attention network and thalamo-cortical dynamics and its potential as a stimulation target for enhancing sustained attention. The objective of this project is to dissect the causal role of higher-order thalamo-cortical oscillations in sustained attention via temporally-precise rhythmic stimulation. I will focus on three regions in the visual thalamo-cortical network: higher-order visual thalamus (lateral aspect of lateral posterior nucleus, LPl), posterior parietal cortex (PPC), and primary visual cortex (V1). I will test the central hypothesis that LPl-cortical theta (4-7 Hz) functional connectivity causally coordinates PPC-V1 functional connectivity to facilitate sustained attention. The rationale of this work is that the proposed temporally-precise rhythmic optogenetic perturbations will directly test the causal role of thalamo-cortical functional connectivity in sustained attention. Accordingly, the two specific aims are: (1) Delineate the functional role of higher-order thalamo-cortical oscillations in sustained attention, (2) Determine the causal role of thalamo-cortical functional connectivity in sustained attention via temporally-precise rhythmic optogenetics. This work is significant because it will causally test a convergent model in which higher-order visual thalamus coordinates the parietal top-down control signals onto visual cortex that is crucial for developing circuit- based therapies to enhance sustained attention. The work is innovative due to its integration of closed-loop optogenetics circuit interrogation, multisite electrophysiology, freely-moving sustained attention task, and machine-learning tools for the investigation of the causal role of oscillatory synchronization. The overall positive impact of the proposed study is to provide a more comprehensive map of how the higher-order visual thalamus interacts with the frontoparietal control signal to modulate V1, and thus mediates sustained attention, a transdiagnostic cognitive function that shows impairment in many psychiatric disorders including attention deficit hyperactivity disorder, bipolar disorder, and schizophrenia. The implication of this study is that it may reveal a general mechanism underlying the interaction between two higher-order processing structures signaling to lower sensory cortices during cognitive processing. PROJECT NARRATIVE Sustained attention enables us to focus our cognitive resources on an activity for a prolonged period of time, and when impaired causes profound deficits in both cognition and behavior. Sustained attention is modulated by the thalamo-cortical rhythms. The research generated in this proposal will investigate (1) what oscillatory feature in the higher-order thalamo-cortical circuit is crucial for sustained attention, and (2) how the temporally- precise enhancing or disrupting of a thalamo-cortical oscillatory feature alters the functional connectivity in the circuit and behavioral outcomes mediated by sustained attention.",Causal role of higher-order thalamo-cortical oscillations in sustained attention,9970165,F31MH118799,"['Anatomy', 'Animal Model', 'Animals', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Behavior', 'Behavioral', 'Bipolar Disorder', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communication', 'Communities', 'Computers', 'Conflict (Psychology)', 'Couples', 'Data', 'Dorsal', 'Electrophysiology (science)', 'Exhibits', 'Ferrets', 'Foundations', 'Frequencies', 'Functional disorder', 'Impairment', 'Implant', 'Impulsivity', 'Investigation', 'Lasers', 'Lateral', 'Lateral posterior nucleus of thalamus', 'Length', 'Link', 'Machine Learning', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Neurons', 'Parietal', 'Parietal Lobe', 'Performance', 'Periodicity', 'Phase', 'Physiologic pulse', 'Prefrontal Cortex', 'Process', 'Psyche structure', 'Reaction Time', 'Research', 'Resources', 'Rewards', 'Role', 'Schizophrenia', 'Signal Transduction', 'Statistical Models', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thalamic structure', 'Therapeutic', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'base', 'behavioral outcome', 'calmodulin-dependent protein kinase II', 'cognitive control', 'cognitive function', 'functional disability', 'innovation', 'neurotransmission', 'novel', 'optogenetics', 'recruit', 'relating to nervous system', 'sensor', 'sensory cortex', 'signal processing', 'sustained attention', 'theories', 'tool', 'visual stimulus']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,F31,2020,37032,0.01890798835453119
"Prefrontal contributions to contextual representation Project Abstract/Summary This application describes a 3-year training plan that will enable me, a cognitive neuroscientist with prior training in electroencephalography (EEG), to conduct research on contextual memory representation using neuroimaging (fMRI) and computational modeling. EEG is useful for examining the timing properties of neural activity, but cannot localize activity to specific regions of the brain. In this proposal, I will receive training on a high-spatial resolution neuroimaging technique (fMRI), which will allow me to develop theories of neural function that are constrained by both space and time. I will also build on my prior degree in applied statistics and receive additional training in computational neuroscience, which will enable me to develop computational theories at the macro-circuit level. I will be supervised by Dr. Sharon Thompson-Schill, an expert fMRI experimentalist and theorist of lateral prefrontal cortex function, who has extensive experience researching the context-dependent nature of semantic memory. I will be co-supervised by Dr. Anna Schapiro, an expert on statistical learning and computational modeling of the brain. I propose to examine how prefrontal cortex (PFC) represents statistical dependencies among sequentially presented visual and auditory input. I will examine how the temporal extent and level of abstraction of sequential representations changes across ventral PFC. This will connect findings from several literatures, ranging from decision-making to emotion processing and language comprehension, within a single unifying framework. In addition, I will explore whether ‘deep’ or ‘shallow’ recurrent neural networks better capture the sensitivity profile of ventral PFC, informing the question of whether the brain conducts ‘deep’ learning. In Aim 1, I will conduct behavioral piloting and collect data for two neuroimaging experiments on hierarchical sequential processing. I will have participants learn the statistical properties of hierarchically organized sequences of abstract visual (Aim 1a&b) and auditory (Aim 1b) images. I then test for neural sensitivity to statistical learning at each hierarchical level using pattern similarity analysis, comparing the neural response to the sequences before and after learning. In Aim 2, I will conduct computational modeling of the neuroimaging data in Aim 1, with held out data to ensure robustness and reproducibility. I compare the neuroimaging data to internal model representations derived from single-layer (‘shallow’) and multi-layer (‘deep’) recurrent neural networks trained on the same sequences as the humans in Aim 1. By modeling the neural representation of context itself, the current proposal will help fill a critical gap in our understanding of how the brain predicts upcoming sensory input, enabling rapid processing of the world around us. It will also inform our understanding of several psychiatric disorders that involve prefrontal cortex disfunction and disturbances of contextual processing, such as schizophrenia, anxiety and depression. Project Narrative As we navigate the world we are bombarded by a flood of sensations that our brain must rapidly make sense of, and understanding the context we are in as it relates to the likelihood of upcoming experiences is important for enhancing the speed and accuracy of this process. This proposal examines how sensory context is represented in the brain, by having people learn statistical regularities in artificial sequences of images and syllables and modeling neural activity in prefrontal cortex as they are exposed to different sensory “contexts” using fMRI. Through computational modeling of prefrontal cortex, we can enhance our understanding of the function of a brain region implicated in many neuropsychological disorders where the perception of context is distorted or disrupted, including anxiety, depression, and schizophrenia.",Prefrontal contributions to contextual representation,9990118,F32MH123002,"['Anxiety', 'Attention', 'Auditory', 'Behavioral', 'Behavioral Model', 'Brain', 'Brain region', 'Cognitive', 'Complex', 'Computer Models', 'Cues', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Electrophysiology (science)', 'Emotions', 'Ensure', 'Esthesia', 'Event', 'Exhibits', 'Exposure to', 'Floods', 'Fractals', 'Functional Magnetic Resonance Imaging', 'Grain', 'Hearing', 'Heart', 'Human', 'Image', 'Knowledge', 'Language', 'Lateral', 'Learning', 'Linguistics', 'Literature', 'Maps', 'Measures', 'Medial', 'Mediating', 'Memory', 'Mental Depression', 'Mental disorders', 'Methods', 'Mind', 'Modality', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurophysiology - biologic function', 'Neuropsychology', 'Parietal', 'Participant', 'Pattern', 'Perceptual Disorders', 'Prefrontal Cortex', 'Process', 'Property', 'Psychology', 'Reproducibility', 'Research', 'Resolution', 'Schizophrenia', 'Semantic memory', 'Semantics', 'Sensory', 'Shapes', 'Signal Transduction', 'Specificity', 'Speed', 'Stimulus', 'Stream', 'Structure', 'Supervision', 'Techniques', 'Testing', 'Time', 'Training', 'Validation', 'Visual', 'Work', 'base', 'computational neuroscience', 'computerized tools', 'deep learning', 'experience', 'experimental study', 'insight', 'interest', 'language comprehension', 'neural model', 'neuroimaging', 'recurrent neural network', 'relating to nervous system', 'response', 'sensory input', 'sensory stimulus', 'sequence learning', 'social', 'sound', 'statistical learning', 'statistics', 'theories']",NIMH,UNIVERSITY OF PENNSYLVANIA,F32,2020,64926,0.01762736182432506
"Multiple timescales of motor planning and execution in mouse cortex Project Summary/Abstract: For animals to execute complicated behaviors, successful motor planning and execution is essential. Moreover, the sequence of events leading to successful goal-based behavior takes place over a wide range of timescales. For example, when walking from home to work, one must first make an abstract, long-timescale decision to go to work, which much then be translated into a sequence of shorter-timescale right-left turning decisions, which are translated into the finely fluctuating electrical patterns that control the muscles. How motor planning and execution occur simultaneously over many timescales in populations of motor cortex neurons is not well understood. Much work in humans and nonhuman primates have shown that visual and auditory stimuli integrate over multiple timescales. This work has shown that early sensory regions, like primary visual cortex, respond to fast fluctuations in the environment. This information is integrated to longer-timescale information in secondary cortical regions, with the longest- timescale information in frontal and association areas. We therefore hypothesize that secondary motor cortex (M2) neurons control behavior over longer timescales than primary motor cortex (M1) neurons. To study this phenomenon, I have built a setup in which head-fixed mice navigate in virtual reality to a rewarded location. In this setup, I can record video from all sides of the animal for high spatiotemporal resolution measurement of motor behaviors. I have developed machine learning algorithms to extract 3D pose data from these videos. In Aim 1, I will use calcium imaging to record large numbers of neurons in mouse M1 and M2 to correlate the activity of individual neurons and populations to the animal’s ongoing pose kinematics. We will supplement with targeted silicon probe recordings to capture fast neural responses. In Aim 2, I will compare the calcium dynamics in populations of M1 and M2 neurons in mice trained to perform a virtual motor planning task versus mice that have not been trained. We hypothesize that training to plan motor actions increases the timescale of M1/M2 neural activity. In Aim 3, we will use optogenetic silencing in specific regions of cortex to perturb the animal’s motor behavior. We hypothesize that the duration of the perturbed movements will be longer when M2 is perturbed than M1. In this way, we will study how different cortical regions relate to behavior over many timescales. This proposal will broaden our knowledge of cortical processing in general, and motor planning and execution in particular. Patients with mental illness, such as ADHD, autism, and Asperger’s disorder show impaired ability to plan upcoming movements. The first step to successfully treating these illnesses is to better understand how motor planning occurs in general. Project Narrative: This proposal will elucidate how motor planning and execution take place simultaneously, over many timescales, and across brain regions. Better understanding motor planning will help generate new treatments for diseases that affect motor planning, like attention deficit hyperactivity disorder and autism.",Multiple timescales of motor planning and execution in mouse cortex,10007591,F31NS108450,"['3-Dimensional', 'Affect', 'Animal Behavior', 'Animals', 'Area', 'Asperger Syndrome', 'Attention deficit hyperactivity disorder', 'Behavior', 'Behavior Control', 'Brain region', 'Calcium', 'Code', 'Communication', 'Cues', 'Data', 'Disease', 'Ensure', 'Environment', 'Event', 'Future', 'Goals', 'Head', 'Home environment', 'Human', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Laser Scanning Microscopy', 'Lasers', 'Left', 'Light', 'Location', 'Measurement', 'Measures', 'Memory', 'Mental disorders', 'Modeling', 'Motor', 'Motor Cortex', 'Movement', 'Mus', 'Muscle', 'Neurons', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Population', 'Research', 'Resolution', 'Rewards', 'Running', 'Sensory', 'Short-Term Memory', 'Side', 'Silicon', 'Stereotyping', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Vision', 'Walking', 'Work', 'area striata', 'auditory stimulus', 'autism spectrum disorder', 'base', 'frontal lobe', 'kinematics', 'machine learning algorithm', 'motor behavior', 'neuromechanism', 'nonhuman primate', 'novel', 'optogenetics', 'prevent', 'relating to nervous system', 'response', 'sensory cortex', 'sensory stimulus', 'spatiotemporal', 'theories', 'two-photon', 'virtual', 'virtual reality', 'visual stimulus']",NINDS,HARVARD MEDICAL SCHOOL,F31,2020,33236,-0.012490523490472295
"Receptors, microcircuits and hierarchical connectivity in predictive coding and sensory awareness SUMMARY The standard view of how we make sense of the world around us focuses on reconstructing our environment from the information received by our sensory organs. In this view, low-level brain areas (e.g., primary sensory cortex) represent basic features of objects, which are elaborated on in successive processing stages, until representations become increasingly complex in high-level areas (e.g., frontal cortex). An alternative view is predictive coding (PC), in which we model our environment to generate sensory predictions. In PC, high-level brain areas generate predictions of sensory activity and transmit them to low-level areas. A prediction that does not match the sensory information gives rise to a prediction error. This error signal is sent from low- to high-level brain areas to update the model of our environment, thereby improving future predictions to minimize errors. Modeling studies show PC is a fast and efficient way to process sensory information, and PC provides innovative hypotheses for understanding sleep and anesthesia, particularly when disconnected consciousness occurs (consciousness without awareness of the environment), like dreaming. PC also holds great promise for conceptualizing and treating brain disorders, including schizophrenia and depression. But key central features of PC have not been empirically tested and little is known about the underlying neural mechanisms. The goal of the proposed project is to characterize the neural dynamics, circuits and receptors enabling PC. There are two principle hypotheses. First, predictions depend on N-methyl-D-aspartate receptors (NMDAR) because NMDAR influence the activity of high-level brain areas where predictions are generated, and NMDAR are enriched on neurons in lower-level areas receiving predictions. Second, in disconnected consciousness, a breakdown of information transmission from low-level to high-level brain areas, as well as a breakdown of computations within each area, explains why models of our environment are not updated by external sensory information. These breakdowns prevent the comparison of predictions and sensory information, as well as the transmission of prediction errors to high-level brain areas. To test these hypotheses, we use a cross-species experimental design connecting cellular, circuit and systems levels to behavior. We will perform electroencephalography, machine learning and computational modeling to define the neural basis of PC in humans performing prediction tasks. Then we will manipulate PC using different anesthetic agents with diverse mechanisms, establishing causal relationships between receptors, large-scale brain networks and PC. In parallel, we will simultaneously record activity from sensory and high-level brain areas of non-human primates (NHPs) using the same PC tasks and pharmacological interventions to measure cellular and circuit level contributions to PC. Investigating PC will illuminate the fundamental mechanisms of perception, providing critical insights to guide therapeutic development for multiple health conditions. NARRATIVE This research advances our understanding of how the brain generates predictions which shape how we perceive the world, otherwise known as predictive coding. Predictive coding is relevant to public health because it holds great promise in conceptualizing and treating brain disorders, including depression, schizophrenia, delirium and dementia, as well as understanding sleep and anesthesia. Progress in understanding the basic mechanisms of predictive coding, as well as predictive coding deficits, is a necessary step in developing more effective treatment strategies for multiple health conditions.","Receptors, microcircuits and hierarchical connectivity in predictive coding and sensory awareness",10034682,R01NS117901,"['Adrenergic Receptor', 'Agonist', 'Anesthesia procedures', 'Anesthetics', 'Area', 'Auditory', 'Auditory area', 'Awareness', 'Behavior', 'Brain', 'Brain Diseases', 'Code', 'Complex', 'Computer Models', 'Conscious', 'Cues', 'Data', 'Delirium', 'Dementia', 'Dexmedetomidine', 'Disinhibition', 'Dose', 'Dreams', 'Electroencephalography', 'Environment', 'Experimental Designs', 'Feedback', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Individual', 'Interneurons', 'Intervention', 'Ketamine', 'Link', 'Macaca', 'Machine Learning', 'Measures', 'Mediating', 'Mental Depression', 'Modality', 'Modeling', 'Molecular Target', 'Monitor', 'N-Methyl-D-Aspartate Receptors', 'Neurons', 'Organ', 'Parietal Lobe', 'Pathway interactions', 'Perception', 'Pharmacology', 'Process', 'Propofol', 'Public Health', 'Pulvinar structure', 'Reaction Time', 'Reporting', 'Research', 'Role', 'Schizophrenia', 'Sedation procedure', 'Sensory', 'Sensory Process', 'Shapes', 'Signal Transduction', 'Sleep', 'Study models', 'System', 'Temporal Lobe', 'Testing', 'Thalamic Nuclei', 'Unconscious State', 'Update', 'base', 'effective therapy', 'experience', 'experimental study', 'frontal lobe', 'human data', 'improved', 'innovation', 'innovative technologies', 'insight', 'multi-electrode arrays', 'neural correlate', 'neuromechanism', 'neurophysiology', 'nonhuman primate', 'paired stimuli', 'postsynaptic', 'prevent', 'receptor', 'relating to nervous system', 'response', 'sedative', 'sensory cortex', 'sensory stimulus', 'therapeutic development', 'transmission process', 'treatment strategy', 'visual stimulus']",NINDS,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,517182,-0.017662665953867392
"Neurocognitive basis of attention and eye movement guidance in the real world scenes Summary/Abstract Real world scenes contain a wealth of information that guide where we look and help us search for things in our visual environment more efficiently. For example, if you were looking for a person in a city, you would look mostly on the sidewalk, whereas if you were looking for a car, you would concentrate your attention on the street. Despite the fact that behavioral experiments have increasingly quantified the role of object and scene knowledge in the guidance of attention and eye movements, models of these processes, particularly neural models, neglect the role of visual knowledge. The goal of this project is to determine whether regions of the brain shown to be important for object and scene recognition are involved in visual guidance in natural scenes. Prior results, including our preliminary data, show that the neural activity from object processing regions can be used to predict what object a person is going to look at next. However, critical questions that remain are: is this predictive activity influenced by scene and object knowledge and is it causally related to visual guidance? Answering these two questions are the specific goals of this proposal. Individuals undergoing neurosurgical evaluation for epilepsy provide the rare opportunity of recording directly from the human brain (intracranial electroencephalography, iEEG), which provides a superior spatial and temporal resolution measure of brain activity compared to other technique. These direct recordings also allow for electrical brain stimulation (EBS), which can provide causal evidence tying the activity in particular regions to cognitive function. Finally, these data will be supplemented by magnetoencephalography (MEG) data to examine whole brain effects in healthy individuals. iEEG and MEG data arising from regions involved in object and scene recognition will be analyzed by multivariate machine learning techniques to continually classify what subjects are viewing on a moment-to- moment basis. Furthermore, we will try to predict what object subjects will view next during free viewing and visual search in natural scenes based on their neural data. We will assess how these neural signals are modified by the presence or absence of information about typical locations of objects or people in the scene that have been shown to guide behavior. Finally, using EBS we will determine if there is a causal link between the activity in regions involved in coding for object and scene knowledge and visual guidance in natural scene vision. If successful, these studies would necessitate a substantial reshaping of models of visual attention in the human brain. The results could form the foundation of a program of research into the neural basis of attention and eye movement guidance in the real world. Attention, perception, and eye movement abnormalities are seen in a host of neurological and psychiatric disorders. Thus, these studies, and the models that arise from them, have the translational potential to advance our understanding of the neurological basis of these disorders and suggest potential neurally inspired rehabilitation strategies. Narrative Abnormalities in visual attention and eye movement guidance are seen in a host of neurological and psychiatric disorders, including visual agnosia, neglect, schizophrenia, autism, etc. The neural basis of visual attention and eye movement guidance in the real world is unknown; therefore it remains unknown how neural abnormalities in these disorders relate to real world visual deficits, which is a critical barrier to designing hypothesis-driven remediation strategies. The proposed research will take critical early steps towards understanding the neural basis of real world attention and eye movement control, which has the potential to transform our understanding of these critical visual processes. The results of this research will lead to a deeper understanding of the neurobiology of eye movement and attentional guidance, a circuit relevant to a number of disorders, and take a critical step towards developing hypotheses for remediation strategies.",Neurocognitive basis of attention and eye movement guidance in the real world scenes,10004653,R21EY030297,"['Agnosia', 'Anatomy', 'Attention', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Caring', 'Categories', 'Cities', 'Code', 'Computer Models', 'Computers', 'Data', 'Disease', 'Dorsal', 'Dyskinetic syndrome', 'Electrical Stimulation of the Brain', 'Electrodes', 'Electroencephalography', 'Environment', 'Epilepsy', 'Evaluation', 'Eye', 'Eye Movements', 'Foundations', 'Functional disorder', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Knowledge', 'Link', 'Literature', 'Location', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mediating', 'Mental disorders', 'Modeling', 'Monitor', 'Motivation', 'Multivariate Analysis', 'Mus', 'Neurobiology', 'Neurocognitive', 'Neurologic', 'Object Attachment', 'Operative Surgical Procedures', 'Parietal', 'Pathology', 'Perception', 'Persons', 'Play', 'Process', 'Research', 'Role', 'Saccades', 'Schizophrenia', 'Semantics', 'Site', 'Stimulus', 'Stream', 'Study models', 'Surface', 'System', 'Techniques', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual attention', 'Walking', 'attentional control', 'autism spectrum disorder', 'base', 'behavioral study', 'cognitive function', 'computer monitor', 'design', 'experimental study', 'neglect', 'nervous system disorder', 'neural circuit', 'neural model', 'neurotransmission', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'remediation', 'response', 'sample fixation', 'spatial relationship', 'temporal measurement', 'theories', 'visual process', 'visual processing', 'visual search', 'visual tracking']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,195625,0.08520747246444126
"Revealing the organization and functional significance of neural timescales in auditory cortex Project Summary People are remarkably adept at making sense of the world through sound: understanding speech in a noisy restaurant, picking out the voice of a family member, or recognizing a familiar melody. Although we take these abilities for granted, they reflect impressive computational feats of biological engineering that are remarkably difficult to replicate in machine systems. The long-term goal of my research program is to develop computational and experimental methods to reverse-engineer how the brain codes natural sounds like speech and to exploit these advances to understand and aid in the treatment of hearing impairment. One of the central challenges of coding natural sounds is that they are structured at many different timescales from milliseconds to seconds and even minutes. How does the brain integrate across these diverse timescales to derive meaning from sound? Answering this question has been challenging because there are no general-purpose methods for measuring neural timescales in the brain. As a consequence, we know relatively little about how neural timescales are organized in auditory cortex and how this organization enables the coding of natural sounds. To overcome these limitations, we develop a simple experimental paradigm (the “temporal context invariance” or TCI paradigm) for estimating the temporal integration period of any sensory response: the time window during which stimuli alter the response. We apply the TCI method to human electrocorticography (ECoG) and animal physiology recordings to reveal the organization of neural timescales at both the region and single-cell level (Aim I). Pilot data from our analyses reveal that timescales are organized hierarchically, with higher-order regions showing substantially longer integration periods. To explore the functional significance of this timescale hierarchy, we couple TCI with computational techniques well-suited for characterizing natural sounds (Aim II). We test whether increased integration periods enable a more noise-robust representation of speech (Aim IIA), whether regions with longer integration periods code higher-order properties of natural sounds (Aim IIB&IIC), whether there are dedicated integration periods for important sounds categories like speech or music (Aim IID), and whether cortical integration periods can be explained by the duration of the features they respond to (Aim IIE). In the process of conducting this research, I will be trained in two critical areas: (1) ECoG, which is the only method with the spatial and temporal precision to understand how neural timescales are organized in the human brain (2) deep neural networks (DNN) which are the only models able to perform challenging perceptual tasks at human levels and predict neural responses in higher-order cortical regions. After completing this training, I will have a unique set of experimental (fMRI, ECoG, psychophysics) and computational skills (data-driven statistical modeling and hypothesis-driven DNN modeling), which will facilitate my transition to an independent investigator. Project Narrative Natural sounds like speech contain information at many different timescales (e.g. phonemes, syllables, words), but how the human brain extracts this information remains unclear. Understanding this process is critical to understanding how hearing impairment degrades speech perception. The proposed research will reveal the organization of neural timescales in the brain, and how this organization facilitates the coding of natural sounds like speech, which is a critical first step in understanding how this code is impaired by hearing loss.",Revealing the organization and functional significance of neural timescales in auditory cortex,9977571,K99DC018051,"['Address', 'Animals', 'Area', 'Auditory area', 'Biological', 'Brain', 'Categories', 'Cells', 'Code', 'Collaborations', 'Communication', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Data', 'Electrocorticogram', 'Engineering', 'Family member', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Hearing', 'Human', 'Learning', 'Measures', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurosciences', 'Noise', 'Physiology', 'Population', 'Process', 'Property', 'Psychophysics', 'Reaction Time', 'Research', 'Research Personnel', 'Research Training', 'Restaurants', 'Sensory', 'Speech', 'Speech Perception', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'Voice', 'Work', 'clinically significant', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'millisecond', 'neuromechanism', 'programs', 'relating to nervous system', 'response', 'skills', 'sound', 'theories']",NIDCD,COLUMBIA UNIV NEW YORK MORNINGSIDE,K99,2020,125442,-0.05393414342394949
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology Project Summary Listening in noise is a core problem in everyday hearing. Sound sources of interest routinely occur amid irrelevant distractors, as when you talk with someone in a bustling coffee shop. This background “noise” distorts the pattern of spikes in the auditory nerve, often to a profound degree. Thus, to recognize sources of interest, the auditory system must somehow separate or suppress the effects of the background. Typical human hearing is remarkably noise-robust, but listeners with age-related hearing loss or other forms of impaired hearing struggle in noisy environments – and are not much helped by contemporary hearing aids. Previous work on the neural basis of noise robustness has typically employed simple, synthetic noise sources, which lack the structure present in real-world sounds, and this work has focused on subcortical regions or on primary auditory cortex. Reasoning that real-world conditions might necessitate more complicated solutions, in the applicant's doctoral work, he considered everyday sources of noise, and leveraged the large-scale coverage afforded by fMRI to examine noise robustness throughout human auditory cortex. Real-world “background noise” was operationalized as a natural sound with statistical properties that are stable over time (i.e., are stationary), conveying little new information about the world (e.g., swamp insects, an air conditioner, rain on pavement). The applicant measured fMRI responses in human listeners to a broad set of natural sounds presented in quiet, as well as embedded in the real-world background noises. Primary auditory cortical responses were substantially altered by the background, but non-primary responses were substantially more robust. This effect was not seen for simple synthetic backgrounds as had been used in previous work, suggesting that becoming robust to real-world background noises require different mechanisms. The applicant's thesis work demonstrates where noise invariance arises, but understanding how will require data with finer spatial and temporal resolution, and thus the proposed postdoctoral research will consist of training in single-unit electrophysiology using marmosets. Aim 1A builds on previous work examining single- unit noise robustness in artificial conditions, extending such work to real-world noise. Aim 1B leverages texture models to probe what aspects of real-world backgrounds disrupt the encoding of foregrounds. Aim 2A deploys linear reconstruction techniques to probe population representations. Aim 2B involves optimizing deep neural networks for noise invariance tasks, and using them as an encoding model to predict single-unit responses. Furthermore, such networks will be deployed as nonlinear decoding algorithms, reconstructing stimuli from neuronal populations. Throughout all aims, the work will characterize neuronal responses in non-primary areas, and in particular in parabelt, which is understudied in primates. The proposed work may enable improvements in hearing aid algorithms or neural prosthetics. Lastly, this training will lay the groundwork for the applicant's long-term goal of developing a marmoset model for hearing loss. Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,10104430,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Quality of life', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'algorithm training', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2020,64926,0.02070098573343451
"Computational Cognitive Neuroscience of Human Auditory Cortex PROJECT SUMMARY Humans with normal hearing excel at deriving information about the world from sound. Our auditory abilities represent stunning computational feats that only recently have been replicated to any extent in machine systems. And yet our auditory abilities are highly vulnerable, being greatly compromised in listeners with hearing impairment, cochlear implants, and auditory neurodevelopmental disorders, particularly in the presence of noise. Difficulties in recognition often lead to frustration and social isolation, and are not adequately addressed by current hearing aids, implants, and remediation strategies. The long-term goal of the proposed research is to reveal the basis of auditory recognition and to provide insights that will facilitate improved prosthetic devices and therapeutic interventions. The development of more effective devices and therapies is currently limited by an incomplete understanding of the factors that underlie real-world recognition by normal-hearing listeners. In particular, although responses to sound in subcortical auditory pathways are relatively well studied, little is known about the transformations that occur within the auditory cortex to create representations of meaningful sound structure. We propose to enrich the understanding of auditory recognition with three sets of experiments that examine the cortical representation of real-world sounds in human listeners, combining functional magnetic resonance imaging (fMRI) with computational modeling of the underlying representations. Aim 1 develops artificial neural network models of speech and music processing and compares their representations to those in the auditory cortex, synthesizing and then measuring brain responses to sounds that generate the same response in a model, and probing the time scale of the auditory analysis of speech and music. Aim 2 develops and tests models of pitch perception in noise, exploring the hypothesis that pitch perception is constrained both by the statistics of natural sounds and the frequency selectivity of the cochlea. Aim 3 develops and tests models that jointly localize and recognize sounds, and probes the brain representations of sound identity and location using fMRI. The results will reveal the mechanisms underlying robust sound recognition by the healthy auditory system and will set the stage for investigations of the cortical consequences of hearing impairment and auditory developmental disorders, hopefully suggesting new strategies for remediation. PROJECT NARRATIVE: People with normal hearing are typically able to recognize, understand and localize sounds of interest, but this ability is often compromised in listeners with hearing disorders. The proposed research will enrich the understanding of the neural mechanisms underlying auditory recognition and localization in normal listeners. The results will likely provide insight into the brain processes whose alteration in hearing disorders underlies listening difficulties, potentially leading to improved remediation strategies.",Computational Cognitive Neuroscience of Human Auditory Cortex,9944496,R01DC017970,"['Address', 'Adopted', 'Auditory', 'Auditory Perception', 'Auditory area', 'Auditory system', 'Behavioral', 'Biological Assay', 'Brain', 'Brain region', 'Characteristics', 'Child', 'Cochlea', 'Cochlear Implants', 'Computer Models', 'Data', 'Development', 'Devices', 'Drops', 'Ear', 'Floor', 'Frequencies', 'Frustration', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing Aids', 'Hearing Tests', 'Hearing problem', 'Human', 'Implant', 'Investigation', 'Lead', 'Location', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Music', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Noise', 'Pathway interactions', 'Peripheral', 'Persons', 'Pitch Perception', 'Population', 'Process', 'Property', 'Prosthesis', 'Psychophysics', 'Research', 'Rest', 'Social isolation', 'Sound Localization', 'Source', 'Speech', 'Stimulus', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Visual Pathways', 'artificial neural network', 'auditory pathway', 'cognitive neuroscience', 'computational basis', 'deep learning', 'deep neural network', 'developmental disease', 'experimental study', 'hearing impairment', 'improved', 'insight', 'interest', 'network architecture', 'neural network', 'neuromechanism', 'neurophysiology', 'normal hearing', 'novel', 'relating to nervous system', 'remediation', 'response', 'sound', 'sound frequency', 'speech processing', 'statistics']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,337875,0.022445604977636247
"Millisecond resolution statistics of cortical populations Project Summary/Abstract The mammalian brain builds and transforms representations of the outside world through the concerted activity of populations of neurons, but the extent to which spike times or spike counts are coordinated within these ensembles beyond pairs is not clear. Models of neural encoding predict variable frequencies of spike pattern occurrence, and models of decoding delineate requirements for spike time precision within the population response. While considerable effort has been made toward the development and refinement of the theoretical basis of such neural coding schemes, and predictions have been tested against single cell and pairwise data, there has been relatively little experimental data beyond pairs able to differentiate between competing hypotheses of population coding. The proposed career development plan aims to marry large-scale electrophysiology in primary visual cortex with analysis of specific predictions derived from computational and theoretical neuroscience work for spike time coordination beyond pairwise interactions. The candidate has a deep background in in vivo experimental techniques and proposes to receive training in the high-dimensional computational techniques and to use experimental data collected to validate specific theoretical predictions. This training will establish the skills necessary for a successful independent research career studying the mechanisms of information representation and transfer in visual cortex, bridging the gap between experimental and computational neuroscience. The candidate will carry out the mentored phase under the guidance of Dr. Clay Reid, a world expert in multiple aspects of mammalian central visual processing including anatomy, physiology, and computation. Additional advising from Dr. Eric Shea- Brown and Dr. Christof Koch will provide guidance in the theoretical and applied mathematical approaches required to implement and assess advanced models of neural encoding and decoding. The training will utilize the strengths of the Allen Institute for Brain Science in collecting large-scale data and the didactic opportunities at the University of Washington. In the independent phase the candidate will use the newly acquired analytical and modeling skills in combination with his previous training in optogenetic techniques to better constrain population measurements. This work will help establish a unique independent research program to elucidate the mechanisms underlying cortical representation. Project Narrative Understanding how the brain uses population activity to build representations of the outside world is an important step towards understanding not only sensory but also psychiatric and other cognitive disorders. This work on the fundamental nature of the neural code will contribute to the body of knowledge required to create effective brain interfaces for motor and sensory prostheses with the potential to reduce sensory disabilities, provide treatments for cognitive disorders, and aid in recovery from central nervous system trauma.",Millisecond resolution statistics of cortical populations,10006552,R00EY028612,"['Address', 'Anatomy', 'Animals', 'Brain', 'Cells', 'Characteristics', 'Code', 'Cognition Disorders', 'Complex', 'Computational Technique', 'Data', 'Development', 'Development Plans', 'Electrophysiology (science)', 'Frequencies', 'Impaired cognition', 'Institutes', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Mentors', 'Modeling', 'Molecular', 'Motor', 'Mus', 'Nature', 'Neuraxis', 'Neurons', 'Neurosciences', 'Output', 'Pattern', 'Perception', 'Performance', 'Phase', 'Physiological', 'Physiology', 'Population', 'Population Process', 'Population Statistics', 'Property', 'Psychophysics', 'Recovery', 'Research', 'Resolution', 'Scheme', 'Science', 'Sensory', 'Sensory Disorders', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Time', 'Training', 'Traumatic CNS injury', 'Universities', 'Variant', 'Visual Cortex', 'Washington', 'Work', 'area striata', 'awake', 'career', 'career development', 'clay', 'computational neuroscience', 'data resource', 'deep learning', 'deep learning algorithm', 'disability', 'extrastriate visual cortex', 'high dimensionality', 'in vivo', 'innovation', 'large scale data', 'mathematical methods', 'millisecond', 'neural model', 'novel', 'optogenetics', 'predictive modeling', 'programs', 'relating to nervous system', 'response', 'sensory prosthesis', 'skills', 'statistics', 'theories', 'visual processing']",NEI,UNIVERSITY OF COLORADO DENVER,R00,2020,249000,0.03430954856918757
"Vision in Natural Tasks Summary/Abstract  In the context of natural behavior, humans make continuous sequences of sensory-motor decisions to satisfy current behavioral goals, and vision must provide the information needed to achieve those goals. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks in natural locomotion, or the requisite information, and the proposal attempts to specify these.  in the context of natural gait, the patterns of optic flow are unexpectedly complex, raising questions about its role. The patterns of motion on the retina during locomotion depend critically on both eye and body motion, and these in turn depend on behavioral goals. Our first Aim is therefore to comprehensively describe the statistics of retinal motion patterns in a variety of terrains and task contexts. We will measure binocular eye and body movements while walking in outdoor terrains of varying roughness, crossing a busy intersection, and making coffee. These contexts will induce different gaze patterns. We will provide a comprehensive description of the motion stimulus in natural locomotion and help separate out self-motion signals from externally generated motion. These data will allow a more precise specification of the response patterns in cortical motion sensitive areas. Because of the complexity of natural motion patterns, we will re-examine the influence of optic flow on walking direction in a virtual reality environment and test alternative explanations for the role of flow.  A central task in walking is foot placement, and we will focus on identifying the image properties that make a good foothold. Stereo, structure from motion, and spatial image structure are all likely contenders. We directly investigate the role of stereo in foothold selection by examining gait patterns in stereo-deficient subjects in terrains with varying degrees of roughness. Using a different strategy, we will attempt to predict gaze locations and footholds in rough terrain using convolution neural nets (CNN’s) to identify potential search templates for footholds in rough terrain. We will describe fixation patterns from crosswalk and sidewalk navigation and attempt to make inferences about their purpose, and use Modular Inverse Reinforcement Learning (MIRL) to predict direction decisions and decompose the behavior into sub-tasks.  The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists The work will be strengthened by the investigation of stereo- deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available. Project Narrative  The central goal of this work is to understand vision in its natural context. This is very important information in order to devise suitable vision aids and rehabilitation strategies for individuals with visual impairments, and it is becoming increasingly accessible because of developments in technology for monitoring eye and body movements. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks and requisite information in natural locomotion, and the proposal attempts to specify these. The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists. The work will be strengthened by the investigation of stereo-deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available.",Vision in Natural Tasks,10004035,R01EY005729,"['Affect', 'Area', 'Behavior', 'Behavioral', 'Binocular Vision', 'Cells', 'Characteristics', 'Coffee', 'Collection', 'Complex', 'Cues', 'Data', 'Data Set', 'Development', 'Distant', 'Environment', 'Eye', 'Eye Movements', 'Gait', 'Goals', 'Grant', 'Head', 'Human', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Link', 'Location', 'Locomotion', 'Machine Learning', 'Measures', 'Monitor', 'Motion', 'Motor', 'Movement', 'Pattern', 'Psychological reinforcement', 'Retina', 'Rewards', 'Robot', 'Robotics', 'Role', 'Sampling', 'Seminal', 'Sensory', 'Signal Transduction', 'Speed', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Visit', 'Visual', 'Visual Fields', 'Visual impairment', 'Walkers', 'Walking', 'Work', 'base', 'convolutional neural network', 'cost', 'experimental study', 'foot', 'gaze', 'imaging properties', 'innovation', 'kinematics', 'novel', 'optic flow', 'rehabilitation strategy', 'response', 'sample fixation', 'statistics', 'virtual reality environment', 'vision aid', 'vision development', 'vision rehabilitation', 'visual information']",NEI,"UNIVERSITY OF TEXAS, AUSTIN",R01,2020,381743,0.03528201070397849
"Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex Project Summary The use of stimuli with increasingly naturalistic properties has become critical to advance our understanding of vision. Many studies demonstrate that simple artificial stimuli (e.g. sinusoidal gratings and white noise) fail to engage nonlinearities that profoundly alter responses in the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). A recent and striking example comes from the use of naturalistic ‘flow’ stimuli, which engage robust responses in V1 that are not predicted from responses to gratings. This gap in understanding motivates the development of a stimulus ensemble and analysis framework that produces a quantitative understanding of visual processing to increasingly naturalistic stimuli and the nonlinearities that they engage. Our objective is to understand how flow stimuli are processed from retina through visual cortex. To meet this goal, we will make neural population recordings in retina (Aims 1 & 3), LGN (Aims 1 & 3) and V1 (Aim 3) using matched experimental conditions and a unified theoretical/modeling framework to map the transformations that occur across these stages of visual processing. Our central hypothesis is that V1 transforms a discrete and heavily light-level-de- pendent retinal representation of natural stimuli into a continuous (uniform) representation that is relatively in- variant to changes in the mean luminance. This invariance places a strong constraint on the class of nonlineari- ties that transform retinal responses to those observed in LGN and V1. We test this hypothesis in three aims: (1) determine early visual processing (retina & LGN) of naturalistic flow stimuli; (2) develop an encoding manifold to capture the population activity at each processing stage and transforms from one stage to the next; (3) test the ability of the manifold description to predict the impact of light adaptation on processing flow stimuli from retina to V1. Aim 1 will yield a matched experimental dataset to an interesting and novel class of ecologically-relevant stimuli. Aim 2 will yield a quantitative framework by which to understand the transformations that occur between retina, LGN, and V1. Aim 3 will provide a platform for globally perturbing the output of the retina by switching from photopic to mesopic and scotopic conditions, and thereby compare predictions of our model to measured changes in LGN and V1 activity. The primary significance of this research is that it will provide a computationally and experimentally unified framework for understanding the transformations that occur in the processing of stim- uli across multiple stages of visual processing. The major innovations are (1) presenting visual stimuli for retinal recordings that are matched to eye movements and pupil dynamics in alert animals; (2) creating a novel analysis framework that captures the responses of neurons at all three levels and the inter-level transformations to in- creasingly complex stimuli; (3) utilizing light adaptation as a method of perturbing retinal output to test our model and the stability (invariance) of LGN and V1 responses to adapting retinal signals. The expected outcome is a data-driven model of the processing from retina to LGN and V1 that generalizes from starlight to sunlight. Project Narrative Restoring vision to the blind likely requires understanding how retinal signals are communicated to the brain and how these signals are transformed in the thalamocortical pathway. This project aims to acquire an understanding of these transformations in the context of complex and more naturalistic visual stimuli.",Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex,10050840,R01EY031059,"['Affect', 'Animals', 'Brain', 'Collaborations', 'Complex', 'Cone', 'Data', 'Data Set', 'Development', 'Environment', 'Eye Movements', 'Future', 'Goals', 'Lateral Geniculate Body', 'Light', 'Light Adaptations', 'Machine Learning', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Movement', 'Mus', 'Neurons', 'Noise', 'Optics', 'Outcome', 'Output', 'Pathway interactions', 'Physiological', 'Population', 'Process', 'Property', 'Pupil', 'Research', 'Retina', 'Retinal Ganglion Cells', 'Rod', 'Signal Transduction', 'Stimulus', 'Structure', 'Sunlight', 'Techniques', 'Testing', 'Theoretical model', 'Variant', 'Vision', 'Visual Cortex', 'Visual system structure', 'Work', 'area striata', 'base', 'blind', 'cell type', 'computational neuroscience', 'experimental study', 'in vivo', 'innovation', 'luminance', 'multi-electrode arrays', 'novel', 'predictive modeling', 'receptive field', 'relating to nervous system', 'response', 'retinal neuron', 'stimulus processing', 'visual processing', 'visual stimulus']",NEI,DUKE UNIVERSITY,R01,2020,528815,0.06351638711633711
"CRCNS: Joint coding of shape and texture in the primate brian PROJECT DESCRIPTION  Collaborating Pis and Consultant  United States  Pl: Anitha Pasupathy, Dept. of Biological Structure, University of Washington, Seattle, USA  Co-Pl: Wyeth Bair, Dept. of Biological Structure, University of Washington, Seattle, USA Japan  Pl: lsamu Motoyoshi, Dept. of Life Sciences, The University of Tokyo, Japan  Consultant: Hidehiko Komatsu, Tamagawa University, Japan  Specific Aims  Our visual system endows us with a diverse set of abilities: to recognize and manipulate  objects, avoid obstacles and danger during navigation, evaluate the quality of food, read text,  interpret facial expressions, etc. This relies on the neuronal processing of information about  form and material texture along the ventral pathway of the primate visual system (Ungerleider &  Mishkin, 1982; Felleman & Van Essen, 1991). Studies over the past several decades have  produced detailed models of how visual information is processed in V1, the earliest stage along . this pathway (Hubel & Wiesel, 1959, 1968; Movshon et al., 1978a, b; Albrecht et al., 1980), but  beyond V1 our understanding of visual processing and representation is limited. This is  particularly true with regard to our understanding of how visual representations of form and  texture jointly contribute to object perception and recognition. The broad goal of this proposal is  two-fold-to develop an experimentally-driven image-computable model for how naturalistic  visual stimuli are processed in area V4, an important intermediate stage along the ventral visual  pathway (Aim 1) and to discover how such a representation contributes to perception (Aim 2).  Past studies have shown that V4 neurons are sensitive to both the form (Desimone and Schein,  1987; Kobatake and Tanaka, 1994; Gallant et al., 1993; Pasupathy and Connor, 2001; Nandy et  al., 2013) and the surface texture of visual stimuli (Arcizet et al., 2008; Goda et al., 2014;  Okazawa et al., 2015). But, because expertise is narrow and experimental time limited,  scientists tend to focus exclusively on the encoding of form or texture and not on their joint  coding. For example, in the laboratories of the USA portion of this collaboration, we have until  now focused on form processing by carrying out neurophysiological studies using 2D shapes  with uniform surface properties to investigate how object boundaries are encoded (Oleskiw et  al., 2014; Popovkina et al., 2016). We have modeled our data by comparing the representation  of V4 neurons to that of the units in AlexNet (Pospisil et al., 2015), a prominent convolutional  neural net (CNN) trained to recognize objects (Krizhevsky et al., 2012). At the same time, the  Japanese contingent of this collaboration has investigated the encoding of surface texture and  gloss in human perception without associated form encoding (Motoyoshi et al., 2007; Sharan et  al., 2008; Motoyoshi, 2010; Motoyoshi & Matoba, 2012). Here we propose to bring our  respective expertise in studying form and texture encoding to bear on the question of how  naturalistic stimuli with both form and surface cues are encoded in area V4 and how these  representations support human visual perception. Our specific aims are:  Aim1. To build a unified image-computable model for neuronal responses to shapes and  textures in area V4  V4 responses to 2D shapes with uniform luminance/chromatic characteristics can be explained  by a hierarchical-Max (HMax) model for object recognition that emphasizes boundary features  (Cadieu et al., 2007). Such responses can also be explained by units in artificial deep  convolutional networks, in which boundary features are not explicitly emphasized (all features  are learned from initially random weights). On the other hand, V4 responses to texture patches  can be well explained by a higher-order image-statistics-based model (Okazawa et al., 2015).  Using shape data from the Pasupathy lab and texture data from the Komatsu lab (Japanese  consultant), we will ask whether responses of V4 neurons to shapes and textures can be Page 21 n/a",CRCNS: Joint coding of shape and texture in the primate brian,9994299,R01EY029997,"['3-Dimensional', 'Biological', 'Biological Sciences', 'Categories', 'Characteristics', 'Code', 'Collaborations', 'Computer Models', 'Computers', 'Cues', 'Data', 'Dimensions', 'Discrimination', 'Facial Expression', 'Goals', 'Human', 'Image', 'Individual', 'Japan', 'Japanese Population', 'Joints', 'Laboratories', 'Modeling', 'Modification', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Physiology', 'Primates', 'Process', 'Psychophysics', 'Scientist', 'Shapes', 'Stimulus', 'Structure', 'Subgroup', 'Surface', 'Surface Properties', 'Text', 'Texture', 'Time', 'Tokyo', 'Training', 'United States', 'Universities', 'V4 neuron', 'Visual', 'Visual Pathways', 'Visual Perception', 'Visual system structure', 'Washington', 'Weight', 'area V4', 'base', 'convolutional neural network', 'experimental study', 'food quality', 'human model', 'human subject', 'information processing', 'luminance', 'neurophysiology', 'novel', 'object perception', 'object recognition', 'response', 'statistics', 'visual information', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2020,230475,0.09980350581947274
"GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN PROJECT SUMMARY & ABSTRACT  Human locomotion through natural environments requires the coordination of all levels of the sensorimotor hierarchy, from the cortical areas involved in processing of visual information and high level planning to the subcortical and spinal structures involved in the regulation of the gait and posture. However, despite the complex neural bases of human locomotion, the output is highly regular and well organized around the basic physical dynamics and biomechanics that define the stability and energetic costs of moving a bipedal body through space. There is a rich and growing body of literature describing detailed knowledge each of the individual components of human locomotion, including neural mechanisms, muscular neuromechanics, and biomechanics. However, very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion through a complex and dynamic world. This lack of integrative research not only restricts the breadth of impact of research from these individual disciplines, but also limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to to fill this critical gap in our knowledge about human locomotion, it is necessary to develop an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world. In service of this general goal, this proposal outlines research projects aimed at specific unanswered questions about locomotion over different terrains. This proposal comprises three specific research and training aims on the visual control of locomotion over rough terrain. Aim 1 focuses on the behavioral task itself, Aim 2 investigates the sensory stimulus experienced during real-world locomotion, and Aim 3 examines the motor integration of visually specified goals into the ongoing gait cycle. Aim 1 investigates effects of changing environmental uncertainty and task demands on gaze allocation strategies during locomotion over real-world rough terrain. Aim 2 analyzes and models the visual stimulus experienced during locomotion over real-world rough terrain. Aim 3 determines how visually specified target footholds and targets are integrated into the ongoing preferred steady-state gait. Together these aims will significantly advance our understanding of how humans use vision to control their movement through the natural world, which greatly increase our ability to develop clinical diagnosis and treatment for loss of locomotor function. PROJECT NARRATIVE  Very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion. This lack of integrative research limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to fill this critical gap in our knowledge about human locomotion, this proposal develops an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world.",GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN,10019556,R00EY028229,"['3-Dimensional', 'Aging', 'Algorithms', 'Area', 'Attention', 'Behavior', 'Behavioral', 'Biomechanics', 'Clinical Treatment', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Development', 'Discipline', 'Environment', 'Eye', 'Gait', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Link', 'Literature', 'Locomotion', 'Measures', 'Mechanics', 'Mentors', 'Modeling', 'Motion', 'Motor', 'Movement', 'Muscle', 'Musculoskeletal', 'Nature', 'Neuromechanics', 'Output', 'Parkinson Disease', 'Pattern', 'Phase', 'Photic Stimulation', 'Positioning Attribute', 'Postdoctoral Fellow', 'Posture', 'Protocols documentation', 'Regulation', 'Research', 'Research Activity', 'Research Project Grants', 'Research Training', 'Services', 'Signal Transduction', 'Specific qualifier value', 'Spinal', 'Stroke', 'Structure', 'System', 'Training', 'Training Programs', 'Uncertainty', 'Vision', 'Visual', 'Visual Fields', 'Walking', 'Wireless Technology', 'area MST', 'area MT', 'base', 'clinical Diagnosis', 'cost', 'design', 'environmental change', 'experience', 'experimental study', 'foot', 'gaze', 'insight', 'instrument', 'kinematics', 'multidisciplinary', 'neuromechanism', 'neuromuscular', 'novel', 'optic flow', 'programs', 'relating to nervous system', 'response', 'sensory stimulus', 'skills', 'statistics', 'treadmill', 'treatment planning', 'visual control', 'visual information', 'visual processing', 'visual stimulus', 'visual-motor integration']",NEI,NORTHEASTERN UNIVERSITY,R00,2020,243713,0.05377184470026173
"Decoding parametric attributes of auditory working memories from human brain activity Decoding parametric attributes of auditory working memories from human brain activity Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Auditory WM dysfunctions are evidenced in individuals with speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as central auditory processing disorders (CAPD). Better understanding of auditory WM would help develop more precise biomarkers and targeted interventions for these deficits. Evidence for neuronal activation related to auditory WM patterns have been found in laboratory animals as well as in non- invasive human neuroimaging studies, both in auditory cortices (AC) and elsewhere in the brain. Recent human fMRI data also provide some evidence on item-specific activation patterns in ACs and frontal cortices. However, exactly where in the brain auditory WM content is stored and, more importantly, how the memorized information is represented is still unclear.  This research program pursues a better understanding of human auditory WM by attempting to infer its contents from the brain: Using state-of-the-art non-invasive neuroimaging and advanced signal-analysis methods we will search for cortical activation patterns that would predict item-specific WM information. We will examine brain function non-invasively with magneto- and electroencephalography (MEG/EEG), transcranial magnetic stimulation (TMS), and functional MRI (fMRI), and validate the findings using intracranial EEG (iEEG) measurements in presurgical patients. Recent studies suggest that, instead of persistent activation patterns, WM is supported by short-term synaptic facilitation, i.e., ""activity-silent"" population-level mechanisms. We hypothesize that these activity-silent representations could be decoded by analyzing the aftereffects of generic auditory ""impulse stimuli"" or TMS, which are utilized to ""ping"" the underlying cortical network during memory maintenance. We also hypothesize that although auditory WM likely involves co-operation of multiple brain regions, which are involved in articulatory-motor functions, perceptual categorization, or semantic processing, the retention of auditory-sensory attributes such as spectrotemporal modulation patterns critically depends on ACs. To examine WM of such auditory attributes, we will use tasks with dynamic ripple sound stimuli, which are spectrotemporally similar to human vocalizations but resist non-auditory processing strategies.  The major significance of this project is that it will increase the understanding of auditory WM, a crucial cognitive function whose neuronal bases have remained elusive. The results may also help develop more precise tools for characterizing auditory WM dysfunctions in hearing and communication deficits as well as in disorders such as dyslexia, attention deficit/hyperactivity disorder (ADHD), and schizophrenia. Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Our research program pursues a better theoretical understanding of this crucial cognitive function using advanced multimodal neuroimaging methods, validated using intracranial recordings in pre-surgical patients. Our results may also help develop more precise tools for characterizing auditory WM dysfunctions in speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as attention deficit/hyperactivity disorder (ADHD) and schizophrenia.",Decoding parametric attributes of auditory working memories from human brain activity,9870791,R01DC016915,"['Attention deficit hyperactivity disorder', 'Auditory', 'Auditory area', 'Biological Markers', 'Brain', 'Brain region', 'Central Auditory Processing Disorder', 'Cognition', 'Communication', 'Data', 'Disease', 'Dyslexia', 'Electroencephalography', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Hearing', 'Human', 'Impairment', 'Individual', 'Intervention', 'Laboratory Animals', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measurement', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Motor', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perceptual Disorders', 'Population', 'Principal Component Analysis', 'Problem Solving', 'Reading', 'Research', 'Schizophrenia', 'Sensory', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Speech Perception', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Transcranial magnetic stimulation', 'base', 'cognitive function', 'cortex mapping', 'electric field', 'experimental study', 'frontal lobe', 'multimodality', 'neuroimaging', 'operation', 'programs', 'semantic processing', 'sound', 'tool', 'vocalization']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,601029,0.01075137346929493
"Early representation of 3D volumetric shape in visual object processing Project Summary The goal of this project is to test a novel theoretical framework for understanding how the ventral pathway subserves object vision. In the standard framework, a series of neural operations on 2D image data through many intermediate cortical stages, including area V4, leads to high-level perceptual representations, including representation of object identity, at the final stages of the ventral pathway. However, our preliminary microelectrode data from a fixating monkey show that many neurons in V4 represent volumetric (volume- enclosing) 3D shape, not 2D image patterns. These neurons respond to many different 2D images that convey the same 3D shape with different shape-in-depth cues, including shading, reflection, and refraction. They even respond preferentially to random dot stereograms that convey 3D volumetric shape with no 2D cues whatsoever. Moreover, our preliminary results with 2-photon functional imaging in anesthetized monkey V4 show that 3D shape signals are grouped by their similarity, and also group with isomorphic (same outline) 2D shape signals (which could contribute evidence to corresponding 3D shape inferences). We propose to capitalize on these preliminary data by demonstrating the prevalence of 3D shape tuning in area V4, analyzing the 3D shape coding strategies used by these neurons, and measuring how 2D and 3D shape signals are arranged at a microscopic level across the surface of V4. We expect these results to provide strong evidence that extraction of 3D shape fragments is a primary goal of V4 processing. This early extraction of 3D shape information, just two synapses beyond primary visual cortex, would suggest a competing framework for understanding the ventral pathway, in which the initial goal is to represent 3D physical structure, independent of the various 2D image cues used to infer it. In this framework, object recognition would be based on preceding information about 3D physical structure, which would explain why human object recognition is so robust to image changes, in a way that the best computational vision systems are not. The scientific impact of this work would be to divert vision experiments toward understanding representation of real world 3D structure (rather than 2D planar stimuli) and to encourage computational vision scientists to incorporate early 3D shape processing into the deep convolutional network models that are the current state of the art. Narrative This study will help explain how the human brain achieves such remarkably robust perception of visual objects. The results will help guide future rehabilitative and prosthetic strategies for patients with visual impairments, by elucidating neural strategies that could be used to bring computer vision prosthetics up to human performance levels, and by discovering specific neural signals for object information that could be replicated by electrode array implants in higher-level visual cortex.",Early representation of 3D volumetric shape in visual object processing,9942414,R01EY029420,"['3-Dimensional', '3D world', 'Area', 'Biological', 'Brain', 'Calcium Signaling', 'Code', 'Computer Vision Systems', 'Cues', 'Data', 'Electrodes', 'Functional Imaging', 'Future', 'Genetic Programming', 'Glass', 'Goals', 'Human', 'Image', 'Implant', 'Lead', 'Learning', 'Measures', 'Medial', 'Microelectrodes', 'Microscopic', 'Microscopy', 'Modeling', 'Monkeys', 'Network-based', 'Neurons', 'Ocular Prosthesis', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Population', 'Prevalence', 'Prosthesis', 'Rehabilitation therapy', 'Scientist', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Structure', 'Surface', 'Synapses', 'System', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'V4 neuron', 'Vision', 'Visual Cortex', 'Visual Perception', 'Visual impairment', 'Work', 'area V4', 'area striata', 'base', 'convolutional neural network', 'experimental study', 'individual response', 'network models', 'neurotransmission', 'nonhuman primate', 'novel', 'object perception', 'object recognition', 'operation', 'relating to nervous system', 'response', 'three dimensional structure', 'two-photon', 'virtual reality', 'visual object processing']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2020,548567,0.0868325048293395
"Access to parietal action representations after stroke lesions in visual cortex PROJECT SUMMARY  The ability to recognize and use objects according to their function (e.g., fork, hammer, pencil) requires integration of visual, semantic and action knowledge across occipital, temporal and parietal areas. Left parietal regions support critical aspects of object-directed action, such as grasping and object manipulation. This research activity uses a combination of fMRI and behavioral measures in patients with ischemic strokes to early and extrastriate visual areas to test the following hypotheses: Aim 1: There is a visual pathway to the parietal grasp region (aIPS) that bypasses processing in primary visual cortex. Aim 2: Left ventral extrastriate cortex is necessary to access manipulation information for visually presented objects. Aim 3A: Ballistic grasping actions to objects in the hemianopic field are influenced by volumetric properties (size, orientation) of targets. Aim 3B: Left ventral extrastriate lesions impair object function (e.g., `scissors used to cut') and disrupt access to manipulation knowledge from visual input. The research leverages strengths of fMRI (whole brain correlational measure) and neuropsychology (causal inference) to test new hypotheses about vision and action.  `Tools' (i.e., small manipulable objects) are an excellent domain in which to address broader questions about the integration of sensory, motor and cognitive processing. This is because tool recognition and tool use require the integration of distinct sensory, motor and cognitive representations, and the neural substrates of tool processing are well described. The research program emphasizes fresh perspectives on longstanding ideas about the dorsal and ventral visual pathways, by a) undertaking the first systematic investigation of the types of information about objects that are extracted by visual pathways that bypass primary visual cortex, and by b) studying how some parietal areas depend on inputs from the ventral stream in order to access the correct action for a given object. The research activity innovates by testing hypotheses about how lesions at different stages in the cortical visual hierarchy affect downstream processing in parietal cortex, combining neural and behavioral measures to study brain damaged patients (generating causal evidence), and by combining univariate and multivariate measures to `read out' the information content of brain regions (parietal cortex) that are anatomically remote from a lesion. The research advances understanding of how lesions in one brain region disrupt computations in other parts of the brain that depend on the damaged region for their inputs, a phenomenon (`dynamic diaschisis') that applies to brain injury generally. Advancing understanding of these basic issues using causal data has broad implications for understanding how the brain selects the correct action for the correct object, and more generally for theories of conceptual organization and causal reasoning. Understanding how the brain accesses actions from visual input has implications for related fields, such as robotics, neuroprosthetics, and evidenced based approaches for rehabilitating function after brain injury. Project Narrative Functional MRI and behavioral testing are used to test hypotheses about how strokes affecting occipital and temporal cortex disrupt access to action representations in parietal cortex. This research will advance understanding of how the brain processes visual information in support of everyday actions.",Access to parietal action representations after stroke lesions in visual cortex,9868307,R01EY028535,"['Address', 'Affect', 'Alexia', 'Anatomy', 'Area', 'Ballistics', 'Behavioral Assay', 'Brain', 'Brain Injuries', 'Brain region', 'Bypass', 'Cognitive', 'Data', 'Dorsal', 'Eating', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Imaging Device', 'Impairment', 'Investigation', 'Ischemic Stroke', 'Knowledge', 'Left', 'Lesion', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Neural Pathways', 'Neuropsychology', 'Occipital lobe', 'Parahippocampal Gyrus', 'Parietal', 'Parietal Lobe', 'Participant', 'Pathway interactions', 'Patients', 'Population', 'Process', 'Property', 'Prosopagnosia', 'Reading', 'Research', 'Research Activity', 'Robotics', 'Role', 'Semantics', 'Sensory', 'Stimulus', 'Stream', 'Stroke', 'Structure of supramarginal gyrus', 'Temporal Lobe', 'Testing', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual system structure', 'Work', 'area striata', 'base', 'behavior measurement', 'behavior test', 'blind', 'cognitive development', 'evidence base', 'extrastriate', 'extrastriate visual cortex', 'fovea centralis', 'grasp', 'information processing', 'innovation', 'lens', 'multisensory', 'neuroprosthesis', 'post stroke', 'programs', 'relating to nervous system', 'sensory integration', 'theories', 'tool', 'visual information', 'visual motor', 'visual object processing', 'visual process', 'visual processing']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2020,423007,0.08353183835977013
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9884770,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Models', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'convolutional neural network', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2020,388626,0.0620740346975979
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9932509,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual environment', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,615717,0.0403740711791051
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,9912748,R01EY011787,"['3-Dimensional', 'Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Cerebral cortex', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'cell type', 'cortical visual impairment', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'mouse genetics', 'nerve supply', 'neural circuit', 'neural network', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2020,395525,0.015328554356119321
"The cerebro-cerebellar-basal-gangliar network for visuomotor learning ABSTRACT Visual learning is critical to the lives of human and non-human primates. Visuomotor association, the assignment of an arbitrary symbol to a particular movement (like a red light to a braking movement), is a well- studied form of visual learning. This proposal tests the hypothesis that the brain accomplishes visuomotor associative learning using an anatomically defined closed-loop network, including the prefrontal cortex, the basal ganglia, and the cerebellum. In our preliminary work we have developed a task that studies how monkeys learn to associate one of two novel fractal symbols with a right hand movement, and the other symbol with a left hand movement. Every experiment begins with the monkeys responding to two overtrained symbols that they have seen hundreds of thousands of times. At an arbitrary time we change the symbols to two fractal symbols that the monkey has never seen. It takes the monkey 40 to 70 trials to learn the new associations. In our preliminary results we have discovered that Purkinje cells in the midlateral cerebellar hemisphere track the monkeys’ learning as they as they figure out the required associations. The neurons signal the result of the prior decision. Half of the neurons respond more when the prior decision was correct; the others respond more when the prior decision was wrong. The difference between the activity of these two types of neurons provides a cognitive error signal that is maximal when the monkeys are performing at a chance level, and gradually becomes not different from zero as the monkeys learn the task. The neurons do not predict the result of the impending decision. Although the neurons change their activity dramatically at the symbol switch, the kinematics of the movements do not change at all. This proposal takes this discovery as the starting point for four aims: 1) to use viral transynaptic tract tracing to discover the cortical and basal ganglia regions that project to the cerebellar visuomotor association area. 2) to record from the four nodes of the network as anatomically defined (midlateral cerebellar hemisphere, dentate nucleus, basal ganglia, prefrontal cortex), simultaneously, using multiple single neuron recordings, to see if these areas also have information about the process of visuomotor association 3) to inactivate each node, to see how their inactivation affects the monkey’s ability to learn new associations, and whether the inactivation affects the activity of the neurons at the other nodes. 4) to develop computational methods to analyze the activity of neural activity recorded simultaneously in all four nodes of the network (Aim 2) in the midlateral cerebellar cortex with regard to parameters such as prior outcome and movement, hand, symbol, and the intensity and epoch of the prior cognitive error signal. We will use dimensional reduction techniques to answer questions like whether hand or symbol can be decoded from network activity. We will model how the cerebellum simple spike cognitive error signal might propagate through the network and be used to facilitate visuomotor association learning and the processing of signals in the cerebellum, basal ganglia and cerebral cortex Project Narrative Learning that a particular object cues a particular action, as a red light makes us stop walking or brake the car, is critical for human behavior and can be degraded by human disease. This project will apply physiological, computational, and anatomical methods to investigate a brain network for visual learning. We will find the exact areas of the cerebral cortex, basal ganglia, and cerebellum that participate in this learning, and use machine learning techniques to understand how the activity of neurons recorded simultaneously in these brain areas can facilitate learning.",The cerebro-cerebellar-basal-gangliar network for visuomotor learning,9983219,R01NS113078,"['Affect', 'Agonist', 'Anatomy', 'Area', 'Association Learning', 'Basal Ganglia', 'Behavior', 'Brain', 'Cerebellar Cortex', 'Cerebellum', 'Cerebral cortex', 'Cognition', 'Cognitive', 'Computational Technique', 'Computer Analysis', 'Computing Methodologies', 'Cues', 'Data Set', 'Dentate nucleus', 'Dimensions', 'Electronic Medical Records and Genomics Network', 'Exhibits', 'Failure', 'Fractals', 'Grant', 'Hand', 'Human', 'Injections', 'Learning', 'Left', 'Light', 'Machine Learning', 'Methods', 'Modeling', 'Monkeys', 'Motor', 'Movement', 'Muscimol', 'Neurons', 'Outcome', 'Parietal', 'Pathway Analysis', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physiological', 'Prefrontal Cortex', 'Process', 'Property', 'Purkinje Cells', 'Rabies virus', 'Reaction Time', 'Reading', 'Reflex action', 'Reporting', 'Role', 'Short-Term Memory', 'Signal Transduction', 'Site', 'Source', 'Suggestion', 'Techniques', 'Testing', 'Time', 'To specify', 'Viral', 'Virus', 'Visual', 'Walking', 'Work', 'classical conditioning', 'cognitive function', 'cognitive process', 'experimental study', 'gamma-Aminobutyric Acid', 'human disease', 'kinematics', 'motor behavior', 'motor control', 'motor learning', 'nonhuman primate', 'novel', 'relating to nervous system', 'signal processing', 'success', 'visual learning', 'visual motor']",NINDS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,1025216,0.015711838883578504
"Auditory brain-computer interface for communication Project Summary  A fundamental end-goal of brain-computer interfaces (BCI) is to enable communication in individuals with severe motor paralysis. BCIs decode the neural signals and accomplish the intended goal via an effector, such as a computer cursor or a robotic limb. The BCI user relies on the realtime feedback of the effector's performance to modulate their neural strategy to control the external device. To date, this feedback is predominantly visual. However patients with the most severe paralysis resulting from amyotrophic lateral sclerosis (ALS), some forms of stroke and traumatic brain injuries can have severe visual impairments including oculomotor fatigue, nystagmus and ophthalmoparesis - that make the reliable use of a visual-based BCI impossible. This puts a premium on developing novel solutions that can leverage sensory modalities that are intact. In this research, I will develop and test the feasibility of an auditory-based interface to establish BCI control in motor-impaired patients with severe neurological insults  In Aim 1, I propose to implement a novel paradigm using auditory cues in lieu of visual signals, and test its feasibility in controlling an effector (ie, computer cursor) to perform a cued target-acquisition task in healthy participants. This will validate the range of parameter values of the four tested auditory input signals: 1) frequency, 2) amplitude, 3) spatial azimuth and 4) spatial elevation. This approach is distinct from most binary class auditory BCI solutions, since it relies on both the natural ability of humans to localize sounds, and the ability to associate new tones to a virtual space, thus allowing a truly multi-class auditory approach. In Aim 2, I propose to implement the auditory interface into the realtime xPC used for visual presentation in clinical trial participants with intracortical BCIs, and test their performance on the cued target-acquisition task. Although much success has been demonstrated in this task using visual feedback, this auditory approach will permit BCI use by people with visual impairments further compounding their paralysis. Finally in Aim 3, I will test the feasibility of BrainGate BCI users to utilize an auditory BCI speller to perform a copy-typing task and free- typing task.  The accomplishment of the goals of this research will be a critical step towards enabling severely paralyzed individuals with visual impairments to re-establish communication independently, continuously and reliably. Project Narrative Brain-computer interfaces enable motor-impaired individuals to communicate using an effector such as a neural cursor or a robotic arm. The successful completion of the proposed project will develop a unique technology that enables a real-time auditory-reliant BCI for communication in severely paralyzed individuals resulting from stroke, amyotrophic lateral sclerosis and severe brain injuries. Study results will advance our knowledge of developing neurotechnologies that leverage non-visual sensory modalities, as well as provide much insight into the cortical neural activities that underpin motor intention and movement.",Auditory brain-computer interface for communication,9851289,F32MH118709,"['Adult', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Auditory', 'Auditory system', 'Base of the Brain', 'Brain Injuries', 'Brain Stem Infarctions', 'Clinical Trials', 'Communication', 'Computers', 'Cues', 'Data', 'Development', 'Devices', 'Eye Movements', 'Family Caregiver', 'Fatigue', 'Feedback', 'Frequencies', 'Functional disorder', 'Future Generations', 'Goals', 'Hearing Tests', 'Human', 'Impairment', 'Individual', 'Infrastructure', 'Institution', 'Intention', 'Joystick', 'Knowledge', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Manuals', 'Measures', 'Modality', 'Motor', 'Movement', 'Mus', 'Neurologic', 'Ophthalmopareses', 'Paralysed', 'Participant', 'Pathologic Nystagmus', 'Pathway interactions', 'Patients', 'Performance', 'Positioning Attribute', 'Psyche structure', 'Quadriplegia', 'Quality of life', 'Research', 'Resources', 'Robotics', 'Sensory', 'Signal Transduction', 'Social Interaction', 'Sound Localization', 'Speech', 'Spinal cord injury', 'Stroke', 'System', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Traumatic Brain Injury', 'Universities', 'User-Computer Interface', 'Vision', 'Visual', 'Visual Fields', 'Visual impairment', 'Workload', 'Writing', 'arm', 'auditory feedback', 'base', 'brain computer interface', 'clinical trial participant', 'engineering design', 'improved', 'insight', 'motor impairment', 'neurotechnology', 'neurotransmission', 'novel', 'oculomotor', 'relating to nervous system', 'speech synthesis', 'spelling', 'success', 'usability', 'virtual', 'visual feedback', 'way finding']",NIMH,BROWN UNIVERSITY,F32,2020,74810,0.05103258627233366
