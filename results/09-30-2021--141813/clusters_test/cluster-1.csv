text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Computational Analysis of Enzyme Catalysis and Regulation Project Summary: It is of great fundamental and biomedical importance to understand the physical princi- ples that govern the coupling between the chemical step in a biomolecule and other events, such as penetration of water molecules into the active site, recruitment of transient metal ions, or conformational rearrangements near and afar. This is a challenging task, however, due to the intrinsic multi-scale nature of the problem. As a result, our understanding in factors that dictate the efﬁciency and speciﬁcity of enzyme catalysis remains in- complete, especially regarding contributions beyond the active site; this knowledge gap has greatly limited our ability to design highly efﬁcient enzymes de novo. Motivated by these considerations, the overarching theme of our research is to develop and apply multi-scale computational methods to reveal the underlying mechanism of enzyme catalysis at an atomic level, with a particular emphasis on establishing to what degree the chem- ical step is coupled with other processes proximal or distal to the active site. Speciﬁcally, we aim to develop an efﬁcient QM/MM framework to compute free energy proﬁles of enzyme reactions with a good balance of computational speed and accuracy; further integration with enhanced sampling approaches, machine learning techniques and modern computational hardwares enables us to gain insights into the nature of coupling be- tween the chemical step and other events during the functional cycle. Accordingly, we are in a unique position to pursue several lines of exciting applications, which include the mechanism and impact of transient metal ion recruiting in nucleic acid processing enzymes, the catalytic and regulatory mechanism of peripheral membrane enzymes, and systemic analysis of allosteric coupling in a transcription factor; an emerging research direction is to explore the interplay of stability, catalytic activity, and allostery during continuous directed evolution. Our project integrates computational method developments with applications inspired by recent experimental ad- vances, such as time-resolved crystallography, deep mutational scanning and continuous directed evolution. The research efforts will lead to novel computational tools and mechanistic insights into the regulatory mech- anisms of enzymes by processes either near or remote from the active site. Thus the project will have both fundamental impacts and implications for better design strategies for catalysis and allostery in biomolecules. Narrative: The computational methodologies we develop will be applicable to a broad set of metalloen- zymes and proteins of biomedical relevance. In particular, we target fundamental mechanistic problems in enzymes that catalyze nucleic acids synthesis/modiﬁcation and lipid metabolism, since mutations in these en- zymes are implicated in numerous human diseases such as cancer, insulin resistance and diabetes. Although our project does not focus on design of drugs, the mechanistic insights into enzyme catalysis and allosteric regulation will broaden strategies that can be used to target various enzymes of biomedical signiﬁcance.",Computational Analysis of Enzyme Catalysis and Regulation,10206585,R35GM141930,"['Active Sites', 'Allosteric Regulation', 'Catalysis', 'Chemicals', 'Computer Analysis', 'Computing Methodologies', 'Coupled', 'Coupling', 'Crystallography', 'Diabetes Mellitus', 'Directed Molecular Evolution', 'Distal', 'Drug Design', 'Enzymes', 'Equilibrium', 'Event', 'Free Energy', 'Insulin Resistance', 'Ions', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Membrane', 'Metals', 'Modernization', 'Modification', 'Molecular Conformation', 'Mutation', 'Nature', 'Nucleic Acids', 'Penetration', 'Peripheral', 'Positioning Attribute', 'Process', 'Proteins', 'Reaction', 'Regulation', 'Research', 'Sampling', 'Specificity', 'Speed', 'Techniques', 'Time', 'Tweens', 'Water', 'computerized tools', 'design', 'enzyme mechanism', 'human disease', 'insight', 'lipid metabolism', 'method development', 'mutation screening', 'novel', 'recruit', 'transcription factor']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R35,2021,295591
"AI based system for longitudinal, repeated measure analyses of freely moving C. elegans worms Abstract This project aims to develop WormInvestigator™, a novel, highly innovative system for performing automated, high-throughput and longitudinal studies of the behavior of C. elegans worms freely moving and socially interacting on agar plates (hereafter: ""freely moving worms"") across multiple time points over extended times (e.g., multiple days) with repeated measures designs. Work in Phase I will focus on demonstrating feasibility of our novel, patent pending, WormRecognizer™ technology – the ability to perform automatic, image-based identification of individual C. elegans worms within a group of freely moving worms (""digital tagging of freely moving worms""). Work in Phase II will focus on creating the full functionality of WormInvestigator for the commercial release. The innovation inherent in WormRecognizer will serve as the basis for enabling a game- changing innovation in the field – the ability to perform high throughput longitudinal, repeated measures design analyses of locomotion and other behavior of freely moving C. elegans worms from discrete, non-continuous video sequences. Compared to study designs that have independent groups repeated measures designs offer more statistical power and the possibility to track an effect over time. Specifically, repeated measures designs for analyzing locomotion and other behavior of freely moving worms will allow researchers to definitively assess the likelihood that a particular behavior is associated with a prior behavior, which is impossible without repeated measures designs or impractical continuous imaging and tracking under constant illumination. WormRecognizer will leverage the Deep Convolutional Neural Network (CNN) architecture to perform automatic identification of the tracks of the same worm in videos of groups of freely moving worms recorded at different time points; encouraging pilot data were generated during preparation of this application. C. elegans is increasingly used as a model organism in research focusing on brain mechanisms underlying complex behaviors and pathological alterations thereof, including research into neurodevelopment, Alzheimer's disease, autism, schizophrenia and traumatic brain injury. Thus, WormInvestigator will enable significant advancements in various mental neuroscience applications that use C. elegans as a model organism. Specifically, the fact that C. elegans express many of the neurotransmitters and associated receptors that are found in higher eukaryotes, including humans, makes C. elegans highly attractive for the (high throughput) screening of next generation therapeutics for mental diseases such as Alzheimer's disease, as well as for disorders that rely on neurotransmitter release modulation such as next generation treatments for schizophrenia. We will perform extensive feasibility studies, product validation and usability studies of WormInvestigator in close collaboration with expert neuroscientists. Market research performed during preparation of this application indicated that WormInvestigator will expand the use of C. elegans as a model organism to many laboratories that do not currently use them. A competing technology is not available. We anticipate the global market size for WormInvestigator to be more than 300 systems. Narrative Performing longitudinal studies and repeated measures design analyses in both short-term and long-term experimental assays focusing on the analysis of locomotion and other behavior of multiple C. elegans worms holds the promise of profound progress in next-generation neuroscience studies such as understanding neurodevelopmental, neuropsychiatric and neurodegenerative disorders, as well as aging research, drug discovery and toxicology. Our proposed product will be a transformative technology, using new analytical methods based on artificial intelligence algorithms that, for the first time, will enable researchers to perform these data-rich longitudinal studies and, thus, repeated measures design analyses in assays using C. elegans as a model organism. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.","AI based system for longitudinal, repeated measure analyses of freely moving C. elegans worms",10258638,R43MH126834,"['Acetylcholine', 'Address', 'Agar', 'Aging', 'Alzheimer&apos', 's Disease', 'Animal Behavior', 'Animal Model', 'Appearance', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Behavioral Research', 'Biological Assay', 'Biotechnology', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Dopamine', 'Eukaryota', 'Feasibility Studies', 'Glutamates', 'Goals', 'Human', 'Image', 'Individual', 'Laboratories', 'Legal patent', 'Lighting', 'Locomotion', 'Longevity', 'Longitudinal Studies', 'Market Research', 'Massachusetts', 'Measures', 'Microscope', 'Molecular', 'Motion', 'Mus', 'Names', 'National Institute of Mental Health', 'Nematoda', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neurosciences', 'Neurotransmitters', 'Pathologic', 'Pharmacologic Substance', 'Phase', 'Population Analysis', 'Preparation', 'Psyche structure', 'Rattus', 'Research', 'Research Design', 'Research Personnel', 'Rodent', 'Schizophrenia', 'Schools', 'Serotonin', 'Speed', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'Validation', 'Visual Fields', 'Work', 'analytical method', 'autism spectrum disorder', 'base', 'behavioral study', 'convolutional neural network', 'design', 'digital', 'drug discovery', 'fighting', 'free behavior', 'gamma-Aminobutyric Acid', 'high throughput screening', 'innovation', 'intelligent algorithm', 'longitudinal analysis', 'neural network architecture', 'neurodevelopment', 'neuropsychiatric disorder', 'neurotransmitter release', 'next generation', 'novel', 'novel therapeutics', 'prevent', 'prototype', 'receptor', 'social', 'usability']",NIMH,"MICROBRIGHTFIELD, LLC",R43,2021,449987
"Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space Project Summary  The natural environment is intrinsically spatiotemporally heterogenous at both macroscopic and microscopic levels. What shapes such a heterogeneity includes the concentration gradients of biologically relevant chemical species in the extracellular medium including dioxygen (O2), reactive oxygen species (ROS), as well as essential redox-active transition metals. While a significant amount of effort has been devoted to spectroscopically image these chemical moieties, our capability to spatiotemporally control their concentration distributions in the extracellular medium remains limited. This is especially the case for biofilms and microbiota, in which the microorganisms’ small length scales pose significant challenges for concentration modulation. The inadequate control of concentration heterogeneity limits our capability of mimicking the natural environments in vitro and investigating how local concentration gradients affect microbial functionality. Therefore, there is a need for an advanced method of controlling chemical concentrations at microscopic level.  Our proposed research aims to use electrochemical nano-/micro-electrodes to spatiotemporally control the concentration gradients in the extracellular medium. When an electrochemical reaction occurs on an electrode’s surface, a concentration gradient is established near the electrode. Taking advantages of this phenomena with the assistance of numerical simulation, we will employ an array of nano-/micro-electrodes with individually addressable electrochemical potentials to program any arbitrary spatiotemporal concentration profiles. We will fine-tune the surface chemistry and the electrochemical properties of these electrodes to ensure biocompatibility and reaction specificity. The developed system will be applied to biofilms and we aim to investigate how the microbial social behavior will be affected by a perturbation of local O2 concentration. Moreover, we will use this device to mimic the heterogenous environment in the gut and culture gut microbiota in vitro. An algorithm based on machine learning will be employed to actively adjust electrode potentials, maintaining a stable concentration profile despite the accumulation of gut microorganisms.  Ultimately, our work will expand our capability of controlling the concentration heterogeneity in nature. The developed electrochemical system will serve an in vitro platform to culture microorganisms in their native environment, or as a tool to perturb the concentration profiles. Combining electrochemistry, inorganic chemistry, and nanomaterials the research will enable a deeper understanding of the spatial distribution and temporal response of microbial systems. Project Narrative The natural environment is intrinsically heterogenous yet our control of concentrations for chemical species is limited at microscopic level. The proposed research is relevant to the mission of the NIH because it describes the development of technology that will expand our capability of controlling chemical concentration profiles in a variety of microbial systems relevant to the public health. The research described here will enable a deeper understanding of disease-related microbial systems and help to formulate strategies to combat diseases.",Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space,10256801,R35GM138241,"['Affect', 'Algorithms', 'Biological', 'Chemicals', 'Chemistry', 'Devices', 'Dioxygen', 'Disease', 'Electrochemistry', 'Electrodes', 'Ensure', 'Environment', 'Heterogeneity', 'In Vitro', 'Individual', 'Inorganic Chemistry', 'Length', 'Machine Learning', 'Methods', 'Microbial Biofilms', 'Microscopic', 'Mission', 'Nanoarray Analytical Device', 'Nature', 'Oxidation-Reduction', 'Property', 'Public Health', 'Reaction', 'Reactive Oxygen Species', 'Research', 'Shapes', 'Social Behavior', 'Spatial Distribution', 'Specificity', 'Surface', 'System', 'Transition Elements', 'United States National Institutes of Health', 'Work', 'base', 'biomaterial compatibility', 'combat', 'extracellular', 'gut microbiota', 'microbial', 'microbiota', 'microorganism', 'microorganism culture', 'nano', 'nanomaterials', 'programs', 'response', 'simulation', 'spatiotemporal', 'spectroscopic imaging', 'technology development', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2021,371084
"A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth This project provides a data science framework and a toolbox of best practices for systematic and reproducible data-driven methods for validating and deriving RDoC constructs with relevance to psychopathology. Despite recent advances in methods for data-driven constructs, results are often hard to reproduce using samples from other studies. There is a lack of systematic statistical methods and analytical design for enhancing reproducibility. To fill this gap, we will develop a data science framework, including novel scalable algorithms and software, to derive and validate RDoC constructs. Although the proposed methods will generally apply to all RDoC domains and constructs, we focus specifically on furthering understanding of the RDoC domains of cognitive control (CC) and attention (ATT) constructs implicated in attention deficit disorder (ADHD) and obsessive-compulsive disorder (OCD). Our application will use multi-modal neuroimaging, behavioral, and clinical/self-report data from large, nationally representative samples from the on Adolescent Brain Cognitive Development (ABCD) study and multiple local clinical samples with ADHD and OCD. Specifically, using the baseline ABCD samples, in aim 1, we will apply and develop methods to assess and validate the current configuration of RDoC for CC and ATT using confirmatory latent variable modeling. We will implement and develop new unsupervised learning methods to construct new computational-driven, brain-based domains from multi-modal image data. In Aim 2, We will introduce network analysis (via Gaussian graphical models) to characterize heterogeneity in the interrelationship of RDoC measurements due to observed characteristics (i.e., age and sex). We will further model the heterogeneity of the population due to unobserved characteristics by introducing the data-driven precision phenotypes, which are the subgroup of participants with similar RDoC dimensions. We propose a Hierarchical Bayesian Generative Model and scalable algorithm for simultaneous dimension reduction and identify precision phenotypes. The model also serves as a tool to transfer information from the community sample ABCD to local clinical enriched studies. In aim 3, we will utilize the follow-up samples from ABCD and local clinical enriched data sets to validate the results from Aims 1 and 2 and assess the clinical utility of the precision phenotypes in predicting psychological development in follow-up time. Our project will provide a suite of analytical tools to validate existing RDoC constructs and derive new, reproducible constructs by accounting for various sources of heterogeneity. To advance the understanding of psychopathology using dimensional constructs of measurements from multiple units of analysis, we propose reproducible statistical framework for validating and deriving RDoC constructs with relevance to psychopathology. We will use multi-modal neuroimaging, behavioral and clinical/self-report data from multiple samples to develop this framework. The design of our study consists of analyzing large, nationally representative samples, validating the results in local clinically enriched samples, and transfer information from the large community samples to local clinical samples.",A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth,10250553,R01MH124106,"['11 year old', 'Accounting', 'Adolescent', 'Age', 'Algorithmic Software', 'Algorithms', 'Attention', 'Attention Deficit Disorder', 'Base of the Brain', 'Behavioral', 'Brain', 'Characteristics', 'Child', 'Chronology', 'Clinical', 'Clinical Data', 'Communities', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Dimensions', 'Ensure', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Goals', 'Heterogeneity', 'Image', 'Knowledge', 'Learning', 'Link', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Obsessive-Compulsive Disorder', 'Participant', 'Pathway Analysis', 'Patient Self-Report', 'Phenotype', 'Population Heterogeneity', 'Prediction of Response to Therapy', 'Psychological Transfer', 'Psychopathology', 'Reproducibility', 'Reproducibility of Results', 'Research Domain Criteria', 'Sampling', 'Source', 'Statistical Methods', 'Structure', 'Subgroup', 'Symptoms', 'Time', 'Variant', 'Youth', 'age effect', 'analytical tool', 'autoencoder', 'base', 'biological sex', 'cognitive control', 'cognitive development', 'deep learning', 'design', 'follow up assessment', 'follow-up', 'high dimensionality', 'independent component analysis', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'multimodality', 'network models', 'neuroimaging', 'novel', 'psychologic', 'response', 'sex', 'tool', 'unsupervised learning']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2021,660324
"Improved Surgical Navigation Using Video-CT Registration Abstract  In many surgical procedures, image guided surgery (IGS), also known as surgical navigation, facilitates precise surgical manipulations near critical structures such as the brain and eye. IGS suffers from critical limitations such as loss of precision and correspondence with preoperative imaging once surgery begins and the anatomy is altered. These limitations may be addressed through intra-operative imaging, which effectively “resets” the model and thus enables both improved precision of IGS as well as improved surgical decision- making. However, intraoperative radiologic imaging has many limitations, including disruption of the workflow, cost, and additional radiation exposure. This project aims to develop solutions to resolve limitations of IGS without the need for intra-operative radiologic imaging. Our solutions rely upon data from a device that is present in every procedure using IGS, namely, the endoscope. Our goal in this project is use endoscopic video images to reconstruct surgical anatomy as it changes. This enables sustained precision in registration with pre- operative imaging throughout the procedure by updating the anatomical model as surgery progresses. We will achieve this by 1) using advances in computer vision to develop improved methods for continuous direct registration between the endoscope and the CT; and 2) developing methods that continuously compute the geometry of observed surfaces and update the preoperative CT with changes in that geometry. The technology developed in this proposal thus enables the following: 1) precise surgical navigation using the endoscope throughout the procedure; 2) surgical decision-making without the need for additional intra-operative imaging; and 3) new tools to reconstruct surgical anatomy and quantitatively evaluate the extent of surgery. Narrative  Image guided surgery is widely used to safely navigate around complex structures like the ethmoid bone and critical structures such as the brain; its utility is greatly enhanced when coupled with intraoperative radiographic imaging because the anatomic changes caused by surgery are clearly elucidated and can be incorporated into the surgical plan. This project will develop computational methods that exploit readily available endoscopic video to improve the accuracy of navigation and to provide intraoperative updates to the anatomic model. This technology will enhance surgical decisions in the operating room and enable precise navigation throughout the surgery without the need for additional radiologic imaging in the operating room.",Improved Surgical Navigation Using Video-CT Registration,10099301,R01EB030511,"['3-Dimensional', 'Address', 'Anatomic Models', 'Anatomy', 'Brain', 'Brain imaging', 'Cadaver', 'Clinical', 'Complex', 'Computer Vision Systems', 'Computing Methodologies', 'Coupled', 'Data', 'Decision Making', 'Detection', 'Devices', 'Diagnostic radiologic examination', 'Documentation', 'Endoscopes', 'Ethmoid bone structure', 'Eye', 'Geometry', 'Goals', 'Image', 'Image-Guided Surgery', 'Investigation', 'Methods', 'Modeling', 'Monitor', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Performance', 'Postoperative Period', 'Problem Solving', 'Procedures', 'Psyche structure', 'Radiation exposure', 'Safety', 'Sinus', 'Slice', 'Speed', 'Structure', 'Surface', 'Surgeon', 'System', 'Technology', 'Touch sensation', 'United States National Institutes of Health', 'Update', 'Vision', 'Visualization', 'Work', 'X-Ray Computed Tomography', 'base', 'cohort', 'cost', 'effectiveness evaluation', 'improved', 'interest', 'novel', 'operation', 'radiological imaging', 'reconstruction', 'tool', 'usability']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2021,628311
"Biomedical Data Translator Development of Autonomous Relay Agent: ARAX This project would continue collaborative work within the Translator consortium by a multi-site team (“Team X-ray”) at Oregon State University (PI Stephen Ramsey) and at two partner institutions, Pennsylvania State University (PI Koslicki) and the Institute for Systems Biology (PI Eric Deutsch; Co-I Jared Roach). Team X-ray was highly productive in Translator's feasibility assessment phase and the team brings critical expertise to Translator (see Resources). Component type: We propose to create, validate, and integrate an autonomous relay agent (ARA) called ARAX . ARAX will be a middleware component in the new Translator architecture that will extend significantly beyond the capabilities of the prototype reasoning tool (RTX) that we created in the feasibility assessment phase. Depending on the input request, ARAX's main output will be ranked subgraphs with clearly explained ranking basis. ARAX will leverage code and algorithms from RTX and will have an explicit application focus area, as described below. Main problems that ARAX is trying to address: Connections within a biomedical knowledge graph have highly variable degrees of (i) confidence (due to ambiguous predicates and/or due to highly variable degrees of reliability of knowledge types) and (ii) potential relevance to the user's query. Such edge-significance variability leads to both incorrect and difficult-to-interpret results which together pose a significant problem for creating broadly useful tools for computer-based biomedical reasoning. We propose to address this problem by explicitly accounting for these two types of edge variability in the reasoning algorithms–spanning a broad range of biomedical query types–that ARAX will provide to Translator. In addition to these broad capabilities, as described in the Project Plan, we will incorporate advanced algorithms in ARAX for responding to queries relating to disease therapy, including (1) drug repositioning for known disease, leveraging knowledge about the disease’s pathogenesis [1] ; and (2) therapeutic recommendations for rare diseases based on symptoms and the putative causal genetic variant. Plan for implementation of the project: In our Project Plan we describe a five-year timeline for creating, validating, and integrating ARAX within Translator, beginning with a three-month sprint leading to a prototype of ARAX by mid-March 2020. Key components of the plan include: (1) leveraging the BioThings Explorer software framework to enable ARAX to dynamically map between compounds, proteins, pathways, variants, phenotypes, and diseases based on knowledge source application programming interfaces in the Translator registry; (2) leveraging COHD and related Translator resources to obtain biomedical semantic distance information; (3) leveraging an application programming interface endpoint for the RTX biomedical knowledge graph, KG2; and (4) implementing probabilistic reasoning algorithms leveraging provenance information and dynamically determined edge relevance scores to improve reasoning. We will systematically use machine-learning to align ranking scores with measures of output quality. Collaboration strengths of our team include (i) developing technical standards for communications between Translator software agents (leveraging PI Deutsch’s extensive past experience); (ii) developing knowledge graph standards (leveraging PI Ramsey’s and PI Koslicki’s expertise); and (iii) deriving use-case vignettes that speak to the transformative potential of Translator (leveraging Co-I Roach’s and PI Ramsey’s expertise). In the development phase, our team would continue to collaborate with other teams and with NIH stakeholders in an adaptive, high-bandwidth, and team-boundary-agnostic fashion, as detailed in the Project Plan. Key challenges to building the proposed system are (1) the need to be able to ""chain"" together analytical steps between tools and (2) the need for cooperative development of standards that enable Translator components to interact; we address them in detail in the Project Plan. n/a",Biomedical Data Translator Development of Autonomous Relay Agent: ARAX,10333468,OT2TR003428,"['Accounting', 'Address', 'Algorithms', 'Architecture', 'Area', 'Code', 'Collaborations', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disease', 'Institutes', 'Institution', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Oregon', 'Output', 'Pathogenesis', 'Pathway interactions', 'Pennsylvania', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Proteins', 'Rare Diseases', 'Recommendation', 'Registries', 'Resources', 'Roentgen Rays', 'Semantics', 'Site', 'Software Framework', 'Source', 'Symptoms', 'System', 'Systems Biology', 'Therapeutic', 'TimeLine', 'United States National Institutes of Health', 'Universities', 'Variant', 'Work', 'application programming interface', 'base', 'experience', 'genetic variant', 'improved', 'knowledge graph', 'middleware', 'prototype', 'tool']",NCATS,OREGON STATE UNIVERSITY,OT2,2021,897051
"Predicting complicated grief from grief processing PROJECT SUMMARY Most people grieving the loss of a loved one will experience a period of intense pain and focusing on the loss lasting around 6 months, which is known as acute grief. Complicated grief (CG) occurs when the experiences of acute grief extend well past 6-months post-loss. Thoughts and feelings about the loss (i.e. grief processing) occurring during acute grief may play a role in healthy grieving and protect against CG development. Identification of the cognitive and emotional mechanisms of grief processing that contribute to healthy grief resolution would advance knowledge of the goals of grieving and assist the development of interventions for complicated grief. Two core components of grief processing are top-down regulation and balanced loss confrontation. Top-down pursue related emotional representations and recruit proportion regulation is the ability to suppress processing of intrusive emotional information to a stated goal. Top-down regulation may facilitate healthy grieving by allowing reprieve from intense loss thinking. Balanced loss confrontation refers to the processing of the loss in a way that protects against overload. Confrontation with the l oss may assist in the process of reforming one's mental of the deceased. This tudy will test extrinsic and intrinsic measures of top-down regulation balanced loss confrontation during acute grieving as predictors of CG development a year later We will a sample at high-risk for CG, the suicide-bereaved, in order to maximize the likeliness that a significant of the sample develops CG. The s . findings produced by this study may advance the knowledge of how CG develops, assist in the identification of people at high-risk for developing CG and potentially form the basis for targeted interventions.  The following K23 presents a research and training program that will support the applicant on the path of becoming an independent investigator of the role of grief processing in the development of complicated grief. The research mentorship, coursework, hands-on experience, seminars and classes ingrained in this training and plan will propel the applicant to independence in the domains of1) Clinical Research, 2) Psychometric Assessment of Grief Processing, 3) Machine Learning analysis of fMRI, 4) Biostatistics, 5) Scientific Independence. team independent and The combination of the environment, t raining plan, research strategy and mentorship will not only provide the candidate with a spectrum of new methods and skills that will establish him as an research scientist, but will also produce a body of knowledge that will clarify the specific cognitive emotional grief processes that contribute to the development of CG. PROJECT NARRATIVE Complicated grief describes an inability to adjust to the loss of a loved one over the course of the first year following the death. This study will identify cognitive, emotional and neural processes occurring in the early grieving period (3 to 5-months post-loss) that predict or protect against the development of complicated grief a year later in suicide bereaved subjects, a sample at high-risk for developing complicated grief. These findings may advance understanding of the process of grief, facilitate early identification of high-risk grievers and potentially form the basis for targeted treatment of complicated grief.",Predicting complicated grief from grief processing,10124433,K23MH114021,"['Acute', 'Age', 'Attention', 'Biometry', 'Cessation of life', 'Clinical', 'Clinical Research', 'Cognitive', 'Data', 'Depressed mood', 'Development', 'Down-Regulation', 'Early identification', 'Emotional', 'Emotions', 'Environment', 'Failure', 'Family member', 'Feeling', 'Functional Magnetic Resonance Imaging', 'Gender', 'Goals', 'Grief reaction', 'Guilt', 'High Prevalence', 'Individual', 'Instruction', 'Intervention', 'Interview', 'Knowledge', 'Machine Learning', 'Measures', 'Mental Depression', 'Mentorship', 'Methods', 'Modeling', 'Pain', 'Pathogenesis', 'Pattern', 'Play', 'Process', 'Psyche structure', 'Psychometrics', 'Questionnaires', 'Rain', 'Reaction Time', 'Recording of previous events', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Role', 'Sampling', 'Scientist', 'Severities', 'Shame', 'Stimulus', 'Suicide', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Training Programs', 'Trauma', 'Unconscious State', 'Validation', 'attentional bias', 'base', 'experience', 'high risk', 'indexing', 'intense pain', 'loved ones', 'neural patterning', 'recruit', 'relating to nervous system', 'response', 'sex', 'skills', 'sustained attention', 'targeted treatment', 'therapy development']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,K23,2021,199800
"Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease. ABSTRACT More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease (LD). While the CDC conventional standard two-tier (CSTT) approach for serodiagnosis of LD has worked relatively well when used as recommended, there is plenty of room for improvement. Of a number of weaknesses associated with the supplemental immunoblot of the CSTT the most significant is low reproducibility due to the subjective visual interpretation of results. To overcome these weaknesses the CDC recently updated its recommendations based on a modified STT (MSTT) in that a second EIA can replace the immunoblot. The major goal of this project is to develop an objective, quantitative, multiplex EIA that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens to build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity. The novelty of this study relies on: 1) evaluation of B. burgdorferi antigen-specific antibody isotypes and IgG subclasses that can be correlated with Lyme disease stage; and 2) development of new diagnostic tools using machine learning techniques to train and integrate all data and produce an objective result to discriminate early Lyme from early disseminated/late Lyme disease. We expect this Phase I SBIR to allow us to develop a new EIA for serodiagnosis of Lyme disease (isoEIAplex-Ld) and to further an ongoing collaboration with DCN diagnostics for the adaptation of our biomarkers to a new rapid Lateral Flow Assay (see Letter of Support) for a follow up Phase II SBIR . NARRATIVE More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease. While the CDC conventional standard two-tier approach for serodiagnosis of Lyme disease has worked relatively well when used as recommended, there is plenty of room for improvement. We propose to develop an objective multiplex enzyme immunoassay that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens and build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity.",Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease.,10204992,R43AI155211,"['Acute', 'Acute Disease', 'Affinity', 'Antibodies', 'Antibody Response', 'Antigens', 'Arthritis', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Borrelia burgdorferi', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Collaborations', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Specificity', 'Discrimination', 'Disease', 'Early Diagnosis', 'Enzyme Immunoassay', 'Evaluation', 'GTP-Binding Protein alpha Subunits, Gs', 'Genetic Recombination', 'Goals', 'Grant', 'High Prevalence', 'Human', 'IgA1', 'IgA2', 'IgE', 'IgG1', 'IgG2', 'IgG3', 'IgG4', 'Immune response', 'Immunodominant Antigens', 'Immunoglobulin A', 'Immunoglobulin D', 'Immunoglobulin G', 'Immunoglobulin Isotypes', 'Immunoglobulin M', 'Immunoglobulins', 'Infection', 'Iowa', 'Laboratories', 'Laboratory Diagnosis', 'Lesion', 'Letters', 'Licensing', 'Lyme Arthritis', 'Lyme Disease', 'Machine Learning', 'OspC protein', 'Patients', 'Peptidoglycan', 'Performance', 'Phase', 'Proteins', 'ROC Curve', 'Recommendation', 'Reproducibility', 'Research', 'Serum', 'Small Business Innovation Research Grant', 'Specificity', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'V(D)J Recombination', 'Visual', 'Work', 'antigen binding', 'base', 'commercialization', 'disease diagnosis', 'erythema migrans', 'follow-up', 'improved', 'lateral flow assay', 'novel diagnostics', 'pathogen', 'tool']",NIAID,"IMMUNO TECHNOLOGIES, INC.",R43,2021,295514
"Genetic determinants of thoracic aortic stiffness and remodeling Project Summary / Abstract This is an application for a K24 mentoring award for patient-oriented research (POR) from Julio Chirinos, MD, PhD, Associate Professor of Medicine at the Perelman School of Medicine at the University of Pennsylvania (Penn). Dr. Chirinos‘ long-term goals are to: (1) Substantially contribute to our understanding and approaches to the prevention and treatment of aortic aging and its associated disease burden, and; (2) to mentor the next generation of investigators interested in the epidemiology of aortic aging and its consequences in human health. This mid-career development award will be critical to help him achieve these goals via dedicated/protected time for mentoring activities, research and development of new skills that are anticipated to greatly enhance the applicant’s impact in this field throughout the rest of his career, as well as the impact and success of his trainees. The candidate has a strong record of mentorship, leadership, and research productivity. His research program encompasses epidemiologic, translational and POR studies of arterial aging and its role in Heart Failure with Preserved Ejection Fraction (HFpEF) and other conditions that afflict our aging population. The scientific goal of this proposal is to investigate the genetic determinants of age-related thoracic aortic stiffening and elongation using large available biobanks with associated genomic and aortic imaging data. These include the UK Biobank and the Penn Medicine Biobank. The projects will include the application of a novel method for quantification of aortic pulse wave velocity that can, for the first time, be applied retrospectively in widely available clinical imaging studies. Deep learning for high-throughput aortic phenotyping will play an important role in this research. The mentoring goals of this application are to engage and support the training of Penn fellows and junior faculty to conduct POR in arterial aging. The career development goal of this application is to support the candidate’s professional development and acquisition of new skills for POR research in aging, specifically: (1) genomics (genome-wide association studies, next generation sequencing, and Mendelian Randomization); (2) Applied deep learning to leverage large banks of imaging data in order to accomplish accurate high-throughput phenotyping of aortic aging. This will be achieved through formal training courses and engaging in sustained collaboration experiences with experts in these topics. The candidate will also engage in career development and promotion of arterial aging research through convening scientific meetings on aortic aging research and improving the national network of POR research in arterial aging through existing professional societies. The institutional environment for clinical and translational science at Penn is outstanding. The Department of Medicine at Penn has made a substantial commitment, including protected time and dedicated space, toward the candidate’s sustained success as a patient-oriented researcher responsible for training a new generation of junior investigators who conduct research in older participants. Project Narrative Dr. Chirinos proposes to augment his scientific skills and program building, continue to develop the local environment for mentoring new clinical investigators who perform patient-oriented research about arterial aging and HFpEF, and conduct studies that will impact our understanding of the genetic determinants of aortic stiffness.",Genetic determinants of thoracic aortic stiffness and remodeling,10106219,K24AG070459,"['Address', 'Adoption', 'Adult', 'Age', 'Aging', 'Aorta', 'Aortic Segment', 'Award', 'Biological', 'Caliber', 'Chest', 'Clinical', 'Clinical Investigator', 'Clinical Sciences', 'Collaborations', 'Data', 'Deposition', 'Development', 'Distal', 'Doctor of Philosophy', 'EFRAC', 'Echocardiography', 'Elastin', 'Enrollment', 'Environment', 'Epidemiology', 'Equation', 'Equipment', 'Exhibits', 'Faculty', 'Failure', 'Fibrosis', 'Generations', 'Genetic Determinism', 'Genetic study', 'Genomics', 'Goals', 'Health', 'Heart failure', 'Heritability', 'Human', 'Image', 'Individual', 'K-Series Research Career Programs', 'Leadership', 'Left', 'Length', 'Location', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medicine', 'Mendelian randomization', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Muscle', 'Participant', 'Pathologic Processes', 'Patients', 'Pennsylvania', 'Phenotype', 'Physicians', 'Physiologic pulse', 'Play', 'Population', 'Population Study', 'Prevention approach', 'Process', 'Productivity', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Respiratory Diaphragm', 'Rest', 'Role', 'Sample Size', 'Science', 'Scientist', 'Site', 'Surface', 'System', 'Thoracic aorta', 'Time', 'Training', 'Training Support', 'Translational Research', 'Ultrasonography', 'Universities', 'Ventricular', 'Work', 'age related', 'aging population', 'aortic valve', 'arterial tonometry', 'ascending aorta', 'base', 'biobank', 'burden of illness', 'calcification', 'career', 'career development', 'clinical imaging', 'clinical practice', 'deep learning', 'electric impedance', 'epidemiology study', 'exome', 'experience', 'genome wide association study', 'genomic data', 'hemodynamics', 'imaging study', 'improved', 'infancy', 'innovation', 'insight', 'interest', 'large datasets', 'medical schools', 'meetings', 'mid-career faculty', 'multidisciplinary', 'next generation', 'next generation sequencing', 'novel', 'patient oriented', 'patient oriented research', 'preservation', 'programs', 'prospective', 'research and development', 'research study', 'skills', 'success', 'time use']",NIA,UNIVERSITY OF PENNSYLVANIA,K24,2021,194955
"Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident Summary Following a large scale radiological or nuclear event, hundreds of thousands of people may be exposed to ionizing radiation/s and require subsequent dose-dependent medical management. It will be crucial to collect and analyze human biofluids (such as blood, urine, saliva) as soon as possible within the first week for accurate dose prediction and early triage decision. There is a need for FDA-approved in vitro diagnostic high-throughput biodosimetry devices with the ability to determine past radiation exposure with precision and accuracy. At the Center for High Throughput Radiation Biodosimetry, the Columbia University Center for Medical Countermeasures against Radiation (CMCR), we have developed FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system, to measure radiation-responsive proteins in human peripheral blood samples for retrospective estimation of radiation dose. The protein panel also includes biomarkers for blood leukocyte subtypes to reflect hematological sensitivity and injury. The FAST- DOSE assay system is intended as an in vitro diagnostic device (IVD) as defined by 21 CFR 809.3. The platform uses a commercial imaging flow cytometry system (ImageStream®X) and associated Image Data Exploration and Analysis Software (IDEAS®) to rapidly quantify changes in biomarker expression levels within specific cellular structures using fluorescent imagery and algorithms for estimation of absorbed dose. The studies planned here are designed to develop and optimize our FAST-DOSE assay system to accurately estimate absorbed dose and assess hematopoietic injury in human lymphocytes after ionizing irradiation. The first objective is to build on our current biomarker validation data for early engagement with the FDA via the pre-submission process. We have used the human ex vivo model and humanized mouse (Hu-NSG) and non- human primate (NHP) models to validate biomarker expression and radiosensitivity in blood leukocytes after acute ionizing radiation exposure. The Specific Aims proposed here are designed to: optimize the assay protocol and identify biomarker dose/time kinetics for accurate dose predictions in vitro and test 1) inter-donor variation, 2) intra-donor variation and 3) inter-laboratory variability (Aim 1); test the effect of specific confounders: age and sex, inheritance with germline BRCA1/2 pathogenic variant, and inflammation and trauma on the biomarker response, before and after irradiation (Aim 2); measure biomarker levels and time kinetics in vivo and correlate with hematopoietic injury, based on peripheral blood leukocyte counts, and stem and progenitor cell levels in the bone marrow of Hu-NSG mice (Aim 3) and, develop mathematical models (using machine learning and regression techniques) to select the best FAST-DOSE biomarkers and their combinations for generating dose predictions based on the ex vivo and in vivo dose response of these biomarkers (Aim 4). Our vision for future development is to develop a more simplified, faster rapid FAST-DOSE assay system whereby the biomarkers could be developed and transitioned for use in a point-of-care (POC) device. NARRATIVE We have developed a high-throughput biodosimetry device, the FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system to measure radiation-responsive proteins in human blood leukocytes for retrospective estimation of radiation dose. Studies are designed to validate and test the performance of the blood protein biomarker panel to accurately predict absorbed dose after ionizing radiation exposure. We will correlate biomarker expression levels and time kinetics with hematopoietic injury, based on peripheral blood leukocyte counts and bone marrow toxicity in humanized mice.","Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident",10089406,U01AI148309,"['Academic Medical Centers', 'Acute', 'Age', 'Algorithms', 'BRCA1 gene', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Proteins', 'Blood specimen', 'Bone Marrow', 'Burn injury', 'Cell Culture Techniques', 'Cellular Structures', 'Computer software', 'Confidence Intervals', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Dose', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Fluorescence', 'Future', 'Gold', 'Hematology', 'Hematopoietic', 'Human', 'Image', 'Imagery', 'Immune', 'Immunoassay', 'Individual', 'Industrial Accidents', 'Inflammation', 'Inherited', 'Injury', 'Ionizing radiation', 'Ions', 'Kinetics', 'Laboratories', 'Leukocytes', 'Linear Regressions', 'Lymphocyte', 'Machine Learning', 'Mass Screening', 'Measures', 'Medical', 'Medical center', 'Modeling', 'Mus', 'Noise', 'Nuclear Accidents', 'Pathogenicity', 'Patients', 'Performance', 'Physiological', 'Population', 'Process', 'Proteins', 'Protocols documentation', 'Radiation', 'Radiation Accidents', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation exposure', 'Reaction Time', 'Reproducibility', 'Research Design', 'Roentgen Rays', 'Saliva', 'Screening procedure', 'Seeds', 'Surface Antigens', 'System', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Trauma', 'Triage', 'Uncertainty', 'Urine', 'Variant', 'Vision', 'White Blood Cell Count procedure', 'base', 'biodosimetry', 'biomarker panel', 'biomarker performance', 'biomarker validation', 'blood damage', 'data exploration', 'design', 'dirty bomb', 'dosimetry', 'humanized mouse', 'in vitro testing', 'in vivo', 'in-vitro diagnostics', 'irradiation', 'machine learning algorithm', 'mathematical model', 'medical countermeasure', 'micronucleus', 'nonhuman primate', 'nonlinear regression', 'performance tests', 'peripheral blood', 'point of care', 'predicting response', 'predictive modeling', 'protein biomarkers', 'response', 'response biomarker', 'sex', 'stem', 'stem cells']",NIAID,COLUMBIA UNIVERSITY HEALTH SCIENCES,U01,2021,483863
"Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident Summary Following a large scale radiological or nuclear event, hundreds of thousands of people may be exposed to ionizing radiation/s and require subsequent dose-dependent medical management. It will be crucial to collect and analyze human biofluids (such as blood, urine, saliva) as soon as possible within the first week for accurate dose prediction and early triage decision. There is a need for FDA-approved in vitro diagnostic high-throughput biodosimetry devices with the ability to determine past radiation exposure with precision and accuracy. At the Center for High Throughput Radiation Biodosimetry, the Columbia University Center for Medical Countermeasures against Radiation (CMCR), we have developed FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system, to measure radiation-responsive proteins in human peripheral blood samples for retrospective estimation of radiation dose. The protein panel also includes biomarkers for blood leukocyte subtypes to reflect hematological sensitivity and injury. The FAST- DOSE assay system is intended as an in vitro diagnostic device (IVD) as defined by 21 CFR 809.3. The platform uses a commercial imaging flow cytometry system (ImageStream®X) and associated Image Data Exploration and Analysis Software (IDEAS®) to rapidly quantify changes in biomarker expression levels within specific cellular structures using fluorescent imagery and algorithms for estimation of absorbed dose. The studies planned here are designed to develop and optimize our FAST-DOSE assay system to accurately estimate absorbed dose and assess hematopoietic injury in human lymphocytes after ionizing irradiation. The first objective is to build on our current biomarker validation data for early engagement with the FDA via the pre-submission process. We have used the human ex vivo model and humanized mouse (Hu-NSG) and non- human primate (NHP) models to validate biomarker expression and radiosensitivity in blood leukocytes after acute ionizing radiation exposure. The Specific Aims proposed here are designed to: optimize the assay protocol and identify biomarker dose/time kinetics for accurate dose predictions in vitro and test 1) inter-donor variation, 2) intra-donor variation and 3) inter-laboratory variability (Aim 1); test the effect of specific confounders: age and sex, inheritance with germline BRCA1/2 pathogenic variant, and inflammation and trauma on the biomarker response, before and after irradiation (Aim 2); measure biomarker levels and time kinetics in vivo and correlate with hematopoietic injury, based on peripheral blood leukocyte counts, and stem and progenitor cell levels in the bone marrow of Hu-NSG mice (Aim 3) and, develop mathematical models (using machine learning and regression techniques) to select the best FAST-DOSE biomarkers and their combinations for generating dose predictions based on the ex vivo and in vivo dose response of these biomarkers (Aim 4). Our vision for future development is to develop a more simplified, faster rapid FAST-DOSE assay system whereby the biomarkers could be developed and transitioned for use in a point-of-care (POC) device. NARRATIVE We have developed a high-throughput biodosimetry device, the FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system to measure radiation-responsive proteins in human blood leukocytes for retrospective estimation of radiation dose. Studies are designed to validate and test the performance of the blood protein biomarker panel to accurately predict absorbed dose after ionizing radiation exposure. We will correlate biomarker expression levels and time kinetics with hematopoietic injury, based on peripheral blood leukocyte counts and bone marrow toxicity in humanized mice.","Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident",10336135,U01AI148309,"['Academic Medical Centers', 'Acute', 'Age', 'Algorithms', 'BRCA1 gene', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Proteins', 'Blood specimen', 'Bone Marrow', 'Burn injury', 'Cell Culture Techniques', 'Cellular Structures', 'Computer software', 'Confidence Intervals', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Dose', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Fluorescence', 'Future', 'Gold', 'Hematology', 'Hematopoietic', 'Human', 'Image', 'Imagery', 'Immune', 'Immunoassay', 'Individual', 'Industrial Accidents', 'Inflammation', 'Inherited', 'Injury', 'Ionizing radiation', 'Ions', 'Kinetics', 'Laboratories', 'Leukocytes', 'Linear Regressions', 'Lymphocyte', 'Machine Learning', 'Mass Screening', 'Measures', 'Medical', 'Medical center', 'Modeling', 'Mus', 'Noise', 'Nuclear Accidents', 'Pathogenicity', 'Patients', 'Performance', 'Physiological', 'Population', 'Process', 'Proteins', 'Protocols documentation', 'Radiation', 'Radiation Accidents', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation exposure', 'Reaction Time', 'Reproducibility', 'Research Design', 'Roentgen Rays', 'Saliva', 'Screening procedure', 'Seeds', 'Surface Antigens', 'System', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Trauma', 'Triage', 'Uncertainty', 'Urine', 'Variant', 'Vision', 'White Blood Cell Count procedure', 'base', 'biodosimetry', 'biomarker panel', 'biomarker performance', 'biomarker validation', 'blood damage', 'data exploration', 'design', 'dirty bomb', 'dosimetry', 'humanized mouse', 'in vitro testing', 'in vivo', 'in-vitro diagnostics', 'irradiation', 'machine learning algorithm', 'mathematical model', 'medical countermeasure', 'micronucleus', 'nonhuman primate', 'nonlinear regression', 'performance tests', 'peripheral blood', 'point of care', 'predicting response', 'predictive modeling', 'protein biomarkers', 'response', 'response biomarker', 'sex', 'stem', 'stem cells']",NIAID,COLUMBIA UNIVERSITY HEALTH SCIENCES,U01,2021,100000
"Web-based Automated Imaging Differentiation of Parkinsonism SUMMARY Across the globe, there has been a considerable growth in the number of people diagnosed with Parkinsonism. Estimates indicate that from 1990 to 2015 the number of Parkinsonism diagnoses doubled, with more than 6 million people currently carrying the diagnosis, and by year 2040, 12 and 14.2 million people will be diagnosed with Parkinsonism. Parkinson’s disease (PD), multiple system atrophy Parkinsonian variant (MSAp), and progressive supranuclear palsy (PSP) are neurodegenerative forms of Parkinsonism, which can be difficult to diagnose as they share similar motor and non-motor features, and they each have an increased chance of developing dementia. In the first five years of a PD diagnosis, about 58% of PD are misdiagnosed, and of these misdiagnoses about half have either MSA or PSP. Since PD, MSAp, and PSP require unique treatment plans and different medications, and clinical trials testing new medications require the correct diagnosis, there is an urgent need for both clinic ready and clinical-trial ready markers for differential diagnosis of PD, MSAp, and PSP. Over the past decade, we have developed diffusion imaging as an innovative biomarker for differentiating PD, MSAp, and PSP. In this proposal, we will leverage our extensive experience to create a web-based software tool that can process diffusion imaging data from anywhere in the world. We will disseminate and test the tool in the largest prospective cohort of participants with Parkinsonism (PD, MSAp, PSP), working closely with the Parkinson Study Group. The reason to test this in the Parkinson Study Group network, is because they are the community that evaluates Phase II and Phase III clinical trials in Parkinsonism. This web-based software tool will be capable of reading raw diffusion imaging data, performing quality assurance procedures, analyzing the data using a validated pipeline, and providing imaging metrics and diagnostic probability. We will test the performance of the wAID-P by enrolling 315 total subjects (105 PD, 105 MSAp, 105 PSP) across 21 sites in the Parkinson Study Group. Each site will perform imaging, clinical scales, diagnosis, and will upload the data to the web-based software tool. The clinical diagnosis will be blinded to the diagnostic algorithm and the imaging diagnosis will be compared to the movement disorders trained neurologist diagnosis. We will also enroll a portion of the cohort into a brain bank to ascertain pathological confirmation and to test the algorithm against cases with post-mortem diagnoses. The final outcome will be to disseminate a validated diagnostic algorithm to the Parkinson neurological and radiological community and to make it available to all on a website. NARRATIVE In this proposal, we will be developing, disseminating, and evaluating a web-based software tool that can perform MRI analyses for the diagnostic accuracy of Parkinsonism. Our goal is to leverage our years of experience and algorithm development, to test a prospective cohort of Parkinson’s disease, Multiple System Atrophy, and Progressive Supranuclear Palsy. We expect that at the end of the project, we will have validated a web-based software tool that can use MRIs from different vendors to read, analyze, and predict the diagnosis of different forms of Parkinsonism.",Web-based Automated Imaging Differentiation of Parkinsonism,10106864,U01NS119562,"['Algorithms', 'American', 'Area Under Curve', 'Autopsy', 'Biological Markers', 'Blinded', 'Brain', 'Clinic', 'Clinical', 'Clinical Trials', 'Communities', 'Data', 'Data Analyses', 'Data Collection', 'Dementia', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Enrollment', 'Goals', 'Growth', 'Health', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Modeling', 'Motor', 'Movement Disorders', 'Multiple System Atrophy', 'Nerve Degeneration', 'Neurologic', 'Neurologist', 'Online Systems', 'Outcome', 'Parkinson Disease', 'Parkinsonian Disorders', 'Participant', 'Pathologic', 'Pathology', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Probability', 'Procedures', 'Process', 'Progressive Supranuclear Palsy', 'Prospective cohort', 'Protocols documentation', 'Radiology Specialty', 'Reading', 'Research Personnel', 'Risk', 'Secure', 'Signal Transduction', 'Site', 'Software Tools', 'System', 'Techniques', 'Testing', 'TimeLine', 'Tissues', 'Training', 'Translating', 'Validation', 'Variant', 'Vendor', 'Water', 'accurate diagnosis', 'algorithm development', 'atypical parkinsonism', 'clinical Diagnosis', 'cohort', 'data exchange', 'diagnostic accuracy', 'diagnostic biomarker', 'disease diagnosis', 'dopamine transporter', 'experience', 'imaging biomarker', 'improved', 'indexing', 'individualized medicine', 'innovation', 'outcome forecast', 'performance tests', 'programs', 'quality assurance', 'support vector machine', 'tool', 'treatment planning', 'web site']",NINDS,UNIVERSITY OF FLORIDA,U01,2021,1553260
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,10187567,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2021,310796
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10228757,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2021,349146
"Detection and characterization of critical under-immunized hotspots Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots,10197938,R01GM109718,"['Affect', 'Bayesian Method', 'Behavioral Model', 'California', 'Characteristics', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Disease model', 'Economic Burden', 'Economics', 'Epidemic', 'Epidemiology', 'Exhibits', 'Funding', 'Geography', 'Growth', 'Health', 'Health Personnel', 'Herd Immunity', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Individual', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Measles-Mumps-Rubella Vaccine', 'Medical', 'Methodology', 'Methods', 'Minnesota', 'Modeling', 'New Jersey', 'New York', 'Oregon', 'Outcome', 'Pathway interactions', 'Policies', 'Policy Maker', 'Population', 'Population Analysis', 'Privatization', 'Public Health', 'Records', 'Registries', 'Resolution', 'Resource Allocation', 'Resources', 'Risk', 'Scanning', 'Schools', 'Science', 'Source', 'System', 'Systems Analysis', 'Techniques', 'Time', 'Uncertainty', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Washington', 'Work', 'base', 'data mining', 'demographics', 'diverse data', 'economic cost', 'economic outcome', 'health care delivery', 'health disparity', 'health organization', 'improved', 'interest', 'novel', 'novel strategies', 'population based', 'provider networks', 'public health intervention', 'social', 'social media', 'spatiotemporal', 'statistics', 'tool', 'transmission process', 'vaccine hesitancy']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,321062
"Development of assistive self-care robot technologies for people with disabilities Towards Autonomy in Daily Living: A Formalism for Intelligent Assistive Feeding Systems  Applicant PI, Tapomayukh Bhattacharjee Overview We propose to develop a design space framework and co-design methodology for the development of assistive self-care robot technologies that are informed by the social model of disability. Our model of assistive robots in the domain of self-care considers an individual's social and environmental context, coping processes and other factors that can affect independent functioning. Our design methods utilize embedded sensing to intelligently respond to these con- siderations. We speciﬁcally focus on assistive feeding tasks, proposing a formalism that enables a robotic system to feed a person with upper-extremity disability. Our guiding principle is that human-level interaction is feasible only if the robot itself relies on human-level semantics. We im- plement this principle by relying on data to learn and develop object-dependent control policies and timing models for acquiring and transferring a bite to a user at a proper time. The system's ob- server detects world states and arbitrator invokes different control policies based on these states. The tangible result will be an intelligent assistive feeding robot whose performance can generalize to different activities, adapt to user preferences, and recover from failures. Objectives and Relevance to NIH A design framework for assistive robots would provide for- malisms that let us address the fundamental challenge of designing robots that are responsive to context of use and support assisted self-care in a variety of social settings. We combine method- ologies from human-robot interaction, cognitive science, machine learning, robotics and haptics with user studies and our formalism to address the following research questions: (Q1) Mechanics of Feeding-Control Policies: How can control policies be designed for dexterous non-prehensile manipu- lation of deformable objects such as food? (Q2) Social Aspects of Feeding-Bite Timing: How should an assistive feeding robot decide the right timing for feeding a user? (Q3) Human-in-the-Loop: How can human-directed feedback be added into the loop for an autonomous assistive feeding system?  The proposed work will allow users with upper-arm disabilities to use this system for intelli- gent assistance with daily feeding tasks. This can in turn help them increase their independence and autonomy making eating easier and more enjoyable. While we presently focus on this spe- ciﬁc application, the tools and insights we gain can generalize to the ﬁelds of robotic assistance and human-robot interaction across other activities of daily living and instrumental activities of daily living. Thus, our work is clearly motivated by the intent to improve the quality of health and life of the aging population and is very relevant to the theme of NIH. 1 Towards Autonomy in Daily Living: A Formalism for Intelligent Assistive Feeding Systems  Applicant PI, Tapomayukh Bhattacharjee  The proposed work will allow users with upper-arm disabilities to use this system for intelli- gent assistance with daily feeding tasks, potentially increasing their independence and autonomy making eating easier and more enjoyable. The long-term promise of this research is to have robots in society that are able to seamlessly and ﬂuently perform complex manipulation tasks in dynamic human environments in real homes which could impact individuals with other disabilities as well as able-bodied individuals. Through improved access to independent living and customizing to the unique needs and preferences of users, the results of this project can positively impact mil- lions of people worldwide, especially given the vast variability in our target population by being transformational in the scalability of assistive robotics for self-care. 1",Development of assistive self-care robot technologies for people with disabilities,10232054,F32HD101192,"['Activities of Daily Living', 'Address', 'Affect', 'Aging', 'Bathing', 'Bite', 'Caregiver Burden', 'Caring', 'Child', 'Cognitive Science', 'Communities', 'Complex', 'Cues', 'Custom', 'Data', 'Development', 'Disabled Persons', 'Eating', 'Emotional', 'Environment', 'Expert Systems', 'Failure', 'Family', 'Feedback', 'Food', 'Generations', 'Health', 'Home environment', 'Human', 'Improve Access', 'Independent Living', 'Individual', 'Intelligence', 'Learning', 'Life', 'Machine Learning', 'Mechanics', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Panthera leo', 'Parents', 'Performance', 'Persons', 'Play', 'Policies', 'Population', 'Process', 'Quality of life', 'Research', 'Robot', 'Robotics', 'Role', 'Self Care', 'Semantics', 'Societies', 'Sterile coverings', 'System', 'Target Populations', 'Taxonomy', 'Technology', 'Time', 'Tweens', 'United States National Institutes of Health', 'Upper Extremity', 'Upper arm', 'Work', 'aging population', 'assistive robot', 'base', 'care recipients', 'coping', 'design', 'disability', 'experience', 'experimental study', 'feeding', 'haptics', 'human subject', 'human-in-the-loop', 'human-robot interaction', 'improved', 'insight', 'instrumental activity of daily living', 'intergenerational', 'kinematics', 'patient oriented', 'peer', 'preference', 'robot assistance', 'robotic system', 'social', 'social model', 'tool']",NICHD,UNIVERSITY OF WASHINGTON,F32,2021,68562
"Data-Driven Learning Framework for Fast Quantitative Knee Joint Mapping PROJECT SUMMARY Osteoarthritis (OA), a leading cause of chronic disability in the elderly population, occurs with the degradation of the extracellular matrix of articular cartilage, mainly composed of proteoglycan, collagen fibers, and water. Early diagnosis of cartilage degeneration requires the detection of changes in proteoglycan concentration and collagen integrity, preferably non-invasively and before any morphological changes occur. Spin-spin relaxation time (T2) and spin-lattice relaxation time in the rotating frame (T1ρ) can provide quantitative information about the structure and biochemical composition of the cartilage before morphological changes occur. Mono-exponential (ME) models can characterize the T2 and T1ρ relaxation processes and map it for articular cartilage in the knee joint. A recent meta-analysis showed that T1ρ provides more discrimination than T2 for OA. However, the ME model alone cannot provide distinct information from different compartments of the cartilage. Recent studies have shown that T1ρ relaxation might have bi-exponential (BE) components, following the hypothesis of the multi- compartmental structure of the cartilage. BE T2 relaxation has shown better diagnostic performance than ME for OA and can show the dispersion of the relaxation times, reflecting the heterogeneity in the macromolecular environment of water in the cartilage. BE analysis of cartilage typically requires a larger number of acquisitions with different spin-lock times (TSLs) or echo times (TEs), resulting in long scan time. High spatial resolution is also needed to visualize the thin and curved cartilage and fine structures in the knee joint. As a result, in vivo application of BE three-dimensional (3D) T1ρ and T2 mapping techniques is still very limited. Compressed sensing (CS) combined with parallel imaging (PI) can accelerate acquisition and reduce the scan time required for ME 3D T1ρ and T2 mappings. T1ρ scans can be reduced from 30 min to ~3 min with an error smaller than 6.5%. However, the error is two to three times larger for BE mapping. This problem can be potentially solved by optimizing the sampling times (TSLs for T1ρ and TEs for T2) and the free parameters of the CS approach (k- space sampling pattern, regularization function, regularization parameter, and minimization algorithm parameters) using fully sampled 3D knee joint datasets, supported by machine learning tools. The overarching goal of this proposal is to develop, optimize, and translate a high-spatial-resolution, rapid 3D magnetic resonance imaging sequence using data-driven learning-based CS for assessment of the human knee joint and using ME and BE 3D T1ρ (T2) mapping for improved biochemical characterization of cartilage and menisci on a standard clinical 3T scanner. PROJECT NARRATIVE Osteoarthritis of the knee is a leading cause of disability in elderly people, and no curative treatments exist. Early detection of osteoarthritis might help delay or prevent the onset of disability later in life. We propose a rapid and robust approach for the quantitative multi-compartment assessment of knee cartilage without using either exogenous contrast agent or hardware modifications as an early screening tool for osteoarthritis.",Data-Driven Learning Framework for Fast Quantitative Knee Joint Mapping,10296235,R01AR078308,"['3-Dimensional', 'Acceleration', 'Affect', 'Algorithms', 'Biochemical', 'Biological Models', 'Cartilage', 'Chronic', 'Clinical', 'Clinical Protocols', 'Collagen', 'Collagen Fiber', 'Contrast Media', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Diagnostic', 'Discrimination', 'Early Diagnosis', 'Elderly', 'Evaluation', 'Extracellular Matrix', 'Extracellular Matrix Degradation', 'Future', 'Goals', 'Heterogeneity', 'Human', 'Hydration status', 'Image', 'Imaging Techniques', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Meniscus structure of joint', 'Meta-Analysis', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Musculoskeletal', 'Pathologic Processes', 'Patients', 'Pattern', 'Performance', 'Population', 'Process', 'Proteoglycan', 'Protocols documentation', 'Relaxation', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Screening procedure', 'Slice', 'Structure', 'T2 weighted imaging', 'Techniques', 'Therapeutic Agents', 'Thick', 'Thinness', 'Time', 'Tissue Engineering', 'Tissues', 'Translating', 'Validation', 'Water', 'articular cartilage', 'base', 'cartilage degradation', 'curative treatments', 'design', 'disability', 'early screening', 'efficacy evaluation', 'healing', 'human data', 'improved', 'in vivo', 'learning algorithm', 'macromolecule', 'prevent', 'reconstruction', 'repaired', 'tool', 'water environment']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,531779
"TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS ABSTRACT There is a growing interest in dietary patterns that capture the overall quality of diet as well as its constituent foods and nutrients. Commonly used dietary patterns are a priori diet score/index based on a set of dietary recommendations for a healthy diet (e.g., Mediterranean diet, Healthy Eating Index) or data-driven dietary patterns (e.g., prudent diet, western diet). Numerous studies have shown that those dietary patterns were related to the risk of chronic diseases such as heart disease, diabetes, and cancer. However, none of these dietary patterns incorporates eating behavior such as when we eat (i.e., eating time) and how often we eat (i.e. eating frequency) during a day. Since the amount of foods and nutrients consumed at one eating occasion influences the food consumption at the subsequent eating occasion and overall intake of the day, eating time and frequency are integral parts of dietary patterns. Furthermore, several lines of evidence consistently suggest that eating time and frequency as well as a meal composition play roles in body weight regulation and metabolic health and also regulate circadian rhythms, all of which may lead to metabolic dysfunctions and ultimately chronic diseases. Given a clear need to expand the dietary patterns framework and close a gap in dietary patterns methodological work, we propose to 1) develop a “temporal” dietary patterns based on temporal distribution of eating time and frequency during a day; and 2) evaluate if the identified temporal dietary patterns are associated with i) overall diet quality and nutrient intakes, ii) adiposity (e.g., BMI, waist circumference), and iii) metabolic biomarkers (e.g., insulin, HOMA-IR, LDL-cholesterol, c-reactive protein). To overcome a limitation that a conventional statistical method cannot capture multidimensional aspects of temporal dietary patterns (e.g., 24-dimensional feature vectors, multivariate dietary intake time-series data), we will use a novel approach combining nutrition and systems science—machine learning method. The Interactive Diet and Activity Tracking in AARP (IDATA) study that repeatedly collected diet, anthropometry, and blood samples from 1,021 men and women, 50-74 years old will be used. During one year, the IDATA study collected 24-hour recalls with clock time for each eating occasion, every other month (total six 24-hour recalls); measured anthropometry three times (baseline and at month 6 and 12); and collected blood twice, 6-month apart. Successful completion of our proposed study will identify temporal dietary patterns that are related to diet quality and metabolic health and validate the utility of temporal dietary patterns as a new tool for future research on diet-health relations and prevention of chronic diseases. NARRATIVE Eating behaviors and its impact on health are complex and multidimensional. The proposed study provides an excellent opportunity to develop new dietary patterns that capture eating behaviors such as when we eat and how often we eat during a day. The findings of the study about healthy eating patterns will also improve dietary recommendations by adding messages on when and how often to eat during a day.",TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS,10053329,R01CA226937,"['Advisory Committees', 'Affect', 'Algorithms', 'Animals', 'Anthropometry', 'Biological Markers', 'Blood', 'Blood specimen', 'Body Weight', 'Body mass index', 'C-reactive protein', 'Calories', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Circadian Rhythms', 'Complex', 'Consumption', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Diet Habits', 'Dietary Practices', 'Dietary intake', 'Dimensions', 'Eating', 'Eating Behavior', 'Energy Intake', 'Evaluation', 'Fasting', 'Fatty acid glycerol esters', 'Food', 'Frequencies', 'Health', 'Healthy Eating', 'Heart Diseases', 'Hour', 'Human', 'Individual', 'Insulin', 'Intake', 'LDL Cholesterol Lipoproteins', 'Lead', 'Macronutrients Nutrition', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediterranean Diet', 'Metabolic', 'Metabolic dysfunction', 'Metabolic syndrome', 'Methodology', 'Modeling', 'Nutrient', 'Obesity', 'Outcome', 'Pattern', 'Persons', 'Physical activity', 'Play', 'Population', 'Positioning Attribute', 'Prevention', 'Recommendation', 'Regulation', 'Risk', 'Role', 'Science', 'Series', 'Statistical Methods', 'System', 'Techniques', 'Time', 'Waist-Hip Ratio', 'Weight maintenance regimen', 'Woman', 'Work', 'base', 'cardiovascular disorder risk', 'dietary', 'dietary guidelines', 'doubly-labeled water', 'epidemiology study', 'food consumption', 'good diet', 'improved', 'indexing', 'interest', 'machine learning method', 'men', 'novel', 'novel strategies', 'nutrient metabolism', 'nutrition', 'obesity risk', 'prudent diet', 'tool', 'vector', 'waist circumference', 'western diet']",NCI,WASHINGTON UNIVERSITY,R01,2021,224806
"Automatic Quantification and Labeling of Cerebral Microbleeds, Oxygen Saturation and Sources of Abnormal Susceptibility ABSTRACT The detection, localization and quantification of cerebral microbleeds (CMBs) plays an important role in diagnosing and establishing appropriate treatment plans in neurodegenerative diseases specifically in vascular dementia (VaD). To date, evaluating CMBs is time consuming, inaccurate and sometimes not possible. We propose to mitigate these problems by developing our software, “qSPIN”, that will provide fast and easy-to-use methods for: 1) automatic identification of CMBs and veins, 2) automatic quantification of CMBs, 3) automatic quantification of oxygen saturation in veins, and 4) creation of a user-friendly software for the practicing radiologist. Recent developments in MRI have provided a new means by which to study the role of CMBs and venous abnormalities in neurological diseases such as Alzheimer’s Disease (AD), VaD, stroke and traumatic brain injury (TBI). Susceptibility weighted imaging (SWI) has proven to be a powerful tool by which to detect CMBs and quantitative susceptibility mapping (QSM) can be used to measure changes in oxygen saturation. Knowing how many CMBs there are can predict the onset of VaD, determine whether anti-platelet therapy in stroke should be used, and correlate with neuropsychological outcome for patients with TBI. Our recent version of multi-echo SWI makes it possible to obtain both an arteriogram and a venogram simultaneously. Oxygen saturation can also be used to monitor perfusion changes and extend the window of treatment in stroke.  Currently, most radiologists and technologists do not have time to perform such detailed quantitative processing and thus it is not being done clinically. Our qSPIN software will provide this quantitative data. With the number, size, and location of CMBs or venous abnormalities, a better diagnosis would be possible. Our group is uniquely positioned to address this problem having developed many of these techniques. The novelty of our approach is the marriage of SWI, QSM, STAGE and deep learning techniques to detect these vascular and functional abnormalities. To accomplish the goals of this proposal, we will develop user friendly software that incorporates all imaging information from SWI and QSM to label CMBs. We will also provide the location of the CMBs in Talairach coordinates using a template dataset. In the end, we will have a complete picture of the prevalence of CMBs, abnormal oxygen saturation and their locations in patients with neurodegenerative disease that will improve diagnosis and potentially change their treatment. PROJECT NARRATIVE There is a huge demand today for a comprehensive analysis of diseases with cerebral microbleeds, abnormal oxygen saturation and thrombosis such as vascular dementia. The quantification of these features will have major ramifications for the diagnosis and treatment of dementia as well hypertension, stroke and traumatic brain injury all of which can lead to dementia. Therefore, our major objective in this application is to design and develop advanced image processing software that can rapidly and accurately identify and quantify the presence of cerebral microbleeds and changes in oxygen saturation in dementia and related diseases.","Automatic Quantification and Labeling of Cerebral Microbleeds, Oxygen Saturation and Sources of Abnormal Susceptibility",10101667,R44HL145826,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Arteriogram', 'Arteriosclerosis', 'Basal Ganglia', 'Blood Vessels', 'Brain', 'Brain hemorrhage', 'Businesses', 'Cerebral Amyloid Angiopathy', 'Cerebral hemisphere hemorrhage', 'Clinical', 'Computer software', 'Consumption', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Diagnosis', 'Diffuse Axonal Injury', 'Disease', 'Feedback', 'Goals', 'Hemorrhage', 'Hypertension', 'Image', 'Image Analysis', 'Impaired cognition', 'Infarction', 'Iron', 'Label', 'Lead', 'Link', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Marriage', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Multiple Sclerosis', 'Neurodegenerative Disorders', 'Neuropsychology', 'Outcome', 'Oxygen', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Play', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Protocols documentation', 'Protons', 'Published Comment', 'Reporting', 'Role', 'Sampling', 'Site', 'Source', 'Spatial Distribution', 'Stroke', 'TBI Patients', 'Techniques', 'Testing', 'Thalamic structure', 'Thrombosis', 'Time', 'Training', 'Traumatic Brain Injury', 'Vascular Dementia', 'Veins', 'Venous', 'base', 'cerebral microbleeds', 'cerebral vein', 'computerized data processing', 'contrast imaging', 'deep learning', 'density', 'design', 'image processing', 'improved', 'innovation', 'mild traumatic brain injury', 'nervous system disorder', 'neurovascular', 'prototype', 'quantitative imaging', 'radiologist', 'stroke risk', 'tool', 'treatment planning', 'user friendly software']",NHLBI,"MAGNETIC RESONANCE INNOVATIONS, INC.",R44,2021,667050
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,10112310,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'PhenX Toolkit', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2021,693835
"Evaluation of multiple medication exposures concurrently using a novel algorithm PROJECT SUMMARY The development of large observational health databases (OHD) has expanded the data available for analysis by pharmacoepidemiology research. The efficiency of these studies may be improved by simultaneously studying the association of multiple medications with a disease of interest. Unfortunately, prior research has demonstrated that it is difficult to distinguish true-positive from false-positive results when studying multiple exposures simultaneously, thus limiting the conclusions drawn from these types of studies and representing a major gap in the field. The objective of this proposal, which is the first step in achieving the applicant's long- term goal of improving the diagnosis and treatment of gastrointestinal diseases using insights derived from OHD, is to evaluate and validate medication class enrichment analysis (MCEA), a novel set-based signal-to- noise enrichment algorithm developed by the applicant to analyze multiple exposures from OHD with high sensitivity and specificity. The central hypothesis of this proposal is that MCEA has equal sensitivity and greater specificity compared to logistic regression, the most widely used analytic method for OHD, for identifying true associations between medications and clinical outcomes. The applicant will complete the following two interrelated specific aims to test the hypothesis: Aim 1 – to calculate the sensitivity and specificity of medication class enrichment analysis (MCEA) and logistic regression (LR) for identifying medication associations with Clostridium difficile infection (CDI) and Aim 2 – to calculate the sensitivity and specificity of MCEA and LR for identifying medication associations with gastrointestinal hemorrhage (GIH). The rationale for these aims is that by reproducing known medication-disease associations without false positives, MCEA can be used to identify novel pharmacologic associations with gastrointestinal diseases in future studies. The expected outcome for the proposed research is that it will demonstrate MCEA as a valid method for pharmacoepidemiology research, opening new research opportunities for the study of multi-exposure OHD. These new research opportunities may lead to more rapid identification of potential pharmacologic causes of emerging diseases and discovery of unanticipated beneficial medication effects, allowing such medications to be repurposed for new indications. To attain the expected outcome, the applicant will complete additional coursework that builds on his Master of Science in Clinical Epidemiology to learn computational biology, machine learning, and econometrics techniques. With the support of this grant and his institution, he will also directly apply these techniques to pharmacoepidemiology applications under the close mentorship of a carefully selected team of faculty with extensive experience in gastroenterology, pharmacoepidemiology, medical informatics, and mentoring prior K-award grant recipients. Through these activities, the applicant will develop the skills necessary to obtain NIH R01-level funding and become a leader in developing novel techniques for application to the epidemiologic study of gastrointestinal diseases. PROJECT NARRATIVE Traditionally, research studying medications associated with diseases are limited to analyzing one medication at a time. This novel proposal will validate medication class enrichment analysis, a recently developed algorithm to study multiple medications simultaneously for association with a disease of interest. Validation of this method will allow researchers to use existing medical databases to more rapidly identify potential medication causes of emerging diseases and identify medications with unanticipated beneficial effects, allowing such medications to be repurposed for new indications.",Evaluation of multiple medication exposures concurrently using a novel algorithm,10128442,K08DK119475,"['Address', 'Algorithms', 'Aminoglycosides', 'Antibiotics', 'Anticoagulants', 'Antiplatelet Drugs', 'Big Data to Knowledge', 'Biological', 'Carbapenems', 'Case-Control Studies', 'Cephalosporins', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Computational Biology', 'Computer software', 'Data', 'Databases', 'Development', 'Development Plans', 'Diagnosis', 'Digestive System Disorders', 'Disease', 'Electronic Health Record', 'Epidemiologic Methods', 'Evaluation', 'Faculty', 'Fluoroquinolones', 'Funding', 'Future', 'Gastroenterology', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Generations', 'Genomics', 'Goals', 'Grant', 'Health', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'K-Series Research Career Programs', 'Lead', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Master of Science', 'Medical', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Noise', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Penicillins', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Research', 'Research Design', 'Research Personnel', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Techniques', 'Testing', 'Time', 'United Kingdom', 'United States Department of Veterans Affairs', 'United States National Institutes of Health', 'Validation', 'analytical method', 'base', 'beta-Lactams', 'career development', 'clinical epidemiology', 'econometrics', 'epidemiology study', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'interest', 'novel', 'research study', 'simulation', 'skills', 'usability']",NIDDK,UNIVERSITY OF PENNSYLVANIA,K08,2021,167900
"A knowledge graph framework for automated gating analysis of cytometry data Project Summary / Abstract Flow and mass cytometry provide multiparametric single-cell data critical for understanding the cellular heterogeneity in various biological systems. Modern polychromatic flow cytometers simultaneously measure about 16 parameters routinely. The next-generation mass cytometry (CyTOF) technology allows for the simultaneous measurement of 50 or more parameters. Even as the cytometry technology is rapidly advancing, approaches for analyzing such complex data remain inadequate. The widely-used manual gating analysis is knowledge-driven and easy-to- interpret, but it is subjective, labor-intensive, and not scalable to handle the increasing complexity of the data. Recent developments of automated data-driven algorithms are able to address the issues of manual gating, but the results from data-driven algorithms are often not intuitive for biology experts to interpret. These limitations create a critical bottleneck for flow and mass cytometry analysis. The overall objective of this application is to develop a novel framework that combines both knowledge-driven and data-driven approaches to achieve automated gating analysis of flow cytometry and CyTOF data. The specific aims are: (1) build knowledge graphs to capture existing knowledge of manual gating analysis, (2) develop algorithms for automated gating analysis, and (3) validate the knowledge graph framework using large-scale studies in ImmPort. The proposed research is significant because it will enable efficient and reproducible gating analysis and provide visualizations that are easy-to-interpret, both of which are critically important to the research community. Such contributions will fundamentally impact single-cell analysis of cellular heterogeneity in diverse fields including immunology, infectious diseases, cancer, AIDS, among others. Project Narrative The proposed research is relevant to public health because it is expected to develop novel computational methods for automated analysis and interpretation of single-cell analysis by flow and mass cytometry. Such contributions will impact single-cell analysis of cellular heterogeneity in diverse fields such as immunology, infectious diseases, cancer, AIDS, among others.",A knowledge graph framework for automated gating analysis of cytometry data,10172842,UH2AI153028,"['Acquired Immunodeficiency Syndrome', 'Address', 'Adopted', 'Adoption', 'Algorithm Design', 'Algorithmic Analysis', 'Algorithms', 'Biological', 'Biological Sciences', 'Biology', 'Cells', 'Clinical', 'Clinical Research', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Set', 'Database and Analysis Portal', 'Development', 'Dimensions', 'Flow Cytometry', 'Graph', 'Heterogeneity', 'Human', 'Immune system', 'Immunology', 'Individual', 'Intuition', 'Knowledge', 'Literature', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Modeling', 'Modernization', 'Mus', 'Online Systems', 'Outcome', 'Public Health', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Technology', 'Thinking', 'Visualization', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'cell type', 'complex data', 'data and analysis portal', 'data resource', 'deep learning', 'design', 'diverse data', 'graphical user interface', 'high dimensionality', 'informatics tool', 'knowledge graph', 'multidimensional data', 'next generation', 'novel', 'protein biomarkers', 'single cell analysis', 'stem', 'user-friendly', 'web based interface']",NIAID,GEORGIA INSTITUTE OF TECHNOLOGY,UH2,2021,237082
"CHABMAP (Cyanobacterial Harmful Algal Bloom Mapping and Analyses Platform) technology automates the quantification of toxic CyanoHABs exposure epochs for any waterbody. Specific Aim #1: Operationalize spatio-temporal CyanoHAB exposure epoch metrics  • Fuse multi-scale and disparate satellite remote sensing platforms and automate retrievals over  space and time to derive CyanoHAB exposure metrics. We will build enterprise software to fully  automate the harmonization and fusion of NASA’s Landsat-8 OLI and ESA’s Sentinel-2 and  Sentinel-3 satellite platforms to provide long-term (1984-present) moderate spatial resolution  (30meter pixels) and high temporal frequency CyanoHAB exposure metrics (Cyanobacteria  Intensity, Color Dissolved Organic Matter, Total Suspended Solids, Floating Algae Index,  Chlorophyll-a Concentration, & toxins). The decision support tool automates epoch synthesis to  understand incubation periods and exposure triggers for neurodegenerative diseases. Specific Aim #2: Scale on-demand CHABMAP commercial product services  • Scale and implement CHABMAP data services for infinite scalability using BigData cloud  technologies. This Aim involves three main development efforts: adapting our proprietary  Geospatial Image and Processing System (GIPS) capabilities to an AWS-deployable auto-scaling  cluster, creation of user interfaces and application programming interfaces (APIs) to interact with  these services, and enhancements to the base GIPS framework to facilitate intercommunication  between remote GIPS-enabled archives and the cloud processing streams. This includes the  creation of deployable compute instances, optimization of computation and parallelization  specific to AWS deployment, optimization of temporary and long-term storage of intermediate  products, and optimization of communication and data transfer with end users. Ultimately, this  Aim will allow for the assessment and monitoring of CyanoHAB conditions for any waterbody or  region (i.e., North America) on the planet. Specific Aim #3: Execute risk assessment frameworks with public health partners  • We will work in partnership with Cleveland Clinic, Dartmouth Hitchcock Medical Center,  University of Miami, Macquarie University, NIH’s Neuromuscular Diseases Research Section and  CDC’s Agency for Toxic Substances and Disease Registry (National ALS Registry) to assess the role  of CyanoHABs exposure as a risk factor for Amyotrophic lateral sclerosis (ALS) using patients,  clinic-, and population-based controls across diverse settings and geographies. Each application  end user has ongoing risk assessment frameworks (i.e., Gene-Environment, Residential History  Machine Learning, eco-epidemiological, molecular biology) which our CHABMAP technology will  integrate exposure epoch metrics to understand the etiology or ALS and support drug discovery. Proposed Innovation CHABMAP technology automates the quantification of toxic Cyanobacterial Harmful Algal Bloom (CHAB) exposure epochs for any waterbody or catchment in the world for the past four decades using multi-scale harmonized satellites. We use custom and proprietary techniques combined with BigData software to generate historical exposure (“exposome”) profiles as well provide Decision Support Tools services for CHAB monitoring in near-real time. During Phase 2 and beyond we work with world experts to integrate our commercial products and services into neurodegenerative disease Gene-Environment (GxE) risk assessment frameworks. Proposed Products, Services, Outcomes  • Develop historical CHAB exposure measurements working with environmental agency partners  • Assessment of CyanoHABs as a risk factor for ALS across multiple, independent study regions  • CHABMAP on-demand Analytics-as-a-Service platform operating at end of Phase 2  • Support discovery of etiology and drug development for neurological disorders and diseases Project Narrative Design, build, and operate a cloud-based Cyanobacterial Harmful Algal Bloom Mapping and Analysis Platform (CHAB-MAP) for developing public health applications’ in partnership with NASA, EPA, and medical centers. Assess as risk factor for ALS. Help address cyanobacteria and toxicity public help threats.",CHABMAP (Cyanobacterial Harmful Algal Bloom Mapping and Analyses Platform) technology automates the quantification of toxic CyanoHABs exposure epochs for any waterbody.,10176488,R44ES025513,"['Address', 'Algae', 'Amyotrophic Lateral Sclerosis', 'Archives', 'Big Data', 'Centers for Disease Control and Prevention (U.S.)', 'Chlorophyll', 'Clinic', 'Color', 'Communication', 'Computer software', 'Custom', 'Cyanobacterium', 'Data', 'Development', 'Environment', 'Epidemiology', 'Etiology', 'Frequencies', 'Genes', 'Geography', 'Machine Learning', 'Measurement', 'Medical center', 'Molecular Biology', 'Monitor', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuromuscular Diseases', 'North America', 'Outcome', 'Patients', 'Phase', 'Planets', 'Poison', 'Public Health', 'Public Health Applications Research', 'Recording of previous events', 'Registries', 'Research', 'Resolution', 'Retrieval', 'Risk Assessment', 'Risk Factors', 'Role', 'Sentinel', 'Services', 'Solid', 'Stream', 'System', 'Techniques', 'Technology', 'Time', 'Toxic effect', 'Toxin', 'United States National Aeronautics and Space Administration', 'United States National Institutes of Health', 'Universities', 'Work', 'application programming interface', 'base', 'cloud based', 'data exchange', 'design', 'disease registry', 'drug development', 'drug discovery', 'harmful algal blooms', 'image processing', 'indexing', 'innovation', 'nervous system disorder', 'parallelization', 'population based', 'remote sensing', 'spatiotemporal', 'support tools']",NIEHS,"APPLIED GEOSOLUTIONS, LLC",R44,2021,486219
"Acoustofluidic Separation of Placental Nanovesicle Subpopulations in Obstetrical Diseases The placenta is essential for fetal development and growth, maternal homeostasis, and broadly, pregnancy health. Yet, our ability to non-invasively probe placental health during human pregnancy is hampered by its deep intrauterine location and its highly vascular composition, rendering the placenta largely inaccessibly for safe and dynamic investigation. Whereas placental research has been advanced by cell culture, ex vivo systems, animal models, and postpartum analyses, these indirect approaches provide ex post facto information about placental health. Placental imaging has revolutionized the field of placental medicine, but resolution at the molecular, cellular, or metabolic level remains limited. To address these challenges, we and others have focused on the release of extracellular vesicles (EVs) from placental trophoblasts, which, in humans, are directly bathed in maternal blood. We focused on exosomes (now termed small EVs or sEVs), microvesicles, and apoptotic blebs, which are continuously and abundantly released from trophoblasts into the maternal circulation and are accessible throughout pregnancy by peripheral blood tests. Among these EVs, we focus mainly on placental sEVs, which harbor messages that are seldom expressed by any other cell types and execute unique placental biological functions, such as an antiviral response. While informative, recent data indicate that sEVs are not a uniform population of vesicles, but comprise several subgroups, defined as large sEVs, small sEVs, and exomeres. In addition to their size, these sEV subtypes are characterized by distinctive cargo. Although the recent discovery of sEV subpopulations has excited researchers due to their potential to revolutionize the field of non-invasive diagnostics, sEV subpopulations have yet to be utilized in clinical settings. This is largely due to the difficulties associated with separation and isolation the nano-sized sEV subpopulations. Our group has now developed advanced acoustofluidic technologies designed to effectively, reproducibly, and rapidly isolate sEVs from blood. We show that we can separate placental sEVs into their specific subpopulations, which has not been previously accomplished. Our proposed investigation therefore focuses on the production of human placental sEV subpopulations, along with their RNA and proteome cargo. We posit that, by profiling these analytes from sEV subpopulations, we can illuminate a unique landscape of bioactive molecules that are relevant to placental health. To reduce data complexity, we propose a machine learning pipeline that will be used to probe the sub-sEV spectra during normal and pathological pregnancies. Further, we will improve our ability to purify sEV subpopulations from lipoproteins, and generate a single, integrated device that can reliably separate vesicles in real time across human gestation. We believe that our automated acoustofluidic approach to separating sEV subpopulations in a high-yield, biocompatible manner is critical to unlocking the clinical utility of sEVs. Insights gained from our investigation will improve non-invasive diagnostics during pregnancy and may uncover new targets for personalized placental therapeutics. Our proposal centers on the discovery and analysis of previously unrecognized nanovesicle subpopulations that are produced by placental cells and are released to the maternal-fetal circulation. By studying these nanovesicle subpopulations in health and diseases of human pregnancy and by innovating new technologies to efficiently, rapidly, and reproducibly purify these nanovesicles from the blood and other biological media, we enable pioneering tools to interrogate the placenta in real time and improve clinical care during pregnancy.",Acoustofluidic Separation of Placental Nanovesicle Subpopulations in Obstetrical Diseases,10099051,R01HD103727,"['Address', 'Animal Model', 'Antiviral Response', 'Apoptotic', 'Biological', 'Biological Process', 'Biology', 'Blood', 'Blood Circulation', 'Blood Tests', 'Blood Vessels', 'Bulla', 'Cell Culture Techniques', 'Cells', 'Clinical', 'Communication', 'Culture Media', 'Data', 'Devices', 'Diagnostic', 'Dimensions', 'Discipline of obstetrics', 'Disease', 'Fetal Development', 'Fetal Growth Retardation', 'Field Flow Fractionation', 'Functional disorder', 'Funding', 'Genomics', 'Glean', 'Grant', 'Growth Factor', 'Growth and Development function', 'Health', 'Health Status', 'Homeostasis', 'Hormones', 'Human', 'Image', 'Inherited', 'Injury', 'Investigation', 'Lipoproteins', 'Location', 'MLLT2 gene', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuscripts', 'Maternal-Fetal Exchange', 'Medicine', 'Metabolic', 'MicroRNAs', 'Modification', 'Molecular', 'National Institute of Child Health and Human Development', 'Nature', 'Pathologic', 'Pathway interactions', 'Physiological', 'Placenta', 'Placenta Diseases', 'Placental Biology', 'Plasma', 'Population', 'Positioning Attribute', 'Postpartum Period', 'Pre-Eclampsia', 'Pregnancy', 'Production', 'Proteins', 'Proteome', 'Proteomics', 'RNA', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Subgroup', 'Surface', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Ultrasonography', 'Uterus', 'Vesicle', 'Woman', 'bioinformatics tool', 'biomaterial compatibility', 'cell type', 'clinical care', 'clinically relevant', 'design', 'differential expression', 'epigenomics', 'exosome', 'extracellular vesicles', 'fetal', 'first responder', 'human disease', 'improved', 'in vivo', 'innovation', 'insight', 'liquid biopsy', 'microvesicles', 'molecular diagnostics', 'nanosized', 'nanovesicle', 'new technology', 'noninvasive diagnosis', 'novel', 'peripheral blood', 'response', 'tool', 'trait', 'transcriptome', 'transcriptomics', 'trophoblast', 'vesicular release']",NICHD,MAGEE-WOMEN'S RES INST AND FOUNDATION,R01,2021,542123
"Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS) Project Abstract  Per- and polyfluoroalkyl substances (PFAS) are a family of over 5000 man-made chemicals that are ubiquitous in the environment, due to their chemical stability and bioaccumulative properties. Many of these “forever chemicals” have been linked with health concerns, including strong evidence of developmental health and harm to hormone-sensitive tissues. Manufacturers continue to substitute new PFAS for which exposure- based health risks are unknown. There is an urgent public health need to determine the effects of PFAS in use on both mammary gland development and increased breast cancer incidence. Current exposure studies use rodent models that require cumbersome end-point analyses as well as large monetary and time investments.  Our proposal is aimed at developing an in vitro to in vivo extrapolation (IVIVE) pipeline of mammary gland development and maintenance to identify and prioritize potentially toxic PFAS, to ultimately mitigate number of animals needed for environmental exposure studies. Our approach is to develop in vitro models of the mammary gland of increasing complexity but decreasing throughput, identifying links between high-throughput and high- complexity model endpoint readouts to best prioritize large chemical libraries. A key technology to establish links across multiple in vitro culture platforms is optical coherence tomography-based structural-functional imaging (OCT-SFI), developed by MPI Oldenburg, which non-invasively visualizes label-free cells, their intracellular motility, and morphology of formed spheroids, within optically turbid tissue models.  Our first specific aim advances a high-throughput paper-based culture system, developed by MPI Lockett, to study mammary epithelial cell invasion in physiologically relevant tissue microenvironments. The platform will evaluate 96 different exposure conditions in parallel. Our second specific aim employs 3D co-culture models that include fibroblasts to model stromal signaling known to affect mammary gland development. OCT-SFI will provide cellular motility and morphology of the organotypic spheroids that form in these cultures. Finally, our third aim will screen a library of 40 PFAS, with a particular focus on the perfluoroethercarboxylic acids (PFECAs) currently used in industrial coatings. In addition, 12 PFAS will be screened for which there is existing in vivo rodent model data available, and comparisons between in vitro assay outputs and in vivo gland remodeling will be used to refine the assay models and establish initial thresholds for screening.  The models developed as part of this proposal will thus be predictive of biology, enabling the high-throughput capability needed for future screening of all PFAS as well as other emerging endocrine disruptors. The project’s risk is balanced by the known imaging capabilities of OCT-SFI to probe responses in 3D spheroid and paper- based co-cultures. The high-throughput nature of this IVIVE pipeline makes it ideal for screening libraries of potential toxicants, providing information-rich datasets of spatially and temporally resolved morphological and molecular changes across the tissue-like structures. Project Narrative This proposal aims to develop a pipeline to screen and prioritize libraries of potentially toxic man-made chemicals found in the environment for further analyses, with particular emphasis on per- and poly-fluoroalkyl substances (PFAS) of which there are over 5000 currently known. Current environmental exposure testing methods evaluate mammary gland development in live mice because the mammary gland is highly susceptible to chemical exposure; yet, such methods are slow and expensive. Our proposal uses mammary cell culture models in increasingly complex, tissue-like environments, in combination with high-speed 3D optical imaging techniques, and ultimately compare the platform with a few candidate PFAS against existing data in live mice, setting the stage for future high-throughput screening of potential environmental toxicants.",Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS),10271405,R01ES032730,"['3-Dimensional', 'Acids', 'Affect', 'Animals', 'Architecture', 'Biological Assay', 'Biology', 'Biometry', 'Breast Cancer Epidemiology', 'Breast Epithelial Cells', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Cellular Morphology', 'Characteristics', 'Chemical Exposure', 'Chemicals', 'Clinical Trials', 'Coculture Techniques', 'Complex', 'Data', 'Data Set', 'Development', 'Endocrine Disruptors', 'Environment', 'Environmental Exposure', 'Epithelial', 'Estrogen receptor positive', 'Exposure to', 'Family', 'Fiber', 'Fibroblasts', 'Functional Imaging', 'Future', 'Gene Proteins', 'Gland', 'Growth', 'Health', 'Hormones', 'Imaging Techniques', 'In Vitro', 'Incidence', 'Industrialization', 'Investments', 'Label', 'Libraries', 'Link', 'Maintenance', 'Malignant Neoplasms', 'Mammary gland', 'Manufacturer Name', 'Mesenchymal', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'Mus', 'National Institute of Environmental Health Sciences', 'Nature', 'North Carolina', 'Odds Ratio', 'Optical Coherence Tomography', 'Optics', 'Output', 'Paper', 'Pathology', 'Physiological', 'Poly-fluoroalkyl substances', 'Property', 'Public Health', 'Rattus', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Rodent', 'Rodent Model', 'S-Phase Fraction', 'Scanning', 'Scoring Method', 'Signal Transduction', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'Toxic Environmental Substances', 'Up-Regulation', 'Work', 'assay development', 'base', 'carcinogenesis', 'carcinogenicity', 'cell motility', 'chemical stability', 'data modeling', 'deep learning', 'deep learning algorithm', 'high throughput screening', 'imaging capabilities', 'in vitro Assay', 'in vitro Model', 'in vivo', 'intercellular communication', 'machine learning algorithm', 'malignant breast neoplasm', 'malignant phenotype', 'mammary epithelium', 'mammary gland development', 'man', 'model design', 'non-invasive imaging', 'novel', 'optical imaging', 'premalignant', 'protein biomarkers', 'response', 'screening', 'small molecule libraries', 'three dimensional cell culture', 'three-dimensional modeling', 'tool', 'toxicant']",NIEHS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,499609
"Augmented Reality Platform for Telehealth Rehabilitiation Efforts to keep the most vulnerable individuals with chronic medical conditions from being exposed to COVID- 19 have triggered an unprecedented decline in the number of visits to ambulatory practices. The repercussions have impacted not only those with the disease, but the many millions of older persons in need of healthcare who forego in-person visits in fear of infection or for socioeconomic reasons. While the precipitating need for alternative healthcare delivery methods has hastened the adoption of software solutions, such as Zoom, traditional videoconferencing services fail to compensate for the lack of direct physical evaluations with a patient that is needed for evaluating musculoskeletal (MSK) deficits, planning therapeutic interventions, and guiding exercise compliance—essential components of evidence-based practice among rehabilitation practitioners. To overcome these shortcomings, our team of computer vision and human movement engineers is partnering with orthopedic rehabilitation specialists at Massachusetts General Hospital (MGH) to develop a telehealth platform that fuses high resolution RGB and Depth (RGD-D) video data readily obtainable from a modern smartphone to facilitate quantitative, MSK assessment. The innovation builds upon our work in computing movement outcome measures from vision-based body tracking algorithms, and our skills in augmented reality (AR) software development to enhance a clinician’s assessment and exercise instruction capabilities. Our pilot data demonstrate that accurate quantitative rehabilitation outcomes are obtainable using RGB-D body tracking algorithms during a sub-set of knee activities. Phase I will advance these capabilities by deriving and validating the accuracy of 3D body tracking and rehabilitation outcome measures during a wider set of activities used clinically for assessing knee mobility, alignment, posture, balance, strength, and function from depth enabled smartphone video recordings in control subjects (Aim 1). Aim 2 will develop a proof-of-concept AR telehealth platform with the help of the MGH team that delivers an enhanced telehealth experience through real-time synchronized audio-visual processing, real-time display of quantitative rehabilitation outcomes for the therapist to assess deficits or guide exercise compliance, and instructional animations for the patient to safely carry out the rehabilitation activities. The proof-of-concept prototype will undergo feasibility testing in Aim 3 among n=5 physical therapists and n=10 patients with knee OA during a simulated telehealth session to achieve high ratings for usability, accessibility, and effectiveness. The results will inform the user-requirements of a more complete Phase II telehealth platform designed in close collaboration with industry partners to provide secure cloud based communication for seamless interoperability between devices; additional examination tools (e.g. gait analysis); a broader range of baseline assessment and therapeutic exercise protocols for additional MSK conditions; and HIPAA-compliant deployment and electronic documentation management. The final prototype system will be evaluated during actual telehealth visits at multiple clinical sites to promote safe and effective clinical care. PROJECT NARRATIVE With the onset of the COVID-19 pandemic, clinical care has by necessity shifted towards telehealth delivery for people at risk due to age, who live in underserved communities or avoid in-person visits out of fear of viral transmission. Existing telehealth software platforms are generally supportive of videoconferencing but have yet to provide rehabilitation professionals with quantitative outcomes typically obtained from direct physical evaluations with a patient. To overcome this shortcoming, we are developing an augmented reality platform that fuses RGB and depth imaging from a patient’s smartphone to deliver quantitative outcomes of knee joint mobility, alignment, posture, balance, strength and function during a telehealth visit to support the mandate for more effective remote delivery of evidence-based rehabilitation during the global pandemics and beyond.",Augmented Reality Platform for Telehealth Rehabilitiation,10256844,R43AG072991,"['3-Dimensional', 'Adoption', 'Age', 'Algorithms', 'Architecture', 'Augmented Reality', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Cellular Phone', 'Chronic', 'Clinical', 'Collaborations', 'Communication', 'Computer Vision Systems', 'Computer software', 'Data', 'Devices', 'Disease', 'Documentation', 'Effectiveness', 'Elderly', 'Engineering', 'Ensure', 'Evaluation', 'Evidence based practice', 'Exercise', 'Exposure to', 'Feasibility Studies', 'Feedback', 'Focus Groups', 'Fright', 'General Hospitals', 'Goals', 'Gold', 'Health', 'Health Care Visit', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Human', 'Image', 'Individual', 'Infection', 'Instruction', 'Intuition', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modality', 'Modernization', 'Motion', 'Movement', 'Musculoskeletal', 'Musculoskeletal Diseases', 'Musculoskeletal Equilibrium', 'Orthopedics', 'Outcome', 'Outcome Measure', 'Patient Self-Report', 'Patients', 'Persons', 'Phase', 'Physical Rehabilitation', 'Physical therapy', 'Protocols documentation', 'Quarantine', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Resolution', 'Risk', 'Secure', 'Services', 'Specialist', 'Supervision', 'System', 'Tablets', 'Technology', 'Testing', 'Therapeutic Intervention', 'Therapeutic exercise', 'Time', 'Validation', 'Video Recording', 'Videoconferencing', 'Virtual Tool', 'Vision', 'Visit', 'Visualization', 'Work', 'animation', 'base', 'clinical care', 'clinical practice', 'clinical research site', 'cloud based', 'design', 'evidence base', 'experience', 'feasibility testing', 'gait examination', 'health care delivery', 'industry partner', 'innovation', 'interoperability', 'joint mobilization', 'new technology', 'outpatient programs', 'pandemic disease', 'partial recovery', 'patient safety', 'physical therapist', 'prototype', 'remote delivery', 'skills', 'socioeconomics', 'software development', 'telehealth', 'tool', 'underserved community', 'usability', 'viral transmission', 'visual processing']",NIA,"ALTEC, INC.",R43,2021,286972
Engineering a diagnostic platform for rapid breath-based respiratory pathogen identification and treatment monitoring No abstract available n/a,Engineering a diagnostic platform for rapid breath-based respiratory pathogen identification and treatment monitoring,10331914,R00EB028311,"['Acute respiratory infection', 'Aftercare', 'Amides', 'Amines', 'Animals', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial susceptibility', 'Bacteria', 'Bacterial Pneumonia', 'Bar Codes', 'Biological Assay', 'Blinded', 'Blood', 'Classification', 'Clinical', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Drug resistance', 'Early Diagnosis', 'Engineering', 'Enzymes', 'Fingerprint', 'Fluorocarbons', 'Goals', 'Immune response', 'In Vitro', 'Infection', 'Inhalation', 'Leukocyte Elastase', 'Ligands', 'Lung', 'Mass Spectrum Analysis', 'Measures', 'Mentors', 'Methods', 'Monitor', 'Mus', 'Peptide Hydrolases', 'Peptides', 'Pharmaceutical Preparations', 'Phase', 'Predisposition', 'Pseudomonas aeruginosa', 'Randomized', 'Reporter', 'Research Personnel', 'Resistance', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Sputum', 'Survival Rate', 'System', 'Testing', 'Time', 'Tissues', 'Validation', 'Work', 'antimicrobial drug', 'base', 'classification algorithm', 'cohort', 'diagnostic platform', 'extracellular', 'in vivo', 'in-vivo diagnostics', 'mouse model', 'nanoparticle', 'nanosensors', 'outcome forecast', 'pathogen', 'pathogenic bacteria', 'pathogenic fungus', 'pathogenic virus', 'portability', 'random forest', 'resistant strain', 'respiratory pathogen', 'response', 'urinary', 'ventilator-associated pneumonia', 'volatile organic compound']",NIBIB,GEORGIA INSTITUTE OF TECHNOLOGY,R00,2021,249000
"Synchronized brain dynamics and eye movement trajectory for objective evaluation of robot-assisted surgical skills Complicated and costly robot assisted surgery (RAS) training results in less frequent use of this technology in several complex areas of surgery, and consequently ends up in harm. RAS requires a unique blend of skills in addition to manual competence with human-machine interaction skills, while operating remotely from patient with no tactile feedback. To address this challenge, numerous studies have focused on simulation-based robotic training curricula, like Fundamental Skills of Robotic Surgery (FSRS), to develop and assess the performance level of the surgeon operator. However, such training tools were developed based on metrics measured by performance on a simulator and other subjectively evaluated metrics. The goal of this research proposal is to develop a tool for objective RAS skill assessment and a model for performance monitoring. We hypothesize that brain dynamics - Electroencephalogram (EEG) - and eye movement behavior are able to detect change of skill level and the level of surgeon’s performance. To validate this hypothesis, we will record EEG signals and eye movement time series from subjects with different RAS expertise levels. Ten novices, 5 beginners, 5 advanced beginners, and 5 expert surgeons will be included in the study and continuously perform four levels of designed RAS training tasks on surgical robot simulator, dry lab, and animal lab during one year; (1) performing six basic tasks on surgical simulator. All subjects will practice these tasks during two weekly sessions and each practice session takes 2 hours. (2) Subjects will practice 3 tasks of peg transfer, pattern cutting, and suturing on dry lab. (3) Subjects will practice 2 tasks (anastomosis and dissection) on animal tissue and also on plastic models. (4) Subjects will practice two operations of nephrectomy and hysterectomy on animal lab, 2 operations in each session, and each session takes 3 hours and occurs every other week. Two master surgeons will subjectively evaluate performance of subjects (all 25 subjects; Score scale: 1-20) and expertise level (four categories) in performing the designed tasks, every practice session. Master surgeons evaluate surgeon’s skill and performance throughout task and notify change of skill level and performance through time. We will then develop a ‘deep convolutional neural network’ algorithm trained by EEG and eye movement time series through running windows with equal size, to classify subject skill level into four categories of a novice, beginner, advanced beginner, and expert. We will also use network neuroscience techniques to extract engineered features from EEG and eye movement data and use them for training a regression algorithm to develop a model for performance level prediction. Ultimately, the developed objective skill evaluation tool and performance monitoring model will make RAS training more efficient by providing feedback to the trainee regarding his/her skills and directing him/her to focus on skills needed improvement. These improvements will result in more frequent use of RAS in complex surgical areas and ultimately lead to patient safety. Project Narrative The use of robot-assisted surgery (RAS) has offered advantages for surgeons and patients, yet there is no clinically practical tool for objective evaluation of subject’s expertise level and performance. The overall objective of this research is to develop a tool for objective RAS skill assessment and a model for performance monitoring, leading to optimized RAS training process, improved patient safety and surgical outcomes.",Synchronized brain dynamics and eye movement trajectory for objective evaluation of robot-assisted surgical skills,10133651,R01EB029398,"['Active Learning', 'Address', 'Algorithms', 'Anastomosis - action', 'Animals', 'Applied Skills', 'Area', 'Automobile Driving', 'Behavior', 'Brain', 'Categories', 'Classification', 'Clinical', 'Cognitive', 'Competence', 'Complex', 'Data', 'Development', 'Dissection', 'Educational Curriculum', 'Electroencephalogram', 'Engineering', 'Evaluation', 'Eye', 'Eye Movements', 'Feedback', 'Goals', 'Hour', 'Human', 'Hysterectomy', 'Individual', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Length', 'Literature', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Needles', 'Nephrectomy', 'Neurosciences', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patients', 'Pattern', 'Performance', 'Process', 'Publishing', 'Research', 'Research Proposals', 'Robot', 'Robotics', 'Role', 'Running', 'Series', 'Signal Transduction', 'Structure', 'Surgeon', 'Surgical sutures', 'System', 'Tactile', 'Techniques', 'Technology', 'Time', 'Training', 'Wrist', 'adaptive learning', 'algorithm development', 'algorithm training', 'animal tissue', 'arm', 'base', 'cognitive process', 'convolutional neural network', 'cost', 'deep neural network', 'density', 'design', 'gaze', 'human disease', 'improved', 'learning strategy', 'motor learning', 'neural network algorithm', 'operation', 'patient safety', 'regression algorithm', 'robot assistance', 'robotic device', 'robotic training', 'safety outcomes', 'sensor', 'signal processing', 'simulation', 'skill acquisition', 'skills', 'surgery outcome', 'tool']",NIBIB,ROSWELL PARK CANCER INSTITUTE CORP,R01,2021,385213
"The Adherence Promotion with Person-centered Technology (APPT) Project: Promoting Adherence to Enhance the Early Detection and Treatment of Cognitive Decline Many older adults experience declines in cognitive ability that can be substantial, including mild cognitive impairment and Alzheimer’s disease and AD-related dementia. Population aging, coupled with age-related cognitive impairment, including Alzheimer’s disease and other dementias, represents an unprecedented challenge. Early detection of cognitive impairment is a crucial goal. This would allow individuals at risk for mild cognitive impairment and/or AD/ADRD to adopt lifestyle changes to minimize decrements and the risk for acquired cognitive impairment. However, the massive potential of cognitive training and longitudinal assessment to detect and prevent age-related cognitive impairment and dementia are unlikely to be realized unless individuals are willing and able to engage with these protocols for an extended period of time. Adherence to cognitive assessment and training is often poor. Addressing the gap between potential and realized benefits of early detection and prevention of cognitive impairment is an urgent goal as the population ages. The aims of the Adherence Promotion with Person-centered Technology (APPT) project are to promote early detection and treatment of age-related cognitive impairment and dementia by 1) enhancing adherence to cognitive intervention and assessment protocols, 2) improving understanding of barriers to long-term adherence, and 3) assisting in the development of algorithms for predicting and preventing adherence failures. Projects aim to investigate these issues within samples of older adults with and without cognitive impairment. Two randomized controlled trials will test an adaptive, tailored, and integrated technology support system predicted to boost adherence to cognitive protocols, over and above a simpler scheduling and reminder system over 6 months. Studies will provide valuable and generalizable insight into not only the benefits of adherence support, but also the individual difference factors that shape protocol adherence (e.g., attitudes, cognitive ability, dementia status, health status, personality, technology proficiency). Data will inform the process of identifying individuals who would benefit from additional support, and predicting and preventing extended adherence failures before they happen. By increasing adherence, these studies will help improve early detection and treatment of cognitive impairment, which will ultimately extend older adults' functional independence, improving their lives and the lives of their families, and reducing care and support resources needed to address lost independence like that associated with Alzheimer’s disease and AD-related dementia. Further, intervention studies for dementia and Alzheimer’s disease can be made more efficient through tools for identifying individuals likely to experience decline before substantial cognitive impairment has occurred. Results have implications that extend far beyond cognitive impairment; the methods and mechanisms uncovered have broad implications for technology-mediated assessment and protocols to enhance health and well-being in general. The project consists of two large randomized controlled trials and smaller needs assessment and usability studies that will guide their development and deployment. PUBLIC HEALTH RELEVANCE: The aims of the Adherence Promotion with Person-centered Technology (APPT) project are to promote early detection and treatment of age-related cognitive impairment and dementia. This project will develop Artificial Intelligence-based reminder systems to help ensure long-term engagement to home-based cognitive assessment and cognitive training protocols to be able to detect and treat cognitive impairment as soon as possible.",The Adherence Promotion with Person-centered Technology (APPT) Project: Promoting Adherence to Enhance the Early Detection and Treatment of Cognitive Decline,10134189,R01AG064529,"['Address', 'Adherence', 'Adopted', 'Age', 'Age-associated memory impairment', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Artificial Intelligence', 'Attitude', 'Caring', 'Clinical Trials', 'Cognition', 'Cognitive', 'Cognitive aging', 'Computer software', 'Coupled', 'Data', 'Dementia', 'Development', 'Early Diagnosis', 'Early treatment', 'Elderly', 'Ensure', 'Failure', 'Family', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Home environment', 'Human', 'Impaired cognition', 'Individual', 'Individual Differences', 'Intervention', 'Intervention Studies', 'Interview', 'Life Style', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Needs Assessment', 'Participant', 'Personal Satisfaction', 'Personality', 'Population', 'Positioning Attribute', 'Prevention', 'Process', 'Protocols documentation', 'Randomized Controlled Trials', 'Reminder Systems', 'Research', 'Resources', 'Risk', 'Sampling', 'Schedule', 'Shapes', 'Structure', 'Support System', 'Technology', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Weight', 'aging population', 'algorithm development', 'base', 'behavioral adherence', 'cognitive ability', 'cognitive change', 'cognitive performance', 'cognitive testing', 'cognitive training', 'design', 'experience', 'functional independence', 'improved', 'insight', 'intelligent algorithm', 'mild cognitive impairment', 'mobile computing', 'next generation', 'person centered', 'prediction algorithm', 'preference', 'prevent', 'public health relevance', 'success', 'therapy design', 'tool', 'usability']",NIA,FLORIDA STATE UNIVERSITY,R01,2021,654065
"Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation Project Summary Neonatal endotracheal intubation (ETI) is a time-sensitive resuscitation procedure! essential for ventilation of newborns. It requires an unusually high level of skill due to the narrow airways, relatively large tongue, anterior glottic position, and low respiratory reserve of neonates (Bercic, Pocajt et al. 1978). Given the difficulty of the procedure and the high rate of complications in untrained hands, effective training is crucial. However, intubation success rates for pediatric residents are low under current resuscitation training programs and show little improvement between years 1-3 of residency (23-25%) (O'Donnell, Kamlin et al. 2006; Haubner, Barry et al. 2013). There is a pressing need to understand the factors that lead to poor training results and for innovative training modalities that can bridge the gap left by traditional training and thereby allow rapid skill acquisition. We hypothesize that current training and assessment methods suffer from 4 key weaknesses: (1) Poor realism: manikin and simulator-based training typically provide little variation in anatomy or difficulty level—key requirements for developing expertise (Dreyfus, Athanasiou et al. 1986)—and do not realistically model the look, feel, and motions of real tissue. (2) Subjective, highly variable, and resource-intensive assessment methods: training opportunities are limited by the availability of expert instructors. (3) Poor visualization: learners have poor knowledge about what went wrong and how to improve; they cannot see exactly what is going on inside the manikin or the patient and cannot directly monitor their actions relative to idealized, expert performance. (4) Assessment under artificially ideal conditions: assessments of ETI performance in classroom settings likely overestimate trainees' skill level because they do not mimic the stressors and distractions that are inherent in the real clinical environment. Technology-enhanced ETI simulators can resolve all of these key weaknesses: We have conducted preliminary work (Hahn, Li et al. 2016; Soghier, Li et al. 2014) on an augmented reality (AR (Azuma 1997)) manikin simulator driven by the motions of the trainee and physical manikin in real time that 1) provides a quantitative assessment of ETI technique and 2) allows the trainee to visualize the motion of the laryngoscope inside the manikin. The assessment score can provide feedback during the performance, as well as constitute part of the evaluation of the trainee's skill. Work under this proposal will build on this preliminary work. The specific aims are to: extend the current augmented reality (AR) manikin simulator to a virtual reality (VR) computer simulator and validate, extend and validate automated assessment and visualization algorithm for ETI, study training effectiveness by testing groups of pediatric residents across 3 years to quantify the effect of technology-enhanced methods relative to the current training regimen in terms of both intubation performance on simulators and clinical outcomes in patients, and assess performance under more realistic conditions. Project Narrative The current training and assessment of neonatal endotracheal intubation (ETI) suffers from key weaknesses of 1) poor realism of task simulators, 2) subjective, highly variable, and resource-intensive assessment methods, 3) poor visualization during simulation, and 4) assessment methods under artificially ideal conditions. This high-yield proposal will bridge the gap between training and clinical practice by using quantitative assessment tools and technology-enhanced simulation to improve ETI performance prior to patient care.",Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation,10194566,R01HD091179,"['Algorithms', 'Anatomy', 'Anterior', 'Assessment tool', 'Attention', 'Augmented Reality', 'Biomedical Engineering', 'Biometry', 'Childhood', 'Clinical', 'Cognitive Science', 'Computer Simulation', 'Computers', 'Data', 'Effectiveness', 'Enhancement Technology', 'Environment', 'Evaluation', 'Feedback', 'Hand', 'Intratracheal Intubation', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Lead', 'Learning', 'Left', 'Libraries', 'Machine Learning', 'Manikins', 'Measures', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Neonatal', 'Neonatology', 'Newborn Infant', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Procedures', 'Regimen', 'Residencies', 'Resources', 'Resuscitation', 'Scanning', 'Standardization', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Tongue', 'Training', 'Training Programs', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'clinical practice', 'computer science', 'distraction', 'effectiveness testing', 'evidence base', 'haptics', 'improved', 'innovation', 'instructor', 'kinematics', 'multidisciplinary', 'neonate', 'respiratory', 'simulation', 'skill acquisition', 'skills', 'stressor', 'success', 'training opportunity', 'ventilation', 'virtual reality', 'virtual reality simulator']",NICHD,GEORGE WASHINGTON UNIVERSITY,R01,2021,314927
"A novel technology to assess chronic toxicity in genetically diverse nematode populations Project Abstract The number of new products such as drugs, cosmetics and food additives introduced into the market is growing and poses a significant challenge for risk prediction. Currently, vertebrate testing is the industry standard for hazard assessment but has limitations including high costs, and the growing public and corporate sentiment against using vertebrates for chemical testing. Importantly, current toxicity assessment does not incorporate genetic diversity leading to failure of drug candidates and unintended risks to human sub-populations. The celebrated invertebrate model C. elegans has the potential to fill this gap since thousands of genetically diverse nematode populations are available. However, the main challenge is that chronic studies of chemicals in the nematode model is still tedious, precluding large-scale toxicity testing in nematode populations. This proposal aims to develop a high-throughput technology for chronic toxicity screening of diverse genetic populations in adult C. elegans. The focus of our Phase I plan is to pursue chronic toxicity studies on select toxins and generate foundational data highlighting the impact of genetic diversity, and subsequently scale the NemaLife technology to enable large-scale genetic diversity screening. AIM 1: To generate chronic dose-response data on toxins affecting diverse C. elegans strains. We will test the effects of five toxins for which we know the variability in human and rodent responses. Animals will be exposed to toxins daily, followed by scoring of survival, reproductive and neuromuscular health. About 1200 whole-life assays will be conducted with data acquired on 500+ animals per assay condition. We will generate data that will define the rank-order of C. elegans toxin response vis-à-vis mammalian systems, optimize phenotyping conditions for large numbers of strains per species, and define the amount of heritable variation in toxin responses. These pilot data will validate the capabilities afforded by our screening platform. AIM 2: To scale the throughput of NemaLife Technology for thousands of chronic toxicity assays. Currently, NemaLife’s technology has a throughput of hundreds of chronic toxicity assays. However, given the large number of toxins and vast library of genetic strains and wild isolates available, there is a significant need to increase the throughput of our technology. Therefore, we will develop the technology infrastructure and workflow to scale the throughput which includes multiplexing our approach, scale-up of chip fabrication and streamlining data analysis. Technology development at the scale of thousands of whole-life toxicity assays in a few weeks with readouts on animal death and neuromuscular impairments will be a major breakthrough in the field opening up new business opportunities in toxicity testing in the drug and consumer industry. Project Narrative Non-parasitic nematodes offer a powerful in vivo model to scale and measure toxin responses in genetically diverse species anchoring a transformative means to bridge current gaps in predictive toxicology with clinically-relevant end points. Our study aims to combine state-of-the art advances in microfluidics, computer vision, laboratory automation and a massively curated genetically diverse nematode species to produce a new screening approach capable of testing thousands of chemicals relevant to agriculture, nutraceutical and biotech markets.",A novel technology to assess chronic toxicity in genetically diverse nematode populations,10112054,R43ES032516,"['Adult', 'Affect', 'Agriculture', 'Animals', 'Arsenic', 'Automation', 'Biological Assay', 'Biotechnology', 'Businesses', 'Cadmium', 'Caenorhabditis elegans', 'Cells', 'Cessation of life', 'Chemicals', 'Chronic', 'Clinical Trials', 'Computer Vision Systems', 'Cosmetics', 'Data', 'Data Analyses', 'Dose', 'Environment', 'Exposure to', 'Failure', 'Food Additives', 'Foundations', 'Gait', 'Gene Library', 'Genetic Models', 'Genetic Variation', 'Genome', 'Hazard Assessment', 'Health', 'Heritability', 'Human', 'Impairment', 'Industry', 'Industry Standard', 'Infrastructure', 'Invertebrates', 'Laboratories', 'Life', 'Life Cycle Stages', 'Liquid substance', 'Maintenance', 'Measures', 'Metformin', 'Methods', 'Microfluidics', 'Modeling', 'Molecular', 'Nematoda', 'Nutraceutical', 'Paraquat', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Heterogeneity', 'Predisposition', 'Public Health', 'Risk', 'Rodent', 'Safety', 'System', 'Technology', 'Testing', 'Toxic Environmental Substances', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Toxin', 'Variant', 'Vertebrates', 'Work', 'base', 'clinically relevant', 'cost', 'drug candidate', 'genetic resource', 'genetic strain', 'high throughput technology', 'in vivo Model', 'neuromuscular', 'new technology', 'reproductive', 'resistant strain', 'response', 'risk prediction', 'scale up', 'screening', 'technology development']",NIEHS,NEMALIFE INC.,R43,2021,251040
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,10160982,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2021,575125
"Creating a foundation for personalized age- and sex-based immune-targeted therapies from an ALS longitudinal cohort by identifying peripheral and central immune signatures ABSTRACT The immune system contributes to amyotrophic lateral sclerosis (ALS) progression and survival, and therapies to target the immune system are of burgeoning interest. However, the changes in the immune system during the course of ALS and the sex-specific alterations in immune function warrant a more in depth analysis in order to develop personalized ALS therapies and biomarkers. The long-term goals are to harness the immune sys- tem’s potential to slow and stop the progression of ALS. The overall objective is to determine how peripheral immune profiles, sex, age, and sex hormones, link to neuronal damage, neuroinflammation, and ALS progres- sion and survival. The central hypothesis is that peripheral immune profiles are an important pathophysiologic agent of ALS progression and survival; that sex, age and sex hormone levels impact these profiles; and that insight into ALS patient-specific immune profiles will yield new drug targets and therapeutic windows. Our ra- tionale is that linking patient-specific immune cell profiles to ALS progression and survival will facilitate person- alized immunomodulatory therapeutic development for ALS and identify potential treatment windows. The cen- tral hypothesis will be pursued with three aims: 1) Identify specific immune profiles that associate with ALS pro- gression and survival rates.; 2) Evaluate the effects of sex hormones on ALS immune profiles, progression, and survival; and 3) Identify immune profiles and corresponding cellular pathways that are most toxic to neu- rons and that associate with central inflammation. In Aim 1 longitudinal immunophenotyping of peripheral blood samples from ALS subjects will generate composite immune profiles that will then be linked to ALS subject characteristics, progression, and survival. Aim 2 will determine if observed sex-dependent associations be- tween immune profiles and ALS progression and survival are mediated by sex hormones, as sex hormones can alter immune profiles. Aim 3 will enrich a cohort of ALS subjects by immune profile clusters; their periph- eral immune populations will be analyzed using 1) RNA-seq and 2) cell toxicity studies via co-cultures with iPSC-derived neurons; subjects will also have positron emission tomography (PET) imaging to quantify central neuroinflammation. Datasets will be synthesized to build prediction models and create deep neural networks capable of associating immune profiles with sex, age, disease severity, progression, and survival The research proposed is innovative, in the applicants’ opinion, because it rigorously examines the effects of sex, age, and sex hormone levels on immune cells and ALS progression and survival in a longitudinal study. It also accounts for the interactions between immune cells by forming immune profiles for individual subjects and assesses how specific profiles associate with dysregulated pathways, cytotoxicity, and neuroinflammation. The proposed re- search is significant because it will provide critical data on the distinct immune profiles and pathways associ- ated with ALS progression and survival in a sex-, age- and sex hormone- specific fashion. PROJECT NARRATIVE The proposed research is relevant to public health because it focuses on identifying the alterations in the im- mune system that impact amyotrophic lateral sclerosis (ALS) and also focuses on identifying whether these altered immune profiles are influenced by sex- and age-specific factors. The development of such strategies will greatly advance the ability to develop personalized treatment approaches for persons with ALS based on immunomodulatory drugs. Thus, the proposed research is relevant to part of the NIH’s mission that pertains to developing the fundamental knowledge about the nervous system and using that knowledge to reduce the bur- den of neurological disease.",Creating a foundation for personalized age- and sex-based immune-targeted therapies from an ALS longitudinal cohort by identifying peripheral and central immune signatures,10177640,R01NS120926,"['ALS patients', 'Address', 'Affect', 'Age', 'Amyotrophic Lateral Sclerosis', 'Animals', 'Area', 'Biological Markers', 'Blood', 'Blood specimen', 'CD4 Positive T Lymphocytes', 'Cell Count', 'Cells', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Trials', 'Coculture Techniques', 'Data', 'Data Set', 'Development', 'Disease', 'Disease Progression', 'Estrogens', 'Foundations', 'Goals', 'Gonadal Steroid Hormones', 'Hormones', 'Human', 'Immune', 'Immune Targeting', 'Immune response', 'Immune system', 'Immunomodulators', 'Immunophenotyping', 'In Vitro', 'Individual', 'Induced pluripotent stem cell derived neurons', 'Inflammation', 'Inflammatory', 'Knowledge', 'Link', 'Literature', 'Longitudinal Studies', 'Longitudinal cohort', 'Mediating', 'Michigan', 'Mission', 'Motor Neuron Disease', 'Natural Killer Cells', 'Nervous system structure', 'Neurons', 'Outcome', 'Pathway interactions', 'Patients', 'Peripheral', 'Persons', 'Phenotype', 'Population', 'Positron-Emission Tomography', 'Prostitution', 'Public Health', 'Recording of previous events', 'Regulatory T-Lymphocyte', 'Research', 'Sampling', 'Severity of illness', 'Survival Rate', 'System', 'Testosterone', 'Time', 'Toxic effect', 'Tweens', 'United States National Institutes of Health', 'Universities', 'amyotrophic lateral sclerosis therapy', 'base', 'biobank', 'cohort', 'cytotoxicity', 'deep neural network', 'design', 'drug development', 'drug repurposing', 'effective therapy', 'immune function', 'in vivo', 'innovation', 'insight', 'interest', 'knowledge base', 'nervous system disorder', 'neuroinflammation', 'neurotoxicity', 'neutrophil', 'new therapeutic target', 'peripheral blood', 'personalized medicine', 'personalized therapeutic', 'predictive modeling', 'sex', 'targeted treatment', 'therapeutic development', 'therapeutic target', 'transcriptome sequencing']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,643473
"Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring Abstract  Building on its commercially available Absolute Q digital PCR platform, during the 24-month Phase 2 SBIR project, Combinati will complete the development of the first Digital Melt Curve Analysis (DMCA) platform to the market to further advance the adoption of digital genomics for highly accurate, sensitive and reproducible nucleic acid quantification for longitudinal patient monitoring. To provide the “whole product” solution and prove the function, we will demonstrate the DMCA platform with Luminex’s 11- plex ESR1 (Estrogen Receptor 1) assay and conduct Beta testing at Dana Farber Cancer Institute: 1. Three beta instruments and the analysis software capable of digital melt curve analysis. 2. Complete dMCA validation internally with commercially available melt calibration kits. 3. Demonstrate <0.1% Mutation Allele Frequency of 11 cell-free DNA targets using Luminex  Corporation’s discrete melt assay. 4. Beta testing at Dana Farber Cancer Institute Narrative  Since PCR was invented back in 1983, it has become the gold standard for applications requiring quantification of nucleic acids. The continuous evolution of the technology enables PCR to be more quantitative (qPCR), more accurate, precise and reproducible (digital PCR). In parallel, with the invention of melt curve analysis in 1997, it opens another dimension in melt temperatures for applications requiring simple and inexpensive genotyping, high degree qualitative multiplexing without sequencing, and assay optimization. Despite that there is a handful of dPCR platforms in the market, none of them supports Melt Curve Analysis. By combining melt curve analysis with digital PCR, Combinati strives to accelerate the adoption of digital genomics for all nucleic acid quantification needs in research and clinical markets.",Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring,10256226,R44CA261523,"['Adopted', 'Adoption', 'Architecture', 'Back', 'Biological Assay', 'Blinded', 'Breast Cancer Patient', 'Calibration', 'Cancer Patient', 'Chemistry', 'Clinical', 'Collection', 'Color', 'Computer software', 'Computers', 'DNA', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Development', 'Dimensions', 'ESR1 gene', 'Evolution', 'Gene Frequency', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Journals', 'Letters', 'Light', 'Mainstreaming', 'Manuscripts', 'Mechanics', 'Memory', 'Metastatic breast cancer', 'Microfluidics', 'Monitor', 'Mutation', 'Nucleic Acids', 'Optics', 'Oranges', 'Patient Monitoring', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Reproducibility', 'Research', 'Resolution', 'Risk', 'Running', 'Sampling', 'Science', 'Small Business Innovation Research Grant', 'Source', 'Speed', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Validation', 'cell free DNA', 'clinically relevant', 'cost', 'cyanine dye 5', 'data exchange', 'design', 'detection limit', 'digital', 'fluorescence imaging', 'graphical user interface', 'image processing', 'improved', 'instrument', 'invention', 'lens', 'liquid biopsy', 'machine learning algorithm', 'meetings', 'melting', 'multidimensional data', 'mutant', 'mutation assay', 'neural network', 'product development', 'sensor', 'simulation']",NCI,"COMBINATI, INC.",R44,2021,772720
"Shape Analysis Toolbox: From medical images to quantitative insights of anatomy PROJECT SUMMARY Three-dimensional shape lies at the core of understanding the physical objects that surround us. The Shape AnaLysis Toolbox (SALT) was created to be a dissemination vehicle for advanced shape modeling and analysis methodology as an open-source, comprehensive and freely distributed software. Over the past four years, we have been successful in increasing the ease of use and effectiveness of state-of-the-art shape analysis methodology for biomedical researchers in need of such techniques. We now propose necessary and novel enhancements to our methods and our dissemination model in order to continue maximizing the success of SALT. We will also modify the architecture of SALT to better integrate biomedical imaging research workflows by improving the efficiency and scripting capabilities so SlicerSALT can be deployed in batch mode for large-scale sequential computations. We will also shift our focus from shape modeling into state-of-the-art statistical shape analysis methodologies, necessary to serve clinical applications and to increase the interpretability of shape biomarkers. We will continue to disseminate novel example applications that best demonstrate how to use our tools to perform impactful research and will provide fully digital documentation for user support. The ultimate goal of SlicerSALT is to maximize the potential benefits of the geometric information contained in medical data and to expand its use beyond simple visualization to support clinical research. PROJECT NARRATIVE Slicer Shape AnaLysis Toolbox (SALT) was developed as an open-source, free comprehensive software that allows biomedical scientists to precisely locate shape changes in their imaging studies. This proposal is designed to increase the continued success of SALT by recognizing that shape models and dynamic anatomical changes are challenging to interpret despite quantification of the geometry of physical objects. We will address this need by incorporating state-of-the-art and interpretable shape statistics methodology into SALT and new driving biological problems to illustrate their utility while continuing to provide effective user support.",Shape Analysis Toolbox: From medical images to quantitative insights of anatomy,10426508,R56EB021391,"['3-Dimensional', 'Accounting', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Automobile Driving', 'Biological', 'Biological Markers', 'Biomedical Research', 'Brain', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Consultations', 'Data', 'Development', 'Disease', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Fostering', 'Funding', 'Geometry', 'Goals', 'Image Analysis', 'Infrastructure', 'Longitudinal Studies', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Online Systems', 'Pediatric cardiology', 'Phase', 'Population', 'Process', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Shapes', 'Software Tools', 'Statistical Methods', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Training', 'Ultrasonography', 'Use Effectiveness', 'Variant', 'Visualization', 'base', 'bioimaging', 'biomedical scientist', 'clinical application', 'complex data', 'computer science', 'deep learning', 'design', 'digital', 'efficacy evaluation', 'fetal', 'geometric structure', 'imaging study', 'improved', 'innovation', 'insight', 'large scale data', 'longitudinal analysis', 'new technology', 'novel', 'open source', 'outreach', 'shape analysis', 'statistics', 'success', 'tool', 'usability', 'web site']",NIBIB,"KITWARE, INC.",R56,2021,436264
"Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences Abstract A major approach in causal inference literature aimed at mitigating bias due to unmeasured confounding is the so- called instrumental variable (IV) design which relies on identifying a variable which (i) influences the treatment process, (ii) has no direct effect on the outcome other than through the treatment, and (iii) is independent of any unmeasured confounder. IV methods are very well developed and widely used in social and health science, although validity of IV inferences may not be reliable if any of required assumptions (i)-(iii) is violated. This proposal aims to develop (a) new IV methods robust to violation of any of (i)-(iii); (b) New negative control methods that can be used to detect and sometimes to nonparametrically account for unmeasured confounding bias; (c) New bracketing methods for partial inference about causal effects in comparative interrupted time series studies. The proposed methods will be used to address current scientific queries in three major substantive public health areas:(1) to understand the health effects of air pollution; (2) to quantify the causal effects of modifiable risk factors for Alzheimer's disease and related disorders; (3) To uncover the mechanism by which a randomized package of interventions produced a substantial reduction of HIV incidence in a recent major cluster randomized trial of treatment as prevention in Botswana, Africa. Our proposal will provide the best available analytical methods to date to resolve confounding concerns in these high impact public health applications and more broadly in observational studies in the health sciences. Summary This proposal aims to develop new causal inference methods to tame bias due to hidden confounding factors in obser- vational studies as well as in randomized experiments subject to non-adherence. The proposed methods are firmly grounded in modern semiparametric theory which will be used to obtain more robust and efficient inferences about causal effects in a broad range of public health applications including in Epidemiology of Aging, Environmental Health Epidemiology and HIV/AIDS Prevention.",Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences,10159821,R01AG065276,"['AIDS prevention', 'Address', 'Adherence', 'Africa', 'Aging', 'Air Pollution', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Area', 'Blood Pressure', 'Body mass index', 'Botswana', 'Cluster randomized trial', 'Data', 'Diabetes Mellitus', 'Disease', 'Environmental Health', 'Epidemiology', 'Genetic', 'HIV', 'Health', 'Health Sciences', 'Incidence', 'Interruption', 'Intervention', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Masks', 'Mendelian randomization', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Observational Study', 'Outcome', 'Participant', 'Process', 'Public Health', 'Public Health Applications Research', 'Randomized', 'Research Design', 'Research Personnel', 'Risk Factors', 'Series', 'Social Sciences', 'Testing', 'Thromboplastin', 'Time', 'ambient air pollution', 'analytical method', 'c new', 'comparative', 'design', 'experimental study', 'genetic variant', 'high dimensionality', 'intervention effect', 'modifiable risk', 'mortality', 'novel', 'pleiotropism', 'semiparametric', 'simulation', 'theories', 'treatment as prevention', 'treatment effect', 'uptake', 'user friendly software']",NIA,UNIVERSITY OF PENNSYLVANIA,R01,2021,468961
"The plasticity of well-being:  A research network to define, measure and promote human flourishing PROJECT SUMMARY/ABSTRACT This U24 application is written in response to RFA-AT-20-003 to establish a high-priority research network on emotional well-being (EWB). While psychological research on well-being has dramatically increased over the past 15 years, virtually all of this work has been descriptive and has not emphasized the “how” of well-being: How might well-being be cultivated? In addition, virtually all of the extant work on the correlates of individual differences in well-being has used responses on retrospective questionnaires as the primary tool to assess well-being. While there have been exciting findings, particularly relating individual differences in well-being to various indices of physical health, many questions remain and methodological limitations plague the validity of this work. This U24 network will assemble a highly multi-disciplinary group of 10 investigators across 3 (or more in the future) institutions to significantly advance our understanding of the “how” of EWB, identify the core plastic constituents of EWB, specify and/or develop robust measures of these constituents at biological, behavioral and experiential levels of analysis and characterize the plasticity of these constituents. The measurement strategy will ultimately focus on the development of technology-based passive measures of EWB that require no explicit user input and are highly scalable. The network will also focus its efforts on the development and evaluation of programs to train EWB and will assess whether such programs might serve as prevention strategies. The network will consist of scientists and scholars from a broad range of fields including psychology, neuroscience, electrical and computer engineering, population health and biology, computer science and the humanities. These scientists and scholars will focus on the following major aims: Aim 1: To arrive at a core consensus of the minimal set of constituents that can be described and measured at biological, behavioral and experiential levels that constitute the plastic elements of EWB and to specify already existing measures and /or develop novel measures of each of these constructs at each level of analysis. Aim 2: Using the active measures described in Aim 1, to develop passive measures using digital technologies of at least two of the core constituents of well-being. Aim 3: To develop pilot projects specifically focusing on prevention strategies for learning well-being in various samples. The network will train new investigators and bring established investigators into this new field, disseminate a framework for understanding the plasticity of well- being, a toolbox of measures for assessing the plasticity of components of well-being, and several pilot datasets that showcase the novel passive and field-friendly biological measures. In these ways, the network will dramatically accelerate progress in the nascent field of EWB. PROJECT NARRATIVE This U24 network on emotional well-being (EWB) will catalyze the emerging field of the plasticity of well-being and will showcase how well-being can be learned and the consequences of such skill development on physical and emotional health and on prevention of disease. A framework for understanding how well-being can be learned along with measures of the core components of well-being that can be learned will be developed and disseminated. The network will also train new investigators in this area and will engage established investigators to contribute to this field.","The plasticity of well-being:  A research network to define, measure and promote human flourishing",10151850,U24AT011289,"['Area', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Biological', 'Cellular Phone', 'Communities', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Distal', 'Drug abuse', 'Elements', 'Emotional', 'Engineering', 'Face', 'Future', 'Gold', 'Grant', 'Health', 'Human', 'Humanities', 'Individual Differences', 'Institution', 'Interruption', 'Literature', 'Measurement', 'Measures', 'Mental Depression', 'Methodology', 'Mind', 'Modernization', 'Neurosciences', 'Outcome', 'Patient Self-Report', 'Personal Satisfaction', 'Pilot Projects', 'Plague', 'Population Biology', 'Prevention strategy', 'Program Evaluation', 'Psychology', 'Publications', 'Questionnaires', 'Randomized Controlled Trials', 'Regulation', 'Research', 'Research Personnel', 'Research Priority', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specific qualifier value', 'Subgroup', 'Techniques', 'Technology', 'To specify', 'Training', 'Well in self', 'Work', 'base', 'computer science', 'cost', 'digital', 'disorder prevention', 'indexing', 'learning strategy', 'mHealth', 'machine learning algorithm', 'meetings', 'member', 'mindfulness meditation', 'multidisciplinary', 'novel', 'physical conditioning', 'population health', 'prevent', 'programs', 'psychologic', 'response', 'skill acquisition', 'social', 'standard measure', 'technology development', 'tool', 'virtual', 'web site']",NCCIH,UNIVERSITY OF WISCONSIN-MADISON,U24,2021,30000
"Estimating Mediation Effects in Prevention Studies The purpose of this competing continuation grant proposal is to develop, evaluate and apply  methodological and statistical procedures to investigate how prevention programs change outcome  variables. These mediation analyses assess the link between program effects on the constructs targeted  by a prevention program and effects on the outcome. As noted by many researchers and federal  agencies, mediation analyses identify the most effective program components and increase  understanding of the underlying mechanisms leading to changing outcome variables. Information from  mediation analysis can make interventions more powerful, more efficient, and shorter. The P. I. of this grant received a one-year NIDA small grant and four multi-year grants to develop and evaluate mediation  analysis in prevention research. This work led to many publications and innovations. The proposed  five-year continuation focuses on the further development and refinement of exciting new mediation  analysis statistical developments. Four statistical topics represent next steps in this research and include  analytical and simulation research as well as applications to etiological and prevention data. The work expands on our development of causal mediation and Bayesian mediation methods that hold great promise for mediation analysis. In Study 1, practical causal mediation and Bayesian mediation analyses  for research designs are developed and evaluated. This approach will clarify methods and develop  approaches for dealing with violation of testable and untestable assumptions. Study 2 investigates  important measurement issues for the investigation of mediation. This work will focus on methods to identify critical facets of mediating variables, approaches to understanding whether mediators and  outcomes are redundant, and develop methods for studies with big data. Study 3 continues the development and evaluation of new longitudinal mediation methods for ecological momentary assessment data and other studies with massive data collection. These new methods promise to more accurately model change over time for both individuals and groups of individuals. Study 4 develops methods to  uncover subgroups in mediation analysis including causal mediation methods, multilevel models, and new  approaches based on residuals for identifying individuals for whom mediating processes differ in  effectiveness from other individuals. For each study, we will investigate unique issues with mediation analysis of prevention data including methods for small N and also massive data collection (big data), the RcErLitEicVaANl rCoEle(Soeef imnsetruacstiounrse):ment for mediating mechanisms, and the application of the growing literature on  causal methods and Bayesian methods. Study 5 applies new statistical methods to data from several NIH  The project further develops a method, statistical mediation analysis, that extracts more information from  funded prevention studies providing important feedback about the usefulness of the methods. Study 6  research. Mediation analysis explains how and why prevention and treatments are successful. Mediation  disseminates new information about mediation analysis through our website and other media, by  analysis improves prevention and treatment so that their effects are greater and even cost less. communication with researchers, and publications from the project. n/a",Estimating Mediation Effects in Prevention Studies,10168488,R37DA009757,"['Address', 'Applications Grants', 'Bayesian Method', 'Behavioral Mechanisms', 'Big Data', 'Biological Models', 'Communication', 'Complex', 'Consultations', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Ecological momentary assessment', 'Educational workshop', 'Effectiveness', 'Etiology', 'Evaluation', 'Feedback', 'Funding', 'Grant', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Outcome', 'Persons', 'Prevention', 'Prevention Research', 'Prevention program', 'Principal Investigator', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Residual state', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Work', 'base', 'computer program', 'cost', 'data space', 'design', 'dynamic system', 'improved', 'innovation', 'interest', 'longitudinal design', 'model design', 'multilevel analysis', 'novel strategies', 'programs', 'simulation', 'substance use treatment', 'successful intervention', 'theories', 'therapy design', 'tool', 'treatment research', 'web site']",NIDA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R37,2021,360584
"Personalized 3D avatar tool development for measurement of body perception across gender identities Abstract Public awareness of the diversity of experiences of gender identities has climbed sharply. The specific issues of those with gender dysphoria (GD) related to self-identity, body image, and medical interventions are challenges for the 21st century, particularly given the high risk of suicide. Gender identity is tightly linked to one’s bodily features, particularly readily observable sexual characteristics. For transgender and nonbinary individuals with GD, the incongruence between their body associated with their birth-assigned sex – what they see in the mirror before any treatment – and the internalized representation of their gender-identified body is a key defining part of their experience and contributes to their dysphoria. Currently, no clinical or research tool exists to capture and quantify the diverse experiences of one’s current body and one’s gender-identified body (which may be distinct from their current body), across a range of gender identities. Measuring the internalized representation of one’s body could be facilitated by technology to visually represent this on a three-dimensional avatar. The technology needed to scan and analyze the human figure is now available and cost efficient. It is now possible to scan individuals to create personalized 3D visualizations, or “avatars,” with which they can interact on mobile and desktop devices to represent internal representation of their bodies. This can allow individuals to see and manipulate their own 3D avatar with a high degree of flexibility. The goal of this project is to create a novel, visually based digital tool to measure, understand, and quantify individuals’ experiences of their bodies. We will develop, validate, and test in transgender, nonbinary, and cisgender adults a personalized avatar tool to represent internalized gender-identified bodies in order to quantify incongruence between this and one’s current body. This tool – “GD Somatomap” – will be an advancement over existing self-report questionnaires to capture visual representations of internalized body image, cross-sectionally and dynamically over time. It will be flexible enough to characterize the heterogenous experiences of a range of gender identities including binary transgender, gender fluid, nonbinary, and cisgender. It can be used in clinical and clinical research applications to track outcomes of cross-hormone and gender-affirming surgical treatments. It can potentially improve clinical outcomes by identifying specific sets of body parts as targets for treatments to improve body congruence. Further, it will provide a unique means to measure own-body perceptual accuracy; understanding differences in perceptual accuracy and what potentially modifiable factors contribute to this may have prognostic significance for treatments to address body incongruence. It could also be used in future studies to investigate functional and structural neurobiological correlates of body perception and internal body representation, and at what point in neurodevelopment these emerge for those with different gender identities. PROJECT NARRATIVE The internalized, conscious experience of one’s body is not easily communicated, much less measured and quantified. This is especially relevant for those with gender dysphoria, whose internal, gender-identified body representation is incongruent with their current body. We will develop and test an innovative technological solution, making use of 3D image reconstruction and advanced 3D modeling, to create personalized avatars to measure body incongruence for research and clinical applications in those with gender dysphoria.",Personalized 3D avatar tool development for measurement of body perception across gender identities,10111313,R21EB030851,"['3-Dimensional', 'Address', 'Adult', 'Area', 'Awareness', 'Birth', 'Body Image', 'Body measure procedure', 'Body part', 'Breast', 'Characteristics', 'Clinical', 'Clinical Research', 'Computer software', 'Conscious', 'Data', 'Development', 'Devices', 'Discriminant Analysis', 'Distress', 'Future', 'Gender', 'Gender Identity', 'Goals', 'Gonadal Steroid Hormones', 'Grouping', 'Hormonal', 'Hormones', 'Human body', 'Individual', 'Intervention', 'Least-Squares Analysis', 'Link', 'Measurement', 'Measures', 'Medical', 'Monitor', 'Neurobiology', 'Operative Surgical Procedures', 'Outcome', 'Patient Self-Report', 'Physical shape', 'Problem Solving', 'Questionnaires', 'Reporting', 'Research', 'Scanning', 'Sex Characteristics', 'Shapes', 'Specific qualifier value', 'Structure', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Time', 'Validation', 'Visual', 'Waist-Hip Ratio', 'base', 'body dissatisfaction', 'cisgender', 'clinical application', 'cost efficient', 'digital', 'dysphoria', 'experience', 'flexibility', 'follow-up', 'gender dysphoria', 'gender fluid', 'high risk', 'image reconstruction', 'improved', 'innovation', 'neurodevelopment', 'novel', 'prognostic significance', 'sex', 'suicidal risk', 'three-dimensional modeling', 'three-dimensional visualization', 'tool', 'tool development', 'transgender', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,203647
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",10083209,U24DK112331,"['ATAC-seq', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Cost efficiency', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Infrastructure', 'Institutes', 'Knowledge', 'Lead', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'analysis pipeline', 'base', 'bisulfite sequencing', 'data exchange', 'data resource', 'epigenomics', 'exercise intervention', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'individual response', 'insight', 'machine learning algorithm', 'medical schools', 'methylome', 'mortality risk', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2021,3913893
"MUFA-SIRT1 signaling as a central node regulating healthspan PROJECT SUMMARY Macronutrients serve a multitude of roles beyond provision of energy, with numerous nutrients and/or their downstream metabolites acting as signaling molecules to coordinate cellular metabolism and function. Indeed, numerous nutrient sensing pathways (e.g. mTOR, AMPK and sirtuins) have evolved allowing us to respond to specific nutrients/metabolites, which in turn impacts healthspan. Sirtuins are largely thought to be driven by redox, whereby high levels of NAD, a cofactor in the sirtuin reaction and indicator of low energy charge, drives sirtuin-catalyzed deacylation of target proteins. SIRT1, the most-studied sirtuin, is a key nutrient sensing node that regulates a plethora of cellular functions to promote lifespan extension and healthy aging. As a result, there is immense interest in the use of SIRT1 activating compounds (STACs) to prevent or treat a wide range of aging-related disease. The links between dietary macronutrients, nutrient sensing and healthspan have historically focused upon caloric or protein restriction with limited attention given to dietary lipids. However, a small and growing body of literature has linked monounsaturated fatty acids (MUFAs) to improved healthspan. In addition to positive effects on lifespan and healthy aging in model organisms, dietary MUFAs have been linked to wide-ranging health benefits in epidemiological studies and, since they are a primary constituent of olive oil, thought to contribute to the benefits of the Mediterranean Diet. Despite these studies, little is known about the biological underpinnings through which MUFAs elicit their beneficial health effects. We have previously shown that lipid droplet catabolism (i.e. lipolysis) increases SIRT1 and downstream PGC-1a/PPAR- a signaling as a means to increase mitochondrial biogenesis and function during times of nutrient deprivation. Our preliminary data show for the first time that MUFAs released specifically from lipolysis are trafficked to the nucleus where they allosterically activate SIRT1 towards select acetylated peptide substrates. This discovery makes MUFAs the first-known endogenous allosteric activators of SIRT1. Moreover, we show that MUFAs activate SIRT1 through a similar mechanism to resveratrol suggesting that MUFA signaling may modulate the response to exogenous SIRT1 activators. Based on these preliminary data, the objective of this application is to further characterize the role of MUFAs as endogenous SIRT1 activators. We hypothesize that MUFAs selectively activate SIRT1 to modulate the response to numerous dietary interventions known to impact healthspan. To test our objective, we propose the following aims: Aim 1: To define how MUFAs modulate SIRT1 substrate selectivity. Aim 2: To characterize the SIRT1-dependent effects of MUFAs/olive oil on healthspan. Aim 3: To determine the contribution of MUFAs in mediating the response to STACs or caloric restriction. Upon completion of the proposes studies, we will have further expanded our understanding of SIRT1 biology allowing for refined approaches to activate SIRT1 to promote healthy aging. NARRATIVE The proposed studies will advance our understanding into the underlying biology linking dietary factors to healthspan. The data gleaned from these studies will help refine therapeutic or nutritional avenues to modulate lifespan and aging-related diseases resulting in a direct, positive impact on human health.",MUFA-SIRT1 signaling as a central node regulating healthspan,10263268,R01AG069768,"['Aging', 'Animal Model', 'Animals', 'Attention', 'Biogenesis', 'Biological', 'Biology', 'Caloric Restriction', 'Catabolism', 'Cell Nucleus', 'Cell physiology', 'Charge', 'Clinical Trials', 'Data', 'Deacetylation', 'Development', 'Diet', 'Dietary Factors', 'Dietary Fats', 'Dietary Intervention', 'Disease', 'Dose', 'FRAP1 gene', 'Fasting', 'Glean', 'Gold', 'Health', 'Health Benefit', 'Human', 'Link', 'Lipids', 'Lipolysis', 'Literature', 'Longevity', 'Machine Learning', 'Macronutrients Nutrition', 'Maps', 'Mediating', 'Mediterranean Diet', 'Metabolism', 'Mitochondria', 'Modeling', 'Monounsaturated Fatty Acids', 'Mus', 'Nutrient', 'Nutritional', 'Oils', 'Olive oil preparation', 'Olives - dietary', 'Outcome', 'Oxidation-Reduction', 'PPAR alpha', 'Pathway interactions', 'Peptides', 'Pharmacologic Substance', 'Proteins', 'Proteomics', 'Reaction', 'Research', 'Resveratrol', 'Role', 'SIRT1 gene', 'Signal Transduction', 'Signaling Molecule', 'Sirtuins', 'Source', 'Testing', 'Therapeutic', 'Time', 'Work', 'analog', 'base', 'cofactor', 'deacylation', 'detection of nutrient', 'dietary', 'epidemiology study', 'healthspan', 'healthy aging', 'improved', 'innovation', 'interest', 'middle age', 'mutant mouse model', 'novel', 'nutrient deprivation', 'polyphenol', 'prevent', 'red wine', 'response']",NIA,UNIVERSITY OF MINNESOTA,R01,2021,317579
"High Throughput Screen and High Information Follow-Up Tests for Genotoxicants Project Summary  Current batteries of genetic toxicology assays exhibit several critical deficiencies. First, the throughput capacity of in vitro genotoxicity tests is low, and does not meet current needs, especially for early, high volume screening environments that need to prioritize chemicals for further testing and/or development. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no information provided about genotoxic mode of action. This is severely limiting, as it does not generate key information necessary for prioritizing chemicals for further testing, guiding subsequent assays’ endpoints/experimental designs, or conducting risk assessments. Finally, most current assays do not place requisite emphasis on dose response relationships, and therefore do not contextualize the results in terms of potency. These deficiencies prevent genotoxicity data from optimally contributing to modern risk assessments, where all of these capabilities and high information content are essential. We will solve these issues by developing, optimizing, and validating a two-tiered testing strategy based on multiplexed DNA damage responsive biomarkers and high-speed flow cytometric analysis. The first-tier focuses on throughput and is used to prioritize likely genotoxicants for more comprehensive analysis in second tier testing. Specifically, it involves a collection of several multiplexed biomarkers that will be used to identify likely genotoxic agents and provide a preliminary assessment of genotoxic mode of action. The gH2AX biomarker detects DNA double strand breaks, phospho-histone H3 identifies mitotic cells, nuclear p53 content reports on p53 activation in response to DNA damage, the frequency of 8n+ cells measure polyploidization, and the ratio of nuclei to microsphere counts provides information about treatment-related cytotoxicity. The second tier focuses on information content and considers many more concentrations as well as additional biomarkers, including micronucleus formation. Collectively, the tier two results provide definitive predictions about test chemicals’ genotoxic potential, mode of action, and potency. Over the course of this project we will study more than 3,000 diverse chemicals in order to understand the performance characteristics and generalizability of the two-tiered testing strategy. An interlaboratory trial will be conducted with prototype assay kits to assess the transferability of the methods, with the ultimate goal of providing the Nation with commercially available kits and testing services. Project Narrative Some chemicals in commercial use and in the environment can cause DNA damage and this damage can contribute to the development of cancer and other severe diseases. We will develop, optimize, and validate an improved testing strategy based on highly automated processes tracking several DNA damage biomarkers that can be analyzed without the need for animal testing. These methods will be configured into commercially available kits and testing services.",High Throughput Screen and High Information Follow-Up Tests for Genotoxicants,10255405,R44ES033138,"['Address', 'Animal Testing', 'Biological Assay', 'Biological Markers', 'Buffers', 'Canada', 'Cell Line', 'Cell Nucleus', 'Cells', 'Characteristics', 'Chemicals', 'Code', 'Collection', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Dose', 'Elements', 'End Point Assay', 'Environment', 'Exhibits', 'Experimental Designs', 'Flow Cytometry', 'Formulation', 'Frequencies', 'Goals', 'Health', 'Histone H3', 'Human', 'In Vitro', 'Industry', 'Logistics', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metabolic Activation', 'Methods', 'Microspheres', 'Miniaturization', 'Mitotic', 'Modeling', 'Modernization', 'Mutagenicity Tests', 'Mutagens', 'National Toxicology Program', 'Nuclear', 'Performance', 'Phase', 'Process', 'Protease Inhibitor', 'Reagent', 'Recommendation', 'Reporting', 'Risk Assessment', 'Sampling', 'Scheme', 'Sensitivity and Specificity', 'Speed', 'Statistical Data Interpretation', 'System', 'TP53 gene', 'Techniques', 'Temperature', 'Testing', 'Time', 'Toxicogenetics', 'Toxicology', 'Training', 'Validation', 'Work', 'base', 'blind', 'cell type', 'climate change', 'computerized tools', 'cytotoxicity', 'design', 'experimental study', 'follow-up', 'genotoxicity', 'high throughput screening', 'improved', 'innovation', 'instrumentation', 'micronucleus', 'phosphatase inhibitor', 'prevent', 'programs', 'prototype', 'response', 'response biomarker', 'screening', 'testing services']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2021,204743
"Reconstruction of heterogeneous and small macromolecules by cyro-EM PROJECT SUMMARY Single-particle electron cryomicroscopy (cryo-EM) has recently joined X-ray crystallography and NMR spectroscopy as a high-resolution structural method for biological macromolecules. In addition, cryo-EM produces images of individual molecules, and therefore has the potential to resolve conformational changes. The proposal aims to develop new algorithms and software for extending the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing computational tools for cryo-EM. This extension requires solving two of the most challenging computational problems posed by cryo-EM. First, mapping the structural variability of macromolecules is widely recognized as the main computational challenge in cryo-EM. Structural variations are of great significance to biologists, as they provide insight into the functioning of molecular machines. Existing computational tools are limited to a small number of distinct conformations, and therefore are incapable of tackling highly mobile biomolecules with multiple, continuous spectra of conformational changes. The first area of investigation in this project is the development of a computational framework to analyze continuous variability. The proposed approach is based on a new mathematical representation of continuously changing structures and its efficient estimation using Markov chain Monte Carlo (MCMC) algorithms. MCMC algorithms have found great success in many other scientific disciplines, yet they have been mostly overlooked for cryo-EM single particle analysis. Second, a major limiting factor for present cryo-EM studies is the molecule size. Images of small molecules (below ~50kDa) have too little signal to allow existing methods to provide valid 3-D reconstructions. It is commonly believed that cryo-EM cannot be used for molecules that are too small to be reliably detected and picked from micrographs. Challenging that widespread belief, the second area of investigation focuses on developing a groundbreaking approach for reconstructing small molecules directly from micrographs without particle picking. The new approach is based on autocorrelation analysis and completely bypasses particle picking and orientation assignment and requires just one pass over the data. The single-pass approach opens new possibilities for real-time processing during data acquisition. PROJECT NARRATIVE Determining structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, and a first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to significantly increase the power of structure-determination using electron cryomicroscopy (cryo-EM). Importantly, our methods will broaden the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing techniques.",Reconstruction of heterogeneous and small macromolecules by cyro-EM,10163220,R01GM136780,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Area', 'Belief', 'Biological', 'Biological Process', 'Bypass', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Cryoelectron Microscopy', 'Crystallization', 'Data', 'Data Set', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Discipline', 'Drug Design', 'Fostering', 'G-Protein-Coupled Receptors', 'Heterogeneity', 'Human Genome', 'Image', 'Individual', 'Institution', 'Investigation', 'Ion Channel', 'Ion Pumps', 'Machine Learning', 'Maps', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mathematics', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Molecular Motors', 'Molecular Weight', 'Motion', 'NMR Spectroscopy', 'Names', 'Noise', 'Particle Size', 'Phase', 'Polymerase', 'Preparation', 'Proteins', 'Pythons', 'Research', 'Resolution', 'Ribosomes', 'Roentgen Rays', 'Sampling', 'Signal Transduction', 'Spliceosomes', 'Structural Protein', 'Structure', 'Techniques', 'Time', 'Uncertainty', 'Update', 'Variant', 'Work', 'X-Ray Crystallography', 'base', 'computer framework', 'computerized data processing', 'computerized tools', 'data acquisition', 'expectation', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'macromolecule', 'molecular mass', 'novel strategies', 'open source', 'particle', 'programs', 'protein complex', 'protein structure', 'receptor', 'reconstruction', 'small molecule', 'statistics', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2021,312940
"Quantitative and Spectroscopic Imaging of Skeletal Muscle Changes in Sarcopenia at High Field Project Summary Sarcopenia, a condition characterized by loss of muscle mass and function in the elderly, is of increasing relevance in the United States due to its aging population. It is generally agreed that the weakening of the muscle in sarcopenia cannot be explained by loss of muscle mass alone, but the mechanisms behind this remain poorly understood. This is partly due to the lack of non-invasive techniques for observing muscle structure and composition in high detail. We propose to develop MRI techniques to measure muscle morphology, microstructure, and fat content to get a detailed view of the changes in muscle quantity and quality in patients with sarcopenia and how they relate to more easily attainable measurements of muscle function such as grip strength and gait speed. This would provide an important contribution to the ongoing debate about how such measurements could be used to define sarcopenia, which would pave the way for treatment development. We aim to develop novel methods to investigate the structure and composition of muscle using ultra-high-field MRI. Specifically, we aim to (1) obtain water-based images of skeletal muscle macro- and microstructure with unparalleled efficiency, image quality, and resolution; (2) obtain images of the spatial distribution of intramyocellular lipids in skeletal muscle, measuring both methyl and methylene to estimate saturation; and (3) to conduct a study comparing skeletal muscle structure and quality by looking at MR measurements of T2 relaxation rates, diffusivity (as proxies for inflammation and fiber size, respectively), fat fraction, and lipid composition, in subjects with sarcopenia and healthy controls and see how these quantities correlate to muscle function. This project has several innovative aspects. First, we will develop a method to estimate muscle morphology, T2 relaxation rates, and diffusivity with a single MRI sequence. Importantly, this will make the developed method easy to run at other MRI sites. Second, we will devise methods to perform robust, efficient imaging of intramyocellular lipid droplet distribution and saturation in human skeletal muscle in vivo at high field. Both of these methods will have unparalleled signal-to-noise ratio and robustness against image artifacts. The significance of this work is the investigation of the role of inflammation, fiber size, and lipid distribution in the weakening of muscle in sarcopenia and how these measurements are related to muscle function. The resulting conclusions and techniques may help establish a common standard for the definition of sarcopenia and aid in the development of future treatments for this condition. Project Narrative Sarcopenia, the loss of muscle mass and function with age, is a condition bound to increase in prevalence with an aging population. The muscle changes involved include not only reduction in mass but also changes in muscle quality not easily visualized with current methods. This work aims to develop efficient MRI techniques to investigate these changes in better detail, improving scientific understanding of the mechanisms of sarcopenia and how they relate to muscle function.",Quantitative and Spectroscopic Imaging of Skeletal Muscle Changes in Sarcopenia at High Field,10125507,K99AG066815,"['3-Dimensional', 'Affect', 'Age', 'Awareness', 'Biological Markers', 'Clinical', 'Communities', 'Consensus', 'Data', 'Development', 'Diagnostic', 'Diffuse', 'Diffusion', 'Elderly', 'Evaluation', 'Fatty acid glycerol esters', 'Fiber', 'Fracture', 'Frequencies', 'Future', 'Gait speed', 'Geriatrics', 'Goals', 'Hand Strength', 'Health', 'Health Personnel', 'Hospitalization', 'Human', 'Image', 'Imaging Techniques', 'Inflammation', 'Investigation', 'Life Expectancy', 'Lipids', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Marker', 'Methods', 'Morphologic artifacts', 'Morphology', 'Muscle', 'Muscle function', 'Muscular Atrophy', 'Noise', 'Patients', 'Phase', 'Physiologic pulse', 'Predisposition', 'Prevalence', 'Protons', 'Proxy', 'Relaxation', 'Research', 'Resolution', 'Role', 'Running', 'Signal Transduction', 'Site', 'Skeletal Muscle', 'Soleus Muscle', 'Spatial Distribution', 'Spectrum Analysis', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Treatment Effectiveness', 'United States', 'Water', 'Work', 'aging population', 'base', 'bone imaging', 'carbene', 'clinical biomarkers', 'design', 'falls', 'imaging biomarker', 'imaging modality', 'improved', 'in vivo', 'innovation', 'muscle form', 'muscle strength', 'muscular structure', 'novel', 'potential biomarker', 'quantitative imaging', 'radio frequency', 'recruit', 'sarcopenia', 'spectroscopic imaging', 'therapy development']",NIA,MASSACHUSETTS GENERAL HOSPITAL,K99,2021,114480
"Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing ABSTRACT No real-time quantitative devices are clinically used to assess oral lesions during routine examination, making in-clinic diagnostic and longitudinal monitoring challenging. Instead, lesions are evaluated through visual inspection and then histopathological analysis of tissue samples extracted during biopsy. Identifying premalignant and malignant oral lesions early is critical to ensuring effective treatment is provided to patients with malignancies. Oral cancer currently has one of the lowest 5-year survival rates (50% or less) among major cancer types, largely due to the challenges in identifying premalignant and malignant lesions early. Clearly, a real-time in-clinic device able to classify oral lesions as benign, premalignant, or malignant has the potential to provide immediate impact to patient care. Significantly different electrical property signatures have been observed between benign and malignant tissues in a variety of organs, including tongue; since the bioelectrical properties are so dependent on tissue architecture and morphology, we hypothesize that sensing and imaging these properties in the context of oral lesions will enable us to accurately characterize and classify morphologically-different benign, premalignant, and malignant oral lesions. We have developed an endoscopic electrical impedance imaging (EII) device for use in intraoperative surgical margin assessment that we aim to optimize for in-clinic oral lesion assessment. We aim to take the significant step of translating our extensive experience in impedance imaging to develop an oral lesion imaging device that can be deployed safely, and in the clinic, to provide real-time feedback regarding oral lesion classification. We propose constructing a novel chip-on-tip EII probe to sense and image at near microscopic resolution oral lesions in an effort to provide clinicians with real-time, accurate classification of oral lesion pathology that can be used for diagnostic and longitudinal monitoring purposes. The probe will be evaluated on a series of in vivo human oral lesions and compared with histopathological analysis of biopsy samples. The low-cost of a device such as this makes it an ideal technology for low-resource settings and the safety and real-time capabilities of the system make it ideal for continuously following lesions. PROJECT NARRATIVE Visual inspection of oral lesions is not sufficient for accurately classifying lesions as benign, premalignant, or malignant. The electrical properties of oral lesion have the potential to be used as a contrast mechanism to accurately classify oral lesions so that optimal treatment can be provided to patients with malignant lesions. We intend to deploy a novel small field of view chip-on-tip electrical impedance imaging (EII) probe in a cohort of patients with oral lesions to evaluate the efficacy of using EII for oral lesion classification.",Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing,10287597,R21DE031095,"['Architecture', 'Area', 'Benign', 'Biological Markers', 'Biopsy', 'Biopsy Specimen', 'Cancerous', 'Carcinoma', 'Carcinoma in Situ', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Contralateral', 'Custom', 'Data', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Dysplasia', 'Electrodes', 'Electronics', 'Ensure', 'Epithelial', 'Excision', 'Feedback', 'Frequencies', 'Hand', 'Histologic', 'Human', 'Hyperplasia', 'Image', 'Imaging Device', 'Ionizing radiation', 'Length', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Microscopic', 'Monitor', 'Morphology', 'Noise', 'Normal tissue morphology', 'Oral Characters', 'Oral cavity', 'Organ', 'Oropharyngeal', 'Pathology', 'Patient Care', 'Patients', 'Positioning Attribute', 'Procedures', 'Property', 'Research Design', 'Resolution', 'Resources', 'Safety', 'Sampling', 'Series', 'Signal Transduction', 'Site', 'Squamous Cell', 'Surgical margins', 'Survival Rate', 'System', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'Tongue', 'Translating', 'Visual', 'analog', 'base', 'bioelectricity', 'cancer type', 'cohort', 'cost', 'design', 'effective therapy', 'efficacy evaluation', 'electric impedance', 'electrical impedance tomography', 'electrical property', 'experience', 'extracellular', 'imaging probe', 'imaging properties', 'in vivo', 'interest', 'malignant mouth neoplasm', 'monitoring device', 'novel', 'optimal treatments', 'oral lesion', 'oral tissue', 'premalignant', 'pressure', 'pressure sensor', 'programs', 'response', 'soft tissue']",NIDCR,DARTMOUTH COLLEGE,R21,2021,191061
"Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0) OVERALL: ABSTRACT  The scope of regenerative medicine encompasses the repair, regeneration, and replacement of defective, injured, and diseased tissues and organs. The success of regenerative therapies is dependent, at least in part, on a favorable microenvironment in which the regenerative processes occur. Technological innovations and a deepened mechanistic understanding of how these microenvironmental signals influence tissue regeneration has drawn attention to the critical importance of the clinical field with foundations in the application of physical, thermal, and electrical stimuli to promote functional restoration—rehabilitation. We propose that the fields of regenerative medicine and rehabilitative science are inextricably intertwined, an intersection of disciplines that we and others have termed Regenerative Rehabilitation. To realize the full potential of Regenerative Rehabilitation, there is a need for formalized mechanisms that promote the interaction of basic scientists with rehabilitation specialists. During the initial funding cycle, the Alliance for Regenerative Rehabilitation Research & Training (AR3T) built a national network of investigators and programs that has helped to expand scientific knowledge, expertise and methodologies across the domains of regenerative medicine and rehabilitation. This proposal seeks funding for AR3T 2.0, in which we will build on successes achieved and lessons learned over the initial period of support with the goal of being even more responsive to the needs of the greater community. Six specific aims define a framework upon which we will achieve our goals. AR3T will provide education and drive the science underlying Regenerative Rehabilitation by: 1) Providing didactic programs that expose rehabilitation researchers to cutting-edge investigations and state-of-the-art technologies in the field of regenerative medicine (Didactic Aim); 2) Cultivating collaborative opportunities between renowned investigators in the fields of regenerative medicine and rehabilitation (Collaborations Aim); 3) Coordinating a pilot funding program to support novel lines of Regenerative Rehabilitation research (Pilot Funding Aim); 4) Developing and validating technologies to advance the measurement and use of the regenerative rehabilitation programs (Technology Aim); 5) Promoting our center’s expertise to a broad community of trainees, investigators, and clinicians (Promotion Aim); 6) Carefully monitoring and evaluating the effectiveness of our program will ensure that we are successful in achieving our goals (Quality Control Aim). Administrative note: In the preparation of this proposal, we made every effort to present a comprehensive and detailed plan for achieving our goals while minimizing redundancy. Therefore, in multiple places, we refer the reader to specific components of the application, rather than repeating text. We appreciate the time and effort the reviewers devote to the evaluation of the proposals.  Sincerely, Fabrisia, Tom and Mike PROJECT NARRATIVE  Regenerative Rehabilitation is the integration of principles and approaches across the fields of rehabilitation science and regenerative medicine. The integration of these two fields will increase the efficiency of interventions designed to optimize physical functioning to the benefit of a wide range of individuals with disabilities. The Alliance for Regenerative Rehabilitation Research & Training (AR3T) 2.0 will build on the momentum gained over the first cycle of funding with the goal of continuing to illuminate and seize opportunities to expand scientific knowledge, expertise and methodologies in the domain of Regenerative Rehabilitation.",Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0),10210417,P2CHD086843,"['Accountability', 'Activities of Daily Living', 'Age', 'Attention', 'Awareness', 'Basic Science', 'Biocompatible Materials', 'Clinical', 'Collaborations', 'Communities', 'Congenital Abnormality', 'Country', 'Data Analyses', 'Development', 'Disabled Persons', 'Discipline', 'Disease', 'Documentation', 'Education', 'Effectiveness', 'Ensure', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'In Vitro', 'Incubators', 'Individual', 'Injury', 'Intervention', 'Investigation', 'Journals', 'Knowledge', 'Laboratories', 'Machine Learning', 'Marketing', 'Measurement', 'Mechanics', 'Mentors', 'Methodology', 'Methods', 'Mission', 'Monitor', 'Natural regeneration', 'Organ', 'Performance', 'Physical Function', 'Pre-Clinical Model', 'Preparation', 'Process', 'Quality Control', 'Reader', 'Regenerative Medicine', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Science', 'Scientist', 'Series', 'Signal Transduction', 'Specialist', 'Stimulus', 'Structure', 'Systems Analysis', 'Technology', 'Text', 'Time', 'Tissues', 'Training', 'Trauma', 'Treatment Efficacy', 'Update', 'career', 'effectiveness evaluation', 'falls', 'functional restoration', 'gait examination', 'healing', 'injured', 'innovation', 'interest', 'investigator training', 'multidisciplinary', 'new technology', 'novel', 'novel strategies', 'pre-clinical', 'programs', 'regenerative', 'regenerative rehabilitation', 'regenerative therapy', 'rehabilitation research', 'rehabilitation science', 'repaired', 'response', 'sabbatical', 'social media', 'success', 'symposium', 'technological innovation', 'therapy design', 'tissue regeneration', 'webinar']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P2C,2021,983634
"Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye Age-related macular degeneration (AMD) is the leading cause of blindness in the elderly in the developed world; no cure exists and prevalence is rising rapidly. Because only primates have a macula and since no model of AMD exists in non-human primates, the disease course can only be elucidated through in-depth study of humans. Blindness in AMD is caused by progressive and irreversible death of rod and cone photoreceptors secondary to degeneration of the retinal pigment epithelium (RPE) that is essential for their health and function. Clinical imaging and histology have informed us greatly about the later stages of disease but fundamental knowledge to understand how AMD diverges from normal aging at onset is lacking. With advanced adaptive optics ophthalmoscopy (AOO) imaging methods, combined with clinical imaging and visual function testing, we will characterize healthy human retinal aging in cross-sectional study, by defining the in vivo RPE-photoreceptor cellular organization and microscopic autofluorescence variation with age and wavelength. This will produce the largest quantitative in vivo normative dataset of AOO cell-based metrics to date and we will use this data to generate new quantitative analysis tools needed to evaluate emerging therapies designed to prevent or slow vision loss in AMD (Aim 1). In a case-control study, we will then compare normal photoreceptor topography and RPE cell morphometry to clinically defined early AMD to quantitatively define the earliest cellular changes in AMD that can be detected in vivo. This work will identify the cellular alterations and phenotypes that differentiate normal aging from early AMD to facilitate early onset detection. These results will be contextualized by comparison to tissue-level alterations seen with aging and early AMD in clinical imaging, specifically choriocapillaris decline and drusen (Aim 2). The results of this study will result in a paradigm shift from the use of clinical diagnosis and classification systems for AMD that rely solely on tissue- level biomarkers or traditional funduscopic clinical signs to those that rely on rigorous quantitative in vivo cell- based metrics. Together, this knowledge and these tools will lay the foundation needed to develop and evaluate new preventative therapies that are needed to limit or prevent vision loss in AMD. Project Narrative Age-related macular degeneration is the leading cause of blindness in the elderly in the US and is a significant public health issue that is projected to worsen due to the rapidly aging population. Here we aim to understand how retinal cells change in normal aging and how these normal age-related changes differ from the changes that lead to age-related macular degeneration. This project will allow us to detect age-related macular degeneration earlier and will produce new tools to monitor retinal cells that will facilitate the development and testing of preventative therapies to slow or prevent vision loss in age-related macular degeneration.",Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye,10172913,R01EY030517,"['Age', 'Age related macular degeneration', 'Aging', 'Area', 'Atrophic', 'Biological Markers', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Case-Control Studies', 'Cells', 'Cessation of life', 'Choroid', 'Classification', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Cross-Sectional Studies', 'Cytoplasmic Granules', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic Procedure', 'Disease', 'Drusen', 'Elderly', 'Evaluation', 'Eye', 'Foundations', 'Genetic', 'Goals', 'Health', 'Histology', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Lead', 'Lipofuscin', 'Machine Learning', 'Maps', 'Melanins', 'Methods', 'Microscopic', 'Modeling', 'Monitor', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Perfusion', 'Phenotype', 'Photoreceptors', 'Prevalence', 'Preventive therapy', 'Preventive treatment', 'Primate Diseases', 'Primates', 'Public Health', 'Retina', 'Retinal Cone', 'Retinal Degeneration', 'Retinal Photoreceptors', 'Risk', 'Secondary to', 'Spatial Distribution', 'Structure', 'Structure of retinal pigment epithelium', 'System', 'Techniques', 'Technology', 'Testing', 'Therapy Evaluation', 'Time', 'Tissues', 'Variant', 'Vertebrate Photoreceptors', 'Vision', 'Work', 'adaptive optics', 'age related', 'aging population', 'base', 'clinical Diagnosis', 'clinical decision-making', 'clinical imaging', 'cohort', 'early onset', 'fluorophore', 'healthy aging', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'macula', 'morphometry', 'multimodality', 'neurovascular unit', 'nonhuman primate', 'normal aging', 'prevent', 'restorative treatment', 'retinal imaging', 'retinal rods', 'therapy design', 'tool']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,524330
"Mechanisms of mechano-chemical rupture of blood clots and thrombi Mechanisms of mechano-chemical rupture of blood clots and thrombi Prashant K. Purohit, John L. Bassani, Valeri Barsegov and John W. Weisel The goal of this proposal is to explore and understand the fracture toughness of blood clots and thrombi, thus providing a mechanistic basis for life-threatening thrombotic embolization. A combination of experiments, theoretical modeling and computer simulations will reveal how mechanical stresses (due to blood flow) in synergy with enzymatic lysis induce structural damage from the molecular to continuum scales and affect the propensity of a clot to embolize. The specific aims of this proposal are: (1) Measure and model fracture toughness of fibrin gels in quasi-static conditions, (2) Investigate rate dependent dissipative effects on toughness of fibrin gels, and (3) Study the effects of blood cells, prothrombotic blood composition, and fibrinolysis on rupture of blood clots. In Specific Aim (SA) 1, we will measure toughness of fibrin clots and provide a structural basis for rupture at the micron and nanometer scales. In SA2, we will delve into the thermodynamics and rate-dependence of the fracture of fibrin gels, including fluid flow through pores and fluid drag on fibrin fibers to capture how energy dissipation increases toughness. In the translational SA3, we will investigate toughness of physiologically relevant clots with effects of platelets, red blood cells, and neutrophils in the absence and presence of the physiological fibrinolytic activator (tPA). We will also study the rupture of clots made from the blood of venous thromboembolism patients to explore the effects of (pro)thrombotic alterations of blood composition on clot mechanical stability. Our preliminary studies show that i) the toughness of cross-linked fibrin gels is in the range of those for synthetic hydrogels, ii) the addition of tPA to a crack tip reduces the loads for crack growth, iii) fibers are aligned and broken along the tensile direction at the crack tip, and iv) crack propagation results from the rupture of covalent and non-covalent bonds. We also developed v) dynamic force spectroscopy in silico to mechanically test fibrin fibers and fibrin networks using pulling simulations and vi) atomic stress approach to map the stress-strain fields using the output from simulations. We will use continuum and finite element models of swellable biopolymer hydrogels, and statistical mechanical models for the forced unfolding of fibrin molecules. We will employ multiscale computational modeling based on Molecular Dynamics simulations of atomic structures of fibrin fibers, and Langevin simulations of fibrin networks accelerated on Graphics Processing Units. The proposed experiments cover the whole gamut of macroscopic tensile tests, shear rheometry, electron microscopy and confocal microscopy to visualize and quantitate the structural alterations of ruptured blood clots. Our experiments and modeling will help us to understand the mechanisms of thrombotic embolization and will address the clinically important question: why is there a strong association between clot structure/mechanical properties and cardiovascular diseases? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering. Project Narrative The research objective of this proposal is to measure, model and predict the mechanisms of mechano-chemical rupture of blood clots and thrombi at the molecular and continuum length scales. Our experiments and modeling will help to understand the mechanisms of embolization and will address the clinically important question: why is there a strong correlation between clot structure/mechanical properties and cardiovascular disease? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering.",Mechanisms of mechano-chemical rupture of blood clots and thrombi,10165811,R01HL148227,"['Address', 'Affect', 'Biocompatible Materials', 'Biological', 'Biomedical Engineering', 'Biopolymers', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood coagulation', 'Blood flow', 'Cardiovascular Diseases', 'Cause of Death', 'Chemicals', 'Clinical', 'Clinical Medicine', 'Coagulation Process', 'Complex', 'Computer Models', 'Computer Simulation', 'Confocal Microscopy', 'Cytolysis', 'Dependence', 'Diagnosis', 'Disease', 'Electron Microscopy', 'Elements', 'Enzymes', 'Erythrocytes', 'Evolution', 'Fiber', 'Fibrin', 'Fibrinogen', 'Fibrinolysis', 'Fracture', 'Frustration', 'Gel', 'Glean', 'Goals', 'Growth', 'Hydrogels', 'Knowledge', 'Laws', 'Length', 'Life', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mechanical Stress', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Molecular Structure', 'Output', 'Patients', 'Physicians', 'Physiological', 'Plasma', 'Predisposition', 'Prevention', 'Process', 'Property', 'Prophylactic treatment', 'Proteins', 'Research', 'Research Proposals', 'Resistance', 'Resources', 'Rupture', 'Specimen', 'Spectrum Analysis', 'Stress', 'Structural Models', 'Structural defect', 'Structure', 'Testing', 'Theoretical Studies', 'Theoretical model', 'Therapeutic Embolization', 'Thermodynamics', 'Thick', 'Thrombin', 'Thromboembolism', 'Thrombosis', 'Thrombus', 'Traction', 'Work', 'base', 'crosslink', 'density', 'design', 'disability', 'experimental study', 'fiber cell', 'fluid flow', 'in silico', 'in vivo', 'insight', 'instrumentation', 'interdisciplinary approach', 'materials science', 'mechanical properties', 'models and simulation', 'molecular dynamics', 'molecular scale', 'multi-scale modeling', 'nanoscale', 'neutrophil', 'novel strategies', 'predictive modeling', 'prevent', 'response', 'simulation', 'synergism', 'theories', 'thrombotic', 'tool', 'venous thromboembolism', 'viscoelasticity']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2021,639595
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),10372242,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,LOVELACE BIOMEDICAL RESEARCH INSTITUTE,P30,2021,373857
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),10173820,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,LOVELACE BIOMEDICAL RESEARCH INSTITUTE,P30,2021,1318547
"Mechanoresponsive Engrailed-1-negative fibroblasts activate Engrailed-1 to promote fibrosis in wound healing 7. Project Summary/Abstract Adult human skin heals by developing fibrotic scar tissue, which can result in devastating disfigurement, growth restriction, and permanent functional loss. Despite a plethora of clinical options, no current treatment strategies successfully prevent or reverse this fibrotic process, and scars and their sequelae cost the United States over $20 billion every year. Progress towards the development of new therapies has been significantly hindered by a lack of understanding of the specific cell populations responsible for scarring. In 2015, our group reported that Engrailed-1 (En-1) lineage-positive fibroblasts (EPFs) are responsible for the vast majority of dorsal scar production in postnatal mice. In early fetal gestation, mice heal scarlessly via skin regeneration, an ideal outcome mediated by En-1 lineage-negative fibroblasts (ENFs; the predominant fetal fibroblast). However, it has not been established if ENFs contribute to postnatal wound healing. In this proposal, we explore for the first time the postnatal conversion of ENFs to pro-fibrotic EPFs (postnatally-derived EPFs; pEPFs) within the wound environment. First, histology, immunohistochemistry, and wounding in a novel transgenic mouse model will be used to study the conversion of ENFs to pEPFs during wound healing. By examining the behavior of ENF subpopulations (derived from papillary dermis, reticular dermis, and hypodermis) in the wound environment and confirming our findings in a tamoxifen-inducible mouse model of En-1 activation, we will precisely define the ENF population that gives rise to pro-fibrotic pEPFs. Second, we will establish the specific wound environment cues that drive ENF-to-EPF transition. Given that mechanical forces are known to modulate both scar burden and fibroblast activity, we will use in vitro and in vivo models to examine the effects of mechanical environment on En-1 activation. We will further use transcriptomic and epigenomic profiling to explore the role of mechanotransduction signaling in ENF-to-EPF transition and pEPF function. Third, having established a mechanotransduction mechanism underlying En-1 activation in wound ENFs, we will inhibit mechanotransduction signaling with the goal of blocking ENF-to-EPF transition. Specifically, we will assess whether blocking mechanotransduction results in ENF-mediated wound healing with reduced fibrosis. Our ultimate translational goal is to develop therapeutics that target fibrogenic fibroblasts to promote regenerative healing. Collectively, the proposed work will significantly enhance our understanding of the key molecular and cellular determinants of cutaneous scarring, inform the development of novel anti-scarring therapies, and shed light on the cellular origin of dermal scarring fibroblasts. 8. Project Narrative Scarring is the end result of injury in adult human skin and results in an enormous financial and medical burden for our society. There are currently no effective molecular therapies that prevent scarring or its sequelae, and development of therapeutics has been hindered by lack of understanding of the precise cell populations that mediate fibrosis in wound healing. Therefore, we propose to explore the contribution of a specific fibroblast subpopulation (Engrailed-1 lineage-negative fibroblasts; ENFs) in fibrotic wound healing, in order to inform novel directions for targeted treatments that minimize scarring and promote regenerative wound healing.",Mechanoresponsive Engrailed-1-negative fibroblasts activate Engrailed-1 to promote fibrosis in wound healing,10130573,R01GM136659,"['3-Dimensional', 'Adult', 'Algorithms', 'Anatomic Surface', 'Behavior', 'Cells', 'Cellular Assay', 'Characteristics', 'Chemicals', 'Chromatin', 'Cicatrix', 'Clinical', 'Collagen', 'Connective Tissue', 'Cues', 'Cultured Cells', 'Cutaneous', 'Data', 'Dermal', 'Dermis', 'Development', 'Dipeptidyl-Peptidase IV', 'Dorsal', 'Elements', 'Engraftment', 'Environment', 'Extracellular Matrix', 'Fiber', 'Fibroblasts', 'Fibrosis', 'Fluorescence-Activated Cell Sorting', 'Focal Adhesion Kinase 1', 'Genetic Transcription', 'Goals', 'Growth', 'Hair follicle structure', 'High-Throughput Nucleotide Sequencing', 'Histologic', 'Histology', 'Hydrogels', 'Immunohistochemistry', 'In Vitro', 'Individual', 'Injury', 'Light', 'Maps', 'Measures', 'Mechanical Stress', 'Mechanics', 'Mediating', 'Medical', 'Microscopy', 'Molecular', 'Morbidity - disease rate', 'Mus', 'Outcome', 'Papillary', 'Pathway interactions', 'Population', 'Pregnancy', 'Process', 'Production', 'Protein Inhibition', 'Proteins', 'Reporting', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Skin', 'Societies', 'Specimen', 'Subcutaneous Tissue', 'Surface', 'Tamoxifen', 'Time', 'Tissues', 'Transgenic Mice', 'Transposase', 'United States', 'Verteporfin', 'Visual', 'Wild Type Mouse', 'Work', 'analog', 'base', 'cost', 'digital', 'epigenomics', 'experimental study', 'fetal', 'functional loss', 'healing', 'in vivo', 'in vivo Model', 'inhibitor/antagonist', 'machine learning algorithm', 'mechanical force', 'mechanotransduction', 'mortality', 'mouse model', 'novel', 'novel therapeutics', 'postnatal', 'prevent', 'reconstruction', 'regenerative', 'response', 'single-cell RNA sequencing', 'skin regeneration', 'skin wound', 'therapeutic development', 'therapeutic target', 'tissue culture', 'tool', 'transcriptomics', 'treatment strategy', 'wound', 'wound bed', 'wound environment', 'wound healing']",NIGMS,STANFORD UNIVERSITY,R01,2021,317427
"Immune Basis & Clinical implications of Threshold-Based Phenotypes of Peanut Allergy Summary: Immune Basis and Clinical Implications of Threshold-Based Phenotypes of Peanut Allergy Peanut allergy (PA) is common, affecting 2-5% of school-age children in the US. The characteristics of PA vary widely among individuals, with some reacting to 1/100th of a peanut and others not having symptoms until they have ingested many peanuts. Symptoms can vary from mild rashes to fatal anaphylaxis. There is no FDA- approved treatment, and all patients with PA are managed with strict allergen avoidance. Most research on PA has focused on those with the most exquisite sensitivity to peanut. Immunotherapy trials commonly exclude subjects with a threshold dose over 1/3 of a peanut (100mg). However, most individuals with PA have higher thresholds of reaction and are excluded from current research approaches. We hypothesize that the natural heterogeneity of PA is a valuable opportunity for investigation. We have shown that milk or egg allergic individuals with tolerance to baked forms of these foods not only tolerate their inclusion in the diet, but this exposure increases the rate of resolution 14-16-fold. We hypothesize that dietary exposure to sub-threshold levels of peanut in those with higher threshold levels of reactivity could lead to significant clinical improvement. Furthermore, studying the natural heterogeneity of PA is a valuable opportunity to elucidate mechanisms of disease. To study the clinical implications and mechanism of phenotypic heterogeneity in PA, we will conduct a randomized open feeding trial (CAFETERIA trial) to investigate a prototype approach where children with moderate PA (tolerating at least 100 mg of peanut) ingest a sub-threshold amount daily, with increasing levels tested every 3 months. The impact of dietary intervention will be tested at 1 and 2 years by oral food challenge. The CAFETERIA study will provide a rich biorepository of samples from highly phenotyped subjects. We anticipate screening 200-250 subjects, including low threshold, high threshold, and sensitized but not allergic, in order to enroll 98 subjects that meet the high threshold criteria for the CAFETERIA trial. We will obtain longitudinal samples from subjects randomized to dietary therapy or avoidance. We will comprehensively profile antibody responses by high-throughput epitope assay, peanut-specific T cell responses by flow cytometry, and whole blood activation by CyTOF to construct a detailed clinical-immune network of PA, and analyze the relationship between immune and clinical parameters. We will identify biomarkers and key causal drivers of PA by performing integrated network-based examination of peripheral blood transcriptomes from PA subjects, sampled before and after food challenge, and before and after dietary therapy. Successful completion of these aims will result in (1) a simple low-cost treatment option applicable to the majority of those with PA; (2) an identification of immune and molecular mechanisms of PA and response to dietary therapy; (3) peripheral blood biomarkers that will practically impact clinical care of PA; (4) the potential for personalized approaches to the treatment of PA; and (5) a tremendously rich resource of clinical, immune, and transcriptional data and analytic tools to be made publicly available to the research community. NARRATIVE This AADCR Center will investigate threshold-based phenotypic heterogeneity of peanut allergy. We will focus on an under-studied high-threshold phenotype of peanut allergy, and examine the impact of dietary therapy with sub-threshold amounts of peanut. We will use this clinically diverse cohort to perform high dimensional profiling in order to elucidate immune and molecular mechanisms of allergy and tolerance to peanut.",Immune Basis & Clinical implications of Threshold-Based Phenotypes of Peanut Allergy,10167620,U19AI136053,"['Affect', 'Allergens', 'Allergic', 'Allergy to eggs', 'Allergy to peanuts', 'Anaphylaxis', 'Antibodies', 'Antibody Response', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Biology', 'Characteristics', 'Child', 'Clinical', 'Clinical Data', 'Communities', 'Computational Biology', 'Data', 'Diet', 'Diet therapy', 'Dietary Intervention', 'Disease', 'Dose', 'Economic Burden', 'Enrollment', 'Epitopes', 'Exanthema', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Food', 'Food Hypersensitivity', 'Funding', 'Genetic Transcription', 'Genomics', 'Goals', 'Heterogeneity', 'Hypersensitivity', 'IgE', 'Immune', 'Immunologics', 'Immunology', 'Individual', 'Ingestion', 'Investigation', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Medical', 'Milk', 'Milk Hypersensitivity', 'Molecular', 'Network-based', 'Nutritional', 'Oral', 'Patients', 'Persons', 'Phase III Clinical Trials', 'Phenotype', 'Predictive Value', 'Proteins', 'Protocols documentation', 'Quality of life', 'Randomized', 'Reaction', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Schedule', 'School-Age Population', 'Severities', 'Speed', 'Symptoms', 'T cell response', 'T-Lymphocyte', 'Testing', 'Treatment Cost', 'Urticaria', 'Visit', 'Whole Blood', 'allergic response', 'analytical tool', 'base', 'biobank', 'biomarker identification', 'clinical care', 'clinical practice', 'cohort', 'cost', 'data tools', 'desensitization', 'dietary', 'egg', 'feeding', 'food allergen', 'food challenge', 'high dimensionality', 'immunotherapy trials', 'individualized medicine', 'intervention cost', 'learning network', 'neglect', 'oral diagnostics', 'oral immunotherapy', 'outcome prediction', 'peripheral blood', 'personalized approach', 'prototype', 'response', 'screening', 'transcriptome']",NIAID,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U19,2021,1524872
"Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics Project Summary/Abstract Viral genome sequencing is growing exponentially and cutting-edge molecular technologies, guided by genomic data, show great promise in detecting and responding to viruses. Yet we lack a computational framework that efficiently leverages viral data to design the nucleic or amino acid sequences applied by these technologies. The proposal provides a career development plan to (i) build computational techniques — algorithms, models, and software — that yield highly accurate diagnostic assays, with potential to outperform existing ones, and (ii) use the techniques to proactively design assays for detecting 1,000s of viruses. The project will first develop methods for designing optimal viral genome-informed diagnostics. The study will formulate objective functions that evaluate an assay’s performance across a distribution of anticipated viral targets. Combinatorial optimization algorithms and generative models, constructed in the study, will optimize the functions. The project will also develop datasets for training predictive models of assay performance, which are used in the objective functions, focusing on CRISPR-, amplification-, and antigen-based diagnostics. Preliminary experimental results suggest such models can render assays with exquisite sensitivity and specificity. The study will compare the algorithmically-designed assays to state-of-the-art tests for four viruses. With these methods, the project will design diagnostic assays that are species-specific and broadly effective across genomic diversity for all viruses known to infect vertebrates. The study will build a system to monitor the assays’ effectiveness against emerging viral genomic diversity and to continually update them as needed. To enable the broad adoption of these methods, the project will implement them efficiently in accessible software. The proposal aligns with a NIAID goal of improving diagnostics via data science. The methods developed here may also aid therapy and vaccine design, and will leave the world better prepared to combat viral outbreaks. The career development award will provide training for the candidate in applied areas of long-term interest to his career. The candidate has previous experience in developing computational methods and analyzing viral genomes. Through the award, he will gain new knowledge and skills in diagnostic applications, alongside formal and informal training in immunology, bioengineering, and related laboratory techniques. This training will help the candidate progress toward therapy and vaccine applications that could benefit from advanced computational methods. The Broad Institute provides a supportive environment for the candidate’s development, including career development workshops, research seminars aligned with the proposed plan, and opportunities to initiate collaborations with scientists having expertise complementary to the candidate’s. The research and training will help him form an independent research group focused on developing and applying computational methods to enable more effective microbial surveillance and response. Project Narrative Viral genomic data is reshaping how we prepare for and respond to viral threats, but there is a scarcity of computational techniques that harness this vast, ever-growing data for designing diagnostic assays. The project will develop and test algorithms, machine learning models, and software systems to efficiently design highly accurate diagnostic assays by optimizing well-defined objective functions, applied to multiple diagnostic technologies, and will build a resource of broadly effective diagnostic assays for 1,000s of viral species. The resource and software developed in the project will advance capabilities for detecting viruses, and the new methods may accommodate challenges in designing more effective viral therapies and vaccines.",Computational Methods for Designing Optimal Genomics-guided Viral Diagnostics,10284445,K01AI163498,"['2019-nCoV', 'Adoption', 'Algorithm Design', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Award', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Models', 'Biology', 'Biomedical Engineering', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Combinatorial Optimization', 'Computational Technique', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Dengue', 'Detection', 'Development', 'Development Plans', 'Diagnostic', 'Disease Outbreaks', 'Educational workshop', 'Effectiveness', 'Ensure', 'Failure', 'Focus Groups', 'Genome', 'Genomics', 'Goals', 'Growth', 'Immunology', 'Influenza', 'Institutes', 'K-Series Research Career Programs', 'Knowledge', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'National Institute of Allergy and Infectious Disease', 'Nucleic Acids', 'Performance', 'Research', 'Research Training', 'Resolution', 'Resources', 'Scientist', 'Sensitivity and Specificity', 'Software Tools', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Validation', 'Variant', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'ZIKA', 'accurate diagnostics', 'advanced analytics', 'antigen diagnostic', 'base', 'career', 'career development', 'combat', 'computer framework', 'design', 'detection assay', 'diagnostic assay', 'diagnostic technologies', 'enzyme activity', 'experience', 'genome sequencing', 'genomic data', 'improved', 'insight', 'interest', 'microbial', 'model design', 'pathogen', 'predictive modeling', 'predictive test', 'prevent', 'response', 'skills', 'software development', 'software systems', 'spatiotemporal', 'success', 'supportive environment', 'therapy design', 'viral genomics']",NIAID,"BROAD INSTITUTE, INC.",K01,2021,129165
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10202460,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2021,749956
"HABIT DESIGN: TESTING A NOVEL BEHAVIORAL APPROACH TO CORPORATE WELLNESS IN THE CONTEXT OF METABOLIC SYNDROME Abstract Metabolic syndrome (MetS) is a constellation of risk factors– elevated triglycerides (TG), insufficient high- density lipoprotein cholesterol (HDL-C), elevated blood pressure (BP), elevated fasting blood glucose (FBG), and above-threshold waist circumference (WC)–that is associated with increased cardiovascular disease, type 2 diabetes mellitus, and some forms of cancer. Research suggests that addressing MetS through the workplace could significantly benefit employee health and employer healthcare costs. Habit Design, Inc., has developed an enhanced behavioral health coaching system called Habit Design (HD) that is the first to integrate habit formation, contingency management, and social learning approaches within a smartphone app to support to behavior change in corporate or employee health contexts. In this Fast Track project, we will adapt the HD approach to address MetS. In Phase I, we will 1) refine and extend existing functional prototypes of the HD app to support the latest versions of iOS and Android, 2) conduct usability testing with 8 targeted end users, and 3) prepare standard treatment manuals for the Phase II clinical trial. In Phase II, we will 1) make indicated changes to the HD app based on findings from the Phase I usability test and 2) evaluate the effectiveness of HD coaching compared to standard health coaching in a randomized trial with 424 corporate wellness program participants who have MetS, with follow-up spanning one year. Participants will employees of TriHealth in Cincinnati who have completed a health screening as part of their corporate wellness program and been identified as having at least 3/5 of the following: 1) TG ≥150 mg/dL), 2) HDL-C <40 mg/dL in males and <50 mg/dL in females, 3) BP ≥130/85 mm Hg, 4) FBG ≥100 mg/dl, and 5) WC ≥102 cm in males and ≥80 cm in females.. All participants will be coached to increase physical activity, which will be monitored with a waist-worn FitBit and Fitabase software. Additionally, participants will choose prior to randomization a goal of increasing fruit and vegetable intake or substituting water for sugar-sweetened beverages. Conditions will be stratified by choice of goal and gender. In both conditions coaching will be monitored for fidelity and delivered in 12 weekly in-person 30-minute sessions followed by one 30-minute maintenance session per month for 4 months. The primary outcome will be average daily step count measured over the course of at least one week at baseline, 4 months, 8 months, and 12 months. The secondary outcome will be standard units increase of fruit/vegetable intake or water intake, according to the participant's choice. Tertiary outcomes will consist of FBG, TG, HDL, BP, WC, and body mass index, measured at each time point. Additionally, we will conduct web-based assessment of self-reported physical activity, junk food, and sugar-sweetened beverage consumption; automaticity of exercise and fruit, vegetable, and water consumption; self-efficacy and social support for target behaviors; and health-related quality of life. Ratings of usability and satisfaction and app usage metrics will be examined. Analyses will be intent-to-treat assuming 15% loss to follow-up. Project Narrative/Relevance Metabolic syndrome is a major public health problem that affects over one in three American adults and increases the risk of cardiovascular disease, type 2 diabetes, and some forms of cancer. Habit Design, Inc., has developed an integrated health coaching system that uses a smartphone app to promote healthy behaviors. We will adapt it for metabolic syndrome and evaluate its effectiveness in a corporate health setting.",HABIT DESIGN: TESTING A NOVEL BEHAVIORAL APPROACH TO CORPORATE WELLNESS IN THE CONTEXT OF METABOLIC SYNDROME,10210291,R44HL142328,"['Address', 'Adherence', 'Adult', 'Affect', 'American', 'Android', 'Behavior', 'Behavioral', 'Behavioral Model', 'Blood Glucose', 'Blood Pressure', 'Body mass index', 'Cardiovascular Diseases', 'Central obesity', 'Chronic', 'Companions', 'Computer software', 'Consumption', 'Cues', 'Development', 'Effectiveness', 'Employee', 'Employee Health', 'Environment', 'Exercise', 'Fasting', 'Feedback', 'Female', 'Food', 'Fostering', 'Gender', 'Goals', 'Habits', 'Health', 'Health Care Costs', 'Health behavior', 'High Density Lipoprotein Cholesterol', 'High Density Lipoproteins', 'Hypertension', 'Hypertriglyceridemia', 'Intake', 'Intervention', 'Link', 'Location', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Metabolic syndrome', 'Modeling', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Participant', 'Patient Self-Report', 'Persons', 'Phase', 'Phase II Clinical Trials', 'Physical activity', 'Psychological reinforcement', 'Psychology', 'Public Health', 'Randomized', 'Randomized Controlled Trials', 'Research', 'Rewards', 'Risk Factors', 'Science', 'Self Efficacy', 'Social support', 'System', 'Telephone', 'Test Result', 'Testing', 'Time', 'Translating', 'Triglycerides', 'Water', 'Water consumption', 'Wellness Program', 'Workplace', 'base', 'behavior change', 'behavioral health', 'cardiovascular disorder risk', 'contingency management', 'crowdsourcing', 'design', 'effectiveness evaluation', 'experience', 'financial incentive', 'fitbit', 'follow-up', 'fruits and vegetables', 'health related quality of life', 'improved', 'innovation', 'male', 'mobile computing', 'novel', 'peer coaching', 'peer support', 'primary outcome', 'programs', 'prototype', 'randomized trial', 'satisfaction', 'screening', 'secondary outcome', 'smartphone Application', 'social learning', 'standard care', 'sugar', 'sweetened beverage', 'usability', 'waist circumference', 'web-based assessment']",NHLBI,"HABIT DESIGN, INC.",R44,2021,725892
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,10158538,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2021,93342
"A Chatbot Utilizing Machine Learning and Natural Language Processing to Implement the Brief Negotiation Interview to Improve Engagement in Buprenorphine Treatment among Justice-Involved Individuals Project Summary/Abstract This Administrative Supplement proposes the participation of a 3-member team from the Center for Progressive Recovery, LLC (CPR) in the Innovation Corps (I-Corps™), an intensive, 8-week program focused on developing a successful commercialization plan and business model for technology-driven start-ups funded by NIH’s SBIR Phase I mechanism. The program would entail training, as well as structure and accountability around conducting 100 interviews with key stakeholders and others whose expertise would inform the company’s plans. The SBIR Phase I award to CPR (the small business concern, SBC) that this application is predicated on addresses the problem that the people at the greatest risk of dying from an opioid overdose are the least likely to get life-saving medication. Justice- involved individuals coming out of prison have the highest risk of death by overdose (8x greater than the general population), yet only 1 in 20 of these individuals receive buprenorphine (bup), a safe, effective medication that has been shown to reduce a person’s risk of death by overdose by half. There is an urgent need to facilitate an increase in bup treatment engagement among these individuals. Two of the top barriers to receiving bup for this population are 1) system level barriers and, 2) low levels of individual motivation. We will disrupt system level barriers by circumventing the pieces of the probation system that are stigmatizing and reduce the chances of a bup referral with an artificial intelligence (AI)-based chatbot. This will be the only tool needed to receive a referral to a bup provider. We will also address low individual motivation with the chatbot by programming it to deliver the efficacious Brief Negotiation Interview (BNI) without the need for a trained human. Our aims are: Aim 1: Design and develop a prototype chatbot to motivate bup engagement. Milestones: (a) human-centered design (HCD) interviews with key stakeholders; and (b) creation of a chatbot using machine learning (ML) and natural language processing (NLP) that is integrated with a mobile application; Aim 2: Conduct a 4-week pilot study with 60 probationers randomly assigned to the BNI Chatbot or Digital Resources (i.e., Digitally-delivered OUD and buprenorphine education and referral resources). The following 3-member team has deep expertise in developing and bringing to market digital health solutions and was formed to pursue the unique benefits of the I-Corps program. All 3 are able to meet the time-intensive requirements of the training program: 1) Michael V. Pantalon, Ph.D., CEO; 2) Marianne S. Pantalon, Ph.D., PI, and 3) Thomas Wheeler, Industry Expert and CTO. With this sophisticated program, CPR would be in a much better position to secure SBIR Phase II funding. Project Narrative This Administrative Supplement proposes the participation of a 3-member team from the Center for Progressive Recovery, LLC (CPR) in the Innovation Corps (I-Corps™), an intensive, 8-week program focused on developing a successful commercialization plan and business model for technology-driven start-ups funded by NIH’s SBIR Phase I mechanism. The program would entail training, as well as structure and accountability around conducting 100 interviews with key stakeholders and others whose expertise would inform the company’s plans. The specific aims of the SBIR Phase I awarded to CPR (the small business concern) that this application is predicated on are: 1) to design and develop a prototype of an AI-powered Brief Negotiation Interview Chatbot to motivate probationers (who have among the highest rates of death by opioid overdose) to engage in buprenorphine, a treatment that reduces overdoses by half, and 2) to conduct a 4-week pilot study with 60 probationers randomly assigned to the BNI Chatbot or Digital Resources.",A Chatbot Utilizing Machine Learning and Natural Language Processing to Implement the Brief Negotiation Interview to Improve Engagement in Buprenorphine Treatment among Justice-Involved Individuals,10304214,R43DA051267,"['Accountability', 'Address', 'Administrative Supplement', 'Artificial Intelligence', 'Award', 'Buprenorphine', 'Businesses', 'Death Rate', 'Doctor of Philosophy', 'Education', 'Funding', 'General Population', 'Human', 'Individual', 'Industry', 'Innovation Corps', 'Interview', 'Justice', 'Life', 'Machine Learning', 'Mediation', 'Modeling', 'Motivation', 'Natural Language Processing', 'Overdose', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Prisons', 'Provider', 'Randomized', 'Recovery', 'Resources', 'Risk', 'Savings', 'Secure', 'Small Business Innovation Research Grant', 'Stigmatization', 'Structure', 'System', 'Technology', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'base', 'buprenorphine treatment', 'chatbot', 'commercialization', 'design', 'digital', 'digital health', 'high risk', 'improved', 'member', 'mobile application', 'mortality risk', 'opioid mortality', 'opioid overdose', 'overdose death', 'probation', 'probationer', 'programs', 'prototype', 'system-level barriers', 'tool']",NIDA,"CENTER FOR PROGRESSIVE RECOVERY, LLC",R43,2021,55000
"OpenMM: Scalable biomolecular modeling, simulation, and machine learning PROJECT SUMMARY / ABSTRACT OpenMM [http://openmm.org] is the most widely-used open source GPU-accelerated framework for biomolecular modeling and simulation (>1300 citations, >270,000 downloads, >1M deployed instances). Its Python API makes it widely popular as both an application (for modelers) and a library (for developers), while its C/C++/Fortran bindings enable major legacy simulation packages to use OpenMM to provide high performance on modern hardware. OpenMM has been used for probing biological questions that leverage the $14B global investment in structural data from the PDB at multiple scales, from detailed studies of single disease proteins to superfamily-wide modeling studies and large-scale drug development efforts in industry and academia. Originally developed with NIH funding by the Pande lab at Stanford, we aim to fully transition toward a community governance and sustainable development model and extend its capabilities to ensure OpenMM can power the next decade of biomolecular research. To fully exploit the revolution in QM-level accuracy with machine-learning (ML) potentials, we will add plug-in support for ML models augmented by GPU-accelerated kernels, enabling transformative science with QM-level accuracy. To enable high-productivity development of new ML models with training dataset sizes approaching 100 million molecules, we will develop a Python framework to enable OpenMM to be easily used within modern ML frameworks such as TensorFlow and PyTorch. Together with continued optimizations to exploit inexpensive GPUs, these advances will power a transformation within biomolecular modeling and simulation, much as deep learning has transformed computer vision. PROJECT NARRATIVE Biomolecular modeling and simulation is a key technology for leveraging the $14B global investment in biomolec- ular structure data in the protein databank to understand the basic molecular mechanisms underlying biology and disease and the development of new therapies. In this proposal, we aim to expand the development of OpenMM, a free and open source biomolecular modeling and simulation package that can exploit a wide range of consumer-grade and high-end graphics processing units (GPUs) to enable researchers and applications built on OpenMM to achieve high performance with extreme ﬂexibility. A key aspect of this proposal is to accelerate research in the emerging ﬁeld of biomolecular machine learning by tightly integrating OpenMM with modern ma- chine learning frameworks, enabling researchers to build, use, and deploy machine learning potentials, collective variables, and integrators to advance the state of biomolecular modeling.","OpenMM: Scalable biomolecular modeling, simulation, and machine learning",10100573,R01GM140090,"['Academia', 'Architecture', 'Automobile Driving', 'Binding', 'Biological', 'Biological Process', 'Biological Response Modifier Therapy', 'Biology', 'Chemical Models', 'Chemicals', 'Chemistry', 'Code', 'Communities', 'Computer Vision Systems', 'Custom', 'Data', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Home environment', 'Hybrids', 'Industry', 'Investigation', 'Investments', 'Laboratories', 'Learning', 'Libraries', 'Ligands', 'Machine Learning', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Conformation', 'Performance', 'Plug-in', 'Productivity', 'Proteins', 'Pythons', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Speed', 'Standardization', 'Structure', 'Study models', 'Sustainable Development', 'System', 'Technology', 'TensorFlow', 'Training', 'United States National Institutes of Health', 'Update', 'Work', 'cluster computing', 'deep learning', 'deep neural network', 'drug development', 'enzyme mechanism', 'flexibility', 'insight', 'interoperability', 'model development', 'models and simulation', 'molecular mechanics', 'next generation', 'novel therapeutics', 'open source', 'operation', 'physical model', 'predictive modeling', 'protein data bank', 'quantum', 'repository', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2021,426294
"Automated Assessment for Robotic Suturing Utilizing Deep Learning Algorithms ABSTRACT Medical errors are the third leading cause of death in the US at a cost of $20 billion annually. Surgical complications account for a third of these deaths and cost. Surgical performance directly impacts patient outcomes. Prostate cancer, the most common cancer in men, is treated with surgery (robot-assisted radical prostatectomy (RARP)) that can lead to impotence, incontinence, and even death. Reliable means of objectively assessing technique are required. In this project we will focus on assessing surgeon suturing skills during RARP through virtual reality (VR) simulation. Suturing is a common skill in many types of surgeries, can be tracked with performance metrics, and has been correlated with patient outcomes after RARP. In this proposal we seek to first determine the critical sub-step maneuvers of suturing and the technical skills necessary to achieve them successfully (Aim 1a). Further, we intend to develop an automated skills assessment pipeline through the analysis of raw kinematic data (Aim 1b), video (Aim 2b), and both kinematic/video (Aim 2c), from VR simulation performance by innovative machine learning strategies and deep-learning-based computer vision. The primary differentiator of the proposed work is determining how well granular sub-step maneuvers in suturing are performed. Surgeons participating in this study will not only provide data through their VR simulation performance, but will also contribute real patient data from the RARP to establish the relationship between surgeon skill, patient factors, and surgical outcomes. Statistical modeling will measure the differential impact of surgeon skill and patient factors to patient outcomes (Aim 3). We hypothesize that innovative application of machine learning algorithms can accurately assess surgeon technical skills, and can further anticipate likelihood of relevant clinical outcomes. The proposed work will enable scalable and actionable feedback in VR, empowering surgeons with valuable knowledge to minimize surgical risk in live surgery. NARRATIVE Surgical performance directly impacts patient outcomes. Prostate cancer, the most common cancer in men, is treated with surgery (robot-assisted radical prostatectomy (RARP)) that can lead to impotence, incontinence, and even death. Reliable means of objectively assessing robotic surgical skills are required. The proposed work will automate technical skills assessment, empowering surgeons with valuable knowledge to minimize prostatectomy surgical risk.",Automated Assessment for Robotic Suturing Utilizing Deep Learning Algorithms,10208178,R01CA251579,"['Address', 'Assessment tool', 'Automobile Driving', 'Behavior', 'Benchmarking', 'Bladder Control', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Computer Vision Systems', 'Consequentialism', 'Consumption', 'Data', 'Data Set', 'E-learning', 'Environment', 'Exercise', 'Feedback', 'Foundations', 'Gestures', 'Impotence', 'Incontinence', 'Knowledge', 'Label', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Maps', 'Measurable', 'Measures', 'Medical Errors', 'Methods', 'Modality', 'Modeling', 'Motion', 'Movement', 'Needles', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Positioning Attribute', 'Prostatectomy', 'Publishing', 'Quality of life', 'Radical Prostatectomy', 'Recovery', 'Recurrence', 'Risk', 'Robotics', 'Statistical Models', 'Surgeon', 'Surgical Error', 'Surgical Specialties', 'Surgical complication', 'Surgical sutures', 'Technical Expertise', 'Techniques', 'Technology', 'Time', 'Tissues', 'Training', 'Travel', 'Vision', 'Work', 'base', 'clinically relevant', 'cognitive task', 'cost', 'deep learning', 'deep learning algorithm', 'empowered', 'improved', 'innovation', 'instrument', 'kinematics', 'learning network', 'learning strategy', 'machine learning algorithm', 'men', 'multimodal data', 'novel', 'operation', 'predictive modeling', 'prospective', 'robot assistance', 'skills', 'surgery outcome', 'surgical risk', 'task analysis', 'virtual coach', 'virtual reality', 'virtual reality simulation', 'virtual reality simulator']",NCI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2021,693355
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876
"Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization PROJECT SUMMARY Assisted Reproduction Technology (ART) is a clinical treatment for infertile couples who want to achieve a pregnancy. In ART, embryologists fertilize eggs retrieved from the patient or a donor, culture the resulting embryos in vitro, and then transfer the selected embryo(s) to the mother's uterus. While ART is responsible for 1.9% of babies born in the United States as of 2018, selecting which embryo to transfer is a signiﬁcant challenge. The difﬁculty comes from the complexity of confounding factors and the lack of understanding of human pre-implantation embryo development. Because of this difﬁculty, multiple embryos are often transferred to increases the potential of success, resulting in multiple pregnancy rates of nearly 20%, which can lead to signiﬁcant morbidity and medical expenses to patients. The ideal is to transfer only a single embryo, but this necessitates the ability to select the best embryo from a cohort. Here, we propose to create a clinical decision support system to improve embryo selection in ART. To this end, we will develop novel deep learning models for robust embryo feature extraction and interactive data visualization methods for human-in-the-loop analysis. We will ﬁrst extract and analyze visual features from routinely collected images of embryos. We will then combine these visual features with patients' electronic health record (EHR) data to develop interpretable computation models that score embryos on their viability. We plan to integrate our machine learning solutions into an easily accessible cloud service platform that will be adaptable across clinics to improve ART embryo selection and clinical data analysis. Our research goals will be achieved by novel machine learning-based models for morphological feature extrac- tion and importance estimation of each confounding factor and a clinical decision support system for ART. For morphological feature extraction, we plan to conduct semi-supervised learning of convolutional neural networks to minimize manual labeling that requires extensive human effort. Our feature extraction model will be the ﬁrst comprehensive classiﬁcation and segmentation method for ART. To aid in embryo selection, we will develop novel deep learning-based models to predict probabilities of achieving pregnancy by accepting visual features and EHR data as the input. We will also develop visual analytic tools that allow analysts to better understand and steer these deep learning models. We will estimate the importance of each input interpretable factor in embryo selection to explain the prediction to embryologists. Finally, we will develop EmbryoProﬁler, a clinical decision support system for ART, that combines our machine learning-based models with a user-facing suite of visual analytic tools to support user guidance and clinical decision making. EmbryoProﬁler will help facilitate daily operation in clinics, foster human-guided decision making, enrich data-driven embryo analysis, and enhance the ability to select the developmentally most competent embryo for transfer to improve ART success rates. Our project will create state-of-the-art analysis approaches for ART clinicians. PROJECT NARRATIVE Assisted Reproductive Technology (ART) is a widespread treatment for infertility, over 300,000 treatment cycles were performed in the US in 2018, but success rates remain low. In this project, we will develop novel machine learning algorithms and a clinical decision support system to assist embryologists in embryo selection. Our tools will also enable embryologists and biologists to obtain new information on the earliest stages of human embryo development, which will advance the fundamental science of human biology and lead to further improvements in ART practice.",Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization,10185936,R01HD104969,"['Adopted', 'Age', 'Assisted Reproductive Technology', 'Back', 'Cell Lineage', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Cloud Service', 'Communities', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Computers', 'Couples', 'Data', 'Data Analyses', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Making', 'Detection', 'Development', 'Discipline', 'E-learning', 'Electronic Health Record', 'Embryo', 'Embryo Transfer', 'Embryonic Development', 'Fostering', 'Goals', 'Human', 'Human Biology', 'Image', 'Image Analysis', 'In Vitro', 'Judgment', 'Knowledge', 'Label', 'Lead', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Mothers', 'Multiple Pregnancy', 'Obesity', 'Patients', 'Pattern', 'Physiological', 'Pre-implantation Embryo Development', 'Pregnancy', 'Pregnancy Rate', 'Privacy', 'Probability', 'Research', 'Science', 'Scientist', 'Secure', 'Security', 'Text', 'Time', 'Trees', 'United States', 'Ursidae Family', 'Uterus', 'Visual', 'Visualization', 'Visualization software', 'analytical tool', 'base', 'blastocyst', 'clinical decision-making', 'clinical practice', 'cloud based', 'cohort', 'convolutional neural network', 'data cleaning', 'data curation', 'data management', 'data visualization', 'deep learning', 'embryo cell', 'embryo monitoring', 'feature extraction', 'human-in-the-loop', 'implantation', 'improved', 'infertility treatment', 'insight', 'large scale data', 'machine learning algorithm', 'microscopic imaging', 'model design', 'multi-task learning', 'multimodality', 'novel', 'operation', 'predictive modeling', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'zygote']",NICHD,HARVARD UNIVERSITY,R01,2021,730410
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,10136061,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2021,579506
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10260577,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'risk stratification', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2021,332101
"AICORE-kids: Artificial Intelligence COVID-19 Risk AssEssment for kids This work is directed at characterizing pediatric COVID-19 and stratifying incoming patients by projected (future) disease severity. Such stratification has several implications: immediately improving treatment planning, and as disease mechanistic pathways are uncovered, directing treatment. Predicting future severity will inform the risks of outpatient treatment; to the patients themselves, their family, other caregivers/cohabitants, and to schools and employers. As varying levels of “reopening” are adopted across the country (and the world), such prognostication will inform policy on the handling of pediatric carriers in the community. Based on our preliminary analysis we assert that a combination of novel assays including quantitative serology inflammatory markers (cytokine/chemokine profiles, immune profiles), transcriptomics, epigenomics, longitudinal physiological monitoring, time series analysis, imaging, radiomics and clinical observation including social determinants of health, contains adequate information even at early stages of infection to stratify the disease and predict disease severity. We propose an artificial intelligence/machine learning approach to integrate this rich and heterogeneous dataset, characterize the spectrum of disease and identify biosignatures that predict severity in progressive disease. To facilitate translation of the approaches developed in this work to a wide user community, we incorporate a Translational Development function, to oversee the design-control process and ensure readiness of our methods for regulatory review. Incorporated into our timelines are appropriate regulatory milestones intended to conform with the Emergency Use Authorization (EUA) programs in effect for SARS- CoV-2 diagnostics. We propose an artificial intelligence/machine learning approach to integrate a rich and heterogeneous dataset on COVID-19 in children, characterize the spectrum of disease and identify biosignatures that predict severity in progressive disease. To facilitate translation of the approaches developed in this work to a wide user community, we incorporate a Translational Development function, to oversee the design-control process and ensure readiness of our methods for regulatory review. Incorporated into our timelines are appropriate regulatory milestones intended to conform with the Emergency Use Authorization (EUA) programs in effect for SARS-CoV-2 diagnostics.",AICORE-kids: Artificial Intelligence COVID-19 Risk AssEssment for kids,10272787,R61HD105593,"['2019-nCoV', 'Admission activity', 'Adopted', 'Adoption', 'Algorithms', 'Ambulatory Care', 'Artificial Intelligence', 'Award', 'Biological Assay', 'Blood', 'COVID-19', 'COVID-19 diagnostic', 'COVID-19 patient', 'COVID-19 severity', 'Caregivers', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Communities', 'Country', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Development', 'Diagnostic Procedure', 'Differentiation Antigens', 'Disease', 'Emergency Situation', 'Ensure', 'FDA Emergency Use Authorization', 'Family', 'Future', 'Image', 'Immune', 'Individual', 'Infection', 'Inherited', 'Laboratories', 'Machine Learning', 'Methods', 'Monitor', 'Mucocutaneous Lymph Node Syndrome', 'Multisystem Inflammatory Syndrome in Children', 'Participant', 'Pathway interactions', 'Patients', 'Pediatric Hospitals', 'Phase', 'PhenX Toolkit', 'Physiologic Monitoring', 'Policies', 'Preparation', 'Process', 'Progressive Disease', 'Psychological Transfer', 'Publishing', 'RADx Radical', 'Readiness', 'Records', 'Risk', 'Risk Assessment', 'Schools', 'Serology', 'Severities', 'Severity of illness', 'Speed', 'Spottings', 'Stratification', 'System', 'Testing', 'Texas', 'Time Series Analysis', 'TimeLine', 'Training', 'Translations', 'Validation', 'Work', 'assay development', 'base', 'biomedical referral center', 'biosignature', 'case-based', 'chemokine', 'cytokine', 'data integration', 'data standards', 'design', 'epigenomics', 'genetic variant', 'hemodynamics', 'heterogenous data', 'improved', 'inflammatory marker', 'interoperability', 'learning progression', 'learning strategy', 'machine learning algorithm', 'next generation', 'novel', 'patient population', 'pediatric patients', 'prognostic', 'programs', 'radiomics', 'repository', 'response', 'social health determinants', 'transcriptomics', 'treatment planning']",NICHD,BAYLOR COLLEGE OF MEDICINE,R61,2021,817546
"Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK) PROJECT SUMMARY  Contemporary ocular surgeries are performed by skilled surgeons through operating microscopes, utilizing freehand techniques and manually operated precision micro-instruments, where the outcomes are often limited by the surgeon's skill levels and experiences. To overcome these human factors, we have assembled an interdisciplinary team including a clinician-scientist and eye surgeon, an optical device scientist and medical robotic engineers to translate existing and developing technologies in our laboratories into precision, “deep- learning” artificial intelligence (AI) guided robotic ocular surgical devices for precise automated Deep Anterior Lamellar Keratoplasty (AUTO-DALK).  DALK is a highly attractive treatment of corneal disease with normally functioning endothelium. However, the procedure is unusually challenging from a technical perspective and time-consuming, limiting its acceptance among corneal surgeons. The most challenging aspect of the procedure is related to the delamination of stroma from Descemet's membrane (DM). A procedure, commonly called “Big Bubble” is used to separate stroma from DM using deep intrastromal pneumatic injection. However, even experienced surgeons have difficulty precisely placing the injection. The most common complication of DALK is the excessive depth of the needle insertion resulting in Descemet's membrane perforation requiring conversion to full-thickness penetrating keratoplasty with its much longer recovery period and a higher risk of graft failure from rejection. The reported rates of Descemet's membrane perforation for beginner and experienced surgeons are 31.8% and 11.7% respectively. In addition, interface haze between the donor and recipient cornea is a common problem caused by the insufficient depth of needle insertion and failure to remove the host stromal tissue, which results in loss of postoperative visual acuity. These problems relate directly to the inability of the current surgical practice to precisely assess the depth of the tooltips inside the cornea layer in real-time.  Here we will build upon our previous and ongoing work in robust fiber optic common-path optical coherence tomography (CP-OCT) and AI-guide system based on convolutional neural network (CNN) robotic microsurgical tools that enable clinicians to precisely guide surgical tools at micron scale. The proposed AUTO- DALK surgical tool system is capable of one-dimensional real-time depth tracking, motion compensation, and detection of early instrument contact with tissue, which enables clinicians to perform DALK precisely and safely. The tool will be built on a handheld platform that will consist of CP-OCT probe, trephine and microinjector that allows precise and safe removal of the anterior section of cornea down to DM  We hypothesize that AI-OCT providing intelligent visualization and depth controlled optimal cornea cutting and tissue tracking will perform the task of DALK with better accuracy and efficiency over the manually performed trephine cutting and “Big Bubble” pneumodissection. Project Narrative  This proposal addresses fundamental limitations in current corneal transplant surgery by developing an artificial intelligence guided compact robotic surgical tool that could empower corneal surgeons to achieve difficult surgical objectives, reduce intraoperative complications, and improve clinical outcomes when performing Deep Anterior Lamellar Keratoplasty (DALK). Further, these capabilities are broadly applicable in other microsurgical problems, and the tools will enable further advances both for ophthalmology and for other microsurgical disciplines.",Artificial intelligence Optical Coherence Tomography Guided Deep Anterior Lamellar Keratoplasty (AUTO-DALK),10100636,R01EY032127,"['Accounting', 'Address', 'Adrenal Cortex Hormones', 'Animal Model', 'Anterior', 'Artificial Intelligence', 'Blindness', 'Blunt Trauma', 'Burr hole procedure', 'Cadaver', 'Clinical', 'Complication', 'Consumption', 'Cornea', 'Corneal Diseases', 'Corneal Opacity', 'Corneal dystrophy', 'Data', 'Descemet&apos', 's membrane', 'Devices', 'Dimensions', 'Discipline', 'Distal', 'Drops', 'Early Diagnosis', 'Endophthalmitis', 'Endothelial Cells', 'Endothelium', 'Engineering', 'Ensure', 'Epithelial', 'Excision', 'Expert Systems', 'Eye', 'Eye Surgeon', 'Failure', 'Fiber Optics', 'Financial compensation', 'Geometry', 'Glaucoma', 'Goals', 'Graft Survival', 'Hemorrhage', 'Human', 'Image', 'Immune', 'Incidence', 'Infection', 'Injections', 'Intelligence', 'Intraoperative Complications', 'Iris', 'Keratoconus', 'Keratoplasty', 'Laboratories', 'Lamellar Keratoplasty', 'Lead', 'Manuals', 'Mechanics', 'Medical', 'Microscope', 'Modeling', 'Motion', 'Movement', 'Needles', 'Ocular Hypertension', 'Operative Surgical Procedures', 'Ophthalmology', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Outcome', 'Pathological Dilatation', 'Patients', 'Penetrating Keratoplasty', 'Perforation', 'Performance', 'Postoperative Complications', 'Postoperative Period', 'Procedures', 'Ptosis', 'Recovery', 'Repeat Surgery', 'Reporting', 'Research Personnel', 'Risk', 'Robotics', 'Rupture', 'Safety', 'Scientist', 'Secondary to', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Systems Development', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Topical Corticosteroids', 'Translating', 'Transplantation Surgery', 'Trauma', 'Validation', 'Visual', 'Visual Acuity', 'Visualization', 'Work', 'base', 'convolutional neural network', 'corneal scar', 'curative treatments', 'deep learning', 'design', 'experience', 'graft failure', 'high risk', 'iatrogenic injury', 'improved', 'in vivo', 'instrument', 'interest', 'novel', 'phantom model', 'photonics', 'preservation', 'prototype', 'sensor', 'skills', 'surgery outcome', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,409997
"AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition ABSTRACT Dietary intake is a complex human behavior that drives disease risk and corresponding economic and healthcare burdens worldwide. Poor diet is the leading cause of death in the US and a known driver of obesity – a global epidemic. A major contributor to poor diet is food eaten away from home, such as restaurant foods. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods. Accurate approaches and tools to evaluate food and nutrient intake are essential in monitoring the nutritional status of individuals. There is a critical need for real-time data capture that minimizes burden and reduces error. While progress has been made, there is no tool available that accurately and automatically estimates foods left unconsumed in a meal. Two major limitations of existing systems is the reliance of a fiducial marker for food detection and volume estimation, and reliance on humans – either the respondent or a trained researcher – to estimate the portion of food leftover. This application leverages novel technology to remove those limitations. The long-term research goal is to utilize digital imaging (DI), artificial intelligence (AI) and computer vision (CV) techniques to develop a novel hybrid methodology for rapid, accurate measurement of dietary intake. To attain this goal, our objective in this R21 application is to refine and test a system architecture that (a) uses digital images to record dietary intake in real-time and (b) uses AI and CV techniques to identify food/beverage items and determine amounts leftover. We plan to build on our current prototype in which digital food images are captured before and after the meal, analyzed to detect the food items, a three-dimensional (3-D) virtual model constructed, and volume remaining after the meal estimated, which will be used to calculate the amount leftover based on the initial volume. Volume consumed will be converted to weight and linked to public-use nutrition information. These calorie estimates will be compared against calories those from (a) DIs coded by trained research staff and (b) weighed plate waste methodology. Our expectation is to develop a valid system architecture for rapidly estimating dietary intake. The outcome of this proposal is expected to have a significant positive impact, enabling nutrition and health researchers to collect high-quality food consumption data in real world settings, increasing knowledge of dietary patterns and improving capacity to assess dietary interventions. This work will lead to an R01 application that will expand food types and meal settings and test the utility of our system among consumers. Project Narrative Solutions to address the global obesity epidemic are urgently needed. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods, a known driver of obesity. This study integrates nutrition science, computer science, and engineering to develop and test a new method for assessing dietary intake, and if successful would yield a rapid, reliable, accurate and cost- effective tool.",AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition,10163822,R21CA250024,"['3-Dimensional', 'Address', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Behavior', 'Beverages', 'Body Weight decreased', 'Calories', 'Cause of Death', 'Cellular Phone', 'Code', 'Complex', 'Computer Vision Systems', 'Consumption', 'Data', 'Databases', 'Detection', 'Development', 'Diet Records', 'Dietary Assessment', 'Dietary Intervention', 'Dietary Practices', 'Dietary intake', 'Economics', 'Engineering', 'Epidemic', 'Food', 'Goals', 'Gold', 'Health', 'Healthcare', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Intake', 'Intervention', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Nutrient', 'Nutritional Science', 'Nutritional status', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Output', 'Participant', 'Research', 'Research Personnel', 'Research Training', 'Respondent', 'Restaurants', 'Side', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unhealthy Diet', 'Validation', 'Weight', 'Work', 'base', 'computer science', 'cost', 'cost effective', 'design', 'dietary', 'digital', 'digital imaging', 'disorder risk', 'expectation', 'food consumption', 'food quality', 'handheld mobile device', 'improved', 'knowledge base', 'new technology', 'novel', 'nutrition', 'prototype', 'success', 'system architecture', 'tool', 'virtual model', 'wasting', 'weight maintenance']",NCI,TUFTS UNIVERSITY BOSTON,R21,2021,197745
"Cooperative Control Robotics and Computer Vision: Development of Semi-Autonomous Temporal Bone and Skull Base Surgery Project Summary I am an assistant professor in the department of Otolaryngology-Head and Neck Surgery at the Johns Hopkins School of Medicine, where my practice is focused on neurotology and lateral skull base surgery. I am applying for a mentored surgeon-scientist career development award (CDA) to obtain further training in robotics, deep learning and computer vision. This will further my long-term career goals of improving neurotologic surgical outcomes through novel applications of engineering methods and ultimately to investigate semi-autonomous, robotic interventions in the inner ear and skull base which are beyond the limits of the human hand alone.  Operating in the temporal bone and lateral skull base is technically demanding due to complex three- dimensional anatomy, small working spaces and delicate neurovascular structures. Many of these challenges are ideally suited to semi-autonomous surgical platforms to augment a surgeon’s skills with robotic and image- guided assistance. Despite the widespread implementation of robotic surgery and image guidance in other areas of the body, the field of neurotology has had relatively little adoption of this technology. We believe one reason for this is the precise registration needed in this field, where millimeter differences differentiate a successful from a catastrophic result. This CDA proposes expanding on my prior work investigating cooperative control robotics and virtual safety barriers by using computer vision and deep learning networks to develop highly accurate surgical image registration. This CDA aims to provide me with multi-disciplinary training in the departments of Otolaryngology, Biomedical Engineering and Computer Science. Specific training goals include: (1) Training in robotics, statistical shape modeling and computer tomography landmark segmentation, (2) Training in deep learning networks and computer vision video image registration, (3) Integrating this training, with my knowledge of temporal bone and skull base surgery to develop into an independent investigator (4) Pursue additional training in the ethical and responsible conduct of research.  The research plan addresses the hypothesis that virtual safety barriers can be accurately enforced by a cooperative control robot, and computer vision methods can be used to automate accurate placement and registration of these safety barriers. I believe that the integration of these techniques will allow for semi- autonomous surgical methods resulting in improved surgical safety and efficiency. The specific aims of the proposal are to: (1) Develop and Validate Cooperative Control Robot Enforced Virtual Safety Barriers for Cortical Mastoidectomy (2) Develop and Test Autonomous Segmentation of Lateral Skull Base Anatomy (3) Develop Video-Based, Fiducial-less, Surgical Image Registration to Detect and Update the 3-D Position of Temporal Bone Anatomy from Intraoperative Stereoscopic Microscope Video. Project Narrative The research proposed here will investigate the feasibility of using novel applications of computer vision and cooperative control robotics to enforce virtual safety barriers in neurotologic surgery. Our long-term goal is to develop semi-autonomous, robotic methods to improve the safety and efficiency of neurotologic surgery, and open the possibilities for surgical interventions which currently are beyond the abilities of the human hand alone.",Cooperative Control Robotics and Computer Vision: Development of Semi-Autonomous Temporal Bone and Skull Base Surgery,10283480,K08DC019708,"['3-Dimensional', 'Address', 'Adoption', 'Algorithms', 'Anatomy', 'Area', 'Atlases', 'Automobile Driving', 'Automobiles', 'Biomedical Engineering', 'Cadaver', 'Cochlea', 'Complex', 'Computer Vision Systems', 'Computers', 'Consumption', 'Data', 'Drug Delivery Systems', 'Dura Mater', 'Electromagnetics', 'Engineering', 'Equilibrium', 'Ethics', 'Facial nerve structure', 'Feedback', 'Future', 'Goals', 'Hand', 'Head and Neck Surgery', 'Hearing', 'Human', 'Image', 'Image-Guided Surgery', 'Intervention', 'Judgment', 'K-Series Research Career Programs', 'Knowledge', 'Labyrinth', 'Lateral', 'Left', 'Manuals', 'Mentors', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Monitor', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Otolaryngology', 'Outcome', 'Patients', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Robot', 'Robotics', 'Safety', 'Scientist', 'Shapes', 'Sigmoid colon', 'Site', 'Speed', 'Structure', 'Surface', 'Surgeon', 'Surgical Instruments', 'Surgical complication', 'System', 'Tactile', 'Techniques', 'Technology', 'Temporal bone structure', 'Testing', 'Time', 'Training', 'Tremor', 'Update', 'Work', 'X-Ray Computed Tomography', 'automated segmentation', 'base', 'career', 'computer science', 'deep learning', 'digital', 'digital imaging', 'image guided', 'image registration', 'improved', 'instrument', 'learning network', 'medical schools', 'microscopic imaging', 'millimeter', 'multidisciplinary', 'neurovascular', 'novel', 'professor', 'responsible research conduct', 'robot control', 'simulation', 'skills', 'skull base', 'stereoscopic', 'success', 'surgery outcome', 'three-dimensional modeling', 'virtual', 'vision development']",NIDCD,JOHNS HOPKINS UNIVERSITY,K08,2021,191792
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250
"Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity PROJECT SUMMARY The long-term goal of this project is to determine whether optical coherence tomography (OCT) and OCT angiography (OCTA) might lead more accurate and objective diagnosis, earlier intervention, and improved outcomes in retinopathy of prematurity (ROP). International consensus and National Institute of Health (NIH) funded clinical trials over the last 30 years have defined the phenotypic classifications, natural history, prognosis, and management of ROP. However, it is well established that due to the subjectivity of the ophthalmoscopic examination, and systematic bias between examiners, there is significant variation in treatment of the most severe forms of ROP in the real world. This leads to both under-treatment (and poor outcomes due to retinal detachment) and over-treatment (exposing neonates to the ocular and systemic risks of treatment). Roughly 20,000 babies per year develop retinal detachments (RD) due to ROP and there is strong evidence that most of these are preventable. In adult retinal vascular diseases, most notably diabetic retinopathy (DR), OCT and OCTA can detect and quantify disease features such as diabetic macular edema (DME) and retinal neovascularization (NV) before they are noted clinically, enabling earlier treatment and reducing the risk of blindness from RD. However, evaluating the use of this technology in neonates requires high speed and portable technology, and the commercially available handheld OCTs are too slow for ultra-widefield (UWF) OCT and OCTA imaging. Several groups (including our own) have published preliminary results using prototype 100 to 200 kHz swept- source (SS) OCT systems, however consistent data acquisition remains challenging due to the lack of fixation and subsequent motion in an awake neonate, which has limited the evaluation of the potential benefits of the technology in this population. Recently, there has been much interest in using artificial intelligence (AI) (specifically deep learning), which relies on high speed graphics processing units (GPUs) to provide real time OCT image processing, segmentation, and tracking. This application addresses 2 fundamental gaps in knowledge: (1) Can we overcome the technical challenges through the development of a faster ultrawide-field view SS-OCT system coupled with a GPU-enabled DL software system to enable consistent data acquisition in neonates? (2) Would quantitative objective metrics of ROP improve objectivity of ROP diagnosis and detect subclinical signs of disease progression which may enable earlier intervention and improved outcomes in the future. By leveraging our institution’s OCT, AI, and ROP expertise, we will address these questions in three specific aims: (1) Develop an ultra-high speed, handheld, panoramic ultra-widefield OCT/OCTA system. (2) Develop real time GPU accelerated intelligent image acquisition software. (3) Evaluate the clinical significance OCT derived biomarkers. Successful translation of this technology to the ROP population could improve the accuracy and objectivity of ROP diagnosis, and lead to earlier intervention and improved outcomes in patients with severe ROP. PROJECT NARRATIVE Optical Coherence Tomography (OCT) and OCT angiography (OCTA) have proven the ability to detect subclinical disease, provide quantitative evaluation of disease progression, and improve outcomes in the leading causes of blindness in adults, age-related macular degeneration and diabetic retinopathy. Technological and practical limitations have limited the application of this technology in routine use for non-sedated children undergoing routine screening for retinopathy of prematurity (ROP), the leading cause of blindness in children. The proposed project will develop an ultra-high speed, handheld OCT system with graphics processing unit (GPU) enabled real-time processing to improve the feasibility of panoramic ultra-widefield OCT/OCTA imaging in non-sedated neonates and evaluate the clinical utility of OCT-derived biomarkers in ROP.",Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity,10198930,R01HD107494,"['Address', 'Adult', 'Aftercare', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Blindness', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Trials', 'Computer software', 'Consensus', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Disease Progression', 'Dyes', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Evaluation', 'Eye', 'Fluorescein Angiography', 'Funding', 'Fundus', 'Future', 'Goals', 'Image', 'Image Analysis', 'Injections', 'Institution', 'Intelligence', 'International', 'Knowledge', 'Lasers', 'Lead', 'Length', 'Longitudinal Studies', 'Measurement', 'Medical Imaging', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Natural History', 'Neonatal', 'Ophthalmic examination and evaluation', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Pilot Projects', 'Population', 'Primary Health Care', 'Publishing', 'Quantitative Evaluations', 'Retina', 'Retinal Detachment', 'Retinal Neovascularization', 'Retinopathy of Prematurity', 'Risk', 'Scanning', 'Severities', 'Severity of illness', 'Source', 'Speed', 'Structure', 'System', 'Systematic Bias', 'Technology', 'Testing', 'Time', 'Translations', 'United States National Institutes of Health', 'Variant', 'Vascular Diseases', 'Visualization', 'accurate diagnosis', 'arm', 'awake', 'base', 'blind', 'clinical Diagnosis', 'clinically significant', 'data acquisition', 'deep learning', 'design', 'diabetic', 'disease classification', 'disorder of macula of retina', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'instrument', 'interest', 'lens', 'macular edema', 'neonate', 'neovascularization', 'novel', 'outcome forecast', 'overtreatment', 'parallel computer', 'portability', 'prototype', 'real-time images', 'research clinical testing', 'routine screening', 'sample fixation', 'software systems', 'standard of care', 'treatment response', 'treatment risk']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,377300
"Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics Abstract The primary objective is to develop an artificial intelligence-centric, quantitative and noninvasive software platform that can be integrated into 3D angiographic scanners (DSA, CTA or MRA) to provide guidance regarding the diagnosis and management of intracranial aneurysms (IA). Hemorrhagic stroke secondary to ruptured IAs leads to significant morbidity and mortality and affects over 35,000 patients on a yearly basis in the United States. The diagnosis of asymptomatic IAs is on the rise with the increasing use of cerebral imaging. However, guidance regarding which aneurysms should be treated has not advanced. Leveraging recent advances in computational science and technology, particularly artificial intelligence, the proposed software platform built on two enabling technologies can (1) propel automated “patient-specific” hemodynamic evaluations into the clinical workflow and (2) conduct “data-driven” risk assessments of IA rupture on an individual basis. Specific research aims are to (1) develop a clinically-oriented CFD platform that enables automated “patient-specific” hemodynamic evaluations of IAs, (2) investigate data-driven analytics toward prediction of rupture risk for IAs and (3) evaluate the data-driven analytics in a blind study. Once validated, a follow-up R01 project is planned to examine the clinical utility of the proposed software platform in a prospective clinical study as a single gateway for computer-aided evaluation of cerebral aneurysms. Public Health Relevance/Narrative This R01 proposal is to investigate the feasibility of developing an innovative, non-invasive and artificial intelligence-centric tool that can be used as a software add-on to clinical angiographic (e.g. DSA) scanners. The software can automatically select high-risk aneurysms for immediate treatments from a pool of patients with unruptured intracranial aneurysms, impacting the clinical management of intracranial aneurysms.",Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics,10121043,R01EB029570,"['3-Dimensional', 'Affect', 'Aneurysm', 'Angiography', 'Architecture', 'Artificial Intelligence', 'Benign', 'Biomedical Computing', 'Biomedical Engineering', 'Brain hemorrhage', 'Cerebral Aneurysm', 'Cerebrum', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational Geometry', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Engineering', 'Ensure', 'Evaluation', 'Genetic', 'Growth', 'Human', 'Image', 'Individual', 'Intracranial Aneurysm', 'Knowledge', 'Liquid substance', 'Machine Learning', 'Medicine', 'Methods', 'Michigan', 'Morbidity - disease rate', 'Morphology', 'Natural History', 'Neural Network Simulation', 'Outcome', 'Patients', 'Physics', 'Play', 'Research', 'Research Proposals', 'Risk', 'Risk Assessment', 'Role', 'Rupture', 'Ruptured Aneurysm', 'Secondary to', 'Smoker', 'Technology', 'TensorFlow', 'Testing', 'Training', 'Translational Research', 'United States', 'Universities', 'Wisconsin', 'Work', 'analytical method', 'base', 'blind', 'computer grid', 'convolutional neural network', 'deep learning', 'flexibility', 'follow-up', 'hemodynamics', 'high risk', 'image guided', 'innovation', 'learning strategy', 'mortality', 'neurosurgery', 'open source', 'personalized management', 'prevent', 'prospective', 'prototype', 'public health relevance', 'shear stress', 'success', 'tool']",NIBIB,MICHIGAN TECHNOLOGICAL UNIVERSITY,R01,2021,346966
"CT and CXR Phenotyping Platform for Assessing COVID-19 Susceptibility and Severity Abstract COVID-19 was declared a pandemic by WHO on March 11. Since then, there have been 8.15 million confirmed cases worldwide with a case fatality rate ranging from 16.3% to 0.1%. In the US, there have been 2,187,202 cases with a 5.4% case fatality rate as of June 16, 2020. The magnitude of this infectious disease has stressed the need to develop novel methodologies to define who are at the highest risk of developing acute symptoms. X-Ray (CXR) and Computed Tomography (CT) play a fundamental role in the detection and follow-up of the COVID-19 lung injury. It also provides a unique opportunity to define quantitative biomarkers that may identify susceptible subjects to the acute phase of the disease using pre-infection and early infection radiological exams. This proposal's broad objective is to provide a better understanding of acute COVID-19 susceptibility markers based on artificial intelligence approaches on radiological exams, both CT and CXR. CT offers a unique way to phenotype the lung and its changes. Subtle changes of normal parenchyma have been associated with systemic inflammation that can be detected on CT. We hypothesize that susceptible subjects for acute COVID- 19 disease evolution will express inflamed normal parenchymal signatures that can be measured on CT scan prior to the infection or in the early phases of the viral infection. We will develop new computational approaches to identify radiographic patterns consistent with inflamed normal parenchyma as well as early COVID-19 injury and compute radiomics signature that can capture the heterogeneity of the radiographic expression for each lung pattern. We will define new CT-based biomarkers for acute COVID-19 susceptibility using Gradient Boosting decision trees and feature importance. We will then translate the quantification of the most relevant features in CXR image using image translation approaches based on deep neural networks. Finally, we will integrate these automated tools in the CIP workstation using clinically friendly end-to-end workflows to empower clinical investigations across the world. We will continue the support and dissemination of this tool across the research community. Over the last 15 years, our group has developed the Chest Imaging Platform (CIP), an NIH-funded open-source software tool for the automated phenotyping of chest CT scans that is widely used in the chronic lung disease research community. Since the beginning of the pandemic, CIP has been used to the characterization of COVID-19 using existing densitometric metrics. Our commitment to open science in the form of open toolkits that are freely distributed is fundamental to catalyze the application of AI and imaging in the context of this pandemic. Project Narrative As of June 16, there has been 2.18 million confirmed cases of COVID-19 in the United States with 118,435 fatalities. Unlike many other diseases, only general epidemiological factors are available for describing the susceptibility to COVID-19 and its acute phase. Biomarkers computed from CT and CXR images of the chest provides a personalized approach to define prognostic markers of disease susceptibility.",CT and CXR Phenotyping Platform for Assessing COVID-19 Susceptibility and Severity,10196276,R21LM013670,"['2019-nCoV', 'Acute', 'Architecture', 'Artificial Intelligence', 'Biological Markers', 'COVID-19', 'COVID-19 patient', 'COVID-19 susceptibility', 'Case Fatality Rates', 'Chest', 'Chronic', 'Chronic lung disease', 'Clinical', 'Communicable Diseases', 'Communities', 'Data', 'Decision Trees', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Disease', 'Disease susceptibility', 'Epidemiologic Factors', 'Evolution', 'Funding', 'Goals', 'Heterogeneity', 'Image', 'Immune response', 'Infection', 'Inflammatory', 'Injury', 'Intensive Care', 'Lung', 'Lung Inflammation', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modality', 'Outcome', 'Patient Care', 'Pattern', 'Phase', 'Phenotype', 'Play', 'Predisposition', 'Prognostic Marker', 'Radiology Specialty', 'Research', 'Resolution', 'Response Elements', 'Roentgen Rays', 'Role', 'SARS-CoV-2 infection', 'Scanning', 'Severities', 'Severity of illness', 'Smoking', 'Software Tools', 'Stress', 'Structure of parenchyma of lung', 'Techniques', 'Technology', 'Thoracic Radiography', 'Training', 'Translating', 'Translations', 'United States', 'United States National Institutes of Health', 'Virus', 'Virus Diseases', 'X-Ray Computed Tomography', 'acute care', 'acute symptom', 'base', 'chest computed tomography', 'clinical investigation', 'clinical translation', 'deep learning', 'deep neural network', 'follow-up', 'high risk', 'imaging platform', 'interest', 'learning strategy', 'lung injury', 'novel', 'open data', 'open source', 'pandemic disease', 'personalized approach', 'predictive modeling', 'prognostic', 'radiomics', 'response', 'severe COVID-19', 'systemic inflammatory response', 'therapeutic development', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R21,2021,155730
"A Handheld Microchip for GC analysis of breath to screen for COVID-19 Project Summary  The COVID-19 pandemic has caused unprecedented societal suffering and economic disruption. In the United States, more than six million people have contracted COVID-19 and more than one hundred ninety thousand patients have died of this disease to date. Although current COVID-19 diagnostic testing technologies are critical for slowing the spread of the virus and preventing future outbreaks, they are not practical for field use. Current diagnostic tests are cumbersome to perform because they use aqueous solutions, require multiple steps, and hours-to-days to obtain results. Since the US began to reopen the economy in May, there has been a significant increase in the number of COVID-19 cases. Therefore, there is an urgent need to develop a diagnostic approach that is non-invasive, portable, and can rapidly provide test results.  The overall goal of the project is to develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). The handheld tool will be a closed system for trapping select volatile organic compounds (VOCs) on a microfabricated chip. The captured VOCs will be eluted with ethanol and then analyzed using a commercially available, portable GC-PID instrument. Artificial intelligence (AI) and machine learning algorithms will be applied to recognize the VOC pattern that correlates with COVID-19 infection. The central innovation is the microfabricated chip that captures carbonyl compounds in exhaled breath and thus serves as a preconcentrator, which enables analysis of carbonyl VOCs by the portable GC-PID. The hypothesis is that the carbonyl metabolome in exhaled breath is directly related to the body’s reaction to the novel coronavirus infection, and changes in the carbonyl VOC composition in exhaled breath relative to healthy controls can be used to detect both symptomatic and asymptomatic COVID-19 patients.  Three specific aims are proposed to fulfill the overall goal. Aim 1 is to build a disposable handheld breath analyzer tool for concentrating carbonyl VOCs. Aim 2 is to identify VOC patterns in the breath of COVID-19 patients by machine learning algorithms. Aim 3 is to integrate portable GC technology with the breath sampling tool for COVID-19 screening guided by an AI system. The University of Louisville is uniquely suited to rapidly transition the microchip technology to field use because of the PI and Co-PI’s experience in breath analysis and translational research, and the project team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence as well as the state-of-the-art facilities that include a MicroNano Technology Center, Biosafety Level 3 Regional Biocontainment Lab, and an NIH-funded REACH program. 8. Project Narrative  This project will develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). Artificial intelligence and machine learning algorithms will be used to analyze the detected signals of volatile organic compounds (VOCs) in exhaled breath by the portable GC for detection of COVID-19 patients. UofL is uniquely suited to develop this approach because of the PI’s expertise in breath analysis for detection of Tuberculosis and lung cancer and the team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence.",A Handheld Microchip for GC analysis of breath to screen for COVID-19,10266377,U18TR003787,"['2019-nCoV', 'Acute', 'Address', 'Artificial Intelligence', 'Biochemical Process', 'Biometry', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnostic', 'COVID-19 pandemic', 'COVID-19 patient', 'COVID-19 screening', 'COVID-19 test', 'Cancer Detection', 'Clinic', 'Collaborations', 'Collection', 'Communicable Diseases', 'Contracts', 'Coronavirus Infections', 'Detection', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Economics', 'Epithelial Cells', 'Ethanol', 'Exhalation', 'Expert Systems', 'Foundations', 'Funding', 'Future', 'Goals', 'Hour', 'Human', 'Influenza', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Malignant neoplasm of lung', 'Mass Fragmentography', 'Medical Device', 'Modeling', 'Monitor', 'Nasal Epithelium', 'Oxidative Stress', 'Patients', 'Pattern', 'Process', 'Production', 'Protocols documentation', 'Rapid screening', 'Reaction', 'Reagent', 'Research Project Grants', 'Role', 'SARS-CoV-2 infection', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Silicon', 'Sterilization', 'System', 'Technology', 'Test Result', 'Testing', 'Training', 'Translational Research', 'Tuberculosis', 'United States', 'United States National Institutes of Health', 'Universities', 'Vial device', 'Viral', 'Viral Respiratory Tract Infection', 'Virulent', 'Virus', 'Virus Diseases', 'adduct', 'aqueous', 'asymptomatic COVID-19', 'biosafety level 3 facility', 'bronchial epithelium', 'carbonyl compound', 'detection sensitivity', 'detector', 'experience', 'innovation', 'instrument', 'machine learning algorithm', 'metabolome', 'microchip', 'mobile computing', 'novel coronavirus', 'photoionization', 'point of care', 'portability', 'prevent', 'programs', 'prototype', 'reagent testing', 'tool', 'virology', 'volatile organic compound']",NCATS,UNIVERSITY OF LOUISVILLE,U18,2021,1026672
"Virtual Biopsy with Tissue-level Accuracy in Glioma Project Summary This is a Bioengineering Research Grant (BRG) proposal in response to PAR-19-158 to further develop and validate a non-invasive panel of the most critical glioma molecular markers (IDH, 1p/19q, MGMT) using standard clinical MRI T2-weighted images and deep learning, and extend the performance to tissue-level accuracies. Currently, the only reliable way of obtaining molecular marker status is through direct tissue sampling of the tumor, requiring either a craniotomy and stereotactic biopsy or a large open surgical resection. Noninvasive determination of molecular markers with tissue-level accuracy would be transformational in the management of gliomas, reducing or eliminating the risks and costs associated with a neurosurgical procedure, accelerating the time to definitive treatment, improving patient experience and ultimately patient outcomes and survival time. Artificial intelligence such as deep learning has emerged as a powerful method for classification of imaging data that can exceed human performance. Preliminary work using our novel voxel-wise classification-segmentation approach with the NIH/NCI TCIA glioma database has outperformed any prior noninvasive methods for determination of IDH, 1p/19q, and MGMT methylation, achieving accuracies of 97%, 93%, and 95%, respectively. The approach however, needs to be validated beyond the TCIA and accuracies need to be extended in order to achieve tissue level performance. This will be accomplished by using our top-performing voxel-wise classification framework, leveraging marker-specific targeted sample sizes, and gaining a final boost from deep-learning artifact correction networks. In Aim 1 we will curate a database of over 2000 gliomas including 500 subjects from our institution, 1200 subjects from our external collaborators, and over 300 subjects from the TCIA. We will train our voxel-wise deep learning classifiers to determine molecular status based on clinical T2-weighted MR images with target accuracies of 97%. In Aim 2 we will rigorously evaluate the motion and noise sensitivity of the networks and create an artifact correction network with the goals of 1) recovering accuracies in the setting of large amounts of motion/noise and 2) further boosting accuracy to tissue-level performance even in the absence of visible artifact. In Aim 3 we will deploy a complete end-to-end clinical workflow and evaluate real-world live performance of the AI tool on 300 prospectively acquired brain tumor cases and 300 subjects from our external collaborators. The AI tool will be made available for deployment at other medical centers. The developed framework can also be extended to additional markers in a straightforward fashion. In summary, this BRG proposal will further develop, refine and validate a non-invasive MRI-based method for determining the most critical glioma molecular markers rivaling tissue-level accuracies to significantly reduce and in many cases eliminate the need for stereotactic biopsy. Project Narrative Knowledge of molecular status for a variety of markers in gliomas has moved to the forefront in clinical decision- making. This requires direct tissue sampling either from an invasive brain biopsy or open surgical resection. In this Bioengineering Research Grant proposal in response to PAR-19-158, we will develop and validate a non- invasive method to determine a panel of the most critical molecular markers (IDH, 1p/19q and MGMT methylation) with near tissue-level accuracies using routine T2-weighted (T2w) MR images and deep learning algorithms to significantly reduce and in many cases eliminate the need for stereotactic biopsy in glioma.",Virtual Biopsy with Tissue-level Accuracy in Glioma,10226632,R01CA260705,"['19q', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Automation', 'Biology', 'Biomedical Engineering', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Classification', 'Clinical', 'Computerized Medical Record', 'Craniotomy', 'Data', 'Data Set', 'Databases', 'Digital Imaging and Communications in Medicine', 'Excision', 'Glioma', 'Goals', 'Human', 'Hyperacusis', 'Image', 'Institution', 'Knowledge', 'MGMT gene', 'Magnetic Resonance Imaging', 'Manuals', 'Medical center', 'Methods', 'Methylation', 'Molecular', 'Molecular Analysis', 'Morphologic artifacts', 'Motion', 'Neurosurgical Procedures', 'Noise', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Process', 'Prospective cohort', 'Reporting', 'Research Project Grants', 'Resources', 'Risk', 'Sample Size', 'Sensitivity and Specificity', 'T2 weighted imaging', 'Testing', 'The Cancer Genome Atlas', 'The Cancer Imaging Archive', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Tumor Tissue', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'clinical decision-making', 'clinical implementation', 'clinical translation', 'contrast imaging', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'large datasets', 'learning classifier', 'learning strategy', 'molecular marker', 'motion sensitivity', 'mutational status', 'novel', 'outcome forecast', 'prospective', 'response', 'surgical risk', 'tool', 'tumor', 'virtual biopsy']",NCI,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,655597
"Evaluation of artificial intelligence-controlled CPR to improve vital organ perfusion and survival during prolonged resuscitation Project Summary / Abstract  Almost 400,000 cases of out-of-hospital cardiac arrest (OHCA) occur each year in the United States. In patients requiring cardiopulmonary resuscitation (CPR) for prolonged periods, current CPR methods are unable to maintain adequate blood flow and oxygen delivery to the vital organs. Survival is <10% in patients with shockable rhythms and ~0% in those with non-shockable rhythms. Current American Heart Association (AHA) recommendations for CPR follow a “one-size-fits-all” paradigm. Our goal is to improve vital organ perfusion during prolonged CPR by “personalizing” compression/decompression therapy with a dynamic CPR method that changes compression characteristics over the course of CPR after taking into account the temporal changes of chest wall compliance and hemodynamics in order to increase the rate of neurologically intact survival after OHCA.  In this grant proposal, we are investigating the deployment of machine learning algorithms incorporated into a mechanical CPR device to predict and optimize hemodynamics during CPR. We will use state-of-the-art dynamical modeling in conjunction with closed-loop control algorithms to individualize CPR characteristics and optimize temporal blood flow. Our preliminary results suggest that deployment of machine learning prediction algorithms paired with control algorithms in a preclinical Ventricular Fibrillation model can adapt compression and decompression depth in real time, resulting in increased vital organ blood flow as compared to standard CPR techniques Based on these results, we hypothesize that optimization of compression depth, decompression depth, duty cycle, and compression rate of CPR will lead to better outcomes. Our proposed research will: 1) identify the most promising algorithm for the prediction of CPR hemodynamics 2) identify the best control algorithm to pair with this prediction algorithm in terms of optimizing CPR hemodynamics and return of spontaneous circulation 3) use the prediction and control pairing to improve 48h neurologically intact survival in a porcine model of ventricular fibrillation, as compared to standard CPR techniques. Throughout this process, we will identify non-invasive alternative measurements to provide to the algorithms with the ultimate goal of proceeding with device development and human trials. Project Narrative In light of a growing body of evidence which suggests that prolonged duration CPR is a dynamic process, without universally optimal “one-size-fits-all” parameters, advanced methods of CPR individualization may be applied to optimize cardiac and cerebral perfusion for these patients. We propose to study the effects of machine learning and optimal control techniques within the context of CPR, thus creating a closed-loop CPR system that has been trained by pre-clinical data to modify CPR characteristics and optimize blood flow. Our preliminary studies suggest that machine learning and control algorithms can be successfully deployed in a preclinical model to adapt compression and decompression depth, increasing vital organ blood flow as compared to standard CPR techniques. If our hypotheses are verified, a gateway for the first human trials is open.",Evaluation of artificial intelligence-controlled CPR to improve vital organ perfusion and survival during prolonged resuscitation,10186125,R01HL157625,"['Acute', 'Algorithms', 'American Heart Association', 'Animal Experiments', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biofeedback', 'Blood Circulation', 'Blood flow', 'Carbon Dioxide', 'Cardiac', 'Cardiopulmonary Resuscitation', 'Cerebrum', 'Cessation of life', 'Characteristics', 'Chest wall structure', 'Choices and Control', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Data', 'Databases', 'Device or Instrument Development', 'Devices', 'E-learning', 'Early Mobilizations', 'Evaluation', 'Family suidae', 'Feedback', 'Frequencies', 'Future', 'Gaussian model', 'Generations', 'Goals', 'Hospitals', 'Hour', 'Human', 'Knowledge', 'Learning', 'Light', 'Linear Regressions', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Modeling', 'Near-Infrared Spectroscopy', 'Neurologic', 'Organ', 'Outcome', 'Oxygen', 'Patients', 'Performance', 'Perfusion', 'Phase I Clinical Trials', 'Pre-Clinical Model', 'Process', 'Publishing', 'Recommendation', 'Research', 'Resuscitation', 'Shock', 'Survival Rate', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Ventricular Fibrillation', 'Ventricular Tachycardia', 'algorithm training', 'base', 'clinically relevant', 'coronary perfusion', 'experience', 'experimental study', 'hemodynamics', 'improved', 'in vivo', 'indexing', 'innovation', 'machine learning algorithm', 'neural network', 'out-of-hospital cardiac arrest', 'pre-clinical', 'prediction algorithm', 'pressure', 'prospective', 'time interval']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2021,547699
"Leveraging Data Science and Informatics in an Automated Detection System of Surgical Errors Technological advancements continue to improve surgical outcomes. However, these technologies also introduce new challenges such as communication complexities, equipment troubleshooting under intense pressure, and higher cognitive demand on OR team members. In other words, surgery will continue to be risky despite technological improvements. There is evidence the number of avoidable complications may be underreported, that approximately 39% of in-hospital adverse events are surgical related, and that as many as 4,000 surgical never events (events which should not have occurred) happen in the US each year. The eventual goal of this research is to develop an automated detection system (ADS) of high- risk surgical states. The ADS will prevent surgical safety incidents before they occur through real-time monitoring and notification of appropriate operating room (OR) team members ahead- of-time if there is a looming risk. Thereby allowing the team to reconsider next steps and address the underlying issues, and hence reduce the rates of negative surgical outcomes. This project demonstrates the feasibility and merit of essential components for an ADS. Specifically, the surgical safety literature provides compelling evidence that surgical work-flow disruption (FD) sequences are informative indicators of error causation, therefore it is likely that a future ADS will model and monitor surgical state through tracking flow disruptions. Our current aims are to (1) finish implementation of the Research & Exploratory Analysis Driven Time-data Visualization (READ-TV) research tool; open-source software to visualize FD patterns and other longitudinal data. (2) Develop a stochastic model to predict whether high-risk, disruptive FD sequences will occur based on FD rates at earlier time points. (3) Link FD patterns and sequences with surgical outcomes by developing a text classifier to identify whether or not a surgical safety incident or near-miss occurred based on the associated EHR note. The classifier will be a deep learning model trained with tens of thousands of surgical EHR notes. The text analysis in the third aim will provide insight to FD types and sequences that are more error prone, thereby revealing the FD patterns that an ADS should warn an OR team to avoid. Additional benefits of this text analysis include a possible confirmation of the existence of incident underreporting. Upon completion of the 3 aims, we will have a computational foundation for an ADS: our research tool (aim 1: READ-TV visualization software) and analyses (aim 3: link flow disruptions to safety incidents through EHR note analysis) will advance interpretation of flow disruption (FD) sequences, and our stochastic models (aim 2: predict future surgical state from FD sequences) will prospectively predict error-prone states. This foundation can be extended in future projects through research in automatic transcription of flow disruptions, and the proper mode of alert delivery if the surgery is prone to enter an error-prone state. Surgery by nature is risky for the patient and will continue to be so for the foreseeable future despite technological advancements. The surgical safety literature provides compelling evidence that surgical work-flow disruption (FD) sequences are informative indicators of error causation, and we propose that an automated detection system (ADS) can detect if a surgery has an entered a high-risk state through monitoring of FD sequences, thereby alerting the OR team and preemptively preventing a safety incident. As the first steps for such a system: our research visualization tool (Aim 1) will advance interpretation and clustering of FD sequences, our text-based artificial intelligence models (Aim 3) will link FD patterns and surgery characteristics to safety incidents through computational analysis of over 150,000 surgical notes, and our stochastic models (Aim 2) will verify that a high-risk surgical state can be predicted ahead-of-time by monitoring disruption sequences.",Leveraging Data Science and Informatics in an Automated Detection System of Surgical Errors,10149122,F31LM013402,"['Address', 'Adverse event', 'Artificial Intelligence', 'Characteristics', 'Clinical', 'Code', 'Cognitive', 'Communication', 'Communities', 'Companions', 'Computer Analysis', 'Computer software', 'Custom', 'Data', 'Data Science', 'Detection', 'Electronic Health Record', 'Engineering', 'Ensure', 'Equipment', 'Etiology', 'Event', 'Foundations', 'Future', 'Genetic Transcription', 'Goals', 'Grant', 'Hospitals', 'Informatics', 'Information Systems', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nature', 'Notification', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Prevalence', 'Procedures', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Series', 'Source Code', 'Surgical Error', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Update', 'Vision', 'Visualization', 'Visualization software', 'Work', 'adverse outcome', 'base', 'data visualization', 'data warehouse', 'deep learning', 'demographics', 'detection platform', 'high risk', 'improved', 'insight', 'large datasets', 'member', 'novel', 'open source', 'operation', 'predictive modeling', 'pressure', 'prevent', 'prospective', 'real time monitoring', 'robot assistance', 'surgery outcome', 'surgical risk', 'text searching', 'tool']",NLM,MEDICAL UNIVERSITY OF SOUTH CAROLINA,F31,2021,43491
"SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN) PROJECT SUMMARY/ABSTRACT In recent years, human cognitive auditory neuroscience has made rapid strides due to advances in human neuroimaging, the advent of innovative machine learning/big data analytic approaches, and a greater mechanistic understanding of cognitive-sensory interactions in animal models. The dynamic landscape of this emergent field necessitates a highly interdisciplinary, human and translation-centric symposium that brings together expertise across academia and industry. This application requests partial funding for the Symposium on Cognitive Auditory Neuroscience (SCAN) to be hosted in Pittsburgh, PA in July 2020 and 2022, as a joint venture between Carnegie Mellon University (CMU) and University of Pittsburgh (Pitt). As a biennial meeting, SCAN aims to become the premiere intellectual and professional venue for current research in the emerging field of human cognitive auditory neuroscience. SCAN will incorporate elements typical to academic conferences (research talks, posters) as well as novel ideas that promote ‘blue sky’ thinking in this rapidly evolving field. SCAN will assiduously and innovatively work towards inclusivity and creating an atmosphere that encourages intellectual and professional engagement from women, underrepresented minorities, and individuals with disabilities. Another critical aim of the SCAN is to foster industry-academic partnerships with an eye towards translation of basic research and fostering career opportunities for trainees. Pittsburgh is uniquely situated to launch SCAN. With an enviable concentration of co-located auditory neuroscience expertise, Pittsburgh is also an intellectual hub for industries/start-ups engaged in in machine learning, natural language processing, and speech recognition. SCAN will leverage these advantages to foster growth and innovation tied to core missions of the National Institutes of Deafness and Communication Disorders. PROJECT NARRATIVE The Symposium on Cognitive Auditory Neuroscience (SCAN) has a strong connection to deafness and communication disorders through its focus on the basic science of human cognitive auditory neuroscience, and its translation. SCAN will establish an intellectual home for dissemination of cutting-edge research in human cognitive auditory neuroscience, support the development of the next generation of scientists, build a vibrant and inclusive community that engages with the grand challenges in the field, and forge new academia-industry partnerships.",SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN),10078266,R13DC018243,"['Academia', 'Acoustics', 'Address', 'Affect', 'Americas', 'Animal Model', 'Atmosphere', 'Attention', 'Auditory', 'Auditory Perception', 'BRAIN initiative', 'Base of the Brain', 'Basic Science', 'Behavioral', 'Big Data Methods', 'Brain', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communities', 'Complex', 'Development', 'Disabled Persons', 'Disease', 'Ear', 'Educational workshop', 'Elements', 'Environment', 'Eye', 'Fertilization', 'Fostering', 'Funding', 'Geographic Locations', 'Goals', 'Growth', 'Hearing', 'Home environment', 'Human', 'Industry', 'Influentials', 'Institutes', 'Joint Ventures', 'Learning', 'Life', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Mission', 'Natural Language Processing', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Otolaryngology', 'Participant', 'Perception', 'Peripheral', 'Problem Solving', 'Process', 'Request for Applications', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Seeds', 'Sensory', 'Societies', 'Speech', 'Thinking', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'analytical tool', 'base', 'career', 'cognitive neuroscience', 'deafness', 'industry partner', 'innovation', 'interest', 'meetings', 'millisecond', 'neuroimaging', 'new technology', 'next generation', 'novel', 'open data', 'posters', 'pressure', 'relating to nervous system', 'sensory input', 'sound', 'speech recognition', 'symposium', 'virtual reality']",NIDCD,CARNEGIE-MELLON UNIVERSITY,R13,2021,1766
"Prevalence effects in visual research: Theoretical and practical implications Low prevalence searches form an important and problematic class of visual search tasks. These are tasks where the search target is rare. Many socially important tasks like airport security or cancer screening are low prevalence tasks. Previous work, much of it from our lab, has shown that low prevalence can have undesirable effects. Most notably, miss (false negative) errors are markedly elevated at low prevalence. This is a clear problem if the purpose of the search is to detect something rare but important like cancer or a terrorist threat. Our previous work has documented this pattern of increased miss errors in a number of expert domains including cytology (cervical cancer screening), airport baggage screening, and breast cancer screening. False alarm (false positive) error rates typically decline at low prevalence, moving in the opposite direction from miss errors. This indicates a shift in the observer’s decision criterion. At low prevalence, observers become more reluctant to call something a target. Several studies – ours and others - have shown that this “conservative” criterion shift is not adequate to explain the entire prevalence effect. Wolfe and VanWert (2010) developed a “Dual- Threshold” model that better captures the important aspects of the prevalence effect data by proposing two effects of low prevalence: (1) the conservative shift in the criterion for deciding if an attended item is a target, and (2) a lowering of the “quitting threshold.” The quitting threshold determines when observers end a search. Quitting too soon also increases the chance that the observer will miss a target. Prevalence effects have been studied in experimental isolation from other aspects of search. However, in tasks like breast cancer screening, other factors interact with prevalence. The four projects in the present proposal each investigate one of these interactions. Project 1 examines the relationship of prevalence to the “vigilance decrements” that are seen as time elapses in a task. In search, observers must maintain an internal, mental representation of the search target (or targets). Project 2 is concerned with the impact of prevalence on these “target templates”. Advances in artificial intelligence (notably deep learning) are producing tools to assist expert searchers. However, once deployed, these AI tools have been less effective than theory predicts. Project 3 tests the hypothesis that part of the problem is another side-effect of low prevalence and the project tests a potential intervention. Finally, clinicians, searching for one type of target (e.g. pneumonia) are supposed to report signs of other possible problems (e.g. lung cancer). Project 4 probes the role of prevalence in the failure to report such “incidental findings”. Again, we test several interventions. This is “use-inspired, basic research” whose results will provide guidance for experts performing socially important low prevalence tasks. Important tasks like breast cancer screening involve visual search for rare (“low prevalence”)  targets but, unfortunately, low prevalence is known to increase the percentage of targets that are  missed even by well-trained experts. In a task like breast cancer screening, prevalence interacts  with other factors like observer vigilance or the effectiveness of an artificial intelligence tool.  This proposal studies four of these interactions with the goal of counteracting the malign effects  of prevalence; thus making it possible for experts to perform their critical search tasks more  effectively.",Prevalence effects in visual research: Theoretical and practical implications,10111519,R01EY017001,"['Artificial Intelligence', 'Basic Science', 'Breast Cancer Detection', 'Cervical Cancer Screening', 'Collaborations', 'Cytology', 'Data', 'Detection', 'Effectiveness', 'Failure', 'Flecks', 'Goals', 'Human', 'Hybrids', 'Incidental Findings', 'Intervention', 'Joints', 'Low Prevalence', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methods', 'Modeling', 'Paper', 'Pattern', 'Performance', 'Pneumonia', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Screening for cancer', 'Security', 'Talents', 'Testing', 'Time', 'Training', 'Trust', 'Visual', 'Work', 'analog', 'base', 'clinically significant', 'deep learning', 'design', 'improved', 'mental representation', 'programs', 'side effect', 'social', 'theories', 'tool', 'vigilance', 'visual search']",NEI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,441020
"Differential artery-vein analysis in OCT angiography for objective classification of diabetic retinopathy Abstract: This project aims to establish differential artery-vein analysis in optical coherence tomography angiography (OCTA), and to validate comprehensive OCTA features for automated classification of diabetic retinopathy (DR). Early detection, prompt intervention, and reliable assessment of treatment outcomes are essential to prevent irreversible visual loss from DR. It is known that DR can target arteries and veins differently. Therefore, differential artery-vein analysis can provide better performance of DR detection and classification. However, clinical OCTA instruments lack the capability of artery-vein differentiation. During this project, we propose to use quantitative feature analysis of OCT, which is concurrently captured with OCTA, to guide artery- vein differentiation in OCTA. The first aim is to establish automated artery-vein differentiation in OCTA. In coordination with our recently demonstrated blood vessel tracking technique, OCT intensity/geometry features will be used to guide artery-vein differentiation in OCTA automatically. Differential artery-vein analysis of blood vessel tortuosity (BVT), blood vessel caliber (BVC), blood vessel density (BVD), vessel perimeter index (VPI), vessel branching coefficient (VBC), vessel branching angle (VBA), branching width ratio (BWR), fovea avascular zone area (FAZ-A) and FAZ contour irregularity (FAZ-CI) will be implemented. Key success criterion of the aim 1 study is to demonstrate robust artery-vein differentiation in OCTA, and to establish OCTA features for objective detection and classification of DR. The second aim is to validate automated OCTA classification of DR. We propose to employ ensemble machine learning to integrate multiple classifiers to achieve robust OCTA classification of DR. Key success criterion of the aim 2 study is to identify OCTA features and optimal-feature- combination to detect early DR, and to establish the correlations between the OCTA features and clinical biomarkers. The third aim is to verify OCTA prediction and evaluation of DR treatment. Our preliminary OCTA study of diabetic macular edema (DME) with anti-vascular endothelial growth factor (anti-VEGF) treatment has shown that BVD can serve as a biomarker predictive of visual improvement. During this project, we plan to test differential artery-vein analysis for DME treatment evaluation. Key success criterion of the aim 3 study is to identify artery-vein features to provide robust prediction and evaluation of DME treatment outcomes. As an alternative approach, we propose a fully convolutional neural network (FCNN) for deep machine leaning based artery-vein and DR classification. Early layers in the FCNN will produce simple features, which will be convolved and filtered into deeper layers to produce complex features for artery-vein and DR classification. Further investigation of the relationship between the new features learned through the machine learning process and clinical biomarkers will allow us to optimize the design for better DR classification. Success of this project will pave the way towards using quantitative OCTA features for early DR detection, objective prediction and assessment of treatment outcomes. Project Narrative This project is to establish quantitative optical coherence tomography angiography (OCTA) analysis for objective classification of diabetic retinopathy (DR). By translating subjective findings into objective assessments, this study will standardize clinical OCTA for eye disease detection and treatment assessment. In addition, objective OCTA analysis based automated DR classification can foster telemedicine in rural and underserved areas where the access to experienced ophthalmologists is limited.",Differential artery-vein analysis in OCT angiography for objective classification of diabetic retinopathy,10080731,R01EY030842,"['Adult', 'Affect', 'Angiography', 'Area', 'Arteries', 'Biological Markers', 'Blindness', 'Blood Vessels', 'Blood capillaries', 'Caliber', 'Classification', 'Clinical', 'Color', 'Complex', 'Derivation procedure', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exudate', 'Eye diseases', 'Fostering', 'Fundus photography', 'Geometry', 'Health Expenditures', 'Individual', 'Intervention', 'Investigation', 'Machine Learning', 'Maps', 'Methods', 'Microaneurysm', 'Modernization', 'Ophthalmologist', 'Optical Coherence Tomography', 'Optics', 'Performance', 'Process', 'Reflex action', 'Retina', 'Retinal Edemas', 'Retinal Hemorrhage', 'Sensitivity and Specificity', 'Source', 'Staging', 'Standardization', 'Symptoms', 'Techniques', 'Telemedicine', 'Testing', 'Thinness', 'Translating', 'Treatment outcome', 'Vascular Endothelial Growth Factors', 'Veins', 'Venous', 'Visual', 'Width', 'base', 'bevacizumab', 'clinical biomarkers', 'convolutional neural network', 'deep neural network', 'density', 'design', 'diabetic', 'diabetic patient', 'experience', 'fovea centralis', 'fundus imaging', 'global health', 'image registration', 'imaging capabilities', 'improved', 'indexing', 'instrument', 'macular edema', 'predictive marker', 'prevent', 'rural area', 'success', 'support vector machine', 'underserved area', 'vascular abnormality']",NEI,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,2021,351666
"Adapt2Quit – A Machine-Learning, Adaptive Motivational System: RCT for Socio-Economically Disadvantaged smokers” 7. Project Summary We will test Adapt2Quit, an innovative Machine-Learning, Adaptive Motivational Messaging System. Adapt2Quit uses complex, machine-learning algorithms to adaptively select the best messages for a smoker, based upon multiple attributes, including: 1) the smoker’s profile; 2) the smoker’s explicit feedback over time to the system; and 3) data from thousands of prior smokers’ profiles and their feedback patterns. Adapt2Quit’s type of machine- learning is called a recommender system. Outside healthcare, companies (like Amazon) use recommender systems to continuously learn from user feedback (e.g.: liked product, products purchased) to improve, thus enhancing personal relevance and customer engagement. Engagement is a huge challenge for digital health. In the field of computer-tailored health messaging, Adapt2Quit is the first to use machine-learning to continuously adapt to feedback and select new personalized messages to send to smokers. To evaluate the impact of the recommender system, Adapt2Quit will be compared with a robust, active control, a simple but effective messaging system. In our pilot experiment, Adapt2Quit outperformed the control, especially among socio- economically disadvantaged (SED) smokers. SED smokers are harder to engage in interventions. Thus, Adapt2Quit’s increased engagement will be of particular importance for targeting SED smokers. In addition to the potential impact of the Adapt2Quit messages in inducing and engaging smokers in cessation, our goal is to increase use of the state Quitline. We will recruit 700 SED smokers at two sites. All smokers will complete a baseline interview and receive a paper brochure with information about the state’s Quitline. Smokers will then be randomized to: Adapt2Quit or the standard messaging. As the system is designed to enhance engagement, and through engagement lead to positive actions, Aim 1 will focus on engagement [Hypothesis (H1a) Among Adapt2Quit smokers, those with higher engagement levels (completed more ratings) will have greater scores on the perceived competence scale (PCS)]. Aim 2 compares (Adapt2Quit and control) behavior change processes including perceived competence for smoking cessation and cessation supporting actions (calling a Quitline) [H2a: Adapt2Quit smokers will have greater scores on the PCS than control smokers; H2b: Adapt2Quit smokers will adopt more cessation supporting actions (Quitline, NRT) than control smokers]. Aim 3 will assess effectiveness of the system [H3a: (primary outcome) Adapt2Quit smokers will have greater smoking cessation rates (6-month point prevalence biochemically verified) than control smokers; H3b: (secondary outcome) Adapt2Quit smokers will have lower time to first quit attempt than control smokers; H3c: (mediation analysis) Measured internal and external processes will mediate the effect of Adapt2Quit on smoking cessation]. To accomplish the above aims, we have brought together a multidisciplinary team with relevant expertise, and a strong track record of collaboration. 8. Narrative We propose testing Adapt2Quit — an innovative motivational texting “recommender system.” Adapt2Quit enhances tailored motivational messaging systems using machine-learning algorithms to learn from, and adapt to, user feedback (prior and daily message ratings), thereby increasing message personal relevance. Our study will test Adapt2Quit motivational messaging texting with socioeconomically disadvantaged (SED) smokers.","Adapt2Quit – A Machine-Learning, Adaptive Motivational System: RCT for Socio-Economically Disadvantaged smokers”",10146309,R01CA240551,"['Address', 'Adopted', 'Award', 'Behavior Therapy', 'Behavioral', 'Belief', 'Biochemical', 'Collaborations', 'Competence', 'Complex', 'Computers', 'Data', 'Disease', 'Effectiveness', 'Engineering', 'Evaluation', 'Feedback', 'Frequencies', 'Funding', 'Goals', 'Health', 'Healthcare', 'Heterogeneity', 'Individual', 'Intervention', 'Interview', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Motivation', 'Odds Ratio', 'Pamphlets', 'Paper', 'Pattern', 'Prevalence', 'Process', 'Randomized', 'Readiness', 'Self Determination', 'Self Efficacy', 'Site', 'Smoke', 'Smoker', 'Smoking', 'Smoking and Health Research', 'System', 'Target Populations', 'Testing', 'Text Messaging', 'Time', 'active control', 'base', 'behavior change', 'design', 'digital health', 'disadvantaged population', 'effectiveness evaluation', 'evidence base', 'experimental study', 'health care settings', 'health disparity', 'high risk population', 'improved', 'innovation', 'learning progression', 'machine learning algorithm', 'multidisciplinary', 'nicotine replacement', 'primary outcome', 'quitline', 'recruit', 'rural healthcare', 'secondary outcome', 'smoking cessation', 'socioeconomic disadvantage', 'theories']",NCI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2021,644137
"Adaptive evolutionary inference frameworks for understudied populations using generative neural networks PROJECT SUMMARY In the field of population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, these algorithms rely heavily on simulated datasets, which currently fail to recapitulate the features of diverse natural genomes. Deep neural networks in particular are disconnected from evolutionary modeling, and their results are difficult to interpret in a biological context. In this project, we propose to develop simulation frameworks that automatically adapt to any population or species. The resulting customized synthetic datasets will be used to train neural networks that quantify the unique evolutionary histories of understudied human groups. By including genealogical and epigenetic information as auxiliary input, we will be able to link predictions back to genomic features. Our results will enable us to estimate the interactions between local phenomena such as natural selection, mutation patterns, and recombination hotspots. Taken together, outcomes from our work will allow us to create a detailed model evolutionary of processes, both along the genome and across human populations. PROJECT NARRATIVE In population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, it is difficult to apply these algorithms to understudied populations, as they are reliant on custom simulations, difficult to interpret, and disconnected from evolutionary modeling. The goals of this project are to develop simulation frameworks that automatically adapt to diverse datasets, allowing us to study evolutionary forces along the genome and across human populations.",Adaptive evolutionary inference frameworks for understudied populations using generative neural networks,10114449,R15HG011528,"['Admixture', 'African', 'Algorithms', 'Area', 'Back', 'Biological', 'Biological Process', 'Chromatin', 'Classification', 'Custom', 'Data', 'Data Set', 'Decision Trees', 'Epigenetic Process', 'European', 'Event', 'Evolution', 'Exposure to', 'Genealogy', 'Genes', 'Genetic Recombination', 'Genome', 'Genomic Segment', 'Genomics', 'Geography', 'Goals', 'Graph', 'Human', 'Human Genetics', 'Image', 'Individual', 'Industry', 'Internships', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Outcome', 'Pattern', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Recording of previous events', 'Research', 'Signal Transduction', 'Students', 'Training', 'Trees', 'Validation', 'Visualization', 'Work', 'automated algorithm', 'base', 'biobank', 'computer science', 'convolutional neural network', 'deep neural network', 'epigenetic marker', 'flexibility', 'health care settings', 'machine learning algorithm', 'machine learning method', 'methylation pattern', 'migration', 'neural network', 'simulation', 'single cell sequencing', 'statistics', 'theories', 'undergraduate student']",NHGRI,HAVERFORD COLLEGE,R15,2021,432494
"Optical design and the development of high accuracy automated tick classification using computer vision Abstract. The incidence of US tick-borne diseases has more than doubled in the last two decades. Due to lack of effective vaccines for tick-borne diseases, prevention of tick bites remains the primary focus of disease mitigation. Tick vector surveillance—monitoring an area to understand tick species composition, abundance, and spatial distribution—is key to providing the public with accurate and up-to-date information when they are in areas of high risk, and enabling precision vector control when necessary. Despite the importance of vector surveillance, current practices are highly resource intensive and require significant labor and time to collect and identify vector specimens. Acarologist or field taxonomist expertise is a limited resource required for tick identification, creating a significant capability barrier for national tick surveillance practice. While mobile applications to facilitate passive surveillance and reporting of human-tick encounters have grown in popularity, variable image quality, limited engagement, and scientist misidentification of rare, invasive, or morphologically similar tick species hinder the scalability of this approach. No automated solutions exist to build tick identification capacity. We seek to develop the first imaging and automated identification system capable of instantaneously and accurately identifying the top nine tick vectors in the US. This proposal will first characterize the optical requirements necessary to image diagnostic morphological features associated with adult ticks and develop a standardized imaging platform for tick identification. This will enable the development of a high-quality tick image dataset in partnership with the Walter Reed Biosystems Unit (WRBU) which will be used to train high-accuracy computer vision models for tick species and sex identification. Ultimately the approaches developed here will enable new tick identification tools for both the lab and citizen scientists; allowing vector surveillance managers to leverage image recognition in a practical system that will increase capacity and capability for biosurveillance, and equipping citizen scientists with improved tools to identify tick species during a human-tick encounter. Project Narrative. Despite the importance of tick vector surveillance for disease prevention, current practices to collect and identify specimens are resource intensive, limiting the quality and quantity of the data informing control efforts. Here we propose the determination of optical requirements for visualization of diagnostic features of the top nine US tick vectors, and the development of high-accuracy computer vision algorithms for the identification of tick species and sex for use in a standardized optical configuration. The high-accuracy tick classification system developed through this proposal promises to expand capacity and capability for tick vector surveillance.",Optical design and the development of high accuracy automated tick classification using computer vision,10325667,R43AI162425,"['Adult', 'Agreement', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Car Phone', 'Cellular Phone', 'Classification', 'Collaborations', 'Computer Vision Systems', 'Culicidae', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Disease Surveillance', 'Disease Vectors', 'Future', 'Goals', 'Grain', 'Human', 'Image', 'Incidence', 'Insecta', 'Larva', 'Learning', 'Leg', 'Life', 'Lighting', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Nymph', 'Optics', 'Phase', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Resolution', 'Resources', 'Scientist', 'Spatial Distribution', 'Specimen', 'Standardization', 'Surveillance Methods', 'System', 'Telephone', 'Testing', 'Tick-Borne Diseases', 'Ticks', 'Time', 'Training', 'Vaccines', 'Validation', 'Visual', 'Visualization', 'Work', 'base', 'citizen science', 'convolutional neural network', 'design', 'detection method', 'disorder prevention', 'field study', 'flexibility', 'high resolution imaging', 'high risk', 'human disease', 'imaging platform', 'imaging system', 'improved', 'insight', 'intelligent algorithm', 'interest', 'mobile application', 'novel', 'sample collection', 'sex', 'tick bite', 'tool', 'validation studies', 'vector', 'vector control', 'vector tick']",NIAID,"VECTECH, LLC",R43,2021,295705
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,10129965,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2021,403882
"A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment  Unhealthy diet is strongly linked to risks of chronic diseases, such as cardiovascular diseases, diabetes and certain types of cancer. The Global Burden of Disease Study has found that, among the top 17 risk factors, poor diet is overwhelmingly the No. 1 risk factor for human diseases. Despite the strong connection between diet and health, unhealthy foods with large portion sizes are widely consumed. Currently, 68.5% of U.S. adults are overweight, among the highest in developed countries. The recent decline in U.S. life expectancy sent another alarming signal about the general health of the American people. Understanding how the diet-related risk factors affect people’s health and finding effective ways to empower them in improving lifestyle habits are among the most important tasks in public health. Unfortunately, dietary assessment in real-world settings has been exceedingly complex and inaccurate to implement. Technology is needed that allows researchers to assess dietary intake easily and accurately in real world settings so that effective intervention to manage obesity and related chronic diseases can be developed. We propose a biomedical engineering project to address the dietary assessment problem, taking advantage of advanced mathematical modeling, wearable electronics and artificial intelligence.  Our research team has been improving the ability to assess diet for over a decade. We have designed the eButton, a small wearable device pinned on clothes in front of the chest, capable of collecting image-based dietary data objectively and passively (i.e., without depending on subject’s self-report or volitional operation of the device). We have also developed algorithms to compute food volumes and nutrients from images. Since the eButton was developed, it has been used by many researchers in the U.S. and other countries for objective and passive diet-intake studies in both adults and children.  Despite the past successes, there have been two lingering critical problems associated with the objective and passive dietary assessment using wearable devices: 1) substantial manual efforts are required for researchers to visually examine image data to identify foods and estimate their volumes (portion sizes), and 2) there are privacy concerns about researchers’ viewing of participants’ real-life images. Although solving these problems could enable the eButton and other wearable devices for large-scale diet-intake studies, we were not able to find effective solutions until recently when Artificial intelligence (AI) emerged. Advanced AI systems, especially those based on deep learning, can be trained by large amounts of labeled data to produce results comparable or even superior to those produced by human in numerous fields of applications. AI technology is also a powerful tool for dietary assessment, potentially providing an ideal solution to the two previously mentioned problems. We thus propose to develop a human-mimetic AI system to recognize foods from images, estimate portion sizes, and find energy and nutrient values from a database in a fully automatic process. Using the AI approach, there will be no need for researchers to view participants’ real-life images, and the AI system well-respects individuals’ privacy because it is trained to recognizes human foods only, nothing else.  Currently, the performances of existing AI systems are limited by the extensive variety and high variability of human foods, insufficient training data, and difficulty in finding appropriate nutritional information from food databases. In this application, we propose a new strategy to personalize the AI system for each research participant using an advanced mathematical model of personal food choices. With this personalization step, the dimensionality of our envisioned AI system can be reduced drastically, and our goal of automatic, objective and passive dietary assessment can be reached realistically. We also propose to improve the electronic hardware and develop a biomimetic camera to enlarge the field of view for the eButton. Finally, we will conduct a thorough evaluation of the personalized AI system in real-world settings using human subjects. This research aims to apply advanced mathematical modeling, wearable electronics and artificial intelligence to evaluate individual’s energy and nutrient intake automatically and objectively.","A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment",10111099,R01DK127310,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'American', 'Artificial Intelligence', 'Biomedical Engineering', 'Biomimetics', 'Cardiovascular Diseases', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Chest', 'Child', 'Chronic Disease', 'Complex', 'Consumption', 'Country', 'Data', 'Databases', 'Developed Countries', 'Devices', 'Diabetes Mellitus', 'Diet', 'Dietary Assessment', 'Dietary intake', 'Dietetics', 'Dimensions', 'Eating', 'Evaluation', 'Expert Systems', 'Eye', 'Feedback', 'Food', 'Food Energy', 'Future', 'Goals', 'Gold', 'Habits', 'Health', 'Health care facility', 'Healthcare', 'Heart Diseases', 'Human', 'Image', 'Individual', 'Intake', 'Label', 'Life', 'Life Expectancy', 'Life Style', 'Link', 'Malignant Neoplasms', 'Manuals', 'Modeling', 'Nutrient', 'Nutritional', 'Nutritional Science', 'Obesity', 'Output', 'Participant', 'Patient Self-Report', 'Performance', 'Persons', 'Play', 'Privacy', 'Problem Solving', 'Process', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Shapes', 'Signal Transduction', 'System', 'Technology', 'Training', 'Unhealthy Diet', 'Update', 'Volition', 'base', 'burden of illness', 'cancer type', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'dietary', 'effective intervention', 'field study', 'good diet', 'human disease', 'human subject', 'improved', 'infancy', 'intelligent algorithm', 'mathematical model', 'mimetics', 'neural network', 'obesity management', 'operation', 'overweight adults', 'robotic system', 'success', 'tool', 'validation studies', 'wearable device']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,657303
"Physically Realistic Virtual Surgery Physically Realistic Virtual Surgery Abstract While virtual reality (VR)-based surgical simulation technology is being developed to improve laparoscopic surgical training outside the operating room (OR), existing simulators focus mostly on technical skills (TS) of hand-eye coordination for isolated tasks and seldom on non-technical skills (NTS) associated with both cognitive skills of decision making, as well as interpersonal skills of communication, team-work and conflict resolution. To enable VR-based surgical simulators to also train for cognitive skills, in the previous grant period we successfully developed the next generation (Gen2) of laparoscopic surgical simulators that immerse the trainee in a virtual OR using a head-mounted display (HMD) system, and introduce distractions, interruptions and other stressors to capture the high-stress environment of the real OR. However, to the best of our knowledge, there exists no VR-based simulator for training interpersonal skills needed for the multidisciplinary integration of OR teams, which consist of surgeons, anesthesiologists, and perioperative nurses. Following the significant reduction of adverse events in other disciplines, such as aviation, by the introduction of mandatory simulation-based team training (e.g., crew resource management), the National Surgical Skills Curriculum developed by the American College of Surgeons (ACS) and Association of Program Directors in Surgery (APDS) has prescribed ten team-based training modules to be performed in a simulation facility (e.g., an OR endosuite) with scenario-based training on high- fidelity manikin simulators. However, such facility-based team training is extremely expensive and cumbersome, requires dedicated facility and faculty time, and entails significant planning and schedule coordination between trainees, technicians, and faculty. To overcome the challenges of facility-based OR team training, the goal of this project is to extend the immersive VR technology (Gen2) developed as part of our prior grant for a single user to the entire OR team, and harness recent advances in cloud computing, mobile device-based VR and artificial intelligence and machine learning to design, develop and evaluate a Virtual Operating Room Team Experience (VORTeX) simulation system. The VORTeX will allow the OR team to train together in a distributed fashion (i.e., not co-located in the same room or simulation facility) wearing mobile device-based HMD systems to develop further their NTS based on computer-generated simulation scenarios replacing the physical ones. Evaluation of the simulation scenarios will be performed asynchronously by a team of experts based on post-action replays. We will implement the VORTeX for a laparoscopic cholecystectomy crisis scenario, developed and validated by our Co-I Dr. Dan Jones at BIDMC and adopted as one of the team training modules of the ACS/APDS national surgical skills curriculum. We hypothesize that the VORTeX will be at least as good as or better than traditional facility-based simulation in providing non-technical skills training to OR teams. Project Narrative: The goal of this research is to develop and validate a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.",Physically Realistic Virtual Surgery,10296166,R01EB005807,"['Adopted', 'Adoption', 'Adverse event', 'American College of Surgeons', 'Artificial Intelligence', 'Aviation', 'Awareness', 'Behavior', 'Board Certification', 'Boston', 'Client', 'Cloud Computing', 'Communication', 'Computer Models', 'Computers', 'Consensus', 'Decision Making', 'Discipline', 'Educational Curriculum', 'Educational process of instructing', 'Effectiveness', 'Enrollment', 'Environment', 'Evaluation', 'Event', 'Exposure to', 'Face', 'Faculty', 'Feedback', 'Floor', 'Goals', 'Grant', 'Internet', 'Interruption', 'Israel', 'Laparoscopic Cholecystectomy', 'Length of Stay', 'Machine Learning', 'Manikins', 'Medical center', 'Minimally Invasive Surgical Procedures', 'Modeling', 'Morbidity - disease rate', 'Operating Rooms', 'Operative Surgical Procedures', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perioperative Nursing', 'Phase', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Resources', 'Risk', 'Running', 'Schedule', 'Software Framework', 'Standardization', 'Stress', 'Surgeon', 'Surgical complication', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Testing', 'Thinking', 'Time', 'Training', 'Training Activity', 'Translating', 'Treatment Cost', 'Variant', 'Work', 'base', 'cloud platform', 'cognitive skill', 'cognitive training', 'computer generated', 'conflict resolution', 'design', 'distraction', 'experience', 'experimental study', 'eye hand coordination', 'handheld mobile device', 'head mounted display', 'healing', 'improved', 'instructor', 'interactive computing', 'member', 'multidisciplinary', 'next generation', 'novel', 'programs', 'simulation', 'simulation environment', 'skills', 'skills training', 'stressor', 'success', 'virtual', 'virtual environment', 'virtual patient', 'virtual reality', 'virtual reality environment', 'virtual surgery']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R01,2021,654073
"Administrative Supplement: Using machine learning to predict odor characteristics from molecular structure PROJECT SUMMARY/ABSTRACT We cannot yet look at a chemical structure and predict if the molecule will have an odor, much less what character it will have. The goal of the proposed research is to apply machine learning to predict perceptual characteristics from chemical features of molecules. The specific aims of the proposal will determine (1) which molecules are odorous , and (2) what data are needed to model odor character. Building a highly predictive model requires two key ingredients: high-quality data and a sound modeling approach. High-quality data must be accurate (ratings are consistent and describe true odor properties) and detailed (ratings describe even small differences in odor properties). We have collected human psychophysical data on a diverse set of molecules and have trained a model to predict if a molecule has an odor, but pilot data identified odorous contaminants that limit model training and measurement of model accuracy. In Aim 1, I will apply my background in analytical chemistry to evaluate the accuracy of the data, using gas chromatography to identify and correct errors caused by chemical contaminants. In Aim 2, I will apply my experience in human sensory evaluation to measure and compare the consistency and the degree of detail in ratings that can be achieved with different sensory methods and subject training procedures. By executing my training plan, I will develop the skills in statistical programming and machine learning needed to employ a sound modeling approach to these problems. The model constructed in Aim 1 will enable prediction of odor classification (odor/odorless) for any molecule and thus define which molecules are perceptually relevant. Predicting odor character is a far more complex challenge – while a molecule can have only one of two odor classifications (odor or odorless) it may elicit any number of diverse odor character attributes (fruity, floral, musky, sweet, etc.). Descriptive Analysis (DA) is the gold standard method for generating accurate and detailed sensory profiles, but this method is time-consuming. We estimate that an odor character dataset will be large enough (“model-ready”) to predict odor character with approximately 10,000 molecules and that it would require more than 30,000 hours of human subject evaluation, or approximately 6 years for the typical trained panel, to produce this dataset using DA. Before we invest the time and resources, it is responsible to evaluate the relative data quality of more rapid sensory methods. The results of Aim 2 are expected to determine the best approach for generating a model-ready dataset by quantifying trade-offs in degree of detail (data resolution), rating consistency, and method speed of five candidate sensory methods. Together, these aims represent a significant step forward in linking chemical recipe to human odor perception, an advancement that supports the NIDCD goal of understanding normal olfactory function (how stimulus relates to percept) and has many potential applications in foods (what composition of molecules should be present to produce a target aroma percept). PROJECT NARRATIVE Currently, scientists cannot predict whether a molecule will have an odor and, if so, what odor characteristics it will have based on its chemical structure. The goal of this project is to develop predictive models linking chemical composition to odor characteristics. These models will advance our understanding of the human olfactory system and help design strategies for improving the aroma and palatability of healthy foods.",Administrative Supplement: Using machine learning to predict odor characteristics from molecular structure,10405294,F32DC019030,"['Address', 'Administrative Supplement', 'Analytical Chemistry', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Classification', 'Collection', 'Complex', 'Consumption', 'Data', 'Data Set', 'Descriptor', 'Development', 'Evaluation', 'Food', 'Fruit', 'Gas Chromatography', 'Goals', 'Gold', 'Health Food', 'Hour', 'Human', 'Human Resources', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Structure', 'National Institute on Deafness and Other Communication Disorders', 'Odors', 'Olfactory Pathways', 'Palate', 'Perception', 'Positioning Attribute', 'Procedures', 'Programmed Learning', 'Property', 'Protocols documentation', 'Psychophysics', 'Quality Control', 'Recipe', 'Research', 'Research Technics', 'Resolution', 'Resources', 'Sampling', 'Science', 'Scientist', 'Sensory', 'Smell Perception', 'Speed', 'Stimulus', 'Structure', 'Testing', 'Time', 'Training', 'Work', 'base', 'data quality', 'design', 'experience', 'food science', 'human subject', 'improved', 'machine learning algorithm', 'model building', 'predictive modeling', 'prevent', 'rapid technique', 'skills', 'sound']",NIDCD,MONELL CHEMICAL SENSES CENTER,F32,2021,2500
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,10150910,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction', 'risk prediction model', 'risk stratification', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2021,984177
"Patient specific 3D printed tissue engineered vascular graft for aortic reconstruction designed by artificial intelligence algorithm. 1 The goal of this study is to create patient-specific, hemodynamically optimized, tissue engineered  2 vascular grafts (TEVG) for use in aortic arch repair surgery. These TEVGs are optimized for high pressure  3 circulation using 3D printing technology and artificial intelligence, and will grow with the patient, in hopes of  4 obviating need for future surgeries to replace grafts, which can occur with contemporary arch reconstruction  5 materials. Congenital heart disease (CHD) is the leading cause of death due to congenital anomalies. Despite  6 significant advances in surgical management for CHD, one significant source of morbidity and mortality arises  7 from the complexity of surgery for diverse anatomies in the aortic arch. Previous studies have demonstrated  8 that the resultant arch geometry after surgical reconstruction of stenotic or hypoplastic aortas is important to  9 minimize reduce energy loss and undesirable flow inside the arch, which can lead to hypertension, abnormal 10 vascular response and ventricular dysfunction. Ensuring a patient-specific graft design for ideal reconstructed 11 route before surgery with minimum energy loss and wall shear stress may yield long-term benefits for patient 12 health and quality of life. 13 We have demonstrated native vessel like neotissue formation of TEVG in small and large animal 14 studies. Based on these experiences, we have developed a novel 3D printing technology combining 3D printed 15 metal mandrels with nanofiber electro-spun technology. With this 3D printing technology, we showed that 16 TEVG developed native like neovessel formation in venous circulation in a sheep model. For this next step, we 17 aim to develop grafts in arterial circulation that can be applied to aortic reconstruction. We will also develop 18 automatic design algorithms to design optimal graft shape in order to reduce time and cost of patient specific 19 design. We hypothesize that patient-specific TEVG using our 3D printing technology can be designed, 20 aided by pre-operative imaging and flow data, computer assisted design (CAD), automatic design 21 algorithms based on computation fluid dynamics (CFD) results, and will demonstrate proper neotissue 22 formation and growth while maintaining optimally designed hemodynamics. 23 This project will be an important step towards clinical application of patient-specific vascular grafts that 24 recapitulate the native anatomy and mechanical properties. The results of this work will have a broader impact 25 on the design and fabrication of other more complex cardiovascular structures for implantation. This paradigm 26 shift in vascular graft technology will improve the quality and safety of pediatric patient care. The goal of this study is to create patient-specific, hemodynamically optimized, tissue engineered vascular grafts using 3D printing technology and artificial intelligence for use in aortic arch repair surgery which demands a structured surgical approach in order to optimize hemodynamics postoperatively. We will optimize the design of an aortic graft automatically using computational flow dynamics, refine 3D printing manufacturing, evaluate grafts with in-vitro testing, and finally will test the performance of the grafts in vivo over time. This paradigm shift in vascular graft technology will improve the quality, safety and longevity of pediatric cardiovascular care.",Patient specific 3D printed tissue engineered vascular graft for aortic reconstruction designed by artificial intelligence algorithm.,10162386,R01HL143468,"['3-Dimensional', '3D Print', '4D MRI', 'Acute', 'Adult', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Animals', 'Aorta', 'Artificial Intelligence', 'Blood Circulation', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Cause of Death', 'Childhood', 'Clinic', 'Complex', 'Computer-Aided Design', 'Computers', 'Consumption', 'Custom', 'Data', 'Descending aorta', 'Ensure', 'Experimental Animal Model', 'FDA approved', 'Future', 'Geometry', 'Goals', 'Growth', 'Health', 'Histologic', 'Hypertension', 'Image', 'Implant', 'In Vitro', 'Inferior vena cava structure', 'Lead', 'Liquid substance', 'Longevity', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Organ', 'Patient Care', 'Patients', 'Performance', 'Physiological', 'Postoperative Period', 'Process', 'Quality of life', 'Route', 'Safety', 'Shapes', 'Sheep', 'Source', 'Structure', 'Surgical Management', 'Technology', 'Time', 'Tissue Engineering', 'Tissues', 'Translating', 'Vascular Graft', 'Venous', 'Ventricular Dysfunction', 'Work', 'aortic arch', 'base', 'clinical application', 'congenital anomaly', 'congenital heart disorder', 'cost', 'design', 'experience', 'hemodynamics', 'implantation', 'improved', 'in vitro testing', 'in vivo', 'intelligent algorithm', 'mechanical properties', 'model design', 'mortality', 'nanofiber', 'novel', 'pediatric patients', 'performance tests', 'preservation', 'pressure', 'reconstruction', 'repaired', 'response', 'scaffold', 'shear stress', 'surgery outcome', 'vascular tissue engineering']",NHLBI,UNIVERSITY OF CHICAGO,R01,2021,643908
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10256071,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2021,339505
"Therapeutic potential of vagal neurostimulation to reduce food intake Obesity affects almost 40% percent of US adults and is associated with high levels of comorbidities, including cancer, cardiovascular disease, and diabetes. Although effective treatments with minimal side effects are lacking, vagus nerve stimulation (VNS) can reduce body weight and suppress feeding behavior. There is little insight, however, into its mechanism and it is unclear whether VNS effects on feeding and body weight result from non-specific side effects, such as nausea. The current application directly addresses these issues by assessing gastrointestinal (GI) myoelectric changes as a potential mechanism for effects of VNS on feeding behavior, while comparing these responses to emetic activation. We plan to accomplish this by using a ferret model, which is a gold-standard for studying emesis, vagus nerve, and GI physiology. We will test the hypothesis that electrical stimulation of the vagus nerve can reduce food intake without triggering indicators of nausea, such as disrupted GI myoelectric responses, retching, and vomiting. We will complete three Aims. Aim 1: Define the individualized GI myoelectric patterns during feeding behavior using machine learning classification. Animals will be implanted with planar electrodes attached to the GI serosal surface from proximal gastric fundus to distal duodenum. We will use machine learning to classify GI myoelectric patterns of meal consumption compared to emetic-related states, including those elicited by intragastric emetine and high amplitude and frequency VNS known to trigger emesis. Aim 2: Test the efficacy of abdominal VNS on reducing meal size without triggering disruptions of GI myoelectric responses, retching, and emesis. Animals will be assessed for effects of abdominal VNS using a variety of stimulus parameters on feeding behavior and multi-site GI myoelectric recordings. Aim 3: Determine the efficacy of cervical VNS in controlling meal size without producing off-target effects (disruptions of GI myoelectric responses, retching, emesis, changes in heart rate, or blood pressure). We will test the impact of cervical VNS parameters on feeding behavior, GI myoelectric responses, retching, emesis, hear rate variability, and blood pressure. Our approach is innovative because we will use machine learning classification to detect individualized GI myoelectric response patterns in an awake free-moving animal for comparing therapeutic and off-target effects of VNS on feeding, GI activity, emesis, and cardiovascular function. This planned research is significant because VNS therapy can potentially provide a frontline treatment option for patients with high levels of obesity refractory to behavioral or pharmacological therapy, which unlike other surgical interventions for weight loss, such as gastric bypass, is potentially tunable and reversible by changing stimulation parameters, switching the device off, or complete removal. Obesity affects almost 40% percent of US adults, is associated with type 2 diabetes, cardiovascular disease, and cancer, and has a health-care cost that could total nearly one trillion US dollars by 2030. The current project is designed to test vagus nerve stimulation to reduce food intake, while limiting adverse effects, such as nausea, vomiting, and disrupted gastrointestinal function. Our proposed research is relevant to the NIH’s plan to support the design and testing of new interventions for achieving and maintaining a healthy weight (Strategic Plan for NIH Obesity Research).",Therapeutic potential of vagal neurostimulation to reduce food intake,10207620,R01DK121703,"['Abdomen', 'Address', 'Adult', 'Adverse effects', 'Affect', 'Anatomy', 'Animals', 'Behavioral', 'Blood Pressure', 'Body Weight', 'Body Weight decreased', 'Cardiovascular Diseases', 'Cardiovascular Physiology', 'Cardiovascular system', 'Cervical', 'Chemicals', 'Chronic', 'Classification', 'Consumption', 'Data', 'Devices', 'Diabetes Mellitus', 'Distal', 'Duodenum', 'Eating', 'Electric Stimulation', 'Electrodes', 'Emetics', 'Emetine', 'Event', 'Excision', 'FDA approved', 'Feeding behaviors', 'Ferrets', 'Fiber', 'Frequencies', 'Gastric Bypass', 'Gastrointestinal Motility', 'Gastrointestinal Physiology', 'Gastrointestinal tract structure', 'Goals', 'Gold', 'Health Care Costs', 'Hearing', 'Heart Rate', 'Implant', 'Individual', 'Intervention', 'Laboratory Rat', 'Laboratory mice', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Modeling', 'Nausea', 'Nausea and Vomiting', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pharmacology', 'Phenotype', 'Physiological', 'Rattus', 'Refractory', 'Reporting', 'Research', 'Rodent Model', 'Satiation', 'Sensory', 'Signal Transduction', 'Site', 'Sleep', 'Stimulus', 'Stomach', 'Strategic Planning', 'Surface', 'Testing', 'Therapeutic', 'Training', 'United States National Institutes of Health', 'Upper digestive tract structure', 'Vagus nerve structure', 'Vomiting', 'awake', 'behavioral pharmacology', 'comorbidity', 'design', 'effective therapy', 'effectiveness evaluation', 'efficacy testing', 'experimental study', 'feeding', 'gastric fundus', 'gastrointestinal', 'gastrointestinal function', 'healthy weight', 'heart rate variability', 'indexing', 'innovation', 'insight', 'learning classifier', 'machine learning algorithm', 'obesity treatment', 'personalized medicine', 'pre-clinical', 'predicting response', 'recruit', 'reduced food intake', 'response', 'side effect', 'support vector machine', 'therapeutic target', 'vagus nerve stimulation', 'weight loss intervention']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,482164
"Machine learning accelerated on-line adaptive replanning Abstract. The overall goal of this proposal is to develop and test a novel machine learning (ML) accelerated On-Line Adaptive Replanning (MOLAR) solution for magnetic resonance imaging (MRI) guided radiation therapy (RT) (MRgRT). During the multi-fraction RT process, the location, shape and size of tumors and normal organs vary significantly between the fractions. These interfraction variations are among the major factors that can limit the accuracy of RT targeting. The current standard practice of image-guided RT (IGRT), developed to address the interfraction variations based on cone-beam CT (CBCT), can only correct for translational errors, and thus does not fully account for interfraction changes. To address this issue, researchers recently introduced online adaptive replanning (OLAR) that generates a new plan based on the anatomy of the day and delivers the plan for the fraction. Currently, two main obstacles affect the success of OLAR: (1) the anatomy of the day cannot be delineated accurately based on CBCT, and (2) the time required to perform OLAR is long enough to render it impractical. One way to improve the delineation accuracy is to use MRI versus CT. MRI-guided OLAR is currently being introduced into the clinics to substantially improve RT targeting. However, the bottleneck is still the impractical length of time required to segment the anatomy of the day, which can exceed 30 minutes. Furthermore, available synthetic CT (sCT) generation methods are slow or inaccurate for MRI-guided OLAR. There is no method available to quickly and objective determine when OLAR is necessary. To address these issues, we plan to develop novel techniques in the MOLAR solution. We hypothesize that the MRI-based MOLAR solution will fully account for interfraction changes, thereby substantially improving tumor targeting during RT delivery and the effectiveness of RT. Specifically, we aim to (1) develop practical ML-based solutions to quickly determine the necessity of OLAR and to rapidly generate accurate synthetic CTs; (2) develop ML-based techniques to substantially accelerate segmentation for OLAR using a progressive three-step process; and (3) verify clinical practicality and effectiveness of MOLAR by retrospectively and prospectively applying the MOLAR on MRI sets to test its speed and effectiveness in accounting for interfraction variations. We will develop this novel MOLAR solution by forging unique collaborations between clinical physicists, radiation oncologists and industry developers via an established academic-industry partnership. The successful completion of this project will enable clinicians to routinely practice “image-plan-treat”, which is the optimal solution for MRgRT. This new paradigm will fully account for interfraction variations, improve tumor targeting, reduce normal tissue toxicity, and ultimately encourage clinicians to revise the current doses and/or dose fractionations to increase therapeutic gain, enhance patient quality of life, and/or substantially save on healthcare costs. Our proposed strategy represents a drastic departure from current practice. We firmly believe that this strategy is the future of RT delivery. Project Narrative: This R01 application proposes to develop and test a novel machine learning accelerated online adaptive replanning (MOLAR) solution for magnetic resonance imaging (MRI) guided adaptive radiation therapy through a unique academic and industry partnership. The MOLAR solution aims to fully account for interfraction variations, thereby substantially improving the accuracy and effectiveness of radiation therapy (RT) for cancer. This solution will enable clinicians to routinely practice “image-plan-treat”, a drastic departure from current practice and representing the future of RT delivery.",Machine learning accelerated on-line adaptive replanning,10129924,R01CA247960,"['3-Dimensional', 'Accounting', 'Address', 'Adoption', 'Affect', 'Air', 'Anatomy', 'Clinic', 'Clinical', 'Collaborations', 'Dose Fractionation', 'Effectiveness', 'Electron Transport', 'Future', 'Generations', 'Goals', 'Health Care Costs', 'Image', 'Industry', 'Learning', 'Length', 'Location', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of pancreas', 'Maps', 'Methodology', 'Methods', 'Modality', 'Normal tissue morphology', 'Organ', 'Patients', 'Physiology', 'Process', 'Quality of life', 'Radiation Oncologist', 'Radiation therapy', 'Research Personnel', 'Shapes', 'Site', 'Speed', 'Surface', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Toxic effect', 'Variant', 'automated segmentation', 'base', 'bone', 'cancer radiation therapy', 'cone-beam computed tomography', 'convolutional neural network', 'electron density', 'forging', 'image guided', 'image guided radiation therapy', 'imaging modality', 'improved', 'industry partner', 'innovation', 'large datasets', 'neural network algorithm', 'novel', 'pancreatic cancer patients', 'prospective', 'prospective test', 'quantitative imaging', 'routine practice', 'soft tissue', 'success', 'targeted treatment', 'tool', 'treatment response', 'tumor']",NCI,MEDICAL COLLEGE OF WISCONSIN,R01,2021,495299
"Improving Diagnosis of Multiple Sclerosis Through the Integration of Novel Imaging and Laboratory Biomarkers Project Summary/Abstract:  The diagnosis of multiple sclerosis (MS) remains challenging due to its clinical heterogeneity and lengthy differential diagnosis. The incorrect assignment of a diagnosis of MS occurs in approximately 9% of newly evaluated patients and is associated with considerable clinically important, and avoidable, medical risk, morbidity, and healthcare costs. At the same time studies have demonstrated that many patients encounter a significant diagnostic delay prior to confirmation of a correct diagnosis of MS. In such patients early and accurate diagnosis of MS can result in prompt initiation of disease modifying therapy and consequent preventable disability. MS remains a clinical diagnosis and diagnostic criteria for MS are revised periodically, including most recently in 2017. Since implementation of the 2017 criteria, like all prior revisions, will continue to rely on subjective clinical and radiological assessments for its fulfillment, misdiagnosis will remain a risk.  New objective, automated, and clinically applicable approaches to MS diagnosis are needed. Recent preliminary data from cross-sectional pilot studies in patients with established diagnoses have shown promise for three new radiographic and three new laboratory methods to differentiate MS from other disorders. The present study will evaluate these six methods for the first time in a prospective cohort of 125 patients undergoing an initial evaluation for MS at an academic MS subspecialty center. The specificity and sensitivity of each method will be compared to fulfillment of 2017 MS diagnostic criteria at the time of initial clinical evaluation. Using diagnostic thresholds developed from this analysis, a two year post-enrollment analysis will also be performed in participants who did not meet 2017 criteria initially but did so during the subsequent two year interval to determine if the study methods could have predicted a diagnosis of MS earlier in such patients. The use of a multimodal and machine-learning approach to evaluate the integration of each of these six new methods which represent different aspects of MS neuroinflammatory and neurodegenerative processes will also be performed during each analysis, and such a combination of radiographic and laboratory methodology may provide superior diagnostic accuracy compared to any given method alone.  Planned collaborative career development, mentoring, and advising activities will facilitate acquisition of specific advanced quantitative and qualitative research skills necessary to develop and coordinate collection of data for this large prospective cohort study to rigorously evaluate new diagnostic methods for MS and incorporate machine learning analyses. Successful completion of this study will provide experience and skills necessary to move the field of MS diagnosis forward through a planned prospective multicenter NIH R01 funded study. Project Narrative: A highly specific, sensitive, objective and automated novel diagnostic approach to multiple sclerosis (MS) is needed maximize early benefits of disease modifying therapy in patients with MS and to prevent the frequent problem of MS misdiagnosis. This project assesses three novel MRI techniques and three novel blood tests for the diagnosis of MS in a large prospective cohort undergoing a new clinical evaluation for suspect MS. While each method may show promise alone, utilization of machine learning methodology combining these approaches that represent different aspects of MS pathophysiology may demonstrate a highly accurate and clinically applicable methodology for MS diagnosis.",Improving Diagnosis of Multiple Sclerosis Through the Integration of Novel Imaging and Laboratory Biomarkers,10070136,K02NS109340,"['Algorithms', 'Appearance', 'Atrophic', 'Binding', 'Biological Assay', 'Biological Markers', 'Blood Tests', 'C-Peptide', 'Central Vein', 'Clinical', 'Clinical/Radiologic', 'Computer Models', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic radiologic examination', 'Differential Diagnosis', 'Disease', 'Early Diagnosis', 'Enrollment', 'Erythrocytes', 'Evaluation', 'Evolution', 'Functional disorder', 'Funding', 'Gene Expression', 'Goals', 'Gold', 'Health Care Costs', 'Image', 'Inflammatory', 'Laboratories', 'Lesion', 'Light', 'Liquid substance', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Multiple Sclerosis', 'Myelin', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuronal Injury', 'Participant', 'Pathogenesis', 'Patients', 'Peptides', 'Pilot Projects', 'Process', 'Prospective cohort', 'Prospective cohort study', 'Qualitative Research', 'RNA', 'Rare Diseases', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Specificity', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Thalamic structure', 'Time', 'Training', 'United States National Institutes of Health', 'Untranslated RNA', 'Whole Blood', 'accurate diagnosis', 'career development', 'clinical Diagnosis', 'clinical application', 'clinical diagnostics', 'clinical heterogeneity', 'clinical phenotype', 'clinical practice', 'cohort', 'diagnostic accuracy', 'disability', 'disease heterogeneity', 'experience', 'gray matter', 'improved', 'machine learning method', 'multimodality', 'multiple sclerosis patient', 'neurofilament', 'neuroinflammation', 'novel', 'novel diagnostics', 'novel imaging technique', 'prevent', 'prospective', 'recruit', 'research clinical testing', 'skills', 'specific biomarkers', 'support vector machine', 'white matter']",NINDS,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,K02,2021,192792
"Optical Coherence Elastography of the Cornea PROJECT SUMMARY The fundamental physical properties of the outer tunic of the eye determine the structural characteristics of the ocular globe and may be altered in several devastating disease states including axial elongation in myopia, pathological deformation in keratoconus, and iatrogenic keratoectasia following corneal refractive surgery. These biomechanical tissue characteristics not only influence our clinical interpretation of diagnostic tests, e.g. measurement of intraocular pressure, but have been implicated as important factors in the development of glaucoma. Currently, there is no available reliable method to perform quantitative measurement of corneal elasticity in vivo. Here we will develop novel method for the assessment of corneal elastic properties that could potentially be used for routine clinical diagnostic and treatment. This method will take advantages of highly localized air pressure stimulation and ultra-sensitive detection and analysis of the pressure waves propagation on corneal posterior and anterior surfaces with a line-field Optical Coherence Tomography to reconstruct volumetric biomechanical properties of the cornea. Our previous work has made fundamental advances in the understanding of corneal biomechanics through a novel approach with potentially impactful applications in other disciplines (e.g. cataract surgery, LAISK, corneal cross-linking, and tissue transplants with personalize treatments). The proposed studies will accelerate transition of this technology into clinics, influence our selection and application of corneal surgical treatments and will help us to understand the structural consequences of corneal disease and wound healing: Aim 1. Develop a line-field OCE (LF-OCE) system for ultrafast 3D clinical imaging. Aim 2. In vivo studies with rabbits. Aim 3. Preliminary clinical studies in humans. Aim 4. Refine numerical (FEM) and Artificial Intelligence (AI) models of the depth-dependent nonlinear viscoelastic properties of the cornea. PROJECT NARRATIVE This proposal will focus on the development of novel technology and methods for noninvasive assessment of biomechanical properties of the cornea. Development of such a technique would significantly advance our understanding of the corneal disorders, allow developing novel clinical therapies and interventions, and improve outcome of current surgical ant therapeutic interventions.",Optical Coherence Elastography of the Cornea,10256083,R01EY022362,"['3-Dimensional', 'Achievement', 'Agreement', 'Air Pressure', 'Animals', 'Anisotropy', 'Anterior', 'Ants', 'Artificial Intelligence', 'Beds', 'Biological', 'Biomechanics', 'Cataract Extraction', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Connective Tissue', 'Cornea', 'Corneal Diseases', 'Custom', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Diagnostic tests', 'Discipline', 'Disease', 'Elasticity', 'Eye', 'Glaucoma', 'Goals', 'Heterogeneity', 'Human', 'Iatrogenesis', 'Image', 'Individual', 'Intervention', 'Keratoconus', 'Knowledge', 'Laser In Situ Keratomileusis', 'Link', 'Location', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Myopia', 'Nature', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Outcome', 'Pathologic', 'Patients', 'Physiologic Intraocular Pressure', 'Physiological', 'Property', 'Protocols documentation', 'Reaction', 'Reporting', 'Research', 'Routine Diagnostic Tests', 'Shapes', 'Signal Transduction', 'Speed', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Time', 'Tissue Transplantation', 'Tissues', 'Training', 'Tunic', 'Validation', 'Variant', 'Work', 'base', 'biomechanical model', 'clinical diagnostics', 'clinical imaging', 'clinical translation', 'clinically significant', 'convolutional neural network', 'corneal epithelial wound healing', 'crosslink', 'deep learning', 'denoising', 'design', 'elastography', 'improved', 'improved outcome', 'in vivo', 'insight', 'mechanical properties', 'models and simulation', 'new technology', 'novel', 'novel strategies', 'personalized medicine', 'physical property', 'pressure', 'response', 'success', 'viscoelasticity', 'visual tracking']",NEI,UNIVERSITY OF HOUSTON,R01,2021,397700
"Virtual Histology for Assessing MS Pathologies PROJECT SUMMARY Multiple sclerosis (MS) is an inflammatory demyelinating disease with, ultimately, irreversible axonal injury leading to permanent neurological disabilities. Preventing disease progression or treating progressive MS remains a major unmet clinical need. We have previously developed a novel data-driven model-selection diffusion basis spectrum imaging (DBSI) to accurately image inflammation, demyelination, and axonal injury, as well as quantifying axonal loss in the presence of vasogenic edema in experimental autoimmune encephalomyelitis (EAE) and spinal cord injury mice, and brain WM pathologies in MS. MRI does not distinguish inter- from intra-axonal water signals, reflecting a weighted-average of signals between the two compartments. However, our recent observation that DBSI derived axial diffusivity (DBSI-λǁ) was slightly elevated in normal appearing white matter (NAWM) in people with MS (pwMS). This elevated DBSI-λǁ added uncertainty in assessing whether axonal injury (against the notion that ↓DBSI-λǁ ≈ axonal injury) is present in NAWM of these pwMS. In this proposed study, we will refine DBSI to further improve its sensitivity and specificity to axonal injury/loss, demyelination, and inflammation for accurately assessing disease progression and therapeutic efficacy in pwMS. Since MRI does not distinguish inter- from intra-axonal water signals, it reflects a weighted-average between inter- and intra-axonal signals. In the presence of inflammation-associated edema or minor axonal loss in pwMS, the longer diffusion time for human scanners coupled with the increased inter-axonal space will lead to increased DBSI-λǁ masking the detectability of axonal injury. Thus, through separating inter- and intra-axonal water compartment signals, the sensitivity and specificity to axonal injury of DBSI-derived intra-axonal λ|| (DBSI-IA-λ||) may be improved. This new model will still preserve the isotropic diffusion specificity to inflammation and tissue loss. We propose three specific aims to prove or disprove this hypothesis: Aim 1. To perform DBSI and DBSI-IA analyses on autopsy specimens from pwMS followed by conventional histology and immunohistochemical staining. Aim 2. To perform DBSI and DBSI-IA modeling on perfused frog sciatic nerve with and without contrast agent to separate inter-/intra-axonal space water signal. Aim 3a. To develop a Diffusion Histology Imaging (DHI) approach combining DBSI/DBSI-IA metrics and machine/deep learning algorithms to recapitulate histology specificity to MS pathology. Aim 3b. To translate DBSI-IA model to analyze existing DWI data from the cohort of pwMS previously imaged in an expired program project. PROJECT NARRATIVE Multiple sclerosis (MS) is common, affecting over 700,000 people in the US. It is an inflammatory demyelinating disease of the central nervous system with pronounced axon damage inflicting long-term neurological disability. Accurate assessment of axonal injury early especially in normal appearing white matter is crucially important in therapeutic intervention. For example, we cannot expect remyelination to work on absent or critically injured axons. Thus, the proposed diffusion basis spectrum imaging to model intra-axonal diffusion for improving the sensitivity of detecting axonal injury is of great importance in treating and curing MS.",Virtual Histology for Assessing MS Pathologies,10121338,R01NS116091,"['Affect', 'Area', 'Autopsy', 'Axon', 'Biological Markers', 'Brain', 'Cellularity', 'Clinical', 'Code', 'Contrast Media', 'Coupled', 'Data', 'Demyelinating Diseases', 'Demyelinations', 'Development', 'Diffuse', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease Progression', 'Edema', 'Electrophysiology (science)', 'Experimental Autoimmune Encephalomyelitis', 'Experimental Designs', 'Fast Blue', 'Fiber', 'Gadolinium DTPA', 'Gadopentetate Dimeglumine', 'Germany', 'Glucose', 'Histologic', 'Histology', 'Human', 'Image', 'Immunohistochemistry', 'Inflammation', 'Inflammatory', 'Injury', 'Magnetic Resonance Imaging', 'Masks', 'Measurement', 'Minor', 'Modeling', 'Morphology', 'Multiple Sclerosis', 'Mus', 'Myelin', 'Nerve', 'Neurologic', 'Optic Nerve', 'Pathology', 'Perfusion', 'Periodic acid Schiff stain method', 'Rana', 'Reporting', 'Ringer&apos', 's solution', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Silver', 'Specificity', 'Specimen', 'Spinal cord injury', 'Stains', 'Structure', 'Temperature', 'Therapeutic Intervention', 'Thinness', 'Time', 'Tissues', 'Tolonium chloride', 'Translating', 'Treatment Efficacy', 'Uncertainty', 'Validation', 'Water', 'Work', 'axon injury', 'base', 'central nervous system demyelinating disorder', 'central nervous system injury', 'cohort', 'deep learning algorithm', 'deep neural network', 'density', 'disability', 'imaging approach', 'improved', 'in vivo', 'manganese chloride', 'neurotransmission', 'novel', 'preservation', 'prevent', 'programs', 'remyelination', 'sciatic nerve', 'severe injury', 'spectrograph', 'support vector machine', 'vasogenic edema', 'virtual', 'white matter']",NINDS,WASHINGTON UNIVERSITY,R01,2021,473791
"Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1 PROJECT SUMMARY Previous studies showed discrepancies of health and behavior prevalence between American Indians (AI) population and other racial or ethnic groups. Most health surveys have certain limitations when studying AI population due to the small sample sizes for AI population. Data collected by AI Tribal Epidemiology Centers (TECs) provides an excellent opportunity to conduct research for AI population due to sufficient sample size and extensive information. However, most surveys conducted by TECs used non-probability sampling design (e.g. convenient sample) due to its lower cost and increased time efficiency. Non-probability sample may suffer from sampling, coverage and nonresponse errors without further proper adjustments. Such difficulties greatly hampers the analysis of AI population in health and behavior research. Our general hypothesis is that data integration by combining information from non-probability and probability samples can reduce sampling, coverage and nonresponse errors in original non-probability sample. The Goal of this project is to develop an accurate and robust data integration methodology for AI population analysis specifically tailored to health and behavior research. During the past years, we have 1) studied data integration using calibration and parametric modeling approaches; 2) investigated machine learning and propensity score modeling methods in survey sampling and other fields; and 3) assembled an experienced team of multi-disciplinary team of experts. In this project, we propose to capitalize on our expertise and fulfill the following Specific Aims: Aim 1. Develop a data integration approach using machine learning and propensity score modeling We will develop machine learning and propensity score based data integration approaches to combine information from non-probability and probability samples. Compared to existing methods (i.e., Calibration, Parametric approach), our proposed approaches are more robust against the failure of underlying model assumptions. The inference is more general and multi-purpose (e.g. one can estimate most parameters such as means, totals and percentiles). Simulation studies will be performed to compare our proposed methods with other existing methods. A computing package will be built to implement the method in other settings. Aim 2. Evaluate the accuracy and robustness of the proposed method in AI health and behavior research We will use real data to validate the proposed methods in terms of accuracy and robustness to the various data types. The performance will also be assessed by comparing with results from existing data integration methods such as calibration and parametric modeling approaches. The planned study takes advantage of a unique data source and expands the impact of the Indian Health Service (IHS)-funded research. We expect this novel integration method will vertically advance the field by facilitating the analysis based on non-probability sample, which can provide in-depth understanding regarding the AI population health and behavior studies. Project Narrative The overall goal of this R21 project is to develop an accurate, robust and multi-purpose data integration methodology for AI population (non-probability sample) analysis specifically tailored to health and behavior research such as diabetes and smoking. The code implementing the proposed method will be released and is general enough to be applied to AI population studies of other fileds. The success of this study will vertically advance the field by facilitating the AI population analysis, which can provide a better guidance and new insights on the future precision personalized prevention and treatment of certain diseases.",Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1,10271402,R21MD014658,"['Adult', 'Age', 'American', 'American Indians', 'Behavioral', 'Behavioral Risk Factor Surveillance System', 'Calibration', 'Censuses', 'Code', 'Communities', 'Community Surveys', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Sources', 'Diabetes Mellitus', 'Disease', 'Epidemiology', 'Ethnic group', 'Event', 'Failure', 'Funding', 'Future', 'General Population', 'Geographic state', 'Goals', 'Health', 'Health Fairs', 'Health Surveys', 'Health behavior', 'High Prevalence', 'Kansas', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Not Hispanic or Latino', 'Oklahoma', 'Performance', 'Population', 'Population Analysis', 'Population Study', 'Prevalence', 'Probability', 'Probability Samples', 'Publishing', 'Race', 'Research', 'Research Personnel', 'Respondent', 'Risk Factors', 'Sample Size', 'Sampling', 'Smoking', 'Surveys', 'Target Populations', 'Testing', 'Texas', 'Time', 'Tobacco', 'Training', 'United States Indian Health Service', 'Weight', 'Work', 'Youth', 'base', 'behavioral study', 'cigarette smoking', 'cluster computing', 'cost', 'data integration', 'data quality', 'design', 'experience', 'improved', 'individualized prevention', 'innovation', 'insight', 'multidisciplinary', 'novel', 'personalized medicine', 'population health', 'simulation', 'smoking prevalence', 'success', 'therapy development', 'tribal health']",NIMHD,UNIVERSITY OF OKLAHOMA HLTH SCIENCES CTR,R21,2021,109613
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Abstract Selective internal radiation therapy (SIRT) with preferential delivery of 90Y microspheres to target lesions has shown promising response rates with limited toxicity in the treatment of hepatocellular (HCC), the second leading cause of cancer death in the world. However, to achieve more durable responses, there is much room to improve/adapt the treatment to ensure that all lesions and lesion sub-regions receive adequate radiation delivery. While externally delivered stereotactic body radiation therapy (SBRT) is well suited for smaller solitary HCC, its application for larger or multifocal disease is challenged by the radiation tolerance of the normal liver parenchyma. A dosimetry guided combined approach that exploits complementary advantages of internal and external radiation delivery can be expected to improve treatment of HCC. To make this transition, however, prospective clinical trials establishing safety are needed. Furthermore, for routine clinic use, accurate and fast voxel-level dose estimation in internal radionuclide therapy, that lags behind external beam therapy dosimetry, is still needed. Our long-term goal is to improve the efficacy of radiation therapy with personalized dosimetry guided treatment. Our objective in this application is to demonstrate that it is possible to use 90Y imaging based absorbed dose estimates after SIRT to safely deliver external radiation to target regions (voxels) that are predicted to be underdosed and to develop deep learning based tools to make voxel-level internal dose estimation practical for routine clinic use. Specifically, in Aim 1, we will perform a Phase 1 clinical trial in HCC patients where we will take the novel approach of using the 90Y PET/CT derived absorbed dose map after SIRT to deliver SBRT to tumor regions predicted to be underdosed based on previously established dose-response models. The primary objective of the trial is to obtain estimates of safety of combined SIRT+SBRT for future Phase II trial design. In parallel, in Aim 2, building on promising initial results we will develop novel deep learning based tools for 90Y PET/CT and SPECT/CT reconstruction, joint reconstruction-segmentation and scatter estimation under the low count-rate setting, typical for 90Y. These methods have a physics/mathematics foundation, where convolutional neural networks (CNNs) are included within the iterative reconstruction process, instead of post-reconstruction denoising. In Aim 3, we will develop a CNN for fast voxel-level dosimetry and combine with the CNNs of Aim 2 to develop an innovative end-to-end framework with unified dosimetry-task based training. At the end of this study, we will be ready to use the new deep learning tools in a Phase II trial to demonstrate enhanced efficacy with SIRT+SBRT compared with SIRT alone and advance towards our long- term goal. This will accelerate adoption of these next-generation tools in clinical practice and will have a significant positive impact because treatment based on patient specific dosimetry will substantially improve efficacy, compared with current standard practice in SIRT. Although we focus on 90Y SIRT, our tools will be applicable in radionuclide therapy in general, a rapidly advancing treatment option. Narrative We will perform a Phase I clinical trial where standard-of-care Y-90 microsphere radioembolization in hepatocellular carcinoma will be followed by external radiation to target regions that are predicted to be underdosed by Y-90, based on patient specific dosimetry. In parallel, we will develop and test voxel-level internal dosimetry tools using convolution neural networks to make such dosimetry-based planning accurate and fast for routine clinic use. This study is relevant to public health because a dosimetry-guided combination radiation treatment approach is likely to substantially improve patient outcome compared to current standard practice of internal or external radiation only.",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,10206138,R01EB022075,"['90Y', 'Address', 'Adoption', 'Cancer Etiology', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Disease', 'Dose', 'Ensure', 'Evaluable Disease', 'External Beam Radiation Therapy', 'Failure', 'Foundations', 'Funding', 'Future', 'Goals', 'Hepatotoxicity', 'Image', 'Joint repair', 'Joints', 'Lesion', 'Liver', 'Liver parenchyma', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motivation', 'Noise', 'PET/CT scan', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Photons', 'Physics', 'Pilot Projects', 'Positron-Emission Tomography', 'Primary carcinoma of the liver cells', 'Process', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation therapy', 'Radioembolization', 'Radionuclide therapy', 'Reporting', 'Safety', 'Scanning', 'Testing', 'Time', 'Toxic effect', 'Training', 'base', 'clinical practice', 'clinically relevant', 'convolutional neural network', 'deep learning', 'denoising', 'dosimetry', 'image reconstruction', 'imaging Segmentation', 'improved', 'innovation', 'internal radiation', 'learning strategy', 'multimodal data', 'multimodality', 'next generation', 'novel', 'novel strategies', 'personalized cancer therapy', 'phase II trial', 'prospective', 'radiation delivery', 'reconstruction', 'response', 'single photon emission computed tomography', 'standard of care', 'tool', 'trial design', 'tumor']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,657625
"A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals PROJECT SUMMARY The aim of this proposal is to deliver an innovative and easy-to-use experimental platform for measuring and quantifying naturalistic behaviors of mammalian animal models used for biomedical research, including rodents and monkeys, across a range of spatial and temporal scales. This will require developing a method for tracking movements freely behaving animals with far higher spatiotemporal resolution and more kinematic detail than currently possible. To overcome the limitations of current technologies, a new solution is proposed that synergistically combines two methods - marker based motion capture and a video- based machine learning approach. First, using marker-based motion capture, the gold standard for 3D tracking in humans, the position of experimental subjects' head, trunk, and limbs will be tracked in 3D with submillimeter precision. An innovative marker design, placement strategy, and post-processing pipeline will ensure an unprecedentedly detailed description of rodent behavior over a large range of timescales. To make the system more efficient, robust, affordable and better suited for high-throughput longitudinal studies, the unprecedentedly rich and large 3D datasets generated by the motion capture experiments will be leveraged to train a deep neural network to predict pose and appendage positions from a set of 1-6 normal video cameras. To best capitalize on the large training datasets, the latest advances in convolutional neural networks for image analysis will be incorporated. Together, these advances will promote generalization of the high-resolution 3D tracking system to a variety of animals and environments, thus establishing a cheap, flexible, and easy-to use kinematic tracking method that can easily be scaled up and adopted by other labs. The large ground-truth datasets will allow the system to be benchmarked and compared against state-of-the art technologies in quantitative and rigorous ways. Preliminary studies have been very positive and suggest large improvements over current methods both when it comes to the range of behaviors that can be tracked and the precision with which they can be measured. Importantly, all new technology will be readily shared with the scientific community, thereby leveraging from this single grant the potential for numerous investigators to dramatically improve the efficiency of their research programs requiring rigorous quantitative descriptions of animal behavior. Narrative We will develop and disseminate innovative new technology for measuring precise 3D kinematics in freely moving animals over long time-periods. Our proposed experimental platform will illuminate how natural behaviors are organized and help us understand how they are controlled by the nervous system, and how this control goes awry in disease. The technological leap made possible by this grant will catalyze a host of studies on the neural mechanisms underlying motor control, learning, and mental disorders, and thus help in the discovery of new diagnostic and therapeutic approaches for afflicted patients.",A system for long-term high-resolution 3D tracking of movement kinematics in freely behaving animals,10120068,R01GM136972,"['3-Dimensional', 'Address', 'Adopted', 'Anatomy', 'Animal Behavior', 'Animal Model', 'Animals', 'Behavior', 'Behavioral', 'Benchmarking', 'Biological Models', 'Biomedical Research', 'Brain', 'Callithrix', 'Cephalometry', 'Communities', 'Complex', 'Data', 'Data Set', 'Deer Mouse', 'Disease', 'Ensure', 'Environment', 'Gold', 'Grant', 'Hand', 'Head', 'Human', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Learning Disorders', 'Lighting', 'Limb structure', 'Logic', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Monkeys', 'Motion', 'Movement', 'Mus', 'Nervous System Physiology', 'Nervous System control', 'Neurologic Deficit', 'Output', 'Patients', 'Performance', 'Positioning Attribute', 'Posture', 'Process', 'Rattus', 'Research', 'Research Personnel', 'Resolution', 'Rodent', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Work', 'appendage', 'base', 'computer science', 'convolutional neural network', 'cost', 'deep neural network', 'design', 'expectation', 'experimental study', 'flexibility', 'improved', 'innovation', 'kinematics', 'motor control', 'neural network', 'neuromechanism', 'new technology', 'novel diagnostics', 'novel therapeutic intervention', 'programs', 'relating to nervous system', 'scale up', 'skeletal', 'spatiotemporal']",NIGMS,HARVARD UNIVERSITY,R01,2021,411071
"2021 Annual Meeting of the American Society for Investigative Pathology The purpose of this proposal is to seek support for the 2021 Annual Meeting of the American Society for Investigative Pathology (ASIP), which will be held in conjunction with the Experimental Biology 2021 conference from May 1-4 using a virtual meeting platform. ASIP’s Annual Meeting provides a unique forum for presentation and sharing of cutting-edge research in experimental pathology. The target audience and subject matter for the meeting are diverse but united by a common focus on mechanisms of disease. The theme of the ASIP 2021 Annual Meeting is ‘From microbiota to artificial intelligence: emerging technologies and approaches for discovering mechanisms of pathobiology.’ Reflecting the interests of the ASIP membership, the 2021 Annual Meeting contains strong components in neoplasia and precision medicine. Major sessions will focus on the tumor microenvironment in breast cancer; hepatic tumorigenesis; epigenetic regulation in cancer; single-cell transcriptome and epigenome analysis; precision oncology; new technologies in precision medicine; and progress in the use of big data and artificial intelligence to understand mechanisms of disease. Application of insights gained from basic research to therapy and prevention will be a particular focus throughout the meeting. The four-day program comprises symposia, workshops, and lectures by award recipients, as well as abstract-driven minisymposia and poster sessions. The program further provides a number of educational initiatives, both targeted and of interest to the biomedical research community as a whole. These include sessions on diverse career paths in the biomedical sciences; preparation for the first faculty position; and creation of individual development plans. The ASIP regards promotion of the career development of trainee and young investigators as an extremely important aspect of the Annual Meeting. Accordingly, the meeting provides not only special events designed for their needs but also sessions that showcase their work. Similarly, the Program Committee works hard to ensure diversity among the participants with respect to gender, ethnic/racial group, and stage of career. The sole specific aim of this application is to promote the participation of trainees in the 2021 Annual Meeting through provision of a trainee scholar award program targeted to graduate students, postdoctoral fellows, and clinical residents and fellows in pathology. The Annual Meeting of the American Society for Investigative Pathology offers a unique forum for the sharing of original research results related to a wide spectrum of human diseases and disorders, with particular emphasis on the development, treatment, and prevention of cancer. Such sharing fosters more rapid advances in the understanding of human diseases such as cancer and accelerates the rate at which this knowledge can be applied to the development of diagnostic and prognostic tests, as well as targeted therapies. A major goal of the meeting is to provide educational and career support to young investigators who are interested in cancer biology and experimental pathobiology.",2021 Annual Meeting of the American Society for Investigative Pathology,10231963,R13CA260876,"['American', 'Area', 'Artificial Intelligence', 'Award', 'Basic Science', 'Big Data', 'Biochemistry', 'Biology', 'Biomedical Research', 'Cancer Biology', 'Career Choice', 'Cells', 'Clinical', 'Communities', 'Development', 'Development Plans', 'Diagnostic tests', 'Disease', 'Disease model', 'Educational workshop', 'Emerging Technologies', 'Ensure', 'Exhibits', 'Experimental Pathology', 'Faculty', 'Feedback', 'Fostering', 'Gender', 'Genomics', 'Goals', 'Hepatic', 'Individual', 'Investigational Therapies', 'Knowledge', 'Malignant Neoplasms', 'Mentors', 'Molecular', 'Molecular Biology', 'Neoplasms', 'Organoids', 'Participant', 'Pathology', 'Pharmaceutical Societies', 'Physiological', 'Positioning Attribute', 'Postdoctoral Fellow', 'Preparation', 'Prevention', 'Program Development', 'Race', 'Research', 'Research Personnel', 'Resources', 'Role', 'Science', 'Scientist', 'Seasons', 'Societies', 'Special Event', 'Structure', 'Suggestion', 'Translating', 'Translational Research', 'Work', 'breast cancer progression', 'cancer prevention', 'cancer therapy', 'career', 'career development', 'clinical application', 'design', 'epigenetic regulation', 'epigenome', 'experience', 'graduate student', 'human disease', 'induced pluripotent stem cell', 'insight', 'interest', 'lectures', 'malignant breast neoplasm', 'meetings', 'member', 'microbiota', 'new technology', 'posters', 'precision medicine', 'precision oncology', 'prognostic assays', 'programs', 'racial and ethnic', 'social', 'symposium', 'targeted treatment', 'transcriptome', 'tumor microenvironment', 'tumorigenesis', 'virtual']",NCI,AMERICAN SOCIETY/INVESTIGATIVE PATHOLOGY,R13,2021,12500
"VR-Based Evaluation and Training System for Emergency Responders and Managers Virtual and Augmented Reality (VR/AR) systems are increasingly being utilized as training platforms for complex, extremely demanding or rarely executed tasks. Often, VR systems focus primarily on delivering increasingly realistic scenarios for training purposes without any capability to assess or refine trainee performance in situ. Our novel VR training platform to deliver HAZMAT training not only delivers realistic scenarios, but also measures and evaluates performance using scientifically validated measures of variables associated with both individual and team performance. The advantage of our approach is to immerse first responders in HAZMAT emergency scenarios that are realistic and also designed to focus on measurement and refinement of specific areas of performance. Key contributors to performance among emergency responders and managers were identified by an extensive review of the literature and subsequent tested for association by psychometric assessment of over three hundred emergency responders. A subset of 18 highly associated contributors were then identified through statistical analysis of survey results. These contributors can be measurably represented in VR Training scenario elements. Performance related to each can then be measured and assessed for individual or team trainees. These refined key contributors can then be validated on larger, more diverse samples of emergency responders using the beta version of our proposed VR-based system. Our VR system is also a configurable platform that enables the evaluation and training of a wide range of skills needed by distinct roles (police, firefighters, EMTs, etc.) in diverse scenarios such as biosafety spills, HAZMAT disasters and bioterrorism threats. Also, HAZMAT disasters that are rare or very difficult/costly to create real world training events can be more easily and cost effectively mastered. Scenarios also can be dynamically modulated by trainer input in real-time, or by computerized Artificial Intelligence analysis of performance and trainee real-time physiological measures to rapidly optimize specific key contributor performance of individuals and teams. Rapid, efficient and effective training of emergency responders serves the ultimate goal of minimizing potential catastrophic consequences of these events. Our novel VR training platform to deliver HAZMAT training not only delivers realistic scenarios, but also measures and evaluates performance using scientifically validated measures of variables associated with both individual and team performance",VR-Based Evaluation and Training System for Emergency Responders and Managers,10164783,R44ES029348,"['Area', 'Artificial Intelligence', 'Bioterrorism', 'Competence', 'Complex', 'Elements', 'Evaluation', 'Event', 'Goals', 'Gold', 'Hazardous Substances', 'In Situ', 'Individual', 'Measurable', 'Measurement', 'Measures', 'Performance', 'Phase', 'Physiological', 'Police', 'Psychometrics', 'Resources', 'Review Literature', 'Role', 'Sampling', 'Statistical Data Interpretation', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Virtual and Augmented reality', 'base', 'computerized', 'cost', 'design', 'effectiveness measure', 'emergency service responder', 'first responder', 'hazardous materials disaster', 'improved', 'novel', 'skills']",NIEHS,"TIETRONIX SOFTWARE, INC.",R44,2021,199154
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10175029,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data repository', 'data resource', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'trustworthiness', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2021,330299
"Modeling the influence of translation-elongation kinetics on protein structure and function Project Summary mRNA degradation is an essential process in post-translational gene regulation, and influences protein expression levels in cells. In S. cerevisea the lifetime of mRNA ranges from 43 sec to 39 min, with a median half-life of 3.6 min. The molecular factors governing these differential degradation rates has long been an area of active research. Recently though, clear evidence has emerged that the codon optimality correlates with half- lives. At a mechanistic level, the emerging perspective is that some transcripts are translated quickly, and some slowly, and that transcripts in which ribosomes end up forming queues, much like a traffic jam of cars on a highway, are recognized by ubiquitin ligases such as Hel2 that trigger the RQC pathway to promote mRNA degradation. There are two major gaps in this field. The first is the capability to predict mRNA half-lives accurately from mRNA sequence features. The second is understanding at the molecular level how the distribution of codon translation speeds along a transcript’s coding sequence promote ribosome queues and hence degradation. In this proposal, a graduate student will combine the PI’s labs expertise in modeling the kinetics of translation and ribosome traffic with interpretable machine learning techniques to address these two gaps. In achieving this, the field will be advanced by having both predictive and explanatory models for how translation speed and codon usage differentially impacts the degradation rates of different mRNAs. Specifically, our first aim is to build an interpretable machine learning model to identify robust and predictive features governing mRNA degradation. Our second aim is to explain at the molecular level why these features influence degradation rates. We will do this in two ways. First, we will use the essential and predictive features resulting from the interpretable machine learning model to identify potential underlying mechanisms contributing to degradation. Second, we will simulate the movement of ribosomes on each transcript based on reported initiation and elongation rates to detect ribosome queues and provide an explanation for differential degradation rates. Finally, our third aim is to test the predictions coming from the models. For example, do the models from Aim 1 accurately predict mRNA half-lives when synonymous mutations are introduced? There is sufficient published data on transcriptome-wide mRNA half-lives on S. cerevisiae to train and test the machine learning models in Aim 1. Further, we have arranged for a machine learning expert to co-advise the graduate student on the second aim. This co-advisor is already a collaborator of the PI on other machine learning projects. Finally, a collaborator who has measured mRNA half-lives will further advise the student on the third aim. In summary, this training supplement will address cutting edge questions in the molecular biology and biophysics of mRNA lifetimes and provide the student the opportunity to get advanced training and expertise in machine learning, molecular modeling, and experimental techniques. Project Narrative Messenger RNA (mRNA) half-lives are influenced by the rate of protein synthesis and the ribosome traffic jams that can form on transcripts when slow-translating codons are encountered by ribosomes. The complex distribution of codon usage across transcripts, and the interplay of initiation and elongation rates that can create ribosome queues make it difficult to predict an mRNA's half-life based on its sequence. Here, we will apply machine learning to accurately predict mRNA half-lives from sequence, and combine it with biophysical modeling to understand the molecular events regulating mRNA degradation.",Modeling the influence of translation-elongation kinetics on protein structure and function,10307359,R35GM124818,"['Address', 'Area', 'Biophysics', 'Cells', 'Code', 'Codon Nucleotides', 'Complex', 'Coupling', 'Data', 'Event', 'Gene Expression Regulation', 'Half-Life', 'Kinetics', 'Lead', 'Machine Learning', 'Measures', 'Messenger RNA', 'Modeling', 'Molecular', 'Molecular Biology', 'Movement', 'Mutation', 'Pathway interactions', 'Process', 'Property', 'Protein Biosynthesis', 'Proteins', 'Publishing', 'Reporter', 'Reporting', 'Research', 'Ribosomes', 'Saccharomyces cerevisiae', 'Speed', 'Students', 'Techniques', 'Testing', 'Training', 'Transcript', 'Translating', 'Translations', 'base', 'biophysical model', 'graduate student', 'insight', 'kinetic model', 'mRNA Transcript Degradation', 'models and simulation', 'molecular modeling', 'protein expression', 'protein structure function', 'ribosome profiling', 'simulation', 'transcriptome', 'ubiquitin ligase']",NIGMS,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R35,2021,31246
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,10128374,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2021,77243
"Bioinformatics Strategies for Genome-Wide Association Studies One promise of precision medicine for Alzheimer’s disease is to edit a patient’s DNA and/or administer therapeutics targeting etiologic molecules that prevent or reverse the disease process using a tailored design. All of this happens at the level of the individual and requires precision knowledge of that patient’s biology. In stark contrast, much of the knowledge we possess about genomic risk factors comes from statistical measures of association in subjects ascertained with and without Alzheimer’s. The conceptual and practical disconnect between the populations we study and the individuals we want to treat is a major source of confusion about how to move forward in an era driven by genome technology. The primary goal of this proposal is to develop novel informatics methodology and software to facilitate precision medicine for Alzheimer’s by connecting population and individual genomic phenomena. We propose here a Virtual Genomic Medicine (VGMed) workbench where clinicians can carry out thought experiments about the treatment of individual Alzheimer’s patients using models of disease risk derived from population-level studies. This will be accomplished by first developing a novel Genomics-guided Automated Machine Learning (GAML) algorithm for deriving risk models from real data that is accessible to Alzheimer’s clinicians (AIM 1). We will then develop a novel simulation approach that is able to generate artificial Alzheimer’s data that preserves the distribution of genetic effects observed in the real data while maintaining other characteristics such as genotype frequencies (AIM 2). This will generate open data allowing anyone to perform virtual interventions on Alzheimer’s patients derived from a population-level risk distribution. The workbench will allow editing of individual genotypes and simulate the administration of drugs by editing machine learning parameters in the simulation model (AIM 3). The change in risk and Alzheimer’s disease status for the specific patient will be tracked in real time. Finally, we provide a feature in the workbench that will allow the Alzheimer’s clinician to generate specific hypotheses about individual genetic variants that can then be validated using integrated Alzheimer’s knowledge sources that include databases such as PubMed and ClinVar thus giving the user immediate feedback (AIM 4). All methods and software will be provided as open-source to the Alzheimer’s disease research community (AIM 5). Most genetic studies of Alzheimer’s disease result in statistical summaries of risk derived from human populations. These statistical summaries are not that helpful for determining the health of an individual. This proposal will create new computer algorithms and software help Alzheimer’s clinicians and researchers connect population-level statistics with individual level genetic effects to advance our understanding of how to treat Alzheimer’s patients based on their own unique genetic makeup.",Bioinformatics Strategies for Genome-Wide Association Studies,10284977,R01LM010098,"['Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease patient', 'Bioinformatics', 'Biology', 'Characteristics', 'ClinVar', 'Communities', 'Computational algorithm', 'Computer software', 'Confusion', 'DNA', 'Data', 'Databases', 'Disease', 'Disease model', 'Etiology', 'Feedback', 'Frequencies', 'Genetic', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Study', 'Process', 'PubMed', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Source', 'Technology', 'Time', 'base', 'data preservation', 'design', 'disorder risk', 'experimental study', 'genetic makeup', 'genetic variant', 'genome wide association study', 'machine learning algorithm', 'models and simulation', 'novel', 'open data', 'open source', 'precision medicine', 'prevent', 'simulation', 'statistics', 'therapeutic target', 'virtual', 'virtual intervention']",NLM,UNIVERSITY OF PENNSYLVANIA,R01,2021,391879
"Statistical Unsupervised Learning VF for IIHTT & ONTT Summary Current assessments of visual field testing depend on algorithms, principally developed to diagnose and monitor progression in glaucoma, or on expert descriptive categorization of deficits. The algorithms do not work well for non-glaucomatous optic neuropathies as these disorders can both improve and deteriorate. Descriptive categorizations are not readily quantifiable to assess change over time. Unsupervised statistical learning archetypal analysis is a new way to investigate glaucoma and potentially other optic neuropathies. Both idiopathic intracranial hypertension and optic neuritis are disorders that often improve and respond to therapy. Archetypal analysis of the visual fields from two NEI sponsored clinical trials on each disorder, ONTT and IIHTT, will be investigated to determine if the findings parallel the reported outcomes and effects of therapy. We will also test whether machine learning quantifiable archetypes, which are disease-associated patterns of field deficits, are similar to expert determinations, whether they are sensitive to changes in optic nerve function, and if they reveal residual optic nerve dysfunction in eyes reported to be normal by prior study criteria. Adding cases of IIH and optic neuritis from the clinic will enhance the archetypes for each disorder for use in the clinic and new studies. Narrative Analysis of the visual fields of patients with optic neuropathies using machine learning will improve the evaluation and provide objective measurement, rather than the current descriptive methods. The approach, called archetypal analysis, should improve safety monitoring during clinical trials as well as uncover residual visual field deficits not seen with other types of analyses.",Statistical Unsupervised Learning VF for IIHTT & ONTT,10192112,R21EY032522,"['Acute', 'Affect', 'Algorithms', 'Clinic', 'Clinical Trials', 'Cost Savings', 'Detection', 'Deterioration', 'Diagnosis', 'Disease', 'Evaluation', 'Event', 'Eye', 'Face', 'Frequencies', 'Functional disorder', 'Future', 'Glaucoma', 'Head', 'Injury', 'Intervention', 'Intervention Studies', 'Lead', 'Machine Learning', 'Manuals', 'Masks', 'Measurement', 'Measures', 'Methods', 'Military Personnel', 'Monitor', 'Optic Nerve', 'Optic Neuritis', 'Outcome', 'Outcome Study', 'Papilledema', 'Patients', 'Pattern', 'Perimetry', 'Physiologic Intraocular Pressure', 'Pseudotumor Cerebri', 'Reader', 'Reporting', 'Residual state', 'Safety', 'Shapes', 'Supervision', 'Testing', 'Time', 'Vision', 'Visit', 'Visual Fields', 'Weight', 'archetypal analysis', 'base', 'central visual field', 'clinical practice', 'eligible participant', 'field study', 'improved', 'longitudinal analysis', 'optic nerve disorder', 'prospective', 'response', 'statistical learning', 'successful intervention', 'treatment effect', 'treatment trial', 'trend', 'unsupervised learning']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R21,2021,331170
"Selection of Flow Modulation Protocols for Patients on Continuous Flow Ventricular Assist Devices (CF-VADs) PROJECT SUMMARY A major concern with continuous flow ventricular assist devices (CF-VADs) is the resulting non-physiological flow with diminished pulsatility which has been shown to be a major risk factor for development of arteriovenous malformations (AVMs) and gastrointestinal (GI) bleeding. To address this issue, flow modulation via rapid changes in pump impeller speed has been proposed as a technique to introduce ‘artificial pulsatility’. However, given the inadequacy of large animal models with recreating CF-VAD associated non-surgical bleeding events, it is still unclear if artificial pulsatility can prevent these adverse events or what level of artificial pulsatility is even necessary. To evaluate the effects of pulsatility and identify promising flow modulation approaches we developed a vascular pulse perfusion model (VPPM) to culture Human Aortic Endothelial Cells (HAECs) under conditions of normal pulsatile flow or flow with diminished pulsatility (CF-VAD support). Our rationale for modeling arterial vessels is because pulsatility primarily affects the arterial side of the circulatory system and its effects are transduced by endothelial cells that line the large arterial vessels. The VPPM was validated as relevant model via direct comparison with aortic samples of patients with and without CF-VADs. Our published data also shows that loss of pulsatility is associated with an increase in production of pro-angiogenic/inflammatory cytokines. The relevance of these results is further strengthened by supporting data from patients that experience AVMs and GI bleeding events (both CF-VAD related and due to other conditions) showing similar elevated levels of pro- angiogenic/inflammatory cytokines. The VPPM therefore provides a powerful model to evaluate artificial pulsatility in the context of CF-VAD flow modulation and determine if restoring pulse pressure and/or pulse frequency can mitigate non-surgical bleeding events. Based on recent studies that suggest that pulse pressure < 35 mmHg is a major risk factor for development of GI bleeds, we hypothesize that “Diminished pulsatility associated with ‘CF-VAD support’ results in endothelial dysfunction and pro-inflammatory/pro-angiogenic soluble factor production. These changes can be mitigated via introduction of artificial pulsatility using flow modulation strategies where pulse pressure is preserved at > 35 mmHg”. Aim1 will evaluate response of patient derived endothelial cells within the VPPM to CF-VAD flow and quantify angiogenic/inflammatory soluble factor production, Aim2 will follow patients for up to 36 months to evaluate serum levels of pro-angiogenic/pro- inflammatory cytokines and non-surgical bleeding events which will then be compared to results from in-vitro studies within the VPPM and Aim3 will evaluate different flow modulation strategies using patient-derived endothelial cells to determine most promising patient-specific approaches via comparison of hemodynamic profiles and cytokine biomarkers using deep learning approaches. Successful completion of this project will enable identification of device-based strategies to prevent non-surgical bleeding in patients on CF-VAD support. PROJECT NARRATIVE This project seeks to determine the effects of diminished pulsatility during continuous flow ventricular assist device (CF-VAD) support on human aortic endothelial cells (HAECs). Changes in production of pro- angiogenic/pro-inflammatory cytokines will be used as biomarkers to evaluate the effects of loss of pulsatility and help validate new approaches to introduce artificial pulsatility in CF-VADs.",Selection of Flow Modulation Protocols for Patients on Continuous Flow Ventricular Assist Devices (CF-VADs),10116660,R01HL151663,"['Activities of Daily Living', 'Address', 'Adverse event', 'Affect', 'Age-Years', 'Aging', 'Animal Model', 'Animals', 'Antioxidants', 'Arteriovenous malformation', 'Biological Markers', 'Blood Vessels', 'Blood specimen', 'Brain hemorrhage', 'Cardiovascular system', 'Cell Line', 'Cells', 'Data', 'Development', 'Devices', 'Endothelial Cells', 'Endothelin-1', 'Endothelium', 'Event', 'Frequencies', 'Functional disorder', 'Gastrointestinal Hemorrhage', 'Heart failure', 'Hemorrhage', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Machine Learning', 'Mediating', 'Medical', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Perfusion', 'Physiologic pulse', 'Physiological', 'Production', 'Protocols documentation', 'Publishing', 'Pulsatile Flow', 'Pulse Pressure', 'Pump', 'Quality of life', 'Quantitative Evaluations', 'Refractory', 'Regulation', 'Risk Factors', 'Sampling', 'Serum', 'Sheep', 'Side', 'Signal Transduction', 'Speed', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Transducers', 'Translating', 'VWF gene', 'Validation', 'Work', 'base', 'cytokine', 'deep learning', 'endothelial dysfunction', 'experience', 'gastrointestinal', 'hemodynamics', 'improved', 'novel strategies', 'operation', 'patient response', 'preservation', 'pressure', 'prevent', 'response', 'safety testing', 'ventricular assist device']",NHLBI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2021,535547
"Development of A High Throughput Image-Guided IMRT System for Preclinical Research Project Summary/Abstract Preclinical radiobiology experiments on small animals are crucial to test the safety and efficacy before human clinical trials. However, limited by currently available technologies, preclinical animal studies substantially differ from state-of-the-art human treatments in dose conformity. Consequently, the animal studies poorly mimic the radiobiological, radioimmunological, and toxicity environment of human therapies. The disparity adversely affects our ability to meaningfully test hypotheses that are intended for human translation. With decades of advancement, human radiotherapy has achieved high targeting accuracy and dose conformality based on technological breakthroughs, including intensity-modulated radiotherapy (IMRT), which is unavailable for mouse experiments. A practical device and algorithm to modulate the x-ray intensity for the scale of small animals is the first step to bridge the gap. With the support of an NIH R21 grant, we engineered a novel small animal IMRT dose modulator termed sparse orthogonal collimator (SOC). Equally important as the hardware, we created the enabling mathematical tools to deliver SOC IMRT plans with higher achievable resolution than a theoretically miniaturized MLC-based IMRT. We commissioned and tested prototypical SOCs to deliver highly modulated doses in silico and on phantoms. Nonetheless, there are still large gaps between an intensity modulation device and a small animal IMRT system suitable for broad adoption and impact. The required time, resources, and training to create sophisticated SOC-IMRT plans are incompatible with preclinical settings. Furthermore, without automation, the existing image-guided small animal IMRT treatment is prohibitively slow for treating live animals under anesthesia. Lastly, the current manual method to switch between imaging and therapy modes results in intractable uncertainties in dose delivery. We propose to fill these gaps using automation, robotics, and system optimization. We propose the following specific aims. Specific Aim 1 (SA1). Automated organ segmentation for mice using deep learning neural networks. Specific Aim 2 (SA2). Development of a fully functional, automated, and efficient IMRT system. Specific Aim 3 (SA3). Development and validation of a robotic Multi Mouse Automated Treatment Environment (Multi-MATE) for automated imaging and treatment. Besides dosimetry, we will quantify the time performance, which is critical to small animal IMRT system. As a result, in addition to improving the hardware accuracy and reliability, the proposed project will provide a fully automated planning and delivery system, thus removing the last barriers towards the broad adoption of small animal IMRT. The success of the proposed project will help existing research to achieve the full potential for human translation and enable future hypotheses testing where accurate complex dose distribution is critical. Project Narrative A major impediment in translating animal radiation studies to human patients is the disparity in radiation techniques. Existing methods cannot create human like conformal radiation dose on mice with necessary accuracy and efficiency. To better mimic human treatment without prohibitively complicated and slow procedures, we propose to develop a high throughput image guided small animal conformal irradiation platform.",Development of A High Throughput Image-Guided IMRT System for Preclinical Research,10317441,R01CA259008,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Anesthesia procedures', 'Animals', 'Automation', 'Calibration', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collimator', 'Complex', 'Computer software', 'Conformal Radiotherapy', 'Development', 'Devices', 'Dose', 'Engineering', 'Environment', 'Future', 'Grant', 'Human', 'Image', 'Individual', 'Intensity-Modulated Radiotherapy', 'Intervention', 'Knowledge', 'Manuals', 'Mathematics', 'Methods', 'Mus', 'Organ', 'Patients', 'Performance', 'Procedures', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Radiobiology', 'Research', 'Resolution', 'Resources', 'Risk', 'Robotics', 'Roentgen Rays', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Toxic effect', 'Training', 'Translating', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'automated segmentation', 'base', 'biological research', 'deep learning', 'deep neural network', 'design', 'dosimetry', 'experimental study', 'image guided', 'improved', 'in silico', 'innovation', 'irradiation', 'miniaturize', 'novel', 'pre-clinical', 'pre-clinical research', 'process optimization', 'robotic system', 'safety testing', 'success', 'tool', 'treatment planning', 'trend', 'tumor', 'user-friendly']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,441662
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,10109124,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'data analysis pipeline', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'programmed cell death protein 1', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2021,314000
"Biomedical Raman Imaging Workshop Summary The purpose of the planned conference is to facilitate development of Raman-spectroscopy based clinical appli- cations.  Raman scattering provides label-free contrast for imaging that derives from intrinsic molecular vibrations. Because it is label-free and reports in an unbiased way on all molecular species in a sample, it provides a holistic “view” of the chemical environment in clinical samples, and thus holds signiﬁcant value as a diagnostic and treatment monitoring tool.  While the phenomenon of Raman scattering has been known since 1920, and its clinical potential has been recognized for many decades, roadblocks including weak signal levels and complexity of its readout has precluded it from clinical use. These roadblocks are now being removed through innovations in instrument development and machine learning. Narrative Raman spectroscopy provides diagnostically important chemical proﬁles of clinical samples, withouth the need of labeling. Throgh this it holds tremendous potential to improve many diagnostic and monitoring aspects of healthcare. The purpose of this workshop is to facilitate efﬁcient development of these techniques in a way that will be clinically acceptable.",Biomedical Raman Imaging Workshop,10318774,R13EB032251,"['Adopted', 'Adoption', 'Antibiotic susceptibility', 'Area', 'Biological', 'Biology', 'Brain', 'Caring', 'Chemicals', 'Clinical', 'Complex', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Diagnostic', 'Educational workshop', 'Environment', 'Excision', 'Fingerprint', 'Fruit', 'Generations', 'Healthcare', 'Histology', 'Image', 'Image Analysis', 'Imaging technology', 'In Situ', 'Label', 'Light', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Molecular', 'Monitor', 'Nature', 'Paper', 'Pathogen detection', 'Photons', 'Physicians', 'Publishing', 'Raman Spectrum Analysis', 'Reporting', 'Role', 'Sampling', 'Scheme', 'Signal Transduction', 'Time', 'Tissues', 'Translating', 'Voice', 'base', 'clinical application', 'clinical practice', 'contrast imaging', 'imaging approach', 'imaging modality', 'improved', 'in vivo', 'innovation', 'liquid biopsy', 'screening', 'symposium', 'technique development', 'technology development', 'tool', 'tumor', 'vibration']",NIBIB,GEORGIA INSTITUTE OF TECHNOLOGY,R13,2021,9996
"Fast and flexible Bayesian phylogenetics via modern machine learning Project Abstract/Summary The SARS-CoV-2 pandemic underlines both our susceptibility to and the toll of a global pathogen outbreak. Phylogenetic analysis of viral genomes provides key insight into disease pathophysiology, spread and po- tential control. However, if these methods are to be used in a viral control strategy they must reliably account for uncertainty and be able to perform inference on 1,000s of genomes in actionable time. Scaling Bayesian phylogenet- ics to meet this need is a grand challenge that is unlikely to be met by optimizing existing algorithms.  We will meet this challenge with a radically new approach: Bayesian variational inference for phylogenet- ics (VIP) using ﬂexible distributions on phylogenetic trees that are ﬁt using gradient-based methods analogous to how one efﬁciently trains massive neural networks. By taking a variational approach we will also be able to integrate phylogenetic analysis into very powerful open-source modeling frameworks such as TensorFlow and PyTorch. This will open up new classes of models, such as neural network models, to integrate data such as sampling location and migration patterns with phylogenetic inference. These ﬂexible models will inform strategies for viral control.  In Aim 1 we will develop the theory necessary for scalable and reliable VIP, including subtree marginal- ization, local gradient updates needed for online algorithms, convergence diagnostics, and parameter support estimates. We will implement these algorithms in our C++ foundation library for VIP. In Aim 2 we will develop a ﬂexible TensorFlow-based modeling platform for phylogenetics, enabling a whole new realm of phylogenetic models based on neural networks to learn phylodynamic heterogeneity with minimal program- ming effort. We will provide efﬁcient gradients to this implementation via our C++ library. In Aim 3 we will use the fact that VIP posteriors are durable and extensible descriptions of the full data posterior to enable dynamic online computation of variational posteriors, including divide-and-conquer Bayesian phylogenetics. This work will enable a cloud-based viral phylogenetics solution to rapidly update our current estimate of the posterior distribution when new data arrive or the model is modiﬁed. 1 Project Narrative We have seen in the current SARS-CoV-2 pandemic, as for all major pathogen outbreaks in the last decade, how phylogenetic (i.e. evolutionary tree) methods are required to use viral genomic information to under- stand large-scale transmission patterns. However, current phylogenetic methods have two major limitations as a tool for viral control: ﬁrst, rigorous Bayesian probabilistic methods cannot scale to 1,000s of genomes, and second, models incorporating phylogenetic trees must be expressed in specialized phylogenetics pack- ages, making modern machine-learning approaches impossible. In this proposal, we develop variational ap- proaches to phylogenetics, which will allow fast inference and procedures to rapidly update inferences when new data arrives, as well as making phylogenetic trees a ﬁrst-class inferential object in major machine-learning packages. 1",Fast and flexible Bayesian phylogenetics via modern machine learning,10266670,R01AI162611,"['Age', 'Algorithms', 'Back', 'Bayesian Method', 'COVID-19 pandemic', 'Code', 'Collection', 'Complex', 'Computational Biology', 'Custom', 'Data', 'Data Set', 'Diagnostic', 'Discipline', 'Disease', 'Disease Outbreaks', 'Epidemic', 'Foundations', 'Functional disorder', 'Genome', 'Graph', 'Heterogeneity', 'Learning', 'Libraries', 'Location', 'Machine Learning', 'Markov chain Monte Carlo methodology', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Nature', 'Neural Network Simulation', 'Pattern', 'Phylogenetic Analysis', 'Predisposition', 'Procedures', 'Public Health', 'Research Personnel', 'Sampling', 'Statistical Models', 'Structural Models', 'Structure', 'Technology', 'TensorFlow', 'Time', 'Training', 'Trees', 'Uncertainty', 'Update', 'Variant', 'Viral', 'Viral Genome', 'Work', 'base', 'cloud based', 'data modeling', 'epidemiologic data', 'flexibility', 'genomic data', 'high dimensionality', 'insight', 'knowledge base', 'mathematical algorithm', 'mathematical methods', 'migration', 'neural network', 'novel strategies', 'open source', 'pathogen', 'prevent', 'scale up', 'social exclusion', 'theories', 'tool', 'transmission process', 'user-friendly', 'viral genomics', 'viral transmission']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,797370
"Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods. 1 This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings –  2 funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating  3 Biology into In Silico Methodologies: Modern Approaches for incorporating biological  4 reasoning and understanding into computational methods. As a “Contemporary Concepts  5 in Toxicology” meeting, this workshop has the full backing, including being financially  6 underwritten, by the Society of Toxicology.  7 Computational modeling is an important tool for assessing the safety and use of  8 chemicals across many industries, including chemical, pharmaceutical, and consumer products.  9 Moreover, in silico methodologies offer academia and regulatory a fast and cheap method of 10 prioritizing its efforts to maintain compliance and safety in the market and environment. 11 This conference is designed to promote the development of actionable insights and 12 methodologies for increasing the biological relevance of in silico solutions. Specifically, this 13 conference will focus on solving the “black box effect”. There are many ways to validate a 14 model’s accuracy and domain – however if the model cannot explain what is happening 15 biologically, its use is severely diminished. This workshop will bring together regulatory, 16 academia, industry, and service providers to discuss current solutions and efforts, as well as 17 ongoing and future research. One goal of this conference will be to develop a roadmap for the 18 incorporation of AOPs (and similar biological reasonings) for computational tools. 19 This workshop has great appeal for multiple stakeholders within toxicology, namely 20 industry, academia, regulators, as well as service providers. The use of machine-learning to 21 replace laboratory toxicological tests is paramount to the future of the industry (3Rs). The use 22 of in silico models are explicitly referenced by NICEATM’s U.S. Strategic Roadmap, as well as 23 TSCA. Moreover, many industries and regulatory entities are taking significant steps away from 24 animal testing. Most recently, the US EPA stated that it will eliminate animal testing by 2035. 25 This workshop will bring together different stakeholders to discuss the current state of 26 AOPs and in silico methodologies, and to work towards a unified approach for their 27 incorporation. The final outcome of the workshop will be a white-paper that not only reviews the 28 current landscape but discusses concretes steps, as outlined in the breakout session, needed 29 for the regulatory acceptance of machine learning technologies – specifically a roadmap for the 30 inclusion of AOPs into computational tools and explanations. This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings – funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating Biology into In Silico Methodologies: Modern Approaches for incorporating biological reasoning and understanding into computational methods. This workshop will bring together different stakeholders to discuss the current state of AOPs and in silico methodologies, and to work towards a unified approach for their incorporation. The final outcome of the workshop will be a white- paper that not only reviews the current landscape but discusses concretes steps, as outlined in the breakout session, needed for the regulatory acceptance of machine learning technologies – specifically a roadmap for the inclusion of AOPs into computational tools and explanations.",Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods.,10144727,R13ES032662,"['Academia', 'Address', 'Adoption', 'Animal Testing', 'Animals', 'Back', 'Biological', 'Biology', 'Budgets', 'Chemicals', 'Chemistry', 'Communities', 'Computer Models', 'Computing Methodologies', 'Decision Making', 'Development', 'Educational workshop', 'Environment', 'Event', 'Funding', 'Future', 'Goals', 'In Vitro', 'Individual', 'Industry', 'Laboratories', 'Laws', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'National Institute of Environmental Health Sciences', 'Nonprofit Organizations', 'Outcome', 'Paper', 'Pathway interactions', 'Pharmacologic Substance', 'Policies', 'Process', 'Publishing', 'Safety', 'Societies', 'System', 'Technology', 'Testing', 'Toxicology', 'United States National Institutes of Health', 'Work', 'adverse outcome', 'cheminformatics', 'computer framework', 'computerized tools', 'consumer product', 'cost', 'design', 'improved', 'in silico', 'in vivo', 'insight', 'meetings', 'predictive modeling', 'research and development', 'service providers', 'symposium', 'tool', 'web site']",NIEHS,"TOXTRACK, LLC",R13,2021,4000
"An Agent-Based Modeling Platform for Environmental Biotechnology Hazardous pollutants in the environment continue to threaten public health and environmental  safety. Human exposure to major contaminant classes, such as polyfluorinated compounds  (PFCs), hazardous organic compounds (HOCs), and heavy metals, has been linked to a variety of  diseases and is subject to stringent State and Federal environmental regulations.  Bioremediation is a low-cost and environmentally friendly approach with many successful  use-cases; however, conventional bioremediation technologies can suffer from unreliability, low  degradation rates, and incomplete degradation. As stakeholders to Superfund sites and other sites  with water or soil pollution urgently demand more efficient, less costly and more reliable  remediation technologies, it is critical to look to advancements in computational  modeling to develop next-generation, precision-engineered bioremediation technologies. The proposed project builds on successful outcomes from Phase I in which a new computational  platform was designed and validated to accurately predict the bioremediation kinetics of  a multi-organism microcosm degrading a combination of HOCs in groundwater. The basis of  this platform is an approach called agent-based modeling (ABM), where the functions of  individual components (e.g. microorganisms) within complex ecosystems are used to predict and  optimize system-level properties (e.g. bioremediation kinetics). In this Phase II project, the novel computational platform developed in Phase I is  further improved with a machine learning component that leverages bioinformatics  databases to develop rationally tailored microbiomes for degrading complex pollutant  mixtures. Iterative experimental validation of model outputs is conducted using an innovative  materials science platform that maintains the relative concentration of different species in the  microbiome constant within the multi-zone treatment barrier (in-situ) or multi-zone bioreactor  (ex-situ). The project includes focused development of a prototype for one bioremediation use-case,  which is directly compared to a conventional (non-precision) bioremediation system treating   actual contaminated groundwater. This will be performed in order to assess and quantify  the expected technical and economic benefits of harnessing the project's novel computational  platform in biotechnology development. The broad, long-term impact of the proposed project will be to transform the development and  implementation of bioremediation by integrating advancements in computational modeling, machine  learning, bioinformatics, and materials science. By leveraging novel tools across disciplines, the  project will accelerate the development of more precise, reliable and inexpensive technologies for  environmental remediation. The successful outcome of the proposed project will also provide new  collaborative opportunities for industry and academia to more rapidly address the remediation of  high-priority pollutants in the environment, and ultimately help mitigate the effects of hazardous  pollutants on communities impacted by the presence of environmental contamination. PROJECT NARRATIVE Contaminated soils and waters continue to threaten public health and safety. This project builds on the development of a novel computational platform for predicting the complex, dynamic interactions between microbial ecosystems and hazardous contaminants-of-concern in the environment, and to utilize this information to develop improved engineered remediation biotechnologies.",An Agent-Based Modeling Platform for Environmental Biotechnology,10158243,R44ES026541,"['Academia', 'Address', 'Biodegradation', 'Bioinformatics', 'Bioreactors', 'Bioremediations', 'Biotechnology', 'Chemicals', 'Classification', 'Colorado', 'Communities', 'Complex', 'Computer Models', 'Data', 'Databases', 'Development', 'Discipline', 'Disease', 'Economics', 'Ecosystem', 'Engineering', 'Environment', 'Environmental Monitoring', 'Environmental Pollution', 'Enzymes', 'Exposure to', 'Ginkgo biloba', 'Goals', 'Growth', 'Heavy Metals', 'In Situ', 'Indiana', 'Individual', 'Industry', 'Kinetics', 'Laboratories', 'Learning Module', 'Letters', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Molecular', 'Municipalities', 'Organism', 'Outcome', 'Output', 'Phase', 'Polymers', 'Process', 'Property', 'Public Health', 'Regulation', 'Research', 'Safety', 'Side', 'Site', 'Soil', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Water', 'Water Pollution', 'base', 'computational platform', 'cost', 'design', 'economic evaluation', 'enzyme pathway', 'exposed human population', 'ground water', 'improved', 'innovation', 'laboratory experiment', 'materials science', 'microbial', 'microbiome', 'microorganism', 'next generation', 'novel', 'pollutant', 'prototype', 'remediation', 'research and development', 'soil pollution', 'success', 'superfund site', 'tool']",NIEHS,"MICROVI BIOTECH, INC.",R44,2021,630992
"Leveraging Heterogeneity in Preclinical Traumatic Brain Injury to Drive Discovery and Reproducibility Traumatic brain injury (TBI) is a leading cause of neurological disorders and affects over 2.5 million people each year, yet no treatment has successfully translated from bench to clinic. TBI is a broad term and encompasses an extremely heterogeneous set of injuries differing by cause, severity, biomechanics, and the varied, complex secondary injury responses that collectively result in chronic disabilities. Current preclinical research circumvents the issue of TBI heterogeneity by relying on specific preclinical animal models that mimic subpopulations of patients and particular secondary injury mechanisms with each study focusing on limited, individual pathways. This proposal instead aims to tackle TBI heterogeneity by approaching TBI as a “big data” problem and aggregating and analyzing the multidimensional data collectively. A framework for data harmonization and curation will be developed, and datasets from a consortium of preclinical labs employing a variety of preclinical TBI models will be collected and curated into an open data commons (ODC-TBI). Utilizing machine learning and multidimensional analytics, the proposed research will directly leverage TBI heterogeneity in the merged dataset to identify persistent features of TBI to empower translational research. By creating a preclinical TBI ODC and applying machine learning to integrate the heterogeneity of preclinical TBI models, the project will reveal multidimensional features of TBI across heterogeneous injuries and characterize how diverse secondary injury mechanisms interact and ultimately affect injury outcome. Throughout the project's timeline, new datasets will continue to be harmonized into the ODC-TBI according to the established framework. The ODC-TBI will be the first open multicenter, multi-model repository of preclinical TBI data and will enable the application of data science to the field of TBI. Furthermore, the ODC-TBI and the methods implemented throughout the project will be openly shared to improve reproducibility of TBI research. Together with the multidimensional analysis that will provide quantitative and qualitative understanding of TBI heterogeneity, the project aims to ultimately accelerate data- driven discovery and precision medicine for TBI. Reflecting the complexities of clinical traumatic brain injury (TBI), preclinical TBI research is confounded by the extreme heterogeneity prevalent across possible injury models and resulting biological responses. The proposed research will aggregate and curate an extensive open data commons (ODC) of preclinical TBI research with multiple TBI models and utilize machine learning to tackle TBI heterogeneity directly. The project will create an ODC for preclinical TBI research to improve data sharing and scientific reproducibility, and will empower translational TBI research by identifying multidimensional features of TBI that best predict functional outcome.",Leveraging Heterogeneity in Preclinical Traumatic Brain Injury to Drive Discovery and Reproducibility,10212363,F32NS117728,"['Address', 'Affect', 'Animal Model', 'Big Data', 'Biological', 'Biological Markers', 'Biomechanics', 'Brain region', 'Chronic', 'Clinic', 'Clinical', 'Closed head injuries', 'Common Data Element', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Commons', 'Data Element', 'Data Science', 'Data Set', 'Development', 'Foundations', 'Goals', 'Heterogeneity', 'Incidence', 'Individual', 'Inflammation', 'Informatics', 'Injury', 'Institutes', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Multivariate Analysis', 'National Institute of Neurological Disorders and Stroke', 'Outcome', 'Pathway interactions', 'Pattern', 'Pharmacologic Substance', 'Population', 'Positioning Attribute', 'Pre-Clinical Model', 'Principal Component Analysis', 'Publishing', 'Reproducibility', 'Research', 'Severities', 'Standardization', 'Synaptic plasticity', 'Therapeutic', 'TimeLine', 'Translating', 'Translational Research', 'Translations', 'Traumatic Brain Injury', 'behavioral outcome', 'bench to bedside', 'biomarker discovery', 'controlled cortical impact', 'data curation', 'data framework', 'data harmonization', 'data sharing', 'disability', 'experimental study', 'functional outcomes', 'genetic manipulation', 'improved', 'insight', 'multidimensional data', 'multiple datasets', 'nerve injury', 'nervous system disorder', 'neuroinflammation', 'open data', 'patient subsets', 'pre-clinical', 'pre-clinical research', 'precision medicine', 'repository', 'response', 'response to injury']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2021,71224
"Maternal Antecedents and Electronic Fetal Monitoring in Term Asphyxia (MAESTRA) Neonatal hypoxic-ischemic encephalopathy (HIE) is a neurologic syndrome that results from reduced flow of oxygenated blood to the fetal or newborn brain. HIE occurs in 1-3 per 1,000 term births and may cause death or neurologic disabilities such as cerebral palsy. Electronic fetal monitoring (EFM) was developed in the 1970's to assess the adequacy of fetal oxygenation as a strategy to prevent HIE, and is now standard of care. Yet clinical trials report that EFM usage has not reduced the rate of CP, perinatal death or HIE, but is associated with a dramatic increase in cesarean deliveries. The currently used 3 Category fetal heart rate (FHR) classification system, based on simple rules designed to be easy to apply at the bedside, has some utility in predicting HIE. However, Category II FHR patterns that make up the vast majority of tracings are poorly predictive of HIE and confer “indeterminate” risk. Category III patterns are also of limited use in predicting HIE due to low sensitivity. There is an urgent need to develop better objective methods to assess EFM that would identify more fetuses at risk of HIE in time for corrective actions. Uterine tachysystole, or excessive frequency of uterine contractions, has been implicated as a preventable cause of HIE; yet studies report conflicting results. EFM research has been limited by an inability to access and manually analyze the large datasets needed to study HIE. We now have the ability to analyze digital EFM signals using automated methods to measure standard FHR patterns as well as to discover novel aspects of the tracing that may not be readily detectable by a clinician at the bedside. We hypothesize that modern signal processing and machine learning techniques can create highly predictive models of HIE by analyzing established and novel features of EFM tracings, in combination with demographic and pertinent clinical information from the mother and fetus. We propose a population-based retrospective cohort study of 350,000 infants born at ≥ 36 weeks gestation at Kaiser Permanente Northern California in 2010-19. Our specific aims are: 1) To create the MAESTRA Cohort dataset that links EFM recordings to HIE and neonatal acidosis among 350,000 infants born at ≥ 36 weeks gestation in 2010-19 at Kaiser Permanente Northern CA; 2) Using modern signal processing and machine learning techniques, to extract established and novel FHR and uterine contractility features from the EFM recordings, and to determine which of these features are most predictive of HIE and acidosis when combined with maternal and fetal clinical data; and 3) To perform external validation by applying the final predictive models to a historical dataset. We anticipate that machine learning techniques incorporating novel FHR and uterine contractility patterns over time, as well as pre- and perinatal clinical characteristics, will improve the predictive value of the EFM data that are already being collected as part of routine care. Our results will inform future clinical trials. Such an unprecedented large-scale multidisciplinary study will lead to improvements in our ability to use EFM data to prevent neonatal brain injury while minimizing unnecessary cesarean sections. MAESTRA Project Narrative Hypoxic-ischemic encephalopathy (HIE) occurs when a baby gets reduced oxygen and blood flow to the brain, and can lead to death or long-term disabilities such as cerebral palsy. During labor and delivery, doctors are able to continuously record the heart rate of the fetus. This study will determine how best to use the heart rate information so that we can reduce the number of infants who develop this severe brain condition.",Maternal Antecedents and Electronic Fetal Monitoring in Term Asphyxia (MAESTRA),10145055,R01HD099216,"['Acidosis', 'Address', 'Apgar Score', 'Asphyxia', 'Blood', 'Blood flow', 'Brain', 'California', 'Categories', 'Cause of Death', 'Cerebral Palsy', 'Cesarean section', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Computerized Medical Record', 'Conflict (Psychology)', 'Data', 'Data Set', 'Discipline of obstetrics', 'Educational workshop', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Frequencies', 'Future', 'Heart Rate', 'Infant', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Metabolic Brain Diseases', 'Metabolic acidosis', 'Methods', 'Modeling', 'Modernization', 'Mothers', 'National Institute of Child Health and Human Development', 'Neonatal', 'Neonatal Brain Injury', 'Neurologic', 'Newborn Infant', 'Observational Study', 'Outcome', 'Oxygen', 'Pattern', 'Perinatal', 'Perinatal anoxic ischemic brain injury', 'Perinatal mortality demographics', 'Population', 'Positioning Attribute', 'Predictive Value', 'Pregnancy', 'Preventive Intervention', 'Records', 'Reporting', 'Research', 'Retrospective cohort study', 'Risk', 'Seizures', 'Sensitivity and Specificity', 'Signal Transduction', 'Syndrome', 'System', 'Techniques', 'Term Birth', 'Testing', 'Time', 'Uterine Contraction', 'Uterus', 'Validation', 'base', 'cohort', 'computerized', 'design', 'digital', 'disability', 'effectiveness evaluation', 'falls', 'fetal', 'fetus at risk', 'high risk', 'improved', 'large datasets', 'multidisciplinary', 'neonatal hypoxic-ischemic brain injury', 'novel', 'population based', 'predictive modeling', 'prevent', 'routine care', 'signal processing', 'standard measure', 'standard of care', 'uterine contractility']",NICHD,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,566881
"Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises Project summary: Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems. This leads to at least 16 million cases of acute gastroenteritis directly linked to pollution at community water systems, with tens of millions more directly impacted by chemical and organic pollutants. Impacts are further exacerbated in locations dealing with water scarcity, in under-served populations, and within other vulnerable populations already suffering from health disparities. Many of these water problems are the direct result of managerial negligence, inconsistent monitoring, and a lack of the ability to anticipate where problems may arise next. While the reasons for drinking water problems are complex, if we could anticipate where health-based drinking water problems were to occur in the future, it could have an immediate and positive impact on tens of millions of Americans annually. Interestingly, extensive data about water quality and the performance of municipal water systems already exists in large, disparate databases. These databases are largely ignored and, when used, are typically used only anecdotally and retroactively. Preliminary evidence suggests that these existing databases, which contain histories of administrative violations and sub-threshold water-quality results, can be mined to accurately predict future drinking water crises. The Superior Statistical Research R&D team is an internationally recognized group of water experts with cross-cutting expertise in statistics/data analysis/modelling/computing, water-quality monitoring of biological and chemical contaminants, and the ability to clearly and compellingly translate water-quality and health information to actionable steps for individuals, organizations and communities. In this Phase I project, we will show that it is possible to predict water-related, health-based problem areas utilizing already collected, historical data on water quality and municipal water system performance. We will begin by harmonizing the disparate water quality and municipal water system performance in two different states (Michigan and Iowa). We will then utilize machine-learning techniques to predict health-based violation histories and will evaluate our methods by comparing predicted violations to actual health-based violations in the previous 5 years. Finally, we will identify at least 10 municipalities determined by our algorithm to be at the highest risk for future health- based water problems and will do systematic sampling to confirm our model-based predictions. We will then demonstrate how making these predictions can be leveraged to profitability by exploring how our model-based predictions can be presented to customers in an economical, usable form. Proof of our concept and profitability models in two states (Phase I) will set us up for widespread (multi-state) database harmonization and improvement of the proposed machine-learning/modelling effort in Phase II. With multi-state harmonized datasets, identification of key data gaps in particular states/areas, and proven financial models, our technology will ultimately lead to dramatic reductions in the number of health-based drinking water problems annually. Project Narrative Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems, but predicting where and when these health-based drinking water problems will occur remains a large and complex obstacle. Current approaches focus on a reactive approach to health-based water-quality violations in community water systems, rather than a proactive one that seeks to anticipate where problems will occur in the future. The overall goal of this project is to leverage large and disparate historical datasets of water quality to accurately predict locations of future health-based water-quality violations, validate the predictions, and commercialize our proprietary predictions as a practical and cost-saving approach to anticipating and heading off future health-based water problems.",Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises,10253600,R43ES033134,"['Acute', 'Address', 'Algorithms', 'American', 'Area', 'Biological Monitoring', 'Chemicals', 'Cities', 'Coal', 'Communities', 'Community Surveys', 'Complex', 'Cost Savings', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ensure', 'Exposure to', 'Filtration', 'Focus Groups', 'Future', 'Gastroenteritis', 'Goals', 'Government', 'Health', 'Human', 'Individual', 'International', 'Iowa', 'Lead', 'Lead levels', 'Link', 'Location', 'Machine Learning', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Municipalities', 'Negligence', 'Pathway interactions', 'Performance', 'Persons', 'Phase', 'Pollution', 'Price', 'Provider', 'Public Health', 'ROC Curve', 'Recording of previous events', 'Records', 'Research', 'Safety', 'Sampling', 'Serinus', 'Site', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Trust', 'Underserved Population', 'Vulnerable Populations', 'Water', 'advocacy organizations', 'base', 'commercialization', 'data harmonization', 'data integration', 'drinking water', 'economic impact', 'health disparity', 'high risk', 'improved', 'inner city', 'innovation', 'large scale data', 'member', 'pollutant', 'predictive modeling', 'research and development', 'rural area', 'statistics', 'water quality', 'water sampling', 'water testing', 'willingness to pay']",NIEHS,"SUPERIOR STATISTICAL RESEARCH, LLC",R43,2021,256579
"Methods for Evolutionary Genomics Analysis Summary/Abstract Continuing advances in nucleotide sequencing have resulted in the assembly of datasets containing large numbers of species, genes, and genomic segments. Phylogenomic analyses of these data are essential to progress in understanding evolutionary patterns across the tree of life, and are finding increasing numbers of applications in practical analyses that require understanding of how patterns change over time. The sheer size of phylogenomic datasets limits the practical utility of available methods due to excessive time and memory requirements. We have developed many high impact methods and tools for comparative analysis of molecular sequences, a tradition we propose to continue through this MIRA project by developing innovative methods that address new challenges in phylogenomics. We will focus on pattern-based approaches of machine learning with sparsity constraint (SL) applied to phylogenomics, as a complement to traditional model-based methods in molecular evolution and phylogenetics. In the proposed SL in Phylogenomics (SLiP) framework, we will build models that best explain the biological trait or evolutionary hypothesis of interest, with genomic loci, such as genes, proteins, and genomic segments, serving as model parameters. Preliminary results from two example applications establish the premise and promise of a general SLiP framework. In one, SLiP successfully detected loci whose inclusion in a phylogenomic dataset overtakes a consistent and contrasting signal from hundreds of other loci when inferring phylogenetic relationships. In the other example, SLiP revealed loci and biological functional categories that harbor convergent sequence evolutionary patterns associated with the emergence of the same trait in distinct evolutionary lineages. In all of these analyses, SLiP required only a small fraction of the computational time and memory demanded by traditional methods, and it enabled better evolutionary contrasts with fewer assumptions. Consequently, the successful development of SLiP will improve the feasibility, rigor, and reproducibility of large-scale data analysis. It will also democratize big data analytics via shortened analysis time and a relatively small memory footprint, and encourage the development of a new class of methods for phylogenomic analysis. This framework will be accessed from a free library of SLiP functions, which will be directly useable via command line and available in a graphical interface through integration with the MEGA software. Narrative The long-term goal of my research program is to develop methods and tools for comparative analysis of molecular sequences. In this project, we will develop a new class of phylogenomic methods based on sparse machine learning and benchmark their absolute and relative performance. New techniques and their software implementation will greatly facilitate data analyses that are vital for evolutionary and functional genomics.",Methods for Evolutionary Genomics Analysis,10086181,R35GM139540,"['Address', 'Benchmarking', 'Big Data Methods', 'Biological', 'Categories', 'Complement', 'Computer software', 'Data Analyses', 'Data Set', 'Development', 'Gene Proteins', 'Genes', 'Genomic Segment', 'Genomics', 'Goals', 'Libraries', 'Life', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular Analysis', 'Molecular Evolution', 'Nucleotides', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Reproducibility', 'Research', 'Signal Transduction', 'Techniques', 'Time', 'Trees', 'base', 'comparative', 'functional genomics', 'genomic locus', 'graphical user interface', 'improved', 'innovation', 'interest', 'large scale data', 'programs', 'tool', 'trait']",NIGMS,TEMPLE UNIV OF THE COMMONWEALTH,R35,2021,396250
"A novel microfluidic platform to study exosome biology in PAH. The endothelium is the cellular monolayer that covers the inner lining of the entire circulatory system. Endothelial dysfunction is a feature of pulmonary arterial hypertension (PAH), a life-threatening disease associated with abnormally high pulmonary pressures and chronic right heart failure. Due to the limitations of available static cell culture and animal models, our understanding of the mechanisms that orchestrate the initiation and perseverance of endothelial dysfunction in PAH remains incomplete. Given that endothelial dysfunction is a common finding in PAH, an understanding of the mechanism behind maladaptive endothelial responses could help accelerate the discovery of novel therapies for PAH. Presently, it is believed that endothelial derived exosomes contribute to PAH by carrying signals that trigger maladaptive endothelial responses in the setting of injury. Exosomes are cell-derived small (~30-150 nm) extracellular vesicles that carry proteins, metabolites and nucleic acids involved in a variety of physiological and pathological processes. While it is known that exosomes carry molecular and genetic factors associated with angiogenesis, inflammation and vasoreactivity, a comprehensive assessment of exosome cargo of healthy and dysfunctional PMVECs has been hindered by current low-yield exosome isolation techniques. These techniques cannot perform real-time dynamic exosome isolation from pulmonary microvascular endothelial cells (PMVECs) exposed to PAH-associated stressors. To address this unmet need, we have designed the MFES (Multifunctional Exosome Sorter) that can dissect the whole exosome population into subpopulations based on size and surface markers. MFES is the first lab-on-a-chip platform that integrates: 1) a vessel-on-a-chip module for real-time characterization of PMVEC functional responses across a wide range of physiological and pathological parameters, 2) a module for high-yield exosome size-based isolation, 3) a surface marker based exosome sorting using magnetic beads, and 4) multi-omics phenotyping of exosomes of PMVECs. Here, we are proposing a technology that can enable broadly to investigate the two main defining characteristics of exosomal subtypes, i.e., size and surface markers, both separately independently, and in combination sequentially. We will characterize changes in exosome cargo in healthy and PAH PMVECs exposed to shear stress-related conditions in the MFES. We will isolate subpopulations of exosomes based on size and surface markers and characterize them for their cargo (Aim 1). Then, we will determine whether exosomes derived from stressed PMVECs can induce pathological changes in healthy PMVECs cultured in a microfluidic culture chip (Aim 2). This technological innovation enables to study endothelial exosome biology in a setting that represents the flow dynamics associated with PAH. Further, the use of cutting-edge -omics technologies, bioinformatic analysis integrated with machine learning algorithms to analyze the purified exosomes is expected to yield a comprehensive dataset of exosome cargo profiles and open exciting opportunities for investigating the biological role of exosomes in PAH pathobiology and the testing of novel therapeutic agents. Due to the limitations of available static cell culture and animal models, our understanding of the mechanisms that orchestrate the initiation and perseverance of endothelial dysfunction in pulmonary arterial hypertension (PAH) remains incomplete. The endothelial cell derived exosomes, small (~30-150 nm) extracellular vesicles, contribute to PAH by carrying signals that trigger maladaptive endothelial responses in the setting of injury via molecular and genetic factors associated with angiogenesis, inflammation and vasoreactivity. However, a comprehensive assessment of exosomal cargo of healthy and dysfunctional pulmonary microvascular endothelial cells (PMVECs) has been hindered by current low-yield exosome isolation techniques that integrates real-time exosome capture from PMVECs exposed to PAH-associated high shear stress. We propose to develop a lab-on-a-chip platform technology, Multifunctional Exosome Sorter (MFES), that can dissect the whole exosome population into subpopulations based on size and surface markers integrating; (i) a vessel-on-a-chip module, (ii) a high-yield exosome size-based isolation module, (iii) a magnetic bead-based surface biomarker sorting chamber, and (iv) multi-omics phenotyping of exosomes investigating the biological role of exosomes in PAH pathobiology, where such a technological innovation will uniquely enable to study the biology of exosome subsets associated with flow dynamics in PAH.",A novel microfluidic platform to study exosome biology in PAH.,10158068,R21HL156761,"['Acoustics', 'Address', 'Animal Model', 'Antibodies', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biology', 'Blood Vessels', 'CD81 gene', 'Cardiovascular system', 'Cell Culture Techniques', 'Cells', 'Characteristics', 'Chronic', 'Culture Media', 'Cultured Cells', 'Data Set', 'Disease', 'Endothelial Cells', 'Endothelium', 'Etiology', 'Experimental Models', 'Exposure to', 'Genetic', 'Goals', 'Heart failure', 'Inflammation', 'Inflammatory', 'Injury', 'Lab-On-A-Chips', 'Life', 'Lung', 'Machine Learning', 'Mediating', 'Methods', 'Microfluidics', 'Molecular', 'Molecular Genetics', 'Nucleic Acids', 'Outcome', 'Pathologic', 'Pathologic Processes', 'Pattern', 'Phase', 'Phenotype', 'Physiological', 'Physiological Processes', 'Population', 'Process', 'Production', 'Proteomics', 'Reporting', 'Reproducibility', 'Resolution', 'Role', 'Seeds', 'Signal Transduction', 'Sorting - Cell Movement', 'Stress', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Vascular remodeling', 'Vision', 'angiogenesis', 'base', 'cytokine', 'design', 'endothelial dysfunction', 'exosome', 'extracellular vesicles', 'hemodynamics', 'machine learning algorithm', 'magnetic beads', 'monolayer', 'multiple omics', 'new technology', 'novel', 'novel therapeutics', 'pressure', 'protein metabolite', 'pulmonary arterial hypertension', 'response', 'shear stress', 'stressor', 'technological innovation', 'tool', 'transcriptome sequencing']",NHLBI,STANFORD UNIVERSITY,R21,2021,236363
"Virtual growing child 5-dimensional functional models for treating respiratory anomalies Thoracic Insufficiency Syndrome (TIS) is a group of serious disorders of the pediatric thorax resulting in an inability of the thorax to support respiration or lung growth. TIS is associated with at least 28 pediatric syndromes, with an estimated health care cost per patient that can easily exceed a million dollars. In TIS, three-dimensional deformity of the thoracic components anatomically and functionally reduces the volume available for ventilation. Pediatric specialists dealing with TIS currently face several serious challenges: (a) The complex interplay among dynamic and growing thoracic structures and its influence on thoracic function and growth are not understood at present. (b) The prime outcome measure for the corrective procedures has remained the radiographic Cobb angle of the spine, a 60-year old metric with poor correlation with lung dynamic function and limited true health assessment value. (c) A normative imaging database with functional metrics describing dynamics and growth of the thoracic structures of the normal pediatric population does not exist. Due to these hurdles, innovations in growth-modulating surgical techniques are difficult to achieve. Supported by extensive preliminary results based on dynamic MRI (dMRI) of patients and normal subjects, the overarching goal of this proposal is to develop novel dynamic functional metrics for TIS by establishing a normative database of dMRI images and anatomic and functional models and metrics, and to translate these to develop markers of TIS and of its corrective-surgery outcomes. The project has three aims. Aim 1: To develop a new methodology called The Virtual Growing Child (VGC) consisting of 4 key components: a) To build a normative database of dMRI images prospectively gathered from 200 normal children divided into 10 groups. b) To build population anatomic models involving key thoraco-abdominal objects following an established automatic anatomy recognition (AAR) technology and deep learning (DL) techniques. c) To develop and validate joint AAR-DL algorithms to segment these objects in dMRI images of TIS patients. d) To build a normative database of measurements derived from dMRI images describing normal thoracic architecture, dynamic function, and growth. The database will also include a full battery of Pulmonary Function Testing data and anthropometric measurements. Aim 2: To test retrospectively the utility of the VGC ensemble in deriving markers of TIS and its surgical treatment effects on a cohort of 100 TIS patients. Aim 3: To retrospectively test the utility of the VGC approach for planning surgery in 30 TIS patients by comparing VGC-guided surgical planning to the current planning method. The post-operative key dMRI parameters of patients whose surgical plan would have changed due to VGC data will be compared to those of patients whose plan did not change. Expected outcomes: (i) A unique registry of thoracic dMRI of 200 normal pediatric subjects, segmented objects, and the associated anatomic, dynamic, and developmental parameters. (ii) A validated VGC approach for studying TIS which can also be utilized for studying other pediatric and adult thoracic disorders. Thoracic Insufficiency Syndrome (TIS) is a group of serious disorders of the pediatric thorax. Currently there are no reliable and scientific functional metrics to describe these disorders and their treatment effects. This grant application proposes to build an innovative methodology called the Virtual Growing Child (VGC) based on dynamic MRI of the thorax, construct a comprehensive normative database of MRI images and associated measurements, and utilize the VGC methodology to scientifically characterize TIS and arrive at innovative surgical planning methods.",Virtual growing child 5-dimensional functional models for treating respiratory anomalies,10086887,R01HL150147,"['3-Dimensional', 'Abdomen', 'Address', 'Adult', 'Aftercare', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Applications Grants', 'Architecture', 'Birth', 'Chest', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Databases', 'Deformity', 'Development', 'Diagnostic radiologic examination', 'Dimensions', 'Disease', 'Face', 'Gender', 'Goals', 'Growth', 'Health Care Costs', 'Image', 'Incidence', 'Joints', 'Life', 'Lung', 'MRI Scans', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Names', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedic Procedures', 'Outcome', 'Outcome Measure', 'Patients', 'Population', 'Population Group', 'Postoperative Period', 'Procedures', 'Pulmonary function tests', 'Registries', 'Respiration', 'Rod', 'Scanning', 'Sensitivity and Specificity', 'Specialist', 'Spinal', 'Spinal Fusion', 'Spirometry', 'Structure', 'Syndrome', 'Techniques', 'Technology', 'Testing', 'Thoracic Diseases', 'Tidal Volume', 'Time', 'Translating', 'Vertebral column', 'Vital capacity', 'age group', 'base', 'clinical outcome measures', 'cohort', 'deep learning', 'deep learning algorithm', 'health assessment', 'innovation', 'novel', 'prospective', 'pulmonary function', 'respiratory', 'surgery outcome', 'treatment effect', 'ventilation', 'virtual']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2021,769122
"Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support,10393815,R01GM109718,"['Communicable Diseases', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Economic Burden', 'Economics', 'Epidemic', 'Geography', 'Growth', 'Health', 'Health Personnel', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Methodology', 'Methods', 'Modeling', 'Policy Maker', 'Population', 'Privatization', 'Public Health', 'Resource Allocation', 'Resources', 'Risk', 'Science', 'Source', 'System', 'Techniques', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Work', 'base', 'data mining', 'health care delivery', 'improved', 'novel', 'provider networks', 'statistics', 'undergraduate student']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,11253
