text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,9976740,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Heterogeneity', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2019,299197,0.028011420094775447
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9748523,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,195128,0.039918252658145456
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9751222,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2019,373460,0.005790158429226098
"Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images ABSTRACT Manual analysis of biomedical images by researchers and pathologists has the potential to introduce bias and error that compromise the reliability of research and clinical findings. These problems are significant barriers to delivering the most beneficial evidence-based medicine, developing effective medical treatments, and promoting confidence in scientific inquiry. Identification of biomarkers and cellular targets following microscopy requires manual analysis of biomedical images, which is time intensive, difficult, and prone to bias and errors. Unintentional bias and attentional limitations during analysis of biomarkers can underlie poor reproducibility of findings in biomedical research and potentially introduce error in clinical diagnostics. We recently developed a “beta” software package designed to improve automation and standardization of image analysis, called “PIPSQUEAK” (Perineuronal net Intensity Program for the Standardization and Quantification of Extracellular matrix Analysis Kit). Since its publication in 2016, PIPSQUEAK beta has amassed approximately 1,300 users worldwide who use it to quantify the intensity and number of perineuronal nets and other neural markers in the brain. This technology significantly increases data reliability between image raters and decreases the time required for analysis by more than 100-fold. However, PIPSQUEAK beta currently uses target detection algorithms that require high-contrast images to automatically identify neurons as clusters of bright pixels on dark backgrounds. A significant current limitation to PIPSQUEAK beta, and other available imaging programs, is that detection of biomarkers can be difficult unless image conditions are ideal. Suboptimal conditions, like high background staining, off-target structures, overlapping or clustered biomarkers, and atypical morphologies, can lead to artifacts and consequently to inaccurate results and erroneous conclusions. Here, we propose to develop a user-friendly artificial intelligence (AI) platform for the automated detection of targeted biomarkers in digital microscopy that reduces this error by learning to distinguish between true cellular biomarkers and artifacts. We propose to integrate AI capabilities into our PIPSQUEAK technology to produce an adaptive, high-throughput, biomedical image analysis platform that quickly and accurately identifies biomarker targets from bench to bedside. A key advantage is that this AI program will be user friendly and available online, making it highly accessible to basic researchers and to technicians and clinicians identifying human pathologies. Thus, successful development of our AI program has a high translational potential. The goal of this proposal is 1) to develop and validate a machine learning model that is capable of detecting common histological marker morphologies in digital microscopy, and 2) to test the feasibility of adapting our AI platform to new biomarker datasets with minimal additional supervised training. Our end goal is to advance the reliability and speed of research findings and clinical diagnoses by making this technology widely available to researchers and clinicians. PROJECT NARRATIVE Manual analysis of biomedical images by researchers and pathologists has the potential to introduces bias and error that compromise the reliability of research and clinical findings; problems which are significant barriers to delivering the most beneficial evidence-based medicine and developing effective medical treatments. Application of artificial intelligence for the detection of disease or cellular targets has the potential to improve the reliability of research findings and clinical diagnoses, while reducing waste, time, and expense. We propose a method to improve the quality of biomedical research reproducibility and clinical diagnoses by developing a high-throughput, adaptive artificial intelligence platform for automated analysis of cellular and disease targets in digital microscopy images, which will be made available to scientists and clinicians as a user-friendly analysis platform.",Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images,9845994,R43GM134789,"['Abbreviations', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Automation', 'Biological Markers', 'Biomedical Research', 'Brain', 'Cell Line', 'Cell model', 'Cellular Morphology', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Coupled', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Evidence Based Medicine', 'Extracellular Matrix', 'FOS gene', 'Fluorescence', 'Future', 'Glial Fibrillary Acidic Protein', 'Goals', 'Histologic', 'Histology', 'Human Pathology', 'Image', 'Image Analysis', 'Immunoassay', 'Immunohistochemistry', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Medical', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Neurons', 'Nuclear', 'Pathologist', 'Performance', 'Procedures', 'Psychological Transfer', 'Publications', 'Rattus', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Shapes', 'Speed', 'Stains', 'Standardization', 'Structure', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Banks', 'Tissue Model', 'Tissue imaging', 'Tissues', 'Training', 'Zebrafish', 'automated analysis', 'base', 'bench to bedside', 'bioimaging', 'biomarker identification', 'cell type', 'cellular targeting', 'clinical Diagnosis', 'clinical diagnostics', 'contrast imaging', 'design', 'digital', 'digital imaging', 'extracellular', 'histological specimens', 'histological stains', 'imaging biomarker', 'imaging program', 'improved', 'interest', 'lateral line', 'microscopic imaging', 'predictive marker', 'programs', 'relating to nervous system', 'software as a service', 'statistics', 'targeted biomarker', 'tool', 'user-friendly', 'wasting']",NIGMS,"REWIRE NEUROSCIENCE, LLC",R43,2019,224915,0.028030838620436413
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning. !",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,9776655,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis\xa0', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2019,185379,0.01107787291367344
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9762102,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2019,460690,-0.018028679357121973
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9692717,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2019,695400,0.07452829812736321
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9706921,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2019,381629,-0.003698260269388962
"Deep learning-based image analysis for assessing real-time smoking risk ABSTRACT Whereas the majority of smokers will quit in any given year, the majority of quit attempts result in relapse. One reason interventions may fail is that they teach smokers strategies for coping with craving in response to environmental triggers, but do not provide smokers with just-in-time information about their risk of smoking lapse. Such risk information could be used to alert smokers to engage in relevant coping strategies including avoidance or use of quick acting pharmacotherapies (e.g. nicotine inhaler). The overarching premise of the proposed research is that prediction of lapse risk can be enhanced by using computer vision to analyze images of everyday life. Recent findings by our team suggest that environments associated with lapse risk can be detected in real-time by coupling deep learning-based object detection with an appropriate classification model. In preliminary research, images taken by smokers of smoking and nonsmoking environments (80 subjects, 2870 images) were used to train such a model, resulting in 77.5% accuracy (0.826 AUC) distinguishing these environments on a separate test set (16 subjects, 516 images). Encouraged by this preliminary finding, we propose to refine and scale up this system by a) creating a larger and more representative image database that includes a sample of everyday environments acquired from smokers (n=60) and b) testing novel, personalized approaches for increasing smoking environment classification accuracy and assessing smoking risk across three aims. In Aim 1, we will improve smoking environment classification accuracy and prediction of smoking risk by re-training an existing deep learning model to recognize a broad set of smoking-related objects (e.g. packs of cigarettes/ashtrays). In Aim 2, we will further improve performance by fitting personalized models that account for individual differences in preferred or typical smoking environments. In Exploratory Aim 3, we will predict craving and negative affect/stress using a similar approach. The proposed research represents an innovative and critical next step in the development of a system that identifies smoking risk and/or its antecedents in real-time to support a just-in-time adaptive intervention for smoking cessation. PUBLIC HEALTH RELEVANCE: The majority of smokers relapse within one month of quitting smoking. Environments (e.g. park) and their related objects (e.g. park bench) are associated with smoking and urges to smoke and can serve as triggers to lapse and relapse. The proposed research will use state-of-the-art computer vision and object detection to identify smoking risk environments and objects with the goal of eventually developing systems that alert smokers to such risks from everyday images acquired with cameras worn by smokers. Such a system can be incorporated into more comprehensive and effective smoking cessation programs.",Deep learning-based image analysis for assessing real-time smoking risk,9774018,R21DA047131,"['Adult', 'Behavior', 'Cigarette', 'Classification', 'Clinical', 'Computer Vision Systems', 'Coupled', 'Coupling', 'Data', 'Databases', 'Detection', 'Development', 'E-learning', 'Environment', 'Event', 'Frequencies', 'Goals', 'Image', 'Image Analysis', 'Individual Differences', 'Intervention', 'Knowledge', 'Life', 'Location', 'Methods', 'Modeling', 'Neural Network Simulation', 'Nicotine Inhaler', 'Patient Self-Report', 'Performance', 'Pharmacotherapy', 'Phase', 'Real-Time Systems', 'Relapse', 'Research', 'Risk', 'Risk Assessment', 'Sampling', 'Shelter facility', 'Smoke', 'Smoker', 'Smoking', 'Smoking Cessation Intervention', 'Source', 'Stress', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Work', 'adaptive intervention', 'base', 'clinically relevant', 'convolutional neural network', 'coping', 'craving', 'deep learning', 'high risk', 'improved', 'innovation', 'longitudinal dataset', 'negative affect', 'non-smoking', 'novel', 'personalized approach', 'programs', 'public health relevance', 'response', 'scale up', 'smartphone Application', 'smoking cessation', 'time use']",NIDA,DUKE UNIVERSITY,R21,2019,201250,0.002649934818478131
"Content-based MR-TRUS Fusion without Tracking There are about 3 million American men living with prostate cancer, the second leading cause of cancer death for men in the United States. If the prostate cancer is caught early before it spreads to other parts of the body, by active monitoring or treatment, most men will not die from it. Nevertheless, 22% to 47% of the patients with negative biopsies but elevated prostate-specific antigen levels may still harbor malignant tumors, which can be life threatening and could have been missed by the commonly used ultrasound guided random biopsy. By contrast, fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted biopsies has shown to significantly improve the cancer detection rate. However, MR-TRUS fusion itself is very challenging due to the difficulties in directly registering images of these two very different modalities in different dimensions. To bypass the difficult registration problems, the existing fusion techniques require the use of specialized expensive and cumbersome hardware tracking devices, which increases cost and elongates procedures. More importantly, due to a number of factors such as patient movement, respiratory motion and ultrasound transducer pressure change, prostate motion can happen during a procedure and cause the images to be misaligned. Timely noticing and correcting such motion require great skill and knowledge of radiological imaging, where studies show a steep learning curve for mastering fusion systems. Failing in image registration and motion compensation renders the fusion guided biopsy performing no differently than random biopsy. To address the fundamental cause of the problems, the goal of this project is to create enabling technology of MR- TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs. Recent advancement in machine learning, especially deep learning, has provided us new tools and new angles to tackle this challenging problem. This project aims for directly fusing 2D TRUS frames with 3D MR volume by developing novel deep learning methods for image reconstruction and registration. The proposed methods are designed to exploit both population and patient specific imaging information to accurately align images. As all learning-based image registration methods try to better use population knowledge to improve the registration performance, few of them have been able to efficiently use patient specific information, which can be essential to obtain robust and accurate performance. Upon successful completion, the innovation created from the project will disrupt the common perception that hardware tracking has to be used for multimodal image fusion-guided interventions and alleviate the demand on physicians’ experience and skill in image analysis and fusion to help obtain consistent results. This project will lead to the development of novel prostate biopsy systems and will also impact a range of other image fusion based interventional guidance technologies. Fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted prostate biopsies can significantly improve the detection of aggressive cancer. The goal of this project is to create enabling technology of MR-TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs.",Content-based MR-TRUS Fusion without Tracking,9726560,R21EB028001,"['3-Dimensional', 'Address', 'American', 'Area', 'Biopsy', 'Body part', 'Bypass', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Cyst', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Electromagnetics', 'Financial compensation', 'Foundations', 'Future', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Intelligence', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Life', 'Liver', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Manuals', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Multimodal Imaging', 'Patients', 'Perception', 'Performance', 'Physicians', 'Population', 'Pressure Transducers', 'Procedures', 'Prostate', 'Prostate-Specific Antigen', 'Psychological Transfer', 'Research', 'Retrospective Studies', 'Risk Assessment', 'Slice', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Thinness', 'Time', 'Training', 'Transrectal Ultrasound', 'Ultrasonic Transducer', 'Ultrasonography', 'United States', 'base', 'calcification', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'experience', 'image reconstruction', 'image registration', 'imaging modality', 'imaging study', 'improved', 'innovation', 'learning strategy', 'men', 'next generation', 'novel', 'patient population', 'population based', 'prostate biopsy', 'radiological imaging', 'reconstruction', 'research clinical testing', 'respiratory', 'skills', 'tool']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R21,2019,217513,0.02895244787747614
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9765316,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Endothelium', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Tissue Transplantation', 'Topical Corticosteroids', 'Translating', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2019,200104,0.044088994059887726
"Automated end-to-end retinal screening system with robotic image capture and deep learning analysis Abstract  In this SBIR project, we propose EyeScreenBot, an end-to-end automated retinal im- age capture and analysis system, comprising a self-driven, robotic fundus camera plat- form for automated image capture and a deep learning-based image analysis engine for generation of automated screening outcome. With the large, growing, and aging popula- tion and the increased prevalence of diabetes, a large number of people are at risk for vision loss due to several eye diseases including diabetic retinopathy (DR), age-related macular degeneration (AMD), and glaucoma. Although eye screening is effective in re- ducing vision loss, there are not enough clinical personnel and eye-care experts for pop- ulation-wide eye screening. Recent advances with automated image analysis are helping alleviate the situation, but they are still limited by the need for good quality images of the patients captured by trained technicians or expensive retinal cameras equipped for auto- mated capture. EyeScreenBot will be developed to provide a truly end-to-end screening solution that is cost-effective and suitable for deployment in primary care clinics or op- tometrist sites, addressing both automated capture and subsequent automated analysis, all without the need for trained technicians or eye experts at the point of care. When deployed and commercialized, this device will rapidly aid scaling of eye screening for the masses, thereby having an enormous impact in improving the quality and accessibility of eye care and helping reduce preventable vision loss. Narrative EyeScreenBot, an end-to-end automated screening system with intelligent image capture and analysis, will truly enable eye screening at massive scale, which is necessary and urgent since the population at risk for preventable vision loss due to retinal diseases (such as diabetic retinopathy) is growing at a staggering rate. Triaging and identification of at-risk patients will allow for timely intervention to prevent, slow, or even reverse the disease progression and loss of vision.",Automated end-to-end retinal screening system with robotic image capture and deep learning analysis,9847891,R43EY029652,"['Address', 'Age', 'Age related macular degeneration', 'Algorithms', 'Area', 'Blindness', 'California', 'Caring', 'Clinic', 'Clinical', 'Color', 'Computational algorithm', 'Computer Vision Systems', 'County', 'Coupled', 'Development', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease Progression', 'Evaluation', 'Eye', 'Eye diseases', 'Fundus', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Hand', 'Health', 'Health Services', 'Human', 'Human Resources', 'Image', 'Image Analysis', 'Institutes', 'Intelligence', 'Intervention', 'Intuition', 'Los Angeles', 'Manuals', 'Mass Screening', 'Measures', 'Medical', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Pilot Projects', 'Population', 'Populations at Risk', 'Prevalence', 'Primary Health Care', 'Process', 'Pupil', 'Retinal', 'Retinal Diseases', 'Risk', 'Robot', 'Robotics', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Small Business Innovation Research Grant', 'Software Engineering', 'Surveys', 'System', 'Systems Analysis', 'Testing', 'Time', 'Training', 'Triage', 'Universities', 'Validation', 'Visual impairment', 'Work', 'aging population', 'automated analysis', 'automated image analysis', 'base', 'cost effective', 'deep learning', 'deep learning algorithm', 'design', 'diabetic', 'digital imaging', 'experience', 'fundus imaging', 'improved', 'interest', 'macula', 'point of care', 'portability', 'prevent', 'professor', 'programs', 'retinal imaging', 'robot interface', 'robotic system', 'screening', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2019,218618,-0.016990502219756606
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,9827476,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Quality', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2019,401628,-0.011938855216192165
"Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment Project Summary More than 20,000 hematopoietic stem cell transplants (including bone marrow transplants) are performed in the U.S. each year to cure a range of diseases ranging from leukemias to sickle cell anemia to autoimmune deficiencies in children. Unfortunately, most long-term non-relapse survivors will die of chronic graft-versus-host disease (cGVHD), which remains a disease of steadily increasing incidence and profound unmet need. A fundamental barrier in cGVHD management and research is a lack of sensitive and objective assessment tools that permit objective and reproducible measures of disease severity and progression. Skin is the most commonly affected organ in cGVHD and automated techniques capable of measuring precisely the surface area of involved skin in photographs may provide the tools necessary for effectively evaluating patient progress. We propose to (1) create the data set necessary to develop machine learning-based methods for the automatic analysis of cGVHD images, and (2) implement and evaluate these methods. Project Narrative  Chronic graft-versus-host disease (cGVHD) is a lethal disease that affects most long-term hematopoietic stem cell transplant (including bone marrow transplants) recipients. Skin images are used to assess disease severity and progression but the technology required to quantitatively and reproducibly analyze these images is lacking. This project aims at developing and evaluating this technology.",Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment,9648538,R21AR074589,"['3-Dimensional', 'Achievement', 'Affect', 'Agreement', 'Allogenic', 'Area', 'Assessment tool', 'Autoimmune Process', 'Body Surface', 'Bone Marrow Transplantation', 'Characteristics', 'Child', 'Circumscribed Lesion', 'Clinic', 'Clinical', 'Clinical Research', 'Cutaneous', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dermatologic', 'Dermatologist', 'Disease', 'Disease Management', 'Disease Progression', 'Documentation', 'Erythema', 'Exanthema', 'Future', 'Goals', 'Hematologic Neoplasms', 'Hematopoietic Stem Cell Transplantation', 'Hematopoietic System', 'Human', 'Image', 'Incidence', 'Industry', 'Institution', 'Label', 'Lead', 'Lesion', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methods', 'Morbidity - disease rate', 'Organ', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Population', 'Protocols documentation', 'Psoriasis', 'Reaction', 'Reproducibility', 'Research', 'Resources', 'Role', 'Scanning', 'Severities', 'Severity of illness', 'Sickle Cell Anemia', 'Site', 'Skin', 'Skin Cancer', 'Standardization', 'Surface', 'Survivors', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-dimensional analysis', 'Time', 'Transplant Recipients', 'Visit', 'Vitiligo', 'automated analysis', 'base', 'cancer imaging', 'chronic graft versus host disease', 'data warehouse', 'deep learning', 'deep neural network', 'digital', 'graft vs host disease', 'high risk', 'image processing', 'improved', 'interdisciplinary approach', 'learning strategy', 'leukemia', 'machine vision', 'mortality', 'network architecture', 'neural network architecture', 'novel therapeutics', 'patient subsets', 'prototype', 'repository', 'response', 'skin disorder', 'skin lesion', 'stereoscopic', 'success', 'tool']",NIAMS,VANDERBILT UNIVERSITY,R21,2019,179706,0.009160564751654292
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9797689,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2019,748584,0.046810734174881095
"A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides Abstract/Summary In this SBIR, we propose to validate our handcrafted image analysis algorithm for auto-detecting Mycobacterium tuberculosis (MTB) in a digitized sputum smear. Once validated in a blinded study against manual microscopy and culture (the gold standard), we will try to improve our handcrafted algorithm by integrating, where appropriate, deep-learning approaches (via Convolutional Neural Networks (CNN)). Our novel diagnostic device (the Diascopic iON platform) uses automated image analysis to detect pathogens of interest. Through a blinded study (400 slides), we will assess the iON's effectiveness in detecting MTB. Our aim is to achieve >99% accuracy vs. microscopy, and sensitivity-specificity vs. culture of 80% and 99%, respectively. Currently, the iON platform can detect MTB on a Ziehl-Neelsen (ZN) stained sputum smear in less than 60 seconds, with accuracy of 95% vs. microscopy. The primary objective of this SBIR is to meet or exceed the minimal requirements for the WHO Target Product Profile (published 2014) of a rapid sputum-based test for detecting TB at the microscopy-center level of the health-care system. We will accomplish this feasibility study through a collaborative effort with the Case Western Reserve University-Uganda (UCRC) research team. A full-slide digitization and automated image analysis of 400 ZN slides is planned while on the ground in Uganda. Results will be published in an appropriate peer-reviewed journal for dissemination to the relevant TB pathology and provider community. A secondary objective of this SBIR is to improve our handcrafted algorithm through the use of deep- learning techniques (CNN). We will collaborate with Dr. Madabhushi (Case Western Reserve) - a world leader in Deep Learning methodologies – on this portion of the study. We are optimistic that by combining our handcrafted approach with a deep-learning approach, we can identify MTB bacilli more effectively (i.e. faster and more accurately). We will leverage the lessons-learned in this study to develop algorithms for other developing-world diseases like Onchocerca (river blindness), Plasmodium (malaria), and Shistomes (schistosomaisis). Successful completion of this SBIR will show that the iON can truly become a platform for automated pathogen detection, which will shift lab practices toward faster & more standardized routines that are performed by unskilled workers. If we're successful in this Phase I SBIR, we will develop auto-detect algorithms for 3-4 other pathogens in a phase II SBIR. We will then market the iON platform to resource-limited clinics in countries adversely affected by developing-world diseases. It is our experience that such clinics are seeking a rapid, low cost, accurate and simple diagnostic tool to improve their efficiency and their ability to detect and treat diseases. Narrative This SBIR is a validation study of a digital pathology platform to detect TB in digitized Ziehl–Neelsen (ZN) slides. We aim to establish a high accuracy (>99%) vs. manual microscopy and a sensitivity & specificity of 80% and 99%, respectively, vs. culture. The TB analysis occurs rapidly, with results available in <60 seconds. We will investigate whether algorithm improvements are possible by combining our handcrafted approach with deep-learning approaches to improve accuracy and efficiency. If high accuracy and sensitivity-specificity can be achieved for TB detection, this low-cost technology can have a significant impact on TB laboratory operations around the world. The technology can also be applied to other pathogens whose primary method of detection is microscopy.",A Study to Validate and Improve an Automated Image Analysis Algorithm to Detect Tuberculosis in Sputum Smear Slides,9851233,R43EB028736,"['Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Bacillus (bacterium)', 'Blinded', 'Case Study', 'Clinic', 'Clinical', 'Color', 'Communities', 'Complex', 'Country', 'DNA', 'Data', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Feasibility Studies', 'Funding', 'Gold', 'Hand', 'Health Status', 'Healthcare Systems', 'Image', 'Image Analysis', 'Infection', 'Infrastructure', 'Ions', 'Journals', 'Laboratories', 'Low income', 'Malaria', 'Manuals', 'Methodology', 'Methods', 'Microscopy', 'Morbidity - disease rate', 'Mycobacterium tuberculosis', 'Ocular Onchocerciasis', 'Onchocerca', 'Pathogen detection', 'Pathology', 'Patient Care', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Plasmodium', 'Preparation', 'Process', 'Provider', 'Publishing', 'Quality Control', 'Readiness', 'Reporting', 'Research', 'Resources', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Small Business Innovation Research Grant', 'Specificity', 'Specimen', 'Sputum', 'Stains', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Tuberculosis', 'Uganda', 'Universities', 'automated image analysis', 'base', 'cohort', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'digital pathology', 'experience', 'improved', 'innovation', 'interest', 'man', 'mortality', 'novel', 'novel diagnostics', 'operation', 'pathogen', 'portability', 'prevent', 'remote location', 'tool', 'tuberculosis diagnostics', 'validation studies']",NIBIB,"DIASCOPIC, LLC",R43,2019,225000,0.01492463217918437
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9618878,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Decubitus ulcer', 'Diabetic Foot Ulcer', 'Diabetic wound', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2019,401916,0.03550680899724636
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,9893208,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human body', 'Image', 'Image Analysis', 'Imagery', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed\xa0imaging', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2019,587413,0.04415447728039358
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",9640524,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Injury', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Receiver Operating Characteristics', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'disorder subtype', 'elastography', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,462750,0.018224371543762875
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this SBIR project, we present EyeMark, a set of advanced image analysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we will develop tools for computation of microaneurysm (MA) ap- pearance and disappearance rates (jointly known as turnover rates) for use as a bi- omarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high positive influ- ence on various aspects of DR care, including screening, monitoring progression, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a MA turnover computation prototype tool that ro- bustly registers longitudinal images (even with multiple lesion changes) and effectively detects DR lesions (lesion level AUROC>=0.95). The tool provides graceful degradation to confounding image factors by reporting MA turnover as a range, thereby capturing the inherent confidence in MA detection. By the end of Phase IIB we will develop a market ready, clinically validated end-to-end desktop software for robust, automated longitudinal lesion analysis and characterization that can work on the cloud to produce results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,9735477,R44TR000377,"['Adult', 'Age', 'Appearance', 'Area', 'Biological', 'Biological Markers', 'Biometry', 'Blindness', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Color', 'Computer Vision Systems', 'Computer software', 'Consumption', 'County', 'Data', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Digital Imaging and Communications in Medicine', 'Early identification', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Joints', 'Lesion', 'Los Angeles', 'Machine Learning', 'Measures', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Patients', 'Pattern Recognition', 'Pear', 'Performance', 'Phase', 'Picture Archiving and Communication System', 'Process', 'Protocols documentation', 'ROC Curve', 'Reporting', 'Research', 'Retinal', 'Retinal Diseases', 'Retrieval', 'Risk', 'Sampling', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'application programming interface', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'computerized', 'computerized tools', 'convolutional neural network', 'deep neural network', 'design', 'diabetic patient', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'high throughput analysis', 'image registration', 'imaging biomarker', 'improved', 'interest', 'longitudinal analysis', 'macula', 'medical schools', 'novel marker', 'novel therapeutics', 'prevent', 'programs', 'prototype', 'response', 'retinal imaging', 'screening', 'screening program', 'serial imaging', 'success', 'tool', 'usability', 'validation studies']",NCATS,"EYENUK, INC.",R44,2019,750000,0.011481634630388716
"An Integrated CT-based Image-Guided Neurosurgical System An Integrated CT-based Image-Guided Neurosurgical System In this SBIR Phase IIb proposal Xoran intends to commercialize a compact and affordable, yet highly- functional, system to provide real time image updates and navigation guidance in support of minimally invasive cranial and spinal neurosurgical procedures. The effort builds on previously developed compact and portable flat-panel Computed Tomography (CT) technology which has been commercialized for hard tissue applications, and incorporates work done in earlier phases of this project to generate viable high- quality images of the soft tissue structures in the brain. Intraoperatively obtained images tightly integrated into an onboard surgical navigation will provide updated instrument localization using next generation electromagnetic tool tip guidance. Workflow optimizations become possible when the imaging and guidance are one device, including fast local image updates, automatic image-to-world registration, as well as speed and simplicity of use. The project includes expansion of the system capabilities to facilitate precise minimally-invasive surgical removal of tumors in both the head and spine. It incorporates a machine-learning based deep neural network method for image finalization to allow high quality, low radiation image updates. The three-year project involves meeting technical milestones of system development including imaging capability, registration, navigation accuracy, speed, workflow, radiation dose considerations and cost. Clinical evaluations will take place at University of Michigan, and a team of consulting physicians has been assembled for oversight, input and feedback. Narrative / Relevance to Public Health Minimally invasive surgical procedures have many benefits to public health including reducing the medical risks and costs associated with brain cancer and spine surgery. However such procedures are often time consuming and technically difficult as the surgeon is unable to directly visualize the area of the operation. In this project, an intraoperative surgical system is developed with onboard imaging capability in order to enable minimally invasive surgeries to be performed more safely and completely, by providing hi-resolution imaging of the brain and spine while the surgeon operates.",An Integrated CT-based Image-Guided Neurosurgical System,9764897,R44CA112966,"['3-Dimensional', 'Address', 'Agreement', 'American', 'Anatomy', 'Animals', 'Area', 'Benefits and Risks', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Businesses', 'Caliber', 'Cancer Etiology', 'Canis familiaris', 'Capital', 'Central Nervous System Neoplasms', 'Cephalic', 'Cessation of life', 'Clinic', 'Clinical', 'Consensus', 'Consult', 'Consumption', 'Data', 'Devices', 'Diagnosis', 'Dose', 'Electromagnetics', 'Environment', 'Evaluation', 'Excision', 'Feedback', 'Fluoroscopy', 'Funding', 'Goals', 'Head', 'Image', 'Image-Guided Surgery', 'Institutional Review Boards', 'Investments', 'Licensing', 'Machine Learning', 'Malignant neoplasm of brain', 'Mediation', 'Medical', 'Medical Imaging', 'Metals', 'Metastatic Neoplasm to the Bone', 'Michigan', 'Minimally Invasive Surgical Procedures', 'Monitor', 'Navigation System', 'Neoplasm Metastasis', 'Neurosurgeon', 'Neurosurgical Procedures', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Pennsylvania', 'Phase', 'Physicians', 'Pituitary Neoplasms', 'Positioning Attribute', 'Procedures', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Resolution', 'Risk', 'Roentgen Rays', 'Safety', 'Scanning', 'Series', 'Small Business Innovation Research Grant', 'Speed', 'Spinal', 'Spine surgery', 'Structure', 'Surgeon', 'Survival Rate', 'System', 'Systems Development', 'Technology', 'Time', 'Tissues', 'Tomography, Computed, Scanners', 'United States National Institutes of Health', 'Universities', 'Update', 'Vertebral column', 'Veterinary Medicine', 'Veterinary Schools', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer site', 'cancer surgery', 'commercial application', 'cost', 'cranium', 'deep neural network', 'human subject', 'image guided', 'image reconstruction', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'instrument', 'interest', 'meetings', 'minimally invasive', 'neurosurgery', 'next generation', 'operation', 'point of care', 'portability', 'real-time images', 'research clinical testing', 'soft tissue', 'spine bone structure', 'tool', 'tumor', 'validation studies']",NCI,"XORAN TECHNOLOGIES, LLC",R44,2019,1350820,0.011000103486790664
"Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities. This suggests that abnormalities are subtle, and perhaps postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a collaboration supported by our concluding Fogarty project, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images produced as part of our concluding Fogarty project, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the arrangement of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high-resolution images of Bielschowsy stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This yields clear and measurable images of individual axons. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin-related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models to combine these various types of data with known properties of CNS white matter and myelin to build a model of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. In the process of completing these scientific aims, we will pursue the pedagogic goals of training the first two professional biostatisticians in Macedonia, and an academic pathologist. We will also hold a seminar course for biological researchers to build awareness and understanding of the power of biostatistical and other computational methods to enrich their research. NARRATIVE Our ongoing Fogarty/NIMH research project in Macedonia (R01 MH060877, “Building Schizophrenia Research in Macedonia”), has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale.",Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia,9953486,R56MH117769,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Architecture', 'Autopsy', 'Awareness', 'Axon', 'Biochemical', 'Biochemistry', 'Biological', 'Biological Assay', 'Biometry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Charge', 'Collaborations', 'Complex', 'Computer-Assisted Diagnosis', 'Computers', 'Computing Methodologies', 'Confocal Microscopy', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electron Microscope', 'Electrons', 'Fiber', 'Goals', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Individual', 'Informatics', 'International', 'Knowledge', 'Learning', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurable', 'Measurement', 'Measures', 'Medical', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Microscopy', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Morphology', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofilament Proteins', 'Paraffin', 'Pathologist', 'Pathology', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Schizophrenia', 'Scientist', 'Silver Staining', 'Stains', 'Statistical Data Interpretation', 'Statistical Methods', 'Structural Models', 'Students', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Transcript', 'Translational Research', 'Triad Acrylic Resin', 'base', 'cognitive function', 'computerized', 'computerized tools', 'data modeling', 'deep neural network', 'diffusion anisotropy', 'high resolution imaging', 'histological image', 'histological studies', 'imaging study', 'innovation', 'interest', 'low and middle-income countries', 'microscopic imaging', 'multidimensional data', 'multimodality', 'network models', 'novel', 'pedagogy', 'reconstruction', 'sex', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R56,2019,10000,-0.006268093344597904
"Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology ABSTRACT Acute infections of the middle ear (acute otitis media - AOM), are the most commonly treated childhood disease. Treatment is fueled by concern for complications and effects on children's cognitive and language development. The financial burden of AOM is estimated at more than $5 billion per year. Because AOM is so common, a major societal problem is the over-diagnosis and over-treatment of this disease, as a result of two factors: First, accurately diagnosing AOM is difficult, even for experienced primary care or ear, nose, and throat (ENT) physicians. Second, with a growing shortage of primary care physicians in the US, more Nurse Practitioners and Physician Assistants serve as first-line clinicians in primary care settings, but lack extensive training in otoscopy (i.e. clinical examination of the eardrum). Consequently, practitioners often err on the side of making a diagnosis of AOM and prescribing oral antibiotics. Over 8 million unnecessary antibiotics are prescribed annually, contributing to the rise of antibiotic-resistant bacteria, and creating the largest number of pediatric medication-related adverse events. Many children with inaccurate diagnoses of AOM are referred to ENTs for surgical placement of ear tubes, and up to 70% of these cases are not indicated. Diagnosing AOM still depends on clinician subjectivity, based on a brief glimpse of the eardrum. This diagnostic subjectivity creates a critical barrier to progress in society's goal of decreasing healthcare costs and reducing over-diagnosis and over-treatment of AOM. According to the American Academy of Pediatrics in 2013, devices are needed to assist in more accurate, consistent, and objective diagnosis of AOM. A simple and objective method of analyzing an image of a patient's ear to diagnose or rule out AOM would drastically reduce over-treatment. This project will fill that gap, by developing computer-assisted image analysis (CAIA) software that provides objective information to a clinician by analyzing eardrum images collected using currently available hardware. Based on previous work in applying similar methods to improve clinician performance in radiology and surgical pathology, our overarching hypothesis is that the incremental implementation of enhanced images, automated identification of abnormalities, and retrieval of similar cases will result in improved clinician diagnostic accuracy. In our preliminary work, we developed software, called Auto-Scope, which labels eardrums as “normal” versus “abnormal.” In this study, we propose two Specific Aims to improve diagnostic performance: Specific Aim #1: Create an enhanced composite image of the eardrum. Specific Aim #2: Use machine learning approaches for clinical decision support. The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality and reducing inter-observer variability, which will ultimately enable more accurate diagnosis and personalized therapeutic approaches for ear abnormalities. Thus, the proposed research is relevant to NIH's mission pertaining to the application of novel strategies that may improve human health, and NIDCD's mission of improving diagnosis and treatment of ear diseases, particularly otitis media.",Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology,9790958,R21DC016972,"['Academy', 'Acute', 'Address', 'Adverse event', 'Affect', 'Algorithms', 'American', 'Antibiotics', 'Appearance', 'Awareness', 'Bacterial Antibiotic Resistance', 'Child', 'Childhood', 'Cholesteatoma', 'Clinic', 'Clinical', 'Clip', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cyst', 'Databases', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Ear Diseases', 'Financial Hardship', 'Goals', 'Guidelines', 'Hair', 'Hand', 'Health', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Interobserver Variability', 'Label', 'Language Delays', 'Language Development', 'Lighting', 'Liquid substance', 'Machine Learning', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nose', 'Nurse Practitioners', 'Operative Surgical Procedures', 'Oral', 'Otitis Media', 'Otitis Media with Effusion', 'Otolaryngologist', 'Otoscopes', 'Otoscopy', 'Pathology', 'Patients', 'Pediatrics', 'Perforation', 'Performance', 'Pharmaceutical Preparations', 'Pharyngeal structure', 'Physician Assistants', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resolution', 'Retrieval', 'Side', 'Skin', 'Societies', 'Surgical Pathology', 'System', 'Testing', 'Training', 'Tube', 'Tympanic membrane', 'United States National Institutes of Health', 'Waxes', 'Work', 'accurate diagnosis', 'acute infection', 'base', 'central database', 'clinical decision support', 'cognitive development', 'computerized', 'diagnostic accuracy', 'digital imaging', 'digital video recording', 'effusion', 'experience', 'hearing impairment', 'improved', 'middle ear', 'novel', 'novel strategies', 'overtreatment', 'personalized therapeutic', 'primary care setting', 'prototype', 'software development']",NIDCD,OHIO STATE UNIVERSITY,R21,2019,199142,0.015651988803369658
"Characterization of Early Response to Chronic Lung Injury using Chest CT Project Summary  In some individuals chronic tobacco smoke exposure results in emphysema and pulmonary fibrosis. Both of these parenchymal changes are irreversible, highlighting the importance of the early identification of their development and progression. Unfortunately, currently available methods for detecting the presence and evolution of these changes have limited sensitivity and specificity for very early disease and for subtle disease progression. Dr. Ash’s work has shown that automated objective analysis of computed tomography (CT) scans of the chest can detect clinically relevant radiologic findings called interstitial changes that may represent early pulmonary fibrosis, even in individuals without visually apparent disease. In the first aim of this proposal, Dr. Ash will refine and utilize a more sensitive and specific automated CT analysis tool that he and his lab have developed for the detection of both emphysema and interstitial changes. He will determine if emphysema and interstitial changes detected using this method are clinically significant in those patients deemed normal by previously performed visual analysis and in those deemed normal by other objective approaches. In the second aim, he will determine if areas of locally high density tissue in visually normal appearing lung parenchyma measured using augmented versions of his objective analysis tools are associated with mortality, other clinical outcomes, and peripheral measures of inflammation. Finally, in the third aim he will utilize these techniques to analyze longitudinal CT scans from the COPDGene study that were obtained over 10 years of follow-up, and will identify factors that predict or modify the development and progression of parenchymal changes on CT.  Dr. Ash will perform this work in the Division of Pulmonary and Critical Care Medicine at Brigham and Women’s Hospital (BWH), a core teaching hospital of Harvard Medical School, under the mentorship of Dr. George Washko, an expert in the field of medical image analysis and the co-principal investigator of the Applied Chest Imaging Laboratory at BWH. With the guidance of Dr. Washko and his scientific advisory committee, Dr. Ash has developed a comprehensive five year training program to develop the skills needed to become an independent investigator with expertise in quantitative image analysis, including predictive modeling and statistical machine learning.  Dr. Ash is dedicated to a career in academic medicine. His goal is to become a clinician-scientist using the skills gained during this award to improve our ability to detect and monitor smoking related lung disease. The techniques he has proposed may help identify modifiable risk factors and treatments for smoking related lung disease, determine which patients are likely to benefit from treatment, and monitor the response to therapy. Project Narrative Cigarette smoking results in emphysema and pulmonary fibrosis, but only in a minority of smokers. This proposal aims to use advanced objective analysis of chest computed tomography images to detect the earliest manifestations of smoking related lung disease. This will enable us to identify susceptible patients at the earliest possible moment, track their disease progression, and ultimately shift treatment strategies from palliating disease related symptoms to preventing disease development.",Characterization of Early Response to Chronic Lung Injury using Chest CT,9646808,K08HL145118,"['Advisory Committees', 'Area', 'Award', 'Chest', 'Chronic', 'Cicatrix', 'Clinical', 'Critical Care', 'Densitometry', 'Detection', 'Development', 'Development Plans', 'Disease', 'Disease Progression', 'Early identification', 'Educational workshop', 'Evolution', 'Fibrosis', 'Goals', 'Hospitals', 'Image', 'Image Analysis', 'Imaging Techniques', 'Individual', 'Inflammation', 'Inflammatory', 'Laboratories', 'Lung', 'Lung diseases', 'Machine Learning', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Minority', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Outcome', 'Patients', 'Peripheral', 'Pharmaceutical Preparations', 'Predictive Factor', 'Primary Prevention', 'Principal Investigator', 'Publications', 'Pulmonary Emphysema', 'Pulmonary Fibrosis', 'Radiologic Finding', 'Radiology Specialty', 'Research Personnel', 'Respiratory physiology', 'Risk', 'Risk Factors', 'Scanning', 'Scientist', 'Sensitivity and Specificity', 'Severity of illness', 'Smoker', 'Smoking', 'Structure of parenchyma of lung', 'Symptoms', 'Teaching Hospitals', 'Techniques', 'Tissues', 'Tobacco smoke', 'Training', 'Training Programs', 'Visual', 'Woman', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'career', 'career development', 'chest computed tomography', 'cigarette smoking', 'clinically relevant', 'clinically significant', 'convolutional neural network', 'deep learning', 'density', 'disorder prevention', 'disorder risk', 'exercise capacity', 'follow-up', 'improved', 'interstitial', 'lung injury', 'mange', 'medical schools', 'modifiable risk', 'mortality', 'new technology', 'novel', 'palliate', 'palliation', 'predictive modeling', 'prevent', 'protein biomarkers', 'quantitative imaging', 'respiratory', 'response', 'skills', 'smoking-related lung disease', 'tool', 'treatment strategy']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,K08,2019,170320,-0.04893756907710228
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",9882865,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2019,340827,-0.0058296538973223
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",9746883,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'injured', 'innovation', 'learning strategy', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2019,824785,-0.011650706308087285
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9746721,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Infrastructure', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'classification algorithm', 'clinical practice', 'community involvement', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,334204,0.022735439011157092
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9750736,R01EB021396,"['3-Dimensional', 'Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'data pipeline', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'off-label use', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2019,434944,0.02629025542628561
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,9831425,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2019,409911,0.050451344757640446
"LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research PROJECT SUMMARY Imaging forms the backbone of living subjects research. Living subjects research is both essential to the progress of translational medicine and very expensive. The research community actively seeks to develop and validate new clinical endpoints to solve a range of etiology, natural history, diagnostic and prognostic problems. This project aims to develop and commercialize LATTICE, an Electronic Research Record, Image Management and Sharing Solution, and Deep Learning Platform. LATTICE is designed to increase the efficiency of imaging-driven biomedical research and clinical trials. This efficiency is accomplished first through a structured workflow that includes protocol management, subject scheduling, and records collection from multiple imaging modalities. Access to imaging and associated data within the same workflow simplifies the process for the research team. Structuring the data into a de-identified, privacy-managed Image Bank enables sharing for collaboration and re-use for retrospective research. Image processing algorithms connected to the Image Bank facilitate batch analysis, while the system also provides a platform for the development of new image-based outcome measures and clinical endpoints. A key objective of LATTICE is to enable investigators and collaborators to accelerate the translation of insights to the clinic with maximum efficiency. Successful translation requires structuring the workflow, record keeping, and protocols into a rigorous, transparent, reproducible and validated process. LATTICE is designed to reduce the friction in translating successful research projects to the clinic. Researchers in the Advanced Ocular Imaging Program (AOIP) at the Medical College of Wisconsin developed elements of LATTICE as separate technologies. The Specific Aims of this proposal are directed to an integrated workflow addressing a broader set of objectives. The AOIP LATTICE Electronic Research Record will be translated into a commercially managed repository and brought under regulatory Design Control. The current AOIP Image Bank containing 3,000,000 de- identified retinal images will be integrated into the LATTICE workflow. Critically, this integration will allow the sharing of the Image Bank with external researchers. Three retinal image process algorithms that operate on retinal images will integrate into this workflow. These algorithms include analysis of adaptive optics images of the fundus, analysis of the foveal avascular zone from optical coherence tomography angiography (OCTA), and model-based analysis of the fovea imaged with OCT. A computational deep learning workflow will also be prototyped using a cloud-based architecture. This final workflow will be constructed to demonstrate the feasibility of deploying a collaborative deep learning environment for the development of new clinical endpoints using shared, de-identified images. LATTICE will be a unique system for both prospective and retrospective translational research. LATTICE will make a profound impact on the cost of managing image-based research and add leverage to translational research expenditures for moving insights into the clinic. PROJECT NARRATIVE LATTICE is an innovative electronic research record and development platform for image-based ophthalmic research. LATTICE is designed to reduce the cost of translational research, promote the re- use of images, and simplify the development and application of new techniques to analyze medical images. LATTICE will integrate research workflow tools with a database of 3,000,000 retinal images and advanced image processing software to accelerate the process of translating eye research insights from the lab to the clinic.",LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research,9777970,R43EY030408,"['Address', 'Algorithmic Software', 'Algorithms', 'Angiography', 'Architecture', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnostic', 'Documentation', 'Elements', 'Etiology', 'Expenditure', 'Eye', 'Friction', 'Future', 'Health Insurance Portability and Accountability Act', 'Image', 'Libraries', 'Medical Imaging', 'Methods', 'Modeling', 'Morphology', 'Natural History', 'Optical Coherence Tomography', 'Outcome Measure', 'Output', 'Privacy', 'Process', 'Protocols documentation', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Scanning', 'Schedule', 'Secure', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Translational Research', 'Translations', 'Vertebral column', 'Wisconsin', 'Writing', 'adaptive optics', 'base', 'cloud based', 'cost', 'deep learning', 'design', 'educational atmosphere', 'fovea centralis', 'fundus imaging', 'image processing', 'imaging modality', 'imaging platform', 'imaging program', 'innovation', 'insight', 'medical schools', 'ocular imaging', 'operation', 'prognostic', 'programs', 'prospective', 'prototype', 'repository', 'retinal imaging', 'system architecture', 'tool', 'translational medicine', 'web services', 'wiki']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R43,2019,299999,0.048592023708428175
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9740493,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Augmented Reality', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Imagery', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Visual', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'tool', 'trend', 'virtual reality', 'web services']",NIBIB,"KITWARE, INC.",R01,2019,508446,0.021754047238243274
"Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research PROJECT SUMMARY/ABSTRACT This proposal represents a vertical advancement in neighborhood effects research, producing for the first time, national neighborhood indicators of the built environment. Thus far, only local studies have been conducted due to the resource-intensive nature of site visits to conduct assessments of community features and also manual annotations of street images. With the recent advancement of computer vision and the emergence of massive sources of image data, we will leverage our team’s abilities to develop a data collection strategy utilizing geographic information systems to assemble a national collection of Google Street View images of all road intersections and street segments in the United States. We will utilize this data bank, and develop informatics algorithms to produce neighborhood summaries of built environment that have been theoretically and empirically identified to be important for health outcomes. After the creation of Neighborhood Looking Glass, we will conduct investigations into the impact of neighborhood environments on health utilizing medical records from hundreds of thousands of patients and accounting for predisposing characteristics in analyses. Our investigative team—comprised of experts in the field of epidemiology, computer vision, bioinformatics, and computer science—is uniquely suited to implement the study aims. Our Specific Aims are: 1) Develop informatics techniques to produce neighborhood quality indicators; 2) Measure the accuracy of data algorithms and construct an interactive geoportal for neighborhood data visualization and data sharing, 3) Utilize Neighborhood Looking Glass and a large collection of medical records from Intermountain Healthcare to investigate neighborhood influences on the risk of obesity and substance abuse. The epidemic rise in chronic health conditions is recent and as such suggests its cause is social, cultural, and constructed rather than purely biological. Thus, we have the possibility of intervening on the environment to better support health. Recent studies suggest that the current cohort of young adults may face historically high cardiovascular disease risk and chronic disease burden. Our substantive investigation of the impact of neighborhood factors on chronic conditions will contribute further to the understanding of contextual influences on the health of this cohort at the forefront of a chronic disease epidemic. Moreover, the dramatic rise in overdoses, accidental poisonings, and mental health issues contributing to premature mortality warrants further investigation into risk-inducing environmental factors for substance abuse. Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics. Results can be utilized to inform population-based strategies to reduce health disparities and improve health. Project Narrative/Relevance to Public Health The epidemic rise in obesity, related chronic diseases, and substance abuse in recent decades signal the importance of structural forces and social processes, but the dearth of data on contextual factors limits the investigation of multilevel effects on health. The development of the Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics with potential impact on health. Results from our project can be utilized to inform system-wide and local strategies to improve community health.",Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research,9756470,R01LM012849,"['Accounting', 'Alcohol or Other Drugs use', 'Algorithms', 'Bioinformatics', 'Biological', 'Characteristics', 'Chronic', 'Chronic Disease', 'Cities', 'Collection', 'Communities', 'Community Health', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Collection', 'Data Sources', 'Development', 'Disease', 'Environment', 'Environmental Risk Factor', 'Epidemic', 'Epidemiology', 'Face', 'Family', 'Food', 'Food Access', 'Geographic Information Systems', 'Geography', 'Glass', 'Grant', 'Happiness', 'Health', 'Health Food', 'Health Personnel', 'Health behavior', 'Health care facility', 'Healthcare', 'Image', 'Individual', 'Informatics', 'Investigation', 'Label', 'Literature', 'Manuals', 'Measures', 'Medical Records', 'Mental Health', 'Methods', 'Nature', 'Neighborhoods', 'Obesity', 'Outcome', 'Overdose', 'Patients', 'Physical activity', 'Physical environment', 'Premature Mortality', 'Process', 'Public Health', 'Quality Indicator', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Signal Transduction', 'Site Visit', 'Social Environment', 'Social Processes', 'Source', 'Structure', 'Substance abuse problem', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Visit', 'built environment', 'burden of illness', 'cardiovascular disorder risk', 'cohort', 'computer science', 'contextual factors', 'convolutional neural network', 'cost', 'crowdsourcing', 'data management', 'data mining', 'data resource', 'data sharing', 'data visualization', 'data warehouse', 'density', 'health care availability', 'health disparity', 'improved', 'land use', 'obesity risk', 'object recognition', 'physical conditioning', 'population based', 'social', 'social media', 'walkability', 'young adult']",NLM,"UNIV OF MARYLAND, COLLEGE PARK",R01,2019,329730,-0.0032337990579137848
"Towards a Compositional Generative Model of Human Vision Understanding object recognition has long been a central problem in vision science, because of its applied utility and computational difficulty. Progress has been slow, because of an inability to process complex natural images, where the largest challenges arise. Recently, advances in Deep Convolutional Neural Networks (DCNNs) spurred unprecedented success in natural image recognition. The general goal of this proposal is to leverage this success to test computational theories of human object recognition in natural images. However, DCNNs still markedly underperform humans when challenged with high levels of ambiguity, occlusion, and articulation. We hypothesize that humans' superior performance arises from the use of knowledge about how images and objects are structured. Preliminary evidence for this claim comes from the success of hybrid models, that combine DCNNS for identifying features and parts in images, with explicit knowledge of object and image structure. These computations occur within a hierarchy, which includes both top-down and bottom- up processing. The specific goal of the work proposed here is to strongly test whether these computational strategies, structured, hierarchical representations and bidirectional processing, are used to recognize objects in natural images. Human bodies are composed of hierarchically organized configurable parts, making them an ideal test domain. We examine the complete recognition process, from parts, to pairs of parts, to whole bodies, each in its own aim. Each aim also tests important sub-hypotheses about when and how the computational strategies are used. Aim 1 examines recognition of individual body parts, testing whether it is dependent on parsing images into more basic features and relationships, for example edges and materials. Aim 2 examines pairs of parts, testing the importance of knowledge of body connectedness relationships. Aim 3 examines perception of entire bodies, testing whether knowledge of global body structure guides bidirectional processing. In each aim, we first develop nested computer vision models that either do or do not make use of structural knowledge, to test whether it aids recognition. We then test whether human performance can be accounted for by the availability of that structural knowledge. We next measure neural activity with functional MRI to identify where and how it is used in cortex. Finally, we integrate these results to produce even stronger tests, using the nested models to predict human performance and confusion matrices as well as fMRI activity levels and confusion matrices. Altogether, this work will strongly test key theoretical accounts of object recognition in the most important domain, perception of natural images. The work, based on extensive preliminary data, measures and models the entire body recognition system. The models developed and tested here should surpass the state-of-the-art, and be useful for many real-world recognition tasks. The proposal will also lay the groundwork for future studies of recognition impaired by disease. This research uses computational, behavioral, and brain imaging methods to investigate how the visual system represents and processes information about human bodies. The studies will reveal how and when people can accurately recognize objects in natural images, how the brain supports this function, and how loss of information, similar to that that accompanies visual disease, may affect the ability to interpret everyday scenes.",Towards a Compositional Generative Model of Human Vision,9818274,R01EY029700,"['Affect', 'Area', 'Articulation', 'Behavioral', 'Body Image', 'Body part', 'Brain', 'Brain imaging', 'Complex', 'Computer Vision Systems', 'Confusion', 'Cues', 'Data', 'Development', 'Disease', 'Elbow', 'Feedback', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Human body', 'Hybrids', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Link', 'Measures', 'Modeling', 'Perception', 'Performance', 'Predictive Value', 'Process', 'Psychophysics', 'Published Comment', 'Research', 'Structure', 'System', 'Testing', 'Training', 'Vision', 'Visual', 'Visual system structure', 'Work', 'Wrist', 'base', 'convolutional neural network', 'crowdsourcing', 'human model', 'imaging modality', 'improved', 'object recognition', 'relating to nervous system', 'spatial relationship', 'success', 'theories', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2019,352996,0.02033838584768834
"Automated Diagnosis and Progression Rate of IPF Using HRCT Project Summary: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. Diagnosis and stratification of disease phenotypes are important in order to decipher the effects of novel therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individuals. Few computerized diagnostic tools have been developed for IPF that correlate with visual and surgical lung biopsy; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good predictive models with localized region exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use as a derivative dataset the anonymized clinical data and source images on 234 patients with IPF and 266 patients with IPF suspected, but not IPF based on HRCT and the surgical biopsy who have participated in multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for high through-put quantitative image analysis, we will train a classifier with features of anatomic distribution and reproducible imaging features expressed with a quantitative lung fibrosis (QLF) score, testing on separate data from in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitial Lung Disease Program. Furthermore, the second aim is to develop a rate of progression at local region and to aggregate predictive models using Cox proportional regression models, which will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that diagnose and anticipate disease course in patients with IPF and subdividing patients into more homogeneous groups prior to the development of significant respiratory impairment. We anticipate that models can be used clinically at the individual patient level to enable more informed and timely management decisions to define more homogeneous cohorts for purposes of testing new targeted therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. Relevance to Public Health: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rate of progression is highly variables, which hampers timely decisions about referral for lung transplantation or treatments using new drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to diagnose and predict disease course robustly in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with IPF and non-IPF with reducing chance of lung biopsy and predict slowly versus rapidly progressive disease, leading to more time to treat patients and timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Automated Diagnosis and Progression Rate of IPF Using HRCT,9765383,R21HL140465,"['Acute', 'Air', 'Algorithms', 'Anatomy', 'Archives', 'Automation', 'Biological', 'Biopsy', 'Categories', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease stratification', 'Elderly', 'Etiology', 'Exhibits', 'General Population', 'Glass', 'Goals', 'Growth', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Informatics', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Laboratories', 'Lobar', 'Lobe', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathology', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Prevalence', 'Probability', 'Progression-Free Survivals', 'Progressive Disease', 'Public Health', 'Pulmonary Fibrosis', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Spatial Distribution', 'Stable Disease', 'Standardization', 'Testing', 'Texture', 'Time', 'Time Management', 'Training', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinically relevant', 'cohort', 'computerized', 'data archive', 'digital imaging', 'disease natural history', 'disease phenotype', 'functional decline', 'idiopathic pulmonary fibrosis', 'image processing', 'imaging biomarker', 'improved', 'individual patient', 'individualized medicine', 'new therapeutic target', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'success', 'survival prediction', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2019,113241,-0.019804777222178886
"STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients Project Summary/Abstract Lung cancer is the leading cause of cancer death and one of the most common cancers among both men and women in the United States. Recent advances in high-resolution imaging set the stage for radiomics to become an active emerging field in cancer research. However, the promise of radiomics is limited by a lack of image standardization tools, because computed tomography (CT) images are often acquired using scanners from different vendors with customized acquisition parameters, posing a fundamental challenge to radiomic studies across sites. To overcome this challenge, especially for large-scale, multi-site radiomic studies, advanced algorithms are required to integrate, standardize, and normalize CT images from multiple sources. We propose to develop STAN-CT, a deep learning software package that can automatically standardize and normalize a large volume of diagnostic images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification. By precisely mitigating the differences in advanced radiomic features of CT images, STAN-CT will overcome research silos and promote medical image resource sharing, ultimately improving the diagnosis and treatment of lung cancer. Our goal will be achieved through two Aims. In Aim 1, we will develop a working prototype to standardize CT images. First, we will collect raw image data from lung cancer patients and reconstruct CT images using multiple image reconstruction parameters, and we will scan a multipurpose chest phantom along with five different nodule inserts. Then, we will develop and train STAN-CT for CT image standardization. An alternative training architecture will be developed to achieve the improved model training stability. In Aim 2. We will deploy and test STAN-CT for image standardization locally and across three medical centers. First, we will make the STAN-CT software package available to the public by providing a menu-driven web-interface so that that users can conveniently convert medical images that were taken using non-standard protocols to one or multiple standards that they specify. Second, we will deploy STAN-CT at the University of Kentucky for local performance validation. We will test the functionality, reliability, and performance of STAN-CT using both patient chest CT image data collected at large-scale and the phantom image data, both independent to training. Third, we will deploy and test STAN-CT at the University of Kentucky as well as the University of Texas Southwestern Medical Center and Emory University for cross- center performance validation. We will use the same multipurpose chest phantom and both standard and non- standard protocols to validate STAN-CT at the three centers. We will test the generalizability of STAN-CT using clinical CT images of human patients and will determine whether a model trained using the data from one medical center are applicable for images collected at another place. Finally, we will distribute the software package of STAN-CT for public use. STAN-CT will enable a wide range of radiomic researches to identify diagnostic image features that strongly associated with lung cancer prognosis. Project Narrative Computed tomography (CT) is one of the most popular diagnostic image modalities routinely used for assessing anatomical tissue characteristics for disease management. However, CT images are often acquired using scanners from different vendors with different imaging standards, posing a fundamental challenge to radiomic studies across sites. The goal of the Standardization and Normalization of CT images for lung cancer patients (STAN-CT) project is to develop a deep learning software package that can automatically standardize and normalize a large volume of chest CT images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification.",STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients,9827910,R21CA231911,"['Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Cancer Etiology', 'Cancer Patient', 'Cancer Prognosis', 'Cessation of life', 'Characteristics', 'Chest', 'Clinical', 'Communities', 'Computer software', 'Custom', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Disease Management', 'Evolution', 'Faculty', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Kentucky', 'Life', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical Imaging', 'Medical center', 'Modeling', 'Multi-Institutional Clinical Trial', 'Names', 'Nodule', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Protocols documentation', 'Quality Control', 'Radiology Specialty', 'Research', 'Resource Sharing', 'Scanning', 'Site', 'Source', 'Specific qualifier value', 'Standardization', 'Stratification', 'Survival Rate', 'System', 'Testing', 'Texas', 'Tissues', 'Tomography, Computed, Scanners', 'Training', 'United States', 'Universities', 'Validation', 'Vendor', 'Woman', 'X-Ray Computed Tomography', 'anticancer research', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'chest computed tomography', 'computational platform', 'data to knowledge', 'deep learning', 'high resolution imaging', 'human imaging', 'image reconstruction', 'imaging modality', 'improved', 'lung imaging', 'member', 'men', 'outcome forecast', 'prototype', 'quantitative imaging', 'radiomics', 'response', 'spatial temporal variation', 'tool', 'trait', 'tumor', 'web interface']",NCI,UNIVERSITY OF KENTUCKY,R21,2019,213271,-0.06309003561022257
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,9886087,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Quality', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Drug effect disorder', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'deep learning', 'denoising', 'detector', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,344862,-0.005466355151722973
"Medical Image Perception Society XVIII Conference MIPS XVIII brings together an international community of experts including radiologists, pathologists, other image-based clinicians, psychologists, statisticians, physicists, engineers, and computer scientists investigating the extraction of diagnostic information from medical images. The meeting forges research and learning opportunities for new students and young researchers in a dedicated forum unmatched by other meetings. MIPS XVIII is being organized by the Medical Image Perception Society (a US-based society; Elizabeth Krupinski, PhD President) in conjunction with local hosts Trafton Drew, PhD (University of Utah Psychology) and William Auffermann, MD, PhD (University of Utah Radiology); and committee Lauren Williams (University of Utah) trainee member, David Alonso trainee member (University of Utah). It will run July 14-17, 2019 at the University of Utah Guest House & Conference Center located near the University of Utah campus. Nine topic areas have been selected for MIPS XVIII, reflecting important dimensions of medical image interpretation. This year’s special focus theme is addressing other image-based specialties outside radiology. Studying how clinicians extract diagnostic information from images identifies the causes of missed diagnoses and ways to eliminate these errors. Careful design and evaluation of imaging systems are critical in view of their enormous costs. With the current emphasis in the practice of medicine on “meaningful use” and “accountable care” to improve the quality, safety, and efficiency of care, the role the clinician as decision-maker cannot be ignored. Medical image perception research develops and applies modern methods to the evaluation of observer performance in diagnostic imaging tasks. Understanding basic aspects of the perception of medical images can reduce diagnostic error and improve medical decision-making quality. This grant will support 10 students to attend and present their research at MIPS XVIII. To date, 115 students have been awarded scholarships. The primary goal in supporting these students is to create opportunities and offer supportive mentoring at this formative stage in the trainee’s career to enhance their research potential and likelihood of success. The meeting brings together researchers investigating the process of extracting diagnostic information from medical images to render accurate and efficient diagnostic decisions. Opportunities for advanced, interdisciplinary training of young scientists interested in medical image perception research and its relevance to disease prevention and treatment are often quite limited at the university level. Since 1997, 115 students have been awarded MIPS scholarships, having a significant impact on the field by creating opportunities and offering supportive mentoring at this formative stage in the trainee’s career to enhance their research potential and likelihood of success as independent basic science and clinician-scientist researchers.",Medical Image Perception Society XVIII Conference,9833051,R13EB028683,"['3-Dimensional', 'Acquired Immunodeficiency Syndrome', 'Address', 'American', 'Area', 'Attention', 'Award', 'Basic Science', 'Behavior', 'Caring', 'Clinical', 'Clinical Trials', 'Cognition', 'Cognitive', 'Color', 'Communities', 'Computers', 'Data Set', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Diagnostic radiologic examination', 'Dimensions', 'Discrimination', 'Doctor of Philosophy', 'Engineering', 'Evaluation', 'Failure', 'Fatigue', 'Frequencies', 'Goals', 'Grant', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institute of Medicine (U.S.)', 'International', 'Judgment', 'Knowledge', 'Lead', 'Learning', 'Malpractice', 'Medical', 'Medical Errors', 'Medical Imaging', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Modern Medicine', 'Modernization', 'Ophthalmology', 'Pathologist', 'Patients', 'Pattern', 'Perception', 'Performance', 'Physician&apos', 's Role', 'Physicians', 'Population', 'Prevention', 'Process', 'Psychologist', 'Psychology', 'Psychophysics', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Running', 'Safety', 'Scholarship', 'Scientist', 'Societies', 'Students', 'Technology', 'Telemedicine', 'Training', 'United States National Institutes of Health', 'Universities', 'Utah', 'Work', 'automobile accident', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'design', 'disorder prevention', 'health care quality', 'image processing', 'imaging system', 'improved', 'interest', 'malignant breast neoplasm', 'medical specialties', 'meetings', 'member', 'outcome forecast', 'prognostic', 'radiologist', 'statistics', 'success', 'symposium', 'whole slide imaging']",NIBIB,EMORY UNIVERSITY,R13,2019,10000,0.018024123280724814
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9784742,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data pipeline', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2019,533529,0.03709118320056418
"UC Davis Alzheimer's Core Center PROJECT SUMMARY/ABSTRACT As reflected in recent budget increases in the National Institutes of Health, and in line with the National Alzheimer’s Project Act, there is a need to enhance and leverage resources to decrease dementia disparities and change the trajectory of Alzheimer’s disease and related dementias. To fill this gap, we seek to enhance the University of California Davis Alzheimer’s Disease Center (UCD ADC), which contains a diverse ethnoracial cohort (having Hispanic, Black, and non-Hispanic White decedents), through implementation of digital pathology within our Neuropathology Core. This implementation will allow for rapid transmission of pathological data for consultation and collaborations, distribution of materials for educational purposes, tissue specimen archiving, and image analysis. In addition, by having a digital pathology with immunofluorescent capabilities will allow for viewing of the distribution (including overlap) of multiple proteins at one time within a tissue specimen. This can enhance biological studies by providing spatial relationships of proteins resulting in a deeper phenotype of disease. This supplement application is designed to support equipment and leverage and enhance infrastructure to allow the UCD ADC the ability to 1) purchase a whole slide image system to digitize existing and future histologically stained samples 2) leverage and enhance current servers and database systems to allow for storage and rapid retrieval of digital images and their data and 3) leverage and enhance hardware to develop and deploy pipelines for quantitative computational methodologies for pathologies found within a diverse ethnoracial cohort of Alzheimer’s disease brains. The UCD ADC continues to excel and expand in its research initiatives to collect and provide brain specimens and pathological data on a diverse population of individuals at various stages of cognitive ability and dementia risk. This supplement will further enable suitable infrastructure for enhancement of current collaborations and facilitate emerging collaborations by providing a means to share and analysis pathology on digitized whole slide images. PROJECT NARRATIVE Digital microscopy paired with machine learning algorithms has aided in diagnosis and provide more quantitative pathology data to unlock the secrets of diseases. These technologies are needed within the dementia field, specifically in diverse cohorts, as disease presentations may differ. By implementing state of the art imaging systems and analysis, the goals of this supplement are to enhance the ADC’s ability to provide greater access to high quality pathological data for educational, consultation and collaborative purposes, infrastructure to pursue digital solutions for more quantitative analysis, and safe secure storage of histologic specimens.",UC Davis Alzheimer's Core Center,9852188,P30AG010129,"['Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Archives', 'Autopsy', 'Back', 'Basic Science', 'Biological', 'Brain', 'Brain Diseases', 'Budgets', 'California', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Consultations', 'Data', 'Database Management Systems', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Educational Materials', 'Equipment', 'Extramural Activities', 'Future', 'Generations', 'Genetic', 'Genetic Variation', 'Glass', 'Glean', 'Goals', 'Grant', 'Heterogeneity', 'Hispanics', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Individual', 'Infrastructure', 'Infusion procedures', 'Knowledge', 'Measurement', 'Measures', 'Medical Genetics', 'Methods', 'Microscope', 'Microscopy', 'Modernization', 'Neurodegenerative Disorders', 'Not Hispanic or Latino', 'Outcome', 'Paper', 'Pathologic', 'Pathologist', 'Pathology', 'Phenotype', 'Population Heterogeneity', 'Proteins', 'Publishing', 'Research', 'Research Infrastructure', 'Resources', 'Retrieval', 'Sampling', 'Scientist', 'Secure', 'Senile Plaques', 'Slide', 'Specimen', 'Stains', 'Structure', 'Systems Analysis', 'Technology', 'Thioflavin S', 'Time', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Work', 'analysis pipeline', 'base', 'beta pleated sheet', 'cognitive ability', 'cohort', 'cost effective', 'data resource', 'data sharing', 'dementia risk', 'design', 'digital', 'digital imaging', 'digital pathology', 'disease phenotype', 'histological specimens', 'histological stains', 'human tissue', 'imaging system', 'machine learning algorithm', 'neuropathology', 'novel therapeutic intervention', 'spatial relationship', 'synergism', 'transmission process', 'whole slide imaging']",NIA,UNIVERSITY OF CALIFORNIA AT DAVIS,P30,2019,289154,-0.032104244364197315
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9600285,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biological Neural Networks', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2018,194115,0.039918252658145456
"Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery Abstract  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques to quantitative image analysis and image reconstruction. There are 12 specific NIH projects that will benefit from the proposed computing infrastructure system. We present the 12 projects through examples from within four Specific Research Topics areas: (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The proposed system is a computing cluster, which uses ScaleMP's Versatile SMP software to aggregate the cluster nodes into a single symmetric multiprocessing computer. The major hardware components consist of 1 HP Enterpris\e ProLiant DL380 server and 8 Apollo 6500 compute nodes, with a total of 2.1 TB of main memory, 18 Intel Xeon E5-2640v4 10-core CPUs, and 32 nVidia Tesla P100 GPUs. The servers will be connected via a 100Gbps EDR Infiniband network. In addition, three important software components, which aim to reduce the complexity of the computing environment and increase researcher productivity, will be integrated into the hardware components: the aforementioned ScaleMP vSMP to create a single virtual computer from the cluster nodes, Cendio ThinLinc to provide remote desktop graphical login services, and Bitfusion Flex AI Platform which provides GPU virtualization, scheduling, and optimization, as well as curated container deployment of common deep learning frameworks. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many-dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA- compliant sharable environment. Project Narrative  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques within four Specific Research Topics areas of (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many- dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA-compliant sharable environment.",Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery,9494294,S10OD025081,"['Algorithmic Analysis', 'Algorithms', 'Area', 'Characteristics', 'Complex', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Development', 'Dimensions', 'Environment', 'Funding', 'Health Insurance Portability and Accountability Act', 'High Performance Computing', 'Image', 'Image Analysis', 'Machine Learning', 'Medical Imaging', 'Memory', 'Productivity', 'Protocols documentation', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Schedule', 'Secure', 'Services', 'System', 'Techniques', 'Translating', 'United States National Institutes of Health', 'biological systems', 'cluster computing', 'computer cluster', 'deep learning', 'genomic data', 'image reconstruction', 'imaging system', 'phenotypic data', 'quantitative imaging', 'radiomics', 'reconstruction', 'tomography', 'tumor', 'virtual']",OD,UNIVERSITY OF CHICAGO,S10,2018,338913,0.03524528465187894
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9580704,R01EB026708,"['Abdomen', 'Air', 'Algorithms', 'Area', 'Biological Neural Networks', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2018,460690,-0.018028679357121973
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9754513,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,30000,-0.04923299259721901
"Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9466642,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,217746,-0.05314808323499061
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9523267,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2018,385011,0.005790158429226098
"Deep learning-based image analysis for assessing real-time smoking risk ABSTRACT Whereas the majority of smokers will quit in any given year, the majority of quit attempts result in relapse. One reason interventions may fail is that they teach smokers strategies for coping with craving in response to environmental triggers, but do not provide smokers with just-in-time information about their risk of smoking lapse. Such risk information could be used to alert smokers to engage in relevant coping strategies including avoidance or use of quick acting pharmacotherapies (e.g. nicotine inhaler). The overarching premise of the proposed research is that prediction of lapse risk can be enhanced by using computer vision to analyze images of everyday life. Recent findings by our team suggest that environments associated with lapse risk can be detected in real-time by coupling deep learning-based object detection with an appropriate classification model. In preliminary research, images taken by smokers of smoking and nonsmoking environments (80 subjects, 2870 images) were used to train such a model, resulting in 77.5% accuracy (0.826 AUC) distinguishing these environments on a separate test set (16 subjects, 516 images). Encouraged by this preliminary finding, we propose to refine and scale up this system by a) creating a larger and more representative image database that includes a sample of everyday environments acquired from smokers (n=60) and b) testing novel, personalized approaches for increasing smoking environment classification accuracy and assessing smoking risk across three aims. In Aim 1, we will improve smoking environment classification accuracy and prediction of smoking risk by re-training an existing deep learning model to recognize a broad set of smoking-related objects (e.g. packs of cigarettes/ashtrays). In Aim 2, we will further improve performance by fitting personalized models that account for individual differences in preferred or typical smoking environments. In Exploratory Aim 3, we will predict craving and negative affect/stress using a similar approach. The proposed research represents an innovative and critical next step in the development of a system that identifies smoking risk and/or its antecedents in real-time to support a just-in-time adaptive intervention for smoking cessation. PUBLIC HEALTH RELEVANCE: The majority of smokers relapse within one month of quitting smoking. Environments (e.g. park) and their related objects (e.g. park bench) are associated with smoking and urges to smoke and can serve as triggers to lapse and relapse. The proposed research will use state-of-the-art computer vision and object detection to identify smoking risk environments and objects with the goal of eventually developing systems that alert smokers to such risks from everyday images acquired with cameras worn by smokers. Such a system can be incorporated into more comprehensive and effective smoking cessation programs.",Deep learning-based image analysis for assessing real-time smoking risk,9617141,R21DA047131,"['Adult', 'Behavior', 'Biological Neural Networks', 'Cigarette', 'Classification', 'Clinical', 'Computer Vision Systems', 'Coupled', 'Coupling', 'Data', 'Databases', 'Detection', 'Development', 'E-learning', 'Environment', 'Event', 'Frequencies', 'Goals', 'Image', 'Image Analysis', 'Individual Differences', 'Intervention', 'Knowledge', 'Life', 'Location', 'Methods', 'Modeling', 'Neural Network Simulation', 'Nicotine Inhaler', 'Patient Self-Report', 'Performance', 'Pharmacotherapy', 'Phase', 'Real-Time Systems', 'Relapse', 'Research', 'Risk', 'Risk Assessment', 'Sampling', 'Shelter facility', 'Smoke', 'Smoker', 'Smoking', 'Smoking Cessation Intervention', 'Source', 'Stress', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Work', 'base', 'clinically relevant', 'coping', 'craving', 'deep learning', 'high risk', 'improved', 'innovation', 'longitudinal dataset', 'negative affect', 'non-smoking', 'novel', 'personalized approach', 'programs', 'public health relevance', 'response', 'scale up', 'smartphone Application', 'smoking cessation', 'time use']",NIDA,DUKE UNIVERSITY,R21,2018,200208,0.002649934818478131
"Extracting rich information from biological images Project Summary  Most laboratories studying biological processes and human disease use microscopes to image samples. Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.  The principal investigator envisions bringing transformative image analysis and machine learning algorithms and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in 3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­ scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image analysis into complex workflows with other software for microscope control, cloud computing, and data mining.  The PI will also pioneer novel algorithms and approaches changing the way images are used in biology, including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines. Public Health Relevance/Narrative Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering computational techniques and software that will change the way microscopy images are used in biology. Biologists will use the resulting software to tackle fundamentally new problems using quantitative image analysis, including detecting changes in the appearance of cells that are overlooked by human vision and studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the context of dozens of projects addressing important fundamental biological questions and world health problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source image analysis software, CellProfiler.",Extracting rich information from biological images,9708392,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,128747,0.07912272993366372
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9474630,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,695400,0.07452829812736321
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9422606,R01EB008374,"['4D Imaging', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Pharmacology', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'clinical diagnostics', 'clinical predictors', 'computerized tools', 'deep learning', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'predictive modeling', 'public health relevance', 'serial imaging', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,451650,-0.009563303019638108
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9518217,R01HL142036,"['Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Simulation', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2018,392932,-0.003698260269388962
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9592472,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Topical Corticosteroids', 'Translating', 'Transplantation', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2018,240000,0.044088994059887726
"Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy Project Summary We propose to introduce and optimize a new method of radiomics extraction via transfer learning with deep convolutional neural networks (CNNs) and to compare it to the conventional segmentation-based radiomics approach on breast dynamic contrast-enhanced magnetic resonance images (DCE-MRIs). The field of breast radiomics has been expanding fast, with many clinical conclusions being successfully derived from medical images using qualitative analysis. In the past couple of years, deep learning has experienced explosive growth in image recognition, easily solving complex problems. Deep CNNs achieve remarkable classification results on everyday image datasets. We propose to investigate the utility of deep neural networks with regards to the medical image datasets, specifically on the breast DCE-MRI dataset. Given the relatively small sizes of these datasets, CNNs previously trained on non-medical images will be utilized for clinical classifications as feature extractors. We will investigate multiple parameters involved in the CNN feature extraction methodology and their effect on classification performance. Two clinical tasks will be studied under the proposed research: 1) malignancy assessment and 2) response to therapy prediction. The optimized CNN method will be compared to and combined with the conventional segmentation- based radiomics method. Furthermore, we aim to investigate the robustness of the segmentation-based features across MR scanners of different manufacturers. The first aim of the proposed research will study the robustness of the segmentation- based features extracted from images acquired on MR scanners of two different manufacturers. The robustness will be investigated under four clinical tasks, such as lymph node involvement and receptor statuses. The second aim will be focused on optimization of CNN feature extraction and subsequent classifier design. Lastly, under the third aim we will compare and combine the CNN and segmentation-based radiomics in the classification tasks of malignancy assessment and response to therapy prediction. Project Narrative The goal of the proposed research is to improve breast cancer diagnosis and prognosis based on dynamic contrast-enhanced magnetic resonance images by introducing novel deep learning methods to medical image classification and combining it with the conventional radiomics systems. The incredible power of deep learning methods to classify everyday images shows great promise to make predictions based on medical image datasets. Our thorough investigation of deep learning methods and their combination with conventional radiomics methods has potential to improve breast cancer management.",Quantitative MRI Radiomics of Breast Cancer in Assessment of Malignancy and Response to Therapy,9469826,F31CA221193,"['Benign', 'Biological Neural Networks', 'Breast', 'Cancer Prognosis', 'Characteristics', 'Classification', 'Clinical', 'Complement', 'Complex', 'Computers', 'Data', 'Data Set', 'Effectiveness', 'Evaluation', 'Goals', 'Growth', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intuition', 'Investigation', 'Lesion', 'Lymph Node Involvement', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical Imaging', 'Methodology', 'Methods', 'Nature', 'Neoadjuvant Therapy', 'Performance', 'Prediction of Response to Therapy', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Research', 'Standardization', 'System', 'Techniques', 'Training', 'Variant', 'base', 'breast cancer diagnosis', 'chemotherapy', 'computerized', 'contrast enhanced', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'learning strategy', 'malignant breast neoplasm', 'novel', 'radiomics', 'receptor', 'response']",NCI,UNIVERSITY OF CHICAGO,F31,2018,26048,-0.05607301247429532
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. Narrative There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9680657,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'professional atmosphere', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2018,449918,0.04669315369588429
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9496652,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Decubitus ulcer', 'Diabetic Foot Ulcer', 'Diabetic wound', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2018,425994,0.03550680899724636
"Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology ABSTRACT Acute infections of the middle ear (acute otitis media - AOM), are the most commonly treated childhood disease. Treatment is fueled by concern for complications and effects on children's cognitive and language development. The financial burden of AOM is estimated at more than $5 billion per year. Because AOM is so common, a major societal problem is the over-diagnosis and over-treatment of this disease, as a result of two factors: First, accurately diagnosing AOM is difficult, even for experienced primary care or ear, nose, and throat (ENT) physicians. Second, with a growing shortage of primary care physicians in the US, more Nurse Practitioners and Physician Assistants serve as first-line clinicians in primary care settings, but lack extensive training in otoscopy (i.e. clinical examination of the eardrum). Consequently, practitioners often err on the side of making a diagnosis of AOM and prescribing oral antibiotics. Over 8 million unnecessary antibiotics are prescribed annually, contributing to the rise of antibiotic-resistant bacteria, and creating the largest number of pediatric medication-related adverse events. Many children with inaccurate diagnoses of AOM are referred to ENTs for surgical placement of ear tubes, and up to 70% of these cases are not indicated. Diagnosing AOM still depends on clinician subjectivity, based on a brief glimpse of the eardrum. This diagnostic subjectivity creates a critical barrier to progress in society's goal of decreasing healthcare costs and reducing over-diagnosis and over-treatment of AOM. According to the American Academy of Pediatrics in 2013, devices are needed to assist in more accurate, consistent, and objective diagnosis of AOM. A simple and objective method of analyzing an image of a patient's ear to diagnose or rule out AOM would drastically reduce over-treatment. This project will fill that gap, by developing computer-assisted image analysis (CAIA) software that provides objective information to a clinician by analyzing eardrum images collected using currently available hardware. Based on previous work in applying similar methods to improve clinician performance in radiology and surgical pathology, our overarching hypothesis is that the incremental implementation of enhanced images, automated identification of abnormalities, and retrieval of similar cases will result in improved clinician diagnostic accuracy. In our preliminary work, we developed software, called Auto-Scope, which labels eardrums as “normal” versus “abnormal.” In this study, we propose two Specific Aims to improve diagnostic performance: Specific Aim #1: Create an enhanced composite image of the eardrum. Specific Aim #2: Use machine learning approaches for clinical decision support. The proposed research is relevant to public health because we are generating new methods aimed at improving diagnostic quality and reducing inter-observer variability, which will ultimately enable more accurate diagnosis and personalized therapeutic approaches for ear abnormalities. Thus, the proposed research is relevant to NIH's mission pertaining to the application of novel strategies that may improve human health, and NIDCD's mission of improving diagnosis and treatment of ear diseases, particularly otitis media.",Auto-Scope Software-Automated Otoscopy to Diagnose Ear Pathology,9669491,R21DC016972,"['Academy', 'Acute', 'Address', 'Adverse event', 'Affect', 'Algorithms', 'American', 'Antibiotics', 'Appearance', 'Awareness', 'Bacterial Antibiotic Resistance', 'Child', 'Childhood', 'Cholesteatoma', 'Clinic', 'Clinical', 'Clip', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cyst', 'Databases', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Ear Diseases', 'Goals', 'Guidelines', 'Hair', 'Hand', 'Health', 'Health Care Costs', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Interobserver Variability', 'Label', 'Language Delays', 'Language Development', 'Lighting', 'Liquid substance', 'Machine Learning', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nose', 'Nurse Practitioners', 'Operative Surgical Procedures', 'Oral', 'Otitis Media', 'Otitis Media with Effusion', 'Otolaryngologist', 'Otoscopes', 'Otoscopy', 'Pathology', 'Patients', 'Pediatrics', 'Perforation', 'Performance', 'Pharmaceutical Preparations', 'Pharyngeal structure', 'Physician Assistants', 'Physicians', 'Primary Care Physician', 'Primary Health Care', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resolution', 'Retrieval', 'Side', 'Skin', 'Societies', 'Surgical Pathology', 'System', 'Testing', 'Training', 'Tube', 'Tympanic membrane', 'United States National Institutes of Health', 'Waxes', 'Work', 'accurate diagnosis', 'acute infection', 'base', 'clinical decision support', 'cognitive development', 'computerized', 'diagnostic accuracy', 'digital imaging', 'digital video recording', 'effusion', 'experience', 'hearing impairment', 'improved', 'middle ear', 'novel', 'novel strategies', 'overtreatment', 'personalized therapeutic', 'primary care setting', 'prototype', 'software development']",NIDCD,OHIO STATE UNIVERSITY,R21,2018,252169,0.015651988803369658
"2018 Image Science Gordon Research Conference & Gordon Research Seminar Project Summary: The proposal requests support for early-career investigators to attend the 2018 Gordon Research Conference on Image Science. The unique feature of this conference in its third offering compared with others in medical imaging is the bringing together of renown speakers from disparate application areas, including astronomy, biology, medicine, remote sensing, and security and defense industries, in a forum that encourages each to describe their greatest challenges and most promising solutions. All speakers are invited based on their leadership in their field and their willingness to debate fundamental issues shared by everyone developing, evaluating, and applying imaging in medicine and biology. We believe the GRC format placed in the context of a small-college venue promotes the type of innovative interdisciplinary thinking that leads to breakthroughs. An environment where leading senior scientists debate core issues is valuable to young investigators trying to build successful independent careers in medical imaging in industry and academia. All attendees are invited to present a poster describing their research in poster sessions that are a key element of the Gordon Conference format. The June 17-22, 2018 GRC conference theme is “Image Science: Creating Knowledge from Information,” which is focused on appropriate acquisition and efficient uses of the massive volume of imaging information now collected from patients. Speakers give 40 minutes presentations in a single-track format with 20 minute discussions following each presentation that are led by experts in the field. Topic range from “Imaging in Brain Science Discovery” to “Advanced Machine Learning” and “Computational Imaging.” At the center of each presentation is a discussion of the core challenges shared by image scientists and novel techniques for acquiring and displaying information in a manner that maximizes decision performance. Given the success of the previous meeting, we will hold the first-ever, student-run Gordon Research Seminars (GRS) on Image Science June 16, 17, 2018. Our aim is to build Image Science as an independent field of study through detailed interdisciplinary discussions and by fostering the success of a new generation of image scientists. Project Narrative: Solutions to very difficult problems often emerge from discussions among experts in different fields of study being challenged by the same core problems. The 2018 GRC on Imaging Science strives to build a community of problem solvers by creating an environment for detailed discussions among senior investigators that involves young investigators at a time when they are building careers. This is a proposal to fund young investigators to attend the conference.",2018 Image Science Gordon Research Conference & Gordon Research Seminar,9461211,R13EB025662,"['Academia', 'Area', 'Astronomy', 'Big Data', 'Biology', 'Brain', 'Collaborations', 'Communities', 'Computational Science', 'Data', 'Data Analytics', 'Development', 'Disabled Persons', 'Discipline', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Fees', 'Female', 'Financial Support', 'Fostering', 'Funding', 'Housing', 'Human', 'Image', 'Industry', 'Information Sciences', 'Interdisciplinary Study', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Minority', 'Modeling', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Recruitment Activity', 'Request for Proposals', 'Research', 'Research Personnel', 'Resource Development', 'Risk-Taking', 'Role', 'Running', 'Science', 'Scientist', 'Security', 'Senior Scientist', 'Series', 'Societies', 'Source', 'Statistical Models', 'Students', 'Systems Development', 'Techniques', 'Thinking', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'career', 'college', 'cost', 'design', 'disabled students', 'educational atmosphere', 'field study', 'frontier', 'graduate student', 'image reconstruction', 'imaging scientist', 'imaging system', 'information display', 'innovation', 'instrument', 'meetings', 'minority student', 'multidisciplinary', 'next generation', 'novel', 'posters', 'preference', 'remote sensing', 'skills', 'success', 'symposium', 'training opportunity', 'virtual', 'willingness']",NIBIB,GORDON RESEARCH CONFERENCES,R13,2018,10000,0.003430473733409582
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment Project Summary NIH is increasing its investment in large mutli-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several open-source software systems. For example, the NIH NIAAA and BD2K funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements that called for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for multi-site QC workflows as that would require a unified platform, design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that supports simplified creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific findings findable, accessible, interoperable, and reusable.  Specifically, our multi-site open-source software platform for Medical Image Quality Assurance (mIQa) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system, machine learning to aid in QC process, and an interactive electronic notebook platform. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automating notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, mIQa is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop multi-site, open-source software for Medical Image Quality Assurance (mIQa) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. mIQa will enable efficient and accurate QC processing by levering open-source, state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive review and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment,9622218,R43MH119022,"['Active Learning', 'Address', 'Adolescence', 'Alcohols', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Data Sources', 'Development', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Environment', 'Evaluation', 'FAIR principles', 'Four-dimensional', 'Funding', 'Geography', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'International', 'Internet', 'Investments', 'Label', 'Libraries', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical', 'Medical Imaging', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'System', 'Techniques', 'Technology', 'Time', 'United States National Institutes of Health', 'Visual', 'Work', 'Writing', 'application programming interface', 'base', 'cohesion', 'cost', 'dashboard', 'data access', 'data management', 'design', 'experience', 'flexibility', 'image archival system', 'imaging study', 'improved', 'innovation', 'member', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'prototype', 'quality assurance', 'research study', 'software systems', 'success', 'tool', 'web interface', 'web-enabled']",NIMH,"KITWARE, INC.",R43,2018,225001,0.01872438315048803
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9535994,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2018,444363,0.02629025542628561
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9536759,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2018,619539,0.022792143883805013
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9525950,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,333515,0.022735439011157092
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9476341,R01HL122484,"['3D ultrasound', '4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Discipline of Nuclear Medicine', 'Dose', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radiation exposure', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical imaging', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging approach', 'imaging modality', 'improved', 'individual patient', 'interest', 'perfusion imaging', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2018,770494,-0.010215819215780995
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this SBIR project, we present EyeMark, a set of advanced image analysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we will develop tools for computation of microaneurysm (MA) ap- pearance and disappearance rates (jointly known as turnover rates) for use as a bi- omarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high positive influ- ence on various aspects of DR care, including screening, monitoring progression, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a MA turnover computation prototype tool that ro- bustly registers longitudinal images (even with multiple lesion changes) and effectively detects DR lesions (lesion level AUROC>=0.95). The tool provides graceful degradation to confounding image factors by reporting MA turnover as a range, thereby capturing the inherent confidence in MA detection. By the end of Phase IIB we will develop a market ready, clinically validated end-to-end desktop software for robust, automated longitudinal lesion analysis and characterization that can work on the cloud to produce results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,9622980,R44TR000377,"['Adult', 'Age', 'Appearance', 'Area', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Biometry', 'Blindness', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Color', 'Communication', 'Computer Vision Systems', 'Computer software', 'County', 'Data', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Early identification', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Joints', 'Lesion', 'Los Angeles', 'Machine Learning', 'Measures', 'Medicine', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Patients', 'Pattern Recognition', 'Pear', 'Performance', 'Phase', 'Picture Archiving and Communication System', 'Process', 'Protocols documentation', 'ROC Curve', 'Reporting', 'Research', 'Retinal', 'Retinal Diseases', 'Retrieval', 'Risk', 'Sampling', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'application programming interface', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'computerized', 'computerized tools', 'deep neural network', 'design', 'diabetic patient', 'digital imaging', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'high throughput analysis', 'image registration', 'improved', 'interest', 'longitudinal analysis', 'macula', 'medical schools', 'novel marker', 'novel therapeutics', 'prevent', 'programs', 'prototype', 'response', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability', 'validation studies']",NCATS,"EYENUK, INC.",R44,2018,750000,0.011481634630388716
"Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research PROJECT SUMMARY/ABSTRACT This proposal represents a vertical advancement in neighborhood effects research, producing for the first time, national neighborhood indicators of the built environment. Thus far, only local studies have been conducted due to the resource-intensive nature of site visits to conduct assessments of community features and also manual annotations of street images. With the recent advancement of computer vision and the emergence of massive sources of image data, we will leverage our team’s abilities to develop a data collection strategy utilizing geographic information systems to assemble a national collection of Google Street View images of all road intersections and street segments in the United States. We will utilize this data bank, and develop informatics algorithms to produce neighborhood summaries of built environment that have been theoretically and empirically identified to be important for health outcomes. After the creation of Neighborhood Looking Glass, we will conduct investigations into the impact of neighborhood environments on health utilizing medical records from hundreds of thousands of patients and accounting for predisposing characteristics in analyses. Our investigative team—comprised of experts in the field of epidemiology, computer vision, bioinformatics, and computer science—is uniquely suited to implement the study aims. Our Specific Aims are: 1) Develop informatics techniques to produce neighborhood quality indicators; 2) Measure the accuracy of data algorithms and construct an interactive geoportal for neighborhood data visualization and data sharing, 3) Utilize Neighborhood Looking Glass and a large collection of medical records from Intermountain Healthcare to investigate neighborhood influences on the risk of obesity and substance abuse. The epidemic rise in chronic health conditions is recent and as such suggests its cause is social, cultural, and constructed rather than purely biological. Thus, we have the possibility of intervening on the environment to better support health. Recent studies suggest that the current cohort of young adults may face historically high cardiovascular disease risk and chronic disease burden. Our substantive investigation of the impact of neighborhood factors on chronic conditions will contribute further to the understanding of contextual influences on the health of this cohort at the forefront of a chronic disease epidemic. Moreover, the dramatic rise in overdoses, accidental poisonings, and mental health issues contributing to premature mortality warrants further investigation into risk-inducing environmental factors for substance abuse. Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics. Results can be utilized to inform population-based strategies to reduce health disparities and improve health. Project Narrative/Relevance to Public Health The epidemic rise in obesity, related chronic diseases, and substance abuse in recent decades signal the importance of structural forces and social processes, but the dearth of data on contextual factors limits the investigation of multilevel effects on health. The development of the Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics with potential impact on health. Results from our project can be utilized to inform system-wide and local strategies to improve community health.",Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research,9499844,R01LM012849,"['Accounting', 'Alcohol or Other Drugs use', 'Algorithms', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Characteristics', 'Chronic', 'Chronic Disease', 'Cities', 'Collection', 'Communities', 'Community Health', 'Computer Vision Systems', 'Data', 'Data Collection', 'Data Sources', 'Development', 'Disease', 'Environment', 'Environmental Risk Factor', 'Epidemic', 'Epidemiology', 'Face', 'Family', 'Food', 'Food Access', 'Geographic Information Systems', 'Geography', 'Glass', 'Grant', 'Happiness', 'Health', 'Health Food', 'Health Personnel', 'Health Services Accessibility', 'Health behavior', 'Health care facility', 'Healthcare', 'Image', 'Individual', 'Informatics', 'Investigation', 'Label', 'Literature', 'Manuals', 'Measures', 'Medical Records', 'Mental Health', 'Methods', 'Nature', 'Neighborhoods', 'Obesity', 'Outcome', 'Overdose', 'Patients', 'Physical activity', 'Physical environment', 'Premature Mortality', 'Process', 'Public Health', 'Quality Indicator', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Signal Transduction', 'Site Visit', 'Social Environment', 'Source', 'Substance abuse problem', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Visit', 'built environment', 'burden of illness', 'cardiovascular disorder risk', 'cohort', 'computer science', 'contextual factors', 'cost', 'crowdsourcing', 'data management', 'data mining', 'data resource', 'data sharing', 'data visualization', 'data warehouse', 'density', 'health disparity', 'improved', 'land use', 'obesity risk', 'object recognition', 'physical conditioning', 'population based', 'social', 'social media', 'walkability', 'young adult']",NLM,"UNIV OF MARYLAND, COLLEGE PARK",R01,2018,355252,-0.0032337990579137848
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9542210,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting', 'whole slide imaging']",NIAMS,UNIVERSITY OF FLORIDA,R01,2018,377571,0.07784596298558623
"Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner Project Summary/Abstract This application is for a shared instrumentation grant from the Light Microscope Imaging Facility at Case Western Reserve University (CWRU) School of Medicine (SOM) to acquire a fully automated, high-capacity, high- resolution Hamamatsu Nanozoomer S60 slide scanner that can accommodate both brightfield and fluorescence imaging in single-slide and double-slide formats. We also request MicroDimensions 3D reconstruction and alignment software packages for manipulating and analyzing the whole slide images produced with the scanner. We need to replace a scanner that is not functioning properly. Our well-established shared core facility supports NIH-funded investigators by giving them access to state-of-the-art microscopy technologies that enhance collaborative, multidisciplinary research. Acquisition of this instrument will have a high impact on the biomedical research at CWRU and expand the scope of our NIH-funded projects. Several projects have been identified that will utilize the scanner and its associated analyses programs. These include: the genetic mechanisms underlying skin fibrosis and cranial bone development (Atit); the mechanisms behind the lifelong functions of transcription factors in axonal growth and architecture (Deneris); deep-learning for histologic image predictors of various diseases (Madabhushi); the development of diagnostic probes to discriminate between glioma subtypes for screening and survival therapies (Brady-Kalnay); the role of progesterone receptors in the control of parturition and the development of therapies to prevent preterm birth (Messiano); the mechanisms by which breast cancer stem cells overcome metastatic latency leading to disease recurrence and the biomarkers that could potentially identify those tumors likely to undergo this process (Schiemann); and the significance of cholesterol-related proteins in brain and retinal function (Pikuleva). Many additional projects of minor users and others at CWRU are anticipated. All of the proposed projects are in need of a high-capacity automated scanner acquiring whole slide images so that analyses can be applied to tissues that cover hundreds of fields of view, rather than the single regions of interest that can be acquired on a standard microscope. Narrative This proposal seeks to acquire a new, state-of-the-art high-speed, high content digital slide scanner for high resolution cellular and biomarker identfcation across large tissue areas. The dual mode (fluorescence and brightfield) allows flexibility in marker visualization while the software allows the automated alignment of whole slide images for multi-stain analysis and 3d reconstruction of serial section for in-depth analysis of specimens. This equipment is essential for our NIH disease-related studies providing a profound positive impact on a wide range of public health areas.",Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner,9489976,S10OD024981,"['Architecture', 'Biological Markers', 'Biomedical Research', 'Birth', 'Bone Development', 'Brain', 'Cephalic', 'Cholesterol', 'Computer software', 'Core Facility', 'Development', 'Diagnostic', 'Disease', 'Enhancement Technology', 'Funding', 'Genetic', 'Glioma', 'Grant', 'Interdisciplinary Study', 'Light Microscope', 'Microscope', 'Microscopy', 'Minor', 'Premature Birth', 'Process', 'Progesterone Receptors', 'Proteins', 'Recurrence', 'Research Personnel', 'Resolution', 'Retinal', 'Role', 'Slide', 'Tissues', 'United States National Institutes of Health', 'Universities', 'axon growth', 'cancer stem cell', 'deep learning', 'digital', 'equipment acquisition', 'fluorescence imaging', 'histological image', 'imaging facilities', 'instrumentation', 'interest', 'malignant breast neoplasm', 'medical schools', 'prevent', 'programs', 'reconstruction', 'screening', 'skin fibrosis', 'therapy development', 'transcription factor', 'tumor', 'whole slide imaging']",OD,CASE WESTERN RESERVE UNIVERSITY,S10,2018,303390,0.009107343479830787
"Fast and Robust Low-Dose X-Ray CT Image Reconstruction Abstract:  The use of CT scans has recently increased, for example, in virtual colonoscopy, CT cardiac screening, screening of the lung in smokers, whole-body CT in asymptomatic patients, and CT imaging of children. Shortening of the scanning time to around 1 second, eliminating the strict need for the subject to remain still or be sedated, is one of the main reasons for the large increase in the pediatric population. CT scans of children have been estimated to produce non-negligible increases in the probability of lifetime cancer mortality, leading to calls for the use of reduced current settings for CT scans of children. For these reasons, the CT industry has put in a lot of effort to develop low-dose CT. One active area of research is methods to reduce the radiation counts by applying adaptive collimation to block unnecessary x-ray photons. Another active area of research is the development of more robust image reconstruction algorithms that are less sensitive to noise for low-count data.  This grant proposal is focused on the second approach — development of fast and robust reconstruction algorithms. It is known that some iterative image reconstruction algorithms outperform the analytical filtered backprojection (FBP) algorithm in terms of producing less-noisy images with the same data set. One disadvantage of these iterative algorithms is their long computation time, making them impractical in a real- world CT reconstruction tasks. For this reason, the FBP algorithm is still the main work horse for CT applications.  The main goal of the proposed research is to develop fast and robust iterative-algorithms so that their computation time is at the same order of an analytic FBP algorithm, using experimental low-dose phantom, cadaver data, and low-dose cancer screen chest CT patient data to perform comparison studies. We will answer the question: When the fast and robust algorithms are used, how much can the CT dose be reduced while retaining the image quality of a standard-dose CT produced by the conventional FBP?  This R15 project provides Weber State University (WSU) computer engineering and computer science students with hands-on opportunities and experiences of performing real-world research in the field of healthcare. It will stimulate the interests of students so that they consider a career in biomedical and bioengineering field/industry. Narrative:  CT dose is currently a major concern for the general public. Low-dose CT is under development. The proposed research will focus on developing fast, robust and practical image reconstruction methods that are able to produce a standard CT image using a lower CT dose.",Fast and Robust Low-Dose X-Ray CT Image Reconstruction,9440734,R15EB024283,"['Algorithms', 'Applications Grants', 'Area', 'Biomedical Engineering', 'Cadaver', 'Cancer Patient', 'Cardiac', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Collimator', 'Computed Tomographic Colonography', 'Computer Hardware', 'Computer Simulation', 'Computers', 'Contracts', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Dimensions', 'Disadvantaged', 'Disease', 'Dose', 'Engineering', 'Environment', 'Equilibrium', 'Equus caballus', 'Evaluation', 'General Population', 'Goals', 'Healthcare', 'Human', 'Image', 'Industry', 'Inferior', 'Internships', 'Investigation', 'Learning', 'Lesion', 'Liver Cirrhosis', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Morphologic artifacts', 'Noise', 'Patients', 'Performance', 'Photons', 'Population', 'Preparation', 'Probability', 'Radiation', 'Radiation exposure', 'Research', 'Resolution', 'Roentgen Rays', 'Running', 'Scanning', 'Screening for cancer', 'Smoker', 'Structure', 'Students', 'Supervision', 'Time', 'Training', 'Universities', 'Utah', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'career', 'chest computed tomography', 'clinical application', 'computer science', 'data acquisition', 'design', 'digital imaging', 'experience', 'high risk', 'image reconstruction', 'improved', 'interest', 'low-dose spiral CT', 'lung cancer screening', 'mortality', 'parallel computer', 'professor', 'radiologist', 'reconstruction', 'screening', 'tomography', 'university student']",NIBIB,WEBER STATE UNIVERSITY,R15,2018,88321,0.00700585619811253
"Automated Diagnosis and Progression Rate of IPF Using HRCT Project Summary: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. Diagnosis and stratification of disease phenotypes are important in order to decipher the effects of novel therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individuals. Few computerized diagnostic tools have been developed for IPF that correlate with visual and surgical lung biopsy; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good predictive models with localized region exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use as a derivative dataset the anonymized clinical data and source images on 234 patients with IPF and 266 patients with IPF suspected, but not IPF based on HRCT and the surgical biopsy who have participated in multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for high through-put quantitative image analysis, we will train a classifier with features of anatomic distribution and reproducible imaging features expressed with a quantitative lung fibrosis (QLF) score, testing on separate data from in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitial Lung Disease Program. Furthermore, the second aim is to develop a rate of progression at local region and to aggregate predictive models using Cox proportional regression models, which will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that diagnose and anticipate disease course in patients with IPF and subdividing patients into more homogeneous groups prior to the development of significant respiratory impairment. We anticipate that models can be used clinically at the individual patient level to enable more informed and timely management decisions to define more homogeneous cohorts for purposes of testing new targeted therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. Relevance to Public Health: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rate of progression is highly variables, which hampers timely decisions about referral for lung transplantation or treatments using new drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to diagnose and predict disease course robustly in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with IPF and non-IPF with reducing chance of lung biopsy and predict slowly versus rapidly progressive disease, leading to more time to treat patients and timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Automated Diagnosis and Progression Rate of IPF Using HRCT,9592308,R21HL140465,"['Acute', 'Air', 'Algorithms', 'Anatomy', 'Archives', 'Automation', 'Biological', 'Biopsy', 'Categories', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease stratification', 'Elderly', 'Etiology', 'Exhibits', 'General Population', 'Glass', 'Goals', 'Growth', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Informatics', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Laboratories', 'Lobar', 'Lobe', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathology', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Prevalence', 'Probability', 'Progression-Free Survivals', 'Progressive Disease', 'Public Health', 'Pulmonary Fibrosis', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Spatial Distribution', 'Stable Disease', 'Standardization', 'Testing', 'Texture', 'Time', 'Time Management', 'Training', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinically relevant', 'cohort', 'computerized', 'data archive', 'digital imaging', 'disease natural history', 'disease phenotype', 'functional decline', 'idiopathic pulmonary fibrosis', 'image processing', 'imaging biomarker', 'improved', 'individual patient', 'individualized medicine', 'new therapeutic target', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'success', 'survival prediction', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2018,113241,-0.019804777222178886
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9449456,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Analysis', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Modality', 'Modernization', 'Morphology', 'Multimodal Imaging', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Pharmacology', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Reproducibility', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Time', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'clinical imaging', 'disease diagnosis', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'imaging study', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2018,64155,0.017558305667664875
"Fully-automated lesion characterization in ultrawide-field retinal images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-automated lesion characterization in ultrawide-field retinal images,9559582,R43EY028081,"['Agreement', 'Algorithms', 'Anti-HIV Agents', 'Applications Grants', 'Architecture', 'Area', 'Biological', 'Blindness', 'Cataract', 'Categories', 'Characteristics', 'Clinical', 'Cloud Computing', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Engineering', 'Ensure', 'Exposure to', 'Exudate', 'Eye', 'Eye diseases', 'Eyelash', 'Gold', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Lasers', 'Lesion', 'Light', 'Manuals', 'Measures', 'Microaneurysm', 'Modality', 'Morphologic artifacts', 'Normalcy', 'Ophthalmoscopy', 'Output', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Receiver Operating Characteristics', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Spottings', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Vision', 'Work', 'base', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fovea centralis', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'operation', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'software development', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2018,216440,0.026240563325891517
"RetiVue DR, a point and shoot, non-mydriatic, widefield retinal camera for diabetic eye screening Project Summary Over the past two decades, diabetic retinopathy (DR) has become the leading cause of adult blindness in the US, affecting 40% of all diabetic patients and resulting in $500 million a year in direct medical costs. Vision loss due to DR is largely preventable and can be reduced by up to 90% with appropriate eye screening. However, in the US, less than 50% of diabetic patients receive a recommended yearly eye exam due to many factors that include lack of access to eye care professionals. Distributed tele-ophthalmic screening thru primary care clinics can potentially provide all diabetic patients cost- effective, yearly evaluations to detect DR and prevent vision loss. However, gold-standard sensitive detection of DR using standard retinal photography is complex and cumbersome process requiring up to 7 images per eye. This screening process cannot for all practical purposes be achieved without having highly trained ophthalmic photographers. RetiVue proposes to develop the RetiVue DR in collaboration with Olympus, to create the first handheld, non- mydriatic, 160 field of view, widefield DR screening camera. It will allow single photo capture of an area up to ten times greater than conventional fundus cameras, allowing sensitive detection of DR at its earliest time points. Full integration of RetiVue and Olympus hardware will enable the most advanced and highest image quality handheld retina camera on the market. Use of automated alignment, auto laser focus, and auto image capture will allow complex imaging of the retina to be performed simply by positioning the iris, requiring no user knowledge of retinal anatomy. We have established clinical proof of concept with our patented technology, but require several additional innovations in optical design, automated image recognition, and retinal image processing to enable a commercial device. We will for this proposal optimize our alignment system and laser based focusing system for widefield imaging, allowing automated alignment and focus to image the retina before eye movement occurs. We will develop a new method of widefield, non-mydriatic peripheral retinal imaging using multiple LED slit-beam projectors to allow rapid, segmental, sequential image capture of 90°, 120°, and 160° FOV on diabetic patients. Finally, we will create the most advanced retinal image processing algorithms to remove Purkinje haze which prevents conventional cameras from imaging beyond 45° FOV and enable seamless stitching of segmental peripheral retina images into a single widefield image. Project Narrative Diabetic retinopathy is a blinding eye disease that affects millions of people with diabetes and costs the US $500 million a year in medical costs. Loss of vision can be prevented if diabetic patients undergo yearly eye screening that examines the retina to detect this disease, but currently less than 50% of diabetics do so. At Re- tiVue LLC, we are designing the first easy to use handheld eye camera to allow primary care doctors to take DSLR quality pictures of the eye to look for diabetic retinopathy. Our eye camera will see 5 times more of the retina than any other handheld camera, ensuring that we find diabetic retinopathy when it first occurs. Earlier detection of diabetic retinopathy will give diabetic patients the best chance to keep their vision long term, and avoid unnecessary blindness.","RetiVue DR, a point and shoot, non-mydriatic, widefield retinal camera for diabetic eye screening",9564677,R44EY028484,"['Adult', 'Affect', 'Age', 'Agreement', 'Algorithms', 'Americas', 'Anatomy', 'Animals', 'Area', 'Blindness', 'Caring', 'Clinic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Color', 'Complex', 'Custom', 'Detection', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Diagnostic Imaging', 'Direct Costs', 'Disease', 'Early Diagnosis', 'Electronics', 'Ensure', 'Evaluation', 'Eye', 'Eye Movements', 'Eye diseases', 'Fundus photography', 'Generations', 'Gold', 'Human', 'Image', 'Imagery', 'Imaging technology', 'Iris', 'Knowledge', 'Lasers', 'Legal patent', 'Light', 'Lighting', 'Masks', 'Medical Care Costs', 'Methods', 'Modeling', 'Movement', 'Ophthalmic examination and evaluation', 'Optics', 'Patients', 'Peripheral', 'Phase', 'Photography', 'Physicians', 'Positioning Attribute', 'Predictive Value', 'Primary Health Care', 'Procedures', 'Process', 'Pupil', 'Resolution', 'Retina', 'Retinal', 'Sensitivity and Specificity', 'Specificity', 'Speed', 'Surface', 'System', 'TNFRSF10B gene', 'Technology', 'Time', 'Training', 'Ultraviolet Rays', 'Validation', 'Visible Radiation', 'Vision', 'base', 'compliance behavior', 'cost', 'cost effective', 'deep learning', 'design', 'detector', 'diabetic', 'diabetic patient', 'image processing', 'imager', 'improved', 'innovation', 'laptop', 'lens', 'novel', 'point of care', 'prevent', 'prototype', 'retinal imaging', 'sample fixation', 'screening', 'seal', 'sensor', 'success']",NEI,RETIVUE,R44,2018,847697,-0.015596997794159812
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9548627,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2018,573677,0.03709118320056418
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,9215686,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cells', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Education', 'Educational Curriculum', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'faculty research', 'graduate student', 'lecturer', 'lectures', 'personalized approach', 'programs', 'public health relevance', 'quantitative imaging', 'student training', 'teaching assistant', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2017,59383,0.00018309780100937576
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9322408,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,30900,0.005790158429226098
"Extracting rich information from biological images Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Extracting rich information from biological images,9276910,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Learning', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2017,513030,0.07912272993366372
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9213309,R01EB008374,"['4D Imaging', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Pharmacology', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'clinical diagnostics', 'clinical predictors', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'public health relevance', 'serial imaging', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2017,451650,-0.009563303019638108
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9315808,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Computing', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'image guided', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'public health relevance', 'quantitative imaging', 'response', 'task analysis', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2017,413289,0.06332998201113395
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris�n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris�n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9264531,R01EY023279,"['Acute', 'Algorithmic Analysis', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Categories', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Image Analysis', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Morphology', 'Nerve Fibers', 'Ophthalmoscopes', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'United States National Institutes of Health', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2017,339750,0.023850800325104685
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9544350,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,56360,0.02629025542628561
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9355633,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,454865,0.02629025542628561
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9315773,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Darkness', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2017,619539,0.022792143883805013
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9150601,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2017,326571,0.022735439011157092
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle. PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9355100,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Intuition', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Morphology', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscle function', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2017,391844,0.03309446437620612
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9268035,R01HL122484,"['3D ultrasound', '4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Discipline of Nuclear Medicine', 'Dose', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radiation exposure', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical imaging', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging approach', 'imaging modality', 'improved', 'individual patient', 'interest', 'perfusion imaging', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2017,770494,-0.010215819215780995
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9316507,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2017,379732,0.07784596298558623
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers. PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9330810,UH2CA203710,"['Algorithms', 'Artificial Intelligence', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Classification', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Image Analysis', 'Institutes', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Nonprofit Organizations', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Specificity', 'Statistical Models', 'Students', 'Technology', 'Territoriality', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'fine art', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'virtual', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2017,320900,0.00657228243000809
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,9194390,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Internet', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'analytical method', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'digital media', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'pedagogy', 'public health relevance', 'sample fixation', 'screening', 'tool', 'transmission process', 'virtual']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,611703,0.03453144130597061
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,9212187,R01HL121226,"['Acute', 'Anatomy', 'Autopsy', 'Bayesian Modeling', 'Biomechanics', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Heart Ventricle', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Pharmacology', 'Phase', 'Physiology', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'perfusion imaging', 'public health relevance', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2017,768639,0.02362252422996243
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9244841,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Analysis', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Modality', 'Modernization', 'Morphology', 'Multimodal Imaging', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Pharmacology', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Reproducibility', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Time', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'clinical imaging', 'disease diagnosis', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'imaging study', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2017,63883,0.017558305667664875
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study No abstract available Project Narrative This study will use computer image analysis techniques to improve our understanding of the causes of diagnostic errors during the interpretation of skin biopsy specimens, as well as seek ways to reduce such errors. As skin biopsies are one of the most common medical procedures performed in the U.S., the results of this study have important implications for patients as these tests are frequently used to guide important treatment recommendations for melanoma and surveillance recommendations for dysplastic nevi.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9666656,R01CA200690,[' '],NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2017,283866,0.01971623650618729
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9341177,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2017,579791,0.03709118320056418
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,9021663,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Health', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'exercise program', 'faculty research', 'graduate student', 'lecturer', 'lectures', 'personalized approach', 'programs', 'quantitative imaging', 'student training', 'teaching assistant', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2016,59383,0.00018309780100937576
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9174605,R01CA200690,"['Adult', 'Algorithms', 'Architecture', 'Area', 'Association Learning', 'Behavior', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Characteristics', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Event', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Property', 'Reference Standards', 'Research', 'Scanning', 'Skin', 'Slide', 'Specimen', 'Staging', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'visual tracking']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,408063,0.005790158429226098
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing. PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8998947,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Health', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'improved outcome', 'neovascular', 'novel', 'programs', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2016,180061,0.0027331065844909117
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9111923,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,539886,0.0839913935408186
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9324484,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,175692,0.0839913935408186
"4D Software Tools for Longitudinal Prediction of Brain Disease DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders. PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.",4D Software Tools for Longitudinal Prediction of Brain Disease,9058040,R01EB008374,"['4D Imaging', 'Accounting', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Health', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2016,451650,-0.009563303019638108
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9110984,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2016,412881,0.06332998201113395
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,9050682,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2016,339750,0.023850800325104685
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9176982,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Shapes', 'Slice', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Translations', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'abstracting', 'aging population', 'base', 'catalyst', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2016,677628,0.02629025542628561
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9108343,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Health', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2016,618809,0.022792143883805013
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle.           PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.              ",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9047634,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Genetic', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'quantitative imaging', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2016,609726,0.03309446437620612
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,9061011,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Health', 'Heart', 'Heart Diseases', 'Image', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Professional Organizations', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging modality', 'improved', 'individual patient', 'interest', 'predictive modeling', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2016,770494,-0.010215819215780995
"Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle,9282051,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'muscular system', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,58482,0.07615396510236444
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9126405,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,316467,0.07784596298558623
"Enabling access to printed text for blind people via assisted mobile OCR DESCRIPTION (provided by applicant): This application proposes new technology development and user studies aiming to facilitate the use of mobile Optical Character Recognition (OCR) for blind people. Mobile OCR systems, implemented as smartphones apps, have recently appeared on the market. This technology unleashes the power of modern computer vision algorithms to enable a blind person to hear (via synthetic speech) the content of printed text imaged by the smartphone's camera. Unlike traditional OCR, that requires scanning of a document with a flatbed scanner, mobile OCR apps enable access to text anywhere, anytime. Using their own smartphones, blind people can read store receipts, menus, flyers, business cards, utility bills, and many other printed documents of the type normally encountered in everyday life. Unfortunately, current mobile OCR systems suffer from a chicken-and-egg problem, which limits their usability. They require the user to take a well-framed snapshot of the document to be scanned, with the full text in view, and at a close enough distance that each character can be well resolved and thus readable by the machine. However, taking a good picture of a document is difficult without sight, and thus without the ability to look at the scene being imaged by the camera through the smartphone's screen. Anecdotal evidence, supported by results of preliminary studies conducted by the principal investigator's group, confirms that acquisition of an OCR-readable image of a document can indeed by very challenging for some blind users. We plan to address this problem by developing and testing a new technique of assisted mobile OCR. As the user aims the camera at the document, the system analyzes in real time the stream of images acquired by the camera, and determines how the camera position and orientation should be adjusted so that an OCR-readable image of the document can be acquired. This information is conveyed to the user via a specially designed acoustic signal. This acoustic feedback allows users to quickly adjust and reorient the camera or the document, resulting in reduced access time and in more satisfactory user experience. Multiple user studies with blind participants are planned with the purpose of selecting an appropriate acoustic interface and of evaluating the effectiveness of the proposed assisted mobile OCR modality. PUBLIC HEALTH RELEVANCE: This application is concerned with the development of new technology designed to facilitate use of mobile Optical Character Recognition (OCR) systems to access printed text without sight. Specifically, this exploratory research will develop and test a novel system that, by means of a specially designed acoustic interface, will help a blind person take a well-framed, well-resolved image of a document for OCR processing using a smartphone or wearable camera. If successful, this novel approach to assisted mobile OCR will reduce access time and improve user experience of blind mobile OCR users.",Enabling access to printed text for blind people via assisted mobile OCR,8989105,R21EY025077,"['Acoustics', 'Address', 'Algorithms', 'Augmented Reality', 'Businesses', 'Cellular Phone', 'Chest', 'Chickens', 'Clothing', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Education', 'Effectiveness', 'Employment', 'Environment', 'Eyeglasses', 'Feedback', 'Goals', 'Hand', 'Health', 'Hearing', 'Image', 'Knowledge', 'Life', 'Light', 'Location', 'Marketing', 'Modality', 'Monitor', 'Participant', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Printing', 'Process', 'Quality of life', 'Reading', 'Report (document)', 'Research', 'Resolution', 'Restaurants', 'Scanning', 'Series', 'Signal Transduction', 'Speech', 'Stream', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Development Study', 'Testing', 'Text', 'Time', 'Translating', 'Travel', 'Vision', 'Visual', 'Visually Impaired Persons', 'blind', 'design', 'egg', 'experience', 'handicapping condition', 'improved', 'new technology', 'novel', 'novel strategies', 'object recognition', 'optical character recognition', 'research study', 'technology development', 'usability', 'way finding']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2016,230563,0.013798670735583694
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,9002898,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Health', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2016,776460,0.02362252422996243
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8970690,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computer Analysis', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'digital media', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'pedagogy', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,624643,0.03453144130597061
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2). PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,9044803,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithms', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Health', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Morphology', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Tissues', 'Underrepresented Groups', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'quantitative imaging', 'reduced muscle strength', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2016,63620,0.017558305667664875
"Prediction of IPF Progression Using Imaging Patterns ﻿    DESCRIPTION (provided by applicant): Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. These designations of natural history assume great importance at a time when insights from preclinical studies are beginning to translate into therapies targeted at specific key pathways of fibrosis. Stratification of disease phenotypes is important in order to decipher the effects of newly approved therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individual patients.  Various prognostic tools have been developed for IPF that correlate with overall survival; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good early predictive models exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use the anonymized clinical data and source images on 234 patients with IPF from multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for quantitative image analysis, we will train a classifier on scans annotated manually by an expert radiologist, analyzing in separate aims static image features present on baseline scans and transitional (difference) morphologic features on sequential scans that herald progressive disease. Features of anatomic distribution will be explored and reproducible imaging features will be expressed with a quantitative lung fibrosis (QLF) score. Aggregate prognostic models using Cox proportional regression models will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Finally, we will externally validate our models in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitia Lung Disease Program.  Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that anticipate disease course in patients with IPF. We anticipate that these models can be used clinically at the individual patient level to enable more informed and timely management decisions for the choice in treatment as well as future research to define more homogeneous cohorts for testing new safe and effective therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. PUBLIC HEALTH RELEVANCE: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rates of progression are highly variable, which hampers timely decisions about referral for lung transplantation or treatments using newer drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to predict disease course in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with slowly versus rapidly progressive disease, leading to more timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Prediction of IPF Progression Using Imaging Patterns,9122467,R21HL123477,"['Acute', 'Algorithms', 'Anatomy', 'Archives', 'Behavior', 'Biopsy', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Decision Making', 'Derivation procedure', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease model', 'Elderly', 'Etiology', 'Exhibits', 'Fibrosis', 'Functional disorder', 'General Population', 'Goals', 'Hamman-Rich syndrome', 'Health', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Individual', 'Institution', 'Interobserver Variability', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Investigation', 'Laboratories', 'Lung Transplantation', 'Lung diseases', 'Measures', 'Mining', 'Modeling', 'Morphology', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Play', 'Prevalence', 'Progression-Free Survivals', 'Progressive Disease', 'Pulmonary Fibrosis', 'Pulmonary function tests', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Stable Disease', 'Stratification', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'cohort', 'data archive', 'digital imaging', 'disease classification', 'disease natural history', 'disease phenotype', 'effective therapy', 'functional decline', 'image processing', 'imaging biomarker', 'individual patient', 'insight', 'interstitial', 'novel', 'novel therapeutics', 'preclinical study', 'predictive modeling', 'prognostic', 'prognostic tool', 'programs', 'pulmonary function', 'quantitative imaging', 'radiologist', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2016,107290,0.005495860732031861
"Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease Abstract: Advances in imaging technology offer great opportunities to study Alzheimer's disease (AD) in many ways that are not previously possible. This leads to various large-scale imaging studies, i.e., ADNI, for discovering AD-related imaging biomarkers. In these imaging studies, image registration plays a key role in reducing the confounding inter-subject variability and also enhancing the statistical power of identifying abnormalities related to AD. However, automated processing of large-scale imaging data, i.e., involving anything from hundreds to thousands of 3D brain images, is not trivial and requires dedicated computational tools. The goal of this project is to develop a series of novel deep multi-layer groupwise registration methods for effective, efficient and simultaneous registration of all brain images with possibly large anatomical and appearance differences. Also, to accommodate for new images acquired from the on-going large-scale imaging study, an efficient incremental groupwise registration method will be further developed to avoid time- and resource-consuming re-registration of all new and existing images from scratch. Our key idea is to break down the complex groupwise registration problem into hierarchical sets of small- scale registration tasks that can be solved easily, thus making the large-scale registration more manageable and fast. Specifically, 1) for fast initialization of large-scale groupwise registration of brain images, we will develop in Aim 1 a hierarchical learning-based landmark detection algorithm, based on random forest regression, to detect salient anatomical landmarks and then jointly align all images with detected landmarks. Since all images are distributed in a complex manifold and also the registration of similar images is much faster and more accurate, we propose to first build a graph to link each image only with similar images, and then formulate groupwise registration as dynamic graph shrinkage. This avoids direct registration of each image to the group-mean image as done in the conventional methods, thus improving both speed and accuracy. 2) To significantly speed up and also improve this single-layer graph-based groupwise registration, we will further develop in Aim 2 a deep multi-layer groupwise registration by simultaneous layer-by-layer graph construction and layer-wise registration. 3) Finally, to significantly increase both the speed and accuracy of registration for new images acquired from on-going large-scale imaging study, we will develop in Aim 3 a novel incremental groupwise registration method to reuse previous registration results of existing images for guiding registration of new images. Specifically, each new image can be quickly registered to the common space of existing images by finding its most similar existing image(s). Accordingly, all new and existing images will become similar in the common space and then can be quickly updated for their overall groupwise registration. All computational tools developed will be made freely available to the research community, for accelerating the imaging study of Alzheimer's disease. Narrative Description of Project Modern imaging techniques offer great opportunities to study Alzheimer's disease (AD) in many ways that are not previously possible. This leads to increasing number of large-scale imaging studies, including ADNI. However, the overwhelmingly big data poses new challenges to researchers in automated data processing. Thus, modern computational tools are expected to be able to handle the vast amount of data within a manageable time frame. In light of this, we aim to solve this large-scale spatial registration problem – a critical step directly related to accuracy and precision of imaging biomarkers to be discovered for AD. In particular, we will develop novel deep multi-layer groupwise registration methods for effective, efficient and simultaneous registration of all brain images with possibly large anatomical and appearance differences. Also, to accommodate for new images acquired from the on-going study, an efficient incremental groupwise registration will be further developed to avoid time- and resource-consuming re-registration of all new and existing images from scratch. The development of these advanced computational tools will eventually benefit for discovery of new imaging biomarkers for AD.",Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease,9240850,RF1AG053867,"['Advanced Development', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Appearance', 'Automatic Data Processing', 'Big Data', 'Brain', 'Brain imaging', 'Communities', 'Complex', 'Computer software', 'Data', 'Detection', 'Documentation', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Imaging technology', 'Learning', 'Light', 'Link', 'Mainstreaming', 'Methods', 'Play', 'Process', 'Research', 'Research Personnel', 'Resources', 'Running', 'Series', 'Speed', 'Subgroup', 'Time', 'Update', 'Work', 'abstracting', 'base', 'computerized tools', 'cost', 'empowered', 'forest', 'image guided', 'image registration', 'imaging biomarker', 'improved', 'neuroimaging', 'novel', 'rapid technique']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,RF1,2016,2485857,0.01224535944182545
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers.         PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1        ",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9076876,UH2CA203710,"['Algorithms', 'Arts', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Code', 'Collaborations', 'Color', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Institutes', 'Intelligence', 'Lead', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Statistical Models', 'Students', 'Technology', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2016,320900,0.00657228243000809
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9145647,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2016,605366,0.03709118320056418
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,8813596,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Health', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'quantitative imaging', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2015,59383,0.00018309780100937576
"Automated Retinal Analysis for Detection of Age Related Macular Degeneration ﻿    DESCRIPTION (provided by applicant): This study focuses on age-related macular degeneration (AMD) because, left untreated, it is the leading cause of blindness in the adult US population over 50. The goals of this program are twofold. First, the focus is to develop new screening tools to detect individuals with the intermediate stage of AMD, that are otherwise asymptomatic for vision loss, at a stage where they can be referred to a clinician for treatment and follow up, and when vision more likely can be preserved. The second goal is to develop Automated Retinal Image Analysis (ARIA) tools that help characterize Geographic Atrophy (GA), for which novel treatments are being investigated. We are developing data-driven algorithms for AMD screening which leverage recent advances in machine learning and machine intelligence and do not rely on detecting and counting or sizing drusen (a procedure which can be error prone). Instead, our method analyzes a fundus image as a whole using an image classification paradigm, and may also exploit ancillary patient information. Our goal is to use the AREDS dbGaP that includes thousands of images from hundreds of patients and offers a unique opportunity to develop and test these algorithms on a scale that has not previously been possible. Our team consists of the Johns Hopkins Wilmer Eye Institute, which will serve as the clinical analysis test site, and the Johns Hopkins University Applied Physics Laboratory, which will conduct the automated screening software tool analysis, development and testing.         PUBLIC HEALTH RELEVANCE: The goals of this project are twofold. First, in order to work towards improving outcome, our goal is to develop novel software screening tools that allow for the automated detection of individuals with the intermediate stage AMD so that they may be referred to clinicians for follow up and treatment at an earlier stage than would otherwise occur. Second, we will develop new tools to characterize the evolution of GA, for which new treatments are being developed and tested. Our project is a secondary study on the AREDS dbGaP, which will be leveraged for the development and validation of these new algorithms on a scale never before attempted.                ",Automated Retinal Analysis for Detection of Age Related Macular Degeneration,8826350,R21EY024310,"['Adult', 'Age related macular degeneration', 'Algorithms', 'Artificial Intelligence', 'Biotechnology', 'Blindness', 'Caring', 'Cataract', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Computer software', 'Computers', 'Data', 'Data Set', 'Detection', 'Development', 'Diabetic Retinopathy', 'Discipline', 'Drusen', 'Evaluation', 'Evolution', 'Eye', 'Eye diseases', 'Funding', 'Fundus', 'Generations', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Individual', 'Institutes', 'Laboratories', 'Lead', 'Left', 'Life', 'Lighting', 'Machine Learning', 'Medical', 'Methods', 'Monitor', 'Morphologic artifacts', 'Myopia', 'National Eye Institute', 'Ophthalmologist', 'Outcome', 'Participant', 'Pathology', 'Patients', 'Performance', 'Physicians', 'Physics', 'Pigmentation physiologic function', 'Population', 'Principal Investigator', 'Procedures', 'Provider', 'Public Health', 'Research Personnel', 'Retina', 'Retinal', 'Risk', 'Scientist', 'Severities', 'Site', 'Software Tools', 'Staging', 'Structure of retinal pigment epithelium', 'Testing', 'Universities', 'Validation', 'Vision', 'Work', 'age related', 'bioimaging', 'computer program', 'database of Genotypes and Phenotypes', 'design', 'dietary supplements', 'experience', 'follow-up', 'geographic atrophy', 'improved', 'neovascular', 'novel', 'programs', 'public health relevance', 'response', 'screening', 'tool']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2015,215393,0.0027331065844909117
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,8910751,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,589523,0.0839913935408186
"4D Software Tools for Longitudinal Prediction of Brain Disease     DESCRIPTION (provided by applicant): Neuroimaging allows safe, non-invasive measurement of brain structures and functions and their changes over time. This has led to many longitudinal studies to discover imaging biomarkers for better prediction of brain disorders. However, the associated longitudinal changes are often tiny within a short follow-up time, and are thus difficult to detect by conventional methods since the measurement errors could be larger than the actual changes. Also, with the significant increase of data with longitudinal follow-ups, it becomes challenging to capture a small set of effective imaging biomarkers from large data for accurate disease prediction. This issue becomes even more critical when there is missing data in the longitudinal study, which is unavoidable in clinical application. The goal of this renewal project is to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. These tools wil allow elucidating subtle abnormal changes that would be otherwise left undetected with existing tools. Specifically, in Aim 1, we will create a novel multi-atlas guided 4D brain labelling method for consistent and accurate labeling of Regions of Interest (ROIs) across longitudinal images (4D image) of the same subject. All longitudinal images of each subject will be first aligned by a novel groupwise 4D registration algorithm that can more accurately estimate longitudinal deformations. Then, these aligned longitudinal images can be further registered with multiple atlases guided by a graph that locally connects all (subject and atlas) images, thus obtaining more accurate/consistent registration and ROI labeling for the longitudinal images of same subject. In Aim 2, we will further create a multimodal, sparse longitudinal prediction model to effectively integrate serial imaging and non-imaging biomarkers for early diagnosis and prediction of brain status. Also, to further extract effective biomarkers, a new machine learning technique, called deep learning, will be adapted to learn high-level features for helping prediction with a novel temporally-constrained group sparse learning method, which is able to predict clinical scores consistently for future time-points. Finally, in Aim 3, we will create nove methods to deal with missing data in longitudinal study, which is unavoidable in clinical application. In particular, we will first develop several data completion methods (including matrix completion) to complete the missing data. Then, instead of designing a single predictor that may be limited, we will design multiple diverse predictors (by multi-task learning) for ensemble prediction, thus significantly increasing the overall prediction performance. Also, considering that the individual's future images are not available at early time-points, to improve the clinical utility of the proposed methods, we will apply our models to various cases with different numbers of longitudinal images and then further train them jointly to achieve the overall best performance. Note that the performance of all proposed methods will be evaluated in this project for Alzheimer's Disease (AD) study, although they are also applicable to studies of other brain disorders.          PUBLIC HEALTH RELEVANCE: This project aims to create a set of innovative 4D software tools that are dedicated to more effective early diagnosis and prediction of brain disorders with longitudinal data. To achieve this goal, we will create 1) a novel multi-atlases guided 4D brain labelling framework for consistent and accurate labeling of Regions of Interest (ROIs) across the longitudinal images (4D image) of the same subject by harnessing the manifold of anatomical variation of 4D image and the atlases, 2) a multimodal, sparse longitudinal prediction model that will automatically learn the relevant information from imaging and non-imaging data of past time-points to predict future status of brain, and 3) novel methods for missing data completion and then multiple diverse predictors for ensemble prediction. We will also make these methods practical for clinical diagnostics setting. Finally, we will package all our methods into a softwar tool and release it publicly, as we have done before. The methods that we will develop can find their applications not only in Alzheimer's Disease (AD) that will be used as example in this project, but also in other fields such as longitudinal monitoring of other neurological diseases (i.e., schizophrenia) and measuring the effects of different pharmacological interventions on the brain.            ",4D Software Tools for Longitudinal Prediction of Brain Disease,8814543,R01EB008374,"['4D Imaging', 'Accounting', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Atlases', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Complex', 'Data', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Future', 'Goals', 'Graph', 'Image', 'Individual', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Left', 'Longitudinal Studies', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Noise', 'Outcome', 'Performance', 'Schizophrenia', 'Software Tools', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'clinical application', 'computerized tools', 'design', 'follow-up', 'imaging biomarker', 'improved', 'innovation', 'interest', 'mild cognitive impairment', 'multitask', 'nervous system disorder', 'neuroimaging', 'novel', 'public health relevance', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2015,477101,-0.009563303019638108
"Image analysis for high-throughput C. elegans infection and metabolism assays DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute. PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8786567,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression Profile', 'Gene Expression Profiling', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'imaging platform', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,309263,0.037395560776333374
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,8902139,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2015,405249,0.06332998201113395
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8842639,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Health', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder']",NEI,UNIVERSITY OF IOWA,R01,2015,332955,0.023850800325104685
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact).         PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.            ",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,8946754,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2015,658985,0.022792143883805013
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8852613,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,213115,0.04902484251160673
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics.         PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.            ",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9072725,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disadvantaged', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Population', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'Solutions', 'Staging', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2015,299984,0.022735439011157092
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient. PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,8842707,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Health', 'Heart', 'Heart Diseases', 'Image', 'Individual', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'cardiac single photon emission computed tomography', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging agent', 'imaging modality', 'improved', 'interest', 'predictive modeling', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2015,758935,-0.010215819215780995
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics. n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8792208,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2015,248295,0.02740824467126123
"Providing Access to Appliance Displays for Visually Impaired Users DESCRIPTION (provided by applicant):  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays.  This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment.  No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents.  Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image.  For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast.  These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view.  Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users.  Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures.  The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.",Providing Access to Appliance Displays for Visually Impaired Users,8916115,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Health', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'contrast enhanced', 'contrast imaging', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2015,368560,0.024152388298734
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8922953,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2015,314327,0.07784596298558623
"Enabling access to printed text for blind people via assisted mobile OCR     DESCRIPTION (provided by applicant): This application proposes new technology development and user studies aiming to facilitate the use of mobile Optical Character Recognition (OCR) for blind people. Mobile OCR systems, implemented as smartphones apps, have recently appeared on the market. This technology unleashes the power of modern computer vision algorithms to enable a blind person to hear (via synthetic speech) the content of printed text imaged by the smartphone's camera. Unlike traditional OCR, that requires scanning of a document with a flatbed scanner, mobile OCR apps enable access to text anywhere, anytime. Using their own smartphones, blind people can read store receipts, menus, flyers, business cards, utility bills, and many other printed documents of the type normally encountered in everyday life. Unfortunately, current mobile OCR systems suffer from a chicken-and-egg problem, which limits their usability. They require the user to take a well-framed snapshot of the document to be scanned, with the full text in view, and at a close enough distance that each character can be well resolved and thus readable by the machine. However, taking a good picture of a document is difficult without sight, and thus without the ability to look at the scene being imaged by the camera through the smartphone's screen. Anecdotal evidence, supported by results of preliminary studies conducted by the principal investigator's group, confirms that acquisition of an OCR-readable image of a document can indeed by very challenging for some blind users. We plan to address this problem by developing and testing a new technique of assisted mobile OCR. As the user aims the camera at the document, the system analyzes in real time the stream of images acquired by the camera, and determines how the camera position and orientation should be adjusted so that an OCR-readable image of the document can be acquired. This information is conveyed to the user via a specially designed acoustic signal. This acoustic feedback allows users to quickly adjust and reorient the camera or the document, resulting in reduced access time and in more satisfactory user experience. Multiple user studies with blind participants are planned with the purpose of selecting an appropriate acoustic interface and of evaluating the effectiveness of the proposed assisted mobile OCR modality.         PUBLIC HEALTH RELEVANCE: This application is concerned with the development of new technology designed to facilitate use of mobile Optical Character Recognition (OCR) systems to access printed text without sight. Specifically, this exploratory research will develop and test a novel system that, by means of a specially designed acoustic interface, will help a blind person take a well-framed, well-resolved image of a document for OCR processing using a smartphone or wearable camera. If successful, this novel approach to assisted mobile OCR will reduce access time and improve user experience of blind mobile OCR users.                ",Enabling access to printed text for blind people via assisted mobile OCR,8812658,R21EY025077,"['Acoustics', 'Address', 'Algorithms', 'Businesses', 'Cellular Phone', 'Chest', 'Chickens', 'Clothing', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Disabled Persons', 'Education', 'Effectiveness', 'Employment', 'Environment', 'Eyeglasses', 'Feedback', 'Goals', 'Hand', 'Hearing', 'Image', 'Knowledge', 'Life', 'Light', 'Location', 'Marketing', 'Modality', 'Monitor', 'Participant', 'Pattern', 'Positioning Attribute', 'Principal Investigator', 'Printing', 'Process', 'Quality of life', 'Reading', 'Report (document)', 'Research', 'Resolution', 'Restaurants', 'Scanning', 'Series', 'Signal Transduction', 'Solutions', 'Speech', 'Stream', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Development Study', 'Testing', 'Text', 'Time', 'Translating', 'Travel', 'Vision', 'Visual', 'Visually Impaired Persons', 'blind', 'design', 'egg', 'experience', 'handicapping condition', 'improved', 'new technology', 'novel', 'novel strategies', 'object recognition', 'optical character recognition', 'public health relevance', 'research study', 'technology development', 'usability', 'way finding']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R21,2015,191510,0.013798670735583694
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care. PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8771432,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy Specimen', 'Breast biopsy', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Health', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'imaging system', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,639475,0.03453144130597061
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography DESCRIPTION (provided by applicant): Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induce stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quantitative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational image analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentially between rest and stress - that will identify myocardial tissue at-risk after dobutamine-induced stress. This work wil involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to humans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,8807942,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Health', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'non-invasive imaging', 'novel', 'novel strategies', 'radio frequency', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2015,767996,0.02362252422996243
"QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES ﻿    DESCRIPTION (provided by applicant): Tissue identification and quantification plays a significant role in the study of aging and age-related diseases. For example, the accumulation of fat in the human body and its regional distribution with aging is associated with type 2 diabetes and cardiovascular diseases. Changes in muscle composition are strongly linked to decline of muscle strength, decreased mobility caused by aging, or musculoskeletal disorders. Especially interesting is analysis of longitudinal changes of morphometric descriptors that is significant for studying the aging process and for the diagnosis and prevention of age-related diseases.  Medical imaging has emerged as a major tool for estimation of body composition mainly due to being non- invasive and producing multi-dimensional information. Nowadays MRI and CT acquisition is a central component of clinical trials. An abundance of imaging data is collected, but this wealth of information has not been utilized to full extent. Therefore research on image analysis techniques for tissue quantification that are reproducible and can be used on large-scale clinical trials is of particular importance.  The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse body composition data from modern MRI and CT imaging. The central hypothesis of this proposal is that qualitative body composition phenotypes on clinical imaging will differentiate individuals who are healthy versus those who are not. The goal of our work is to provide a foundation for image analysis of the abdomen and lower extremities and to study the relationship between body morphological changes and age-related pathologies.  We will build upon recent advances in medical image computing to segment muscle, regional adipose tissue, and bone in clinical CT and MRI scans. We will also develop image registration procedures to achieve intra- and inter-subject correspondence and make efficient use of information provided by multi-modal and multi-temporal imaging data collected in clinical trials (aim 1). After these methods have been developed, we will address the hypothesis that quantitative use of clinical imaging can increase the prognostic accuracy of age-related pathologies (aim2).          PUBLIC HEALTH RELEVANCE: Age-related diseases such as type-2 diabetes, cardiovascular diseases, and sarcopenia have become a worldwide epidemic and affect the quality of life of millions. To give a global perspective, roughly 343.8 million people in the world have type-2 diabetes today, and 175 million don't know they have diabetes at all. Metabolic diseases are strongly linked to longitudinal changes in body composition, morphology and function. This project will contribute novel and non-invasive medical image analysis techniques for studying the human body composition and its changes with increasing age to achieve timely prognosis of these pathologies.                 ",QUANTITATIVE IMAGE ANALYSIS TECHNIQUES FOR STUDIES OF AGING PHENOTYPES AND AGE-RELATED DISEASES,8854343,SC3GM113754,"['Abdomen', 'Address', 'Adipose tissue', 'Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithms', 'Anatomy', 'Biological Markers', 'Body Composition', 'Cardiovascular Diseases', 'Clinical', 'Clinical Trials', 'Computational Technique', 'Data', 'Data Analyses', 'Delaware', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Early Diagnosis', 'Epidemic', 'Epidemiology', 'Fatty acid glycerol esters', 'Foundations', 'Gerontology', 'Goals', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Lower Extremity', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metabolic Diseases', 'Metabolic syndrome', 'Methods', 'Morphology', 'Muscle', 'Musculoskeletal Diseases', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Participant', 'Pathology', 'Pattern', 'Pennsylvania', 'Phenotype', 'Play', 'Prevention', 'Procedures', 'Quality of life', 'Research', 'Role', 'Skeletal Muscle', 'Techniques', 'Thigh structure', 'Tissues', 'Underrepresented Minority', 'United States National Institutes of Health', 'Work', 'X-Ray Computed Tomography', 'age related', 'biophysical model', 'bone', 'effective therapy', 'graduate student', 'image processing', 'image registration', 'in vivo', 'interest', 'longitudinal analysis', 'morphometry', 'muscle form', 'muscle strength', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'quantitative imaging', 'sarcopenia', 'statistics', 'tool', 'undergraduate student']",NIGMS,DELAWARE STATE UNIVERSITY,SC3,2015,63363,0.017558305667664875
"Prediction of IPF Progression Using Imaging Patterns ﻿    DESCRIPTION (provided by applicant): Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. These designations of natural history assume great importance at a time when insights from preclinical studies are beginning to translate into therapies targeted at specific key pathways of fibrosis. Stratification of disease phenotypes is important in order to decipher the effects of newly approved therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individual patients.  Various prognostic tools have been developed for IPF that correlate with overall survival; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good early predictive models exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use the anonymized clinical data and source images on 234 patients with IPF from multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for quantitative image analysis, we will train a classifier on scans annotated manually by an expert radiologist, analyzing in separate aims static image features present on baseline scans and transitional (difference) morphologic features on sequential scans that herald progressive disease. Features of anatomic distribution will be explored and reproducible imaging features will be expressed with a quantitative lung fibrosis (QLF) score. Aggregate prognostic models using Cox proportional regression models will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Finally, we will externally validate our models in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitia Lung Disease Program.  Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that anticipate disease course in patients with IPF. We anticipate that these models can be used clinically at the individual patient level to enable more informed and timely management decisions for the choice in treatment as well as future research to define more homogeneous cohorts for testing new safe and effective therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression.         PUBLIC HEALTH RELEVANCE: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rates of progression are highly variable, which hampers timely decisions about referral for lung transplantation or treatments using newer drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to predict disease course in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with slowly versus rapidly progressive disease, leading to more timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.            ",Prediction of IPF Progression Using Imaging Patterns,8956609,R21HL123477,"['Acute', 'Algorithms', 'Anatomy', 'Archives', 'Behavior', 'Biopsy', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Decision Making', 'Derivation procedure', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease model', 'Elderly', 'Etiology', 'Exhibits', 'Fibrosis', 'Functional disorder', 'General Population', 'Goals', 'Hamman-Rich syndrome', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Individual', 'Institution', 'Interobserver Variability', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Investigation', 'Laboratories', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measures', 'Mining', 'Modeling', 'Morphology', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Play', 'Prevalence', 'Progression-Free Survivals', 'Progressive Disease', 'Pulmonary function tests', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Stable Disease', 'Stratification', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'cohort', 'digital imaging', 'disease classification', 'disease natural history', 'disease phenotype', 'effective therapy', 'functional decline', 'image processing', 'imaging biomarker', 'insight', 'interstitial', 'novel', 'preclinical study', 'predictive modeling', 'prognostic', 'prognostic tool', 'programs', 'public health relevance', 'pulmonary function', 'quantitative imaging', 'radiologist', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2015,107290,0.005495860732031861
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8919113,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'imaging software', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'targeted imaging', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,341788,0.09588428593059224
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities.         PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.                ","Pathology Image Informatics Platform for visualization, analysis and management",8970326,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2015,606305,0.03709118320056418
"Computational Image Analysis for Cellular and Developmental Biology     DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. !         PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.             ",Computational Image Analysis for Cellular and Developmental Biology,8628140,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'public health relevance', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2014,59383,0.00018309780100937576
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8699686,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'E-learning', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2014,142837,0.04382720934963616
"Automated retinopathy of prematurity classification using machine learning     DESCRIPTION (provided by applicant): The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH-funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi-disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing.         PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.",Automated retinopathy of prematurity classification using machine learning,8723225,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2014,198905,0.042601743623795874
"Continued Development of CellProfiler Cell Image Analysis Software     DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology.         PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.            ",Continued Development of CellProfiler Cell Image Analysis Software,8761195,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'public health relevance', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,522488,0.0839913935408186
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8600293,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,310129,0.037395560776333374
"ENTROPY-BASED TISSUE DISCRIMINATORS     DESCRIPTION (provided by applicant): The major problem addressed in this proposal is the development and evaluation of an automated noninvasive approach to discriminate different normal and pathological tissue types using machine learning algorithms; previous applications of machine learning have been based on features of the backscattered ultrasound that are essentially energy based. Our approach will be based on extracting features from images whose pixels are determined by the entropy contained in segments of the backscattered ultrasound. The unique attributes of entropy imaging suggest that the automated analysis we propose would be particularly robust for discrimination of deep tissues in a clinical environment.        PUBLIC HEALTH RELEVANCE: All skilled clinical practitioners and interpreters of ultrasound studies realize that much information exists in recorded US images that is processed immediately by the visual cortex and is useful for qualitatively defining pathology, yet defies ready quantification by any robust algorithm. Traditional energy-based representations display grayscale intensities and speckle patterns that have been mapped parametrically into various tissue classification schemes that have yet to demonstrate organ or tissue specificity, although progress has been reported in distinguishing pathologies over the last 30 years. However, the fact that US signal processing and representation of backscatter data in terms of energy functions has not changed over the last 50 years suggests that alternative signal processing schemes may be indicated to represent the richness of the information contained within the backscattered data. To meet this challenge, we have been involved over the past 10 years in processing backscattered RF to create ""information"" images and in designing ""information sensitive"" approaches to classifying the data sets based on statistical analysis of these images These novel and user independent metrics utilize the entropy of windowed segments of radiofrequency (RF) backscatter signal from tis- sue, which represents a radical departure from grayscale or speckle metrics. In this approach the entropy of the backscattered segment is used to produce a pixel value in the tissue image. This processing strategy has proven to be sensitive to weak, sub-resolution sized changes in tissue.            ",ENTROPY-BASED TISSUE DISCRIMINATORS,8737902,R21EB018095,"['Address', 'Algorithms', 'Back', 'Base Composition', 'Bayesian Analysis', 'Cardiac', 'Classification', 'Classification Scheme', 'Clinical', 'Color', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffuse', 'Dimensions', 'Discrimination', 'Disease', 'Ensure', 'Entropy', 'Environment', 'Evaluation', 'Expeditions', 'Fatty Liver', 'Fibrosis', 'Fishes', 'Foundations', 'Fractals', 'Frequencies', 'Heart', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Ischemia', 'Joints', 'Kidney', 'Knowledge', 'Label', 'Liver', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Metric', 'Microscopic', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Physiological', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Prostate', 'Radio', 'Reporting', 'Resolution', 'Rodent', 'Scheme', 'Shapes', 'Signal Transduction', 'Specificity', 'Staining method', 'Stains', 'Stream', 'Structure', 'Testing', 'Time', 'Tissue Differentiation', 'Tissue Model', 'Tissues', 'Ultrasonic Transducer', 'Ultrasonics', 'Ultrasonography', 'Visual Cortex', 'Work', 'attenuation', 'base', 'data reduction', 'design', 'detector', 'heart motion', 'indexing', 'meetings', 'n-dimensional', 'novel', 'public health relevance', 'radiofrequency', 'signal processing', 'sound', 'tissue processing', 'vector']",NIBIB,WASHINGTON UNIVERSITY,R21,2014,184300,0.029116312419722408
"Graph-Based Medical Image Segmentation in 3D and 4D     DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care.         PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.            ",Graph-Based Medical Image Segmentation in 3D and 4D,8759436,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'public health relevance', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2014,395708,0.06332998201113395
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8652462,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2014,332955,0.023850800325104685
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8664845,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,214609,0.04902484251160673
"Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging     DESCRIPTION (provided by applicant): Radiation exposure of patients during medical imaging has become a major concern, with computed tomography (CT) and cardiac single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI) being the biggest contributors. In this project our aim will be to dramatically reduce radiation dose in cardiac SPECT MPI based on inexpensive software techniques that can be translated readily to clinical practice. Our initial results suggest that at least an eightfold reduction in radiation doe might be possible, which could lead to an estimated reduction of 6500 cancer deaths per year in the U.S. alone.  In lay terms, cardiac SPECT MPI is used routinely to evaluate heart disease, allowing the physician to assess blood flow reaching the heart wall, the motion of the heart, and whether the heart wall's tissue is viable. This form of imaging involves administration of a radioactive pharmaceutical (tracer) to the patient, which exposes the patient to radiation; thus, i would be desirable to minimize tracer dose used during imaging. Image quality is determined by the amount of tracer used, and these levels were chosen prior to recent technological improvements that can produce high-quality images at lower dose; therefore, there is clear evidence that doses can be lowered, and indeed there is considerable current interest in doing so.  We are proposing a translational research project to thoroughly and quantitatively study the extent to which administered dose might be reduced without sacrificing image quality. This work will build, in particular, on new four-dimensional (4D) image reconstruction techniques and respiratory motion compensation approaches we have developed. Furthermore, we propose a new dosing approach we call ""personalized imaging"", in which a computer algorithm will be trained to predict, for a given patient, the minimum dose required to obtain the current level of image quality, so that the administered dose is no more than necessary.  In 4D reconstruction, a computer algorithm tracks the heart's beating motion, and uses this information to improve image quality by smoothing image noise in a way that preserves image details. In respiratory motion compensation, the patient's breathing and body motions are tracked by external sensors, and this information is used to reduce the appearance of motion blur in the images, and thereby improve diagnostic accuracy. The proposed ""personalized imaging"" approach builds on our group's extensive experience in machine learning.  We expect that the combination of these various strategies will greatly reduce radiation dose, and because the improvements are based on software, the cost of these enhancements is very low. The project will result in recommendations for image reconstruction algorithms and parameters to be used in the clinic, along with corresponding tracer dose recommendations. The ""personalized imaging"" method will be implemented as a user-friendly computer program that customizes the dose for each given patient.         PUBLIC HEALTH RELEVANCE: Radiation exposure of patients via medical imaging has become a significant concern. This project will investigate software methods that may allow the radiation dose in cardiac SPECT imaging to be reduced by a factor of eight or more. This will be accomplished by: optimizing the image processing that is used, further developing new and better image processing methods, and developing a method of ""personalized imaging"", in which, for each individual patient, the minimum amount of imaging agent needed to obtain a good image is computed.            ",Probing Dose Limits in Cardiac SPECT with Reconstruction and Personalized Imaging,8674683,R01HL122484,"['4D Imaging', 'Acceleration', 'Accounting', 'Address', 'Adopted', 'Algorithms', 'American', 'Appearance', 'Attention', 'Blood flow', 'Breathing', 'Cardiac', 'Cardiac Catheterization Procedures', 'Cardiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Protocols', 'Clinical Research', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Discipline of Nuclear Medicine', 'Dose', 'Dose-Limiting', 'Electromagnetic Energy', 'Evaluation', 'Financial compensation', 'Four-dimensional', 'Goals', 'Government', 'Heart', 'Heart Diseases', 'Image', 'Individual', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial perfusion', 'Noise', 'Nuclear', 'Obesity', 'Patients', 'Performance', 'Perfusion', 'Persons', 'Pharmacologic Substance', 'Physicians', 'Population', 'Procedures', 'Process', 'Protocols documentation', 'Radiation', 'Radiation Protection', 'Radioactive', 'Reader', 'Recommendation', 'Research Project Grants', 'Societies', 'Stress', 'Sum', 'System', 'Techniques', 'Tissues', 'Tracer', 'Training', 'Translating', 'Translational Research', 'Ultrasonography', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'computer program', 'cost', 'diagnostic accuracy', 'experience', 'heart motion', 'image processing', 'image reconstruction', 'imaging modality', 'improved', 'interest', 'predictive modeling', 'public health relevance', 'reconstruction', 'respiratory', 'sensor', 'single photon emission computed tomography', 'user-friendly']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2014,782871,-0.010215819215780995
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8631080,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2014,250003,0.02740824467126123
"HHSN261201400054C; TOPIC 308 AUTOMATED COLLECTION, STORAGE, ANALYSIS, AND REPORTING SYSTEMS FOR DIETARY IMAGES 'TITLE: THE MOBILE FOOD INTAKE PHOTO STORAGE & ANALYSIS SYSTEM. PERFORMANCE PERIOD 09/16/ This proposal describes enhancements to Viocare’s Mobile Food Intake Visual and Voice Recognizer (FIVR)  System, a novel combination of innovative technologies including computer vision and speech recognition to  measure dietary intake using a mobile phone. FIVR uses a mobile phone’s camera to capture a short video  of foods to be consumed, which is then verbally-annotated on the mobile phone by the user. These video  and audio files are processed through a real-time backend server speech and image recognition engine for  food recognition and portion size measurement. This project will extend FIVR’s capabilities to analyze more  foods, enhance the analysis and reporting tools, expand system support tools, and develop interfaces to a  diverse set of clinical and research systems. A final evaluation of the FIVR system will be conducted at The  Ohio State University to assess the usability and accuracy of food intake tracking with a group of 100 freeliving  subjects, comparing 4 days of FIVR food intake data to 4 days of 24 hour recalls collected using  ASA24 data. The resulting FIVR product will be a unique food intake tracker that combines selfadministration,  automation (vision), and backend coding to collect food intake records to generate a detailed  nutritional analysis. n/a","HHSN261201400054C; TOPIC 308 AUTOMATED COLLECTION, STORAGE, ANALYSIS, AND REPORTING SYSTEMS FOR DIETARY IMAGES 'TITLE: THE MOBILE FOOD INTAKE PHOTO STORAGE & ANALYSIS SYSTEM. PERFORMANCE PERIOD 09/16/",8947304,61201400054C,"['Architecture', 'Automation', 'Car Phone', 'Clinical Research', 'Code', 'Collection', 'Computer Vision Systems', 'Computerized Medical Record', 'Data', 'Databases', 'Diet', 'Dietary intake', 'Eating', 'Evaluation', 'Food', 'Health', 'Hour', 'Image', 'Individual', 'Location', 'Measurement', 'Measures', 'Methods', 'Nutritional', 'Ohio', 'Output', 'Patients', 'Performance', 'Procedures', 'Process', 'Records', 'Reporting', 'Research Personnel', 'Speech', 'Support System', 'System', 'Systems Analysis', 'Time', 'Universities', 'Vision', 'Visual', 'Voice', 'innovative technologies', 'mobile application', 'novel', 'speech recognition', 'tool', 'usability']",NCI,"VIOCARE, INC.",N44,2014,1000000,-0.0017983893352244433
"Providing Access to Appliance Displays for Visually Impaired Users     DESCRIPTION (provided by applicant):  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays.  This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment.  No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents.  Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image.  For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast.  These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view.  Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users.  Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures.  The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software.         PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.",Providing Access to Appliance Displays for Visually Impaired Users,8712492,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype', 'public health relevance']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2014,368560,0.024152388298734
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus     DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community.         PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.            ",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8761698,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'prognostic', 'public health relevance', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2014,314327,0.07784596298558623
"In-field FAST Procedure Support and Automation     DESCRIPTION (provided by applicant): The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound examination performed to identify intra-peritoneal hemorrhage or pericardial tamponade. FAST involves the detection of free fluid in ultrasound images from four specific abdominal areas. Unstable patients with positive FAST results are operated on, and stable patients with negative results tend to be observed.  We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life-saving FAST procedures. The proposed system will consist of a low-cost ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an intuitive application. Using that system, a novice operator will be visually guided to acquire ultrasound images from the abdominal locations and quantify the free fluid in those images.  The target for our initial deployment of the system is level 3 and 4 trauma centers. These centers must often serve areas spanning hundreds and even thousands of miles; however, they are typically under-staffed and under-equipped.  The proposal is being clinically driven by Jeffrey Lowell, MD. He is a USNR Trauma Surgeon, and he was recently deployed to Landstuhl Regional Medical Center, the only Level I Trauma Center outside the U.S.         PUBLIC HEALTH RELEVANCE: The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound-based examination for rapidly detecting blood in the abdomen, particularly after blunt abdominal trauma, which is common, for example, with car accidents. The challenge is that the FAST procedure requires expertise and equipment which is not commonly available at level 3 and 4 trauma centers that serve rural populations. We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life- saving FAST procedures. The proposed system will consist of a low-cost, hand-held ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an easy-to-follow software application.            ",In-field FAST Procedure Support and Automation,8652454,R43EB016621,"['Abdomen', 'Abdominal Injuries', 'Accidents', 'Address', 'Age', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Blood', 'Businesses', 'Caring', 'Cause of Death', 'Cessation of life', 'Computer Vision Systems', 'Computer software', 'Conduct Clinical Trials', 'Custom', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Doctor of Medicine', 'Environment', 'Equipment', 'Evaluation', 'FDA approved', 'Funding', 'Hand', 'Hemoperitoneum', 'Hemorrhage', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imagery', 'Injury', 'Kidney', 'Life', 'Liquid substance', 'Location', 'Medical', 'Medical center', 'Methods', 'Military Personnel', 'Morbidity - disease rate', 'Nurses', 'Operating Rooms', 'Organ Harvestings', 'Organ Procurements', 'Patients', 'Pediatric Hospitals', 'Pelvis', 'Pericardial body location', 'Persons', 'Phase', 'Physical Examination', 'Physics', 'Population', 'Positioning Attribute', 'Procedures', 'Publishing', 'Research', 'Running', 'Rural', 'Rural Population', 'Surgeon', 'System', 'Systems Integration', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Time', 'Training', 'Transplant Surgeon', 'Trauma', 'Ultrasonography', 'Uncompensated Care', 'Universities', 'Washington', 'Work', 'base', 'cost', 'emergency service responder', 'experience', 'follower of religion Jewish', 'health disparity', 'imaging Segmentation', 'innovation', 'medical schools', 'mortality', 'novel', 'pericardial sac', 'prototype', 'public health relevance', 'tool', 'trauma centers']",NIBIB,"KITWARE, INC.",R43,2014,195709,0.032941509272418054
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization     DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care.         PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.            ",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8601692,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy', 'Biopsy Specimen', 'Breast', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'public health relevance', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,623127,0.03453144130597061
"Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography  Project Summary/Abstract  Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease by imaging the left ventricle (LV) of the heart at rest and then after either exercise or pharmacologically-induced stress to reveal ischemia. However, acquisitions are heavily operator dependent, two-dimensional (2D), and interpretation is generally based on qualitative assessment. While a variety of quan- titative 2D approaches have been proposed in the research literature, none have been shown to be superior to the still highly variable qualitative visual comparison of rest/stress echocardiographic image sequences for detecting ischemic disease. Here, we propose that the way forward must focus on a new computational im- age analysis paradigm for quantitative 4D (three spatial dimensions plus time) stress echocardiography. Our strategy integrates information derived from both radiofrequency (RF) and B-mode echocardiographic images acquired using a matrix array probe. The integrated analysis system will yield accurate and robust measures of strain and strain rate - at rest, stress and differentiallly between rest and stress - that will identify my- ocardial tissue at-risk after dobutamine-induced stress. This work will involve the development of novel (1) phase-sensitive, correlation-based RF ultrasound speckle tracking to estimate mid-wall displacements, (2) ma- chine learning techniques to localize the LV bounding surfaces and their displacements from B-mode data, (3) a meshless integration approach based on radial basis functions (RBFs) and Bayesian reasoning/sparse coding to estimate dense spatiotemporal parameters of strain and strain rate and (4) non-rigid registration of rest and stress image sequences to develop unique, 3D differential deformation parameters. The quantitative approach will be validated with implanted sonomicrometers and microsphere-derived flows using an acute canine model of stenosis. The ability of deformation and differential deformation derived from 4D stress echocardiography to detect new myocardial tissue at-risk in the presence of existing infarction will then be determined in a hybrid acute/chronic canine model of infarction with superimposed ischemia. The technique will be translated to hu- mans and evaluated by measuring the reproducibility of our deformation and differential deformation parameters in a small cohort of subjects. Three main collaborators will team on this work. A group led by Matthew O'Donnell from the University of Washington will develop the RF-based speckle tracking methods. An image analysis group led by the PI James Duncan at Yale University will develop methods for segmentation, shape tracking, dense displacement integration and strain computation. A cardiology/physiology group under Dr. Albert Sinusas at Yale will perform the acute and chronic canine studies and the human stress echo studies. A consultant from Philips Medical Systems will work with the entire team to bridge the ultrasound image acquisition technology. PUBLIC HEALTH RELEVANCE: The detection and diagnosis of coronary artery disease are commonly performed using stress echocardiography, a test that is performed 3 million times in the United States annually. Our new methods will enable the accurate and robust quantification of changes in myocardial deformation in 4D (three spatial dimensions over time) due to stress using a cost efficient and noninvasive imaging technology. The resulting methodology may lead to more sensitive and accurate detection of stress-induced ischemia that will better guide clinical decision making.            ",Integrated RF and B-mode Deformation Analysis for 4D Stress Echocardiography,8614454,R01HL121226,"['Acute', 'Autopsy', 'Bayesian Modeling', 'Canis familiaris', 'Cardiology', 'Chest', 'Chronic', 'Clinical', 'Code', 'Collection', 'Coronary Arteriosclerosis', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diastole', 'Dictionary', 'Dimensions', 'Disease', 'Dobutamine', 'Dose', 'Echocardiography', 'Exercise', 'Four-Dimensional Echocardiography', 'Frequencies', 'Heart', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Implant', 'Infarction', 'Ischemia', 'Lead', 'Learning', 'Left', 'Left ventricular structure', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motion', 'Myocardial', 'Myocardial Ischemia', 'Myocardial tissue', 'Patients', 'Perfusion', 'Phase', 'Physiology', 'Plague', 'Process', 'Radial', 'Radio', 'Reader', 'Reporting', 'Reproducibility', 'Research', 'Resolution', 'Rest', 'Risk', 'Shapes', 'Signal Transduction', 'Stenosis', 'Stress', 'Stress Echocardiography', 'Surface', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'United States', 'Universities', 'Ventricular', 'Visual', 'Washington', 'Work', 'base', 'clinical decision-making', 'cohort', 'cost effective', 'cost efficient', 'data integration', 'elastography', 'in vivo', 'novel', 'novel strategies', 'public health relevance', 'radiofrequency', 'single photon emission computed tomography', 'spatiotemporal', 'two-dimensional']",NHLBI,YALE UNIVERSITY,R01,2014,819740,0.015540060348852053
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8737899,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,335356,0.09588428593059224
"Computational Image Analysis for Cellular and Developmental Biology     DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. !         PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.             ",Computational Image Analysis for Cellular and Developmental Biology,8414506,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'public health relevance', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2013,59383,0.00018309780100937576
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8522756,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2013,150000,0.04382720934963616
"Automated retinopathy of prematurity classification using machine learning  Project Summary/Abstract The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH- funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi- disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing. PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.                 ",Automated retinopathy of prematurity classification using machine learning,8445584,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2013,283543,0.04274425740148528
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.         PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8466969,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'public health relevance', 'screening', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2013,1,0.012337377951297034
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8402395,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,301051,0.037395560776333374
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8522304,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2013,216041,0.0773149690889866
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex. We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning. To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support: First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management. Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices. Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements. These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8479372,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,474880,0.07863278280036545
"3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema     DESCRIPTION (provided by applicant): Currently, the clinical assessment of optic nerve swelling is limited by the subjective ophthalmoscopic evaluation by experts in order to diagnose and differentiate the cause of the optic disc edema. The long-term goal of our research effort is to develop automated 3D image-analysis approaches for the identification of an optimal set of 3D parameters to quantify the severity of optic nerve edema over time and to help differentiate the underlying cause. The overall objective in this application is to develop strategies, using spectral-domain optical coherence tomography (SD-OCT), to rapidly and accurately determine the severity of optic nerve swelling in patients diagnosed with papilledema and to ascertain morphological features that differentiate papilledema from other disorders causing optic nerve edema. The central hypothesis is that information about volumetric and shape parameters obtainable from 3D image analysis techniques will improve the ability to accurately assess the severity and cause of optic disc edema over the existing subjective ophthalmoscopic assessment of optic nerve swelling using the Fris¿n scale or current 2D OCT parameters. The rationale for the proposed research is that having such 3D parameters will dramatically improve the way optic disc swelling is assessed. The following specific aims will be pursued: 1. Develop and evaluate the methodology for computing novel volumetric and shape parameters of a swollen optic nerve head from SD-OCT. This will be completed by refining and evaluating our novel 3D graph-based segmentation algorithms in SD-OCT volumes of patients with optic disc swelling. 2. Identify SD-OCT parameters that optimally correlate with clinical measurements of severity in patients with papilledema and develop a continuous severity scale. This will be accomplished by using machine-learning approaches to relate SD-OCT parameters to expert-defined Fris¿n scale grades (a fundus-based measure of severity). It is anticipated that volumetric 3D parameters will more closely correlate with clinical measures than 2D parameters and will provide a continuous severity scale. 3. Identify SD-OCT parameters that differentiate papilledema from other causes of optic disc swelling (or apparent optic disc swelling, as in pseudopapilledema) and develop a corresponding predictive classifier. Our working hypothesis is that 3D shape parameters, especially those near Bruch's membrane opening, will contribute the most in the automatic differentiation process. The approach is innovative because the 3D image-analysis methodology developed by the applicants enables novel determination of 3D volumetric and shape parameters and represents a significant improvement over the status quo of using qualitative image information and 2D OCT image information for assessing optic disc swelling. The proposed research is significant because it will help to establish a much-needed alternative and more objective method by which to assess the severity and cause of optic disc swelling.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because the identification of novel spectral-domain optical coherence tomography parameters for assessing the severity and cause of optic nerve edema is expected to enable more efficient and effective diagnosis and management strategies of patients with such swelling. Thus, the proposed research is relevant to the part of NIH's mission that pertains to developing fundamental knowledge to reduce the burdens of disability and is particularly relevant to the part of NEI's mission regarding understanding blinding eye diseases and preserving sight.                ",3D Image Analysis Approach to Determine Severity and Cause of Optic Nerve Edema,8477880,R01EY023279,"['Acute', 'Algorithms', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Clinical', 'Clinical assessments', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Dimensions', 'Disease', 'Early Diagnosis', 'Edema', 'Evaluation', 'Eye diseases', 'Fundus', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Intracranial Hypertension', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mission', 'Modality', 'Monitor', 'Nerve Fibers', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Papilledema', 'Patients', 'Process', 'Public Health', 'Relative (related person)', 'Research', 'Resolution', 'Severities', 'Shapes', 'Staging', 'Structure', 'Swelling', 'Techniques', 'Testing', 'Thick', 'Three-Dimensional Image', 'Time', 'Vision', 'Work', 'base', 'cost', 'digital', 'disability burden', 'expectation', 'improved', 'innovation', 'instrument', 'novel', 'optic nerve disorder', 'public health relevance']",NEI,UNIVERSITY OF IOWA,R01,2013,339750,0.023850800325104685
"Automatic 3D Quantification of Synapse Distribution in Complex Dendritic Arbor     DESCRIPTION (provided by applicant): The subcellular distribution of synapses is critical for the assembly, function, and plasticity of the nervous system and plays a role in its disorders. Underlying molecular mechanisms, however, remain largely unknown. While advanced multidimensional images, in conjunction with single-cell genetic techniques, have afforded an unprecedented opportunity to understand synapse development at a new level, there is a knowledge gap in our capacity to effectively quantify subcellular synapses from large quantities of three-dimensional images. This is a significant problem and has hampered large-scale studies of the molecular mechanisms of synapse development, especially in neurons with complex arbor-such as Purkinje cells in mammals and lobula plate tangential cells (LPTC) in Drosophila-where existing approaches do not yield complete or robust synapse quantification for the entire dendritic tree and do not scale to efficient genetic screening. The objective of thi project is to bridge this gap by providing tools for quantitative investigation of subcellular synapse distribution and its molecular mechanisms using three-dimensional microscopy images. Specifically, our highly cross- disciplinary team will pursue two aims: (1) Develop automatic algorithms to analyze and quantify synapse distribution in the entire dendritic tree of neurons with complex arbor. Holistic and objective description of synapse density will enable automatic detection of mutant patterns. (2) Develop automatic algorithms to analyze and quantify synapse distribution in different parts of the entire dendritic tree of neurons with complex arbor. Efficient quantification at distinct subcellular locations will assist discovery of novel regulators for different subcellular parts. As a test case, we will use synapse distribution n Drosophila LPTC neurons, which are amenable to both genome-wide genetic screens and genetic manipulations with single-neuron resolution. We will develop reliable methods to characterize the density of inhibitory GABAergic and excitatory cholinergic synapses from three-dimensional fluorescence confocal images. Our algorithms will lead to the next level of mechanistic understanding that controls the subcellular distribution of inhibitory and excitatory synapses, and enable a wide range of quantitative analyses for other types of neurons with similar complexity. Powerful multichannel co-analysis and machine learning approaches will be used to improve synapse detection and subcellular compartment extraction for overcoming challenges in 3D confocal image, including staining artifacts and anisotropic resolution. Algorithms will be developed using a model-guided methodology that emphasizes efficiency for large volume 3D images during genetic screening. Pattern-recognition methods will be used to speed up proofreading of the synapse quantification results. A novel ordering strategy will be adapted for neurons of complex dendritic arbor to quantify subcellular synapses in a functionally meaningful way. The project will produce a set of open-source, extensible tools for automatic synapse quantification and proofreading, with friendly graphical-user interfaces, to serve the neuroscience community.         PUBLIC HEALTH RELEVANCE: The underlying molecular mechanisms for the subcellular distribution of synapses remain largely unknown, which hinders the discovery of novel therapies for many neurological disorders. By developing new, efficient automatic algorithms and open-source tools for quantifying synapses in neurons, this research intends to advance the capacity to effectively analyze large quantities of three-dimensional neuronal images, especially those of complex dendritic arbor. The work will impact public health by enabling a better understanding of disease mechanisms, which is the critical first step toward new treatments, and supports NIH's goal to advance understanding of fundamental biology to uncover the causes of specific diseases.            ",Automatic 3D Quantification of Synapse Distribution in Complex Dendritic Arbor,8574710,R15MH099569,"['Academic Research Enhancement Awards', 'Algorithms', 'Area', 'Biology', 'Cells', 'Collaborations', 'Communities', 'Complex', 'Data', 'Dendrites', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Excitatory Synapse', 'Fluorescence', 'Generations', 'Genetic', 'Genetic Screening', 'Genetic Techniques', 'Goals', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'Inhibitory Synapse', 'Investigation', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Mammals', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Modeling', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Nervous system structure', 'Neurons', 'Neurosciences', 'Pattern', 'Pattern Recognition', 'Play', 'Public Health', 'Purkinje Cells', 'Pyramidal Cells', 'Research', 'Resolution', 'Role', 'Speed', 'Staging', 'Staining method', 'Stains', 'Surface', 'Synapses', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Trees', 'Variant', 'Work', 'base', 'cholinergic synapse', 'density', 'falls', 'genetic manipulation', 'genome-wide', 'graduate student', 'graphical user interface', 'high throughput technology', 'improved', 'in vivo', 'innovation', 'interdisciplinary approach', 'mutant', 'nervous system disorder', 'novel', 'open source', 'public health relevance', 'tool', 'undergraduate student', 'user-friendly']",NIMH,NORTHERN ILLINOIS UNIVERSITY,R15,2013,461165,0.017217999201086003
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    The technology developed as part of this NIH SBIR project will transform the cell phone camera of visually impaired individuals into a powerful tool capable of identifying the objects they encounter, track the items they own, or navigate complex new environments. Broad access to low-cost visual intelligence technologies developed in this project will improve the independence and capabilities of the visually impaired. There has been tremendous technological progress in computer vision and in the computational power and network bandwidth of and Smartphone platforms. The synergy of these advances stands to revolutionize the way people find information and interact with the physical world. However, these technologies are not yet fully in the hands of the visually impaired, arguably the population that could benefit the most from these developments. Part of the barrier to progress in this area has been that computer vision can accurately handle only a small fraction of the typical images coming from a cell phone camera. To cope with these limitations and make any-image recognition possible, IQ Engines will develop a hybrid system that uses both computer vision and crowdsourcing: if the computer algorithms are not able to understand an image, then the image is sent to a unique crowdsourcing network of people for image analysis. The proposed research includes specific aims to both develop advanced computer vision algorithms for object recognition and advanced crowdsourced networks optimized to the needs of the visually impaired community. This approach combines the speed and accuracy of computer vision with the robustness and understanding of human vision, ultimately providing the user fast and accurate information about the content of any image.           The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.            ",Mobile Search for the Visually Impaired,8389864,R44EY019790,"['Address', 'Algorithms', 'Area', 'Car Phone', 'Cellular Phone', 'Classification', 'Client', 'Clip', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Crowding', 'Data', 'Databases', 'Detection', 'Development', 'Devices', 'Ensure', 'Environment', 'Family', 'Feedback', 'Friends', 'Glosso-Sterandryl', 'Human', 'Hybrid Computers', 'Hybrids', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Location', 'Modeling', 'Monitor', 'Phase', 'Population', 'Preparation', 'Process', 'Quality of life', 'Research', 'Running', 'Scanning', 'Services', 'Small Business Innovation Research Grant', 'Social Network', 'Source', 'Speed', 'System', 'Technology', 'Telephone', 'Time', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual impairment', 'base', 'blind', 'cell transformation', 'coping', 'cost', 'improved', 'innovation', 'novel', 'object recognition', 'open source', 'sensor', 'tool', 'visual information', 'visual search', 'volunteer']",NEI,"IQ ENGINES, INC.",R44,2013,499358,0.03837382668615962
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8599843,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,224942,0.04902484251160673
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8599834,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2013,249999,0.02740824467126123
"Providing Access to Appliance Displays for Visually Impaired Users  Providing Access to Appliance Displays for Visually Impaired Users Summary The goal of this project is to develop a computer vision system that runs on smartphones and tablets to enable blind and visually impaired persons to read appliance displays. This ability is increasingly necessary to use a variety of household and commercial appliances equipped with displays, such as microwave ovens and thermostats, and is essential for independent living, education and employment. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed system runs as software on a standard, off-the-shelf smartphone or tablet and uses computer vision algorithms to analyze video images taken by the user and to detect and read the text within each image. For blind users, this text is either read aloud using synthesized speech, or for low vision users, presented in magnified, contrast- enhanced form (which is most suited to the use of a tablet).  We propose to build on our past work on a prototype display reader using powerful new techniques that will enable the resulting system to read a greater variety of LED/LCD display text fonts, and to better accommodate the conditions that often make reading displays difficult, including glare, reflections and poor contrast. These techniques include novel character recognition techniques adapted specifically to the domain of digital displays; finger detection to allow the user to point to a specific location of interest in the display; the use of display templates as reference images to match to, and thereby help interpret, noisy images of displays; and the integration of multiple views of the display into a single clear view. Special user interface features such as the use of finger detection to help blind users aim the camera towards the display and contrast-enhancement for low vision users address the particular needs of different users. Blind and visually impaired subjects will test the system periodically to provide feedback and performance data, driving the development and continual improvement of the system, which will be assessed with objective performance measures. The resulting display reader system will be released as an app for smartphones and tablets that can be downloaded and used by anybody for free, and also as an open source project that can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self-sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays.  The proposed research would result in a smartphone/tablet-based assistive technology system (available for free) to provide increased access to such display information for the approximately 10 million Americans with significant vision impairments or blindness.                ",Providing Access to Appliance Displays for Visually Impaired Users,8579051,R01EY018890,"['Access to Information', 'Address', 'Adoption', 'Algorithms', 'American', 'Automobile Driving', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Detection', 'Development', 'Devices', 'Economics', 'Education', 'Employment', 'Evaluation', 'Feedback', 'Fingers', 'Glare', 'Goals', 'Hand', 'Home environment', 'Household', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging problem', 'Impairment', 'Independent Living', 'Location', 'Mainstreaming', 'Measures', 'Movement', 'Performance', 'Prevalence', 'Printing', 'Procedures', 'Reader', 'Reading', 'Research', 'Research Infrastructure', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'System', 'Tablets', 'Techniques', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'consumer product', 'design', 'digital', 'improved', 'information display', 'interest', 'microwave electromagnetic radiation', 'novel', 'open source', 'optical character recognition', 'prototype', 'public health relevance']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2013,376082,0.023918208845212136
"In-field FAST Procedure Support and Automation     DESCRIPTION (provided by applicant): The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound examination performed to identify intra-peritoneal hemorrhage or pericardial tamponade. FAST involves the detection of free fluid in ultrasound images from four specific abdominal areas. Unstable patients with positive FAST results are operated on, and stable patients with negative results tend to be observed.  We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life-saving FAST procedures. The proposed system will consist of a low-cost ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an intuitive application. Using that system, a novice operator will be visually guided to acquire ultrasound images from the abdominal locations and quantify the free fluid in those images.  The target for our initial deployment of the system is level 3 and 4 trauma centers. These centers must often serve areas spanning hundreds and even thousands of miles; however, they are typically under-staffed and under-equipped.  The proposal is being clinically driven by Jeffrey Lowell, MD. He is a USNR Trauma Surgeon, and he was recently deployed to Landstuhl Regional Medical Center, the only Level I Trauma Center outside the U.S.         PUBLIC HEALTH RELEVANCE: The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound-based examination for rapidly detecting blood in the abdomen, particularly after blunt abdominal trauma, which is common, for example, with car accidents. The challenge is that the FAST procedure requires expertise and equipment which is not commonly available at level 3 and 4 trauma centers that serve rural populations. We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life- saving FAST procedures. The proposed system will consist of a low-cost, hand-held ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an easy-to-follow software application.            ",In-field FAST Procedure Support and Automation,8472102,R43EB016621,"['Abdomen', 'Abdominal Injuries', 'Accidents', 'Address', 'Age', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Blood', 'Businesses', 'Caring', 'Cause of Death', 'Cessation of life', 'Computer Vision Systems', 'Computer software', 'Computers', 'Conduct Clinical Trials', 'Custom', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Doctor of Medicine', 'Environment', 'Equipment', 'Evaluation', 'FDA approved', 'Funding', 'Hand', 'Hemoperitoneum', 'Hemorrhage', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imagery', 'Injury', 'Kidney', 'Life', 'Liquid substance', 'Location', 'Medical', 'Medical center', 'Methods', 'Military Personnel', 'Morbidity - disease rate', 'Nurses', 'Operating Rooms', 'Organ Harvestings', 'Organ Procurements', 'Patients', 'Pediatric Hospitals', 'Pelvis', 'Pericardial body location', 'Persons', 'Phase', 'Physical Examination', 'Physics', 'Population', 'Positioning Attribute', 'Procedures', 'Publishing', 'Research', 'Running', 'Rural', 'Rural Population', 'Surgeon', 'System', 'Systems Integration', 'Tablets', 'Technology', 'Testing', 'Time', 'Training', 'Transplant Surgeon', 'Trauma', 'Ultrasonography', 'Uncompensated Care', 'Universities', 'Washington', 'Work', 'base', 'cost', 'emergency service responder', 'experience', 'follower of religion Jewish', 'health disparity', 'imaging Segmentation', 'innovation', 'medical schools', 'mortality', 'novel', 'pericardial sac', 'prototype', 'public health relevance', 'tool', 'trauma centers']",NIBIB,"KITWARE, INC.",R43,2013,200000,0.032941509272418054
"Perception of Tactile Graphics    DESCRIPTION (provided by applicant): The broad objective of the proposed research is to answer the following question: why are tactile graphics difficult to understand? People with normal vision can easily recognize line drawings of objects. However, both blind and sighted people find it very difficult to recognize the same drawings when they are presented as tactile images. For blind people, tactile graphics are the only solution for accessing information in visual diagrams and illustrations found in textbooks. Consequently, the results of the proposed research will be used to improve the production of tactile graphics so that they are better understood by blind people. The specific aims of this project are to: 1) explore how the complexity of tactile images affects perception, 2) determine the effects of spatial and temporal integration on perception of tactile images, and 3) investigate how well people can recognize tactile images of objects embedded in backgrounds. The general methodology of the proposed experiments is to present participants with tactile images and to have them draw what they perceive the images to be. Blind individuals will draw tactile images using special paper and a stylus. The experimenters will evaluate the drawings by using a quantitative measure that computes a distance score reflecting the discrepancy between the original image and the participant's drawing. In the first study, participants will feel tactile stimuli of varying complexity, from simple lines in different orientations to complex depictions of objects. The second study will determine the limitations of tactile perceptual integration by limiting either the spatial or temporal window over which participants feel the image. Participants will either view or feel images through apertures of various sizes (spatial window) or they will have a limited amount of time to view or feel the images (temporal window). In the third study, participants will feel tactile images of objects embedded in simple backgrounds. This research will impact several areas of study, including computer vision, human object and scene recognition, and low vision rehabilitation.       PUBLIC HEALTH RELEVANCE: Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.            ",Perception of Tactile Graphics,8417005,F32EY019622,"['Affect', 'Area', 'Categories', 'Child', 'Complex', 'Computer Vision Systems', 'Development', 'Devices', 'Disadvantaged', 'Education', 'Elements', 'Goals', 'Grouping', 'Human', 'Image', 'India', 'Individual', 'Link', 'Measures', 'Methodology', 'Methods', 'Names', 'Nature', 'Paper', 'Participant', 'Perception', 'Population', 'Production', 'Psychophysics', 'Rehabilitation therapy', 'Research', 'Science', 'Sensory', 'Services', 'Shapes', 'Solutions', 'Stimulus', 'Swelling', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Vision', 'Visual', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'blind', 'braille', 'improved', 'object recognition', 'public health relevance', 'research study', 'sight for the blind', 'skills', 'tactile vision substitution system', 'two-dimensional', 'vision development', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2013,53942,0.06479590852711657
"Digital Pathology_Accuracy Viewing Behavior and Image Characterization     DESCRIPTION (provided by applicant): Approximately 1.4 million women per year depend on pathologists to accurately interpret breast biopsies for a diagnosis of benign disease or cancer. Diagnostic errors are alarmingly frequent and likely lead to altered patient treatment, especially at the thresholds of atypical hyperplasia and ductal carcinoma in situ, where up to 50% of cases are misclassified. The causes underlying these errors remain largely unknown.  Technology similar to Google Maps now allows pan and zoom manipulation of high-resolution digital images of glass microscope slides. This technology has virtually replaced the microscope in medical schools and is rapidly diffusing into U.S. pathology practices. No research has evaluated the accuracy and efficiency of pathologists' interpretion of digital images vs. glass slides. However, these ""digital slides"" offer a novel opportunity to study the accuracy, efficiency, and viewing behavior of a large number of pathologists as they manipulate and interpret images. The innovative analytic techniques proposed in this application are similar to those used to improve the performance of pilots and air traffic controllers. Our specific aims are: Aim 1. Digital Image vs. Glass Slides: To compare the interpretive accuracy of pathologists viewing digitized slide images over the Internet to their performance viewing original glass slides under a microscope. A randomized national sample of pathologists (N=200) will interpret 240 test cases in one or both formats in two phases. Measures will include a diagnostic assessment for each test case and for digital slides, cursor- (i.e., mouse) tracking data and region of interest (ROI) markings. Completion of this aim will establish benchmarks for the comparative diagnostic accuracy of whole-slide digital images.  Aim 2. Interpretive Screening Behavior: To identify visual scanning patterns associated with diagnostic accuracy and efficiency. Detailed simultaneous eye-tracking and cursor-tracking data will be collected on 60 additional pathologists while they interpret digital slides to complement data from Aim 1. Viewing patterns will be analyzed from computer representations of raw movement data. Videos depicting accurate, efficient visual scanning and cursor movement will be valuable tools in educating the next generation of digital pathologists. Aim 3. Image Analyses: To examine and classify the image characteristics (including color, texture, and structure) of ROIs captured in Aims 1 and 2. Computer-based statistical learning techniques will be used to identify image characteristics that lead to correct and incorrect diagnoses. Characteristics of both diagnostic and distracting ROIs will be identified, linking all three aims. In summary, we will determine whether digitized whole-slide images are diagnostically equivalent to original glass slides. Our in-depth scientific evaluation of viewing patterns and characteristics of ROIs identified by pathologists will be critical to understanding diagnostic errors and sources of distraction. Optimization of viewing techniques will improve diagnostic performance and thus, the quality of clinical care.         PUBLIC HEALTH RELEVANCE: Pathologist errors in the interpretation of biopsy specimens can result in significant harm to patients. Digital imaging technology is rapidly diffusing into medical settings, providing a unique opportunity to obtain data on the process used by pathologists when interpreting slides. The results will provide the foundation needed to improve interpretive accuracy and efficiency, support quality improvement efforts, and ultimately reduce the burden of misdiagnosis on patients and the health care delivery system.            ",Digital Pathology_Accuracy Viewing Behavior and Image Characterization,8420220,R01CA172343,"['Adoption', 'Air', 'Archives', 'Area', 'Attention', 'Atypical hyperplasia', 'Behavior', 'Benchmarking', 'Benign', 'Biopsy', 'Biopsy Specimen', 'Breast', 'Characteristics', 'Clinical', 'Color', 'Communities', 'Community Hospitals', 'Comparative Study', 'Complement', 'Complex', 'Computers', 'Data', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diffuse', 'Disease', 'Ensure', 'Error Sources', 'Eye', 'Foundations', 'Glass', 'Goals', 'Gold', 'Histopathology', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Internet', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Medical Errors', 'Methods', 'Microscope', 'Microscopic', 'Movement', 'Mus', 'Noninfiltrating Intraductal Carcinoma', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Process', 'Randomized', 'Recommendation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Rural', 'Rural Hospitals', 'Sampling', 'Scanning', 'Scientific Evaluation', 'Slide', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Time', 'Training', 'Visit', 'Visual', 'Woman', 'base', 'clinical care', 'comparative', 'computer monitor', 'diagnosis standard', 'diagnostic accuracy', 'digital', 'digital imaging', 'distraction', 'eye hand coordination', 'health care delivery', 'improved', 'innovation', 'innovative technologies', 'interest', 'medical schools', 'migration', 'new technology', 'next generation', 'novel', 'public health relevance', 'sample fixation', 'screening', 'tool', 'trafficking', 'transmission process']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,682340,0.03453144130597061
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.        The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8383103,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2013,222916,0.002827700732613552
"Spatially Accurate Deformable Image Registration for Thoracic C Applications    DESCRIPTION (Provided by the applicant)   Abstract:  Deformable image registration (DIR) is a cross-cutting technology with diagnostic and therapeutic medical applications. DIR algorithms were first developed in computer vision research to estimate motion between a source and target image, the resulting registered image visually appears similar to the target image. For medical applications the goal in applying DIR is to obtain an accurate spatial registration of the underlying anatomy and not simply image similarity. We developed a statistical framework for quantitative evaluation of DIR spatial accuracy based on large samples of expert-determined landmark features. Central to this framework is the statistical relationship between the number of landmark points required to assess spatial accuracy, the desired uncertainty range of the mean error, and an a priori estimated behavior of the DIR. DIR is at the heart of our strategy to quantify COPD small airway disease air-trapping and four dimensional computed tomography (4D CT) ventilation. The optimal DIR algorithm and its spatial accuracy in registering the underlying anatomy should be assessed for each application. We will develop and test new DIR algorithms for exhale and inhale breath-hold CT (eBH-CT & iBH-CT) images pairs (COPD air trapping evaluation) and for 4D CT images (4D CT ventilation). Current CT image analysis methods for COPD evaluation focus on the separate anatomic evaluation of the eBH-CT & iBH-CT images. They are unable to find air-trapping due to bronchiolitis alone. We propose to evaluate the eBH- & iBH CT image pairs simultaneously using DIR to link the two to identify regions of air-trapping due to both emphysema and bronchiolitis. Next, to continue our development of ventilation imaging derived from 4D CT, we will test the ability of 4D CT ventilation image guidance to reduce pulmonary function loss after radiotherapy in a randomized phase II trial for non-small cell lung cancer patients.    Public Health Relevance:  This study will develop novel image registration methods and their application, with an emphasis on application specific validation. With this technology we will develop and test methods to find air-trapping in chronic obstructive pulmonary disease patients. We will test our novel ventilation imaging method in radiation treatment planning to reduce normal lung injury after treatment for lung cancer.      ",Spatially Accurate Deformable Image Registration for Thoracic C Applications,8558551,DP2OD007044,"['4D Imaging', 'Aftercare', 'Air', 'Algorithms', 'Anatomy', 'Behavior', 'Breathing', 'Bronchiolitis', 'Cancer Patient', 'Chest', 'Chronic Obstructive Airway Disease', 'Computers', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Exhalation', 'Four-dimensional', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Link', 'Malignant neoplasm of lung', 'Medical', 'Methods', 'Motion', 'Non-Small-Cell Lung Carcinoma', 'Patients', 'Phase II Clinical Trials', 'Pulmonary Emphysema', 'Quantitative Evaluations', 'Radiation', 'Radiation therapy', 'Randomized', 'Sampling', 'Source', 'Technology', 'Testing', 'Therapeutic', 'Uncertainty', 'Validation', 'Vision research', 'X-Ray Computed Tomography', 'abstracting', 'base', 'image registration', 'imaging modality', 'lung injury', 'novel', 'public health relevance', 'pulmonary function', 'small airways disease', 'treatment planning']",OD,UNIVERSITY OF TX MD ANDERSON CAN CTR,DP2,2013,201518,0.013692350115248155
"ENTROPY-BASED TISSUE DISCRIMINATORS No abstract available PUBLIC HEALTH RELEVANCE: All skilled clinical practitioners and interpreters of ultrasound studies realize that much information exists in recorded US images that is processed immediately by the visual cortex and is useful for qualitatively defining pathology, yet defies ready quantification by any robust algorithm. Traditional energy-based representations display grayscale intensities and speckle patterns that have been mapped parametrically into various tissue classification schemes that have yet to demonstrate organ or tissue specificity, although progress has been reported in distinguishing pathologies over the last 30 years. However, the fact that US signal processing and representation of backscatter data in terms of energy functions has not changed over the last 50 years suggests that alternative signal processing schemes may be indicated to represent the richness of the information contained within the backscattered data. To meet this challenge, we have been involved over the past 10 years in processing backscattered RF to create ""information"" images and in designing ""information sensitive"" approaches to classifying the data sets based on statistical analysis of these images These novel and user independent metrics utilize the entropy of windowed segments of radiofrequency (RF) backscatter signal from tis- sue, which represents a radical departure from grayscale or speckle metrics. In this approach the entropy of the backscattered segment is used to produce a pixel value in the tissue image. This processing strategy has proven to be sensitive to weak, sub-resolution sized changes in tissue.            ",ENTROPY-BASED TISSUE DISCRIMINATORS,8636638,R21EB018095,"['Address', 'Algorithms', 'Back', 'Base Composition', 'Bayesian Analysis', 'Cardiac', 'Classification', 'Classification Scheme', 'Clinical', 'Color', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffuse', 'Dimensions', 'Discrimination', 'Disease', 'Ensure', 'Entropy', 'Environment', 'Evaluation', 'Expeditions', 'Fatty Liver', 'Fibrosis', 'Fishes', 'Foundations', 'Fractals', 'Frequencies', 'Heart', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Ischemia', 'Joints', 'Kidney', 'Knowledge', 'Label', 'Liver', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Metric', 'Microscopic', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Physiological', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Prostate', 'Radio', 'Reporting', 'Resolution', 'Rodent', 'Scheme', 'Shapes', 'Signal Transduction', 'Specificity', 'Staining method', 'Stains', 'Stream', 'Structure', 'Testing', 'Time', 'Tissue Differentiation', 'Tissue Model', 'Tissues', 'Ultrasonic Transducer', 'Ultrasonics', 'Ultrasonography', 'Visual Cortex', 'Work', 'attenuation', 'base', 'computerized data processing', 'data reduction', 'design', 'detector', 'heart motion', 'indexing', 'meetings', 'n-dimensional', 'novel', 'public health relevance', 'radiofrequency', 'sound', 'tissue processing', 'vector']",NIBIB,WASHINGTON UNIVERSITY,R21,2013,228000,0.03166487823392117
"Multimodal image registration by proxy image synthesis No abstract available PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8614480,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,343798,0.06502764623871761
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.        PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.              Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8266132,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2012,199915,-0.00789671103209339
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8323502,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2012,234509,0.0773149690889866
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Public Health Relevance/Narrative Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8208036,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,311786,0.046308245218890175
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8274831,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,503268,0.0789623365173247
"Objective imaging-based assessment of smoking behavior from used filters    DESCRIPTION (provided by applicant): Accurate measurement of smoking behaviors and exposures may become critical as FDA implements its authority to regulate tobacco products, and in particular proposes product standards and considers approval of modified risk products. Recently, digital image analysis systems have been developed that can identify the blocking of filter vents on spent cigarette filters with high accuracy and can also estimate the degree of smoker compensation. There is strong potential for such digital imaging systems to unobtrusively infer a rich set of smoker topography variables as well as a smoker's exposure to toxins. The existing literature base on filter-based assays is growing and points to growing prominence and applicability of these approaches to important research questions. We propose to modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth- level cigarette smoke exposure by examining tar stains on cigarette filter butts. The Specific Aims are designed to provide rigorous evaluations of the utility of the systems, from establishing prediction equations using machine-smoked cigarettes to cross- validation in human-smoked samples against other established measures of mouth-level exposure. At the conclusion of this project, we plan to release a validated suite of software to the research community to support external verification of digital image analysis for smoking-related research.        Accurately and simply measuring smoking behavior and smoke exposure is important, and digital image analysis systems have been developed that can estimate smoke intake and identify the blocking of filter vents on spent cigarette filters. The proposed project will modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth-level cigarette smoke exposure. We plan to make a suite of software publicly available to allow others to apply this technology in their own research.               ",Objective imaging-based assessment of smoking behavior from used filters,8328891,R21CA160825,"['Biological Assay', 'Biological Markers', 'Cigarette', 'Communities', 'Computer software', 'Data Analyses', 'Equation', 'Evaluation', 'Exposure to', 'Financial compensation', 'Human', 'Image', 'Image Analysis', 'Intake', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Oral cavity', 'Patient Self-Report', 'Research', 'Risk', 'Sampling', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Smoking Behavior', 'Staining method', 'Stains', 'System', 'Systems Analysis', 'Tars', 'Technology', 'Testing', 'Tobacco', 'Toxin', 'Validation', 'Validity and Reliability', 'Vent', 'authority', 'base', 'cigarette smoking', 'cigarette smoking', 'design', 'digital imaging']",NCI,ROSWELL PARK CANCER INSTITUTE CORP,R21,2012,195788,0.02200791710795837
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    The technology developed as part of this NIH SBIR project will transform the cell phone camera of visually impaired individuals into a powerful tool capable of identifying the objects they encounter, track the items they own, or navigate complex new environments. Broad access to low-cost visual intelligence technologies developed in this project will improve the independence and capabilities of the visually impaired. There has been tremendous technological progress in computer vision and in the computational power and network bandwidth of and Smartphone platforms. The synergy of these advances stands to revolutionize the way people find information and interact with the physical world. However, these technologies are not yet fully in the hands of the visually impaired, arguably the population that could benefit the most from these developments. Part of the barrier to progress in this area has been that computer vision can accurately handle only a small fraction of the typical images coming from a cell phone camera. To cope with these limitations and make any-image recognition possible, IQ Engines will develop a hybrid system that uses both computer vision and crowdsourcing: if the computer algorithms are not able to understand an image, then the image is sent to a unique crowdsourcing network of people for image analysis. The proposed research includes specific aims to both develop advanced computer vision algorithms for object recognition and advanced crowdsourced networks optimized to the needs of the visually impaired community. This approach combines the speed and accuracy of computer vision with the robustness and understanding of human vision, ultimately providing the user fast and accurate information about the content of any image.      PUBLIC HEALTH RELEVANCE:    The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.                 The image recognition technology developed in this application will enable the visually impaired to access visual information using a mobile phone camera, a device most people already have. Transforming the camera into an intelligent visual sensor will lower the cost of assistance and improve the quality of life of the visually impaired community through increased independence and capabilities.            ",Mobile Search for the Visually Impaired,8198847,R44EY019790,"['Address', 'Algorithms', 'Area', 'Car Phone', 'Cellular Phone', 'Classification', 'Client', 'Clip', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Crowding', 'Data', 'Databases', 'Detection', 'Development', 'Devices', 'Ensure', 'Environment', 'Family', 'Feedback', 'Friends', 'Glosso-Sterandryl', 'Human', 'Hybrid Computers', 'Hybrids', 'Image', 'Image Analysis', 'Individual', 'Intelligence', 'Label', 'Learning', 'Location', 'Modeling', 'Monitor', 'Phase', 'Population', 'Preparation', 'Process', 'Quality of life', 'Research', 'Running', 'Scanning', 'Services', 'Small Business Innovation Research Grant', 'Social Network', 'Source', 'Speed', 'System', 'Technology', 'Telephone', 'Time', 'United States National Institutes of Health', 'Vision', 'Visual', 'Visual impairment', 'base', 'blind', 'cell transformation', 'coping', 'cost', 'improved', 'innovation', 'novel', 'object recognition', 'open source', 'sensor', 'tool', 'visual information', 'visual search', 'volunteer']",NEI,"IQ ENGINES, INC.",R44,2012,499358,0.02938705184790121
"OTHER FUNCTIONS SBIR TOPIC 308, PHASE I: THE MOBILE FOOD INTAKE PHOTO STORAGE AN This proposal describes plans to enhance Viocare¿s Mobile Food Intake Visual and Voice Recognizer (FIVR) System. FIVR, an active Genes, Environment and Health Initiative (GEI) project, is a novel combination of innovative technologies including computer vision and speech recognition to measure dietary intake using a mobile phone. Version 1 of FIVR uses a mobile phone¿s embedded camera to capture a short video of food to be consumed. The food to be eaten is annotated verbally on the mobile phone by the user. These video and audio files are sent to a backend server for real-time food recognition and portion size measurement through speech recognition and image analysis. This project will develop specifications to extend FIVR¿s capabilities to standardize, store, and analyze more diverse food images, such as 3D photos; to collect other food data; to enhance the analysis tools; and for interfaces to a variety of clinical/research systems. The FIVR Version 2 functional prototype will be developed to use 3D dietary images as input. A final evaluation of the FIVR V2 prototype will be conducted to assess the accuracy and feasibility of the 3D image diet capture with a group of 9 subjects in a controlled feeding study. n/a","OTHER FUNCTIONS SBIR TOPIC 308, PHASE I: THE MOBILE FOOD INTAKE PHOTO STORAGE AN",8554263,61201200042C,"['Car Phone', 'Clinical Research', 'Computer Vision Systems', 'Data', 'Diet', 'Dietary intake', 'Documentation', 'Eating', 'Environment', 'Evaluation', 'Food', 'Genes', 'Health', 'Image', 'Image Analysis', 'Measurement', 'Measures', 'Phase', 'Reporting', 'Small Business Innovation Research Grant', 'System', 'Three-Dimensional Image', 'Time', 'Visual', 'Voice', 'feeding', 'innovative technologies', 'novel', 'prototype', 'speech recognition', 'tool']",NCI,"VIOCARE, INC.",N43,2012,200000,0.009488484228100664
"Perception of Tactile Graphics    DESCRIPTION (provided by applicant): The broad objective of the proposed research is to answer the following question: why are tactile graphics difficult to understand? People with normal vision can easily recognize line drawings of objects. However, both blind and sighted people find it very difficult to recognize the same drawings when they are presented as tactile images. For blind people, tactile graphics are the only solution for accessing information in visual diagrams and illustrations found in textbooks. Consequently, the results of the proposed research will be used to improve the production of tactile graphics so that they are better understood by blind people. The specific aims of this project are to: 1) explore how the complexity of tactile images affects perception, 2) determine the effects of spatial and temporal integration on perception of tactile images, and 3) investigate how well people can recognize tactile images of objects embedded in backgrounds. The general methodology of the proposed experiments is to present participants with tactile images and to have them draw what they perceive the images to be. Blind individuals will draw tactile images using special paper and a stylus. The experimenters will evaluate the drawings by using a quantitative measure that computes a distance score reflecting the discrepancy between the original image and the participant's drawing. In the first study, participants will feel tactile stimuli of varying complexity, from simple lines in different orientations to complex depictions of objects. The second study will determine the limitations of tactile perceptual integration by limiting either the spatial or temporal window over which participants feel the image. Participants will either view or feel images through apertures of various sizes (spatial window) or they will have a limited amount of time to view or feel the images (temporal window). In the third study, participants will feel tactile images of objects embedded in simple backgrounds. This research will impact several areas of study, including computer vision, human object and scene recognition, and low vision rehabilitation.      PUBLIC HEALTH RELEVANCE: Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.              Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.",Perception of Tactile Graphics,8265243,F32EY019622,"['Affect', 'Area', 'Categories', 'Child', 'Complex', 'Computer Vision Systems', 'Development', 'Devices', 'Disadvantaged', 'Education', 'Elements', 'Goals', 'Grouping', 'Human', 'Image', 'India', 'Individual', 'Link', 'Measures', 'Methodology', 'Methods', 'Names', 'Nature', 'Paper', 'Participant', 'Perception', 'Population', 'Production', 'Psychophysics', 'Rehabilitation therapy', 'Research', 'Science', 'Sensory', 'Services', 'Shapes', 'Solutions', 'Stimulus', 'Swelling', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Vision', 'Visual', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'blind', 'braille', 'improved', 'object recognition', 'public health relevance', 'research study', 'sight for the blind', 'skills', 'tactile vision substitution system', 'two-dimensional', 'vision development', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2012,52190,0.06087255871009835
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.      PUBLIC HEALTH RELEVANCE: The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.           The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8227796,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2012,197444,0.009185534034425567
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis  Project Summary All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This proposal takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.  Project Narrative This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8300746,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2012,151744,0.03852319206450578
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8299311,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2011,239426,0.0773149690889866
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8022635,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,304318,0.046322601944267384
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,8142000,R01EY016093,"['Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Peripheral', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2011,1141143,0.026607741173521982
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8102722,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,458901,0.0789623365173247
"PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY    DESCRIPTION (provided by applicant): Well trained, experienced gastroenterologists in academic and high volume settings can reliably recognize 97% of pathologies in Capsule Endoscopy (CE) video. However, community physicians and infrequent users may miss up to 20%. The end goal of our proposed new line of research is to develop clinical software that provides automatic decision support to physicians who are trying to declare that a patient is pathology free or has a certain disease process. The risk for the physician - and their patients - is that of a less than optimal clinical outcome due to:  1) missing a lesion/pathology in the video and putting the patient at risk of developing a more serious condition over time, or  2) mistakenly ""identifying"" a pathology that is not present and thus subjecting the patient to unnecessary further diagnostic or surgical procedures.  The research aims in this proposal will enable Ikona to create a pathology prioritization image processing module. Implementing modern machine learning techniques such as Support Vector Machines (SVM) and Adaboost methodologies together with proprietary image feature analysis, this technology will assign a probability metric to every frame in the image sequence for specific pathology (lesions, ulcers, bleeding, etc) and the major landmarks in the GI tract (ileo-cecal valve, pyloric valve etc.). Filtering and sorting endoscopy image data will be done such that the images with the highest probability of containing pathology will be presented to the reviewer first.  This pathology prioritized sequencing is not intended to replace the clinician in the workflow, but rather to allow the clinician to focus more time on frames with a higher potential of containing pathology. Often times, clinically significant pathology may only be present in a single frame. A single ""pathological"" frame in the middle of a 50,000 frame sequence can easily be overlooked by a novice reviewer or a reviewer whose attention is temporarily distracted. With our proposed pathology prioritization, that single pathological frame will be identified and sorted near the beginning of the image sequence thus greatly increasing the likelihood of detection by the reviewer.  Specifically for Phase I, we plan to investigate and develop different algorithms for classifying image frames and recognizing pathological and normal frames, and, algorithms for ranking frames by severity of pathology. Following the implementation of a working prototype, we will further test the clinical utility of these algorithms with human clinical capsule endoscopy videos.      PUBLIC HEALTH RELEVANCE: Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.           Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.         ",PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY,8057895,R43DK091083,"['Affect', 'Algorithms', 'American', 'Attention', 'Blood', 'Categories', 'Classification', 'Classification Scheme', 'Clinical', 'Community Physician', 'Computer software', 'Crohn&apos', 's disease', 'Data', 'Data Set', 'Databases', 'Deformity', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Disease', 'Endoscopy', 'Evaluation', 'Family', 'Fatigue', 'Gastroenterologist', 'Gastrointestinal tract structure', 'Goals', 'Hemorrhage', 'Hour', 'Human', 'Image', 'Imagery', 'Lesion', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Metric', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Phase', 'Physicians', 'Polyps', 'Population', 'Probability', 'Procedures', 'Process', 'Readability', 'Reader', 'Reading', 'Research', 'Risk', 'Risk Reduction', 'Severities', 'Small Intestines', 'Sorting - Cell Movement', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'Ulcer', 'Work', 'base', 'capsule', 'clinically relevant', 'clinically significant', 'cost', 'experience', 'gastrointestinal', 'image processing', 'improved', 'innovation', 'interest', 'prospective', 'prototype', 'tumor']",NIDDK,IKONA MEDICAL CORPORATION,R43,2011,176778,0.0310632862363607
"Digital image analysis for quantitative and qualitative assessment of pig islets    DESCRIPTION (provided by applicant): The demonstration by the Edmonton group that human islet transplantation can be successfully used to manage adult type 1 diabetes patients with refractory hypoglycemia has led to increased funding of clinical trials and further research to extend the scope of this therapy by using porcine islets in place of human islets. Significant advances have been made in improving immunosuppression treatment regimens so that results obtained from treating adult diabetic patients with human islet transplants are similar to those obtained after pancreas transplantation. The major hurdle to move this therapy from clinical research to routine clinical practice is to improve the yield and quality of islets recovered from human or porcine pancreas. Presently, there are no standardized methods that can accurately assess the number or quality of islets that are used in the islet transplantation procedures so that results between laboratories can be objectively evaluated. This grant is focused on developing a robust, islet image analysis software to objectively analyze the number and quality of porcine islets recovered from the pancreas. The two major aims of the project are first to develop an improved image analysis software program that will provide a standardized measurement of the number and mass of porcine islets in a cell preparation. And second, enhance the capabilities of the software program by correlating the image signatures of each porcine islet to an artificial category. Porcine islets of similar size will be handpicked and sorted into three categories based on the shape, border, integrity, or uniformity of dithizone staining. The first software enhancement will find those features in the images that can be used to distinguish the different categories of islets. The second enhancement will assess the feasibility of using machine learning methods to correlate these features with data recovered from the images but also other discrete or continuous variables that are used to characterize the porcine islet preparations. If successful, the ability to use a rapid and objective image analysis methodology will improve the assessment of the number and quality of islets within and between laboratories; correlate image features with success of transplantation as measured by graft survival and insulin independence; and improve the islet isolation methods to achieve favorable islet image scores that are determined by retrospective analysis. The ability of a commercial firm focused on improving islet yields by focusing on tissue dissociation with a leading academic laboratory that has sophisticated expertise in developing software algorithms from microscopic images provides a fresh approach to a difficult medical that needs to be resolved to realize the full potential of islet transplantation to treat adult type 1 diabetic patients.      PUBLIC HEALTH RELEVANCE: An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.           An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.         ",Digital image analysis for quantitative and qualitative assessment of pig islets,8058009,R43DK091103,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Biochemical', 'Biological', 'Biological Assay', 'Caliber', 'Categories', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computer Assisted', 'Computer software', 'Data', 'Data Collection', 'Development', 'Dissociation', 'Dithizone', 'Drops', 'Enzymes', 'Family suidae', 'Feasibility Studies', 'Funding', 'Genetic', 'Glucose', 'Graft Survival', 'Grant', 'Human', 'Hypoglycemia', 'Image', 'Image Analysis', 'Immunosuppression', 'In Vitro', 'Insulin', 'Insulin-Dependent Diabetes Mellitus', 'Islet Cell', 'Islets of Langerhans Transplantation', 'Laboratories', 'Liver', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microscope', 'Microscopic', 'Modification', 'Optics', 'Organ', 'Outcome', 'Pancreas', 'Pancreas Transplantation', 'Pathway interactions', 'Patients', 'Pattern Recognition', 'Pattern Recognition Systems', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Portal vein structure', 'Predictive Value', 'Preparation', 'Procedures', 'Proteomics', 'Protocols documentation', 'Recovery', 'Refractory', 'Reporting', 'Research', 'Sampling', 'Sampling Errors', 'Scientist', 'Screening procedure', 'Shapes', 'Sorting - Cell Movement', 'Staining method', 'Stains', 'Standardization', 'Statistical Models', 'Stress', 'Structure', 'Survival Rate', 'System', 'Techniques', 'Time', 'Tissues', 'Transplantation', 'Treatment Protocols', 'base', 'cell preparation', 'clinical practice', 'diabetic patient', 'digital', 'digital imaging', 'improved', 'indexing', 'innovation', 'islet', 'programs', 'software development', 'standardize measure', 'success', 'tool', 'type I diabetic']",NIDDK,"VITACYTE, LLC",R43,2011,232329,0.060364277179921044
"Objective imaging-based assessment of smoking behavior from used filters    DESCRIPTION (provided by applicant): Accurate measurement of smoking behaviors and exposures may become critical as FDA implements its authority to regulate tobacco products, and in particular proposes product standards and considers approval of modified risk products. Recently, digital image analysis systems have been developed that can identify the blocking of filter vents on spent cigarette filters with high accuracy and can also estimate the degree of smoker compensation. There is strong potential for such digital imaging systems to unobtrusively infer a rich set of smoker topography variables as well as a smoker's exposure to toxins. The existing literature base on filter-based assays is growing and points to growing prominence and applicability of these approaches to important research questions. We propose to modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth- level cigarette smoke exposure by examining tar stains on cigarette filter butts. The Specific Aims are designed to provide rigorous evaluations of the utility of the systems, from establishing prediction equations using machine-smoked cigarettes to cross- validation in human-smoked samples against other established measures of mouth-level exposure. At the conclusion of this project, we plan to release a validated suite of software to the research community to support external verification of digital image analysis for smoking-related research.      PUBLIC HEALTH RELEVANCE: Accurately and simply measuring smoking behavior and smoke exposure is important, and digital image analysis systems have been developed that can estimate smoke intake and identify the blocking of filter vents on spent cigarette filters. The proposed project will modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth-level cigarette smoke exposure. We plan to make a suite of software publicly available to allow others to apply this technology in their own research.                 Accurately and simply measuring smoking behavior and smoke exposure is important, and digital image analysis systems have been developed that can estimate smoke intake and identify the blocking of filter vents on spent cigarette filters. The proposed project will modify existing analysis systems and conduct a series of studies to test their reliability, validity, and applicability for determining mouth-level cigarette smoke exposure. We plan to make a suite of software publicly available to allow others to apply this technology in their own research.               ",Objective imaging-based assessment of smoking behavior from used filters,8166424,R21CA160825,"['Biological Assay', 'Biological Markers', 'Cigarette', 'Communities', 'Computer software', 'Data Analyses', 'Equation', 'Evaluation', 'Exposure to', 'Financial compensation', 'Human', 'Image', 'Image Analysis', 'Intake', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Oral cavity', 'Patient Self-Report', 'Research', 'Risk', 'Sampling', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Smoking Behavior', 'Staining method', 'Stains', 'System', 'Systems Analysis', 'Tars', 'Technology', 'Testing', 'Tobacco', 'Toxin', 'Validation', 'Validity and Reliability', 'Vent', 'authority', 'base', 'cigarette smoking', 'cigarette smoking', 'design', 'digital imaging']",NCI,ROSWELL PARK CANCER INSTITUTE CORP,R21,2011,137113,0.021819704643082607
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",8100386,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2011,220839,-0.0041757128218074336
"Perception of Tactile Graphics    DESCRIPTION (provided by applicant): The broad objective of the proposed research is to answer the following question: why are tactile graphics difficult to understand? People with normal vision can easily recognize line drawings of objects. However, both blind and sighted people find it very difficult to recognize the same drawings when they are presented as tactile images. For blind people, tactile graphics are the only solution for accessing information in visual diagrams and illustrations found in textbooks. Consequently, the results of the proposed research will be used to improve the production of tactile graphics so that they are better understood by blind people. The specific aims of this project are to: 1) explore how the complexity of tactile images affects perception, 2) determine the effects of spatial and temporal integration on perception of tactile images, and 3) investigate how well people can recognize tactile images of objects embedded in backgrounds. The general methodology of the proposed experiments is to present participants with tactile images and to have them draw what they perceive the images to be. Blind individuals will draw tactile images using special paper and a stylus. The experimenters will evaluate the drawings by using a quantitative measure that computes a distance score reflecting the discrepancy between the original image and the participant's drawing. In the first study, participants will feel tactile stimuli of varying complexity, from simple lines in different orientations to complex depictions of objects. The second study will determine the limitations of tactile perceptual integration by limiting either the spatial or temporal window over which participants feel the image. Participants will either view or feel images through apertures of various sizes (spatial window) or they will have a limited amount of time to view or feel the images (temporal window). In the third study, participants will feel tactile images of objects embedded in simple backgrounds. This research will impact several areas of study, including computer vision, human object and scene recognition, and low vision rehabilitation.      PUBLIC HEALTH RELEVANCE: Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.              Relevance The proposed research seeks to improve the translation of visual graphics into tactile graphics for use by visually-impaired individuals. By making the information in visual graphics more accessible, this research will improve educational services for people with low vision. This work will also facilitate the development of better visual-to-tactile substitution technologies.            ",Perception of Tactile Graphics,8060259,F32EY019622,"['Affect', 'Area', 'Categories', 'Child', 'Complex', 'Computer Vision Systems', 'Development', 'Devices', 'Disadvantaged', 'Education', 'Elements', 'Goals', 'Grouping', 'Human', 'Image', 'India', 'Individual', 'Link', 'Measures', 'Methodology', 'Methods', 'Names', 'Nature', 'Paper', 'Participant', 'Perception', 'Population', 'Production', 'Psychophysics', 'Rehabilitation therapy', 'Research', 'Science', 'Sensory', 'Services', 'Shapes', 'Solutions', 'Stimulus', 'Swelling', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Vision', 'Visual', 'Visual Perception', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'blind', 'braille', 'improved', 'object recognition', 'research study', 'sight for the blind', 'skills', 'tactile vision substitution system', 'two-dimensional', 'vision development', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2011,48398,0.06087255871009835
"Human-Centered Perceptual and Conceptual Classification of Biomedical Images    DESCRIPTION (provided by applicant): Biomedical images are ever increasing in quantity and importance yet effective computing solutions for managing images and understanding their content are lacking. Image understanding is a key limiting factor in advancing these endeavors. Major challenges remain in understanding the capabilities of the human visual system with respect to biomedical imaging and in extracting and utilizing tacit knowledge of domain experts. To meet these challenges, we propose an innovative, multidisciplinary approach which combines methods of user centered design, visual perception and computer imaging research to interact with domain experts and to elicit and use their extrinsic and intrinsic knowledge. We will use a novel contextual design approach to inspection of dermatology images to discover relationships between perceptually- relevant visual content of images and users' conceptual understanding as expressed through natural language. Analysis of users' eye movements and verbal descriptions, together with mapping to domain medical ontologies, will allow us to integrate visual data with a user-specified language model to define perceptual categories and inform image classification. This is a fundamental and challenging data to knowledge problem that has not been solved. This study will provide proof of concept of the value of eliciting tacit knowledge from domain experts through multiple perceptually relevant modes in order to integrate data and knowledge models for better image understanding and may help enact a paradigm shift in how we conceptualize and develop biomedical information systems, in general.             Project Narrative Biomedical images are ever increasing in quantity yet their usefulness for research, medicine, and teaching is limited by the design of current computing systems. Discoveries and concrete advances made in this study will contribute to solutions for effective use of digital images-a problem that is central to research and application across science, technology, and medicine. Advancements in our understanding of the design of useful and usable information systems will benefit society at large and contribute to the public health.  ",Human-Centered Perceptual and Conceptual Classification of Biomedical Images,8077991,R21LM010039,"['Algorithms', 'Categories', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Computer Systems', 'Conceptual Domain', 'Data', 'Data Set', 'Dermatologist', 'Dermatology', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Information Resources', 'Information Systems', 'Internet', 'Knowledge', 'Language', 'Learning', 'Link', 'Maps', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Perception', 'Phase', 'Process', 'Public Health', 'Research', 'Retrieval', 'Science', 'Semantics', 'Societies', 'Solutions', 'Specific qualifier value', 'Statistical Models', 'Structure', 'System', 'Technology', 'Training', 'Unified Medical Language System', 'Validation', 'Visual', 'Visual Perception', 'Visual system structure', 'base', 'bioimaging', 'biomedical information system', 'design', 'digital imaging', 'innovation', 'interdisciplinary approach', 'interest', 'meetings', 'natural language', 'novel', 'success', 'tool', 'user centered design', 'vector']",NLM,ROCHESTER INSTITUTE OF TECHNOLOGY,R21,2011,192348,-0.0009923611483641875
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,8123240,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Clinical Research', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost effective', 'digital imaging', 'image archival system', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'two-dimensional', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2011,677070,0.041202261834547074
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis    DESCRIPTION (provided by applicant): All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This application takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.      PUBLIC HEALTH RELEVANCE: This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.           This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.         ",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8192056,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2011,148255,0.02277794735407267
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7921476,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2010,110591,0.0773149690889866
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7904837,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2010,1196495,0.026607741173521982
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,7761085,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2010,463608,0.07863278280036545
"Integrating Quantitative Histological Image and Vascular Density Patterns for Pro    DESCRIPTION (provided by applicant):       With increasing detection of early CaP with improved diagnostic methodologies, it has become important to predict biologic behaviors and ""aggressivity"" to identify patients who might benefit from a ""wait and watch policy"" as opposed to those who need more aggressive strategies. Traditionally, T-stage, amount of cancer in the core biopsy, the Gleason grade, and PSA at diagnosis has been used to evaluate the prognosis in localized CaP. While the Gleason score is currently assumed to be the strongest prognostic marker for CaP, there is often considerably high inter-, intra-observer variability associated with Gleason grade determination by pathologists. While some newer markers have recently shown promise, none of these methods have individually proven to be accurate enough to serve routinely as a prognostic marker for CaP.  Recently, there has been a call to combine multiple prognostic markers to create an integrated meta-marker, with potentially greater accuracy in predicting CaP recurrence compared to any individual marker. While it is apparent that prognostic information resides in histopathology imagery in terms of the arrangement of nuclei and glands, sophisticated graph, and computerized image analysis algorithms are required to quantitatively model and characterize the architectural appearance of prostate cancer histopathology and thus provide a marker that is accurate and reproducible (unlike Gleason grade). In addition, while tumor micro-vascular density has been correlated to CaP outcome, prognostic information may also potentially reside in the specific spatial architectural arrangement of the micro-vascular network. The objective of the proposed work is to develop an integrated quantitative prognostic marker that combines information based on architectural arrangement of nuclear, glandular, and micro-vasculature network patterns on whole mount histology sections (WMHS) obtained via radical prostatectomy (RP) to predict prostate cancer recurrence.  The proposed work comprises a total of 3 specific aims. For this project we will digitize approximately 100 annonymized WMHS obtained via RP that have been matched for Gleason score, stage, PSA, but with different clinical outcomes (half the patients having undergone cancer recurrence and the other not, following RP). Under Aim 1, segmentation algorithms will be developed to automatically identify cancerous nuclei, glands and tumor microvasculature (MV), stained immuno-histochemically via CD31. Under Aim 2 we will apply graph based image analysis algorithms to quantitatively characterize the architectural arrangement of CaP nuclei, glands and the MV network. These graph-based features will be integrated via a computerized machine learning algorithm to yield a numerical image based risk score (IbRiS) reflecting the CaP prognosis (disease recurrence or non-recurrence) of the patient. IbRiS will be evaluated in terms of its ability to distinguish between CaP progressors and non-progressors (matched for stage, Gleason grade, PSA), in a cohort of 50 independent studies (test set) for which survival and outcome data is available.  This project will be a collaboration between investigators at Rutgers University (RU) and the University of Pennsylvania (UPENN). Data accrual will be done at UPENN while algorithmic development for computerized image analysis and classification will be carried out at RU.             The broad long term goal of this project is to develop an integrated image based histological biomarker for  predicting  prostate  cancer  (CaP)  survival  and  outcome  by  integrating  quantitative  image  signatures  that  define  tissue  architecture  and  vascular  density  patterns.  Sophisticated  image  analysis  and  graph  based  algorithms will be developed to yield an image based risk score (IbRis) to predict whether or not a CaP patient  will  have  disease  recurrence  following  treatment.  Our  hypothesis  is  that  IbRis  will  prove  to  be  a  better  prognostic marker compared to such traditional markers as Gleason score and PSA.   ",Integrating Quantitative Histological Image and Vascular Density Patterns for Pro,7941833,R03CA143991,"['Algorithms', 'Appearance', 'Architecture', 'Area', 'Behavior', 'Biological Markers', 'Blood Vessels', 'Cancerous', 'Cell Nucleus', 'Classification', 'Clinical', 'Collaborations', 'Computers', 'Core Biopsy', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'E-Cadherin', 'Early Diagnosis', 'Gland', 'Gleason Grade for Prostate Cancer', 'Goals', 'Graph', 'Histocytochemistry', 'Histology', 'Histopathology', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intraobserver Variability', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Nuclear', 'Outcome', 'Output', 'PECAM1 gene', 'Pathologist', 'Patients', 'Pattern', 'Pennsylvania', 'Policies', 'Prognostic Marker', 'Protocols documentation', 'Radical Prostatectomy', 'Randomized', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Scheme', 'Slide', 'Specimen', 'Staging', 'Staining method', 'Stains', 'Structure', 'TP53 gene', 'Testing', 'Tissues', 'Training', 'Tumor stage', 'Universities', 'Validation', 'Work', 'base', 'cancer recurrence', 'cohort', 'computerized', 'density', 'digital', 'imaging Segmentation', 'improved', 'novel marker', 'outcome forecast', 'prognostic', 'repository', 'tumor', 'vector']",NCI,"RUTGERS, THE STATE UNIV OF N.J.",R03,2010,81236,0.00491037422408695
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7877019,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2010,223070,-0.0041757128218074336
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7799708,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'image processing', 'meetings', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'public health relevance', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2010,427932,0.02009742356782054
"Dx Ear: An automated tool for diagnosis of otitis media    DESCRIPTION (provided by applicant):    Otitis media is a general term for middle-ear inflammation that is classified clinically as either acute otitis media (AOM) or otitis media with effusion (OME). AOM represents a bacterial super infection of the middle ear fluid and OME a sterile effusion that tends to subside spontaneously. Antibiotics are generally beneficial only for AOM. Accurate diagnosis of AOM, as well as distinction from both OME and no effusion (NOE) requires considerable training.  AOM is the most common infection for which antimicrobial agents are prescribed for children in the US. By age seven, 93 percent of children will have experienced one or more episodes of otitis media.1 AOM results in significant social burden and indirect costs due to time lost from school and work. Estimated direct costs of AOM in 1995 were $1.96 billion and indirect costs were estimated to be $1.02 billion, with a total of 20 million prescriptions for antimicrobials related to otitis media.2 Given these considerations, our goal is to:  Develop a software tool to classify images into one of three stringent clinical diagnostic categories (AOM/OME/NOE), and validate the algorithm on tympanic membrane (TM) images.  We have assembled a strong multidisciplinary team that can successfully develop an automated diagnostic algorithm in this Phase-I program. We have (1) gathered a team of nationally-recognized otoscopists with substantial clinical and research experience in the context of AOM clinical trials; (2) studied the predictive value of diagnostic findings in discriminating AOM from OME from NOE; (3) acquired a large number of TM images from children; and (4) involved an internationally recognized expert in developing algorithms in all areas of image analysis and processing.  In the planned Phase-II, we will use the algorithm developed in the Phase-I program and incorporate it into a user-friendly and marketable digital otoscope-software platform that can be used at the point-of-care by clinicians to improve the care of children with this frequently occurring condition. This will be followed by a clinical trial evaluating its immediate impact on clinical care, and, in particular, utilization of antimicrobials.  Our main goal will be to develop an accurate automated algorithm for classifying the three diagnostic categories (AOM/OME/NOE). We aim to achieve an overall accuracy of 95 percent by applying a newly developed classification algorithm. This will include applying state-of-the-art classification methods as well as segmentation algorithms, for automated, robust diagnosis and classification of the three diagnostic categories (AOM/OME/NOE). We propose to achieve this through the following two specific aims:  Specific Aim 1: Develop a robust and accurate diagnostic algorithm that can discriminate TM digital images into 1of 3 stringent diagnostic categories (AOM/OME/NOE).  Specific Aim 2: Validate the algorithm on a dataset that includes over 2000 TM images collected in a recently completed NIAID-sponsored clinical trial.      PUBLIC HEALTH RELEVANCE:    AOM is the most common infection for which antimicrobial agents are prescribed in children in the US. By age seven, 93 percent of children will have experienced one or more episodes of otitis media. AOM results in significant social burden and indirect costs due to time lost from school and work. Estimated direct costs of AOM in 1995 were $1.96 billion and indirect costs were estimated to be $1.02 billion, with a total of 20 million prescriptions for antimicrobials related to otitis media. Developing an automated and accurate software tool to help classify otitis media images into one of three stringent clinical categories would have a great impact on both clinical care as well as reducing the unnecessary prescriptions of antibiotics in the US.              NARRATIVE AOM is the most common infection for which antimicrobial agents are prescribed in children in the US. By age seven, 93% of children will have experienced one or more episodes of otitis media. AOM results in significant social burden and indirect costs due to time lost from school and work. Estimated direct costs of AOM in 1995 were $1.96 billion and indirect costs were estimated to be $1.02 billion, with a total of 20 million prescriptions for antimicrobials related to otitis media. Developing an automated and accurate software tool to help classify otitis media images into one of three stringent clinical categories would have a great impact on both clinical care as well as reducing the unnecessary prescriptions of antibiotics in the US.",Dx Ear: An automated tool for diagnosis of otitis media,7908336,R41DC010283,"['Acute', 'Age', 'Algorithms', 'Antibiotics', 'Area', 'Arts', 'Categories', 'Child', 'Child Care', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Computer software', 'Consensus', 'Data Set', 'Diagnosis', 'Diagnostic', 'Direct Costs', 'Ear', 'Facilities and Administrative Costs', 'Goals', 'Image', 'Image Analysis', 'Infection', 'Inflammation', 'Liquid substance', 'Machine Learning', 'Methods', 'Otitis Media', 'Otitis Media with Effusion', 'Otoscopes', 'Phase', 'Physicians', 'Predictive Value', 'Process', 'Schools', 'Signs and Symptoms', 'Site', 'Software Tools', 'Solutions', 'Sterility', 'System', 'Techniques', 'Time', 'Training', 'Tympanic membrane', 'Work', 'antimicrobial', 'antimicrobial drug', 'bacterial resistance', 'clinical care', 'diagnostic accuracy', 'digital', 'digital imaging', 'ear infection', 'effusion', 'experience', 'image processing', 'improved', 'middle ear', 'multidisciplinary', 'point of care', 'programs', 'public health relevance', 'skills', 'social', 'superinfection', 'tool', 'user-friendly']",NIDCD,"BLUE BELT TECHNOLOGIES, INC.",R41,2010,172771,-0.0543095818542408
"Mobile Search for the Visually Impaired    DESCRIPTION (provided by applicant):    IQ Engines' mobile visual search technology will enable the visually impaired to access real-time information about physical objects using their mobile phone camera. The mobile phone provides a visually-driven hyperlink between the physical and digital world: point the camera at an object and get information (for example product information or navigation information). The mobile phone camera is a powerful yet underutilized tool for the visually impaired. Our proposal has two specific aims. Working directly with the visually impaired community, we will build a prototype mobile visual search application that meets their accessibility and use requirements. Our second aim is to improve upon the state of the art for 3D object recognition. We will investigate a novel combination of sparse image representation, feature matching algorithm, and geometric verification in order to advance the performance of 3D object matching. While state-of-the-art image intelligence is robust enough to enable rapid and accurate image search of flat feature-rich objects, current computer vision pales in comparison to the abilities of biological vision systems to recognize 3-dimensional objects. Our underlying goal is to bring inspiration from recent advances in theoretical neuroscience and apply them to image and video search solutions.      PUBLIC HEALTH RELEVANCE:    Mobile visual search, using a cell phone camera to retrieve object information, enables a mobile phone camera to become an artificial 'eye' with object recognition intelligence. Implemented on a cell phone, a mobile visual search tool can be a low cost visual aid for the blind.           Mobile visual search, using a cell phone camera to retrieve object information, enables a mobile phone camera to become an artificial 'eye' with object recognition intelligence. Implemented on a cell phone, a mobile visual search tool can be a low cost visual aid for the blind.",Mobile Search for the Visually Impaired,7909025,R43EY019790,"['3-Dimensional', 'Algorithms', 'Arts', 'Biological', 'Breathing', 'Car Phone', 'Cellular Phone', 'Color', 'Communities', 'Computer Vision Systems', 'Databases', 'Feedback', 'Funding', 'Future', 'Goals', 'Image', 'Intelligence', 'Internet', 'Letters', 'Modeling', 'Neurosciences', 'Ocular Prosthesis', 'Performance', 'Research', 'Solutions', 'Speech Synthesizers', 'System', 'Technology', 'Text', 'Time', 'Vision', 'Visual', 'Visual Aid', 'Visual impairment', 'Work', 'base', 'blind', 'cost', 'digital', 'improved', 'meetings', 'novel', 'object recognition', 'prototype', 'public health relevance', 'technology development', 'tool', 'visual search']",NEI,"IQ ENGINES, INC.",R43,2010,138770,0.010534320000725916
"Spatially Accurate Deformable Image Registration for Thoracic CT Application    DESCRIPTION (Provided by the applicant)   Abstract:  Deformable image registration (DIR) is a cross-cutting technology with diagnostic and therapeutic medical applications. DIR algorithms were first developed in computer vision research to estimate motion between a source and target image, the resulting registered image visually appears similar to the target image. For medical applications the goal in applying DIR is to obtain an accurate spatial registration of the underlying anatomy and not simply image similarity. We developed a statistical framework for quantitative evaluation of DIR spatial accuracy based on large samples of expert-determined landmark features. Central to this framework is the statistical relationship between the number of landmark points required to assess spatial accuracy, the desired uncertainty range of the mean error, and an a priori estimated behavior of the DIR. DIR is at the heart of our strategy to quantify COPD small airway disease air-trapping and four dimensional computed tomography (4D CT) ventilation. The optimal DIR algorithm and its spatial accuracy in registering the underlying anatomy should be assessed for each application. We will develop and test new DIR algorithms for exhale and inhale breath-hold CT (eBH-CT & iBH-CT) images pairs (COPD air trapping evaluation) and for 4D CT images (4D CT ventilation). Current CT image analysis methods for COPD evaluation focus on the separate anatomic evaluation of the eBH-CT & iBH-CT images. They are unable to find air-trapping due to bronchiolitis alone. We propose to evaluate the eBH- & iBH CT image pairs simultaneously using DIR to link the two to identify regions of air-trapping due to both emphysema and bronchiolitis. Next, to continue our development of ventilation imaging derived from 4D CT, we will test the ability of 4D CT ventilation image guidance to reduce pulmonary function loss after radiotherapy in a randomized phase II trial for non-small cell lung cancer patients.   Public Health Relevance:  This study will develop novel image registration methods and their application, with an emphasis on application specific validation. With this technology we will develop and test methods to find air-trapping in chronic obstructive pulmonary disease patients. We will test our novel ventilation imaging method in radiation treatment planning to reduce normal lung injury after treatment for lung cancer.       n/a",Spatially Accurate Deformable Image Registration for Thoracic CT Application,7980382,DP2OD007044,"['Air', 'Algorithms', 'Anatomy', 'Behavior', 'Breathing', 'Bronchiolitis', 'Cancer Patient', 'Chest', 'Chronic Obstructive Airway Disease', 'Computer Vision Systems', 'Development', 'Diagnostic', 'Environmental air flow', 'Evaluation', 'Exhalation', 'Four-dimensional', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Link', 'Medical', 'Methods', 'Motion', 'Non-Small-Cell Lung Carcinoma', 'Phase II Clinical Trials', 'Pulmonary Emphysema', 'Quantitative Evaluations', 'Radiation therapy', 'Randomized', 'Sampling', 'Source', 'Technology', 'Testing', 'Therapeutic', 'Uncertainty', 'Vision research', 'X-Ray Computed Tomography', 'abstracting', 'base', 'image registration', 'pulmonary function', 'small airways disease']",OD,UNIVERSITY OF TX MD ANDERSON CAN CTR,DP2,2010,1645038,0.012102501185764454
"Human-Centered Perceptual and Conceptual Classification of Biomedical Images    DESCRIPTION (provided by applicant): Biomedical images are ever increasing in quantity and importance yet effective computing solutions for managing images and understanding their content are lacking. Image understanding is a key limiting factor in advancing these endeavors. Major challenges remain in understanding the capabilities of the human visual system with respect to biomedical imaging and in extracting and utilizing tacit knowledge of domain experts. To meet these challenges, we propose an innovative, multidisciplinary approach which combines methods of user centered design, visual perception and computer imaging research to interact with domain experts and to elicit and use their extrinsic and intrinsic knowledge. We will use a novel contextual design approach to inspection of dermatology images to discover relationships between perceptually- relevant visual content of images and users' conceptual understanding as expressed through natural language. Analysis of users' eye movements and verbal descriptions, together with mapping to domain medical ontologies, will allow us to integrate visual data with a user-specified language model to define perceptual categories and inform image classification. This is a fundamental and challenging data to knowledge problem that has not been solved. This study will provide proof of concept of the value of eliciting tacit knowledge from domain experts through multiple perceptually relevant modes in order to integrate data and knowledge models for better image understanding and may help enact a paradigm shift in how we conceptualize and develop biomedical information systems, in general.             Project Narrative Biomedical images are ever increasing in quantity yet their usefulness for research, medicine, and teaching is limited by the design of current computing systems. Discoveries and concrete advances made in this study will contribute to solutions for effective use of digital images-a problem that is central to research and application across science, technology, and medicine. Advancements in our understanding of the design of useful and usable information systems will benefit society at large and contribute to the public health.  ",Human-Centered Perceptual and Conceptual Classification of Biomedical Images,7896281,R21LM010039,"['Algorithms', 'Categories', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Computer Systems', 'Conceptual Domain', 'Data', 'Data Set', 'Dermatologist', 'Dermatology', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Information Resources', 'Information Systems', 'Internet', 'Knowledge', 'Language', 'Learning', 'Link', 'Maps', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Perception', 'Phase', 'Process', 'Public Health', 'Research', 'Retrieval', 'Science', 'Semantics', 'Societies', 'Solutions', 'Specific qualifier value', 'Statistical Models', 'Structure', 'System', 'Technology', 'Training', 'Unified Medical Language System', 'Validation', 'Visual', 'Visual Perception', 'Visual system structure', 'base', 'bioimaging', 'biomedical information system', 'design', 'digital imaging', 'innovation', 'interdisciplinary approach', 'interest', 'meetings', 'natural language', 'novel', 'success', 'tool', 'user centered design', 'vector']",NLM,ROCHESTER INSTITUTE OF TECHNOLOGY,R21,2010,163457,-0.0009923611483641875
"Computational Photography Project for Pill Identification (C3PI) In a national effort to promote patient safety, the National Library of Medicine (NLM) proposes to create a comprehensive, public digital image inventory of the nation's commercial prescription solid dose medications. The primary intention of this effort is create a test data collection for the advancement of automatic pharmaceutical identification through computer analysis from photographic data. NLM expects to promote computer-based image research applied to the domain of content-based information retrieval (CBIR) of solid-dose pharmaceuticals, and anticipates the need for generating a test environment, including variations of photographs of the same drug or sample under different environments. n/a",Computational Photography Project for Pill Identification (C3PI),8174192,76201000698P,"['Algorithms', 'Collection', 'Color', 'Computer Analysis', 'Computer Vision Systems', 'Computers', 'Data', 'Data Collection', 'Dose', 'Environment', 'Equipment', 'Equipment and supply inventories', 'Image', 'Imagery', 'Information Retrieval', 'Intention', 'Measurement', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Photography', 'Research', 'Resolution', 'Sampling', 'Shapes', 'Solid', 'Structure', 'Surface Properties', 'Testing', 'Text', 'United States National Library of Medicine', 'Variant', 'base', 'digital imaging', 'patient safety', 'pill']",NLM,"MEDICOS CONSULTANTS, LLC",N03,2010,500000,0.010810934288765586
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7936871,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost', 'digital imaging', 'image archival system', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2010,805328,0.041202261834547074
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),8136874,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,125017,0.03914266211436139
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),8143048,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,76123,0.03914266211436139
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7876805,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2010,676574,0.03914266211436139
"Towards the Building of a Comprehensive Searchable Biological Experiment Database    DESCRIPTION (provided by applicant):       The rapid growth of the biomedical literature and the expansion in disciplinary biomedical research, heralded by high-throughput genome sciences and technologies, have overwhelmed scientists who attempt to assimilate information necessary for their research. The widespread adoption of title/abstract word searches, such as highly desirable the National Library of Medicine's PubMed system, has provided the first major advance in the way bioscientists find relevant publications since the origin of Index Medicus in 1879 (Hunter and Cohen 2006). The importance of developing valid information retrieval systems for bioscientists has led to the development of information systems worldwide (e.g., Arrowsmith (Smalheiser and Swanson 1998), BioText (Hearst 2003), GeneWays (Friedman et al. 2001; Rzhetsky et al. 2004), iHOP (Hoffmann and Valencia 2005), and BioMedQA (Lee et al. 2006a), and annotated databases (e.g., SWISSPROT, OMIM (Hamosh et al. 2005) and BIND (Alfarano et al. 2005)).      However, most of information systems target only text information and fail to provide access to other important data such as images (e.g., figures). More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biological articles nearly always incorporate figures/images that are the crucial content of the biomedical literature. Our examination of biological articles in the Proceedings of the National Academy of Sciences (PNAS) revealed the occurrence of 5.2 images per article on average (Yu and Lee 2006a). Biologists need to access image data to validate research facts and to formulate or to test novel research hypotheses. It has been evaluated that textual statements reported in literature frequently are noisy (i.e., containing ""false facts"") (Krauthammer et al. 2002). Capturing images that are experimental ""evidence"" to support the textual ""fact"" will benefit bioscience information systems, databases, and bioscientists.      Unfortunately, this wealth of information remains virtually inaccessible without automatic systems to organize these images. We propose the development of advanced natural language processing (NLP) tools to semantically organize images. We hypothesize that text that associated with images semantically entails the image content and natural language processing techniques can be developed to accurately associate the text to their images. Furthermore, we hypothesize that images can be semantically organized by categories specified by standard biological ontology, and that natural language processing approaches can accurately assign the ontological categories to images.      Our specific aims are:      Aim 1: To develop and evaluate NLP techniques for identifying textual statements that correspond to images in full-text articles. We will develop different approaches for two types of the associations. We will first propose rule-based and statistical approaches to identify the associated text that appears in the full-text articles. We will then develop hybrid approaches to link sentences in abstracts to images in the body of the articles.      Aim 2: To develop and evaluate NLP techniques for automatic classification of experimental results into categories (e.g., Western-Blot, PCR verification, etc) specified in the experimental protocol Protocol-Online.      We will explore the use of dictionary-based, rule-based, image classification, and machine-learning approaches for accomplishing this aim.      Aim 3: To develop and evaluate NLP techniques for automatic assignment of Gene Ontology categories to experiments, which will provide a knowledge-based organization of experiments according to biological properties (e.g., catalytic activity). We will develop statistical and machine-learning approaches for accomplishing this aim.      We found that most of the images that appear in full-text biological articles are figure images (Yu and Lee 2006a) and we therefore focus on figure images only in this proposal. The deliverable of Specific Aim 1 will be an effective user-interface BioEx from which bioscientists can access images directly from sentences in the abstracts. BioEx has the promise of improvement over the traditional single-document-per-article format that has dominated bioscience publications since the first scientific article appeared in 1665 (Gross 2002). The deliverables of Specific Aim 2 and 3 will be open-source algorithms and tools that accurately map images to categories specified by the Gene Ontology and the Protocol Online. Those algorithms and tools will enhance bioscience information retrieval, information extraction, summarization, and question answering.          n/a",Towards the Building of a Comprehensive Searchable Biological Experiment Database,7534822,R21RR024933,"['Adoption', 'Advanced Development', 'Algorithms', 'Binding', 'Biological', 'Biomedical Research', 'Categories', 'Classification', 'Data', 'Databases', 'Development', 'Dictionary', 'Documentation', 'Flowcharts', 'Genes', 'Genome', 'Hybrids', 'Image', 'Index Medicus', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Principal Investigator', 'Property', 'Protocols documentation', 'PubMed', 'Publications', 'Reporting', 'Research', 'Science', 'Scientist', 'Specific qualifier value', 'SwissProt', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'United States National Academy of Sciences', 'United States National Library of Medicine', 'Western Blotting', 'abstracting', 'base', 'knowledge base', 'novel', 'open source', 'programs', 'rapid growth', 'research study', 'tool']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2009,179517,-0.009436548136738545
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7739714,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2009,104963,0.0773149690889866
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7668573,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,1187062,0.026607741173521982
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7922310,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,152260,0.026607741173521982
"Integrating Quantitative Histological Image and Vascular Density Patterns for Pro    DESCRIPTION (provided by applicant):       With increasing detection of early CaP with improved diagnostic methodologies, it has become important to predict biologic behaviors and ""aggressivity"" to identify patients who might benefit from a ""wait and watch policy"" as opposed to those who need more aggressive strategies. Traditionally, T-stage, amount of cancer in the core biopsy, the Gleason grade, and PSA at diagnosis has been used to evaluate the prognosis in localized CaP. While the Gleason score is currently assumed to be the strongest prognostic marker for CaP, there is often considerably high inter-, intra-observer variability associated with Gleason grade determination by pathologists. While some newer markers have recently shown promise, none of these methods have individually proven to be accurate enough to serve routinely as a prognostic marker for CaP.  Recently, there has been a call to combine multiple prognostic markers to create an integrated meta-marker, with potentially greater accuracy in predicting CaP recurrence compared to any individual marker. While it is apparent that prognostic information resides in histopathology imagery in terms of the arrangement of nuclei and glands, sophisticated graph, and computerized image analysis algorithms are required to quantitatively model and characterize the architectural appearance of prostate cancer histopathology and thus provide a marker that is accurate and reproducible (unlike Gleason grade). In addition, while tumor micro-vascular density has been correlated to CaP outcome, prognostic information may also potentially reside in the specific spatial architectural arrangement of the micro-vascular network. The objective of the proposed work is to develop an integrated quantitative prognostic marker that combines information based on architectural arrangement of nuclear, glandular, and micro-vasculature network patterns on whole mount histology sections (WMHS) obtained via radical prostatectomy (RP) to predict prostate cancer recurrence.  The proposed work comprises a total of 3 specific aims. For this project we will digitize approximately 100 annonymized WMHS obtained via RP that have been matched for Gleason score, stage, PSA, but with different clinical outcomes (half the patients having undergone cancer recurrence and the other not, following RP). Under Aim 1, segmentation algorithms will be developed to automatically identify cancerous nuclei, glands and tumor microvasculature (MV), stained immuno-histochemically via CD31. Under Aim 2 we will apply graph based image analysis algorithms to quantitatively characterize the architectural arrangement of CaP nuclei, glands and the MV network. These graph-based features will be integrated via a computerized machine learning algorithm to yield a numerical image based risk score (IbRiS) reflecting the CaP prognosis (disease recurrence or non-recurrence) of the patient. IbRiS will be evaluated in terms of its ability to distinguish between CaP progressors and non-progressors (matched for stage, Gleason grade, PSA), in a cohort of 50 independent studies (test set) for which survival and outcome data is available.  This project will be a collaboration between investigators at Rutgers University (RU) and the University of Pennsylvania (UPENN). Data accrual will be done at UPENN while algorithmic development for computerized image analysis and classification will be carried out at RU.             The broad long term goal of this project is to develop an integrated image based histological biomarker for  predicting  prostate  cancer  (CaP)  survival  and  outcome  by  integrating  quantitative  image  signatures  that  define  tissue  architecture  and  vascular  density  patterns.  Sophisticated  image  analysis  and  graph  based  algorithms will be developed to yield an image based risk score (IbRis) to predict whether or not a CaP patient  will  have  disease  recurrence  following  treatment.  Our  hypothesis  is  that  IbRis  will  prove  to  be  a  better  prognostic marker compared to such traditional markers as Gleason score and PSA.   ",Integrating Quantitative Histological Image and Vascular Density Patterns for Pro,7792785,R03CA143991,"['Algorithms', 'Appearance', 'Architecture', 'Area', 'Behavior', 'Biological Markers', 'Blood Vessels', 'Cancerous', 'Cell Nucleus', 'Classification', 'Clinical', 'Collaborations', 'Computers', 'Core Biopsy', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'E-Cadherin', 'Early Diagnosis', 'Gland', 'Gleason Grade for Prostate Cancer', 'Goals', 'Graph', 'Histocytochemistry', 'Histology', 'Histopathology', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intraobserver Variability', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Nuclear', 'Outcome', 'Output', 'PECAM1 gene', 'Pathologist', 'Patients', 'Pattern', 'Pennsylvania', 'Policies', 'Prognostic Marker', 'Protocols documentation', 'Radical Prostatectomy', 'Randomized', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Scheme', 'Slide', 'Specimen', 'Staging', 'Staining method', 'Stains', 'Structure', 'TP53 gene', 'Testing', 'Tissues', 'Training', 'Tumor stage', 'Universities', 'Validation', 'Work', 'base', 'cancer recurrence', 'cohort', 'computerized', 'density', 'digital', 'imaging Segmentation', 'improved', 'novel marker', 'outcome forecast', 'prognostic', 'repository', 'tumor', 'vector']",NCI,"RUTGERS, THE STATE UNIV OF N.J.",R03,2009,79576,0.00491037422408695
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7664924,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2009,225323,-0.0041757128218074336
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7589644,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Custom', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'image processing', 'meetings', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'public health relevance', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information', 'web site']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2009,426946,0.02009742356782054
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7563977,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug candidate', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2009,355016,-0.032126904753264754
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7915039,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2009,168580,0.03914266211436139
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7643324,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'population based', 'programs', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2009,815277,0.03914266211436139
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7686733,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2009,819428,0.041202261834547074
"Towards the Building of a Comprehensive Searchable Biological Experiment Database    DESCRIPTION (provided by applicant):       The rapid growth of the biomedical literature and the expansion in disciplinary biomedical research, heralded by high-throughput genome sciences and technologies, have overwhelmed scientists who attempt to assimilate information necessary for their research. The widespread adoption of title/abstract word searches, such as highly desirable the National Library of Medicine's PubMed system, has provided the first major advance in the way bioscientists find relevant publications since the origin of Index Medicus in 1879 (Hunter and Cohen 2006). The importance of developing valid information retrieval systems for bioscientists has led to the development of information systems worldwide (e.g., Arrowsmith (Smalheiser and Swanson 1998), BioText (Hearst 2003), GeneWays (Friedman et al. 2001; Rzhetsky et al. 2004), iHOP (Hoffmann and Valencia 2005), and BioMedQA (Lee et al. 2006a), and annotated databases (e.g., SWISSPROT, OMIM (Hamosh et al. 2005) and BIND (Alfarano et al. 2005)).      However, most of information systems target only text information and fail to provide access to other important data such as images (e.g., figures). More than any other documentation, figures usually represent the ""evidence"" of discovery in the biomedical literature. Full-text biological articles nearly always incorporate figures/images that are the crucial content of the biomedical literature. Our examination of biological articles in the Proceedings of the National Academy of Sciences (PNAS) revealed the occurrence of 5.2 images per article on average (Yu and Lee 2006a). Biologists need to access image data to validate research facts and to formulate or to test novel research hypotheses. It has been evaluated that textual statements reported in literature frequently are noisy (i.e., containing ""false facts"") (Krauthammer et al. 2002). Capturing images that are experimental ""evidence"" to support the textual ""fact"" will benefit bioscience information systems, databases, and bioscientists.      Unfortunately, this wealth of information remains virtually inaccessible without automatic systems to organize these images. We propose the development of advanced natural language processing (NLP) tools to semantically organize images. We hypothesize that text that associated with images semantically entails the image content and natural language processing techniques can be developed to accurately associate the text to their images. Furthermore, we hypothesize that images can be semantically organized by categories specified by standard biological ontology, and that natural language processing approaches can accurately assign the ontological categories to images.      Our specific aims are:      Aim 1: To develop and evaluate NLP techniques for identifying textual statements that correspond to images in full-text articles. We will develop different approaches for two types of the associations. We will first propose rule-based and statistical approaches to identify the associated text that appears in the full-text articles. We will then develop hybrid approaches to link sentences in abstracts to images in the body of the articles.      Aim 2: To develop and evaluate NLP techniques for automatic classification of experimental results into categories (e.g., Western-Blot, PCR verification, etc) specified in the experimental protocol Protocol-Online.      We will explore the use of dictionary-based, rule-based, image classification, and machine-learning approaches for accomplishing this aim.      Aim 3: To develop and evaluate NLP techniques for automatic assignment of Gene Ontology categories to experiments, which will provide a knowledge-based organization of experiments according to biological properties (e.g., catalytic activity). We will develop statistical and machine-learning approaches for accomplishing this aim.      We found that most of the images that appear in full-text biological articles are figure images (Yu and Lee 2006a) and we therefore focus on figure images only in this proposal. The deliverable of Specific Aim 1 will be an effective user-interface BioEx from which bioscientists can access images directly from sentences in the abstracts. BioEx has the promise of improvement over the traditional single-document-per-article format that has dominated bioscience publications since the first scientific article appeared in 1665 (Gross 2002). The deliverables of Specific Aim 2 and 3 will be open-source algorithms and tools that accurately map images to categories specified by the Gene Ontology and the Protocol Online. Those algorithms and tools will enhance bioscience information retrieval, information extraction, summarization, and question answering.          n/a",Towards the Building of a Comprehensive Searchable Biological Experiment Database,7314689,R21RR024933,"['Adoption', 'Advanced Development', 'Algorithms', 'Binding', 'Biological', 'Biomedical Research', 'Categories', 'Classification', 'Data', 'Databases', 'Development', 'Dictionary', 'Documentation', 'Flowcharts', 'Genes', 'Genome', 'Hybrids', 'Image', 'Index Medicus', 'Information Retrieval', 'Information Retrieval Systems', 'Information Systems', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Polymerase Chain Reaction', 'Principal Investigator', 'Property', 'Protocols documentation', 'PubMed', 'Publications', 'Reporting', 'Research', 'Science', 'Scientist', 'Specific qualifier value', 'Standards of Weights and Measures', 'SwissProt', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Title', 'United States National Academy of Sciences', 'United States National Library of Medicine', 'Western Blotting', 'abstracting', 'base', 'knowledge base', 'novel', 'open source', 'programs', 'rapid growth', 'research study', 'tool']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2008,230085,-0.009436548136738545
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7500697,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2008,1146026,0.026607741173521982
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7596500,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Numbers', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'desire', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'size', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2008,225323,-0.0041757128218074336
"A Non-Document Text and Display Reader for Visually Impaired Persons    DESCRIPTION (provided by applicant): The goal of this project is to develop a computer vision system based on standard camera cell phones to give blind and visually impaired persons the ability to read appliance displays and similar forms of non-document visual information. This ability is increasingly necessary to use everyday appliances such as microwave ovens and DVD players, and to perform many daily activities such as counting paper money. No access to this information is currently afforded by conventional text reading systems such as optical character recognition (OCR), which is intended for reading printed documents. Our proposed software runs on a standard, off-the- shelf camera phone and uses computer vision algorithms to analyze images taken by the user, to detect and read the text within each image, and to then read it aloud using synthesized speech. Preliminary feasibility studies indicate that current cellular phones easily exceed the minimum processing power required for these tasks. Initially, the software will read out three categories of symbols: LED/LCD appliance displays, product or user-defined barcodes, and denominations of paper money. Ultimately these functions will be integrated with other capabilities being developed under separate funding, such as reading a broad range of printed text (including signs), recognizing objects, and analyzing photographs and graphics, etc., all available as free or low-cost software downloads for any cell phone user. Our specific goals are to (1) gather a database of real images taken by blind and visually impaired persons of a variety of LED/LCD appliance displays, barcodes and US paper currency; (2) develop algorithms to process the images and extract the desired information; (3) implement the algorithms on a camera phone; and (4) conduct user testing to establish design parameters and optimize the human interface. PUBLIC HEALTH RELEVANCE:  For blind and visually impaired persons, one of the most serious barriers to employment, economic self sufficiency and independence is insufficient access to the ever-increasing variety of devices and appliances in the home, workplace, school or university that incorporate visual LED/LCD displays, and to other types of text and symbolic information hitherto unaddressed by rehabilitation technology. The proposed research would result in an assistive technology system (with zero or minimal cost to users) to provide increased access to such display and non- document text information for the approximately 10 million Americans with significant vision impairments or blindness.          n/a",A Non-Document Text and Display Reader for Visually Impaired Persons,7446299,R01EY018890,"['Access to Information', 'Acoustics', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Auditory', 'Blindness', 'Categories', 'Cellular Phone', 'Code', 'Computer Vision Systems', 'Computer software', 'Cosmetics', 'Count', 'Custom', 'Daily', 'Data', 'Databases', 'Development', 'Devices', 'Economics', 'Electronics', 'Employment', 'Evaluation', 'Feasibility Studies', 'Figs - dietary', 'Funding', 'Goals', 'Hand', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Lavandula', 'Mainstreaming', 'Marketing', 'Memory', 'Modification', 'Paper', 'Printing', 'Process', 'Public Health', 'Range', 'Reader', 'Reading', 'Research', 'Resolution', 'Running', 'Schools', 'Self-Help Devices', 'Speech', 'Standards of Weights and Measures', 'Surveys', 'System', 'Telephone', 'Testing', 'Text', 'Training', 'Universities', 'Vision', 'Visit', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Voice', 'Workplace', 'base', 'blind', 'consumer product', 'cost', 'design', 'desire', 'image processing', 'microwave electromagnetic radiation', 'optical character recognition', 'prevent', 'programs', 'rehabilitation technology', 'response', 'time interval', 'tool', 'trafficking', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2008,421791,0.02009742356782054
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7496032,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2008,189850,0.014553735760327537
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7405144,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Numbers', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Range', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2008,394557,-0.032126904753264754
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7665248,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2008,80289,0.03914266211436139
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7489821,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2008,1042528,0.03914266211436139
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7494022,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Compatible', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Condition', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Numbers', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'computerized', 'cost', 'day', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2008,856688,0.041202261834547074
"Development and Dissemination of Robust Brain MRI Measurement Tools    DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: This application responds to RFA: PAR-07-249, ""Collaborations with National Centers for Biomedical Computing"". The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods. The project will collaborate with the National Alliance for Medical Image Computing (NA-MIC) to develop the software using the NA-MIC Software Engineering Process, leverage the NA-MIC engineering infrastructure, and integrate this software into the 3D Slicer, a well-architected application environment being developed in NA-MIC. The particular software package will include both a brain image registration and warping algorithm, called HAMMER, and an algorithm for the segmentation of white matter lesions (WMLs), which can arise from a variety of pathologies including vascular pathology and multiple sclerosis. HAMMER received 2006 Best Paper Award from IEEE Signal Processing Society. HAMMER has been successfully applied to many large clinical research studies and clinical trials involving over 5,000 MR brain images and has been downloaded by 318 users from 102 institutions in over 20 countries. The WML segmentation algorithm has been successfully applied to ""Action to Control Cardiovascular Risk in Diabetes-Memory in Diabetes"" (ACCORD-MIND) sub- study, with data acquired from 4 centers on 650 patients over a period of 8 years. Designing an easy-to-use, robust software package for these two algorithms and incorporating it into the 3D Slicer will benefit a large community of end-users that need access to advanced image analysis methods in various neuroimaging studies. To increase the robustness of the algorithms to the highly variable quality and characteristics of clinical image data, further algorithm development is necessary. To increase ease of use by non-experts in computer analysis methods and integrate this software into the Slicer platform, significant software engineering efforts are planned. Three aims will be investigated. The first aim is to further develop and extend novel image analysis methods aiming at improving the robustness and performance of HAMMER registration and WML segmentation algorithms, so that they can be easily applied to various clinical research studies. The second and third aims are to design separate software modules for these two algorithms, and to incorporate them into the 3D Slicer. These two modules will be designed (1) with consistent cross-platform interactive and scripted interfaces, (2) allowing end-users to interactively explore the suitable parameters for their data, (3) enabling developers to add new functions. The robustness of these two modules will be extensively tested and improved by both software engineering tools and various clinical research data (acquired from different centers). The final software will be freely available in both source code and pre-compiled programs. PUBLIC HEALTH REVELANCE: The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods.          n/a",Development and Dissemination of Robust Brain MRI Measurement Tools,7556497,R01EB006733,"['Academia', 'Address', 'Adopted', 'Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Arts', 'Attention', 'Automobile Driving', 'Award', 'Behavioral', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Blood Vessels', 'Brain', 'Brain imaging', 'Brain region', 'Budgets', 'California', 'Characteristics', 'Child', 'Class', 'Clinical', 'Clinical Data', 'Clinical Engineering', 'Clinical Research', 'Clinical Trials', 'Cocaine', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Communities', 'Compatible', 'Complex', 'Computational algorithm', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computers', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Documentation', 'Educational Materials', 'Educational process of instructing', 'Educational workshop', 'Elderly', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'General Hospitals', 'Genetic', 'Genomics', 'Goals', 'Government', 'Hand', 'Head', 'Health', 'Healthcare', 'Heavy Drinking', 'Hemoglobin', 'Histocompatibility Testing', 'Hormonal', 'Hospitals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Industry', 'Information Technology', 'Institutes', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Lesion', 'Licensing', 'Life', 'Localized', 'Longitudinal Studies', 'Los Angeles', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Memory', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Mind', 'Modality', 'Modeling', 'Molecular Abnormality', 'Morphology', 'Multimodal Imaging', 'Multiple Sclerosis', 'National Center for Research Resources', 'Nature', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'North Carolina', 'Numbers', 'Operative Surgical Procedures', 'Organ', 'Paper', 'Participant', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Philosophy', 'Physiological', 'Play', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Production', 'Property', 'Protocols documentation', 'Psychiatry', 'Public Health', 'Publications', 'Purpose', 'Radiology Specialty', 'Range', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Secure', 'Series', 'Services', 'Simulate', 'Site', 'Societies', 'Software Engineering', 'Software Tools', 'Source', 'Source Code', 'Spatial Distribution', 'Speed', 'Structure', 'System', 'Talents', 'Techniques', 'Technology', 'Testing', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'USA Georgia', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Upper arm', 'Ursidae Family', 'Utah', 'Visible Radiation', 'Vision', 'Vision research', 'Western Asia Georgia', 'Woman', 'Women&apos', 's Health', 'Work', 'abstracting', 'base', 'bioimaging', 'biomedical scientist', 'cardiovascular risk factor', 'computerized data processing', 'computerized tools', 'cost', 'design', 'disability', 'egg', 'endophenotype', 'experience', 'follow-up', 'human disease', 'image registration', 'improved', 'innovation', 'mathematical model', 'medical schools', 'member', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'open source', 'outreach program', 'portability', 'professor', 'programs', 'receptor', 'repository', 'research and development', 'research study', 'scripting interface', 'software development', 'tool', 'usability', 'user-friendly', 'vector', 'vision development', 'water diffusion', 'web-enabled', 'white matter']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2008,402999,0.03386755212196145
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7172503,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2007,1159531,0.026607741173521982
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7362843,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2007,235138,0.014553735760327537
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,7194202,R01EY015888,"['Agnosia', 'Area', 'Awareness', 'Color', 'Communication', 'Computer Vision Systems', 'Condition', 'Conscious', 'Cues', 'Development', 'Disease', 'Distant', 'Dyslexia', 'Elements', 'Goals', 'Grouping', 'Image', 'Lateral', 'Lead', 'Literature', 'Location', 'Measurable', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Nature', 'Neighborhoods', 'Paint', 'Perception', 'Process', 'Rate', 'Research', 'Research Personnel', 'Source', 'Staging', 'Stimulus', 'Structure', 'Textbooks', 'Texture', 'Time', 'Vision', 'Visual', 'Visual Fields', 'Visual system structure', 'base', 'design', 'interest', 'millisecond', 'neurophysiology', 'novel', 'perceptual organization', 'receptive field', 'relating to nervous system', 'research study', 'visual process', 'visual processing']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2007,216928,0.016532287111625205
"Mobile Food Intake Visualization and Voice Recognize (FIVR) Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives. n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7490204,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2007,3000,0.038307505387753515
"Mobile Food Intake Visualization and Voice Recognize (FIVR)    DESCRIPTION (provided by applicant):   Inadequate dietary intake assessment tools hamper studying relationships between diet and disease. Methods suitable for use in large epidemiologic studies (e.g., dietary recall, food diaries, and food frequency questionnaires) are subject to considerable inaccuracy, and more accurate methods (e.g., metabolic ward studies, doubly-labeled water) are prohibitively costly and/or labor-intensive for use in population-based studies. A simple, inexpensive and convenient, yet valid, dietary measurement tool is needed to provide more accurate determination of dietary intake in populations. We therefore propose a three-phase project to develop and test a new assessment tool called FIVR (Food Intake Visualization and Voice Recognizer) that uses a novel combination of innovative technologies: advanced voice recognition, visualization techniques, and adaptive user modeling in an electronic system to automatically record and evaluate food intake. FIVR uses cell phones to capture both voice recordings and photographs of dietary intake in real-time. These dual sources of data are sent to a database server for recognition processing for real-time food recognition and portion size measurement through speech recognition and image analysis. The user model will allow for enhanced identification of food and method of preparation in situations that images alone might not produce accurate results as the system learns through experience and adapts to the individual's food patterns. Objectives are to fuse existing voice and image recognition techniques into a system that will recognize foods by food type and unique characteristics and determine volume by film clip showing an image from at least two angles. The item identified will be matched to an appropriate food item and amount within a food composition database and nutrient intake computed. Researchers will be able to view the resulting analysis through an adapted version of the dietary analysis program, ProNutra. The proposed protocol will incorporate three discrete phases: 1) technology development, integration, and testing; 2) validity testing with a controlled diet (metabolic ward study); and 3) real-world utility testing. Validity of the data collected will be judged by how closely the nutrient calculations match the known composition of the metabolic ward diets consumed. FIVR has the potential to establish a method of highly accurate dietary intake assessment suitable for cost-effective use at the population level, and thereby advance crucial public health objectives.             n/a",Mobile Food Intake Visualization and Voice Recognize (FIVR),7340845,U01HL091738,"['Accounting', 'Algorithms', 'Cellular Phone', 'Characteristics', 'Clip', 'Computer Vision Systems', 'Data', 'Data Sources', 'Databases', 'Detection', 'Diet', 'Diet Records', 'Diet Research', 'Dietary intake', 'Disease', 'Eating', 'Electronics', 'Energy Intake', 'Environment', 'Epidemiologic Studies', 'Film', 'Food', 'Food Patterns', 'Frequencies', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intake', 'Internet', 'Label', 'Learning', 'Life', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modeling', 'Multimedia', 'Nutrient', 'Nutritional Study', 'Outcome', 'Patient Self-Report', 'Phase', 'Population', 'Preparation', 'Process', 'Protocols documentation', 'Public Health', 'Qualitative Evaluations', 'Quantitative Evaluations', 'Questionnaires', 'Reliance', 'Reminder Systems', 'Research', 'Research Personnel', 'Standards of Weights and Measures', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Visual', 'Voice', 'Water', 'base', 'cost', 'experience', 'feeding', 'graphical user interface', 'innovative technologies', 'novel', 'programs', 'size', 'speech recognition', 'technology development', 'tool', 'voice recognition', 'ward']",NHLBI,"VIOCARE, INC.",U01,2007,1039742,0.03914266211436139
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7289973,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Compatible', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Condition', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Numbers', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'computerized', 'cost', 'day', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2007,853883,0.041202261834547074
"Traffic Intersection Analysis Algorithms for the Blind DESCRIPTION (provided by applicant): This project aims to explore, develop and test computer vision algorithms to analyze images of street intersections from a camera worn by a blind person.  Urban intersections are the most dangerous parts of a blind person's travel.  They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult.  We will explore computer vision algorithms to help a blind person find the crosswalk, find the pedestrian signal button, determine when the ""walk"" light is on, and alert him/her to any veering out of the crosswalk.  We will emphasize the development of completely novel methods of analyzing non-ideal images including shadows, occlusions and other irregularities using spatial grouping techniques based on Bayesian inference.  The resulting algorithms are intended for eventual integration as modules for a computer vision system we are already developing to help blind persons with travel tasks such as finding and reading aloud printed signs and negotiating street crossings.  The combined system would have potential for a radical advance in independent travel for blind persons.  In this exploratory project, we aim to: (1) Explore and test alternative approaches to algorithm design to process intersection images and extract the information about the crosswalk, crossing signal, etc., using a database of real-world images taken by blind persons at a variety of different kinds of intersections.  (2) Test the algorithms using a portable camera connected to a notebook computer with speech output. n/a",Traffic Intersection Analysis Algorithms for the Blind,7096566,R21EY015187,"['blind aid', 'blindness', 'clinical research', 'computer simulation', 'computer system design /evaluation', 'gait', 'human subject', 'injury prevention', 'mathematical model', 'statistics /biometry', 'transportation /recreation safety', 'urban area']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2006,214738,0.027059946289701764
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,7037390,R01EY015888,"['clinical research', 'computational neuroscience', 'cues', 'form /pattern perception', 'human subject', 'mathematical model', 'mental process', 'motion perception', 'neural information processing', 'neuropsychological tests', 'neuropsychology', 'psychophysics', 'space perception', 'statistics /biometry', 'time perception', 'vision tests', 'visual depth perception', 'visual stimulus', 'visual tracking']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2006,215583,0.016532287111625205
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6985366,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2006,183324,0.0037960460428726485
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6995047,R43EY014487,"['artificial intelligence', 'biomedical equipment development', 'clinical research', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'data collection', 'digital imaging', 'functional ability', 'human subject', 'image processing', 'medical rehabilitation related tag', 'patient oriented research', 'portable biomedical equipment', 'questionnaires', 'vision aid', 'vision disorders', 'visual fields', 'visual perception', 'visual threshold', 'visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2005,144106,0.029168632549910763
"Multiresolution Autofocusing for Automated Microscopy    DESCRIPTION (provided by applicant): This project will further develop and refine an innovative digital auto-focus technology for automated microscopy. Auto-focusing is essential to automated microscope imaging. Currently available techniques rely on various algorithms of focus computation at a single image resolution and suffer from inherent performance limitations, which affect their success and utilization in clinical and research applications. Auto-focusing for fluorescence microscopy, for example, represents a serious challenge to existing methods for desired accuracy, reliability and speed since in this case the images have very low signal-to-noise ratio and narrow depth-of-fields while specimen exposure to fluorescent excitation must be minimized to avoid photo-bleaching and formation of undesirable substances such as free radicals and singlet oxygen. We propose a novel multi-resolution image analysis approach to microscope auto-focusing, based on the recently developed mathematical theory of wavelet transform. The new approach overcomes a number of inherent limitations of currently available techniques, and holds the promise to make the measurement of the microscope focus function and the detection of best-focus imaging position considerably more accurate, reliable, and fast. This innovative technology will significantly increase the ability and efficacy of automated microscope instruments for a wide range of clinical and research applications where a large number of specimens need to be imaged and quantitatively analyzed on a routine basis. During the Phase 1 project we investigated the feasibility of the proposed technology for fluorescence microscopy. We developed software to implement the algorithms for multi-resolution focus function measurements and for in-focus imaging position search. We evaluated the new approach in software simulation on a variety of sample image stacks of cytogenetic FISH specimens, and compared it with all current best-performing methods for microscope auto-focusing using the criteria of (1) accuracy, (2) range, (3) robustness, and (4) speed. The Phase 1 results suggest that, by using a proper wavelet-based auto-focus function, the new multi-resolution method significantly outperforms all competing methods in each of the aforementioned performance categories, and clearly exceeds the Phase 1 feasibility criteria. In the Phase 2 project, we will further develop, refine, integrate, and validate the new technology in real-time operation environment. We plan to build a prototype system with multi-resolution auto-focusing capabilities for both fluorescence and bright-field microscope imaging. We will evaluate the system extensively for a variety of applications including genetics, pathology, and cytology. We will beta test the new system and technology in routine clinical laboratory environment and optimize the technology as end user input and feedbacks are gathered. Once fully developed and qualified, this new technology will be patented and incorporated into future IRIS automated imaging cytometry instruments. It will also be made commercially available to Applied Imaging Corporation and other manufacturers of automated microscope instruments through licensing agreements and partnerships.           n/a",Multiresolution Autofocusing for Automated Microscopy,6951446,R44RR016817,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'flow cytometry', 'fluorescence microscopy', 'fluorescent in situ hybridization', 'human data', 'image enhancement', 'image processing', 'mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2005,318350,0.007839306653963063
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6879624,R01HD041386,"['Internet', 'artificial intelligence', 'attitude', 'behavior prediction', 'behavior test', 'behavioral /social science research tag', 'clinical research', 'computer human interaction', 'cues', 'data collection methodology /evaluation', 'human subject', 'imagery', 'interactive multimedia', 'mathematics', 'population survey', 'questionnaires', 'space perception', 'visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2005,206550,0.020099878668105142
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6935840,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2005,399984,-0.014425311281655485
"Traffic Intersection Analysis Algorithms for the Blind DESCRIPTION (provided by applicant): This project aims to explore, develop and test computer vision algorithms to analyze images of street intersections from a camera worn by a blind person.  Urban intersections are the most dangerous parts of a blind person's travel.  They are becoming increasingly complex, making safe crossing using conventional blind orientation and mobility techniques ever more difficult.  We will explore computer vision algorithms to help a blind person find the crosswalk, find the pedestrian signal button, determine when the ""walk"" light is on, and alert him/her to any veering out of the crosswalk.  We will emphasize the development of completely novel methods of analyzing non-ideal images including shadows, occlusions and other irregularities using spatial grouping techniques based on Bayesian inference.  The resulting algorithms are intended for eventual integration as modules for a computer vision system we are already developing to help blind persons with travel tasks such as finding and reading aloud printed signs and negotiating street crossings.  The combined system would have potential for a radical advance in independent travel for blind persons.  In this exploratory project, we aim to: (1) Explore and test alternative approaches to algorithm design to process intersection images and extract the information about the crosswalk, crossing signal, etc., using a database of real-world images taken by blind persons at a variety of different kinds of intersections.  (2) Test the algorithms using a portable camera connected to a notebook computer with speech output. n/a",Traffic Intersection Analysis Algorithms for the Blind,6920594,R21EY015187,"['blind aid', 'blindness', 'clinical research', 'computer simulation', 'computer system design /evaluation', 'gait', 'human subject', 'injury prevention', 'mathematical model', 'statistics /biometry', 'transportation /recreation safety', 'urban area']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2005,255198,0.027059946289701764
"The formation of visual objects    DESCRIPTION (provided by applicant): Perceptual grouping is the process by which the initially raw and inchoate visual image is organized into perceptual ""objects"". What spatial factors induce perceptual grouping? What is the sequence of computations whereby the image is progressively organized? One source of difficulty in modeling this process is that, unlike many aspects of early vision, perceptual grouping inherently involves non-local: computations - integration of cues from potentially distant locations in the image. Another difficulty in understanding perceptual grouping has been the lack of objective and temporally precise methods for actually measuring the observer's subjective organization of an image. This proposal seeks to combine (a) recent advances in understanding the non-local computations involved in perceptual grouping with (b) novel experimental methods for determining subjective organization. The experimental methods are based on the finding that perceptual objects enjoy certain objectively measurable benefits, including more efficient visual comparisons within them than between distinct objects. This proposal seeks to use this effect to discover what the visual system in fact treats as a perceptual object, and how this percept develops over the course of processing. Most of the proposed experiments involve carefully constructed artificial stimuli with various grouping cues in force, designed to allow detailed comparisons of the strength, interaction, and time-course of each potential grouping cue. In addition, several experiments involve natural images, in order to uncover how perceptual organization proceeds under more naturalistic conditions. This research may lead to technological advancement in the area of computer vision, as well as to better understanding of disorders of perceptual organization such as visual agnosia and dyslexia.         n/a",The formation of visual objects,6924971,R01EY015888,"['clinical research', 'computational neuroscience', 'cues', 'form /pattern perception', 'human subject', 'mathematical model', 'mental process', 'motion perception', 'neural information processing', 'neuropsychological tests', 'neuropsychology', 'psychophysics', 'space perception', 'statistics /biometry', 'time perception', 'vision tests', 'visual depth perception', 'visual stimulus', 'visual tracking']",NEI,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,2005,222488,0.016532287111625205
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6850297,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2005,172385,0.0037960460428726485
"Multiresolution Autofocusing for Automated Microscopy    DESCRIPTION (provided by applicant): This project will further develop and refine an innovative digital auto-focus technology for automated microscopy. Auto-focusing is essential to automated microscope imaging. Currently available techniques rely on various algorithms of focus computation at a single image resolution and suffer from inherent performance limitations, which affect their success and utilization in clinical and research applications. Auto-focusing for fluorescence microscopy, for example, represents a serious challenge to existing methods for desired accuracy, reliability and speed since in this case the images have very low signal-to-noise ratio and narrow depth-of-fields while specimen exposure to fluorescent excitation must be minimized to avoid photo-bleaching and formation of undesirable substances such as free radicals and singlet oxygen. We propose a novel multi-resolution image analysis approach to microscope auto-focusing, based on the recently developed mathematical theory of wavelet transform. The new approach overcomes a number of inherent limitations of currently available techniques, and holds the promise to make the measurement of the microscope focus function and the detection of best-focus imaging position considerably more accurate, reliable, and fast. This innovative technology will significantly increase the ability and efficacy of automated microscope instruments for a wide range of clinical and research applications where a large number of specimens need to be imaged and quantitatively analyzed on a routine basis. During the Phase 1 project we investigated the feasibility of the proposed technology for fluorescence microscopy. We developed software to implement the algorithms for multi-resolution focus function measurements and for in-focus imaging position search. We evaluated the new approach in software simulation on a variety of sample image stacks of cytogenetic FISH specimens, and compared it with all current best-performing methods for microscope auto-focusing using the criteria of (1) accuracy, (2) range, (3) robustness, and (4) speed. The Phase 1 results suggest that, by using a proper wavelet-based auto-focus function, the new multi-resolution method significantly outperforms all competing methods in each of the aforementioned performance categories, and clearly exceeds the Phase 1 feasibility criteria. In the Phase 2 project, we will further develop, refine, integrate, and validate the new technology in real-time operation environment. We plan to build a prototype system with multi-resolution auto-focusing capabilities for both fluorescence and bright-field microscope imaging. We will evaluate the system extensively for a variety of applications including genetics, pathology, and cytology. We will beta test the new system and technology in routine clinical laboratory environment and optimize the technology as end user input and feedbacks are gathered. Once fully developed and qualified, this new technology will be patented and incorporated into future IRIS automated imaging cytometry instruments. It will also be made commercially available to Applied Imaging Corporation and other manufacturers of automated microscope instruments through licensing agreements and partnerships.           n/a",Multiresolution Autofocusing for Automated Microscopy,6833120,R44RR016817,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'flow cytometry', 'fluorescence microscopy', 'fluorescent in situ hybridization', 'human data', 'image enhancement', 'image processing', 'mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2004,427818,0.007839306653963063
"Optimized Retinal Camera DESCRIPTION (provided by applicant):  A low-cost, high-resolution, high-contrast color digital camera optimized for ophthalmology will be demonstrated. This Optimized Retinal Camera will be specifically tested for its effectiveness in meeting the image quality requirements for the screening and assessment of pre-proliferative and proliferative diabetic retinopathy in both traditional clinical settings and in telemedicine. The proposed device exploits recent technological advances in high sensitivity charge coupled device (CCD) cameras and digital signal processing electronics. Today's CCD cameras do not have the dynamic range to image the human retina. The human retina is characterized by regions of high reflectivity (20-40 percent), such as the optic disc, and very low reflectivity (<2 percent), such as the macula and fovea. Further, these existing digital cameras treat each of the color channels in the same manner and do not consider the special, red-saturated characteristics of the retina. The approach builds on existing fundus imaging technology developed by Kestrel for the National Eye Institute. The proposed Optimized Retinal Camera will be shown to offer significant improvement over existing digital color cameras by addressing each of the deficiencies mentioned above. Joslin Diabetes Center, the University of Iowa Department of Opthalmology, and the University of New Mexico Health Sciences Center will provide independent, ""masked"" evaluation of the optimized digital retinal images. n/a",Optimized Retinal Camera,6752819,R44EY013038,"['artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'charge coupled device camera', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'diabetic retinopathy', 'digital imaging', 'human subject', 'image processing', 'ophthalmoscopy', 'thermodynamics']",NEI,KESTREL CORPORATION,R44,2004,340158,0.023609090181230634
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6743701,R01HD041386,"['Internet', 'artificial intelligence', 'attitude', 'behavior prediction', 'behavior test', 'behavioral /social science research tag', 'clinical research', 'computer human interaction', 'cues', 'data collection methodology /evaluation', 'human subject', 'imagery', 'interactive multimedia', 'mathematics', 'population survey', 'questionnaires', 'space perception', 'visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2004,201780,0.020099878668105142
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6834860,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2004,350214,-0.014425311281655485
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6710523,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,139234,0.029168632549910763
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6665322,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,245656,0.029168632549910763
"MicroSeer, Analysis software for microscopy imagery  DESCRIPTION (provided by applicant): This project will create new pattern recognition software to improve the analysis and interpretation of in vivo  biomedical imagery. Currently, researchers can get remarkably detailed images of living cells and their  constituent proteins using molecular genetic and microscopy-based approaches in conjunction with  sophisticated microscopy hardware. Available image analysis techniques and software, however, lag behind  the power of this new imaging equipment to visualize the microscopic world.  This phase I SBIR project will apply existing technology in spatial analysis of satellite image data to microscopy data, create new statistical techniques specific to the study of spatial association of proteins in  cells, and create software that implements these statistics for use in the analysis of spatial association timeslice in vivo biomedical imagery.   n/a","MicroSeer, Analysis software for microscopy imagery",6581125,R43EB000575,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' image processing', ' statistics /biometry', ' structural biology']",NIBIB,BIOMEDWARE,R43,2003,177261,0.02270253336089577
"Vessel Segmentation/Registration from Ultrasound Images    DESCRIPTION (provided by applicant):    Ultrasound is widely used for imaging of blood vessels as it is non-invasive, real-time, and relatively inexpensive. This proposal focuses on segmentation of abdominal aortic aneurysms (AAA) from ultrasound images with extension to other vascular imaging applications in the long term. Reliable quantitative evaluation of AAAs plays a pivotal role in diagnoses and frequent follow-up studies needed to avoid life-threatening rupture. These studies require vessel segmentation (for size analysis) and registration between serial studies (for monitoring the progression of the disease before and/or after vascular repair). AAA evaluation is routinely carried out for both high-risk patient populations and those treated with endovascular repair. Currently, AAA management is primarily based on measurements from two-dimensional (2-D) slices in CT scans. AAA monitoring and follow-up could be improved by 1) measurement from 3-D reconstructions, and 2) use of ultrasound imaging to minimize radiation exposure and reduce costs. 3-D ultrasound reconstructions provide accuracy comparable to that of CT. However, large inter-observer variability and long processing times preclude routine clinical use of 3-D image information. This research aims to develop software solutions for improved ultrasound-based AAA monitoring and other vascular diseases (in the long term). The tools used will be based on advanced image segmentation and registration algorithms involving curvature-driven image processing techniques and deformable models. The goal of the Phase I study is to establish feasibility of the proposed methods by demonstrating an improvement in the repeatability and accuracy of measurements and reduction in delineation time.         n/a",Vessel Segmentation/Registration from Ultrasound Images,6641019,R43HL069540,"['abdomen', ' aorta aneurysm', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' gastrointestinal circulation disorder', ' gastrointestinal imaging /visualization', ' human data', ' mathematics', ' three dimensional imaging /topography']",NHLBI,INSIGHTFUL CORPORATION,R43,2003,99621,0.020460285897658255
"Optimized Retinal Camera DESCRIPTION (provided by applicant):  A low-cost, high-resolution, high-contrast color digital camera optimized for ophthalmology will be demonstrated. This Optimized Retinal Camera will be specifically tested for its effectiveness in meeting the image quality requirements for the screening and assessment of pre-proliferative and proliferative diabetic retinopathy in both traditional clinical settings and in telemedicine. The proposed device exploits recent technological advances in high sensitivity charge coupled device (CCD) cameras and digital signal processing electronics. Today's CCD cameras do not have the dynamic range to image the human retina. The human retina is characterized by regions of high reflectivity (20-40 percent), such as the optic disc, and very low reflectivity (<2 percent), such as the macula and fovea. Further, these existing digital cameras treat each of the color channels in the same manner and do not consider the special, red-saturated characteristics of the retina. The approach builds on existing fundus imaging technology developed by Kestrel for the National Eye Institute. The proposed Optimized Retinal Camera will be shown to offer significant improvement over existing digital color cameras by addressing each of the deficiencies mentioned above. Joslin Diabetes Center, the University of Iowa Department of Opthalmology, and the University of New Mexico Health Sciences Center will provide independent, ""masked"" evaluation of the optimized digital retinal images. n/a",Optimized Retinal Camera,6583366,R44EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' human subject', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R44,2003,431799,0.023609090181230634
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6629976,R01HD041386,"['Internet', ' artificial intelligence', ' attitude', ' behavior prediction', ' behavior test', ' behavioral /social science research tag', ' clinical research', ' computer human interaction', ' cues', ' data collection methodology /evaluation', ' human subject', ' imagery', ' interactive multimedia', ' mathematics', ' population survey', ' questionnaires', ' space perception', ' visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2003,205876,0.020099878668105142
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by investigator):  The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47% to 58% of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy, with 8% stating that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side-effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better-informed treatment decisions, and facilitate coping when it occurs.         n/a",Computer Imaging to Diminish Alopecia Distress,6586963,R43CA099873,"['alopecia', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted patient care', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' coping', ' desensitization psychotherapy', ' drug adverse effect', ' female', ' imaging /visualization /scanning', ' psychological aspect of cancer', ' quality of life', "" women's health""]",NCI,"BARRON ASSOCIATES, INC.",R43,2003,99973,-0.015396912112354033
"Novel Methods for Automated Key Image Selection    DESCRIPTION (provided by the applicant):  Significant new knowledge about human behavior and the brain has come to light in recent years, due in part to rapid technical developments in imaging. As the role of imaging becomes increasingly important in neurosciences, effective methods for managing and retrieving images will become even more critical; without such advances, further progress will be hindered. The goal of this proposal is the automated summarization of large imaging sets. Image summarization proffers a method to compress imaging studies by selecting only pertinent image slices that objectively document a patient's condition; as such, its applications include multimedia electronic medical records, telemedicine, and teaching files. In Phase I, development is focused on a customizable brain atlas used for registering patient imaging studies in order to select key images. This phase addresses selection of images from ""normal"" studies and studies with only subtle morphological changes, as typical of most patients with psychiatric disorders. Automatic techniques for customizing the atlas to imaging study acquisition parameters are developed, in addition to registration methods for mapping the atlas to the patient's original study. Building from this initial work, Phase II expands to encompass selection of images from ""abnormal"" studies that exhibit gross morphological changes through principle component analysis, further customization of the atlas for different age groups (e.g., pediatric), and incorporation of structured data entry (SDE) and natural language processing (NLP) of medical reports to help guide automatic selection of key images. The resultant product will be a fully automated software system that can select relevant images from any imaging study. Initial evaluation in Phase I will examine the performance of the contrast customizable atlas and summarization/relevant slice selection, as compared to human experts.         n/a",Novel Methods for Automated Key Image Selection,6583176,R43MH065764,"['archives', ' biomedical automation', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' human data', ' image processing', ' method development']",NIMH,MEDAXIS CORPORATION,R43,2003,93365,0.017062170053940524
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6636516,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2003,374063,-0.002619954552181166
"SEED LOCALIZER FOR IMAGE GUIDED PROSTATE BRACHYTHERAPY Permanent implantation of radioactive seeds is a viable and effective therapeutic option widely used today for early-stage prostate cancer. Compared to external radiation therapy in which radiation must penetrate healthy tissues in order to reach cancer cells, implantation of low-energy radionuclides permits highly localized delivery of radiation.  Although the implant procedure has improved in recent years with the help of computerized treatment planning and image guidance techniques, significant enhancement of clinical outcome is expected from implementation of real-time intraoperative dosimetry and optimization. Intraoperative evaluation of dose delivery would permit identification of underdosed regions and remedial seed placement, thus ensuring that the entire prostate volume receive the prescribed dose.  However, before the concept can be realized, the problem of real-time seed localization must be solved.  This is the focus of this investigation.  The specific aims of the project include development of (1) a fully automated method to segment seed images from the fluoroscopic data and (2) a fully automated method to identify individual seed positions including those that are superposed.  The image segmentation will be accomplished by a region based adaptive thresholding technique.  Subsequent localization of the seeds will be performed by a hierarchical decision process aided by an artificial intelligence controlled seed classifier.  n/a",SEED LOCALIZER FOR IMAGE GUIDED PROSTATE BRACHYTHERAPY,6498041,R21CA089061,"['artificial intelligence', ' biomedical automation', ' computer assisted patient care', ' computer simulation', ' computer system design /evaluation', ' fluoroscopy', ' neoplasm /cancer radionuclide therapy', ' phantom model', ' prostate neoplasms', ' radiation therapy dosage']",NCI,UNIVERSITY OF WASHINGTON,R21,2002,148557,0.008642828407757954
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6580977,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2002,246164,0.029168632549910763
"Ultrasonic Registration of Knee Anatomy to MRI Images  DESCRIPTION (provided by applicant): The proposed research will investigate the feasibility of using intra-operative ultrasound (US) images to noninvasively register the bone surfaces of the knee to preoperative magnetic resonance (MR) images. A surgical navigation system, KneeNav, is being developed by CASurgica for intraoperatively planning the proper location of ligament attachment sites and drill tunnel locations and then guiding the surgeon to execute the plan. Despite agreement on the correct points of insertion, great variability exists in tunnel placement among surgeons and the rate of misplaced tunnels in ACL reconstruction surgery has been reported to be between 10-40 percent. Malpositioning of the bone tunnels is the main reason for revision surgery. The proposed research would increase the accuracy of the procedure versus current videoscopic techniques or versus competitive image guidance systems. The research plan is to establish a ""gold standard"" for registration accuracy using reconstructed CT scans, point-based surface matching algorithms, and optical tracking. Reconstructed MR models will be substituted for CT models and the accuracy reassessed. The US probe will then be calibrated and US surface collection will then be substituted for point based collection and the accuracy reassessed. Finally, registration of US directly to MR without reconstruction will be assessed.  PROPOSED COMMERCIAL APPLICATION: Not Available. n/a",Ultrasonic Registration of Knee Anatomy to MRI Images,6550304,R41AR049104,"['artificial intelligence', ' bioimaging /biomedical imaging', ' bone imaging /visualization /scanning', ' computed axial tomography', ' computer program /software', ' knee', ' magnetic resonance imaging', ' orthopedics', ' surgery material /equipment']",NIAMS,"CASURGICA, INC.",R41,2002,99995,0.015392728481901716
"Multiresolution Autofocusing for Automated Cytogenetics The goal of this project is to develop innovative digital microscope autofocusing techniques for automated cytogenetics applications.  We propose a novel multi-resolution image analysis approach to focus measurement and detection, based on the recently developed mathematical theory of wavelet transform.  In comparison to currently available single-resolution techniques, the proposed method overcomes their fundamental limitations and promises considerably more accurate, reliable and faster means to compute and determine in-focus image position for image acquisition.  This will significantly increase the ability and efficacy of automated scanning microscope instruments for clinical and cancer cytogenetics applications. In Phase 1 we will investigate the feasibility of the proposed method based on its utilization in fluorescence microscopy.  We will develop and implement the algorithm and software for multi-resolution focus function computation and in-focus position determination.  We will test and evaluate the new method against the current best-performing algorithms by comparing (1) Accuracy; (2)  Range; (3)  Insensitivity to other parameters; and (4)  Speed. If the new approach achieves superior performance, in Phase 2 the technique will be further developed and extended to bright-field microscopy applications.  When fully developed, the new technology will be made available to Applied Imaging (AIC) for integration into the PowerGene cytogenetics automation products. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new techniques are developed and qualified for routine application, they will be made available to AIC for incorporation into the PowerGene product line of cytogenetics automation equipment, both in new systems sold and as an upgrade to existing systems already in use in cytogenetics labs, thus commercializing the technology quickly. n/a",Multiresolution Autofocusing for Automated Cytogenetics,6443502,R43RR016817,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' cytogenetics', ' digital imaging', ' fluorescence microscopy', ' fluorescent in situ hybridization', ' human data', ' image enhancement', ' image processing', ' mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R43,2002,91727,0.02865076935911737
"Deployment Framework for Medical Imaging Applications DESCRIPTION (provided by applicant): There are many reasons for the relatively slow proliferation of advanced medical image processing methods but a significant reason is the present paradigm for providing access: most applications are still tied to proprietary software and hardware environments that carry significant up-front costs. The ultimate intent of this work is leverage commodity computing technologies to develop an open, extensible framework for deploying medical image processing applications in the heterogeneous, networked computing environment of today. The framework will provide clinicians and researchers access to state-of-the-art image processing applications regardless of their particular computing platform or locally available computing resources connecting them with federated database resources, with high-end computing resources, or even with their colleagues in a peer-to-peer computing environment. The aims for Phase I of this project are: (1) Demonstrate that the framework provides access to image processing applications to an extent that is largely independent of local computing resources. (2) Demonstrate that the framework is general in that the same components can be reused for deploying a wide variety of medical imaging applications. (3) Demonstrate that the framework is customizable both by third-party developers and by end-users allowing power-users to both create and deploy new applications. Work in Phase II will extend the framework and develop two-demonstration applications--computer aided diagnosis (CAD) for mammography and multimodality image fusion. The ultimate goal is to obtain key partnerships and the private equity investment necessary for commercialization, which will proceed by launching revenue-generating versions of the CAD and image fusion applications. n/a",Deployment Framework for Medical Imaging Applications,6494576,R44EB000149,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computed axial tomography', ' computer assisted diagnosis', ' computer human interaction', ' computer network', ' computer program /software', ' computer system design /evaluation', ' human data', ' image processing', ' mammography', ' mathematics', ' positron emission tomography', ' telemedicine']",NIBIB,"FRONTIER MEDICAL, LLC",R44,2002,143577,-0.0003596652507982627
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6520333,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2002,363261,-0.002619954552181166
"SEED LOCALIZER FOR IMAGE GUIDED PROSTATE BRACHYTHERAPY Permanent implantation of radioactive seeds is a viable and effective therapeutic option widely used today for early-stage prostate cancer. Compared to external radiation therapy in which radiation must penetrate healthy tissues in order to reach cancer cells, implantation of low-energy radionuclides permits highly localized delivery of radiation.  Although the implant procedure has improved in recent years with the help of computerized treatment planning and image guidance techniques, significant enhancement of clinical outcome is expected from implementation of real-time intraoperative dosimetry and optimization. Intraoperative evaluation of dose delivery would permit identification of underdosed regions and remedial seed placement, thus ensuring that the entire prostate volume receive the prescribed dose.  However, before the concept can be realized, the problem of real-time seed localization must be solved.  This is the focus of this investigation.  The specific aims of the project include development of (1) a fully automated method to segment seed images from the fluoroscopic data and (2) a fully automated method to identify individual seed positions including those that are superposed.  The image segmentation will be accomplished by a region based adaptive thresholding technique.  Subsequent localization of the seeds will be performed by a hierarchical decision process aided by an artificial intelligence controlled seed classifier.  n/a",SEED LOCALIZER FOR IMAGE GUIDED PROSTATE BRACHYTHERAPY,6227506,R21CA089061,"['artificial intelligence', ' biomedical automation', ' computer assisted patient care', ' computer simulation', ' computer system design /evaluation', ' fluoroscopy', ' neoplasm /cancer radionuclide therapy', ' phantom model', ' prostate neoplasms', ' radiation therapy dosage']",NCI,UNIVERSITY OF WASHINGTON,R21,2001,146790,0.008642828407757954
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6445973,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2001,354009,0.0373039097259824
"MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING   A low-cost, high-resolution, high-contrast color digital camera optimized        for ophthalmology will be demonstrated. The maximum entropy camera         will be tested for its effectiveness in meeting the image quality requirements       for telemedicine and for remote screening of pre-proliferative and                   proliferative diabetic retinopathy. The proposed device exploits recent              technological advances in high sensitivity CCD cameras and digital signal            processing electronics. Today's low cost 8-bit CCD cameras do not have the           dynamic range to image the human retina, which is characterized by regions of        high reflectivity (20-40 percent), such as the optic disc, and very low              reflectivity (<2 percent), such as the macula and fovea. Existing digital            cameras used in ophthalmology are not designed to deal with the high dynamic         range and do not consider the special re-saturated characteristics of the            retina. The proposed device will be shown to offer significant improvement over      existing digital color cameras by addressing each of the deficiencies                mentioned.                                                                           PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING,6292349,R43EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R43,2001,107706,0.01843173194146199
"IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION Colorectal carcinoma is the second leading cause of cancer deaths in the         United States today.  In an effort to reduce mortality, Congress                 recently included a provision in the Balanced Budget Act of 1997 to              support screening colonoscopy as a means for early detection and removal         of colorectal polyps, the precursors to cancer.  In this country alone,          more than 68 million people are eligible for colorectal screening, but           the majority are unlikely to comply with screening recommendations               because of the costs, risks, discomfort, and inconvenience associated            with traditional endoscopy.  Furthermore, even if a small fraction of            eligible persons are examined, the number of available                           gastroenterologists would be insufficient to perform so many procedures.                                                                                          We have developed a new technique, called virtual colonoscopy (VC), as           an alternative to screening diagnostic colonoscopy (DC). The procedure           consists of cleansing a patient's colon, inflating the colon with air,           scanning the abdomen with helical computed tomography (CT), and                  generating a rapid sequence of three-dimensional (3D) images of the              colon by means of virtual reality computer technology.  Although VC              makes possible the visualization of 3D images of the colon in a manner           similar to that of DC, a correct diagnosis depends upon a physician's            ability to identify small and sometimes subtle polyps within hundreds            of 3D images.  The absence of visual cues that normally occur with DC            makes VC interpretation tedious and susceptible to error.                                                                                                         With support from a National Science Foundation (NSF) grant, we have             developed a computer-assisted polyp detection (CAPD) system that                 calculates areas of abnormal colon wall thickness in helical CT image            data in order to highlight potential polyps in the 3D images.  A                 physician ultimately determines if each detected lesion represents a             true abnormality.  Although we have found CAPD to be sensitive for               finding subtle abnormalities, poor specificity can be attributed to              several obstacles, including imprecise image segmentation, limited               feature analysis, and suboptimal bowel preparation prior to helical CT           scanning.  With these challenges in mind, we propose research to perfect         CAPD. Our specific aims are as follows: 1. To develop an image                   segmentation algorithm that accurately isolates the colon from helical           CT image data; 2. To improve our polyp detection algorithm with expanded         feature analysis and artificial intelligence methods; 3. To optimize             bowel preparation with digital subtraction of opacified feces and                controlled gas distention; and 4. To validate the accuracy of VC, with           the modifications achieved in the stated aims, by comparing the results          of VC and DC in 200 patients undergoing usual-care colonoscopy.                                                                                                   If VC with CAPD proves accurate and efficient in the diagnosis of                colorectal polyps, it could evolve into a simple laboratory test,                thereby meeting the demand for worldwide colorectal cancer screening.             n/a",IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION,6376842,R01CA078485,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical research', ' colon neoplasms', ' colon polyp', ' computed axial tomography', ' computer assisted diagnosis', ' computer simulation', ' diagnosis design /evaluation', ' endoscopy', ' gastrointestinal imaging /visualization', ' human subject', ' image enhancement', ' mathematical model', ' model design /development', ' neoplasm /cancer diagnosis']",NCI,WAKE FOREST UNIVERSITY,R01,2001,607399,-0.03865586990722819
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6484619,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2001,337739,-0.002619954552181166
"METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES DESCRIPTION (Adapted from Applicant's Abstract):  The aim of this proposal       is to further develop and validate algorithms for analysis of SPAMM MR           cardiac images based on novel spline methods.  MRI is unique in its ability      to non-invasively and selectively alter tissue magnetization, and create         tagged patterns within the deforming tissue such as the heart muscle.  The       resulting pattern defines a time-varying curvilinear coordinate system on        the underlying tissue, allowing for precise and quantitative measurement of      tissue motion and deformation.  The investigators are developing two             frameworks for analysis of SPAMM tagged images, both of these aimed at           providing a more automated and reproducible approach to analysis of SPAMM        data, as well as providing dense 3-D displacement information at all points      within the LV myocardium.  The investigators propose to (a) further develop      and extend our analyses techniques.  The extensions considered will all be       related and based on currently developed computer vision-based techniques        for regional LV wall motion analysis, that operates either on a sequence of      SA slice stacks or on a time sequence of single slice.  (b) The                  investigators will validate the motion tracking methods by comparing ""true""      and algorithm-estimated motion trajectories:  1) on dense field of points        derived from 3-D tagged computer models of objects that simulate the moving      LV, 2) on dense field of points derived from Finite Element Model                simulations of the constitutive equations of LV deformations (once again tag     planes will be superimposed on the time course of simulated geometries), 3)      on selected points in the LV myocardium of the in vivo heart using a porcine     model.  Here, ""true"" motion will be determined by tracking implanted image       distinguishable markers.  (c) The investigators will test whether regions of     postmortem myocardial injury imply similar-sized and locate regions of           altered deformations (as measured by parameters developed in (a)).  The          algorithm-derived LV function assessment based on the analysis of in vivo        tagged MRI sequences will be compared with postmortem myocardial injury          assessment determined by myocardial staining techniques.  The validated          parameters will also be use to examine the time-course of change in the          ischemic areas of the chronic animal models.                                      n/a",METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES,6389619,R01HL057628,"['bioimaging /biomedical imaging', ' cardiography', ' clinical research', ' computer data analysis', ' computer simulation', ' diagnosis design /evaluation', ' heart motion', ' histopathology', ' human subject', ' image processing', ' magnetic resonance imaging', ' myocardial ischemia /hypoxia', ' swine']",NHLBI,BARNES-JEWISH HOSPITAL,R01,2001,122402,-0.014589735450423125
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6210821,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2000,395990,0.0373039097259824
"IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY DESCRIPTION:  The research and development of teleradiology and telemedicine     systems has progressed through many technical and clinical endeavors.  When      dealing with large volume image transmission and storage, image data             compression is an outstanding issue in medical applications to which current     techniques were not designed to address.  The technical objectives of this       project are to develop optimized error-free as well as error-controllable        methods for medical image compression based on wavelet transform and             associated methods.  In this project, we employ both advanced artificial         intelligent and compression techniques to achieve these goals.                                                                                                    Our recent research outcomes include:  (a) development of a mathematics          approach to unify prediction, subband, and wavelet transforms, (b)               development of convolution neural network training methods to obtain             optimized wavelet kernel, (c) development of a data splitting technique to       improve edge accuracy and to provide error-control methods, and (d)              development of an integer implementation method for all wavelet transforms,      etc.  Based on the above technical advances, we propose to use integer form      of an adaptive (optimized) wavelets in conjunction with newly developed          coding methods such as ""partitioning in hierarchical trees"" (PHT) for            lossless compression.  For error-controllable approaches, we propose to use      adaptive wavelets coupled with optimized neural network prediction methods       in this study.  Since lossless compression is a part of the error -              controllable method, both systems can be implemented in the same scheme          which is a breakthrough approach in the field.  We will compare the              compression results (i.e., compression ratio and speed) of the proposed          compression methods with those of the current wavelet techniques using the       embedded zero-tree coding method.  At the end of the project, we will            deliver a software package for the radiological society.  Hence, the             evaluation for various clinical applications using the proposed methods can      be performed by the investigators.                                                                                                                                As the field of telemedicine is rapidly growing, we believe that development     of a dedicated compression module for economical storage and fast                communication of patient data (particularly for patient images) is               necessary.  This project is designed to address the related technical issues     with a strong clinical consideration.                                             n/a",IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY,6173899,R01CA079139,"['artificial intelligence', ' bioimaging /biomedical imaging', ' charge coupled device camera', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' human data', ' image processing', ' radiology', ' telemedicine']",NCI,GEORGETOWN UNIVERSITY,R01,2000,176034,0.025481123283089945
"WAVELET ENHANCEMENT OF CHROMOSOME BANDING PATTERNS This project aims to develop and commercialize significantly improved software for digital enhancement of the detail of chromosome banding patterns in microscopic images. These investigators have developed an innovative technique for this application, based upon wavelet transforms and multiresolution image analysis. Used with modern computerized chromosome analysis the proposed technique promises significantly improved enhancement of chromosome banding patterns and more effective visual detection of subtle rearrangements. This will help clinicians and researchers detect previously invisible or sub-visible band pattern alterations in conventional and high resolution banding. It will significantly increase the ability of automated instruments to assist the evaluation of chromosome alterations in clinical samples and in normal and neoplastic mammalian cells. During Phase I we implemented and tested three wavelet transforms with desirable mathematical properties. We developed a prototype multiresolution image processing system for chromosome enhancement. We obtained extremely encouraging results, strongly suggesting that these techniques offer considerably improved enhancement capability over conventional methods. and clearly demonstrating the feasibility of this approach. In Phase II we will complete the implementation and refinement of the software. We will implement several wavelet design approaches and evaluate many wavelet transform basis function sets that potentially can bring out relevant detail in chromosome banding patterns. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new enhancement techniques are developed and qualified for routine application, they will be incorporated into PSII's PowerGene products, both in new systems sold and as an upgrade to existing systems.  n/a",WAVELET ENHANCEMENT OF CHROMOSOME BANDING PATTERNS,6181715,R44HD033658,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' chromosome aberrations', ' chromosomes', ' computer data analysis', ' computer program /software', ' computer simulation', ' cytogenetics', ' digital imaging', ' image enhancement', ' image processing', ' molecular dynamics']",NICHD,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2000,260552,0.024189150927790913
"THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES DESCRIPTION (Taken from application abstract):  Recent advances in               understanding neuronal functions have led to an expanded scientific interest     in defining the organization of the nervous system so the spatial correlates     of these functions can be identified.  This interest has been formalized as      the Human Brain Project, an ambitious multi disciplinary effort to map the       nervous system from the organismal to the macromolecular levels.  One of the     greatest challenges of this effort is to preserve the complex                    three-dimensional relationships that occur between neuronal structures.          This problem will require new methods for data acquisition as well as data       visualization.                                                                                                                                                    The project described here is an interdisciplinary effort to derive              three-dimensional reconstructions of synaptic architecture from stereo           electron micrographs acquired from multiple viewpoints.  The collaboration       combines advanced ultrastructural visualization techniques with massively        parallel computational methods and an innovative set of pattern recognition,     stereo correspondence and depth mapping algorithms.  Our goal is to              integrate structural information from numerous images into a single,             high-accuracy three-dimensional reconstruction of the synaptic cytoskeleton.     The immediate result of this collaboration will be an improved understanding     of the spatial relationships between synaptic macromolecules.  More              importantly, the project will produce a set of computational tools that can      be applied to stereo image data sets of various areas of the nervous system,     from the macroscopic to the molecular level.  Finally, our studies will          advance the state-of-the-art of parallel computation and interactive             reconstruction methods that can provide novel solutions to difficult             problems of neuroscience visualization.                                           n/a",THREE DIMENSIONAL RECONSTRUCTION OF SYNAPSES,6185220,R01LM006326,"['artificial intelligence', ' bioimaging /biomedical imaging', ' brain mapping', ' cell cell interaction', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' cytoskeleton', ' data collection', ' electron microscopy', ' image processing', ' imaging /visualization /scanning', ' macromolecule', ' method development', ' nerve endings', ' neurons', ' parallel processing', ' stereophotography', ' structural biology', ' synapses']",NLM,UNIVERSITY OF MARYLAND BALTIMORE,R01,2000,117821,0.0006421981208832391
"IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION Colorectal carcinoma is the second leading cause of cancer deaths in the         United States today.  In an effort to reduce mortality, Congress                 recently included a provision in the Balanced Budget Act of 1997 to              support screening colonoscopy as a means for early detection and removal         of colorectal polyps, the precursors to cancer.  In this country alone,          more than 68 million people are eligible for colorectal screening, but           the majority are unlikely to comply with screening recommendations               because of the costs, risks, discomfort, and inconvenience associated            with traditional endoscopy.  Furthermore, even if a small fraction of            eligible persons are examined, the number of available                           gastroenterologists would be insufficient to perform so many procedures.                                                                                          We have developed a new technique, called virtual colonoscopy (VC), as           an alternative to screening diagnostic colonoscopy (DC). The procedure           consists of cleansing a patient's colon, inflating the colon with air,           scanning the abdomen with helical computed tomography (CT), and                  generating a rapid sequence of three-dimensional (3D) images of the              colon by means of virtual reality computer technology.  Although VC              makes possible the visualization of 3D images of the colon in a manner           similar to that of DC, a correct diagnosis depends upon a physician's            ability to identify small and sometimes subtle polyps within hundreds            of 3D images.  The absence of visual cues that normally occur with DC            makes VC interpretation tedious and susceptible to error.                                                                                                         With support from a National Science Foundation (NSF) grant, we have             developed a computer-assisted polyp detection (CAPD) system that                 calculates areas of abnormal colon wall thickness in helical CT image            data in order to highlight potential polyps in the 3D images.  A                 physician ultimately determines if each detected lesion represents a             true abnormality.  Although we have found CAPD to be sensitive for               finding subtle abnormalities, poor specificity can be attributed to              several obstacles, including imprecise image segmentation, limited               feature analysis, and suboptimal bowel preparation prior to helical CT           scanning.  With these challenges in mind, we propose research to perfect         CAPD. Our specific aims are as follows: 1. To develop an image                   segmentation algorithm that accurately isolates the colon from helical           CT image data; 2. To improve our polyp detection algorithm with expanded         feature analysis and artificial intelligence methods; 3. To optimize             bowel preparation with digital subtraction of opacified feces and                controlled gas distention; and 4. To validate the accuracy of VC, with           the modifications achieved in the stated aims, by comparing the results          of VC and DC in 200 patients undergoing usual-care colonoscopy.                                                                                                   If VC with CAPD proves accurate and efficient in the diagnosis of                colorectal polyps, it could evolve into a simple laboratory test,                thereby meeting the demand for worldwide colorectal cancer screening.             n/a",IMPROVING VIRTUAL COLONOSCOPY WITH COMPUTER DETECTION,6173999,R01CA078485,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical research', ' colon neoplasms', ' colon polyp', ' computed axial tomography', ' computer assisted diagnosis', ' computer simulation', ' diagnosis design /evaluation', ' endoscopy', ' gastrointestinal imaging /visualization', ' human subject', ' image enhancement', ' mathematical model', ' model design /development', ' neoplasm /cancer diagnosis']",NCI,WAKE FOREST UNIVERSITY,R01,2000,563099,-0.03865586990722819
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6193019,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN,R01,2000,478050,-0.002619954552181166
"METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES DESCRIPTION (Adapted from Applicant's Abstract):  The aim of this proposal       is to further develop and validate algorithms for analysis of SPAMM MR           cardiac images based on novel spline methods.  MRI is unique in its ability      to non-invasively and selectively alter tissue magnetization, and create         tagged patterns within the deforming tissue such as the heart muscle.  The       resulting pattern defines a time-varying curvilinear coordinate system on        the underlying tissue, allowing for precise and quantitative measurement of      tissue motion and deformation.  The investigators are developing two             frameworks for analysis of SPAMM tagged images, both of these aimed at           providing a more automated and reproducible approach to analysis of SPAMM        data, as well as providing dense 3-D displacement information at all points      within the LV myocardium.  The investigators propose to (a) further develop      and extend our analyses techniques.  The extensions considered will all be       related and based on currently developed computer vision-based techniques        for regional LV wall motion analysis, that operates either on a sequence of      SA slice stacks or on a time sequence of single slice.  (b) The                  investigators will validate the motion tracking methods by comparing ""true""      and algorithm-estimated motion trajectories:  1) on dense field of points        derived from 3-D tagged computer models of objects that simulate the moving      LV, 2) on dense field of points derived from Finite Element Model                simulations of the constitutive equations of LV deformations (once again tag     planes will be superimposed on the time course of simulated geometries), 3)      on selected points in the LV myocardium of the in vivo heart using a porcine     model.  Here, ""true"" motion will be determined by tracking implanted image       distinguishable markers.  (c) The investigators will test whether regions of     postmortem myocardial injury imply similar-sized and locate regions of           altered deformations (as measured by parameters developed in (a)).  The          algorithm-derived LV function assessment based on the analysis of in vivo        tagged MRI sequences will be compared with postmortem myocardial injury          assessment determined by myocardial staining techniques.  The validated          parameters will also be use to examine the time-course of change in the          ischemic areas of the chronic animal models.                                      n/a",METHODS FOR ANALYSIS OF TAGGED MR CARDIAC IMAGES,6184044,R01HL057628,"['bioimaging /biomedical imaging', ' cardiography', ' clinical research', ' computer data analysis', ' computer simulation', ' diagnosis design /evaluation', ' heart motion', ' histopathology', ' human subject', ' image processing', ' magnetic resonance imaging', ' myocardial ischemia /hypoxia', ' swine']",NHLBI,BARNES-JEWISH HOSPITAL,R01,2000,119129,-0.014589735450423125
"TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH Developing artificial intelligence technology for medical imaging applications requires training models on large and diverse datasets.  Currently, aggregation of large data repositories, including radiology and pathology images, is limited by concerns around patient privacy.  In order to successfully share medical images, an institution must be able to quickly and accurately de-identify large numbers of images in batches.  This process is currently manual and time-consuming. We propose a pipeline to remove PHI from both radiology DICOM images and pathology whole slide images by leveraging machine learning, natural language processing, and compartmentalized workflow techniques to significantly reduce the human intervention needed to anonymize medical images.  In addition to examining header data in the images, we will use optical character recognition and computer vision algorithms to detect text in any location or orientation in the image, then automatically record and subsequently purge these regions. These techniques will be configured to work on a variety of image types (CT, MRI, radiograph, etc) and cover multiple OEM vendors for both radiology and pathology images. This phase I statement of work will construct the software tools, methods, and datasets necessary to facilitate a phase II where the complex algorithms needed for autonomous deidentification will be developed.  This phase II processing will be referred to throughout this document as the workflow. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH,10274086,5N91020C00023,"['Algorithms', 'Artificial Intelligence', 'Complex', 'Computer Vision Systems', 'Consumption', 'Contracts', 'Data', 'Data Set', 'Digital Imaging and Communications in Medicine', 'Elements', 'Excision', 'Head', 'Human', 'Image', 'Ingestion', 'Institution', 'Intervention', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Medical Imaging', 'Medical Technology', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology', 'Phase', 'Process', 'Radiology Specialty', 'Research', 'Sampling', 'Slide', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Vendor', 'Work', 'cancer imaging', 'data ingestion', 'data warehouse', 'file format', 'optical character recognition', 'pathology imaging', 'patient privacy', 'purge', 'radiological imaging', 'whole slide imaging']",NCI,"BIODATA CONSORTIUM, LLC",N43,2020,386526,0.06348042854396363
"Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study PROJECT SUMMARY Road traffic injuries are a major contributor to the burden of disease globally with nearly 1.3 million deaths globally and as many as 50 million injured annually with pedestrians and cyclists in low and middle-income countries (LMICs) among the most affected. Road infrastructure of the built environment (e.g., sidewalks), neighborhood design (e.g., street connectivity) and urban development (e.g., urban sprawl) are key determinants of the risk of pedestrian injuries. In LMICs, poor road infrastructure and neighborhood design are acknowledged as being important contributors to rising numbers of road traffic injuries and deaths, but there are few studies systematically identifying and quantifying what specific features of the built environment are contributing to motor vehicle collisions in these settings. Within LMIC cities, there are often large disparities where infrastructure is improved that reflect socioeconomic characteristics, leading to health inequities in road traffic injury. The paucity of georeferenced data on the built environment in LMICs has made research on road traffic injuries more difficult, though recent advances in computer vision and image analysis combined with Big Data of publicly available, georeferenced, images of roads worldwide (e.g., Google Street View, GSV) can help overcome the paucity of data and the cost and time limitations of collecting and analyzing data on the built environment in LMICs. Automated image analysis has largely been made possible via deep learning, a subfield of artificial intelligence and machine learning and relies on training neural networks to detect and label specific objects within images. These methods can drastically reduce the barriers to citywide built environment and traffic safety research in LMIC cities, thus substantially increasing research capacity and generalizability. My career goal is to become an independent investigator in global urban health with a focus on road safety and the built environment in LMICs. I propose undertaking research and training in deep learning methods applied to public health in the setting of Bogota, Colombia: 1) Develop neural networks to create a database of BE features of the road infrastructure from image data and to create neighborhood typologies from those features; 2) Assess the association between neighborhood-level BE features and typologies and pedestrian collisions and fatalities and road safety perceptions; 3) Assess the association of neighborhood social environment characteristics with pedestrian collision and fatalities, perceptions, and BE features and typologies. I am seeking additional training in 1) developing competency in deep learning methods applied to public health; 2) creating neighborhood indictors and typologies of health and the built environment; 3) applying Bayesian spatiotemporal models to understand how neighborhood characteristics and typologies influence health; 4) develop skills in multi-country collaboration, grant writing and overseeing research projects in LMICs. PROJECT NARRATIVE Roads and neighborhoods with a built environment that support safe and active transportation are a major priority in low- and middle-income countries (LMICs) due to 90% of road traffic deaths occurring in these locations, especially to pedestrians and other vulnerable road users, yet data on key built environment features at a large scale are not always readily available in these settings. My career goal is to improve population health by examining the effects of the built environment and transportation on health through the adoption and use of methods that can leverage Big Data sources and answer complex, multilevel research questions by overcoming the lack of built environment data in LMICs. The proposed research uses deep learning and advanced statistical methods to create a citywide dataset of built and social environment features in Bogota, Colombia that will provide crucial data to answer questions of their impact on pedestrian injuries and deaths, as well as assessing the presence of health inequities in their distribution and that will lay the groundwork to expand these efforts to more cities in Latin America and other LMICs.","Built Environment, Pedestrian Injuries and Deep Learning (BEPIDL) Study",10123391,K01TW011782,"['Adopted', 'Adoption', 'Affect', 'Artificial Intelligence', 'Big Data', 'Cessation of life', 'Characteristics', 'Cities', 'Classification', 'Collaborations', 'Colombia', 'Competence', 'Complex', 'Computer Vision Systems', 'Country', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Discipline', 'Education', 'Future', 'Goals', 'Grant', 'Health', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Injury', 'Label', 'Latin America', 'Lead', 'Location', 'Machine Learning', 'Mathematics', 'Mentors', 'Methods', 'Modeling', 'Neighborhoods', 'Perception', 'Persons', 'Public Health', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Risk', 'Safety', 'Social Environment', 'Statistical Methods', 'Time', 'Training', 'Transportation', 'Typology', 'Urban Developments', 'Urban Health', 'Vehicle crash', 'Writing', 'automated image analysis', 'built environment', 'burden of illness', 'career', 'career development', 'computer science', 'cost', 'data infrastructure', 'deep learning', 'design', 'digital imaging', 'experience', 'high risk', 'improved', 'injured', 'learning strategy', 'low and middle-income countries', 'neighborhood association', 'neural network', 'pedestrian injury', 'population health', 'skills', 'social', 'socioeconomics', 'spatiotemporal', 'virtual']",FIC,DREXEL UNIVERSITY,K01,2020,138024,0.011929102984531544
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10019459,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2020,291252,0.028011420094775447
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10029418,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2020,447500,0.056712570987273246
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9913520,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Visualization', 'Work', 'algorithm training', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,235027,0.039918252658145456
"Advancing Ulcerative Colitis Monitoring with Deep Learning Models Project Summary/Abstract The number of practicing pathologists around the world is expected to decrease by as much as 30% over the next two decades, with some of the world’s poorest countries having a ratio of only one pathologist to many hundreds of thousands of people. At the same time, the diagnostic caseload that requires their expertise in clinical trials and hospital settings will continue to grow. The digitization of pathology data, coupled with the use of machine learning techniques for analyzing and scoring the data, provides exciting opportunities to make the field of pathology more efficient and scalable, even as the workforce continues to evolve. Deep learning in particular provides the potential to enhance the interpretation of medical images by improving the detection of image-based biomarkers for a broad range of diseases. Image interpretation plays an important role in patient eligibility and endpoint determination during the course of clinical trials. For patients with ulcerative colitis, the development of trained and reliable algorithms that can help pathologists identify disease progression and response to treatment in a timely and effective manner can provide benefit in two important ways. First, it will help to ensure that the most appropriate score for histological disease severity is being assigned to each image using the Robarts Histopathology Index (RHI) or similar grading scale. Second, it will support a triage process by which images known to contain non- healthy tissues can be prioritized for earlier assessment. Through a unique partnership between Azavea, a geospatial technology and machine learning firm, and Robarts, a clinical trials organization, the proposed research will begin to address these needs by developing deep learning algorithms for histopathology digital image analysis, testing them on machine-readable annotations of medical imagery from previous clinical studies, and exposing them through a metadata- searchable interface that will enable the images to be categorized and quickly accessed by pathologists and others to support reader training and increase communication between multiple readers and sites. In so doing, it will not only help streamline the evaluation of new ulcerative colitis treatments that rely heavily on the image interpretation process, but also provide the foundation for the identification of additional components present in other gastrointestinal disease indications in the future. Project Narrative The proposed research will contribute critical new insights on the reliability, sensitivity, and practicality of machine learning to support gastrointestinal disease detection and evaluation in a clinical trials setting. In pathology, where manual interpretation of images using a microscope has remained relatively unchanged for decades, machine learning provides particular potential to improve the speed and accuracy of diagnoses by reducing the subjectivity that is often inherent in the process.",Advancing Ulcerative Colitis Monitoring with Deep Learning Models,10081185,R43EB030441,"['Address', 'Algorithms', 'Appearance', 'Architecture', 'Catalogs', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communication', 'Computer software', 'Country', 'Coupled', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Eligibility Determination', 'Endoscopy', 'Endpoint Determination', 'Ensure', 'Evaluation', 'Foundations', 'Future', 'Gastrointestinal Diseases', 'Histologic', 'Histology', 'Histopathology', 'Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Learning Skill', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Metadata', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Output', 'Pathologist', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Predictive Value', 'Process', 'Publications', 'Readability', 'Reader', 'Reporting', 'Research', 'Role', 'Series', 'Services', 'Severity of illness', 'Site', 'Software Design', 'Speed', 'Stains', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Triage', 'Ulcerative Colitis', 'Validation', 'base', 'deep learning', 'deep learning algorithm', 'diagnostic accuracy', 'digital imaging', 'gastrointestinal', 'imaging biomarker', 'imaging detection', 'improved', 'indexing', 'insight', 'instrument', 'learning network', 'prototype', 'software development', 'tool', 'treatment response']",NIBIB,"AZAVEA, INC",R43,2020,150000,0.04202512401040815
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,9957898,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2020,271250,0.022665396371364516
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,9895214,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2020,235500,0.013582737062805699
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning.",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,10140491,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis ', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'software infrastructure', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2020,742405,0.01107787291367344
"TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT This Fast Track SBIR aims to implement comprehensive image anonymization within an enterprise imaging informatics platform built on XNAT.  Our vision is for this platform to provide large healthcare enterprises with tools to generate secure research databases at scale that mirror their clinical image archives.  These databases would then provide local academic and industry collaborators with a rich resource for clinical research and development of AI-powered applications. Thus, our proposed anonymization services are designed to be scalable, risk-based, and verifiable. The platform's AI-powered image anonymization will include automated detection of PHI using a deep learning based natural language processing engine and automated detection of PHI in image content using a convolutational neural network.  The anonymization services will be integrated into Radiologics enterprise and clinical trial XNAT products. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT,10274066,5N91020C00025,"['Clinical Research', 'Clinical Trials', 'Computer software', 'Contracts', 'Data', 'Database Management Systems', 'Databases', 'Detection', 'Healthcare', 'Image', 'Industry Collaboration', 'Intelligence', 'Natural Language Processing', 'Phase', 'Radiology Specialty', 'Research', 'Resources', 'Risk', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Vision', 'base', 'clinical imaging', 'deep learning', 'design', 'image archival system', 'imaging informatics', 'neural network', 'prototype', 'research and development', 'tool']",NCI,"RADIOLOGICS, INC.",N43,2020,399691,0.039357126825149746
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9976466,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'neural network classifier', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,385010,0.005790158429226098
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10056062,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data warehouse', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,188198,0.0017369020101477438
"Clinical Development and Evaluation of a Deep Learning Approach to Improve Diagnostic Accuracy PROJECT SUMMARY Introduction: PhotoniCare, Inc. is a medical device company developing the TOMi Scope, a handheld, optical imaging device for improved diagnosis of middle ear health. The purpose of this proposal is to establish and evaluate a machine learning approach to facilitate both: (1) ease and reliability of quality data capture in a pediatric population from users with a range of otscopy expertise, and; (2) assist interpretation of the TOMi Scope’s correlated otoscopy and depth-resolved images in order to enable improved diagnostic accuracy and, ultimately, effective management. Significance: Ear infections affect 93% of all children, yet they are one of the most poorly diagnosed (~50% accuracy) and managed diseases in all of medicine, resulting in high antimicrobial over-prescription and resistance development. Correctly identifying the absence or presence/type of middle ear effusion (MEE; fluid) through the non-transparent eardrum is critical to accurate diagnosis, and the limited current diagnostic tools suffer poor diagnostic adoption (7-38% reported use) and accuracy (50-70%) due to inherent subjectivity and dependence on user expertise. Therefore, there is a clear and unmet need for superior, objective screening, starting with a definitive yet easily and reliably usable diagnostic tool for this extremely prevalent yet poorly managed disease. Hypothesis: Applying a machine learning approach to TOMi Scope imaging guidance and diagnostic classification will facilitate both: 1) ease-of-use and reliable quality data collection improvement, and 2) accurate detection of the presence or absence of MEE, as well as classification of the type of infection, regardless of user experience. Specific Aims: (1) Collect labeled TOMi Scope data (otoscopy and depth-scan images) from 268 patients at pediatric offices affiliated with UPMC Children’s Hospital of Pittsburgh, (2) Achieve reliable usability of the TOMi Scope by guiding image capture using TOMi-net, a deep learning model, (3) Develop a multimodal deep learning model to provide diagnostic assistance using TOMi Scope otoscopy and depth-scan data. Commercial Opportunity: The TOMi Scope will provide physicians with a superior user experience and new, objective information, enabling better decision-making for antibiotic prescription and surgical intervention. This has the potential to impact the standard of care for ~1B children worldwide that experience ear infections, representing a multi-billion-dollar commercial opportunity. PROJECT NARRATIVE Ear infections (otitis media) are highly prevalent in the pediatric population and represent a significant clinical challenge due to the limitations of the gold-standard diagnostic tools, resulting in high antimicrobial prescription and consequent resistance development. Accurate detection and classification of effusion (fluid) in the middle ear is a critical element for this diagnosis, and for making informed medical treatment decisions, particularly regarding antibiotic stewardship. The long-term goal of this work is to reduce antibiotic resistance and healthcare costs through improving patient outcomes by addressing the low diagnostic accuracy and user experience issues of current subjective methods, with a novel, non-invasive imaging tool capable of quantitative depth-resolved measurements to not only visualize the underlying infection behind the eardrum, but also, with automated machine learning image analysis algorithms, minimize user experience dependence and variability.",Clinical Development and Evaluation of a Deep Learning Approach to Improve Diagnostic Accuracy,10156035,R44DC017422,"['Acute', 'Address', 'Adoption', 'Affect', 'Algorithmic Analysis', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Appointment', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Childhood', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials Unit', 'Collection', 'Custom', 'Data', 'Data Collection', 'Decision Making', 'Dependence', 'Detection', 'Development', 'Development Plans', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Ear', 'Elements', 'External auditory canal', 'Feedback', 'Focus Groups', 'Goals', 'Gold', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Imaging Device', 'Infection', 'Label', 'Light', 'Liquid substance', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Device', 'Medical center', 'Medicine', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Otitis Media', 'Otitis Media with Effusion', 'Otoscopy', 'Patient-Focused Outcomes', 'Patients', 'Pediatric Hospitals', 'Pediatrics', 'Phase', 'Physicians', 'Population', 'Prevalence', 'Primary Health Care', 'Recording of previous events', 'Reporting', 'Resistance development', 'Scanning', 'Schedule', 'Surface', 'Surveys', 'Testing', 'Time', 'Training', 'Tympanic membrane', 'Universities', 'Work', 'accurate diagnosis', 'antimicrobial', 'bacterial resistance', 'clinical development', 'clinically relevant', 'convolutional neural network', 'deep learning', 'diagnostic accuracy', 'ear infection', 'effusion', 'electronic data capture system', 'experience', 'hearing impairment', 'image guided', 'improved', 'middle ear', 'middle ear fluid', 'multimodality', 'non-invasive imaging', 'novel', 'optical imaging', 'prevent', 'recruit', 'research clinical testing', 'screening', 'standard of care', 'tool', 'usability']",NIDCD,"PHOTONICARE, INC.",R44,2020,1136886,0.005444733635749864
"Support for New Bioinformatics Methods Development New bioinformatics method development support includes, image analysis for glyphosate toxicity where deep-learning based image processing tmethods were used to discriminate between normal, stressed and cell-death conditions of HepaRG cells and primary hepatocytes; Evidence tagging protocols were develop for evidence mapping for the OHAT group;  an evaluation of existing tagging methods was performed currently available in the SWIFT-Review program; Machine Learning methods were used for Document tagging activity exploring alternative to the keyword-based tagging strategy currently used in SWIFT-Review. n/a",Support for New Bioinformatics Methods Development,10281443,73201700001C,"['Bioinformatics', 'Cell Death', 'Cells', 'Chemical Exposure', 'Chemicals', 'Contractor', 'DNA Sequence', 'Development', 'Evaluation', 'Genes', 'Hepatocyte', 'Image Analysis', 'Measures', 'Methods', 'Output', 'Program Reviews', 'Programming Languages', 'Protocols documentation', 'Sampling', 'Series', 'Specific qualifier value', 'Stress', 'Toxic effect', 'base', 'bioinformatics tool', 'deep learning', 'differential expression', 'glyphosate', 'image processing', 'machine learning method', 'method development', 'programs', 'transcriptomics']",NIEHS,"SCIOME, LLC",N01,2020,210270,0.021730677970175968
"Robust AI to develop risk models in retinopathy of prematurity using deep learning ROP is a retinal neovascular disease affecting preterm infants, and is a leading cause of childhood blindness worldwide. Known clinical risk factors include preterm birth, low birthweight and use of supplemental oxygen but improved risk models are needed to identify infants that progress to treatment requiring disease and blindness. Deep learning techniques have been used to successfully identify “plus” disease in multi- institutional cohorts and to provide a continuous measure of disease severity. A major limitation of deep learning, however, is the need for large amounts of well curated datasets. Other limitations include overfitting and “brittleness” that can cause model performance to drop on external data. There are, however, numerous barriers to building and hosting these large central repositories with multi-institutional data required for robust deep learning including concerns about data sharing, regulations costs, patient privacy and intellectual property. In this project, we aim to demonstrate the utility of distributed/federated deep learning approaches where the data are located within institutions, but model parameters are shared with a central server. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Specifically, we seek to build robust risk models for predicting treatment requiring disease. Two large cohorts will be used to validate the hypothesis that the performance of the risk models using distributed learning approaches that of centrally hosted and is more robust than models built on single institutional datasets.  Grants Admin Updated 04.01.2019 JBou Retinopathy of prematurity is a retinal neovascular disease affecting preterm infants and a leading cause of preventable blindness worldwide. We are developing machine-learning based techniques to collaboratively build risk models for treatment requiring disease using multi-institutional data repositories. Distributed deep learning will be used to build robust models to improve clinical decision making in ROP.",Robust AI to develop risk models in retinopathy of prematurity using deep learning,10048436,R21EY031883,"['Affect', 'Architecture', 'Blindness', 'Blood Vessels', 'Childhood', 'Clinical', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Disease', 'Drops', 'Ecosystem', 'Eye diseases', 'Future', 'Gestational Age', 'Grant', 'Heterogeneity', 'Image', 'Infant', 'Institution', 'Intellectual Property', 'Label', 'Lead', 'Learning', 'Left', 'Logistic Regressions', 'Low Birth Weight Infant', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Oxygen', 'Patient imaging', 'Patients', 'Performance', 'Premature Birth', 'Premature Infant', 'Protocols documentation', 'Publishing', 'Rare Diseases', 'Regulation', 'Research', 'Research Personnel', 'Retina', 'Retinal Detachment', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Sensitivity and Specificity', 'Severities', 'Severity of illness', 'Site', 'Techniques', 'Testing', 'Time', 'Training', 'Update', 'Vascular Diseases', 'Vascular Proliferation', 'Weight', 'Work', 'base', 'clinical decision-making', 'clinical risk', 'cohort', 'convolutional neural network', 'cost', 'data de-identification', 'data sharing', 'data warehouse', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'individual patient', 'large datasets', 'learning strategy', 'multiple data sources', 'neovascular', 'open source', 'patient population', 'patient privacy', 'patient subsets', 'predictive modeling', 'repository', 'risk prediction model', 'screening guidelines', 'secondary analysis', 'tool']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2020,274883,0.013954917370542275
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9927625,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,458900,-0.018028679357121973
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9973167,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'algorithm training', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2020,383601,-0.003698260269388962
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9952370,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2020,695400,0.07452829812736321
"Content-based MR-TRUS Fusion without Tracking There are about 3 million American men living with prostate cancer, the second leading cause of cancer death for men in the United States. If the prostate cancer is caught early before it spreads to other parts of the body, by active monitoring or treatment, most men will not die from it. Nevertheless, 22% to 47% of the patients with negative biopsies but elevated prostate-specific antigen levels may still harbor malignant tumors, which can be life threatening and could have been missed by the commonly used ultrasound guided random biopsy. By contrast, fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted biopsies has shown to significantly improve the cancer detection rate. However, MR-TRUS fusion itself is very challenging due to the difficulties in directly registering images of these two very different modalities in different dimensions. To bypass the difficult registration problems, the existing fusion techniques require the use of specialized expensive and cumbersome hardware tracking devices, which increases cost and elongates procedures. More importantly, due to a number of factors such as patient movement, respiratory motion and ultrasound transducer pressure change, prostate motion can happen during a procedure and cause the images to be misaligned. Timely noticing and correcting such motion require great skill and knowledge of radiological imaging, where studies show a steep learning curve for mastering fusion systems. Failing in image registration and motion compensation renders the fusion guided biopsy performing no differently than random biopsy. To address the fundamental cause of the problems, the goal of this project is to create enabling technology of MR- TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs. Recent advancement in machine learning, especially deep learning, has provided us new tools and new angles to tackle this challenging problem. This project aims for directly fusing 2D TRUS frames with 3D MR volume by developing novel deep learning methods for image reconstruction and registration. The proposed methods are designed to exploit both population and patient specific imaging information to accurately align images. As all learning-based image registration methods try to better use population knowledge to improve the registration performance, few of them have been able to efficiently use patient specific information, which can be essential to obtain robust and accurate performance. Upon successful completion, the innovation created from the project will disrupt the common perception that hardware tracking has to be used for multimodal image fusion-guided interventions and alleviate the demand on physicians’ experience and skill in image analysis and fusion to help obtain consistent results. This project will lead to the development of novel prostate biopsy systems and will also impact a range of other image fusion based interventional guidance technologies. Fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted prostate biopsies can significantly improve the detection of aggressive cancer. The goal of this project is to create enabling technology of MR-TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs.",Content-based MR-TRUS Fusion without Tracking,9968409,R21EB028001,"['3-Dimensional', 'Address', 'American', 'Area', 'Biopsy', 'Body part', 'Bypass', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Cyst', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Electromagnetics', 'Financial compensation', 'Foundations', 'Future', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Intelligence', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Life', 'Liver', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Manuals', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Multimodal Imaging', 'PSA level', 'Patients', 'Perception', 'Performance', 'Physicians', 'Population', 'Pressure Transducers', 'Procedures', 'Prostate', 'Psychological Transfer', 'Research', 'Retrospective Studies', 'Risk Assessment', 'Slice', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Thinness', 'Time', 'Training', 'Transrectal Ultrasound', 'Ultrasonic Transducer', 'Ultrasonography', 'United States', 'base', 'calcification', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'experience', 'image reconstruction', 'image registration', 'imaging modality', 'imaging study', 'improved', 'innovation', 'learning strategy', 'men', 'next generation', 'novel', 'patient population', 'population based', 'prostate biopsy', 'radiological imaging', 'reconstruction', 'research clinical testing', 'respiratory', 'skills', 'tool']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R21,2020,192513,0.02895244787747614
"Content-based MR-TRUS Fusion without Tracking There are about 3 million American men living with prostate cancer, the second leading cause of cancer death for men in the United States. If the prostate cancer is caught early before it spreads to other parts of the body, by active monitoring or treatment, most men will not die from it. Nevertheless, 22% to 47% of the patients with negative biopsies but elevated prostate-specific antigen levels may still harbor malignant tumors, which can be life threatening and could have been missed by the commonly used ultrasound guided random biopsy. By contrast, fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted biopsies has shown to significantly improve the cancer detection rate. However, MR-TRUS fusion itself is very challenging due to the difficulties in directly registering images of these two very different modalities in different dimensions. To bypass the difficult registration problems, the existing fusion techniques require the use of specialized expensive and cumbersome hardware tracking devices, which increases cost and elongates procedures. More importantly, due to a number of factors such as patient movement, respiratory motion and ultrasound transducer pressure change, prostate motion can happen during a procedure and cause the images to be misaligned. Timely noticing and correcting such motion require great skill and knowledge of radiological imaging, where studies show a steep learning curve for mastering fusion systems. Failing in image registration and motion compensation renders the fusion guided biopsy performing no differently than random biopsy. To address the fundamental cause of the problems, the goal of this project is to create enabling technology of MR- TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs. Recent advancement in machine learning, especially deep learning, has provided us new tools and new angles to tackle this challenging problem. This project aims for directly fusing 2D TRUS frames with 3D MR volume by developing novel deep learning methods for image reconstruction and registration. The proposed methods are designed to exploit both population and patient specific imaging information to accurately align images. As all learning-based image registration methods try to better use population knowledge to improve the registration performance, few of them have been able to efficiently use patient specific information, which can be essential to obtain robust and accurate performance. Upon successful completion, the innovation created from the project will disrupt the common perception that hardware tracking has to be used for multimodal image fusion-guided interventions and alleviate the demand on physicians’ experience and skill in image analysis and fusion to help obtain consistent results. This project will lead to the development of novel prostate biopsy systems and will also impact a range of other image fusion based interventional guidance technologies. Fusion of magnetic resonance (MR) imaging and transrectal ultrasound (TRUS) for guiding targeted prostate biopsies can significantly improve the detection of aggressive cancer. The goal of this project is to create enabling technology of MR-TRUS image fusion solely based on internal image content without using external tracking devices. The proposed research is foundational for developing next generation of MR-TRUS fusion guidance systems for prostate biopsy to achieve robust performance with lower costs.",Content-based MR-TRUS Fusion without Tracking,10204244,R21EB028001,"['3-Dimensional', 'Address', 'American', 'Area', 'Biopsy', 'Body part', 'Bypass', 'Cancer Detection', 'Cancer Etiology', 'Cessation of life', 'Cyst', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Electromagnetics', 'Financial compensation', 'Foundations', 'Future', 'Goals', 'Heart', 'Image', 'Image Analysis', 'Intelligence', 'Intervention', 'Kidney', 'Knowledge', 'Learning', 'Life', 'Liver', 'Location', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Manuals', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Movement', 'Multimodal Imaging', 'PSA level', 'Patients', 'Perception', 'Performance', 'Physicians', 'Population', 'Pressure Transducers', 'Procedures', 'Prostate', 'Psychological Transfer', 'Research', 'Retrospective Studies', 'Risk Assessment', 'Slice', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Thinness', 'Time', 'Training', 'Transrectal Ultrasound', 'Ultrasonic Transducer', 'Ultrasonography', 'United States', 'base', 'calcification', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'design', 'experience', 'image reconstruction', 'image registration', 'imaging modality', 'imaging study', 'improved', 'innovation', 'learning strategy', 'men', 'next generation', 'novel', 'patient population', 'population based', 'prostate biopsy', 'radiological imaging', 'reconstruction', 'research clinical testing', 'respiratory', 'skills', 'tool']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R21,2020,194351,0.02895244787747614
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,10018827,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data privacy', 'data quality', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2020,394824,-0.011938855216192165
"Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions Project Summary Fluoroscopy guidance using C-arm X-ray systems is used in more than 17 million procedures across the US and constitutes the state-of-care for various percutaneous procedures, including internal ﬁxation of pelvic ring injuries. To infer procedural progress from 2D radiographs, well-deﬁned views onto anatomy must be achieved and restored multiple times during surgery. This process, known as ”ﬂuoro hunting”, is associated with 4.7 s of excessive ﬂuoroscopy time per C-arm position (c. f. 120 s total per ﬁxation), yielding radiographs that are never interpreted clinically, but drastically increasing procedure time and radiation dose to patient and surgical staff.  Our long-term project goal is to use concepts from machine learning and active vision to develop task-aware algorithms for autonomous robotic C-arm servoing that interpret intra-operative radiographs and autonomously adjust the C-arm pose to acquire ﬂuoroscopic images that are optimal for inference. We have three speciﬁc aims: 1) Detecting unfavorable K-wire trajectories from monoplane ﬂuoroscopy images: We will extend a physics-based sim- ulation framework for ﬂuoroscopy from CT that enables fast generation of structured and realistic radiographs documenting procedural progress. Based on this data, we will train a state-of-the-art convolutional neural net- work that interprets ﬂuoroscopic images to infer procedural progress. 2) Developing and validating a task-aware imaging system in silico: Using the autonomous interpretation tools and simulation pipeline available through Aim 1, we will train an artiﬁcial agent based on reinforcement learning and active vision. This agent will be capable of analyzing intra-operative ﬂuoroscopic images to autonomously adjust the C-arm pose to yield task- optimal views onto anatomy. 3) Demonstrating feasibility of our task-aware imaging concept ex vivo: Our third aim will establish task-aware C-arm imaging in controlled clinical environments. We will attempt internal ﬁxation of anterior pelvic ring fractures and our task-aware artiﬁcial agent will interpret intra-operatively acquired ra- diographs to infer procedural progress and suggest optimal C-arm poses that will be realized manually with an optically-tracked mobile C-arm system.  This work combines the expertise of a computer scientist, a surgical robotics expert, and an orthopedic trauma surgeon to explore the untapped, understudied area of autonomous imaging enabled by advances in machine learning in ﬂuoroscopy-guided procedures. This development has only recently been made feasible by innovations in fast ﬂuoroscopy simulation from CT to provide structured data for training that is sufﬁciently realistic to warrant generalization to clinical data. With support from the NIH Trailblazer Award, our team will be the ﬁrst to investigate autonomous and task-aware C-arm imaging systems, paving the way for a new paradigm in medical image acquisition, which will directly beneﬁt millions of patients by task-oriented image acquisition on a patient-speciﬁc basis. Subsequent R01 funding will customize this concept to other high-volume procedures, such as vertebroplasty. Project Narrative Fluoroscopy guidance using C-arm X-ray systems is the state-of-care for percutaneous fracture ﬁxation, and requires surgeons to achieve and reproduce well deﬁned views onto anatomy to infer procedural progress. This requirement alone is estimated to contribute 4.7 s of ﬂuoroscopy time per C-arm repositioning (c. f. 120 s total per ﬁxation), drastically increasing procedure time and radiation dose to patient and surgical team. The goal of this project is to develop machine learning-based C-arm servoing algorithms that introduce task awareness by interpreting intra-operative radiographs and autonomously adjusting the C-arm pose to task-optimal views.",Task-aware and Autonomous Robotic C-arm Servoing for Flouroscopy-guided Interventions,9972122,R21EB028505,"['3-Dimensional', 'Age-Years', 'Algorithms', 'Anatomy', 'Anterior', 'Area', 'Artificial Intelligence', 'Assessment tool', 'Automobile Driving', 'Award', 'Awareness', 'Back', 'Bladder', 'Cadaver', 'Caring', 'Clinical', 'Clinical Data', 'Compression Fracture', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnostic radiologic examination', 'Discipline', 'Environment', 'Exhibits', 'Expert Systems', 'Fluoroscopy', 'Fracture', 'Fracture Fixation', 'Funding', 'Generations', 'Goals', 'Image', 'Incidence', 'Injury', 'Intervention', 'Label', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Modality', 'Modernization', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Patients', 'Pelvis', 'Physics', 'Population', 'Positioning Attribute', 'Probability', 'Procedures', 'Process', 'Psychological reinforcement', 'Radiation Dose Unit', 'Risk', 'Robotics', 'Roentgen Rays', 'Scientist', 'Specimen', 'Structure', 'Surgeon', 'System', 'Testing', 'Time', 'Training', 'Trauma', 'United States', 'United States National Institutes of Health', 'Variant', 'Vertebral column', 'Width', 'Work', 'active vision', 'adverse outcome', 'algorithm training', 'arm', 'base', 'bone', 'convolutional neural network', 'deep learning algorithm', 'deep reinforcement learning', 'femoral artery', 'imaging modality', 'imaging system', 'improved outcome', 'in silico', 'innovation', 'learning algorithm', 'mortality', 'multitask', 'novel strategies', 'pre-clinical', 'sample fixation', 'simulation', 'spine bone structure', 'structured data', 'success', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,193784,0.013873324843095019
"AI platform for microscopy image restoration and virtual staining AI Platform for Microscopy Image Restoration and Virtual Staining Project Summary:  Fluorescence microscopy has enabled many major discoveries in biomedical sciences. Despite the rapid advancements in optics, lasers, probes, cameras and novel techniques, major factors such as spatial and temporal resolution, light exposure, signal-to-noise, depth of penetration and probe spectra continue to limit the types of experiments that are possible. Deep learning (DL) algorithms are well suited for image-based problems like SNR/super-resolution restoration and virtual staining, which have great enabling potentials for microscopy experiments. Previously impossible experiments could be realized such as achieving high signal-to-noise and/or spatial-temporal resolution without photobleaching/phototoxicity; simultaneously observing many image channels without interfering with native processes, etc. This could pave the way for a quantum leap forward in microscopy-based discoveries that elucidate biological functions and the mechanisms of disorders, and enable new diagnostics and therapies for human diseases.  However, these new methods have not been widely translated to new microscopy experiments. The delay is due to several practical hurdles and challenges such as required expertise, computing and trust. In order to accelerate the adoption of DL in microscopy, novel AI platform tailored for biologists are needed for training, applying and validating DL models and outputs.  The present project aims to develop an AI platform for microscopy image restoration and virtual staining called AI for Restoring and Staining (AIRS) platform. With our collaborator, Dr. Hari Shroff (National Institute of Biomedical Imaging and Bioengineering) we have successfully created DL models for SNR restoration, super-resolution restoration and virtual staining for a variety of imaging conditions and organelles in our preliminary studies. The AIRS platform intends to (1)provide a comprehensive suite of validated DL models for microscopy restoration and virtual staining applications including SNR restoration, super-resolution restoration, spatial deconvolution, spectral unmixing, prediction of 3d from 2d images, organelle virtual staining and analysis; (2)provide plug and play for common microscopy experiments; (3)provide semi-automatic update training to tailor DL models to match advanced microscopy experiments; (4)provide user friendly support for new DL model training for pioneering microscopy experiments; (5)provide confidence scores to assess the output results by a DL model, (6) provide DL models that avoid image artifact (hallucination) and allow continuous learning and evolution; (7) and be able to access the required computing infrastructure and database connection. Project Narrative Deep learning (DL) algorithms have great enabling potentials for microscopy experiments. Previously impossible experiments could now be realized. This could pave the way for a quantum leap forward in microscopy-based discoveries.  Powered by deep learning and DRVision innovations and collaborating with Dr. Hari Shroff and 7 additional labs, this project aims to create an AI platform for microscopy image restorations and virtual staining called AI for restoring and staining (AIRS). The tool will be integrated with DRVision’s flagship product Aivia for commercialization to accelerate the adoption of DL in microscopy.",AI platform for microscopy image restoration and virtual staining,9909318,U44GM136091,"['3-Dimensional', 'Active Learning', 'Adoption', 'Artificial Intelligence', 'Biological Process', 'Data', 'Databases', 'Disease', 'Evaluation', 'Evolution', 'Feedback', 'Fluorescence Microscopy', 'Government', 'Hallucinations', 'Image', 'Infrastructure', 'Lasers', 'Libraries', 'Light', 'Manuals', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'National Institute of Biomedical Imaging and Bioengineering', 'Noise', 'Optics', 'Organelles', 'Output', 'Penetration', 'Performance', 'Persons', 'Phase', 'Photobleaching', 'Phototoxicity', 'Play', 'Process', 'Resolution', 'Science', 'Signal Transduction', 'Stains', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Translating', 'Trust', 'Update', 'Validation', 'base', 'commercialization', 'deep learning', 'deep learning algorithm', 'experience', 'experimental study', 'human disease', 'improved', 'innovation', 'learning progression', 'microscopic imaging', 'novel', 'novel diagnostics', 'novel therapeutics', 'prototype', 'quantum', 'restoration', 'temporal measurement', 'tool', 'usability', 'user-friendly', 'virtual']",NIGMS,"DRVISION TECHNOLOGIES, LLC",U44,2020,172359,0.022209137020607443
"Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment Project Summary More than 20,000 hematopoietic stem cell transplants (including bone marrow transplants) are performed in the U.S. each year to cure a range of diseases ranging from leukemias to sickle cell anemia to autoimmune deficiencies in children. Unfortunately, most long-term non-relapse survivors will die of chronic graft-versus-host disease (cGVHD), which remains a disease of steadily increasing incidence and profound unmet need. A fundamental barrier in cGVHD management and research is a lack of sensitive and objective assessment tools that permit objective and reproducible measures of disease severity and progression. Skin is the most commonly affected organ in cGVHD and automated techniques capable of measuring precisely the surface area of involved skin in photographs may provide the tools necessary for effectively evaluating patient progress. We propose to (1) create the data set necessary to develop machine learning-based methods for the automatic analysis of cGVHD images, and (2) implement and evaluate these methods. Project Narrative  Chronic graft-versus-host disease (cGVHD) is a lethal disease that affects most long-term hematopoietic stem cell transplant (including bone marrow transplants) recipients. Skin images are used to assess disease severity and progression but the technology required to quantitatively and reproducibly analyze these images is lacking. This project aims at developing and evaluating this technology.",Automatic analysis of 3D skin images for chronic graft-versus-host disease (cGVHD) severity assessment,9864040,R21AR074589,"['3-Dimensional', 'Achievement', 'Affect', 'Agreement', 'Allogenic', 'Area', 'Assessment tool', 'Autoimmune Process', 'Body Surface', 'Bone Marrow Transplantation', 'Characteristics', 'Child', 'Circumscribed Lesion', 'Clinic', 'Clinical', 'Clinical Research', 'Cutaneous', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dermatologic', 'Dermatologist', 'Disease', 'Disease Management', 'Disease Progression', 'Documentation', 'Erythema', 'Exanthema', 'Future', 'Goals', 'Hematologic Neoplasms', 'Hematopoietic Stem Cell Transplantation', 'Hematopoietic System', 'Human', 'Image', 'Incidence', 'Industry', 'Institution', 'Label', 'Lead', 'Lesion', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Methods', 'Morbidity - disease rate', 'Organ', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Population', 'Protocols documentation', 'Psoriasis', 'Reaction', 'Reproducibility', 'Research', 'Resources', 'Role', 'Scanning', 'Severities', 'Severity of illness', 'Sickle Cell Anemia', 'Site', 'Skin', 'Skin Cancer', 'Standardization', 'Surface', 'Survivors', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Three-dimensional analysis', 'Time', 'Transplant Recipients', 'Visit', 'Vitiligo', 'automated analysis', 'base', 'cancer imaging', 'chronic graft versus host disease', 'data warehouse', 'deep learning', 'deep neural network', 'digital', 'graft vs host disease', 'high risk', 'image processing', 'improved', 'interdisciplinary approach', 'learning strategy', 'leukemia', 'machine vision', 'mortality', 'network architecture', 'neural network architecture', 'novel therapeutics', 'patient subsets', 'prototype', 'repository', 'response', 'skin disorder', 'skin lesion', 'stereoscopic', 'success', 'tool']",NIAMS,VANDERBILT UNIVERSITY,R21,2020,201692,0.009160564751654292
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9989186,R44MH118815,"['3-Dimensional', 'Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'stem cells', 'treatment strategy', 'two-dimensional', 'usability', 'virtual environment', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2020,749716,0.046810734174881095
"An Integrated CT-based Image-Guided Neurosurgical System An Integrated CT-based Image-Guided Neurosurgical System In this SBIR Phase IIb proposal Xoran intends to commercialize a compact and affordable, yet highly- functional, system to provide real time image updates and navigation guidance in support of minimally invasive cranial and spinal neurosurgical procedures. The effort builds on previously developed compact and portable flat-panel Computed Tomography (CT) technology which has been commercialized for hard tissue applications, and incorporates work done in earlier phases of this project to generate viable high- quality images of the soft tissue structures in the brain. Intraoperatively obtained images tightly integrated into an onboard surgical navigation will provide updated instrument localization using next generation electromagnetic tool tip guidance. Workflow optimizations become possible when the imaging and guidance are one device, including fast local image updates, automatic image-to-world registration, as well as speed and simplicity of use. The project includes expansion of the system capabilities to facilitate precise minimally-invasive surgical removal of tumors in both the head and spine. It incorporates a machine-learning based deep neural network method for image finalization to allow high quality, low radiation image updates. The three-year project involves meeting technical milestones of system development including imaging capability, registration, navigation accuracy, speed, workflow, radiation dose considerations and cost. Clinical evaluations will take place at University of Michigan, and a team of consulting physicians has been assembled for oversight, input and feedback. Narrative / Relevance to Public Health Minimally invasive surgical procedures have many benefits to public health including reducing the medical risks and costs associated with brain cancer and spine surgery. However such procedures are often time consuming and technically difficult as the surgeon is unable to directly visualize the area of the operation. In this project, an intraoperative surgical system is developed with onboard imaging capability in order to enable minimally invasive surgeries to be performed more safely and completely, by providing hi-resolution imaging of the brain and spine while the surgeon operates.",An Integrated CT-based Image-Guided Neurosurgical System,10017876,R44CA112966,"['3-Dimensional', 'Address', 'Agreement', 'American', 'Anatomy', 'Animals', 'Area', 'Benefits and Risks', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Businesses', 'Caliber', 'Cancer Etiology', 'Canis familiaris', 'Capital', 'Central Nervous System Neoplasms', 'Cephalic', 'Cessation of life', 'Clinic', 'Clinical', 'Computed Tomography Scanners', 'Consensus', 'Consult', 'Consumption', 'Data', 'Devices', 'Diagnosis', 'Dose', 'Electromagnetics', 'Environment', 'Evaluation', 'Excision', 'Feedback', 'Fluoroscopy', 'Funding', 'Goals', 'Head', 'Image', 'Image-Guided Surgery', 'Institutional Review Boards', 'Investments', 'Licensing', 'Machine Learning', 'Malignant neoplasm of brain', 'Mediation', 'Medical', 'Medical Imaging', 'Metals', 'Metastatic Neoplasm to the Bone', 'Michigan', 'Minimally Invasive Surgical Procedures', 'Monitor', 'Navigation System', 'Neoplasm Metastasis', 'Neurosurgeon', 'Neurosurgical Procedures', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Pennsylvania', 'Phase', 'Physicians', 'Pituitary Neoplasms', 'Positioning Attribute', 'Procedures', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Resolution', 'Risk', 'Roentgen Rays', 'Safety', 'Scanning', 'Series', 'Small Business Innovation Research Grant', 'Speed', 'Spinal', 'Spine surgery', 'Structure', 'Surgeon', 'Survival Rate', 'System', 'Systems Development', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Update', 'Vertebral column', 'Veterinary Medicine', 'Veterinary Schools', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer site', 'cancer surgery', 'commercial application', 'cost', 'cranium', 'deep neural network', 'human subject', 'image guided', 'image reconstruction', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'instrument', 'interest', 'meetings', 'minimally invasive', 'neurosurgery', 'next generation', 'operation', 'point of care', 'portability', 'real-time images', 'research clinical testing', 'soft tissue', 'spine bone structure', 'tool', 'tumor', 'validation studies']",NCI,"XORAN TECHNOLOGIES, LLC",R44,2020,1279629,0.011000103486790664
"Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD Abstract Non-alcoholic fatty liver disease (NAFLD) is exceptionally common, with an estimated one hundred million afflicted people in the United States. Detection and risk stratification of this very common disease remains a major challenge. Despite recent advances, including development of numerous therapeutic agents presently in phase 2 and 3 trials, NAFLD remains a silent disease in which the vast majority of patients accumulate progressive liver damage without signs or symptoms and, undiagnosed, receive no medical care. The NAFLD patients at highest risk of cirrhosis are those with moderate or greater liver fibrosis at the time of diagnosis, a group of patients who are described as having high risk non-alcoholic steatohepatitis (hrNASH). The current reference standard for identifying people with hrNASH is liver biopsy, which is expensive, invasive, and limited by interobserver variability. The focus of this project is to develop and validate low cost non-invasive diagnostic technology to diagnose hrNASH. We propose to accomplish this in three Specific Aims. First, we will expand and annotate an existing database of patients with chronic liver disease from 328 subjects to 1,000 subjects, ~40% of whom will have NAFLD. The database will contain ~20,000 images (~10,000 ultrasound elastography images and ~ 10,000 conventional ultrasound images) and multiple demographic and clinical data points for each subject (a total of ~30,000 clinical, laboratory, and demographic data points). We have previously developed advanced image processing techniques to make ultrasound elastography more accurate and less variable. We will use this large database to develop, customize and refine our image processing techniques for NAFLD evaluation (Aim 1), with the goal of improving ultrasound elastography diagnosis of hrNASH. Second, we will combine conventional ultrasound elastography imaging, conventional ultrasound imaging, our advanced image analysis techniques, and the demographic, clinical, and laboratory data in a machine learning model to predict hrNASH and will compare the performance of our predictive model with the FIB4, a widely-used blood test-based prediction rule (Aim 2). Third, we will validate our predictive model in an independent prospective cohort of NAFLD subjects undergoing biopsy for NAFLD risk stratification (Aim 3). We hypothesize that the combination of image processing-enhanced elastography and conventional ultrasound imagery combined with demographic, clinical, and laboratory data will have greater predictive power for hrNASH than clinical or sonographic data alone. The proposed predictive models have the potential to (1) reduce the number of liver biopsies performed for hrNASH detection, (2) facilitate recruitment for clinical trials of NAFLD therapeutics, and (3) improve care quality for the most common liver disease in the United States. Project Narrative In this project, we aim to create low-cost non-invasive technology to diagnose people with high risk non-alcoholic steatohepatitis (hrNASH), a common liver disease that has a high risk of cirrhosis. We will accomplish this goal by improving liver ultrasound imaging and by creating a prediction tool that integrates liver ultrasound, laboratory testing and clinical information. This prediction tool has the potential to reduce the need for liver biopsies.","Development of a Machine Learning Model to Integrate Clinical, Laboratory, Sonographic, and Elastographic Data for Noninvasive Liver Tissue Characterization in NAFLD",9850968,R01DK119860,"['Algorithmic Analysis', 'Area', 'Biopsy', 'Blood Tests', 'Caring', 'Cirrhosis', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Custom', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Evaluation', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Interobserver Variability', 'Laboratories', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Methods', 'Modeling', 'Outcome', 'Pathology', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase II/III Trial', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Prospective cohort', 'Quality of Care', 'ROC Curve', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Running', 'Schedule', 'Sensitivity and Specificity', 'Staging', 'Symptoms', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Texture', 'Therapeutic', 'Therapeutic Agents', 'Therapeutic Clinical Trial', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Validation', 'Work', 'base', 'chronic liver disease', 'clinical care', 'cost', 'disorder subtype', 'elastography', 'hepatocellular injury', 'high risk', 'image processing', 'improved', 'liver biopsy', 'liver imaging', 'liver injury', 'non-alcoholic fatty liver disease', 'nonalcoholic steatohepatitis', 'noninvasive diagnosis', 'patient population', 'predictive modeling', 'prospective', 'recruit', 'screening', 'standard of care', 'tool']",NIDDK,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,442592,0.018224371543762875
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,10246250,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Visualization', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed imaging', 'multiscale data', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'three-dimensional visualization', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2020,750000,0.04415447728039358
"q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy Project Summary/Abstract  Ischemic heart disease remains the top cause of death in the world. Acute myocardial infarction (MI) causes regional dysfunction which places remote areas of the heart at a mechanical disadvantage resulting in long term adverse left ventricular (LV) remodeling and complicating congestive heart failure (CHF). The course of MI and post-MI remodeling is complex and includes vascular and myocellular injury, acute and chronic inflammation, alterations of the extracellular matrix (ECM) and angiogenesis. Stress echocardiography is a clinically established, cost-effective technique for detecting and characterizing coronary artery disease and myocardial injury by imaging the LV at rest and after either exercise or pharmacologically-induced stress to reveal ischemia and/or scar. In our previous effort on this project, we developed quantitative 3D differential deformation measures for stress echocardiography from 4DE-derived LV strain maps taken at rest and after dobutamine stress. These measures can localize and quantify the extent and severity of LV myocardial injury and reveal ischemic regions. We now propose that improved versions of these same measures can be used for both targeting of therapy and outcomes assessment in the treatment of adverse local myocardial remodeling following MI. We choose a particular up and coming therapeutic strategy as an exemplar: the local delivery of injectable hydrogels within the MI region that are intended to alter the biomechanical properties of the LV myocardium, as well as inflammation, and thereby help to minimize adverse remodeling. Our new, robust approach for estimating improved dense displacement and differential deformation measures is based on an innovative data-driven, deep feed-forward, neural network architecture that employs domain adaptation between data from labeled, carefully-constructed synthetic models of physiology and echocardiographic image formation (i.e. with ground truth), and data from unlabeled noisy in vivo porcine or human echocardiography (missing or very limited ground truth). Training is based on tens of thousands of four-dimensional (4D) image-derived patches from these two domains, initially based on displacements derived separately from shape-based processing of conventional B-mode data and block-mode, speckle-tracked processing of raw radio-frequency (RF) data; and later based on learning directly from B-mode and RF image intensity information. After non-rigid registration of rest and stress 4DE image sequences, quantitative 4D differential deformation parameters will be derived from porcine and human echocardiographic test data. These parameters will be derived at baseline, and at several timepoints after delivery of injectable hydrogels into the MI region. The ability of the differential deformation parameters derived from 4D stress echocardiography to guide local delivery of injectable hydrogels in a MI region and assess/predict outcomes will then be determined in a hybrid acute/chronic porcine model of MI and post-MI remodeling. The technique will be translated to humans and evaluated by measuring the reproducibility and the relationship to remodeling of our new robust, deep learning-based differential deformation parameters in a small cohort of subjects. Project Narrative  At the core of the proposed effort is the development and evaluation of novel 4D (three spatial dimensions over time) echocardiographic imaging, image analysis, and machine learning methods that will enable the accurate and robust quantification of changes in myocardial deformation due to stress. Our methods will use this information to guide delivery and assess outcome of a promising new therapy to improve the biomechanical properties of the heart after myocardial injury based on injectable hydrogels.","q4DE: A Biomarker for Image-Guided, Post-MI Hydrogel Therapy",9890853,R01HL121226,"['3-Dimensional', '4D Imaging', 'Acute', 'Acute myocardial infarction', 'Area', 'Autopsy', 'Biological Markers', 'Biomechanics', 'Blood Vessels', 'Canis familiaris', 'Cardiac', 'Cause of Death', 'Chronic', 'Cicatrix', 'Clinical', 'Complex', 'Congestive Heart Failure', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Dimensions', 'Disadvantaged', 'Dobutamine', 'Echocardiography', 'Environment', 'Evaluation', 'Exercise', 'Extracellular Matrix', 'Family suidae', 'Four-Dimensional Echocardiography', 'Four-dimensional', 'Functional disorder', 'Future', 'Heart', 'Human', 'Hybrids', 'Hydrogels', 'Image', 'Image Analysis', 'Infarction', 'Inflammation', 'Inflammatory Response', 'Injectable', 'Injections', 'Injury', 'Intelligence', 'Ischemia', 'Label', 'Learning', 'Left', 'Left Ventricular Remodeling', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Matrix Metalloproteinase Inhibitor', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Modification', 'Motion', 'Myocardial', 'Myocardial Infarction', 'Myocardial Ischemia', 'Myocardial tissue', 'Myocardium', 'Outcome', 'Outcome Assessment', 'Patients', 'Pharmacology', 'Physiology', 'Prediction of Response to Therapy', 'Property', 'Recombinants', 'Reproducibility', 'Research', 'Rest', 'Severities', 'Shapes', 'Source', 'Stains', 'Stress', 'Stress Echocardiography', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Ultrasonography', 'Ventricular', 'Ventricular Remodeling', 'Work', 'angiogenesis', 'base', 'cohort', 'cone-beam computed tomography', 'cost effective', 'deep learning', 'feedforward neural network', 'heart imaging', 'human subject', 'image guided', 'imaging biomarker', 'improved', 'in vivo', 'innovation', 'machine learning method', 'myocardial injury', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'novel therapeutics', 'outcome prediction', 'precision medicine', 'predicting response', 'prevent', 'radio frequency', 'spatiotemporal', 'synthetic construct', 'targeted treatment', 'treatment response', 'treatment strategy']",NHLBI,YALE UNIVERSITY,R01,2020,795348,-0.011650706308087285
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10016301,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2020,396286,0.050451344757640446
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10010814,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2020,819293,0.018274582869983503
"Characterization of Early Response to Chronic Lung Injury using Chest CT Project Summary  In some individuals chronic tobacco smoke exposure results in emphysema and pulmonary fibrosis. Both of these parenchymal changes are irreversible, highlighting the importance of the early identification of their development and progression. Unfortunately, currently available methods for detecting the presence and evolution of these changes have limited sensitivity and specificity for very early disease and for subtle disease progression. Dr. Ash’s work has shown that automated objective analysis of computed tomography (CT) scans of the chest can detect clinically relevant radiologic findings called interstitial changes that may represent early pulmonary fibrosis, even in individuals without visually apparent disease. In the first aim of this proposal, Dr. Ash will refine and utilize a more sensitive and specific automated CT analysis tool that he and his lab have developed for the detection of both emphysema and interstitial changes. He will determine if emphysema and interstitial changes detected using this method are clinically significant in those patients deemed normal by previously performed visual analysis and in those deemed normal by other objective approaches. In the second aim, he will determine if areas of locally high density tissue in visually normal appearing lung parenchyma measured using augmented versions of his objective analysis tools are associated with mortality, other clinical outcomes, and peripheral measures of inflammation. Finally, in the third aim he will utilize these techniques to analyze longitudinal CT scans from the COPDGene study that were obtained over 10 years of follow-up, and will identify factors that predict or modify the development and progression of parenchymal changes on CT.  Dr. Ash will perform this work in the Division of Pulmonary and Critical Care Medicine at Brigham and Women’s Hospital (BWH), a core teaching hospital of Harvard Medical School, under the mentorship of Dr. George Washko, an expert in the field of medical image analysis and the co-principal investigator of the Applied Chest Imaging Laboratory at BWH. With the guidance of Dr. Washko and his scientific advisory committee, Dr. Ash has developed a comprehensive five year training program to develop the skills needed to become an independent investigator with expertise in quantitative image analysis, including predictive modeling and statistical machine learning.  Dr. Ash is dedicated to a career in academic medicine. His goal is to become a clinician-scientist using the skills gained during this award to improve our ability to detect and monitor smoking related lung disease. The techniques he has proposed may help identify modifiable risk factors and treatments for smoking related lung disease, determine which patients are likely to benefit from treatment, and monitor the response to therapy. Project Narrative Cigarette smoking results in emphysema and pulmonary fibrosis, but only in a minority of smokers. This proposal aims to use advanced objective analysis of chest computed tomography images to detect the earliest manifestations of smoking related lung disease. This will enable us to identify susceptible patients at the earliest possible moment, track their disease progression, and ultimately shift treatment strategies from palliating disease related symptoms to preventing disease development.",Characterization of Early Response to Chronic Lung Injury using Chest CT,9843731,K08HL145118,"['Advisory Committees', 'Area', 'Award', 'Chest', 'Chronic', 'Cicatrix', 'Clinical', 'Critical Care', 'Densitometry', 'Detection', 'Development', 'Development Plans', 'Disease', 'Disease Progression', 'Early identification', 'Educational workshop', 'Evolution', 'Fibrosis', 'Goals', 'Hospitals', 'Image', 'Image Analysis', 'Imaging Techniques', 'Individual', 'Inflammation', 'Inflammatory', 'Laboratories', 'Lung', 'Lung diseases', 'Measurement', 'Measures', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Minority', 'Monitor', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Outcome', 'Patients', 'Peripheral', 'Pharmaceutical Preparations', 'Predictive Factor', 'Primary Prevention', 'Principal Investigator', 'Publications', 'Pulmonary Emphysema', 'Pulmonary Fibrosis', 'Radiologic Finding', 'Radiology Specialty', 'Research Personnel', 'Respiratory physiology', 'Risk', 'Risk Factors', 'Scanning', 'Scientist', 'Sensitivity and Specificity', 'Severity of illness', 'Smoker', 'Smoking', 'Structure of parenchyma of lung', 'Symptoms', 'Teaching Hospitals', 'Techniques', 'Tissues', 'Tobacco smoke', 'Training', 'Training Programs', 'Visual', 'Woman', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'career', 'career development', 'chest computed tomography', 'cigarette smoking', 'clinically relevant', 'clinically significant', 'convolutional neural network', 'deep learning', 'density', 'disorder prevention', 'disorder risk', 'exercise capacity', 'follow-up', 'improved', 'interstitial', 'lung injury', 'mange', 'medical schools', 'modifiable risk', 'mortality', 'new technology', 'novel', 'palliate', 'palliating symptoms', 'palliation', 'predictive modeling', 'prevent', 'protein biomarkers', 'quantitative imaging', 'respiratory', 'response', 'skills', 'smoking-related lung disease', 'statistical and machine learning', 'tool', 'treatment strategy']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,K08,2020,170320,-0.04893756907710228
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10011054,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2020,1159612,0.0374106016662198
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9910382,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2020,510157,0.021754047238243274
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9823881,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2020,401916,0.03550680899724636
"Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research PROJECT SUMMARY/ABSTRACT This proposal represents a vertical advancement in neighborhood effects research, producing for the first time, national neighborhood indicators of the built environment. Thus far, only local studies have been conducted due to the resource-intensive nature of site visits to conduct assessments of community features and also manual annotations of street images. With the recent advancement of computer vision and the emergence of massive sources of image data, we will leverage our team’s abilities to develop a data collection strategy utilizing geographic information systems to assemble a national collection of Google Street View images of all road intersections and street segments in the United States. We will utilize this data bank, and develop informatics algorithms to produce neighborhood summaries of built environment that have been theoretically and empirically identified to be important for health outcomes. After the creation of Neighborhood Looking Glass, we will conduct investigations into the impact of neighborhood environments on health utilizing medical records from hundreds of thousands of patients and accounting for predisposing characteristics in analyses. Our investigative team—comprised of experts in the field of epidemiology, computer vision, bioinformatics, and computer science—is uniquely suited to implement the study aims. Our Specific Aims are: 1) Develop informatics techniques to produce neighborhood quality indicators; 2) Measure the accuracy of data algorithms and construct an interactive geoportal for neighborhood data visualization and data sharing, 3) Utilize Neighborhood Looking Glass and a large collection of medical records from Intermountain Healthcare to investigate neighborhood influences on the risk of obesity and substance abuse. The epidemic rise in chronic health conditions is recent and as such suggests its cause is social, cultural, and constructed rather than purely biological. Thus, we have the possibility of intervening on the environment to better support health. Recent studies suggest that the current cohort of young adults may face historically high cardiovascular disease risk and chronic disease burden. Our substantive investigation of the impact of neighborhood factors on chronic conditions will contribute further to the understanding of contextual influences on the health of this cohort at the forefront of a chronic disease epidemic. Moreover, the dramatic rise in overdoses, accidental poisonings, and mental health issues contributing to premature mortality warrants further investigation into risk-inducing environmental factors for substance abuse. Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics. Results can be utilized to inform population-based strategies to reduce health disparities and improve health. Project Narrative/Relevance to Public Health The epidemic rise in obesity, related chronic diseases, and substance abuse in recent decades signal the importance of structural forces and social processes, but the dearth of data on contextual factors limits the investigation of multilevel effects on health. The development of the Neighborhood Looking Glass will be a significant benefit to neighborhood effects researchers, harnessing the largely untapped potential of street image data to capture built environment characteristics with potential impact on health. Results from our project can be utilized to inform system-wide and local strategies to improve community health.",Neighborhood Looking Glass: 360 Degree Automated Characterization of the Built Environment for Neighborhood Effects Research,9979947,R01LM012849,"['Accounting', 'Alcohol or Other Drugs use', 'Algorithms', 'Bioinformatics', 'Biological', 'Characteristics', 'Chronic', 'Chronic Disease', 'Cities', 'Collection', 'Communities', 'Community Health', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Collection', 'Data Sources', 'Development', 'Disease', 'Environment', 'Environmental Risk Factor', 'Epidemic', 'Epidemiology', 'Face', 'Family', 'Food', 'Food Access', 'Geographic Information Systems', 'Geography', 'Glass', 'Grant', 'Happiness', 'Health', 'Health Food', 'Health Personnel', 'Health behavior', 'Health care facility', 'Healthcare', 'Image', 'Individual', 'Informatics', 'Investigation', 'Label', 'Literature', 'Manuals', 'Measures', 'Medical Records', 'Mental Health', 'Methods', 'Nature', 'Neighborhoods', 'Obesity', 'Outcome', 'Overdose', 'Patients', 'Physical activity', 'Physical environment', 'Premature Mortality', 'Process', 'Public Health', 'Quality Indicator', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Signal Transduction', 'Site Visit', 'Social Environment', 'Social Processes', 'Source', 'Structure', 'Substance abuse problem', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Visit', 'built environment', 'burden of illness', 'cardiovascular disorder risk', 'cohort', 'computer science', 'contextual factors', 'convolutional neural network', 'cost', 'crowdsourcing', 'data management', 'data mining', 'data resource', 'data sharing', 'data visualization', 'data warehouse', 'density', 'health care availability', 'health disparity', 'improved', 'land use', 'obesity risk', 'object recognition', 'physical conditioning', 'population based', 'social', 'social media', 'walkability', 'young adult']",NLM,"UNIV OF MARYLAND, COLLEGE PARK",R01,2020,329703,-0.0032337990579137848
"Towards a Compositional Generative Model of Human Vision Understanding object recognition has long been a central problem in vision science, because of its applied utility and computational difficulty. Progress has been slow, because of an inability to process complex natural images, where the largest challenges arise. Recently, advances in Deep Convolutional Neural Networks (DCNNs) spurred unprecedented success in natural image recognition. The general goal of this proposal is to leverage this success to test computational theories of human object recognition in natural images. However, DCNNs still markedly underperform humans when challenged with high levels of ambiguity, occlusion, and articulation. We hypothesize that humans' superior performance arises from the use of knowledge about how images and objects are structured. Preliminary evidence for this claim comes from the success of hybrid models, that combine DCNNS for identifying features and parts in images, with explicit knowledge of object and image structure. These computations occur within a hierarchy, which includes both top-down and bottom- up processing. The specific goal of the work proposed here is to strongly test whether these computational strategies, structured, hierarchical representations and bidirectional processing, are used to recognize objects in natural images. Human bodies are composed of hierarchically organized configurable parts, making them an ideal test domain. We examine the complete recognition process, from parts, to pairs of parts, to whole bodies, each in its own aim. Each aim also tests important sub-hypotheses about when and how the computational strategies are used. Aim 1 examines recognition of individual body parts, testing whether it is dependent on parsing images into more basic features and relationships, for example edges and materials. Aim 2 examines pairs of parts, testing the importance of knowledge of body connectedness relationships. Aim 3 examines perception of entire bodies, testing whether knowledge of global body structure guides bidirectional processing. In each aim, we first develop nested computer vision models that either do or do not make use of structural knowledge, to test whether it aids recognition. We then test whether human performance can be accounted for by the availability of that structural knowledge. We next measure neural activity with functional MRI to identify where and how it is used in cortex. Finally, we integrate these results to produce even stronger tests, using the nested models to predict human performance and confusion matrices as well as fMRI activity levels and confusion matrices. Altogether, this work will strongly test key theoretical accounts of object recognition in the most important domain, perception of natural images. The work, based on extensive preliminary data, measures and models the entire body recognition system. The models developed and tested here should surpass the state-of-the-art, and be useful for many real-world recognition tasks. The proposal will also lay the groundwork for future studies of recognition impaired by disease. This research uses computational, behavioral, and brain imaging methods to investigate how the visual system represents and processes information about human bodies. The studies will reveal how and when people can accurately recognize objects in natural images, how the brain supports this function, and how loss of information, similar to that that accompanies visual disease, may affect the ability to interpret everyday scenes.",Towards a Compositional Generative Model of Human Vision,10018020,R01EY029700,"['Affect', 'Area', 'Articulation', 'Behavioral', 'Body Image', 'Body part', 'Brain', 'Brain imaging', 'Complex', 'Computer Vision Systems', 'Confusion', 'Cues', 'Data', 'Development', 'Disease', 'Elbow', 'Feedback', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Human body', 'Hybrids', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Link', 'Measures', 'Modeling', 'Perception', 'Performance', 'Predictive Value', 'Process', 'Psychophysics', 'Published Comment', 'Research', 'Structure', 'System', 'Testing', 'Training', 'Vision', 'Visual', 'Visual system structure', 'Work', 'Wrist', 'base', 'convolutional neural network', 'crowdsourcing', 'human model', 'imaging modality', 'improved', 'object recognition', 'relating to nervous system', 'spatial relationship', 'success', 'theories', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2020,332870,0.02033838584768834
"Opera Phenix High-Content Imaging System for Drug Discovery PROJECT SUMMARY The University of Pittsburgh Drug Discovery Institute (UPDDI) is requesting funds to purchase the Perkin Elmer OPERA PHENIX high speed, high resolution spinning disk confocal High-Content Screening (HCS) device. The Opera Phenix will replace two Molecular Devices ImageXpress Ultra high content readers purchased in 2008, which are critical to multiple NIH-, DoD-, and Foundation-funded projects at the University of Pittsburgh, but are no longer supported by the manufacturer and have been decommissioned. We have determined that one Opera Phenix instrument can replace the two IXUs. The Phenix is a third generation HCS instrument that will be essential to satisfy the diverse needs of users that the UPDDI serves. No comparable instruments exist at the University of Pittsburgh, the University of Pittsburgh Medical Center, and Carnegie Mellon University. Over the last decade, HCS has become a standard in the pharmaceutical industry for target identification, phenotypic screening, as well as toxicology, and in academia for large-scale biological studies, where cell-by- cell quantitation is critical. The UPDDI has been an academic pioneer in the application of HCS and serves an extensive number of collaborators across campus that require and rely on HCS, ranging from neurodegeneration, organ regeneration, cancer, liver diseases, organotypic model development, and traumatic brain injury. Our diverse user groups’ needs emphasize discovery models of physiological relevance and high complexity, and therefore require fast, high resolution 2D, 3D, and kinetic imaging and maximum flexibility in image analysis. The large number of HCS users working in the UPDDI further demands a fast system to permit effective sharing of instrument time, and an integrated database with off-site user access to perform off- line analysis. Key requirements for an HCS imager therefore are superior speed in acquiring z-series of images at high resolution of thick specimens in aqueous matrices, mature yet flexible image algorithms, and seamless integration of instrument software with system, public,and custom-developed UPDDI databases. The only instrument that meets all of these criteria is the Opera Phenix because it has 1) fast laser-based illumination and the ability to acquire multiple channels simultaneously 2) water immersion objectives that eliminate non-matching refractive indices, which limit spherical aberrations of air and oil objectives at longer working distances and require adjustment of correction collars depending on imaging depth; 3) a powerful suite of user-friendly yet flexible image analysis routines including a 3D module, advanced texture and morphology analysis, and intuitive and user-friendly machine learning; and 4) the ability to perform seamless “adaptive high-resolution imaging”, i.e., pre-scanning a large area at low magnification, followed by automated “on-the- fly” switching to higher magnification to acquire high resolution images of user-defined regions of interest. The Opera Phenix is the only instrument on the market that is capable of fulfilling the demands of the University of Pittsburgh’s diverse drug discovery community. PROJECT NARRATIVE Modern drug discovery increasingly demands better and more disease relevant models and the ability to analyze them. High-content screening (HCS) has become indispensable in the analysis of such models as it permits the analysis of cells, their constituents, and interactions in their proper biological context. The third generation HCS instrument, Opera Phenix, produces the quality and quantity of data from cells, tissues and experimental animals that are required for computational and systems biological investigations, while at the same time providing the throughput needed for automated screening.",Opera Phenix High-Content Imaging System for Drug Discovery,9935240,S10OD028450,"['3-Dimensional', 'Academia', 'Air', 'Algorithms', 'Area', 'Biological', 'Cells', 'Communities', 'Computer software', 'Custom', 'Databases', 'Devices', 'Drug Industry', 'Foundations', 'Funding', 'Generations', 'Image', 'Image Analysis', 'Immersion', 'Institutes', 'Intuition', 'Kinetics', 'Lasers', 'Lighting', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical center', 'Molecular', 'Morphology', 'Nerve Degeneration', 'Oils', 'Phenotype', 'Reader', 'Refractive Indices', 'Resolution', 'Scanning', 'Series', 'Site', 'Specimen', 'Speed', 'System', 'Texture', 'Thick', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Universities', 'Water', 'aqueous', 'base', 'drug discovery', 'flexibility', 'high resolution imaging', 'imager', 'imaging system', 'instrument', 'interest', 'model development', 'organ regeneration', 'physiologic model', 'screening', 'user-friendly']",OD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,S10,2020,1010594,-0.0004404642944889473
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,9855767,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2020,1835520,0.019296527750357444
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10023935,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2020,256578,-0.0058296538973223
"Computational and Statistical Framework to Model Tissue Shape and Mechanics PROJECT SUMMARY  The morphologic and mechanical characteristics of a tissue are fundamental to understanding the development, homeostasis, and pathology of the human body. During the previous period of funding, we developed statistical shape modeling (SSM) methods and applied these to the study of structural hip disease. We also developed the initial framework to integrate SSM with finite element (FE) analysis to enable the study of shape and mechanics together. If incorporated into clinical practice, SSM and FE analysis could identify features of the anatomy likely responsible for injury, remodeling, or repair. Geometry needed for SSM and FE models is typically generated by segmentation of volumetric imaging data. This step can be painstakingly slow, error prone, and cost prohibitive, which hampers clinical application of these computational techniques. We have created a deep machine learning algorithm ‘DeepSSM’ that uses a convolutional neural network to establish the correspondence model directly from unsegmented images. In Aim 1 we will apply DepSSM to improve clinical understanding of structural hip disease by characterizing differences in anatomy between symptomatic and asymptomatic individuals; these morphometric comparisons will identify anatomic features most telling of disease, thereby guiding improvements in diagnosis. Computational advancements have simplified the process to generate patient-specific FE models, enabling clinically focused research. However, there is no framework to collectively visualize, compare, and interpret (i.e., post-process) results from multiple FE models. Currently, inter-subject comparisons require oversimplifications such as averaging results over subjectively defined regions. In Aim 2 we will develop new post-processing methods to collectively visualize, interpret and statistically analyze FE results across multiple subjects and study groups. We will map FE results to synthetic anatomies representing statistically meaningful distributions using the correspondence model. Statistical parametric mapping will be applied to preserve anatomic detail through statistical testing. We will use our published FE models of hip joint mechanics as the test system. Finally, volumetric images provide a wealth of information that is delivered to physicians in a familiar format. Yet, tools are not available to interpret model data with clinical findings from volumetric images. In Aim 3, we will develop methods that evaluate relationships between shape, mechanics, and clinical findings gleaned from imaging through integrated statistical tests and semi-automatic medical image annotation tools that utilize standard ontologies. Quantitative CT and MRI images of the hip, which estimate bone density and cartilage ultrastructure, respectively, will be evaluated as test datasets. To impart broad impact, we will disseminate our methods to the community as open source software that will call core functionality provided by existing, open source software that has a large user base (FEBio, ShapeWorks). PROJECT NARRATIVE The proposed technology will provide the methodologies necessary to increase the clinical acceptance and applicability of computer models. These models measure three-dimensional tissue shape and estimate tissue mechanics, providing information that cannot be measured conventionally. We will implement these methods into software that can be used by the public free-of-charge.",Computational and Statistical Framework to Model Tissue Shape and Mechanics,9972694,R01EB016701,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anatomy', 'Architecture', 'Bone Density', 'Cardiology', 'Cartilage', 'Characteristics', 'Charge', 'Clinical', 'Communities', 'Computational Technique', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Finite Element Analysis', 'Foundations', 'Funding', 'Geometry', 'Glean', 'Grooming', 'Hip Joint', 'Hip region structure', 'Homeostasis', 'Human Pathology', 'Human body', 'Image', 'Individual', 'Injury', 'Intuition', 'Libraries', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Mechanics', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Neurology', 'Ontology', 'Orthopedics', 'Pathology', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Procedures', 'Process', 'Publishing', 'Quantitative Evaluations', 'Research', 'Resources', 'Scheme', 'Shapes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Validation', 'X-Ray Computed Tomography', 'annotation  system', 'base', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data modeling', 'disease diagnosis', 'improved', 'in vivo', 'machine learning algorithm', 'novel', 'open source', 'predictive modeling', 'preservation', 'relating to nervous system', 'repaired', 'shape analysis', 'simulation', 'three-dimensional modeling', 'tool']",NIBIB,UNIVERSITY OF UTAH,R01,2020,563658,0.015215618877612146
"Novel Algorithms for Reducing Radiation Dose of CT Perfusion Project Summary/Abstract X-ray computed tomography (CT) has been increasingly used in medical diagnosis, currently reaching more than 100 million CT scans every year in the US. The increasing use of CT has sparked concern over the effects of radiation dose on patients. It is estimated that every 2000 CT scans will cause one future cancer, i.e., 50,000 cases of future cancers from 100 million CT scans every year. CT brain perfusion (CTP) is a widely used imaging technique for the evaluation of hemodynamic changes in stroke and cerebrovascular disorders. However, CTP involves high radiation dose for patients as the CTP scan is repeated on the order of 40 times at the same anatomical location, in order to capture the full passage of the contrast bolus. Several techniques have been applied for radiation dose reduction in CTP scans, including reduction of tube current and tube voltage, as well as the use of noise reduction techniques such as iterative reconstruction (IR). However, the resultant radiation dose of existing CTP scans is still significantly higher than that of a standard head CT scan. The application of IR techniques in CTP is very limited due to the high complexity and computational burden for processing multiple CTP images that impairs clinical workflow. During the Phase 1 STTR project, we introduced a novel low dose CTP imaging method based on the k-space weighted image contrast (KWIC) reconstruction algorithm. We performed thorough evaluation in both a CTP phantom and clinical CTP datasets, and demonstrated that the KWIC algorithm is able to reduce the radiation dose of existing CTP techniques by 75% without affecting the image quality and accuracy of quantification (i.e., Milestone of Phase 1 STTR). However, the original KWIC algorithm requires rapid-switching pulsed X-ray at pre-specified rotation angles – a hardware capability yet to be implemented by commercial CT vendors. In order to address this limitation, we recently introduced a variant of the KWIC algorithm termed k-space weighted image average (KWIA) that preserves high spatial and temporal resolutions as well as image quality of low dose CTP data (~75% dose reduction) to be comparable to those of standard CTP scans. Most importantly, KWIA does not require modification of existing CT hardware and is computationally simple and fast, therefore has a low barrier for market penetration. The purpose of the Phase 2 STTR project is to further optimize and validate the KWIA algorithm for reducing radiation dose of CTP scans by ~75% while preserving the image quality and quantification accuracy in CTP phantom, clinical CTP data and animal studies. We will further develop innovative deep-learning (DL) based algorithms to address potential motion and other artifacts in KWIA, and commercialize the developed algorithms by collaborating with CT vendors. Relevance to Public Health More than 100 million CT scans are performed every year in the US, estimated to cause 50,000 cases of future cancers. This project will develop, evaluate and commercialize novel CT imaging technologies that reduce the radiation dose of existing CT perfusion techniques by ~75% without compromising imaging speed or quality.",Novel Algorithms for Reducing Radiation Dose of CT Perfusion,10006737,R44EB024438,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American Heart Association', 'Anatomy', 'Angiography', 'Animals', 'Bolus Infusion', 'Brain', 'Brain Neoplasms', 'Cerebrovascular Disorders', 'Clinical', 'Collaborations', 'Data', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Dose', 'Evaluation', 'Future', 'Goals', 'Guidelines', 'Head', 'Heart', 'Image', 'Imaging Techniques', 'Imaging technology', 'Impairment', 'Infarction', 'Location', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical', 'Methods', 'Modification', 'Monitor', 'Morphologic artifacts', 'Motion', 'Noise', 'Organ', 'Patients', 'Pattern', 'Penetration', 'Perfusion', 'Phase', 'Physiologic pulse', 'Public Health', 'Radiation Dose Unit', 'Reperfusion Therapy', 'Roentgen Rays', 'Rotation', 'Scanning', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specific qualifier value', 'Speed', 'Stroke', 'Techniques', 'Technology', 'Time', 'Traumatic Brain Injury', 'Tube', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'acute stroke', 'base', 'brain tissue', 'contrast imaging', 'deep learning', 'denoising', 'hemodynamics', 'imaging modality', 'innovation', 'low dose computed tomography', 'novel', 'perfusion imaging', 'preservation', 'radiation effect', 'reconstruction', 'temporal measurement', 'voltage']",NIBIB,"HURA IMAGING, INC",R44,2020,820709,-0.0025949593635758448
"FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring Project Abstract/Summary Ultra-low dose CT, defined as sub-millisievert (sub-mSv) imaging of the entire chest, abdomen or pelvis, is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, photon starvation and electronic noise make imaging at such dose levels challenging. Photon starvation refers to the number of transmitted photons. When no photons are transmitted, the measurement is essentially useless. If few photons are transmitted, the measurement carries information, but its interpretation and value are confounded by electronic noise. Solutions with encouraging results have been offered for sub-mSv chest imaging, but these are not widely available and not easily generalizable across anatomical sites, vendors and scanner models. We propose a novel, robust solution for ultra-low dose CT that will overcome these issues. We refer to our solution as FAIR-CT, which stands for Finite-Angle Integrated-Ray CT. FAIR-CT operates under the principle that photon starvation and the confounding effect of electronic noise are best handled by avoiding them, which is made possible by increasing the data integration time during the source-detector rotation. FAIR-CT data strongly deviate from the classical CT data model and share the streak artifact problem of sparse view sampling. FAIR-CT data acquisition also affects azimuthal resolution. We anticipate that these issues can be suitably handled using advanced image reconstruction techniques. Once available, FAIR-CT will allow improvements in longitudinal monitoring of patients with chronic diseases such as COPD, urolithiasis and diabetes, thereby reducing mortality and co-morbidities. FAIR-CT will also allow advancing cancer therapy treatments by enabling adjustments in radiation therapy plans between dose fractions without increasing CT radiation exposure, and by facilitating early detection of inflammations in drug-based therapies. To bring FAIR-CT towards fruition, we will work on two specific aims: (1) Creation of a comprehensive collection of FAIR-CT data sets enabling rigorous development, validation and evaluation of image reconstruction algorithms; (2) Development, validation and evaluation of advanced image reconstruction algorithms. The FAIR-CT data sets will involve the utilization of state-of-the-art scanners and include real patient data synthesized from high dose scans acquired for standard of care. Two complementary image reconstruction approaches will be investigated. Namely, model-based iterative reconstruction with non-linear forward model and dedicated compressed sensing regularization; and deep learning-based refinement of FBP reconstructions using target images with task-adapted image quality. Image quality evaluation will account for critical biological variables and involve objective metrics such as structure similarity and contrast-to-noise ratio for clinically-proven lesions, as well as task-based performance metrics involving human readers. Ultra-low dose X-ray computed tomography is critically needed for healthcare of patients with chronic diseases and cancer. Unfortunately, physics-related challenges and impractical solutions make this concept unavailable for everyday clinical use. We will develop a novel solution that is practical and can quickly be brought to clinical practice.",FAIR-CT: a practical approach to enable ultra-low dose CT for longitudinal disease and treatment monitoring,9877188,R21EB029179,"['Abdomen', 'Academia', 'Advanced Malignant Neoplasm', 'Affect', 'Algorithms', 'Anatomy', 'Biological', 'Body mass index', 'Chest', 'Chronic Disease', 'Chronic Obstructive Airway Disease', 'Clinical', 'Collection', 'Computers', 'Cystic Fibrosis', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Dose', 'Early Diagnosis', 'Epidemic', 'Evaluation', 'Fruit', 'Goals', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Industry', 'Inflammation', 'Inflammatory Bowel Diseases', 'Lesion', 'Malignant Neoplasms', 'Measurement', 'Metabolic Diseases', 'Modeling', 'Modernization', 'Monitor', 'Morphologic artifacts', 'Noise', 'Obesity', 'Patient Monitoring', 'Patients', 'Pelvis', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physics', 'Polycystic Kidney Diseases', 'Process', 'Pulmonary Inflammation', 'Radiation exposure', 'Radiation therapy', 'Radiology Specialty', 'Reader', 'Research', 'Resolution', 'Rotation', 'Sampling', 'Scanning', 'Source', 'Starvation', 'Structure', 'Techniques', 'Technology', 'Time', 'Validation', 'Vendor', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer risk', 'cancer therapy', 'clinical practice', 'clinical translation', 'clinically translatable', 'comorbidity', 'data acquisition', 'data integration', 'data modeling', 'data sharing', 'deep learning', 'detector', 'expectation', 'image reconstruction', 'improved', 'low dose computed tomography', 'mortality', 'novel', 'reconstruction', 'sex', 'side effect', 'standard of care', 'targeted imaging', 'urolithiasis']",NIBIB,UNIVERSITY OF UTAH,R21,2020,265345,-0.005841013671843176
"STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients Project Summary/Abstract Lung cancer is the leading cause of cancer death and one of the most common cancers among both men and women in the United States. Recent advances in high-resolution imaging set the stage for radiomics to become an active emerging field in cancer research. However, the promise of radiomics is limited by a lack of image standardization tools, because computed tomography (CT) images are often acquired using scanners from different vendors with customized acquisition parameters, posing a fundamental challenge to radiomic studies across sites. To overcome this challenge, especially for large-scale, multi-site radiomic studies, advanced algorithms are required to integrate, standardize, and normalize CT images from multiple sources. We propose to develop STAN-CT, a deep learning software package that can automatically standardize and normalize a large volume of diagnostic images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification. By precisely mitigating the differences in advanced radiomic features of CT images, STAN-CT will overcome research silos and promote medical image resource sharing, ultimately improving the diagnosis and treatment of lung cancer. Our goal will be achieved through two Aims. In Aim 1, we will develop a working prototype to standardize CT images. First, we will collect raw image data from lung cancer patients and reconstruct CT images using multiple image reconstruction parameters, and we will scan a multipurpose chest phantom along with five different nodule inserts. Then, we will develop and train STAN-CT for CT image standardization. An alternative training architecture will be developed to achieve the improved model training stability. In Aim 2. We will deploy and test STAN-CT for image standardization locally and across three medical centers. First, we will make the STAN-CT software package available to the public by providing a menu-driven web-interface so that that users can conveniently convert medical images that were taken using non-standard protocols to one or multiple standards that they specify. Second, we will deploy STAN-CT at the University of Kentucky for local performance validation. We will test the functionality, reliability, and performance of STAN-CT using both patient chest CT image data collected at large-scale and the phantom image data, both independent to training. Third, we will deploy and test STAN-CT at the University of Kentucky as well as the University of Texas Southwestern Medical Center and Emory University for cross- center performance validation. We will use the same multipurpose chest phantom and both standard and non- standard protocols to validate STAN-CT at the three centers. We will test the generalizability of STAN-CT using clinical CT images of human patients and will determine whether a model trained using the data from one medical center are applicable for images collected at another place. Finally, we will distribute the software package of STAN-CT for public use. STAN-CT will enable a wide range of radiomic researches to identify diagnostic image features that strongly associated with lung cancer prognosis. Project Narrative Computed tomography (CT) is one of the most popular diagnostic image modalities routinely used for assessing anatomical tissue characteristics for disease management. However, CT images are often acquired using scanners from different vendors with different imaging standards, posing a fundamental challenge to radiomic studies across sites. The goal of the Standardization and Normalization of CT images for lung cancer patients (STAN-CT) project is to develop a deep learning software package that can automatically standardize and normalize a large volume of chest CT images to facilitate cross-site large-scale image feature extraction for lung cancer characterization and stratification.",STAN-CT: Standardization and Normalization of CT images for Lung Cancer Patients,9961508,R21CA231911,"['Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Cancer Etiology', 'Cancer Patient', 'Cancer Prognosis', 'Cessation of life', 'Characteristics', 'Chest', 'Clinical', 'Communities', 'Computed Tomography Scanners', 'Computer software', 'Custom', 'Data', 'Diagnosis', 'Diagnostic Imaging', 'Disease Management', 'Evolution', 'Faculty', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Imaging technology', 'Kentucky', 'Life', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Medical Imaging', 'Medical center', 'Modeling', 'Multi-Institutional Clinical Trial', 'Names', 'Nodule', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Protocols documentation', 'Quality Control', 'Radiology Specialty', 'Research', 'Resource Sharing', 'Scanning', 'Site', 'Source', 'Specific qualifier value', 'Standardization', 'Stratification', 'Survival Rate', 'System', 'Testing', 'Texas', 'Tissues', 'Training', 'United States', 'Universities', 'Validation', 'Vendor', 'Woman', 'X-Ray Computed Tomography', 'anticancer research', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer therapy', 'chest computed tomography', 'computational platform', 'data to knowledge', 'deep learning', 'feature extraction', 'high resolution imaging', 'human imaging', 'image reconstruction', 'imaging modality', 'improved', 'lung imaging', 'member', 'men', 'outcome forecast', 'prototype', 'quantitative imaging', 'radiomics', 'response', 'spatial temporal variation', 'tool', 'trait', 'tumor', 'web interface']",NCI,UNIVERSITY OF KENTUCKY,R21,2020,175505,-0.06309003561022257
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this project, we present EyeMark, a system with advanced longitudinal image anal- ysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we have developed tools for computation of microan- eurysm (MA) appearance and disappearance rates (jointly known as turnover rates) for use as a biomarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high pos- itive influence on various aspects of DR care, including screening, monitoring progres- sion, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a prototype tool that robustly registers longitudinal images (even with multiple lesion changes) and effectively detects and localizes DR le- sions. This fully automated tool can work on the cloud to produces results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. This commercialization readiness pilot (CRP) project is intended to develop a regulatory strategy and a market access plan for EyeMark to enable its introduction in the US market and foster commercial success. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,10082344,SB1TR000377,"['Adult', 'Age', 'Appearance', 'Biological', 'Biological Markers', 'Biometry', 'Blindness', 'Caring', 'Clinical', 'Clinical Research', 'Code', 'Color', 'Communication', 'Computer Vision Systems', 'Consumption', 'Contracts', 'County', 'Detection', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Early identification', 'Environment', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Feedback', 'Fostering', 'Funding', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Legal', 'Lesion', 'Los Angeles', 'Machine Learning', 'Market Research', 'Marketing', 'Measures', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Participant', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Price', 'Process', 'Prothrombin', 'Readiness', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Sales', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Surveys', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'algorithm development', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'commercialization', 'computerized', 'computerized tools', 'convolutional neural network', 'design', 'diabetic patient', 'drug discovery', 'experience', 'fundus imaging', 'health economics', 'high risk', 'high throughput analysis', 'image registration', 'imaging biomarker', 'interest', 'large datasets', 'longitudinal analysis', 'medical schools', 'novel marker', 'novel therapeutics', 'payment', 'prevent', 'programs', 'prototype', 'retinal imaging', 'screening', 'serial imaging', 'sound', 'success', 'tool', 'usability']",NCATS,"EYENUK, INC.",SB1,2020,300000,0.006628419661853517
"Human Tumor Atlas Network: Data Coordinating Center Supplement This proposal is a collaboration with the HTAN Data Coordination Center DCC and describes an Image Data Project aimed at developing and deploying the technology needed for storage, distribution and basic analysis of cell and tissue images collected by multiple HTAN Centers. Multiplexed tissue images are an important type of data for nearly all of the centers contributing to the HTAN (second only to single cell sequencing data in number of centers collecting data). However, the software needed to visualize, analyze, manage, and share multiplexed images of tissues and tumors is underdeveloped. The initial availability of SARDANA images has highlighted the challenges faced by HTAN, including the DCC, in deploying an infrastructure for distributing large and complex images. We therefore propose a two-year HTAN Image Data Project (IDP) led by the DCC and HMS PCA focused on the rapid development and deployment of image informatic systems and computational resources for image management and analysis. Our goal is to put in place a functional first-generation system no later than summer 2020 and to then steadily refine the system so that it becomes the backbone of cross-functional HTAN atlases. As a matter of necessity, we will start with informatic systems and software that are either available today or in a relatively advanced state of development. However, we expect to evaluate these choices throughout the IDP and change course as necessary to incorporate potentially superior approaches. We will also support the diverse needs and formats of centers using different data collection methods. Aim 1 will focus on the deployment and progressive improvement of a cloud-based database for image management based on the OMERO standard as well as a parallel system for access to primary data. Aim 2 will develop and deploy software for visualizing HTAN image data by the general public. The IDP will use the existing MCWG and DAWG mechanisms for oversight and reporting, and all centers will be invited to participate. Within IDP, the HMS PCA will take primary responsibility for initial deployment of image informatics software. The DCC and HMS will jointly undertake software development and code hardening, and the DCC will take the lead in user assistance and software deployment, particularly in year two. Images of tumor specimens obtained from biopsy or surgery are one of the primary ways in which cancer is diagnosed and staged by pathologists, but such images have typically lacked molecular detail. The highly multiplexed tissue images being collected by HTAN will fundamentally change this, and it is therefore essential that the data be efficiently and widely distributed. The HTAN Image Data Project IDP will address an acute need for software for data dissemination and visualization.",Human Tumor Atlas Network: Data Coordinating Center Supplement,10206514,U24CA233243,"['Acute', 'Address', 'Atlases', 'Bioinformatics', 'Biopsy', 'Client', 'Code', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Databases', 'Development', 'Diagnosis', 'European', 'General Population', 'Generations', 'Goals', 'Human', 'Image', 'Imaging Device', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Malignant Neoplasms', 'Manuscripts', 'Methods', 'Modeling', 'Molecular', 'Operative Surgical Procedures', 'Output', 'Pathologist', 'Performance', 'Reporting', 'Side', 'Slide', 'Software Tools', 'Specimen', 'System', 'Technology', 'Testing', 'Tissue imaging', 'Tissues', 'Vertebral column', 'Visualization', 'base', 'cancer imaging', 'cellular imaging', 'cloud based', 'computing resources', 'data dissemination', 'data management', 'data resource', 'data visualization', 'imaging Segmentation', 'imaging informatics', 'improved', 'machine learning algorithm', 'multiplexed imaging', 'programs', 'relational database', 'single cell sequencing', 'software development', 'supervised learning', 'tumor']",NCI,DANA-FARBER CANCER INST,U24,2020,926364,0.05302087028383411
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,10021685,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'algorithm development', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'data quality', 'deep learning', 'denoising', 'detector', 'drug action', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,344862,-0.005466355151722973
"Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes/eyelids and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to develop a more precise DR scoring scheme. This would help identify patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images,10082348,R44EY028081,"['Agreement', 'Algorithms', 'Applications Grants', 'Biological', 'Blindness', 'Cataract', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Ensure', 'Exposure to', 'Eye', 'Eye diseases', 'Eyelash', 'Eyelid structure', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Internet', 'Lasers', 'Lesion', 'Light', 'Localized Lesion', 'Manuals', 'Measures', 'Modality', 'Morphologic artifacts', 'Online Systems', 'Ophthalmoscopy', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scheme', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Validation', 'Vision', 'Work', 'automated analysis', 'base', 'cloud based', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability']",NEI,"EYENUK, INC.",R44,2020,1000000,0.026263767796714427
"Diabetic Retinopathy: genetics and neurodegeneration PROJECT SUMMARY/ABSTRACT Diabetes mellitus (DM) is the leading cause of vision loss among working aged adults. Its prevalence is increasing and despite the strides in knowledge and treatments, our understanding of the pathways leading to vision loss in DM remains limited. Hyperglycemia and duration of DM contribute to but do not fully explain the predisposition to develop diabetic retinal diseases. Given the predisposition for diabetic retinal diseases to cluster in families, genetic risk factors are thought to be important but none has so far been definitively implicated. Furthermore, data from small studies suggest that there are more phenotypes of diabetic retinal disease than are currently recognized in clinical practice. Diabetic retinal disease has traditionally been considered primarily a vascular process: diabetic retinopathy (DR) and diabetic macular edema (DME) are the main clinical manifestations. With improved imaging modalities and image analysis algorithms, there has been increasing recognition of a new clinical manifestation of diabetic retinal disease, diabetic retinal neurodegeneration (DRN). This is visible as alterations in thickness of retinal nerve fiber (RNFL) and/or ganglion cell layer (GCL) on optical coherence tomography (OCT) images. To date, DRN is poorly understood, and its role in clinical management of patients with DM has not been established. However, if retinal neurodegeneration occurs and is progressive, it can lead to profound visual difficulties for patients with DM. DRN may account for previously unexplained poor visual outcomes among patients with diabetic retinal disease despite standard of care treatment. Dr. Channa is a retina specialist, with prior research experience in retinal imaging and clinical trials of novel treatments for DME. In this K23 career development award she proposes to use a nationally representative dataset, the UK Biobank cohort to: 1) improve our understanding of DRN by determining RNFL and GCL thickness, using OCT imaging, in participants with DM (who have no DR or DME) compared to those who do not have DM 2) determine genetic factors associated with DR, DME and DRN. Dr. Channa proposes a career development plan, which includes mentorship, coursework, publications and clinical time. This will situate her as an independent clinician-scientist with expertise in translational research employing bioinformatics and computational skills in genomics and retinal image analysis to elucidate pathways of vision loss among patients with DM, ultimately leading to development of novel therapies. Her research work and career development will take place in the academic and collaborative environment of the largest medical center in the world, where she has institutional support and mentorship to develop as an independent clinician-scientist. PROJECT NARRATIVE In this career development award we aim to use genetic and retinal imaging data to enhance our understanding of the pathways that can lead to vision loss among people with diabetic retinal diseases. Improved understanding will translate into interventions aimed at preventing blindness from diabetes.",Diabetic Retinopathy: genetics and neurodegeneration,9868630,K23EY030911,"['Address', 'Adult', 'Affect', 'Algorithmic Analysis', 'American', 'Appearance', 'Artificial Intelligence', 'Bioinformatics', 'Blindness', 'Blood Vessels', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational algorithm', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Disease', 'Disease Pathway', 'Environment', 'Family', 'Fundus', 'Future', 'Ganglion Cell Layer', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genomics', 'Goals', 'Hyperglycemia', 'Image', 'Image Analysis', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Measurement', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Molecular', 'Nerve', 'Nerve Degeneration', 'Nerve Fibers', 'Optical Coherence Tomography', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Phenotype', 'Predisposition', 'Prevalence', 'Prevention', 'Process', 'Publications', 'Race', 'Regression Analysis', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Risk Factors', 'Role', 'Sample Size', 'Scanning', 'Scientist', 'Specialist', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Translating', 'Translational Research', 'Vascular Endothelial Growth Factors', 'Vision', 'Visual', 'Work', 'aged', 'base', 'biobank', 'career development', 'clinical practice', 'cohort', 'collaborative environment', 'diabetes management', 'diabetic', 'disability', 'experience', 'family genetics', 'fiber cell', 'genetic risk factor', 'genome wide association study', 'genomic data', 'illness length', 'imaging modality', 'improved', 'large datasets', 'macular edema', 'novel', 'novel therapeutics', 'population based', 'prevent', 'retinal imaging', 'screening', 'skills', 'standard of care']",NEI,BAYLOR COLLEGE OF MEDICINE,K23,2020,290835,-0.014874095857359314
