text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,9739919,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Base Management', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistics', 'subchondral bone', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,588354,-0.02332961214690937
"Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures PROJECT SUMMARY/ABSTRACT: Arterial hemorrhage after pelvic fractures is a leading reversible cause of death after blunt trauma. Prediction of arterial bleeding risk is difficult, and currently determined using subjective criteria, often based on qualitative results of admission computed tomography (CT). Segmented hematoma and contrast extravasation (CE) volumes predict need for angioembolization, major transfusion, and mortality but cannot be applied in real-time. The ill-defined multi-focal nature of pelvic hematomas and CE prevents reliable estimation using diameter-based measurements. Dr. Dreizin is a trauma radiologist at the University of Maryland School of Medicine. His early work has focused on improving the speed and reliability of volumetric analysis of pelvic hematomas using semi-automated techniques, and derivation of a logistic regression-based prediction tool for major arterial injury after pelvic fractures. Dr. Dreizin’s goal for this four- year K08 mentored career development award proposal is to gain the skills needed to 1) implement deep learning architectures for automated hematoma volume segmentation and 2) develop computational models for outcome prediction after pelvic trauma. These tools could greatly improve the speed and accuracy of clinical decision making in the setting of life-threatening traumatic pelvic bleeding. Fully convolutional neural networks (FCNs) have emerged as the most robust and scalable method for automated medical image segmentation. Intuitive software platforms for training FCN implementations and generating multivariable machine learning models have been developed in the Python programming environment. The training objectives and research activities of this proposal are necessary to provide Dr. Dreizin with new skills and practical experience in Python programming, deep learning software, and computational modeling software. By understanding the principles and computational infrastructure behind modern machine learning, Dr. Dreizin will be able to train and validate state-of-the-art algorithms independently and effectively lead a team of researchers in this area. To achieve his goals, Dr. Dreizin has assembled a multidisciplinary team of mentors, advisors, and collaborators with world-leading expertise in computer vision in medical imaging, probability theory, data science, and comparative effectiveness research. Dr. Dreizin will focus on two specific aims. In Aim 1, he will train and validate deep learning architectures for segmentation of traumatic pelvic hematomas and CE by computing the Dice metric, time effort, and correlation with clinical outcomes. In Aim 2, he will generate and test quantitative models for predicting major arterial bleeding after pelvic trauma based on a rich multi-label dataset of segmented features. The training and pilot data will be necessary for Dr. Dreizin’s long- term goal of research independence and R01 support to develop automated segmentation algorithms for the spectrum of clinically important imaging features after pelvic trauma, as well as fully automated multivariable clinical prediction tools with potential for translation to industry and as an FDA-cleared product. PROJECT NARRATIVE: Hemorrhage after pelvic fractures is common after motor vehicle collisions, falls, and crush injuries, with mortality rates that range from 5-54%. The volume of hemorrhage, as measured on computed tomography (CT) scans, predicts the need for rapid intervention or transfusion, and is a strong predictor of mortality, but no automated image-processing methods exist for real-time hemorrhage volume measurement. We propose to develop automated software for hemorrhage-detection, and real-time risk prediction software for major arterial hemorrhage after pelvic fractures.",Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures,9819865,K08EB027141,"['Admission activity', 'Adoption', 'Algorithms', 'Angiography', 'Architecture', 'Area', 'Arterial Injury', 'Award', 'Blunt Trauma', 'Caliber', 'Catheters', 'Cause of Death', 'Clinical', 'Communities', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Crush Injury', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Detection', 'Development', 'Diagnosis', 'Early Intervention', 'Engineering', 'Environment', 'Extravasation', 'Fall injury', 'Funding', 'Goals', 'Hematoma', 'Hemorrhage', 'Hospitalization', 'Human', 'Image', 'Industry', 'Intervention', 'Intuition', 'K-Series Research Career Programs', 'Knowledge', 'Label', 'Lead', 'Learning', 'Life', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Maryland', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Obesity', 'Outcome', 'Patients', 'Pelvis', 'Predictive Value', 'Probability Theory', 'Process', 'Programming Languages', 'Pythons', 'Radiology Specialty', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Shorthand', 'Speed', 'Supervision', 'Techniques', 'Terminology', 'Testing', 'Therapeutic Embolization', 'Thinness', 'Time', 'Training', 'Transfusion', 'Translations', 'Trauma', 'Treatment outcome', 'Triage', 'Universities', 'Vehicle crash', 'Work', 'X-Ray Computed Tomography', 'adverse outcome', 'artificial neural network', 'base', 'clinical decision-making', 'comparative effectiveness', 'computer infrastructure', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'effectiveness research', 'experience', 'hemodynamics', 'heuristics', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'learning strategy', 'medical schools', 'mortality', 'multidisciplinary', 'muscle form', 'neural network architecture', 'outcome prediction', 'pelvis fracture', 'personalized predictions', 'predictive modeling', 'prevent', 'primary outcome', 'radiologist', 'random forest', 'real time model', 'secondary outcome', 'skills', 'standard of care', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF MARYLAND BALTIMORE,K08,2019,186183,-0.012230453580440155
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,9713512,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Catalogs', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2019,647706,-0.008592928994367106
"AmplideX DeepNet, a new paradigm for deep learning analytical tools in the molecular diagnostic space Project Summary  An extensible analysis platform will be developed to accurately perform the automated genotyping of PCR/capillary electrophoresis (CE) traces for multiple disease-associated short tandem repeater (STR) assays. This study will evaluate the feasibility of developing generalizable and adaptive molecular analysis models, and will ultimately establish a new paradigm for deep learning analytical tools in the molecular diagnostic space.  Advanced machine learning strategies will be applied to interpret genotypes of inherited disorders caused by genetically unstable STR DNA sequences. STRs have traditionally been difficult to investigate due to their length (on the order of kilobases) and low sequence complexity, which elude detection by traditional and next- generation sequencing technologies. However, advances in PCR/CE technology have enabled the amplification and fragment sizing of STR DNA fragments, advancing clinical research and diagnostic test development for several neurodegenerative disorders, such as fragile X syndrome and amyotrophic lateral sclerosis. Despite these advances, the analysis of PCR/CE data from assays targeting STRs remains a manual, burdensome, and subjective process. There is a clear need to create a system that can scale with the development of new assays, and the proposed approach utilizes modern breakthroughs in artificial intelligence to fulfill that need.  This method will leverage recent advances in representation learning to establish a generalized and adaptive framework for automated PCR/CE annotation that can scale to new assays and improve automatically with the inclusion of new data. The project will benefit from Asuragen’s experience in optimizing repeat-primed chemistries to develop and commercialize multiple high performance assays including the AmplideX PCR/CE FMR1 kit. Importantly, the proposed modeling strategy will borrow-strength across multiple established PCR/CE assays and generalize to future PCR/CE assays for novel STR disease associated biomarkers. This system will be paramount to enabling a continuous learning platform wherein computationally-assisted annotation of PCR/CE assays can be continuously improved and integrated in to clinical research tools and diagnostics. Project Narrative  We are developing AmplideX DeepNet, an artificial intelligence-based analysis system that can accurately perform computationally-assisted analysis of molecular diagnostic assays. The proposed system will build upon recent breakthroughs in artificial intelligence to allow it to easily adapt to new assays and to continue to improve. The system will be applied to assays for several disorders, including fragile X syndrome, amyotrophic lateral sclerosis (ALS), myotonic dystrophy, and Huntington’s disease, and will provide a number of benefits over current analysis methods by reducing turn-around time for assay results and assuring reproducible reporting between operators and labs.","AmplideX DeepNet, a new paradigm for deep learning analytical tools in the molecular diagnostic space",9678895,R43GM128498,"['Alleles', 'American', 'Amyotrophic Lateral Sclerosis', 'Artificial Intelligence', 'Automated Annotation', 'Biological Assay', 'Biological Markers', 'C9ORF72', 'Capillary Electrophoresis', 'Chemistry', 'Clinical', 'Clinical Research', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnostic', 'Diagnostic tests', 'Disease', 'FMR1', 'FMR1 repeat', 'Fragile X Syndrome', 'Future', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Guidelines', 'Hand', 'Hereditary Disease', 'Heritability', 'Huntington Disease', 'Interruption', 'Learning', 'Length', 'Machine Learning', 'Manuals', 'Medical Genetics', 'Methods', 'Modeling', 'Modernization', 'Molecular Analysis', 'Myotonic Dystrophy', 'Neurodegenerative Disorders', 'Nucleotides', 'Pathogenicity', 'Performance', 'Phase', 'Process', 'Quality Control', 'Reagent', 'Reporting', 'Reproducibility', 'Running', 'Sampling', 'Short Tandem Repeat', 'System', 'Systems Analysis', 'Technology', 'Testing', 'Time', 'Training', 'analysis pipeline', 'analytical tool', 'automated analysis', 'base', 'clinical diagnostics', 'cohort', 'computer framework', 'deep learning', 'design', 'diagnostic assay', 'experience', 'frontotemporal lobar dementia-amyotrophic lateral sclerosis', 'heuristics', 'human-in-the-loop', 'improved', 'instrumentation', 'learning progression', 'learning strategy', 'medical schools', 'molecular diagnostics', 'nervous system disorder', 'next generation sequencing', 'novel', 'research and development', 'success', 'tool']",NIGMS,"ASURAGEN, INC.",R43,2019,269217,-0.0033175598348618206
"Machine learning approaches for improved accuracy and speed in sequence annotation Summary/Abstract Alignment of biological sequences is a key step in understanding their evolution, function, and patterns of activity. Here, we describe Machine Learning approaches to improve both accuracy and speed of highly- sensitive sequence alignment. To improve accuracy, we develop methods to reduce erroneous annotation caused by (1) the existence of low complexity and repetitive sequence and (2) the overextension of alignments of true homologs into unrelated sequence. We describe approaches based on both hidden Markov models and Artificial Neural Networks to dramatically reduce these sorts of sequence annotation error. We also address the issue of annotation speed, with development of a custom Deep Learning architecture designed to very quickly filter away large portions of candidate sequence comparisons prior to the relatively-slow sequence-alignment step. The results of these efforts will be incorporated into forks of the open source sequence alignment tools HMMER, MMSeqs, and (where appropriate) BLAST; we will also work with community developers of annotation pipelines, such as RepeatMasker and IMG/M, to incorporate these approaches. The development and incorporation into these widely used bioinformatics tools will lead to widespread impact on sequence annotation efforts. Narrative Modern molecular biology depends on effective methods for creating sequence alignments quickly and accurately. This proposal describes a plan to develop novel Machine Learning approaches that will dramatically increase the speed of highly-sensitive sequence alignment, and will also address two significant sources of erroneous sequence annotation, (i) the presence of repetitive sequence in biological sequences, and (ii) the tendency for sequence alignment algorithms to extend alignments beyond the boundaries of true homology. The proposed methods represent a mix of applications of hidden Markov models and Artificial Neural Networks, and build on prior success in applying such methods to the problem of sensitive sequence annotation.",Machine learning approaches for improved accuracy and speed in sequence annotation,9887588,R01GM132600,"['Address', 'Algorithms', 'Architecture', 'Bioinformatics', 'Biological', 'Classification', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Custom', 'DNA Transposable Elements', 'Data Set', 'Deletion Mutation', 'Descriptor', 'Development', 'Error Sources', 'Evolution', 'Foundations', 'Genome', 'Genomics', 'Hour', 'Human', 'Human Genome', 'Industry Standard', 'Insertion Mutation', 'Institutes', 'Intervention', 'Joints', 'Label', 'Letters', 'Licensing', 'Machine Learning', 'Manuals', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Molecular Biology', 'Network-based', 'Nucleotides', 'Pattern', 'Pilot Projects', 'Proteins', 'Repetitive Sequence', 'Sequence Alignment', 'Sequence Analysis', 'Source', 'Speed', 'Statistical Models', 'Takifugu', 'Work', 'annotation  system', 'artificial neural network', 'base', 'bioinformatics tool', 'computing resources', 'convolutional neural network', 'deep learning', 'density', 'design', 'genomic data', 'improved', 'markov model', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'software development', 'statistics', 'success', 'tool']",NIGMS,UNIVERSITY OF MONTANA,R01,2019,286435,-0.03589934916451005
"Synergistic integration of topology and machine learning for the predictions of protein-ligand binding affinities and mutation impacts Project Summary Fundamental challenges that hinder the current understanding of biomolecular systems are their tremendous complexity, high dimensionality and excessively large data sets associated with their geometric modeling and simulations. These challenges call for innovative strategies for handling massive biomolecular datasets. Topology, in contrast to geometry, provides a unique tool for dimensionality reduction and data simplification. However, traditional topology typically incurs with excessive reduction in geometric information. Persistent homology is a new branch of topology that is able to bridge traditional topology and geometry, but suffers from neglecting biological information. Built upon PI’s recent work in the topological data analysis of biomolecules, this project will explore how to integrate topological data analysis and machine learning to significantly improve the current state-of-the-art predictions of protein-ligand binding and mutation impact established in the PI’s preliminary studies. These improvements will be achieved through developing physics-embedded topological methodologies and advanced deep learning architectures for tackling heterogeneous biomolecular data sets arising from a variety of physical and biological considerations. Finally, the PI will establish robust databases and online servers for the proposed predictions. Project Narrative The project concerns the integration of topological data analysis and machine learning architectures for the predictions of protein-ligand binding affinities and mutation induced protein stability changes from massive data sets. This new data approach has considerable impact for future generation methods in computational biophysics and drug design.",Synergistic integration of topology and machine learning for the predictions of protein-ligand binding affinities and mutation impacts,9756427,R01GM126189,"['3-Dimensional', 'Address', 'Affinity', 'Architecture', 'Big Data', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biophysics', 'Characteristics', 'Chemicals', 'Classification', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Dimensions', 'Drug Design', 'Electrostatics', 'Elements', 'Free Energy', 'Freedom', 'Future Generations', 'Geometry', 'Handwriting', 'Image Analysis', 'Induced Mutation', 'Ions', 'Learning', 'Ligand Binding', 'Ligands', 'Lipids', 'Machine Learning', 'Medical', 'Membrane', 'Membrane Proteins', 'Metals', 'Methodology', 'Methods', 'Mutation', 'Physics', 'Plant Roots', 'Proteins', 'Psychological Transfer', 'Site', 'Speech', 'System', 'Techniques', 'Thermodynamics', 'Work', 'algebraic topology', 'base', 'cofactor', 'data warehouse', 'deep learning', 'deep learning algorithm', 'direct application', 'high dimensionality', 'improved', 'innovation', 'language processing', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'metallicity', 'models and simulation', 'multi-task learning', 'multitask', 'mutant', 'neglect', 'next generation', 'search engine', 'tool', 'trend', 'user-friendly']",NIGMS,MICHIGAN STATE UNIVERSITY,R01,2019,319267,-0.03634541068929208
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9747977,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2019,115051,-0.01865859727934722
"Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment PROJECT SUMMARY We propose a study of radiomic texture analysis in terms of robustness assessment and classification utility. We will introduce novel robustness metrics geared towards assessment of radiomic features in comparison across two image conditions, and apply these metrics to study feature robustness across imaging parameters and patient biology. In addressing the utility of radiomic features in cancer risk assessment, we will identify and evaluate texture signatures from mammography and tomosynthesis datasets. The field of radiomics is evolving fast, and quantitative texture analysis is being applied to a growing number of applications in medical imaging. By performing a thorough investigation of the robustness of these radiomic features to dataset heterogeneities we aim to identify the strengths and weaknesses of commonly used features to guide their implementations on future applications.  Two clinical tasks will be studied under the proposed research: 1) risk assessment and cancer prediction and 2) malignancy evaluation. Multiple modalities including tomosynthesis, mammography and MRI will be involved in studies geared towards addressing these clinical questions. An evaluation of the robustness of commonly employed radiomic features will help guide the field of medical texture analysis and contribute to meaningful conclusions in future studies throughout the field of quantitative image analysis. The first aim of the proposed research involves the proposition and evaluation of novel robustness metrics for investigations lacking a classification task. The second aim will extend the study of radiomics to investigate the utility of robust features in classification tasks and identification of texture signatures relate to biomedical characteristics. The third aim will build upon the two previous aims and culminate in the application of cutting-edge technologies in machine learning and deep learning in further promoting image processing in the field of medical physics. PROJECT NARRATIVE The goal of the proposed research is to evaluate and improve the application of radiomic texture features in cancer risk assessment. We will accomplish this by evaluating the robustness of various radiomic metrics, testing the classification utility of texture features in clinical tasks, and extending current classification methods to include cutting-edge developments in machine learning technology. Careful preliminary studies have demonstrated methods for selection of robust texture features and improvement in classification tasks by emphasizing feature robustness in feature selection methodology and we therefore believe that a meticulous evaluation of the impact of imaging parameters on feature calculations will lead to overall improvement of computer-aided diagnosis and clinical translation to progress in cancer screening protocols.",Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment,9683697,F31CA228247,"['Address', 'Benign', 'Biological', 'Biology', 'Breast', 'Breast Cancer Risk Factor', 'Characteristics', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Effectiveness', 'Eligibility Determination', 'Emerging Technologies', 'Evaluation', 'Family', 'Future', 'Goals', 'Heterogeneity', 'Image', 'Image Analysis', 'Impact evaluation', 'Incidence', 'Intuition', 'Investigation', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammography', 'Maps', 'Mathematics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Output', 'Patients', 'Pattern', 'Performance', 'Physics', 'Protocols documentation', 'Psychological Transfer', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Screening for cancer', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Imaging', 'Time', 'Translations', 'Variant', 'Work', 'base', 'breast imaging', 'cancer risk', 'clinical translation', 'deep learning', 'expectation', 'high risk', 'image processing', 'image registration', 'imaging modality', 'imaging system', 'improved', 'innovation', 'molecular subtypes', 'multimodality', 'novel', 'outcome forecast', 'patient population', 'quantitative imaging', 'radiomics', 'response', 'tomosynthesis', 'tumor']",NCI,UNIVERSITY OF CHICAGO,F31,2019,24304,-0.04325705357742914
"Real-time Non-Rigid 3D Reconstruction and Registration for Laparoscopic-guided Minimally Invasive Liver Surgery Project Summary/Abstract Liver deformation leads to difficulties in tumor localization during minimally invasive liver surgery (MILS). The goal of this proposal is to develop an efficient surgical navigation tool for MILS by compensating for liver deformation and mapping preoperative data to the patient’s anatomy. Specifically, we will develop a non-rigid simultaneously localization and mapping (SLAM) approach to estimate the deformation of liver surface from stereo laparoscopy videos. We will develop machine-learning methods to detect landmarks and perform non- rigid registration. The algorithms will be implemented on a GPU to achieve real-time. Preliminary data has demonstrated the feasibility. During the R00 phase, we will mainly address the clinical needs and develop novel ways to provide intraoperative guidance. This project will greatly improve the tumor resection accuracy in MILS. The candidate for this award Dr. Haoyin Zhou is a postdoc at Surgical Planning Laboratory (SPL), Brigham and Women’s Hospital (BWH) and Harvard Medical School (HMS). Dr. Zhou has extensive experience and expertise in computer vision, machine learning and their applications in medicine. BWH is an international leader in basic, clinical and translational research on human diseases, and has established multiple research programs to promote the work and professional career development of young investigators. National Center for Image Guided Therapy, and Advanced Multi-modality Image Guided Operating (AMIGO) suite will greatly support this research. Dr. Zhou’s long-term research goal is to develop and apply advanced computer vision and machine learning technologies to improve understanding, diagnosis, treatment, and prevention of diseases for better health care. His long-term career goal is to become an independent investigator working at the frontier of medical image processing and image-guided therapy. To achieve these goals, Dr. Zhou plans to receive more education and training in the following four areas: (1) Critical training in conducting translational research in the hospital environment with surgeons and radiologists, (2) knowledge in the development of technologies for surgical guidance, (3) training in machine learning and its applications in medicine, and (4) training on writing grant applications independently and seeking funding. Dr. Zhou will participate in formal courses selected from Harvard, Harvard Catalyst, MIT CSAIL and Stanford Courses. He will attend weekly seminars at BWH, HMS and MIT. He will also attend one or two academic conferences per year to discuss his work and meet with experts in the field. A strong mentoring team, including one primary mentor, three co-mentors, and two collaborators, has been organized for the K99 phase of this award, which will provide solid support on both research and career development to Dr. Zhou based on their well-established expertise in diverse research fields. Prof. William M. Wells III (primary mentor) is a professor in medical image processing. Prof. Jayender Jagadeesan (co-mentor) is an assistant professor in surgical robotics and surgical navigation. Drs. Ali Tavakkoli and Jiping Wang (co- mentors) are experienced surgeons. All mentors and collaborators are from BWH, HMS. Project Narrative  Minimally invasive liver surgery (MILS) has many potential advantages but liver deformation leads to significant difficulties in localizing tumors and avoiding main vessels accurately. This project aims to develop a novel surgical navigation approach as a tool to guide MILS intraoperatively. Novel computer vision and machine learning algorithms, including GPU-based non-rigid simultaneously localization and mapping (SLAM), learning- based landmarks recognition and non-rigid registration will be developed to compensate for live deformation and map preoperative data to the patient’s anatomy in real-time during MILS.",Real-time Non-Rigid 3D Reconstruction and Registration for Laparoscopic-guided Minimally Invasive Liver Surgery,9822028,K99EB027177,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Applications Grants', 'Area', 'Award', 'Basic Science', 'Binocular Vision', 'Blood', 'Carbon Dioxide', 'Clinical', 'Clinical Research', 'Color', 'Computer Vision Systems', 'Computer software', 'Data', 'Dependence', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Environment', 'Excision', 'Family suidae', 'Feedback', 'Funding', 'Goals', 'Healthcare', 'Hemorrhage', 'Hepatic', 'Hospitals', 'Image', 'Imagery', 'International', 'Knowledge', 'Laboratories', 'Laparoscopes', 'Laparoscopy', 'Learning', 'Liver', 'Liver neoplasms', 'Location', 'Machine Learning', 'Malignant neoplasm of liver', 'Maps', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Motion', 'Multimodal Imaging', 'Navigation System', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Phase', 'Pneumoperitoneum', 'Postdoctoral Fellow', 'Procedures', 'Psyche structure', 'Recovery', 'Research', 'Research Personnel', 'Research Support', 'Respiration', 'Robotics', 'Solid', 'Stress', 'Structure', 'Supervision', 'Surface', 'Surgeon', 'Surgical Instruments', 'System', 'Technology', 'Texture', 'Time', 'Tissues', 'Titan', 'Training', 'Training and Education', 'Translational Research', 'Trauma patient', 'Ultrasonography', 'Uncertainty', 'United States National Institutes of Health', 'Woman', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'career', 'career development', 'catalyst', 'deep learning', 'design', 'disorder prevention', 'experience', 'frontier', 'haptics', 'human disease', 'image guided', 'image guided therapy', 'image processing', 'image registration', 'improved', 'in vivo', 'learning strategy', 'machine learning algorithm', 'medical schools', 'minimally invasive', 'novel', 'postoperative recovery', 'professor', 'programs', 'prototype', 'radiologist', 'reconstruction', 'research and development', 'research clinical testing', 'symposium', 'technology development', 'tissue reconstruction', 'tool', 'tumor', 'uptake', 'virtual']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,K99,2019,93280,-0.03501927974422041
"Development of Machine Learning Algorithms to Assess and Train Vesico-Urethral Anastomosis during Robot Assisted Radical Prostatectomy PROJECT SUMMARY/ABSTRACT CANDIDATE (Andrew J. Hung, MD): My long-term goal is to establish a career in innovating training methods for robotic surgery which will lead to curtailing surgeon learning curve, and maximize patient safety. My first step towards that goal focuses on understanding objective metrics that measure surgeon performance, and how machine learning algorithms can process that data to guide training. I have developed a career development program that builds on my clinical training in robotic urologic surgery and prior research in surgical training. Through mentorship, a fellowship, and formal coursework, this K23 award will provide me the necessary support to develop expertise in 3 areas where I do not have formal training, yet are critical to my success: (1) Machine learning; (2) Surgical education; (3) Advanced statistical skills and study design. MENTORING TEAM: My career development and research plans leverage existing institutional resources, including the USC Machine Learning Center, led by co-primary mentor Dr. Yan Liu; and Keck Hospital of USC, the second busiest robotic center by volume in the United States and the USC Institute of Urology (led by co- primary mentor and chairman Dr. Inderbir Gill), home to pioneers of several urologic surgical techniques with a robust research apparatus supporting several NIH-funded clinical scientists. My mentoring team is complemented by co-mentor Dr. Robert Sweet, a DOD-funded expert on surgical education; career mentor Dr. Larissa Rodriguez, a federally funded clinician/scientist experienced in mentoring K awardees; educational psychology collaborator Dr. Kenneth Yates, an authority on cognitive task analysis; and consultant Dr. Anthony Jarc, at Intuitive Surgical who has supported much of the pilot data on objective performance metrics. The proposed K23 work truly requires the robust collaboration of experts in robotic surgery, education, and machine learning. RESEARCH: The learning curve for surgeons performing robot assisted radical prostatectomy (RARP) is steep: over 100 cases. Current ‘gold standard’ methods of surgical assessment rely on subjective expert review, but such evaluations are time consuming and inconsistent. Nonetheless, credentialing a surgeon to perform robotic surgery has enormous implications - patient outcomes are at risk, and a surgeon’s career is on the line. Informed by my clinical expertise in robotic urological surgery and preliminary data, I will develop a novel method of utilizing machine learning (ML) algorithms to objectively assess robotic surgeon performance and to guide training for the vesico-urethral anastomosis (VUA), the most critical reconstructive part of the robot-assisted radical prostatectomy (RARP). I will develop and validate objective metrics directly captured from the da Vinci robot during the VUA (Aim 1), train machine learning algorithms to assess a surgeon’s performance of VUA (Aim 2), and utilize ML algorithms to guide surgeons learning the VUA (Aim 3). Armed with these data and skills from this award, I will be uniquely suited to utilize machine learning to generalize objective surgeon assessment for robot-assisted surgical procedures within and beyond urology. Finally, the results from this study will provide preliminary data for independent funding through mechanisms such as an NIH R01 grant. PROJECT NARRATIVE The learning curve for surgeons performing robot assisted radical prostatectomy (RARP) for prostate cancer is steep, and current methods of evaluating surgeons require subjective and time-consuming expert review. Streamlined training and assessment utilizing objective performance metrics and machine learning algorithms can significantly curtail learning curve with patients, and decrease the overall morbidity of prostate cancer treatment.",Development of Machine Learning Algorithms to Assess and Train Vesico-Urethral Anastomosis during Robot Assisted Radical Prostatectomy,9767765,K23EB026493,"['Address', 'Adopted', 'Affect', 'Anastomosis - action', 'Area', 'Artificial Intelligence', 'Award', 'Chairperson', 'Characteristics', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Consumption', 'Credentialing', 'Data', 'Data Analyses', 'Development', 'Education', 'Educational Intervention', 'Educational Psychology', 'Evaluation', 'Event', 'Fellowship', 'Foundations', 'Funding', 'Future', 'Gills', 'Goals', 'Gold', 'Grant', 'Hand', 'Home environment', 'Hospitals', 'Individual', 'Institutes', 'Intervention', 'Intuition', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Medical Research', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Meta-Analysis', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Positioning Attribute', 'Procedures', 'Process', 'Program Development', 'Prostate Cancer therapy', 'Radical Prostatectomy', 'Research', 'Research Design', 'Resources', 'Risk', 'Robot', 'Robotics', 'Scientist', 'Specialist', 'Surgeon', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Urethra', 'Urologic Surgical Procedures', 'Urology', 'Work', 'authority', 'base', 'burden of illness', 'career', 'career development', 'clinically significant', 'cognitive task', 'common treatment', 'computer program', 'data reduction', 'experience', 'feeding', 'functional outcomes', 'improved', 'innovation', 'kinematics', 'machine learning algorithm', 'male', 'novel', 'patient safety', 'peer', 'reconstruction', 'research and development', 'robot assistance', 'simulation', 'skills', 'success', 'task analysis', 'urologic', 'virtual reality']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,K23,2019,193082,-0.013137163459120709
"Deep Learning to Transform Clinician Autism Diagnostic Assessments and More NODA Telehealth system improves access to an autism diagnostic assessment by guiding families to share video clips of their child at home, so diagnostic clinicians can directly observe and ‘tag’ video of any atypical behavior, and if warranted, render a diagnosis. This system is evidence-based and has been commercialized, with several published studies to discuss the benefits. We now propose to improve this service by developing a Deep (machine) Learning capability in a software product called ‘NODA DL Classifier’ to help clinicians more quickly identify and better quantify typical and atypical behaviors on videos they receive from families. If successful, this NODA DL feature within the NODA system will have a profound impact in the time to reach a firm diagnosis, and then the capability could be used subsequently to effectively monitor treatment progress of individuals diagnosed with autism. In this project, we will determine how much DL improves the diagnostic process. In Phase I, we will test our use previously generated datasets to qualify and quantify potential benefits. In Phase II, we will conduct a clinical study to document time-savings and other clinical benefits. Our proposed NODA DL innovation represents a large step change in identification and then the care for ASD individuals, not an incremental one. It will lead to a significant improvement in both health outcomes and in reduced time required by clinicians or psychologists for office visits and for analyzing video data. This reduced time can be translated into reduced costs. We anticipate that significant commercial benefits will result from the use of our innovative computer methodologies. The proposed computerized Deep Learning (DL) function within our current NODA Telehealth System will have a profound impact in saving time to reach a firm diagnosis of individuals with ASD, plus provide other important benefits.",Deep Learning to Transform Clinician Autism Diagnostic Assessments and More,9742525,R44MH115523,"['Address', 'Applications Grants', 'Behavior', 'Behavioral', 'Caring', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Clip', 'Computer Assisted', 'Computer software', 'Computers', 'Current Procedural Terminology Codes', 'DSM-V', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Environment', 'Family', 'Health', 'Health Professional', 'Home environment', 'Image', 'Improve Access', 'Individual', 'Industry', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Measures', 'Medicaid', 'Methodology', 'Modification', 'Monitor', 'Neurodevelopmental Disorder', 'Office Visits', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Privatization', 'Procedures', 'Process', 'Psychologist', 'Publishing', 'Recommendation', 'Savings', 'Services', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Translating', 'Work', 'autism spectrum disorder', 'base', 'behavioral construct', 'clinically relevant', 'computerized', 'cost', 'deep learning', 'evidence base', 'human study', 'improved', 'innovation', 'prototype', 'satisfaction', 'telehealth', 'telehealth systems', 'user-friendly']",NIMH,"CARING TECHNOLOGIES, INC.",R44,2019,491792,-0.07164773604175238
"Deep Learning to Transform Clinician Autism Diagnostic Assessments and More NODA Telehealth system improves access to an autism diagnostic assessment by guiding families to share video clips of their child at home, so diagnostic clinicians can directly observe and ‘tag’ video of any atypical behavior, and if warranted, render a diagnosis. This system is evidence-based and has been commercialized, with several published studies to discuss the benefits. We now propose to improve this service by developing a Deep (machine) Learning capability in a software product called ‘NODA DL Classifier’ to help clinicians more quickly identify and better quantify typical and atypical behaviors on videos they receive from families. If successful, this NODA DL feature within the NODA system will have a profound impact in the time to reach a firm diagnosis, and then the capability could be used subsequently to effectively monitor treatment progress of individuals diagnosed with autism. In this project, we will determine how much DL improves the diagnostic process. In Phase I, we will test our use previously generated datasets to qualify and quantify potential benefits. In Phase II, we will conduct a clinical study to document time-savings and other clinical benefits. Our proposed NODA DL innovation represents a large step change in identification and then the care for ASD individuals, not an incremental one. It will lead to a significant improvement in both health outcomes and in reduced time required by clinicians or psychologists for office visits and for analyzing video data. This reduced time can be translated into reduced costs. We anticipate that significant commercial benefits will result from the use of our innovative computer methodologies. The proposed computerized Deep Learning (DL) function within our current NODA Telehealth System will have a profound impact in saving time to reach a firm diagnosis of individuals with ASD, plus provide other important benefits.",Deep Learning to Transform Clinician Autism Diagnostic Assessments and More,9840810,R44MH115523,"['Address', 'Applications Grants', 'Behavior', 'Behavioral', 'Caring', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Clip', 'Computer Assisted', 'Computer software', 'Computers', 'Current Procedural Terminology Codes', 'DSM-V', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Environment', 'Family', 'Health', 'Health Professional', 'Home environment', 'Image', 'Improve Access', 'Individual', 'Industry', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Measures', 'Medicaid', 'Methodology', 'Modification', 'Monitor', 'Neurodevelopmental Disorder', 'Office Visits', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Privatization', 'Procedures', 'Process', 'Psychologist', 'Publishing', 'Recommendation', 'Savings', 'Services', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Translating', 'Work', 'autism spectrum disorder', 'base', 'behavioral construct', 'clinically relevant', 'computerized', 'cost', 'deep learning', 'evidence base', 'human study', 'improved', 'innovation', 'prototype', 'satisfaction', 'telehealth', 'telehealth systems', 'user-friendly']",NIMH,"CARING TECHNOLOGIES, INC.",R44,2019,107870,-0.07164773604175238
"Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches Project Summary The form (or shape) and function relationship of anatomical structures is a central theme in biology where abnor- mal shape changes are closely tied to pathological functions. Morphometrics has been an indispensable quan- titative tool in medical and biological sciences to study anatomical forms for more than 100 years. Recently, the increased availability of high-resolution in-vivo images of anatomy has led to the development of a new generation of morphometric approaches, called statistical shape modeling (SSM), that take advantage of modern computa- tional techniques to model anatomical shapes and their variability within populations with unprecedented detail. SSM stands to revolutionize morphometric analysis, but its widespread adoption is hindered by a number of sig- niﬁcant challenges, including the complexity of the approaches and their increased computational requirements, relative to traditional morphometrics. Arguably, however, the most important roadblock to more widespread adop- tion is the lack of user-friendly and scalable software tools for a variety of anatomical surfaces that can be readily incorporated into biomedical research labs. The goal of this proposal is thus to address these challenges in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM), which automat- ically constructs optimal statistical landmark-based shape models of ensembles of anatomical shapes without relying on any speciﬁc surface parameterization. The proposed research will provide an automated, general- purpose, and scalable computational solution for constructing shape models of general anatomy. In Aim 1, we will build computational and machine learning algorithms to model anatomies with complex surface topologies (e.g., surface openings and shared boundaries) and highly variable anatomical populations. In Aim 2, we will introduce an end-to-end machine learning approach to extract statistical shape representation directly from im- ages, requiring no parameter tuning, image pre-processing, or user assistance. In Aim 3, we will provide intuitive graphical user interfaces and visualization tools to incorporate user-deﬁned modeling preferences and promote the visual interpretation of shape models. We will also make use of recent advances in cloud computing to enable researchers with limited computational resources and/or large cohorts to build and execute custom SSM work- ﬂows using remote scalable computational resources. Algorithmic developments will be thoroughly evaluated and validated using existing, fully funded, large-scale, and constantly growing databases of CT and MRI images lo- cated on-site. Furthermore, we will develop and disseminate standard workﬂows and domain-speciﬁc use cases for complex anatomies to promote reproducibility. Efforts to develop the proposed technology are aligned with the mission of the National Institute of General Medical Sciences (NIGMS), and its third strategic goal: to bridge biology and quantitative science for better global health through supporting the development of and access to computational research tools for biomedical research. Our long-term goal is to increase the clinical utility and widespread adoption of SSM, and the proposed research will establish the groundwork for achieving this goal. Project Narrative This project will develop general-purpose, scalable, and open-source statistical shape modeling (SSM) tools, which will present unique capabilities for automated anatomy modeling with less user input. The proposed tech- nology will introduce a number of signiﬁcant improvements to current SSM approaches and tools, including the support for challenging modeling problems, inferring shapes directly from images (and hence bypassing the seg- mentation step), parallel optimizations for speed, and new user interfaces that will be much easier and scalable than the current tools. The proposed technology will constitute an indispensable resource for the biomedical and clinical communities that will enable new avenues for biomedical research and clinical investigations, provide new ways to answer biologically related questions, allow new types of questions to be asked, and open the door for the integration of SSM with clinical care.","Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches",9803774,R01AR076120,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomic Surface', 'Anatomy', 'Area', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Brain', 'Bypass', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Collection', 'Communities', 'Complex', 'Complex Analysis', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Felis catus', 'Funding', 'Generations', 'Geometry', 'Goals', 'Human', 'Ice', 'Image', 'Imagery', 'Injury', 'Intuition', 'Laboratory Research', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematical Computing', 'Measures', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Modernization', 'Modification', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Occupations', 'Online Systems', 'Organism', 'Orthopedics', 'Pathologic', 'Population', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Shapes', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Speed', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Variant', 'Visual', 'Visualization software', 'Work', 'base', 'biomedical resource', 'clinical care', 'clinical investigation', 'clinically relevant', 'cohort', 'computerized tools', 'computing resources', 'deep learning', 'experience', 'flexibility', 'global health', 'graphical user interface', 'image archival system', 'image processing', 'imaging Segmentation', 'in vivo imaging', 'innovation', 'machine learning algorithm', 'model development', 'multidisciplinary', 'open source', 'particle', 'preference', 'software development', 'tool', 'usability', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2019,631809,-0.02580105990898986
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,9927093,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Comorbidity', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2019,253545,-0.021915205537083312
"Multiscale ab initio QM/MM and machine learning methods for accelerated free energy simulations Q-Chem is a state-of-the-art commercial computational quantum chemistry program that has aided about 60,000 users in their modeling of molecular processes in a wide range of disciplines, including biology, chemistry, and materials science. In this proposal, we seek to significantly reduce the computational time (now around 500,000 CPU hours) required to obtain accurate free energy profiles of enzymatic reactions. Specifically, we propose to use a multiple time step (MTS) simulation method, where a low-level (and less accurate) quantum chemistry method is used to propagate the system (i.e. move all atoms) at each time step (usually 0.5 or 1 fs), and then a high-level (i.e. more accurate and expensive) quantum chemistry method is used to correct the force on the atoms at longer time intervals. In this way, the simulation can be performed at the high-level energy surface in a fraction of time, compared with simulations performed only using the high-level quantum chemical method. In the Phase I proposal, our goal is to allow the high-level force update only once every 40—50 fs by identifying appropriate lower-level theories (Aim 1) and incorporating machine-learning techniques (Aim 2). This will accelerate accurate free energy simulations by 20—25 fold, reducing the overall computer time to around 25,000 CPU hours. Thus, our new MTS simulation method will make it feasible to routinely perform computational studies on enzymatic reaction mechanism. The addition of these new tools will also further strengthen Q-Chem's position as a global leader in the molecular modeling software market, making our program the most efficient and reliable computational quantum chemistry package for simulating large, complex chemical/biological systems. In this project, we seek to significantly reduce the computational time (ca. 500,000 CPU hours) required to obtain accurate free energy profiles of enzymatic reactions to ca. 25,000 CPU Hours. Building upon sophisticated quantum mechanics, this can lead to reliable and quick predictions of enzyme activities.",Multiscale ab initio QM/MM and machine learning methods for accelerated free energy simulations,9778517,R43GM133270,"['Acceleration', 'Accounting', 'Adopted', 'Back', 'Biochemical', 'Biochemical Reaction', 'Biology', 'Biomedical Research', 'Chemicals', 'Chemistry', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Computers', 'Development', 'Discipline', 'Enzymes', 'Foundations', 'Free Energy', 'Goals', 'Hour', 'Hybrids', 'Lead', 'Machine Learning', 'Maps', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Pathway interactions', 'Performance', 'Phase', 'Positioning Attribute', 'Potential Energy', 'Process', 'Protein Conformation', 'Proteins', 'Quantum Mechanics', 'Reaction', 'Recipe', 'Research', 'Research Personnel', 'Sampling', 'Scheme', 'Solvents', 'Surface', 'System', 'Techniques', 'Time', 'Update', 'biological systems', 'computer studies', 'cost', 'density', 'enzyme activity', 'enzyme model', 'improved', 'innovation', 'learning strategy', 'materials science', 'molecular mechanics', 'molecular modeling', 'programs', 'quantum', 'quantum chemistry', 'quantum computing', 'simulation', 'theories', 'time interval', 'tool']",NIGMS,"Q-CHEM, INC.",R43,2019,132011,-0.019548564521068387
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9806367,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2019,184118,-0.022110119221933927
"A Clinical Trial Enrichment Tool Based on Subgroups Defined by Machine Learning Predictive Models ABSTRACT Neurodegenerative disorders, including amyotrophic lateral sclerosis (ALS), Friedreich's ataxia (FA), multiple sclerosis (MS), Duchenne muscular dystrophy (DMD), Alzheimer’s disease (AD), Parkinson’s disease (PD), and Huntington’s disease (HD) are characterized by heterogeneous disease progression. Efforts to identify responder subgroups may uncover subgroups that are more homogeneous in disease-related features than the full study population. As a result, a subgroup may exhibit a statistically significant effect size. However, current methodologies for subgroup analysis are limited by the relatively small number of prognostic and predictive indicators that can be used to describe subgroups. These methods are not well suited to describing subgroups with reduced heterogeneity in disease progression, or in identifying indicators for multifactorial diseases. We have developed and submitted a patent application for a novel subgroup analysis method based on grouping participants with similar predicted disease progression profiles and analyzing nearest neighbor subgroups within a clinical trial. We call this method Detectable Effect Cluster(DEC) analysis. In our phase 1 and phase 2 SBIR grants, we used ALS as a model disease to develop our API product that uses machine learning disease models to improve trial arm randomization and provide covariates for statistical analysis. In the ongoing phase 2 grant we are expanding our disease offerings to include AD. PD and HD. Building on a set of ALS disease progression models that we have previously developed and validated, we seek in this grant application to develop a novel prototype machine-learning based subgroup analysis application that we plan on adding to our product offerings. During this proposed phase 1 grant, we will address research-level questions regarding the nature of the subgroups defined using DEC analysis including how to define confidence intervals of our DEC-clusters, and estimated bounds for using prediction-thresholds as selection criteria for a confirmatory clinical trial. Finally, we will apply DEC analysis to three publicly-available clinical trial data sets in an attempt to identify subgroups with significant treatment effects. Aim 1: We will apply methods used in image analysis for identifying statistically significant subgroups to address the  multiplicity issue inherent in DEC Analysis. Aim 2: We will use statistical methods to model the confidence intervals of a power analysis in which DEC cluster  based selection criteria would be used for a confirmatory trial. Aim 3: We will isolate records from PRO-ACT that include whether a patient was treated with riluzole and two other  publicly available recent ALS datasets to test the application of DEC Analysis. Origent’s current suite of products will answer drug development needs of a full portfolio of neurodegenerative diseases. Ultimately, we see a series of machine learning applications aimed at solving drug development issues for multiple disease areas, including orphan diseases. These models and applications will vastly increase the speed and efficiency of drug development, resulting in faster, cheaper, more efficient drug trials that yield numerous new medications to ease human pain and suffering. NARRATIVE This work will develop Detectable Effect Cluster (DEC) analysis, a novel machine-learning based method of subgroup analysis. DEC analysis shows great promise in identifying patient subgroups with statistically significant drug effects within larger, more heterogeneous, failed therapeutic clinical trials. DEC analysis has the potential to rescue a drug that otherwise would have been discarded as a drug that does not provide therapeutic benefit, when, in fact, the opposite is true.",A Clinical Trial Enrichment Tool Based on Subgroups Defined by Machine Learning Predictive Models,9846759,R43MH122925,"['Address', 'Alzheimer&apos', 's Disease', 'Amyotrophic Lateral Sclerosis', 'Applications Grants', 'Area', 'Autoimmune Diseases', 'Cardiology', 'Clinical', 'Clinical Drug Development', 'Clinical Trials', 'Cluster Analysis', 'Communicable Diseases', 'Confidence Intervals', 'Data', 'Data Set', 'Disease', 'Disease Progression', 'Disease model', 'Drug Industry', 'Duchenne muscular dystrophy', 'Exhibits', 'Friedreich Ataxia', 'Grant', 'Grouping', 'Health', 'Heterogeneity', 'Hot Spot', 'Human', 'Huntington Disease', 'Image Analysis', 'Legal patent', 'Letters', 'Lung diseases', 'Machine Learning', 'Maps', 'Metabolic Diseases', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'Nature', 'Neurodegenerative Disorders', 'Neurologic', 'Non-linear Models', 'Pain', 'Parkinson Disease', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Plant Roots', 'Prognostic Marker', 'Randomized', 'Rare Diseases', 'Records', 'Research', 'Riluzole', 'Risk', 'Scientist', 'Secondary to', 'Selection Criteria', 'Series', 'Small Business Innovation Research Grant', 'Speed', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Clinical Trial', 'Training', 'Work', 'arm', 'base', 'cohort', 'drug development', 'drug testing', 'experience', 'improved', 'interest', 'nervous system disorder', 'novel', 'off-patent', 'oncology', 'patient subsets', 'power analysis', 'predictive modeling', 'prognostic', 'prototype', 'research and development', 'response', 'study population', 'systems research', 'tool', 'treatment effect']",NIMH,"ORIGENT DATA SCIENCES, INC.",R43,2019,222907,-0.05022135670214287
"Development of label-free computational flow cytometry for high-throughput micro-organism classification The purpose of flow cytometers is to enable the classification of cells or organisms at high throughput. Label-free optical flow cytometers not based on fluorescence are generally based on scattering. The most common of these compares the amount of forward (FS) versus side (SS) scattering. Such two-parameter information permits rudimentary classification based on size or granularity, but it misses more subtle features that can be critical in defining organism identity. Nevertheless, FS/SS flow cytometry remains popular, largely because of its simplicity and capacity for high throughput.  We propose to develop a label-free computational flow cytometer that preserves much of the simplicity and high-throughput capacity of FS/SS flow cytometry, but provides significantly enhanced information. Instead of characterizing organisms based on scattering direction (as does FS/SS flow cytometry), we will characterize based on scattering patterns. We will insert a reconfigurable diffractive element in the imaging optics of a flow cytometer to route user-defined basis patterns to independent detectors. The basis patterns will be optimally matched to specific sample features. The respective weights of these basis patterns will serve as signatures to identify organisms of interest. The basis patterns themselves will be determined by machine learning algorithms. Both the device and the learning algorithms will be developed from scratch.  We anticipate that our flow cytometer will be able to operate at flow rates on the order of meters per second, commensurate with state-of-the-art FS/SS flow cytometers, while providing significantly more information for improved classification capacity. While our technique should be advantageous for any label-free flow cytometry application requiring high throughput, we will test it here by demonstrating high-throughput classification of microbial communities. NARRATIVE Our goal is to improve the information extraction capacity of label-free flow cytometers, while maintaining high throughput capacity. As such, our device should have a broad range of applications.",Development of label-free computational flow cytometry for high-throughput micro-organism classification,9702053,R21GM128020,"['Address', 'Awareness', 'Bioinformatics', 'Biological', 'Biology', 'Categories', 'Cells', 'Classification', 'Communities', 'Custom', 'Detection', 'Development', 'Devices', 'Elements', 'Flow Cytometry', 'Fluorescence', 'Goals', 'Image', 'Image Compression', 'Label', 'Light', 'Machine Learning', 'Measurement', 'Microbe', 'Modernization', 'Optics', 'Organism', 'Pattern', 'Performance', 'Pupil', 'Resolution', 'Route', 'Sampling', 'Side', 'Signal Transduction', 'Specificity', 'Speed', 'Techniques', 'Testing', 'Traction', 'Validation', 'Weight', 'base', 'cellular imaging', 'cost', 'cost effective', 'design', 'detector', 'improved', 'interest', 'learning algorithm', 'machine learning algorithm', 'meter', 'microbial community', 'microorganism', 'microorganism classification', 'optical imaging', 'preservation', 'prototype', 'recruit']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2019,206250,-0.006478136599454918
"Automatic Thoracic Organ Segmentation Tool for Radiation Treatment Planning of Cancers in Thoracic Region ABSTRACT As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. Cancers in the thoracic region, which include lung, esophageal, thymus, mesothelioma and breast cancers, are among the most pervasive and deadly cancers. The protection of normal thoracic organs including lungs, heart, esophagus and spinal cord is critical in reducing long term toxicity in such cancers. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans during radiation treatment planning to get an accurate dosage distribution. Despite tremendous effort into the development of semi- or fully-automatic segmentation solutions, current automated segmentation software, mostly using the atlas-based methods, has not yet reached the level of accuracy and robustness required for clinical usage. Therefore, in current practice, significant manual efforts are still required in the OAR segmentation process. Manual contouring suffers from inter- and intra-observer variability as well as institutional variability where different sites adopt distinct contouring atlases and labeling criteria and thus leads to inaccuracy and variability in OAR segmentation. When OARs are very close to the treatment target, segmentation errors as small as a few millimeters can have a statistically significant impact on dosimetry distribution and outcome. In addition, it is also costly and time consuming as it can take 1-2 hours of a clinicians’ time to segment major thoracic organs due to the large number of axial slices required. The associated human efforts would significantly increase if adaptive radiation therapy (ART) is used as OARs from two or more simulation CT scans need to be segmented to adjust treatment plans. In recent years, the rapid development of deep learning methods has revolutionized many computer-vision areas and the adoption of deep learning in medical applications has shown great success. Based on a deep-learning-based algorithm we developed that achieved better-than-human performance and ranked 1st in 2017 American Association of Physicist in Medicine Thoracic Auto-segmentation Challenge, a thoracic OAR auto-segmentation product will be developed in this project with the two aims: 1) improve and validate the deep-learning-based automatic thoracic organ segmentation algorithm on a larger clinical data set, and 2) incorporate this algorithm into a preliminary product that fits into the clinical workflow. With this product, the segmentation accuracy can be improved, leading to more robust treatment plans in protecting normal organs and improved long term patient outcome. Furthermore, the time and cost of radiation treatment planning can be greatly reduced, contributing to a more affordable cancer treatment and reduced healthcare burden. NARRATIVE As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans. A deep-learning-based thoracic OAR auto-segmentation product developed in this project can improve the segmentation accuracy and reduce the time and cost of radiation treatment planning as compared with the current manual process, leading to improved long term patient outcome and reduced cancer treatment cost.",Automatic Thoracic Organ Segmentation Tool for Radiation Treatment Planning of Cancers in Thoracic Region,9776272,R43EB027523,"['3-Dimensional', 'Adopted', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Area', 'Atlases', 'Attention', 'Cancer Center', 'Cancer Patient', 'Chest', 'Client', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Early Diagnosis', 'Environment', 'Esophageal', 'Esophagus', 'Goals', 'Healthcare', 'Heart', 'Hour', 'Human', 'Image', 'Intraobserver Variability', 'Kentucky', 'Label', 'Lung', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medicine', 'Mesothelioma', 'Methods', 'Modeling', 'Organ', 'Outcome', 'Pathologic', 'Patient-Focused Outcomes', 'Performance', 'Phase', 'Privatization', 'Process', 'Protocols documentation', 'Radiation Dose Unit', 'Radiation therapy', 'Risk', 'Scanning', 'Site', 'Slice', 'Spinal Cord', 'Structure', 'Survival Rate', 'Testing', 'Thymus Gland', 'Time', 'Toxic effect', 'Training', 'Treatment Cost', 'Universities', 'Validation', 'X-Ray Computed Tomography', 'base', 'cancer radiation therapy', 'cancer therapy', 'clinically relevant', 'convolutional neural network', 'cost', 'deep learning', 'dosage', 'dosimetry', 'improved', 'learning strategy', 'malignant breast neoplasm', 'millimeter', 'novel', 'prototype', 'satisfaction', 'simulation', 'success', 'tool', 'treatment planning']",NIBIB,"CARINA MEDICAL, LLC",R43,2019,299288,-0.04100863680680585
"Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study PROJECT SUMMARY The built environment is an important modifiable determinant of human health, yet our ability to understand its effects on human health have been limited by the lack of scalable data on specific components (and exposures) of the built environment. The emergence of ubiquitous geo-referenced imagery in the United States (e.g. Google Street View Imagery), combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring street-level built environment features at scales needed for population-based research. To develop and demonstrate the potential of deep learning algorithms for environmental health research we will: develop methods to assess green space features using street view imagery and deep learning algorithms; create new deep learning algorithms to predict urban green space quality, stress reduction and restorative potential; and apply new street view measures to 9,070 adult Twin Pairs in the Washington Twin Registry to determine associations between green space and mental health. Our proposed study will dramatically move the field of environmental health forward by provided a completely new, transferable and scalable exposure assessment method for assessing built environment exposures relevant to human health and provide robust information on how urban green space influences mental health. Overall, our new approach will provide rich new data sources for environmental epidemiologists, city planners, policy makers and neighborhoods and communities at large. PROJECT NARRATIVE The built environment is an important determinant of human health, yet our ability to measure specific components of the built environment relevant to health is limited. The availability of street view imagery, combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring detailed built environment features at scales needed for population-based research. Here we develop such approaches for green space and evaluate associations with mental health using a unique Twin analysis.",Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study,9824066,R21ES029722,"['Adult', 'Algorithms', 'Anxiety', 'Attention', 'Baseline Surveys', 'Biological', 'Buffers', 'Case Study', 'Cities', 'Communities', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Databases', 'Dizygotic Twins', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Epidemiologist', 'Esthetics', 'Flowers', 'Genetic', 'Green space', 'Health', 'Human', 'Image', 'Imagery', 'Link', 'Measures', 'Mechanics', 'Mental Depression', 'Mental Health', 'Mental Health Associations', 'Methods', 'Monozygotic twins', 'Nature', 'Neighborhoods', 'Neurocognitive', 'Outcome Measure', 'Pathway interactions', 'Perception', 'Plants', 'Poaceae', 'Policy Maker', 'Population Research', 'Psychological Transfer', 'Registries', 'Research', 'Rest', 'Sampling', 'Stress', 'Surveys', 'Training', 'Trees', 'Twin Multiple Birth', 'Twin Studies', 'United States', 'Washington', 'base', 'biological adaptation to stress', 'built environment', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'directed attention', 'distraction', 'early life exposure', 'experimental study', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'learning strategy', 'longitudinal analysis', 'novel', 'novel strategies', 'response', 'restoration', 'stress reduction', 'theories']",NIEHS,OREGON STATE UNIVERSITY,R21,2019,221376,-0.01791087370686608
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user's location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user's location by recognizing standard informational signs present in the environment, tracking the user's trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9934891,R01EY029033,"['Adoption', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Environment', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Medical center', 'Process', 'Research', 'Schools', 'System', 'Tactile', 'Time', 'Travel', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'interest', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,105337,-0.006694477636391068
"NIDDK Extramural Digital Pathology Repository System In recent years, new technology and data processing capabilities have removed barriers to integration of molecular and histopathological data sets. Several clinical research networks across the National Institute of Diabetes, Digestive and Kidney Diseases extramural programs have put Digital Pathology Repositories (DPRs) into place with digital whole slide images (WSI) available to support standardization of classical diagnostic criteria across clinical sites. A developing line of investigation is the “mining” of these digital sets to identify features which correlate with disease. Computer assisted-image analysis for feature detection and feature recognition are key components of such investigation. The Centralized NIDDK Digital Pathology Repository will serve as an online repository to facilitate standardized archiving of WSI with the goal of providing controlled access for standardization, discovery and validation research efforts. n/a",NIDDK Extramural Digital Pathology Repository System,10032690,5N94019F00322,"['Archives', 'Artificial Intelligence', 'Clinical', 'Clinical Research', 'Computer-Assisted Image Analysis', 'Data Set', 'Diabetes Mellitus', 'Diagnostic', 'Digestive System Disorders', 'Disease', 'Extramural Activities', 'Future', 'Goals', 'Institutes', 'Investigation', 'Kidney Diseases', 'Machine Learning', 'Metadata', 'Mining', 'Molecular', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Research', 'Standardization', 'System', 'Validation', 'clinical research site', 'computerized data processing', 'digital', 'digital pathology', 'feature detection', 'new technology', 'online repository', 'programs', 'repository', 'whole slide imaging']",NICHD, ,N02,2019,95738,-0.02182813500243637
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9663319,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,416374,-0.0062000952965249895
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,9859232,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Dimensions', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'One-Step dentin bonding system', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2019,345016,-0.005491284838194706
"Prospective Health Outcomes and Inflammatory Biomarkers Associated with e-Cigarette Use Project Summary. This project is designed to identify validated biomarkers for use in the assessment of electronic nicotine delivery systems (ENDS) by the FDA. Since the introduction of ENDS, commonly referred to as e-cigarettes, there has been a large increase in ENDS use among young adults and older traditional cigarette smokers who also use ENDS (dual users). Since 2016, the Food and Drug Administration (FDA) has had regulatory authority over ENDS, and there is an acute need for ENDS-related biomarkers that can be used as validated surrogate endpoints for evaluation of new ENDS products. With the goal of validated biomarker discovery in two independent cohorts, the COPDGene and UCSD ENDS studies, we propose to identify ENDS-related inflammatory biomarkers in ENDS only and dual users and relate these biomarkers to five-year lung health outcomes. COPDGene is an ongoing, longitudinal study of >6,000 current and former traditional cigarette (t-cig) smokers enriched for chronic obstructive pulmonary disease (COPD) with detailed longitudinal lung phenotyping data (including chest CT), genome-wide blood RNA-seq, and proteomic data. The UCSD ENDS Study is a controlled study of young ENDS only users and controls with detailed assessment of inflammatory biomarkers in the oropharynx, airways and blood.  Biomarkers used as validated surrogate measures must be 1) associated with ENDS use, 2) predictive of health outcomes, and 3) have a strong biological rationale. We hypothesize that inflammatory biomarkers of ENDS use will be predictive of five-year lung health effects. In Aim 1 of this proposal, discovery of inflammatory transcriptomic and proteomic biomarkers of ENDS exposure will be performed in subjects from the COPDGene five-year study visit, and biomarkers will be validated in two independent sets of subjects from the COPDGene ten-year visit and the UCSD ENDS Study. In Aim 2 we will identify antibody-specific adaptive immune response biomarkers of ENDS exposure using adaptive immune receptor repertoire sequencing (AIRR-seq). Auto-antibodies are biomarkers that are associated with the degree of lung damage in COPD. AIRR-seq is a powerful tool for inflammatory biomarker discovery that characterizes an individual’s decades-long history of antibody responses. In Aim 3 we will use machine learning predictive models to relate ENDS-associated biomarker panels to five-year lung health outcomes from COPDGene. The investigative team for this grant is well-positioned to identify novel inflammatory biomarkers of ENDS use. The COPDGene and UCSD cohorts have the detailed lung phenotyping and molecular characterization necessary to discover and clinically validate biomarkers in two important populations of ENDS users, i.e. ENDS only and dual users. Public Health Relevance: Since the introduction of electronic nicotine delivery systems (ENDS), commonly referred to as e-cigarettes, there has been a large increase in ENDS use among young adults and older traditional cigarette smokers who also use ENDS (dual users). Since 2016, the Food and Drug Administration (FDA) has had regulatory authority over ENDS, and there is an acute need for ENDS-related biomarkers that can be used as validated surrogate endpoints for evaluation of new ENDS products. Using two studies of ENDS users and controls, this project is designed to identify validated biomarkers for use in the health assessment of ENDS products.",Prospective Health Outcomes and Inflammatory Biomarkers Associated with e-Cigarette Use,9871798,R01HL147326,"['Acute', 'Adaptive Immune System', 'Address', 'Antibodies', 'Antibody Response', 'Autoantibodies', 'B-Lymphocytes', 'Biological', 'Biological Markers', 'Blood', 'Cells', 'Chronic Obstructive Airway Disease', 'Cigarette', 'Cigarette Smoker', 'Clinical', 'Control Groups', 'Controlled Study', 'Data', 'Disease', 'Electronic Nicotine Delivery Systems', 'Electronic cigarette', 'Elements', 'Evaluation', 'Genomics', 'Goals', 'Grant', 'Health', 'Human', 'Immunologic Receptors', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Response', 'Link', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Measures', 'Methods', 'Molecular', 'Mouse Strains', 'Oropharyngeal', 'Outcome', 'Pattern', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Proteomics', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Questionnaires', 'Recording of previous events', 'Respiratory Signs and Symptoms', 'Smoker', 'Spirometry', 'Surrogate Endpoint', 'T cell response', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Testing', 'United States Food and Drug Administration', 'Visit', 'X-Ray Computed Tomography', 'adaptive immune response', 'authority', 'biomarker discovery', 'biomarker panel', 'candidate marker', 'chest computed tomography', 'cohort', 'design', 'electronic cigarette use', 'genome-wide', 'health assessment', 'lung injury', 'novel', 'novel strategies', 'patient population', 'phenotypic data', 'predictive modeling', 'prospective', 'public health relevance', 'random forest', 'response biomarker', 'study population', 'targeted sequencing', 'tool', 'transcriptome sequencing', 'transcriptomics', 'young adult']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2019,502599,-0.04147142432142091
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9705993,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'analysis pipeline', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2019,314000,-0.022071014994134063
"Real-time non-intrusive workload monitoring-Integration of human factors in surgery training and assessment Project Summary/Abstract (30 lines)  High physiological and cognitive workload required in de-coupled surgical work demands may have significant impact on patient outcome, surgical efficacy, and surgical performance. As novel surgical techniques, e.g., telesurgery, are developed, surgical operations will become more complex and the mental and physical demand on surgeons will likely increase, making it critical to develop remote and connected workload monitoring methods for the safe and effective surgical procedure design, testing, and training. This work will implement novel technology and machine learning analytics to quantify real-time and remote workload and test how workload feedback can impact care delivery in both in telesurgery and surgical simulation environments. Our overall hypothesis is that connected sensing technology in telesurgical procedures and simulation can improve surgical training and understanding of the impact of their workload on performance; ultimately improving patient health, surgery efficacy, and patient access (e.g., tele-mentoring) to surgical care. Two specific aims are proposed to investigate this hypothesis.  The objective of Specific Aim 1 is to develop a connected sensor system to objectively quantify workload real-time in simulated telerobotic procedures. This involves: 1) integrating non-intrusive sensors into a single system within the simulation trainer or environment, 2) training machine learning techniques to objectively distinguish workload using a simulated surgical skills tasks, and 3) validating metrics across varying levels of cognitive loads under various task difficulty with medical trainees and expert participants.  The objective of Specific Aim 2 is to determine the impact of the real-time workload feedback intervention on trainee performance times, errors, and intraoperative workload. Two tasks are proposed: 1) Explore modalities preferred by surgeons for providing real-time feedback on workload and 2) Assess impact of workload feedback on task performance and learning. Our primary hypothesis is that performance times and errors will improve when participants are provided realtime feedback on workload compared to performance with no feedback.  The expected deliverables include 1) workload monitoring technology, algorithms, and software for complementing current simulation-based training, 2) objective and automated workload metrics, 3) real-time assistive intervention tool, and 4) preliminary evidence on impact of workload monitoring on training. The technology in this proposed work will improve public health by reducing adverse events due to human factors in surgery and improve access to surgical care with intervention technology that can adaptively train surgeons and remotely assess proficiency. Project Narrative High physiological and cognitive workload required in de-coupled surgical work demands may have significant impact on patient outcome, surgical efficacy, and surgical team performance. Our overall hypothesis is that connected sensing technology, machine learning analytics, and real-time user-centered feedback on cognitive and physiological workload in telesurgical procedures and simulation can improve surgical training and understanding of the impact of their workload on performance; ultimately improving patient health, surgery efficacy, and patient access to surgical care. The technology in this proposed work will improve public health by reducing adverse events due to human factors in surgery and improve access to surgical care with intervention technology that can adaptively train surgeons and remotely assess proficiency.",Real-time non-intrusive workload monitoring-Integration of human factors in surgery training and assessment,9669763,R21EB026177,"['Accreditation', 'Adverse event', 'Algorithmic Software', 'Algorithms', 'Assessment tool', 'Attention', 'Awareness', 'Caring', 'Cognitive', 'Complement', 'Complex', 'Computer software', 'Coupled', 'Environment', 'Equipment', 'Event', 'Feedback', 'Future', 'Health', 'Human', 'Impairment', 'Improve Access', 'Intervention', 'Joints', 'Knowledge', 'Learning', 'Literature', 'Machine Learning', 'Measures', 'Medical', 'Mentors', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Plant Roots', 'Postoperative Period', 'Procedures', 'Psyche structure', 'Public Health', 'Robotics', 'Sentinel', 'Supervision', 'Surgeon', 'Surveys', 'System', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Telerobotics', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'Workload', 'base', 'care delivery', 'cognitive load', 'design', 'distraction', 'experience', 'improved', 'individualized feedback', 'innovation', 'new technology', 'novel', 'operation', 'patient safety', 'programs', 'recruit', 'robotic training', 'sensor', 'sensor technology', 'simulation', 'skills', 'skills training', 'tool', 'vigilance']",NIBIB,PURDUE UNIVERSITY,R21,2019,221595,-0.01139530096375967
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9752019,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2019,991516,-0.046335303285177806
"Detecting Middle Ear Fluid Using Smartphones PROJECT SUMMARY Otitis media is one of the most common childhood diseases in developing countries; many of its complications are preventable if middle ear fluid is detected early. We propose an accessible and accurate smartphone-based screening tool that (i) sends a soft acoustic chirp into the ear canal using the smartphone speaker, (ii) detects reflected sound from the eardrum using the smartphone microphone, and (iii) employs a machine learning model to classify these reflections and predict middle ear fluid status in realtime. Given the ubiquity of smartphones and the inaccuracy of visual otoscopy, the system we propose has the potential to be the default screening tool used in developing countries by healthcare providers and caregivers at home. PROJECT NARRATIVE Otitis media is one of the most common childhood diseases in developing countries affecting over 1.23 billion people in 2013 and can lead to complications such as hearing loss, developmental delay, meningitis, mastoiditis, and death. Many of these complications are preventable if middle ear fluid is detected early. However, the absence of an accurate and accessible method to detect middle ear fluid has led to high misdiagnosis rates. The consequence is associated hearing and speech impairment rates greater than any other pediatric condition and growing microbial resistance as a result of antibiotic over-prescription. Currently, the technique of choice for detecting middle ear fluid by primary care providers is visual otoscopy, which has a diagnostic accuracy as low as 51%. Although more accurate methods like tympanometry and pneumatic otoscopy exist, they require significant expertise and referral to a specialist. Commercial acoustic reflectometers and smartphone-mounted otoscopes require specialized hardware. Thus, there is an urgent, unmet need for an accurate, rapid and easily accessible method for resource-limited healthcare providers and caregivers to detect middle ear fluid. This project aims to demonstrate the feasibility of using the speakers and microphones on existing smartphones to detect middle ear fluid by assessing eardrum mobility. Our proposed system would operate by (i) sending a soft acoustic chirp into the ear canal using the smartphone speaker, (ii) detecting reflected sound from the eardrum using the smartphone microphone, and (iii) employing a machine learning model to classify these reflections and predict middle ear fluid status. No additional attachments would be required beyond a paper funnel, which acts as a speculum to reduce waveform variability and can be constructed with printer paper, scissors, and tape. This technique is the first software-based screening tool for middle ear fluid detection that uses off-the-shelf smartphones which does not require hardware attachments or visual interpretation. Using data from our existing preliminary clinical study we aim to develop signal processing and machine learning algorithms to optimize sensitivity and specificity. We plan to develop a bench testing technique that enables previously unsupported smartphones to to run our test and prospectively validate our optimized algorithm clinically in parallel testing with an acoustic reflectometer. Further we aim to develop a user interface and improved funnel design. These new designs will undergo usability testing in physician and parent populations. Given the ubiquity of smartphones, our app has the potential to be the default screening tool used in developing countries by healthcare providers and caregivers at home.",Detecting Middle Ear Fluid Using Smartphones,9906782,R43DC018434,"['Acoustics', 'Affect', 'Agreement', 'Algorithms', 'Antibiotics', 'Caregivers', 'Cellular Phone', 'Cessation of life', 'Childhood', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Computer software', 'Data', 'Detection', 'Developing Countries', 'Development', 'Developmental Delay Disorders', 'Diagnosis', 'Disease', 'Ear', 'Earwax', 'Environment', 'External auditory canal', 'FDA approved', 'Feedback', 'Future', 'Galaxy', 'Health', 'Health Personnel', 'Hearing', 'Home environment', 'Impairment', 'Industry Standard', 'Lead', 'Liquid substance', 'Machine Learning', 'Mastoiditis', 'Measures', 'Meningitis', 'Methods', 'Modeling', 'Obstruction', 'Otitis Media', 'Otoscopes', 'Otoscopy', 'Outcome', 'Output', 'Paper', 'Parents', 'Patients', 'Performance', 'Peripheral', 'Phase', 'Physicians', 'Population', 'Preparation', 'Publishing', 'Research Personnel', 'Resistance', 'Resources', 'Running', 'Screening procedure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Specialist', 'Specificity', 'Speculums', 'Speech', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Tympanic membrane', 'Tympanometry', 'Visual', 'base', 'care providers', 'clinical care', 'clinical practice', 'design', 'diagnostic accuracy', 'experience', 'hearing impairment', 'improved', 'machine learning algorithm', 'meetings', 'microbial', 'microphone', 'middle ear', 'prospective', 'screening', 'signal processing', 'sound', 'telehealth', 'tool', 'urgent care', 'usability']",NIDCD,"WAVELY DIAGNOSTICS, INC.",R43,2019,157842,-0.023930226384343847
"Patient specific 3D printed tissue engineered vascular graft for aortic reconstruction designed by artificial intelligence algorithm. 1 The goal of this study is to create patient-specific, hemodynamically optimized, tissue engineered  2 vascular grafts (TEVG) for use in aortic arch repair surgery. These TEVGs are optimized for high pressure  3 circulation using 3D printing technology and artificial intelligence, and will grow with the patient, in hopes of  4 obviating need for future surgeries to replace grafts, which can occur with contemporary arch reconstruction  5 materials. Congenital heart disease (CHD) is the leading cause of death due to congenital anomalies. Despite  6 significant advances in surgical management for CHD, one significant source of morbidity and mortality arises  7 from the complexity of surgery for diverse anatomies in the aortic arch. Previous studies have demonstrated  8 that the resultant arch geometry after surgical reconstruction of stenotic or hypoplastic aortas is important to  9 minimize reduce energy loss and undesirable flow inside the arch, which can lead to hypertension, abnormal 10 vascular response and ventricular dysfunction. Ensuring a patient-specific graft design for ideal reconstructed 11 route before surgery with minimum energy loss and wall shear stress may yield long-term benefits for patient 12 health and quality of life. 13 We have demonstrated native vessel like neotissue formation of TEVG in small and large animal 14 studies. Based on these experiences, we have developed a novel 3D printing technology combining 3D printed 15 metal mandrels with nanofiber electro-spun technology. With this 3D printing technology, we showed that 16 TEVG developed native like neovessel formation in venous circulation in a sheep model. For this next step, we 17 aim to develop grafts in arterial circulation that can be applied to aortic reconstruction. We will also develop 18 automatic design algorithms to design optimal graft shape in order to reduce time and cost of patient specific 19 design. We hypothesize that patient-specific TEVG using our 3D printing technology can be designed, 20 aided by pre-operative imaging and flow data, computer assisted design (CAD), automatic design 21 algorithms based on computation fluid dynamics (CFD) results, and will demonstrate proper neotissue 22 formation and growth while maintaining optimally designed hemodynamics. 23 This project will be an important step towards clinical application of patient-specific vascular grafts that 24 recapitulate the native anatomy and mechanical properties. The results of this work will have a broader impact 25 on the design and fabrication of other more complex cardiovascular structures for implantation. This paradigm 26 shift in vascular graft technology will improve the quality and safety of pediatric patient care. The goal of this study is to create patient-specific, hemodynamically optimized, tissue engineered vascular grafts using 3D printing technology and artificial intelligence for use in aortic arch repair surgery which demands a structured surgical approach in order to optimize hemodynamics postoperatively. We will optimize the design of an aortic graft automatically using computational flow dynamics, refine 3D printing manufacturing, evaluate grafts with in-vitro testing, and finally will test the performance of the grafts in vivo over time. This paradigm shift in vascular graft technology will improve the quality, safety and longevity of pediatric cardiovascular care.",Patient specific 3D printed tissue engineered vascular graft for aortic reconstruction designed by artificial intelligence algorithm.,9718303,R01HL143468,"['3-Dimensional', '3D Print', '4D MRI', 'Acute', 'Adult', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Animals', 'Aorta', 'Artificial Intelligence', 'Blood Circulation', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Cause of Death', 'Childhood', 'Clinic', 'Complex', 'Computer-Aided Design', 'Computers', 'Consumption', 'Custom', 'Data', 'Descending aorta', 'Ensure', 'Experimental Animal Model', 'FDA approved', 'Future', 'Geometry', 'Goals', 'Growth', 'Health', 'Histologic', 'Hypertension', 'Image', 'Implant', 'In Vitro', 'Inferior vena cava structure', 'Lead', 'Liquid substance', 'Longevity', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Organ', 'Patient Care', 'Patients', 'Performance', 'Physiological', 'Postoperative Period', 'Printing', 'Process', 'Quality of life', 'Route', 'Safety', 'Shapes', 'Sheep', 'Source', 'Structure', 'Surgical Management', 'Technology', 'Time', 'Tissue Engineering', 'Tissues', 'Translating', 'Vascular Graft', 'Venous', 'Ventricular Dysfunction', 'Work', 'aortic arch', 'base', 'clinical application', 'congenital anomaly', 'congenital heart disorder', 'cost', 'design', 'experience', 'hemodynamics', 'implantation', 'improved', 'in vitro testing', 'in vivo', 'mechanical properties', 'model design', 'mortality', 'nanofiber', 'novel', 'pediatric patients', 'performance tests', 'preservation', 'pressure', 'reconstruction', 'repaired', 'response', 'scaffold', 'shear stress', 'surgery outcome', 'vascular tissue engineering']",NHLBI,UNIVERSITY OF CHICAGO,R01,2019,734159,-0.011166571752904458
"Computer Vision-Based Navigation System for High-Precision Orthopedic Trauma Surgery PROJECT SUMMARY / ABSTRACT Closed or open fracture reduction and internal fixation is the standard surgical approach in treating pelvic fractures, with current clinical practice using fluoroscopic guidance, guidewire insertion, and cannulated screw placement. The challenge in reckoning complex 3D morphology in 2D fluoroscopy presents a major source of uncertainty, trial-and- error, and poor outcomes, with 20-30% rate of suboptimal screw placement and long fluoroscopic runtime (mean fluoro time > 123 s) exposing operating personnel to high levels of radiation exposure. Despite these challenges, mainstream surgical approach has remained largely unchanged for 35 years, and surgical navigation systems (though increasingly common in neurosurgery) present cost and workflow barriers that limit their broad applicability in trauma surgery. We propose a computer vision-based navigation approach that is compatible with routine trauma surgery workflow, offers real-time guidance with accuracy comparable to stereotactic navigation, gives ten-fold reduction in radiation exposure, and works with tools already common in the trauma surgery arsenal. The proposed system uses a miniature stereoscopic camera mounted onboard the surgical drill in combination with 3D-2D registration of fluoroscopic views for direct, real-time registration of the instrument trajectory relative to patient anatomy. Real-time overlay of instrument trajectory in fluoroscopic views and/or CT permits accurate identification of guidewire entry point, orientation, and conformance within bone corridors and will reduce reliance on “fluoro hunting” and trial-and-error guidewire placement. The following aims develop and evaluate the system for application in pelvic trauma surgery, including quantitative assessment of accuracy, workflow, and radiation dose in pre-clinical studies. Aim 1. System for computer vision-based guidance in trauma surgery. The hardware and software components required for vision-based tracking onboard a standard surgical drill will be developed, providing real-time trajectory overlay in fluoroscopy and/or preoperative CT. A fast calibration method will be developed for automatic drill axis calibration. Automatic feature-based registration of the video and fluoroscopic frames enables real-time overlay of instrument trajectory in fluoroscopic views (Fluoro Navigation), and 3D-2D registration between CT and fluoroscopy will enable real-time overlay of the instrument trajectory in CT (CT Navigation). Aim 2: Evaluation in preclinical studies. The vision-based navigation system will be implemented in pre-clinical (cadaver) experiments to evaluate accuracy and workflow. These studies will evaluate the geometric accuracy and workflow factors relating to the number of repeated insertion attempts, procedure time, and radiation dose, evaluating vision-based Fluoro Navigation and CT Navigation in comparison to conventional freehand fluoroscopy guidance. Successful completion of the aims will establish a system suitable for computer vision-based navigation to be translated to clinical studies in future work. Such a system offers a potentially major advance in routine trauma surgery, bringing capabilities comparable to state-of-the-art stereotactic navigation without the cost, complexity, and additional workflow of conventional navigation. PROJECT NARRATIVE Even experienced trauma surgeons are challenged in resolving the complex 3D morphology of the pelvis in 2D x-ray fluoroscopy, presenting a major source of uncertainty, a high rate of malpositioned screws, and high levels of radiation exposure to the patient and operating staff. To facilitate high-precision pelvic trauma surgery and reduce intraoperative radiation dose, we propose a computer vision-based navigation approach providing real-time overlay of surgical instrument trajectories in fluoroscopic views and CT, facilitating accurate identification of guidewire entry point, orientation, and conformance within safe bone corridors. The approach offers a major advance compared to conventional navigation by not requiring intraoperative 3D imaging, avoiding time-consuming calibration, and eliminating externally-positioned hardware in the operating room, and the proposed research translates the system from basic development and quantitative testing to preclinical studies evaluating geometric accuracy, workflow, and radiation dose.",Computer Vision-Based Navigation System for High-Precision Orthopedic Trauma Surgery,9806153,R21EB028330,"['3-Dimensional', '3D Print', 'Affect', 'Anatomy', 'Biopsy', 'Cadaver', 'Calibration', 'Clinical Research', 'Closed Fractures', 'Communities', 'Comorbidity', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Ensure', 'Evaluation', 'Exposure to', 'Fluoroscopy', 'Fracture', 'Future', 'Healthcare', 'High Prevalence', 'Hour', 'Human Resources', 'Image', 'Incidence', 'Mainstreaming', 'Methods', 'Morphology', 'Navigation System', 'Needles', 'Open Fractures', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Outcome', 'Patients', 'Pelvis', 'Persons', 'Positioning Attribute', 'Procedures', 'Radiation Dose Unit', 'Radiation exposure', 'Research', 'Roentgen Rays', 'Source', 'Structure', 'Surgeon', 'Surgical Instruments', 'System', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Training', 'Translating', 'Translations', 'Trauma', 'Uncertainty', 'Visceral', 'Vision', 'Work', 'base', 'bone', 'clinical practice', 'cortical bone', 'cost', 'disability', 'experience', 'experimental study', 'improved', 'instrument', 'instrumentation', 'mortality', 'neurosurgery', 'neurovascular', 'pelvis fracture', 'pre-clinical', 'preclinical study', 'sample fixation', 'socioeconomics', 'stereoscopic', 'tool', 'virtual']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,238182,-0.009514732917924273
"Innovations in cervical cancer diagnosis for low resource settings using advanced optical imaging and machine learning diagnostic algorithms. The broad goal of this project is to adapt a portable, low-cost, easy-to-use Pocket-sized Colposcope (developed under other funding) for use in a community setting, and develop automated algorithms that combine neovascularization, glycogen depletion and acetowhitening to provide comparable diagnosis to an expert. This work will be done in a collaboration between 3rd Stone Design, Inc, Duke University and Kenya Medical Research Institute. The specific aims of this proposal are:  Aim 1 (Phase I): Improve Pocket colposcope by designing continuous magnification mechanism and improving device workflow integration to eliminate between-use disinfection through the use of a disposable optically clear sterile sleeve. Provider feedback on our previously developed Pocket colposcope has unanimously suggested the addition of a slider mechanism to control coarse zoom and a sleeve consumable to the Pocket colposcope design.  Aim 2 (Phase I): Automated algorithms and software for cervical pre-cancer detection We will improve the specificity of VIA using a novel software application with embedded machine learning diagnostic algorithms for automated cervical cancer screening. We will apply and validate the individual algorithms for VIA and GIVI (green illumination vascular imaging) to existing images obtained from a 200-patient clinical study with the Pocket colposcope. We will then compare the performance of the algorithms to expert physician interpretation of the same images, with pathology serving as the gold standard.  Aim 3 (Phase II): Document user experience with Pocket colposcope in Kenya. We will develop a culturally relevant training package directly in the community healthcare setting. We will collect quantitative and qualitative data including surveys, in-depth interviews, and clinic observations from both naive providers and patients and use these findings to and use these findings to improve the introduction of the Pocket colposcope in Kenya and simultaneously, inform the clinical investigations in Aim 4.  Aim 4 (Phase II): Compare the performance of the Pocket colposcope to Visual Inspection with Acetic Acid for triage of HPV+ women in Kenya. We will carry out a cluster-randomized trial among 400 HPV+ women to compare the standard triage with that using the Pocket colposcope in Kisumu, Kenya. All HPV+ women will undergo biopsy to determine sensitivity, specificity and positive and negative predictive values of the different triage strategies. Data will be used to model the performance of the algorithm against that of expert colposcopists.  Aim 5 (Phase II): Assess the costs, incremental cost-effectiveness and population health impact of HPV-based cervical cancer screening programs with proposed triage strategies. We will determine the incremental cost-effectiveness ratio and the absolute and relative costs for four triage strategies by measuring the costs and model population health outcomes (cancer cases, deaths and disability adjusted life years). NARRATIVE The SBIR activities proposed by 3rd Stone Design and Duke University will advance the state of the art in cervical cancer imaging through the R&D of novel optics for a portable colposcope combined with automated algorithms for diagnosis. The project will confirm the benefits of these innovations through a clinical trial in Kenya conducted by the Kenya Medical Research Institutes. The innovations developed have tremendous potential to effect public health by increasing diagnostic acuity and decreasing costs of healthcare delivery which ultimately will reduce the impact of the deadly disease.",Innovations in cervical cancer diagnosis for low resource settings using advanced optical imaging and machine learning diagnostic algorithms.,9778122,R44CA240019,"['Acetic Acids', 'Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Ambulatory Care', 'American Society of Clinical Oncology', 'Back', 'Biopsy', 'Blood Vessels', 'Cancer Burden', 'Cervical', 'Cervical Cancer Screening', 'Cessation of life', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Clinical Trials', 'Cluster randomized trial', 'Collaborations', 'Colposcopes', 'Colposcopy', 'Community Health', 'Community Healthcare', 'Computer software', 'Cost Analysis', 'Cost Measures', 'Country', 'Coupled', 'Cytology', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Disinfection', 'Feedback', 'Fogs', 'Foundations', 'Funding', 'Glycogen', 'Goals', 'Gold', 'Guidelines', 'Health Care Costs', 'Healthcare', 'Human Papillomavirus', 'Image', 'Incidence', 'Individual', 'Infrastructure', 'International', 'Interview', 'Kenya', 'Lesion', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Medical Research', 'Modeling', 'Optics', 'Outcome', 'Pathology', 'Patients', 'Performance', 'Phase', 'Physicians', 'Predictive Value', 'Prevention', 'Primary Health Care', 'Protocols documentation', 'Provider', 'Public Health', 'Research Institute', 'Resources', 'Rural', 'Sensitivity and Specificity', 'Site', 'Sledding', 'Small Business Innovation Research Grant', 'Specificity', 'Sterility', 'Surveys', 'Technology', 'Testing', 'Training', 'Triage', 'Universities', 'Vagina', 'Visual', 'Woman', 'Work', 'World Health Organization', 'base', 'burden of illness', 'cancer diagnosis', 'cancer imaging', 'clinical investigation', 'cohort', 'community setting', 'cost', 'cost effectiveness', 'cost-effectiveness ratio', 'design', 'disability-adjusted life years', 'experience', 'health care delivery', 'health care settings', 'improved', 'incremental cost-effectiveness', 'innovation', 'low and middle-income countries', 'mortality', 'neovascularization', 'novel', 'optical imaging', 'overtreatment', 'point of care', 'population health', 'portability', 'primary care setting', 'relative cost', 'research and development', 'screening', 'screening program']",NCI,CALLA HEALTH FOUNDATION,R44,2019,299992,-0.03301512218924463
"BlueBox: A Complete Code Blue Data Recorder, Phase II “Code blue” is the signal used in hospitals to call for an immediate cardiopulmonary resuscitation (CPR) following a cardiac or respiratory arrest. Reviewing the performance of the “code blue team” is a cornerstone for improving outcomes. The current standard of using handwritten records on a paper “code sheet” does not allow measurement of key quality indicators and is subject to human error. In the Phase I STTR project, we developed an electronic device for complete recording of code blue events, called BlueBox. The BlueBox is a small electronic recorder on an adhesive patch to be placed on the left chest next to the mid-sternum. The prototype we developed in Phase I was successfully tested on high fidelity mannequins and on pigs. In Phase II, our goal is to complete the product development and testing and prepare the BlueBox for regulatory clearance and market launch. To achieve this goal, we propose 3 Specific Aims. Aim 1 is to complete the product development of the BlueBox device and the software user interface (UI) for the “electronic code sheet.” We will turn the engineering prototype we developed in Phase I into a product ready for commercialization through rigorous product development processes. We will develop a mobile app for iPads with a software UI for the “electronic code sheet.” Aim 2 is to conduct human factors and usability engineering (HF/UE) testing and prepare for regulatory submission. The alpha prototype will undergo HF/UE testing in the Simulation Center. We will establish and maintain quality management records and conduct a pilot production run of 200 units of BlueBox. Aim 3 is to validate the BlueBox system in a clinical study of code blues in the hospital. We will first conduct a pilot study of 5 code blue patients in the CCU and Cath Lab. Once the pilot study is successful, we plan to conduct a full clinical study of 100 patients recruited from the Harbor-UCLA ICU/CCU and emergency departments. The objectives of the clinical study are: 1) to establish equivalence of the electronic code sheet to the current standard of paper code sheet; 2) to demonstrate the effectiveness of the electronic code sheet in identifying key CPR quality indicators. The criteria for successful development of the product will be that it passes all required regulatory testing and is validated in the clinical study for its equivalence and effectiveness in code blue recording. There will be two major milestones in this project: (1) finalizing product development with successful test production of 200 units; and (2) completing the clinical study and preparing for a 510(k) submission. Achieving the aims will result in a validated BlueBox system ready for submission to the FDA and commercialization. We intend to first introduce the BlueBox system to hospitals as a tool for staff training and quality improvement. We will continue the technology development with machine learning to provide instant feedback in the second generation BlueBox. Our ultimate goal is to minimize human error and improve patient outcomes through the BlueBox system's better documentation and continuous feedback mechanism. PROJECT NARRATIVE Debriefings and detailed reviews of the performance of the “code blue team” in cardiopulmonary resuscitation (CPR) can improve quality of care and patient outcomes. In Phase I, we developed and successfully tested an electronic device, the BlueBox, for recording all CPR events and enabling full displays of code blue resuscitations in an “electronic code sheet.” We will turn the engineering prototype into a product ready for regulatory submission and commercialization in the proposed Phase II project.","BlueBox: A Complete Code Blue Data Recorder, Phase II",9680137,R42GM113463,"['Accident and Emergency department', 'Adhesives', 'American Heart Association', 'Animals', 'Cardiac', 'Cardiopulmonary Resuscitation', 'Chest', 'Clinical', 'Clinical Research', 'Code', 'Code Blue', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Documentation', 'Effectiveness', 'Electric Countershock', 'Electronics', 'Emergency Situation', 'Engineering', 'Event', 'Family suidae', 'Feedback', 'Generations', 'Goals', 'Guidelines', 'Hospital Administrators', 'Hospitals', 'Human', 'Industrialization', 'Left', 'Machine Learning', 'Manikins', 'Measurement', 'Mechanics', 'Medical', 'Medical Errors', 'Miniaturization', 'Modeling', 'Outcome', 'Paper', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Pilot Projects', 'Preparation', 'Procedures', 'Process', 'Production', 'Quality Indicator', 'Quality of Care', 'Records', 'Resuscitation', 'Running', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specialist', 'Specific qualifier value', 'Sternum', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Validity and Reliability', 'base', 'care outcomes', 'commercialization', 'design', 'heart rhythm', 'human error', 'improved', 'improved outcome', 'machine learning algorithm', 'meetings', 'member', 'mobile application', 'patient safety', 'product development', 'prototype', 'respiratory', 'sensor', 'simulation', 'technology development', 'tool', 'usability', 'validation studies']",NIGMS,"NEOVATIVE, INC.",R42,2019,723986,-0.013861454104330224
"Therapeutic potential of vagal neurostimulation to reduce food intake Obesity affects almost 40% percent of US adults and is associated with high levels of comorbidities, including cancer, cardiovascular disease, and diabetes. Although effective treatments with minimal side effects are lacking, vagus nerve stimulation (VNS) can reduce body weight and suppress feeding behavior. There is little insight, however, into its mechanism and it is unclear whether VNS effects on feeding and body weight result from non-specific side effects, such as nausea. The current application directly addresses these issues by assessing gastrointestinal (GI) myoelectric changes as a potential mechanism for effects of VNS on feeding behavior, while comparing these responses to emetic activation. We plan to accomplish this by using a ferret model, which is a gold-standard for studying emesis, vagus nerve, and GI physiology. We will test the hypothesis that electrical stimulation of the vagus nerve can reduce food intake without triggering indicators of nausea, such as disrupted GI myoelectric responses, retching, and vomiting. We will complete three Aims. Aim 1: Define the individualized GI myoelectric patterns during feeding behavior using machine learning classification. Animals will be implanted with planar electrodes attached to the GI serosal surface from proximal gastric fundus to distal duodenum. We will use machine learning to classify GI myoelectric patterns of meal consumption compared to emetic-related states, including those elicited by intragastric emetine and high amplitude and frequency VNS known to trigger emesis. Aim 2: Test the efficacy of abdominal VNS on reducing meal size without triggering disruptions of GI myoelectric responses, retching, and emesis. Animals will be assessed for effects of abdominal VNS using a variety of stimulus parameters on feeding behavior and multi-site GI myoelectric recordings. Aim 3: Determine the efficacy of cervical VNS in controlling meal size without producing off-target effects (disruptions of GI myoelectric responses, retching, emesis, changes in heart rate, or blood pressure). We will test the impact of cervical VNS parameters on feeding behavior, GI myoelectric responses, retching, emesis, hear rate variability, and blood pressure. Our approach is innovative because we will use machine learning classification to detect individualized GI myoelectric response patterns in an awake free-moving animal for comparing therapeutic and off-target effects of VNS on feeding, GI activity, emesis, and cardiovascular function. This planned research is significant because VNS therapy can potentially provide a frontline treatment option for patients with high levels of obesity refractory to behavioral or pharmacological therapy, which unlike other surgical interventions for weight loss, such as gastric bypass, is potentially tunable and reversible by changing stimulation parameters, switching the device off, or complete removal. Obesity affects almost 40% percent of US adults, is associated with type 2 diabetes, cardiovascular disease, and cancer, and has a health-care cost that could total nearly one trillion US dollars by 2030. The current project is designed to test vagus nerve stimulation to reduce food intake, while limiting adverse effects, such as nausea, vomiting, and disrupted gastrointestinal function. Our proposed research is relevant to the NIH’s plan to support the design and testing of new interventions for achieving and maintaining a healthy weight (Strategic Plan for NIH Obesity Research).",Therapeutic potential of vagal neurostimulation to reduce food intake,9796542,R01DK121703,"['Abdomen', 'Address', 'Adult', 'Adverse effects', 'Affect', 'Anatomy', 'Animals', 'Behavioral', 'Blood Pressure', 'Body Weight', 'Body Weight decreased', 'Cardiovascular Diseases', 'Cardiovascular Physiology', 'Cardiovascular system', 'Cervical', 'Chemicals', 'Chronic', 'Classification', 'Comorbidity', 'Consumption', 'Data', 'Devices', 'Diabetes Mellitus', 'Distal', 'Duodenum', 'Eating', 'Effectiveness', 'Electric Stimulation', 'Electrodes', 'Emetics', 'Emetine', 'Event', 'Excision', 'FDA approved', 'Feeding behaviors', 'Ferrets', 'Fiber', 'Frequencies', 'Gastric Bypass', 'Gastrointestinal Motility', 'Gastrointestinal Physiology', 'Gastrointestinal tract structure', 'Goals', 'Gold', 'Health Care Costs', 'Hearing', 'Heart Rate', 'Implant', 'Individual', 'Intervention', 'Laboratory Rat', 'Laboratory mice', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Modeling', 'Nausea', 'Nausea and Vomiting', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pharmacology', 'Phenotype', 'Physiological', 'Rattus', 'Refractory', 'Reporting', 'Research', 'Rodent Model', 'Satiation', 'Sensory', 'Signal Transduction', 'Site', 'Sleep', 'Stimulus', 'Stomach', 'Strategic Planning', 'Surface', 'Testing', 'Therapeutic', 'Training', 'United States National Institutes of Health', 'Upper digestive tract structure', 'Vagus nerve structure', 'Vomiting', 'awake', 'behavioral pharmacology', 'design', 'effective therapy', 'efficacy testing', 'experimental study', 'feeding', 'gastric fundus', 'gastrointestinal', 'gastrointestinal function', 'healthy weight', 'heart rate variability', 'indexing', 'innovation', 'insight', 'machine learning algorithm', 'obesity treatment', 'personalized medicine', 'pre-clinical', 'predicting response', 'recruit', 'reduced food intake', 'response', 'side effect', 'therapeutic target', 'vagus nerve stimulation', 'weight loss intervention']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,488645,-0.028520419242678067
"Systems Biology of Aging: Data-science meets Gero-science PROJECT SUMMARY / ABSTRACT The funds requested in this R13 application are for partial support of “Systems Biology of Aging: Data-science meets Gero-science” annual meetings to be offered each August/September from 2019 through 2022 at The Jackson Laboratory for Genomic Medicine (JAX-GM) in Farmington, Connecticut. This meeting will bring together up to 150 interdisciplinary scientists including molecular biologists, immunologists, computational biologists, and geriatricians, who share a common interest in understanding aging and aging-associated disease at the systems level. Many aging-associated diseases, such as cancer and cardiovascular disease, are influenced by dysfunctions in the immune system. Recent advances in genomic profiling techniques (e.g., single cell transcriptomics) provide an opportunity to uncover aging-related changes in human cells/tissues and to link these changes to health and lifespan. The wealth and complexity of data produced using these technologies is ever increasing, as is the need to develop advanced computational methods to mine and integrate these data. Despite this need, there are currently no formal venues at which scientists, specifically those in the aging field, can be trained in the basics and application of data mining techniques (i.e., machine learning algorithms). Furthermore, current conferences on aging are not aimed at specifically bringing together computational biologists, immunologists and basic and clinical aging researchers. Therefore, the objectives of this meeting are: (1) to recognize and emphasize the highly interdisciplinary nature of the aging field and to promote and accelerate collaborations and cross-pollination of ideas across the three disciplines: aging, immunology, and computational biology; (2) to provide trainees (students and postdoctoral fellows) an opportunity to closely interact with, and gain feedback from, more senior investigators to advance their projects and establish connections to help build their careers; and (3) to provide an opportunity for researchers in the field of aging to learn the basics of machine learning techniques, which they will be able to immediately apply to their own research upon return to their home institutions. We will reach these objectives through carrying out the following Aims. In Aim 1, we will organize an interdisciplinary meeting and hands-on workshop focused on aging and aging-related diseases. The meeting will include a 2-day seminar session featuring talks by leading scientists, followed by a 1-day hands-on workshop on the basics of machine learning. In Aim 2, we will promote interactions to foster collaborative research and career advancement, including through a poster session. In Aim 3, we will recruit diverse attendees. Our proposed speaker list features several female scientists, and we will use our partnership networks to specifically recruit attendees from nationally underrepresented racial and ethnic groups. The ultimate goal of the meeting is to advance the aging research field through expediting collaborations and the understanding of aging-related genomic data via application of advanced data mining approaches. PROJECT NARRATIVE / RELEVANCE TO PUBLIC HEALTH Aging and aging-associated diseases, such as Alzheimer's, cancer and cardiovascular disease, represent a significant and growing health and economic burden, with the elderly population of the US projected to double by 2030. Herein, we propose to organize an interdisciplinary conference with a hands-on computational training component that will bring together scientists from the fields of aging, immunology, and computational biology, which will enable creative collaborations and train early career scientists in the aging research field on the basics of advanced computational techniques to mine aging-related genomic data. This is ultimately expected to lead to a better molecular understanding of the aging process and to novel approaches for the improvement of human healthspan and/or lifespan.",Systems Biology of Aging: Data-science meets Gero-science,9912317,R13AG064968,"['Academia', 'Address', 'Affect', 'Aging', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Biology of Aging', 'Cardiovascular Diseases', 'Career Mobility', 'Cell physiology', 'Cells', 'Cities', 'Clinical', 'Collaborations', 'Complex', 'Computational Biology', 'Computational Technique', 'Computing Methodologies', 'Connecticut', 'Data', 'Data Analyses', 'Data Science', 'Data Scientist', 'Development', 'Discipline', 'Disease', 'Economic Burden', 'Educational workshop', 'Elderly', 'Ethnic group', 'Etiology', 'Feedback', 'Female', 'Fostering', 'Functional disorder', 'Funding', 'Genomic medicine', 'Genomics', 'Geroscience', 'Goals', 'Health', 'Home environment', 'Human', 'Immune', 'Immune system', 'Immunologist', 'Immunology', 'Impaired cognition', 'Industry', 'Institution', 'Lead', 'Learning', 'Link', 'Location', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Mus', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Organism', 'Outcome', 'Participant', 'Phenotype', 'Play', 'Population', 'Postdoctoral Fellow', 'Process', 'Public Health', 'Pythons', 'Race', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scholarship', 'Science', 'Scientist', 'Series', 'Shock', 'Societies', 'Students', 'Support System', 'System', 'Systems Biology', 'Techniques', 'Technology', 'The Jackson Laboratory', 'Time', 'Tissues', 'Training', 'Underrepresented Minority', 'Universities', 'Work', 'aging population', 'cancer type', 'career', 'clinical biomarkers', 'clinically significant', 'data mining', 'epigenome', 'epigenomics', 'genomic biomarker', 'genomic data', 'genomic profiles', 'graduate student', 'health economics', 'healthspan', 'innovation', 'interdisciplinary approach', 'interest', 'machine learning algorithm', 'meetings', 'next generation', 'novel strategies', 'posters', 'programs', 'recruit', 'response', 'senescence', 'skills', 'symposium', 'technology development', 'transcriptome', 'transcriptomics', 'translational approach']",NIA,JACKSON LABORATORY,R13,2019,38566,-0.03104014198193982
"Predicting complicated grief from grief processing PROJECT SUMMARY Most people grieving the loss of a loved one will experience a period of intense pain and focusing on the loss lasting around 6 months, which is known as acute grief. Complicated grief (CG) occurs when the experiences of acute grief extend well past 6-months post-loss. Thoughts and feelings about the loss (i.e. grief processing) occurring during acute grief may play a role in healthy grieving and protect against CG development. Identification of the cognitive and emotional mechanisms of grief processing that contribute to healthy grief resolution would advance knowledge of the goals of grieving and assist the development of interventions for complicated grief. Two core components of grief processing are top-down regulation and balanced loss confrontation. Top-down pursue related emotional representations and recruit proportion regulation is the ability to suppress processing of intrusive emotional information to a stated goal. Top-down regulation may facilitate healthy grieving by allowing reprieve from intense loss thinking. Balanced loss confrontation refers to the processing of the loss in a way that protects against overload. Confrontation with the l oss may assist in the process of reforming one's mental of the deceased. This tudy will test extrinsic and intrinsic measures of top-down regulation balanced loss confrontation during acute grieving as predictors of CG development a year later We will a sample at high-risk for CG, the suicide-bereaved, in order to maximize the likeliness that a significant of the sample develops CG. The s . findings produced by this study may advance the knowledge of how CG develops, assist in the identification of people at high-risk for developing CG and potentially form the basis for targeted interventions.  The following K23 presents a research and training program that will support the applicant on the path of becoming an independent investigator of the role of grief processing in the development of complicated grief. The research mentorship, coursework, hands-on experience, seminars and classes ingrained in this training and plan will propel the applicant to independence in the domains of1) Clinical Research, 2) Psychometric Assessment of Grief Processing, 3) Machine Learning analysis of fMRI, 4) Biostatistics, 5) Scientific Independence. team independent and The combination of the environment, t raining plan, research strategy and mentorship will not only provide the candidate with a spectrum of new methods and skills that will establish him as an research scientist, but will also produce a body of knowledge that will clarify the specific cognitive emotional grief processes that contribute to the development of CG. PROJECT NARRATIVE Complicated grief describes an inability to adjust to the loss of a loved one over the course of the first year following the death. This study will identify cognitive, emotional and neural processes occurring in the early grieving period (3 to 5-months post-loss) that predict or protect against the development of complicated grief a year later in suicide bereaved subjects, a sample at high-risk for developing complicated grief. These findings may advance understanding of the process of grief, facilitate early identification of high-risk grievers and potentially form the basis for targeted treatment of complicated grief.",Predicting complicated grief from grief processing,9686793,K23MH114021,"['Acute', 'Age', 'Attention', 'Biometry', 'Cessation of life', 'Clinical', 'Clinical Research', 'Cognitive', 'Data', 'Depressed mood', 'Development', 'Down-Regulation', 'Early identification', 'Emotional', 'Emotions', 'Environment', 'Failure', 'Family member', 'Feeling', 'Functional Magnetic Resonance Imaging', 'Gender', 'Goals', 'Grief reaction', 'Guilt', 'High Prevalence', 'Individual', 'Instruction', 'Intervention', 'Interview', 'Knowledge', 'Machine Learning', 'Measures', 'Mental Depression', 'Mentorship', 'Methods', 'Modeling', 'Pain', 'Pathogenesis', 'Pattern', 'Play', 'Process', 'Psyche structure', 'Psychometrics', 'Questionnaires', 'Rain', 'Reaction Time', 'Recording of previous events', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Role', 'Sampling', 'Scientist', 'Severities', 'Shame', 'Stimulus', 'Suicide', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Training Programs', 'Trauma', 'Unconscious State', 'Validation', 'attentional bias', 'base', 'experience', 'high risk', 'indexing', 'intense pain', 'loved ones', 'neural patterning', 'recruit', 'relating to nervous system', 'response', 'sex', 'skills', 'sustained attention', 'targeted treatment', 'therapy development']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,K23,2019,199800,-0.03710232796114265
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9739188,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Simulation', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in vivo', 'insight', 'intracranial artery', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'multiple omics', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'single photon emission computed tomography', 'spatiotemporal', 'supervised learning', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2019,506426,-0.016190259495739958
"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis. PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.",Developing Classification Criteria for the Uveitides,9663961,R01EY026593,"['Acute', 'Adult', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Anterior uveitis', 'Antiviral Agents', 'Blindness', 'Child', 'Choroiditis', 'Chronic', 'Classification', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'Cytomegalovirus Retinitis', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Enrollment', 'Ensure', 'Epidemiology', 'Future', 'Genomics', 'Goals', 'Immune', 'Immunosuppression', 'Infection', 'Inflammation', 'Informatics', 'Intermediate Uveitis', 'Machine Learning', 'Mediating', 'Nomenclature', 'Outcomes Research', 'Panuveitis', 'Pathogenesis', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Pigments', 'Posterior Uveitis', 'Publications', 'Research', 'Retinitis', 'Risk Factors', 'Sensitivity and Specificity', 'Specificity', 'Standardization', 'Syndrome', 'Techniques', 'Terminology', 'United States', 'Uveitis', 'Vision', 'Visual impairment', 'Voting', 'age group', 'age related', 'aging population', 'antimicrobial', 'birdshot chorioretinitis', 'cost', 'outcome forecast', 'public health relevance', 'symposium', 'tool', 'web page', 'working group']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2019,127308,-0.013954191307579378
"An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography SUMMARY – OVERALL Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function. Although the basic electron cryo-tomography technique has been used for several decades, the technology is being revolutionized by recent advances in sample preparation, electron cryo-microscopy hardware, improved capabilities for automatic data collection, direct electron detection imaging devices, and phase plate technologies. Combined, these advances led to the ability to generate extraordinarily large numbers of cellular cryo-tomograms of exquisite quality. In principle, such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. However, collection of cellular data is now at a far faster rate than can currently be analyzed with existing methods, producing a serious barrier to progress: to match the data production rates of a single laboratory, at least 50 experienced scientists would need to handle the data analysis. The primary goal of this Program Project is to establish quantitative and highly automated tools for the reconstruction and interpretation of highly complex cellular tomographic data. We have assembled a highly synergistic team of PIs with complimentary expertise in cutting-edge computational and experimental electron microscopy techniques to achieve this goal through collaborative efforts. Project 1 (Hanein & Penczek) focuses on development and implementation of tomogram quality assessment and validation techniques and on experimentally guided optimization of data collection strategies. Project 2 focuses on automatic tomographic reconstruction technology, extraction of various features from the tomograms, and the analysis of distribution patterns derived from the extracted features. Project 3 focuses on development of quantitative tools for tomogram annotation through deep learning and sub-tomogram alignment as well as interactive visualization tools. The set of highly automated tools developed in this Program Project will permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study. NARRATIVE Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function and—with recent instrumental advances—it is now possible to image hundreds of cells per months, enabling collection of cellular data at a far faster rate than can currently be analyzed. Such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. This Program Project brings together an accomplished team of investigators to develop new strategies for effectively processing and interpreting this massive influx of data, developing a set of highly automated tools to permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study.",An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography,9769773,P01GM121203,"['Address', 'Algorithms', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biology', 'Cancer Diagnostics', 'Cell physiology', 'Cells', 'Classification', 'Collection', 'Complex', 'Computing Methodologies', 'Cryo-electron tomography', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Electrons', 'Environment', 'Floods', 'Goals', 'Health', 'Heart', 'Human', 'Image', 'Imaging Device', 'Individual', 'Knowledge', 'Laboratories', 'Methodology', 'Methods', 'Molecular', 'Molecular Structure', 'Morphology', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Preparation', 'Process', 'Production', 'Real-Time Systems', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Tomogram', 'Validation', 'Variant', 'Visualization software', 'base', 'computer framework', 'convolutional neural network', 'deep learning', 'electron tomography', 'experience', 'imaging detection', 'improved', 'insight', 'knowledge base', 'learning strategy', 'nanomachine', 'novel diagnostics', 'particle', 'programs', 'reconstruction', 'response', 'software development', 'statistics', 'tomography', 'tool', 'virtual']",NIGMS,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,P01,2019,928444,-0.028101844664047523
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9807074,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Simulation', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'random forest', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2019,482291,-0.020162373117959223
"The next generation of RNA-Seq simulators for benchmarking analyses Abstract: RNA-Sequencing (RNA-Seq) has established itself as the primary method for studying transcription in basic research, with an emerging role in the clinic – currently upwards of 5,000 publications using the technology are indexed in PubMed. However, the interpretation of RNA-Seq requires several complex operations including alignment, quantification, normalization and statistical analyses of various types. Since its inception a large number of algorithms have appeared for each step, creating a very confusing landscape for investigators. In order to determine the best analysis practices, numerous benchmarking studies have emerged which leverage real RNA-Seq data made from well-studied RNA samples, such as the Genetic European Variation in Health and Disease (GEUVADIS) consortium data. These valuable RNA-Seq datasets contain the biases and errors introduced by sequencing biochemistry—factors that any analysis method must account for and overcome. However, the utility of such datasets for benchmarking analysis methods is limited by the fact that we do not know the underlying truth (e.g. the true number of RNA molecules from each transcript in the original sample). Therefore researchers tend to rely heavily on simulated data, since we know everything about the true composition of these samples. There are dozens of DNA simulators aimed at benchmarking applications such as variant calling. And while the need for simulators is just as strong in RNA analysis, there are only a scant few RNA-Seq simulators available. Furthermore, the available RNA- Seq simulators are based on simplifying assumptions that greatly restrict their utility for benchmarking anything but the most upstream steps in the analysis pipeline (e.g. alignment). The further downstream the analysis method is, the more accurately the true nature of real data and its technical biases need to be modeled in order to draw meaningful conclusions. For example, no simulator generates data from a diploid genome, which would be necessary to evaluate allele specific quantification. Given our extensive experience with RNA-Seq analysis and transcriptomics in general, and our success at building the BEERS simulator, and our track record of authorship on all comprehensive RNA-Seq aligner benchmarking studies published to date, we are ideally situated to develop the next generation of open-source RNA-Seq simulator which aims to model all sources of technical variability. Furthermore, the simulator will model biological variability with an empirical approach based on using real data to configure the simulator’s parameters, which is a natural problem for machine learning. There are eleven steps in RNA-Seq library preparation which introduce bias, all of which will be modeled by the software in an object-oriented modular framework. Project Narrative: There have been many algorithms developed for every step of the RNA-Seq analysis pipeline with no easy way to compare between them. Simulated data are useful for this purpose, but to date there are very few RNA-Seq simulators available and all make too many simplifying assumptions to be used for anything but the most upstream steps in the pipeline, e.g. alignment. We propose to develop the next generation of open-source RNA-Seq simulator, which will capture all of the biochemical processes in a modular fashion and model all of the sources of technical variation.",The next generation of RNA-Seq simulators for benchmarking analyses,9730605,R21LM012763,"['Affect', 'Algorithms', 'Alleles', 'Alternative Splicing', 'Authorship', 'Basic Science', 'Benchmarking', 'Biochemical', 'Biochemical Process', 'Biochemical Reaction', 'Biological', 'Biological Models', 'Clinic', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'DNA-Directed DNA Polymerase', 'Data', 'Data Set', 'Development', 'Diploidy', 'Disease', 'Enzymes', 'European', 'Genetic', 'Genetic Transcription', 'Genome', 'Goals', 'Guanine + Cytosine Composition', 'Health', 'In Vitro', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Nature', 'Output', 'Preparation', 'Process', 'Protein Isoforms', 'Protocols documentation', 'PubMed', 'Public Domains', 'Publications', 'Publishing', 'RNA', 'RNA Splicing', 'RNA analysis', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Sequencing Biochemistry', 'Signal Transduction', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Transcript', 'Variant', 'Work', 'analog', 'analysis pipeline', 'base', 'biochemical model', 'design', 'digital', 'experience', 'experimental study', 'flexibility', 'indexing', 'next generation', 'open source', 'operation', 'power analysis', 'success', 'tool', 'transcriptome sequencing', 'transcriptomics']",NLM,UNIVERSITY OF PENNSYLVANIA,R21,2019,181125,-0.024434457774742617
"Improving Diagnosis of Multiple Sclerosis Through the Integration of Novel Imaging and Laboratory Biomarkers Project Summary/Abstract:  The diagnosis of multiple sclerosis (MS) remains challenging due to its clinical heterogeneity and lengthy differential diagnosis. The incorrect assignment of a diagnosis of MS occurs in approximately 9% of newly evaluated patients and is associated with considerable clinically important, and avoidable, medical risk, morbidity, and healthcare costs. At the same time studies have demonstrated that many patients encounter a significant diagnostic delay prior to confirmation of a correct diagnosis of MS. In such patients early and accurate diagnosis of MS can result in prompt initiation of disease modifying therapy and consequent preventable disability. MS remains a clinical diagnosis and diagnostic criteria for MS are revised periodically, including most recently in 2017. Since implementation of the 2017 criteria, like all prior revisions, will continue to rely on subjective clinical and radiological assessments for its fulfillment, misdiagnosis will remain a risk.  New objective, automated, and clinically applicable approaches to MS diagnosis are needed. Recent preliminary data from cross-sectional pilot studies in patients with established diagnoses have shown promise for three new radiographic and three new laboratory methods to differentiate MS from other disorders. The present study will evaluate these six methods for the first time in a prospective cohort of 125 patients undergoing an initial evaluation for MS at an academic MS subspecialty center. The specificity and sensitivity of each method will be compared to fulfillment of 2017 MS diagnostic criteria at the time of initial clinical evaluation. Using diagnostic thresholds developed from this analysis, a two year post-enrollment analysis will also be performed in participants who did not meet 2017 criteria initially but did so during the subsequent two year interval to determine if the study methods could have predicted a diagnosis of MS earlier in such patients. The use of a multimodal and machine-learning approach to evaluate the integration of each of these six new methods which represent different aspects of MS neuroinflammatory and neurodegenerative processes will also be performed during each analysis, and such a combination of radiographic and laboratory methodology may provide superior diagnostic accuracy compared to any given method alone.  Planned collaborative career development, mentoring, and advising activities will facilitate acquisition of specific advanced quantitative and qualitative research skills necessary to develop and coordinate collection of data for this large prospective cohort study to rigorously evaluate new diagnostic methods for MS and incorporate machine learning analyses. Successful completion of this study will provide experience and skills necessary to move the field of MS diagnosis forward through a planned prospective multicenter NIH R01 funded study. Project Narrative: A highly specific, sensitive, objective and automated novel diagnostic approach to multiple sclerosis (MS) is needed maximize early benefits of disease modifying therapy in patients with MS and to prevent the frequent problem of MS misdiagnosis. This project assesses three novel MRI techniques and three novel blood tests for the diagnosis of MS in a large prospective cohort undergoing a new clinical evaluation for suspect MS. While each method may show promise alone, utilization of machine learning methodology combining these approaches that represent different aspects of MS pathophysiology may demonstrate a highly accurate and clinically applicable methodology for MS diagnosis.",Improving Diagnosis of Multiple Sclerosis Through the Integration of Novel Imaging and Laboratory Biomarkers,9646600,K02NS109340,"['Algorithms', 'Appearance', 'Atrophic', 'Binding', 'Biological Assay', 'Biological Markers', 'Blood Tests', 'C-Peptide', 'Central Vein', 'Clinical', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic radiologic examination', 'Differential Diagnosis', 'Disease', 'Early Diagnosis', 'Enrollment', 'Erythrocytes', 'Evaluation', 'Evolution', 'Functional disorder', 'Funding', 'Gene Expression', 'Goals', 'Gold', 'Health Care Costs', 'Image', 'Inflammatory', 'Laboratories', 'Lesion', 'Light', 'Liquid substance', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Multiple Sclerosis', 'Myelin', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuronal Injury', 'Participant', 'Pathogenesis', 'Patients', 'Peptides', 'Pilot Projects', 'Process', 'Prospective cohort', 'Prospective cohort study', 'Qualitative Research', 'RNA', 'Rare Diseases', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Specificity', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Thalamic structure', 'Time', 'Training', 'United States National Institutes of Health', 'Untranslated RNA', 'Whole Blood', 'accurate diagnosis', 'career development', 'clinical Diagnosis', 'clinical application', 'clinical diagnostics', 'clinical heterogeneity', 'clinical phenotype', 'clinical practice', 'cohort', 'diagnostic accuracy', 'disability', 'disease heterogeneity', 'experience', 'gray matter', 'improved', 'learning strategy', 'multimodality', 'multiple sclerosis patient', 'neurofilament', 'neuroinflammation', 'novel', 'novel diagnostics', 'novel imaging technique', 'polypeptide C', 'prevent', 'prospective', 'recruit', 'research clinical testing', 'skills', 'specific biomarkers', 'white matter']",NINDS,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,K02,2019,193783,-0.011706356191380314
"An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis Project Summary  Improved methods for the bedside diagnosis and evaluation of neuromuscular disorders are needed. One technology that is finding increasing use for this purpose is electrical impedance myography (EIM). In EIM, a very weak, high frequency electrical current is passed through a muscle of interest and the resulting surface voltages are measured. Disease associated alterations in the composition and microstructural features of the muscle produce characteristic changes that can be used to help classify specific conditions and grade disease severity. To date, most studies using EIM analysis have utilized a fairly limited data set for disease assessment. While effective, this approach ignores a great deal of information locked within the impedance data, including those values that can assist in predicting specific muscle features (such as myofiber diameter) and the presence of pathological change (e.g., fat or connective tissue deposition). In addition, as it stands, the data set is challenging for the clinician to understand without a detailed knowledge of impedance theory. Myolex, Inc is a small business concern located in Boston, MA has as its main focus the development of EIM technologies for clinical use. Myolex recently completed a Phase 1 SBIR that demonstrated the potential capability of machine learning based classification algorithms to effectively discriminate healthy muscle from diseased and to discriminate one disease from another. In this proposed work, we will greatly advance this concept by embodying classification algorithms into a powerful new software suite for Myolex’s current EIM system, the mView. Our underlying hypothesis is that EIM data analysis can be automated to the point that classification systems can provide data on disease diagnosis as well as disease severity for improved ease-of-use. We propose to study this hypothesis via 2 specific aims. In Specific Aim 1, we will design a software suite capable of assisting with artifact-free data collection to be incorporated into our current EIM system, the mViewTM. Then using classification paradigms based on a prodigious amount of previous collected data, we will develop an automated data analysis tool to help provide data on disease category as well as microscopic features, muscle based on the impedance data alone using Microsoft’s Azure Cloud platform. In Specific Aim 2, we will test this developed software suite in a total of180 adult and pediatric neuromuscular disease patients and healthy participants evaluated at Ohio State University Wexner Medical Center (adults) and Boston Children’s Hospital (children). During this data collection period, the Ohio State and Boston Children’s researchers will have real- time access to Myolex staff to provide feedback and have questions/problems answered and addressed. The user interface will continue to be refined and classification algorithms improved. At the conclusion of this work, a new diagnostic tool will be developed for potential 510(k) FDA approval. It will serve as the basis for a continuously self-refining system as additional data sets are collected by end-users employing them in regular clinical use. Project Narrative  Electrical impedance myography (EIM) is a valuable technique to assist with the evaluation of a variety of conditions affecting nerve and muscle. However, to date, only simplistic EIM outcomes have been utilized to assess muscle condition. In this proposed work, we will develop a software platform using machine learning to be incorporated into current EIM technology to allow for automated diseased classification and characterization using the entire large EIM data set collected with each muscle measurement. This will serve as the basis for a new, powerful and convenient tool for neuromuscular diagnosis that will continue to advance over time.",An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis,9846955,R44NS113756,"['Address', 'Adult', 'Affect', 'Algorithmic Software', 'Amyotrophic Lateral Sclerosis', 'Area', 'Back Pain', 'Boston', 'Businesses', 'Caliber', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Classification', 'Clinical', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Set', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Duchenne muscular dystrophy', 'Effectiveness', 'Electrodes', 'Ensure', 'Evaluation', 'Fatty acid glycerol esters', 'Feedback', 'Fiber', 'Frequencies', 'Functional disorder', 'Health', 'Inclusion Body Myositis', 'Individual', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Medical Technology', 'Medical center', 'Methods', 'Microscopic', 'Morphologic artifacts', 'Muscle', 'Muscular Dystrophies', 'Myography', 'Myopathy', 'Myositis', 'Nerve', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Ohio', 'Outcome', 'Participant', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Provider', 'Radiculopathy', 'Research Personnel', 'Role', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Work', 'base', 'classification algorithm', 'cloud based', 'cloud platform', 'commercialization', 'data acquisition', 'design', 'diagnosis evaluation', 'disease classification', 'disease diagnosis', 'electric impedance', 'improved', 'indexing', 'interest', 'machine learning algorithm', 'method development', 'nerve injury', 'neuromuscular', 'novel diagnostics', 'pediatric patients', 'physical therapist', 'prototype', 'sarcopenia', 'software development', 'success', 'theories', 'tool', 'usability', 'user friendly software', 'user-friendly', 'voltage']",NINDS,"MYOLEX, INC.",R44,2019,621318,-0.002226455895009987
"Enabling Technology for Safe Robot-assisted Surgical Micromanipulation Project Summary  The goal of this grant is to develop enabling technology and systems that address fundamental limitations in microsurgery with a specific focus on vitreoretinal surgery. Due to the inherent micro-scale and the fragility of the neurosensory retina, vitreoretinal surgeons can be challenged by physiological hand tremor where the tremor amplitude is larger than retinal structures, delicate movements that are below tactile sensation, and multiple cognitive decisions that are required when executing high-risk movements, such as during retinal vein cannulation (RVC). Nevertheless currently vitreoretinal surgery is at the limits of human physiological performance and lacks the adequate technology that could further improve the technical performance. This situation is less than optimal and can significantly benefit from the recent advances in medical robotics, sensor feedback and human machine interface design. Robotic assistance may be ideally suited to address common problems encountered in the performance of the demanding micromanipulations in retinal microsurgery.  We propose a robotic system with enhanced real-time multisensory feedback that assesses multiple points of instrument contact located both inside and outside of the eye. Our comprehensive system will enable the surgeon to manipulate tools based on quantitative feedback that will prevent mechanical injury by implementing safeguards against the application of excessive and previously unmeasurable forces at the eyewall and the tool tip. Our aims are: (1) Develop and demonstrate in vivo position/force hybrid control algorithms for enabling real- time high-fidelity sensorimotor capabilities at the sclerotomy for safe robot-assisted vitreoretinal microsurgery: real-time sensorimotor capabilities at the sclerotomy will be uniquely used to control the robot through a machine learning method that adaptively learns a nonlinear mapping from user behavior to sclera-force/position and predicts unsafe motions; (2) Develop and demonstrate in vivo force-input control algorithms for enabling real- time high-fidelity sensorimotor capabilities at the tool-tip for safe robot-assisted vein cannulation: real-time tool- tip-to-tissue interaction force sensing and non-linear robot control algorithms based on observing the user behavior will be used to control the tool-tip position and force and to prevent entry into subretinal areas during RVC; (3) Demonstrate safe robot-assisted RVC in rabbit model in vivo: real-time, position/force hybrid control algorithms based on dual-point (tool-shaft and tip) information fusion will provide sensorimotor guidance of surgical maneuvers during RVC. Statistically significant results in vivo, in clinically realistic conditions will demonstrate the feasibility of our approach.  This highly innovative system will enable surgeons to perform maneuvers in a tremor free environment with a higher level of precision than previously possible and with the ability to sense forces on a scale that have been previously imperceptible. We envision this development as a logical next step in the integration of man, machine and computer for the performance of unprecedented microsurgical maneuvers. Project Narrative  This R01 grant addresses fundamental limitations in current microsurgical practice, focusing on vitreoretinal surgery (VRS), which is the most technically demanding ophthalmologic surgery. Our goal is to develop a cooperatively controlled robotic system with enhanced sensorimotor capabilities that in conjunction with multifunction force-sensing microsurgical instruments could enable safe robot-assisted retinal surgery. Although focused on VRS, our results will be applicable to a broader range of microsurgical training and practice.",Enabling Technology for Safe Robot-assisted Surgical Micromanipulation,9636559,R01EB023943,"['Address', 'Algorithms', 'Area', 'Behavior', 'Cannulations', 'Clinic', 'Clinical', 'Cognitive', 'Computers', 'Development', 'Disadvantaged', 'Discipline', 'Environment', 'Eye', 'Eye Movements', 'Feedback', 'Future', 'Goals', 'Grant', 'Hand', 'Healthcare', 'Hemorrhage', 'Histology', 'Human', 'Hybrids', 'Iatrogenesis', 'Injury', 'Intervention', 'Learning', 'Machine Learning', 'Manuals', 'Mechanics', 'Medical', 'Micromanipulation', 'Microsurgery', 'Miniaturization', 'Monitor', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Ophthalmologic Surgical Procedures', 'Ophthalmology', 'Optics', 'Oryctolagus cuniculus', 'Otorhinolaryngologic Surgical Procedures', 'Patients', 'Perception', 'Performance', 'Phase', 'Physiological', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Property', 'Reporting', 'Research', 'Research Proposals', 'Retina', 'Retinal', 'Retinal Hemorrhage', 'Retinal Perforations', 'Retinal Vein Occlusion', 'Robot', 'Robotics', 'Safety', 'Sclera', 'Site', 'Sterilization', 'Structure', 'Structure of central vein of the retina', 'Surgeon', 'Surveys', 'System', 'Tactile', 'Techniques', 'Technology', 'Time', 'Tissues', 'Touch sensation', 'Training', 'Tremor', 'User-Computer Interface', 'Veins', 'Vision', 'Work', 'adaptive learning', 'base', 'design', 'dexterity', 'high risk', 'improved', 'in vivo', 'in vivo Model', 'innovation', 'instrument', 'interest', 'learning strategy', 'man', 'medical specialties', 'multisensory', 'neurosensory', 'neurosurgery', 'operation', 'prevent', 'research clinical testing', 'robot assistance', 'robot control', 'robotic system', 'sensor', 'technological innovation', 'tool', 'trend', 'virtual']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2019,356164,-0.011089036486789144
"TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS ABSTRACT There is a growing interest in dietary patterns that capture the overall quality of diet as well as its constituent foods and nutrients. Commonly used dietary patterns are a priori diet score/index based on a set of dietary recommendations for a healthy diet (e.g., Mediterranean diet, Healthy Eating Index) or data-driven dietary patterns (e.g., prudent diet, western diet). Numerous studies have shown that those dietary patterns were related to the risk of chronic diseases such as heart disease, diabetes, and cancer. However, none of these dietary patterns incorporates eating behavior such as when we eat (i.e., eating time) and how often we eat (i.e. eating frequency) during a day. Since the amount of foods and nutrients consumed at one eating occasion influences the food consumption at the subsequent eating occasion and overall intake of the day, eating time and frequency are integral parts of dietary patterns. Furthermore, several lines of evidence consistently suggest that eating time and frequency as well as a meal composition play roles in body weight regulation and metabolic health and also regulate circadian rhythms, all of which may lead to metabolic dysfunctions and ultimately chronic diseases. Given a clear need to expand the dietary patterns framework and close a gap in dietary patterns methodological work, we propose to 1) develop a “temporal” dietary patterns based on temporal distribution of eating time and frequency during a day; and 2) evaluate if the identified temporal dietary patterns are associated with i) overall diet quality and nutrient intakes, ii) adiposity (e.g., BMI, waist circumference), and iii) metabolic biomarkers (e.g., insulin, HOMA-IR, LDL-cholesterol, c-reactive protein). To overcome a limitation that a conventional statistical method cannot capture multidimensional aspects of temporal dietary patterns (e.g., 24-dimensional feature vectors, multivariate dietary intake time-series data), we will use a novel approach combining nutrition and systems science—machine learning method. The Interactive Diet and Activity Tracking in AARP (IDATA) study that repeatedly collected diet, anthropometry, and blood samples from 1,021 men and women, 50-74 years old will be used. During one year, the IDATA study collected 24-hour recalls with clock time for each eating occasion, every other month (total six 24-hour recalls); measured anthropometry three times (baseline and at month 6 and 12); and collected blood twice, 6-month apart. Successful completion of our proposed study will identify temporal dietary patterns that are related to diet quality and metabolic health and validate the utility of temporal dietary patterns as a new tool for future research on diet-health relations and prevention of chronic diseases. NARRATIVE Eating behaviors and its impact on health are complex and multidimensional. The proposed study provides an excellent opportunity to develop new dietary patterns that capture eating behaviors such as when we eat and how often we eat during a day. The findings of the study about healthy eating patterns will also improve dietary recommendations by adding messages on when and how often to eat during a day.",TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS,9659103,R01CA226937,"['Advisory Committees', 'Affect', 'Algorithms', 'Animals', 'Anthropometry', 'Biological Markers', 'Blood', 'Blood specimen', 'Body Weight', 'C-reactive protein', 'Calories', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Circadian Rhythms', 'Complex', 'Consumption', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Diet Habits', 'Dietary Practices', 'Dietary intake', 'Dimensions', 'Eating', 'Eating Behavior', 'Energy Intake', 'Evaluation', 'Fasting', 'Fatty acid glycerol esters', 'Food', 'Frequencies', 'Health', 'Healthy Eating', 'Heart Diseases', 'Hour', 'Human', 'Individual', 'Insulin', 'Intake', 'LDL Cholesterol Lipoproteins', 'Lead', 'Machine Learning', 'Macronutrients Nutrition', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediterranean Diet', 'Metabolic', 'Metabolic dysfunction', 'Metabolic syndrome', 'Methodology', 'Modeling', 'Nutrient', 'Obesity', 'Outcome', 'Pattern', 'Persons', 'Physical activity', 'Play', 'Population', 'Positioning Attribute', 'Prevention', 'Recommendation', 'Regulation', 'Risk', 'Role', 'Science', 'Series', 'Statistical Methods', 'System', 'Techniques', 'Time', 'Waist-Hip Ratio', 'Weight maintenance regimen', 'Woman', 'Work', 'base', 'cardiovascular disorder risk', 'dietary guidelines', 'doubly-labeled water', 'epidemiology study', 'food consumption', 'good diet', 'improved', 'indexing', 'interest', 'learning strategy', 'men', 'novel', 'novel strategies', 'nutrient metabolism', 'nutrition', 'obesity risk', 'prudent diet', 'tool', 'vector', 'waist circumference', 'western diet']",NCI,WASHINGTON UNIVERSITY,R01,2019,347716,-0.013024199089438464
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,9737676,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Quality', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2019,804907,-0.017054325036819876
"3D temperature control to study biological processes Project Summary Temperature control technology is necessary for a broad range of biologically relevant processes including organ-on-chip operation, biomolecular kinetics, cell growth, studying gene function with temperature-sensitive mutations, cancer cell resistance to hyperthermia treatments, protein crystallization, and DNA analysis. Most biosensing devices lack the needed temperature measurement accuracy and precise temperature control to understand the thermal mechanisms of these processes. For example, temperature variations of 0.2°C can activate heat shock proteins, increasing the resistance of cancer cells to thermal ablation treatment, but reported temperature accuracies are often near ±1°C. This proposal aims to revolutionize the biomedical temperature measurement and control ecosystem by developing technology, models, and validated devices capable of microscopic, spatially resolved temperature sensing and control at ±0.1°C accuracy (10x better than what is used in most biosensing systems). Microfluidics is a promising technology for an extremely broad range of biomedical applications that notably lacks the necessary temperature accuracies and spatial temperature control to effectively study biothermal mechanisms. This proposal intends to impact human health by developing disruptive temperature control tools to accelerate biomedical innovation in thermally sensitive processes. Our group recently demonstrated the capacity to measure temperature at a single point with fluorescent dyes, achieving a ±0.05°C noise floor by using machine learning techniques. We have also 3D printed a cell-based genotype and phenotype assay device with cell growth chambers, monoliths for mRNA capture & fluorescence measurement, and integrated pumps and valves in a volume of only 2.2 mm × 2.2 mm × 1 mm. Aims 1 and 2 of this proposal will build on these successes by developing 3D printing technologies that easily incorporate complex temperature sensing, heating, and cooling channels, coupled with multi-physics/CAD models to rapidly iterate through the prototype development cycle. These advances will be used in Aim 3 to construct a microscopically temperature-controlled chip to measure DNA melt curves to determine the zygosity of a Factor 5 Leiden. This will show that the technology can detect the subtle difference in melting temperature that is undetectable by most PCR machines, as a proof-of-concept before the technology can be applied to other biological process. The overall objective of these studies is to develop a suite of affordable technologies researchers can use to understand biothermal mechanisms to lay the foundation for advances in disease diagnosis, treatment, and prevention. Project Narrative The instruments we use to study the effects of temperature on biological processes are less accurate than humans’ own ability to perceive temperature changes. The proposed research will develop improved microscopic temperature sensing & control technologies and demonstrate them by performing DNA analysis in a 3D printed device. Because the technology is cheap and accurate, it will be widely accessible to any lab, increasing our ability to understand the fundamental role biothermal processes have in disease occurrence, diagnosis, and treatment.",3D temperature control to study biological processes,9732034,R15GM132868,"['3-Dimensional', '3D Print', 'Automation', 'Biochemistry', 'Biological', 'Biological Assay', 'Biological Process', 'Biomedical Research', 'Biosensing Techniques', 'Blood specimen', 'Cells', 'Complex', 'Coupled', 'Crystallization', 'Custom', 'DNA', 'DNA analysis', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Ecosystem', 'Electrical Engineering', 'Engineering', 'Environment', 'Factor Analysis', 'Factor V', 'Floor', 'Fluorescence', 'Fluorescent Dyes', 'Foundations', 'Future', 'General Population', 'Genotype', 'Geometry', 'Goals', 'Grant', 'Health', 'Heat Stress Disorders', 'Heat shock proteins', 'Heating', 'High temperature of physical object', 'Hour', 'Human', 'Hyperthermia', 'Institution', 'Kinetics', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Messenger RNA', 'Microfluidic Analytical Techniques', 'Microfluidic Microchips', 'Microfluidics', 'Microscopic', 'Modeling', 'Mutation', 'Noise', 'Outcome', 'Performance', 'Persons', 'Phenotype', 'Physics', 'Plant Resins', 'Prevention', 'Printing', 'Process', 'Proteins', 'Pump', 'Quantum Dots', 'Reagent', 'Reporting', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Risk', 'Role', 'Sampling', 'Shapes', 'Single Nucleotide Polymorphism', 'Source', 'Spatial Distribution', 'System', 'Techniques', 'Technology', 'Temperature', 'Temperature Sense', 'Testing', 'Thermal Ablation Therapy', 'Thermometry', 'Thermoreceptors', 'Thromboembolism', 'Training', 'Variant', 'Venous', 'Work', 'base', 'biological systems', 'cancer cell', 'career', 'cell growth', 'computer science', 'design', 'disease diagnosis', 'experience', 'gene function', 'graduate student', 'hyperthermia treatment', 'improved', 'improved outcome', 'innovation', 'innovative technologies', 'instrument', 'melting', 'new technology', 'operation', 'organ on a chip', 'prototype', 'sensor', 'sensor technology', 'success', 'tool', 'undergraduate student']",NIGMS,BRIGHAM YOUNG UNIVERSITY,R15,2019,439058,-0.04036576223030978
"SCH: INT: Conversations for Vision: Human-Computer Synergies in Prosthetic Interactions  The project will investigate prosthetic support for people with visual impairment (PVI) that integrates computer vision-based prosthetics with video-mediated human-in-the-loop prosthetics. Computer vision- based (CV) prosthetics construe the fundamental technical challenge for visual prosthetics as one of parsing and identifying objects across scales, distances, and orientations. Visual prosthetic applications have been central drivers in the development of computer vision technology through the past 50 years. Video-mediated remote sighted assistance (RSA) prosthetics are more recent, enabled by different technologies, and construe the orienting technical challenge for visual prosthetics as one of effective helping interactions. RSA services are commercially available now, and have evoked much excitement in the PVI community. The two approaches, CV and RSA, will be successively integrated through a series of increasingly refined Wizard of Oz simulations, and investigate possible synergies between the two approaches. We will employ a human-centered design approach, identifying a set of key assistive interaction scenarios that represent authentic needs and concerns of PVIs, by leveraging our 6-year relationship working directly with our local chapter of the National Federation of the Blind. RELEVANCE (See Instructions): 23.7 million American adults have vision loss; 1.3 million people in US are legally blind. This project addresses a transformational opportunity to enhance human performance and experience, to diversify workplace participation, and to enhance economic and social well-being. n/a",SCH: INT: Conversations for Vision: Human-Computer Synergies in Prosthetic Interactions ,9928587,R01LM013330,"['Address', 'Adult', 'American', 'Articulation', 'Back', 'Blindness', 'Communities', 'Computer Vision Systems', 'Computers', 'Data Set', 'Development', 'Economics', 'Emotional', 'Female', 'Goals', 'Human', 'Information Sciences', 'Instruction', 'Mediating', 'Modeling', 'Ocular Prosthesis', 'Performance', 'Prosthesis', 'Route', 'Self-Help Devices', 'Series', 'Services', 'Social Well-Being', 'Technology', 'Time', 'Underrepresented Students', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'design', 'experience', 'graduate student', 'human-in-the-loop', 'learning materials', 'legally blind', 'outreach', 'prototype', 'simulation', 'synergism', 'undergraduate student']",NLM,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2019,225147,-0.02095939501022066
"Evaluation of multiple medication exposures concurrently using a novel algorithm PROJECT SUMMARY The development of large observational health databases (OHD) has expanded the data available for analysis by pharmacoepidemiology research. The efficiency of these studies may be improved by simultaneously studying the association of multiple medications with a disease of interest. Unfortunately, prior research has demonstrated that it is difficult to distinguish true-positive from false-positive results when studying multiple exposures simultaneously, thus limiting the conclusions drawn from these types of studies and representing a major gap in the field. The objective of this proposal, which is the first step in achieving the applicant's long- term goal of improving the diagnosis and treatment of gastrointestinal diseases using insights derived from OHD, is to evaluate and validate medication class enrichment analysis (MCEA), a novel set-based signal-to- noise enrichment algorithm developed by the applicant to analyze multiple exposures from OHD with high sensitivity and specificity. The central hypothesis of this proposal is that MCEA has equal sensitivity and greater specificity compared to logistic regression, the most widely used analytic method for OHD, for identifying true associations between medications and clinical outcomes. The applicant will complete the following two interrelated specific aims to test the hypothesis: Aim 1 – to calculate the sensitivity and specificity of medication class enrichment analysis (MCEA) and logistic regression (LR) for identifying medication associations with Clostridium difficile infection (CDI) and Aim 2 – to calculate the sensitivity and specificity of MCEA and LR for identifying medication associations with gastrointestinal hemorrhage (GIH). The rationale for these aims is that by reproducing known medication-disease associations without false positives, MCEA can be used to identify novel pharmacologic associations with gastrointestinal diseases in future studies. The expected outcome for the proposed research is that it will demonstrate MCEA as a valid method for pharmacoepidemiology research, opening new research opportunities for the study of multi-exposure OHD. These new research opportunities may lead to more rapid identification of potential pharmacologic causes of emerging diseases and discovery of unanticipated beneficial medication effects, allowing such medications to be repurposed for new indications. To attain the expected outcome, the applicant will complete additional coursework that builds on his Master of Science in Clinical Epidemiology to learn computational biology, machine learning, and econometrics techniques. With the support of this grant and his institution, he will also directly apply these techniques to pharmacoepidemiology applications under the close mentorship of a carefully selected team of faculty with extensive experience in gastroenterology, pharmacoepidemiology, medical informatics, and mentoring prior K-award grant recipients. Through these activities, the applicant will develop the skills necessary to obtain NIH R01-level funding and become a leader in developing novel techniques for application to the epidemiologic study of gastrointestinal diseases. PROJECT NARRATIVE Traditionally, research studying medications associated with diseases are limited to analyzing one medication at a time. This novel proposal will validate medication class enrichment analysis, a recently developed algorithm to study multiple medications simultaneously for association with a disease of interest. Validation of this method will allow researchers to use existing medical databases to more rapidly identify potential medication causes of emerging diseases and identify medications with unanticipated beneficial effects, allowing such medications to be repurposed for new indications.",Evaluation of multiple medication exposures concurrently using a novel algorithm,9645854,K08DK119475,"['Address', 'Algorithms', 'Aminoglycosides', 'Antibiotics', 'Anticoagulants', 'Antiplatelet Drugs', 'Big Data to Knowledge', 'Biological', 'Carbapenems', 'Case-Control Studies', 'Cephalosporins', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Computational Biology', 'Computer software', 'Data', 'Databases', 'Development', 'Development Plans', 'Diagnosis', 'Digestive System Disorders', 'Disease', 'Electronic Health Record', 'Epidemiologic Methods', 'Evaluation', 'Faculty', 'Fluoroquinolones', 'Funding', 'Future', 'Gastroenterology', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Generations', 'Genomics', 'Goals', 'Grant', 'Health', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'K-Series Research Career Programs', 'Lead', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Master of Science', 'Medical', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Noise', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Penicillins', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Research', 'Research Design', 'Research Personnel', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Techniques', 'Testing', 'Time', 'United Kingdom', 'United States National Institutes of Health', 'Validation', 'Veterans', 'analytical method', 'base', 'beta-Lactams', 'career development', 'clinical epidemiology', 'econometrics', 'epidemiology study', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'interest', 'novel', 'research study', 'simulation', 'skills', 'usability']",NIDDK,UNIVERSITY OF PENNSYLVANIA,K08,2019,169440,-0.026908611274504782
"SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data Abstract Over 30 million people in the US suffer from genetic diseases or cancers caused by mutations of which ~15% disrupt the regulation of splicing. Alternative splicing (AS) errors have been reported in literature to drive 370 genetic diseases out of ~800 described to date. In addition, due to the recent success of FDA-approved splicing modulators like Nusinersen, along with fascinating pre- clinical results underlining the importance of AS as therapeutic targets; splicing research has become of major interest to pharmaceutical companies. Envisagenics is developing SpliceCoreTM, an innovative cloud-based software platform using biomedical big data for AS analysis to discover new therapies and biomarkers for complex diseases. Our breakthrough platform combines algorithms and databases developed and experimentally validated at Cold Spring Harbor Laboratory (CSHL): SpliceTrapTM, for the detection of splicing activity using RNA-seq data; SpliceDuoTM, for the identification of significant splicing variation across biological samples; SpliceImpact2TM, for the prioritization of biologically relevant AS variants with therapeutic potential; and TXdbTM, a splicing isoform database that connects client’s proprietary data to public repositories such as the Cancer Genome Atlas (TCGA). Thanks to the Phase I award SpliceCore was adapted as a cloud-based software, accelerating scalability and adaptation to the fast- evolving market of biomedical Big Data. We now have deployed SpliceCore’s back-end on three cloud-service providers, increased its overall run-time by a factor of 12, developed tools to discover disease-specific AS isoforms, finalized and tested a machine-learning algorithm to predict the biological impact of AS, and experimentally validated some of our new predictions with a success rate of 82.5%. The goal for Phase II is to accelerate client acquisition through the development of user-interactive applications informed from client’s feedback by substantially expanding the platform’s knowledgebase and predictive functions with novel AS isoforms extracted from ~37,000 public datasets. Thus, a new version of SpliceCore will be developed to predict regulatory interactions between RNA-binding proteins and their RNA targets to assist in the interpretation of aberrant splicing factors through a collaboration with world renowned HHMI Professor Dr. Tom Tuschl from Rockefeller University and developer of Nusinersen, Professor Dr. Adrian Krainer from CSHL. Envisagenics is targeting the global bioinformatics market valued at $4 billion in 2014 with a CAGR of over 21%. SpliceCore could capture ~10% of the market, identify novel drug targets, and design RNA therapeutics from aberrant splicing events prevalent in cancer and a multitude of genetic diseases while increasing the efficiency of R&D in biopharma. Project Narrative In this SBIR Phase II, Envisagenics will advance the development of SpliceCoreTM, a cloud-based software platform for the discovery of drug-targets and biomarkers using biomedical big data. Therapeutic screens are increasingly focusing on Alternative Splicing (AS), a biological process that regulates gene-product structure and function. Strikingly, 50% of genetic diseases described in literature can be triggered by AS errors. The recent FDA approval of RNA-therapeutic compounds to correct AS errors, combined with increasingly available big datasets and groundbreaking cloud-computing provide a unique opportunity for computerized discovery of AS therapeutics. Envisagenics’ technology will help biomedical researchers to translate basic science into new therapeutic products for cancer and genetic diseases. By the completion of this project, we will deploy a user-friendly, secured and scalable SpliceCore software, with new functionalities ready for integration into biopharmaceutical Research & Development workflows.",SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data,9677178,R44GM116478,"['Achievement', 'Advanced Development', 'Affect', 'Algorithms', 'Alternative Splicing', 'Amyotrophic Lateral Sclerosis', 'Award', 'Back', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Products', 'Cancer Etiology', 'Client', 'Cloud Computing', 'Cloud Service', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Databases', 'Defect', 'Detection', 'Development', 'Disease', 'Drops', 'Drug Targeting', 'Dysmyelopoietic Syndromes', 'Ensure', 'Event', 'FDA approved', 'Face', 'Failure', 'Feedback', 'Food and Drug Administration Drug Approval', 'Frequencies', 'Genetic Diseases', 'Genotype-Tissue Expression Project', 'Goals', 'Growth', 'Imagery', 'Immunoprecipitation', 'Infrastructure', 'Laboratories', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Meta-Analysis', 'Methods', 'Mutation', 'Nucleotides', 'Pathway interactions', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Predictive Analytics', 'Prevalence', 'Price', 'Privatization', 'Probability', 'Protein Binding Domain', 'Protein Isoforms', 'Protein Splicing', 'RNA', 'RNA Splicing', 'RNA-Binding Protein FUS', 'RNA-Binding Proteins', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Ribonucleosides', 'Risk', 'Running', 'SRSF2 gene', 'Sampling', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Specificity', 'Spinal Muscular Atrophy', 'Structure', 'System', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Universities', 'Validation', 'Variant', 'Work', 'big biomedical data', 'cancer genetics', 'case control', 'cloud based', 'commercial application', 'computerized', 'cost', 'crosslink', 'data mining', 'data warehouse', 'design', 'drug discovery', 'experimental study', 'fascinate', 'flexibility', 'gene product', 'human disease', 'improved', 'innovation', 'interest', 'knowledge base', 'learning strategy', 'machine learning algorithm', 'new therapeutic target', 'novel', 'novel therapeutics', 'petabyte', 'pre-clinical', 'preclinical study', 'predictive modeling', 'professor', 'repository', 'research and development', 'service providers', 'success', 'system architecture', 'targeted biomarker', 'therapeutic RNA', 'therapeutic target', 'tool', 'transcriptome sequencing', 'user-friendly']",NIGMS,"ENVISAGENICS, INC.",R44,2019,517226,-0.04967716387576125
"Accelerating Multi-modal Biomarker Discovery in Translational Research with Cloud Data Integration Project Summary/Abstract Cytobank is the leading cloud-based platform for analysis and storage of single cell flow and mass cytometry data, technologies that are essential for investigating the interplay between the immune system and disease conditions including cancer. There are numerous data analysis steps between raw data and insight especially for many single-cell technologies, where the data analysis is complex, highly expert-driven and/or reliant on novel computational methodologies. Cytobank already makes major contributions (1) centralizing single-cell cytometry data, (2) providing data analysis traceability that removes knowledge sharing complexities, and (3) establishing a platform that increases access to cutting edge algorithms and makes complex machine learning methods easy for biologists to use. However, as the amount, complexity, and different types of single cell data and other associated data increases and the number of workflows and single-cell algorithms to analyze the data also increases, the need for open and easy access to existing and new tools and secure, complete storage of the workflows and the resulting data has increased to the point of being critical for supporting basic and translational research collaborations and enabling them to efficiently achieve their objectives including biomarker discovery and development. The proposed project significantly extends the capabilities of the Cytobank platform. This will benefit the community by (1) enabling scalable and secure access to a number of new single-cell data analysis tools that will result in new automated workflows, and (2) enable more efficient cross platform knowledge generation with increased meta-analysis capabilities across experiments and data types. The potential of this project is that thousands of scientists around the world will be able to more easily leverage additional single-cell cytometry, transcript, and other data in their translational research data analysis including automating analysis that has primarily been dominated by expert-driven annotation, thus providing a central repository and knowledge management framework that will accelerate biomarker discovery and precision medicine. Project Narrative Single-cell biology and Immunotherapy are exploding and generating larger and more complex datasets in combination clinical trials. To take full advantage of these revolutions, the iteration and dissemination of advanced single-cell data analysis algorithms (many of whose development was funded by the NIH) needs to scale at the same rate as single-cell data generation technologies are scaling, and multi-omics data analysis and visualization must be integrated and automated. This project will greatly accelerate scientific research, transparency, and reproducibility by significantly lowering the barrier to perform complex data analysis of multiple types of high-dimensional data, providing the biomedical research community with access to powerful tools needed in immuno-oncology, autoimmunity and other high-impact disease areas.",Accelerating Multi-modal Biomarker Discovery in Translational Research with Cloud Data Integration,9672504,R44GM117914,"['Algorithmic Analysis', 'Algorithms', 'Area', 'Autoimmunity', 'B-Cell Acute Lymphoblastic Leukemia', 'Basic Science', 'Biological Markers', 'Biomedical Research', 'Cells', 'Cellular biology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Follicular Lymphoma', 'Foundations', 'Funding', 'Generations', 'Immune System Diseases', 'Immune system', 'Immunologic Monitoring', 'Immunology', 'Immunooncology', 'Immunotherapy', 'Information Resources Management', 'Knowledge', 'Label', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Meta-Analysis', 'Modality', 'Modeling', 'Multiomic Data', 'Outcome', 'Patients', 'Phase', 'Population', 'Positioning Attribute', 'Regimen', 'Relapse', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Scientist', 'Secure', 'System', 'Target Populations', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Toxic effect', 'Transcript', 'Translational Research', 'Treatment Efficacy', 'United States National Institutes of Health', 'Work', 'anti-cancer', 'automated analysis', 'base', 'biomarker development', 'biomarker discovery', 'biomarker validation', 'clinically actionable', 'cloud based', 'cost effective', 'cytokine', 'data integration', 'data management', 'data visualization', 'experimental study', 'high dimensionality', 'immunotherapy trials', 'improved', 'insight', 'learning strategy', 'multidimensional data', 'multimodal data', 'multimodality', 'novel', 'outcome prediction', 'personalized medicine', 'population based', 'precision medicine', 'predict clinical outcome', 'predictive marker', 'predictive modeling', 'relapse prediction', 'repository', 'response', 'single cell analysis', 'single cell technology', 'single-cell RNA sequencing', 'synergism', 'tool', 'transcriptome sequencing', 'transcriptomics', 'tumor']",NIGMS,"CYTOBANK, INC.",R44,2019,652516,-0.026524607774253646
"Intelligent Virtual Reality Curriculum for Personalized Surgical Training PROJECT SUMMARY The problems with current surgical training paradigms include the failure of opportunities for training to keep up with rising demands; surgeons in practice often have limited time and resources to practice, leading to risky usage of more complex technologies. Successful utilization of virtual reality (VR) in surgical training has led to the wide-spread adoption of such systems in General Surgery training programs; however, the focus on high-fidelity, near-real-life environments has made the methodology prohibitively expensive and inaccessible. This resource intensiveness has resulted in generalized VR modules that do not target specific procedures or skills. Considering the increasing number of new and complex devices coming onto the market and the direct link between volume of procedures and surgical expertise, the healthcare field must see a radical shift in the use of surgeon training technology in order to maximize quality training time before trainees enter the workforce. The current state of VR is ill-fit to be a true surgical training supplement as it cannot fulfil this need. Osso VR is developing a solution to this issue: The Smart Curriculum, a purposefully low-fidelity VR-based training curriculum that incorporates an artificial intelligence (AI) to adapt the session and curriculum to a trainee’s performance. A low-fidelity approach has been shown in pilot studies to have equal transfer rates compared to high-fidelity while being much less resource-intensive, thus making it ideal for broadening the accessibility of VR. An AI to customize a procedure to a surgeon’s performance and background will provide targeted practice to hone procedure familiarity and surgical skill. Thus, the combination of VR and AI will show increased transfer rates compared to classic VR paradigms at a fraction of the cost. Practicing surgical techniques on-demand with direct quantitative feedback plays an essential part in developing the needed expertise to a) improve the quality of the outcomes for patients and b) improve efficiency in the surgical technique thereby reducing the operating time. The work proposed in this Phase I project will focus on developing a proof-of-concept AI-incorporated module for the treatment of hip fractures with a cephalomedullary fixation device as a proof-of-concept. The proposed system will allow orthopedic surgeons to enhance their training in a virtual environment and predict the outcome of interventional decisions before actual surgery without any risks to the patients. The work plan for this Phase I SBIR project will be accomplished by first establishing all key subject matter and technical needs for the cephalomedullary fixation procedure to determine key learning milestones for a pilot procedure; second, we will determine the parameters for and wireframe the AI; finally, we will build necessary technical components for the prototype training module to validate the pilot procedure. Osso VR is the current leader in the field, and the addition of an AI component to individualize each surgeon’s training experience will be invaluable to revolutionizing the surgical training paradigm. The proposed project is a purposefully low-fidelity virtual-reality-based surgical training curriculum that incorporates an artificial intelligence to adapt the session and curriculum to a trainee’s performance. This technology will provide new surgeons with targeted practice to hone their procedural familiarity and surgical skill to improve proficiency, thus reducing training costs and operating time, and improving surgical outcomes for patients.",Intelligent Virtual Reality Curriculum for Personalized Surgical Training,9778500,R43EB028203,"['Adoption', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Big Data', 'Clinical', 'Complex', 'Consult', 'Controlled Environment', 'Country', 'Custom', 'Development', 'Devices', 'Educational Curriculum', 'Effectiveness', 'Engineering', 'Environment', 'Failure', 'Familiarity', 'Feedback', 'Healthcare', 'Hip Fractures', 'Industry', 'Intelligence', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Link', 'Manuals', 'Methodology', 'Modality', 'Movement', 'Operating Rooms', 'Operative Surgical Procedures', 'Orthopedics', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Play', 'Preparation', 'Problem Solving', 'Procedures', 'Reporting', 'Research', 'Resources', 'Risk', 'Sample Size', 'Small Business Innovation Research Grant', 'Statistical Data Interpretation', 'Surgeon', 'System', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Training Activity', 'Training Programs', 'Transferable Skills', 'Validation', 'Work', 'base', 'cost', 'design', 'experience', 'experimental study', 'falls', 'improved', 'innovation', 'outcome prediction', 'pedagogy', 'prototype', 'rehearsal', 'sample fixation', 'simulation', 'skills', 'surgery outcome', 'tool', 'training opportunity', 'virtual reality']",NIBIB,"OSSO VR, INC.",R43,2019,215545,-0.001379060043998617
"Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence Abstract Enzyme functionality is a critical component of all life systems. Whereas advances in experimental methodology have enabled a better understanding of factors that control enzyme function, critical components of the reaction space such as highly unstable intermediates and transition states are best accessed for evaluation through computational simulations. Similarly, computational methodology continues to provide a key resource for probing excited-state processes such as bioluminescence. Combined ab initio quantum mechanical molecular mechanical (ai-QM/MM) simulations are, in principle, the preferred choice in the modeling of both processes. But ai-QM/MM modeling of enzymatic reactions is now severely limited by its computational cost, where a direct ai-QM/MM free energy simulation of an enzymatic reaction can take 500,000 or more CPU hours. Meanwhile, ai-QM/MM modeling of firefly bioluminescence is also hindered by the computational accuracy, where it has yet to produce quantitatively correct predictions for the bioluminescence spectral shift with site-directed mutagenesis. The goal of this proposal is to accelerate ai-QM/MM simulations of enzymatic reaction free energy and to improve the quality of ai-QM/MM-simulated bioluminescence spectra, so that ai-QM/MM simulations can be routinely performed by experimental groups. This will be achieved via a) using a lower-level (semi-empirical QM/MM) Hamiltonian for sampling; b) an enhancement to the similarity between the two Hamiltonians by calibrating the low-level Hamiltonian using the reaction pathway force matching approach, in conjunction with several other methods. The expected outcomes of this collaborative effort include: a) advanced methodologies for accelerated reaction free energy simulations and accurate bioluminescence spectra predictions, which will be released through multiple software platforms; b) a fundamental understanding of reactions such as Kemp elimination and polymerase-eta catalyzed DNA replication; c) a deeper insight into the role of macromolecular environment in the modulation of enzyme catalytic activities or bioluminescence wavelengths, which can further enhance our capability of designing new enzymes and bioluminescence probes. Narrative This project aims to develop quantum-mechanics-based computational methods to more quickly model enzymatic reactions and more accurately model bioluminescence spectra. It will lead to reliable and efficient computational tools for use by the general scientific community. It will facilitate the probe of enzymatic reaction mechanisms and the computer-aided design of new bioluminescence probes.",Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence,9864664,R01GM135392,"['Adopted', 'Biochemical Reaction', 'Bioluminescence', 'Calibration', 'Communities', 'Computer Simulation', 'Computer software', 'Computer-Aided Design', 'Computing Methodologies', 'DNA biosynthesis', 'DNA-Directed DNA Polymerase', 'Electrostatics', 'Environment', 'Enzymes', 'Evaluation', 'Fireflies', 'Free Energy', 'Freedom', 'Generations', 'Goals', 'Hour', 'Ions', 'Life', 'Machine Learning', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Multienzyme Complexes', 'Outcome', 'Pathway interactions', 'Polymerase', 'Process', 'Protocols documentation', 'Quantum Mechanics', 'Reaction', 'Resources', 'Role', 'Sampling', 'Site-Directed Mutagenesis', 'System', 'Temperature', 'Thermodynamics', 'Time', 'base', 'computerized tools', 'cost', 'design', 'experimental group', 'improved', 'innovation', 'insight', 'multi-scale modeling', 'mutant', 'quantum', 'simulation', 'theories']",NIGMS,UNIVERSITY OF OKLAHOMA NORMAN,R01,2019,269849,-0.02272406109198158
"Expert Guiding Technology to Help Individuals with Developmental Challenges Build Life and Vocational Skills Applied Behavior Analysis (ABA) remains the most effective and scientifically-validated approach to remediate the deficits due to Autism Spectrum Disorders (ASD) and intellectual disabilities (ID). There are serious challenges in delivering effective ABA: unavailability of effective treatment in many places; high instructor turnover; loss of program fidelity due to complexity and instructor variability; onerous data collection that directs attention away from the learner; and the time sink of creating required reports and charts that steals time away from instructional activities. A software platform named GAINS (Guidance, Assessment and Information System) is being developed that uniquely incorporates artificial intelligence to overcome problems in delivering ABA. GAINS is powered by expert guiding software that incorporates knowledge of ABA practice and curricula personalized for the individual with developmental challenges. Like Google Maps that guides you step-by-step and updates as you go along, GAINS guides instructors and caregivers and adapts to client responses on the fly. In this way, expert guiding technology reduces a priori training requirements in ABA while providing real- time apprenticeship coaching to overcome variability in instructor experience and improve program fidelity. Improved program fidelity promotes better learning outcomes of individuals with ASD and ID. The project will evaluate and iteratively innovate expert guiding technology to support the powerful, but difficult to implement, ABA technique of Task Analysis (TA). There are two overarching aims: 1) conduct scientifically-valid, clinical trials to evaluate the efficacy of expert guiding technology to support instructors to better help individuals with developmental challenges due to ASD and ID learn life and vocational skills and use the results in Phase I to develop larger, more comprehensive clinical trials to be conducted in Phase II; and 2) use clinical trials in Phase I and Phase II to more effectively identify and prioritize iterative innovations in expert guiding technology as part of successive Design Science Research Cycles. Single Case Research Designs (SCRD) will be used to evaluate expert guiding technology interventions to support Task Analysis. SCRDs are a viable alternative to large group studies such as randomized clinical trials. Single case studies involve repeated measures, and manipulation of an independent variable. SCRD studies allow for rigorous experimental evaluation of intervention effects and provide a strong basis for establishing causal inferences. Advances in design and analysis techniques for SCRD have made SCRD studies increasingly popular in educational and psychological research. Chimes Delaware will be the site for clinical trials. Chimes Delaware is one of the largest providers of community services for adults with intellectual, autism, and co-occurring disabilities. The project team has worked together for many years and is uniquely qualified. If successful, the increase of scientifically-validated technical capabilities of expert guiding technology will profoundly affect clinical practice. The clinical trials proposed in this project will provide new scientific knowledge on the efficacy of expert guiding technology to overcome problems in delivering quality ABA therapy. Iterative innovations of expert guiding technology will greatly increase the technical capabilities. If successful, the increase of scientifically-validated technical capabilities of expert guiding technology will profoundly affect clinical practice.",Expert Guiding Technology to Help Individuals with Developmental Challenges Build Life and Vocational Skills,9846769,R43MH121230,"['Adoption', 'Adult', 'Affect', 'Artificial Intelligence', 'Behavior', 'Caregivers', 'Case Study', 'Child', 'Client', 'Clinical', 'Clinical Trials', 'Community Services', 'Complex', 'Computer software', 'Conduct Clinical Trials', 'Cues', 'Data', 'Data Collection', 'Decision Modeling', 'Delaware', 'Development', 'Educational Curriculum', 'Evaluation', 'Failure', 'Gold', 'Hand', 'Health', 'Individual', 'Information Systems', 'Instruction', 'Intellectual functioning disability', 'International', 'Intervention', 'Knowledge', 'Learning', 'Learning Disabilities', 'Life', 'Maps', 'Measures', 'Names', 'Phase', 'Provider', 'Psychological reinforcement', 'Randomized Clinical Trials', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Science', 'Techniques', 'Technology', 'Theft', 'Time', 'Toothbrushing', 'Toothpaste', 'Training', 'Update', 'Work', 'applied behavior analysis', 'apprenticeship', 'autism spectrum disorder', 'base', 'board certified behavior analyst', 'clinical practice', 'clinical research site', 'cost effective', 'design', 'directed attention', 'disability', 'effective therapy', 'experience', 'field study', 'improved', 'innovation', 'innovative technologies', 'instructor', 'intervention effect', 'learning outcome', 'member', 'programs', 'psychologic', 'response', 'skills', 'task analysis']",NIMH,GUIDING TECHNOLOGIES CORPORATION,R43,2019,282159,-0.05754252797859716
" SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track) The overall objective of this Fast-Track SBIR contract project is to develop DigiBioMarCTM (Digital BioMarkers for Clinical Impact), a scalable and flexible cloud-based platform to capture and analyze wearable, implantable, or external device data. This platform also provides an informatics tool for automated data aggregation, integration, and machine learning algorithms. It is based on the scalable user-centered Medable platform, which implements standardization and normalization of patient-generated data to drive health insights. DigiBioMarCTM will compare and combine disparate data streams to understand contextualized patient physiology in real time in order to identify disease and/or detect changes in disease/health status. It also will support cohort and clinical studies, particularly those testing digital biomarkers from wearable sensor technologies. This Fast-Track project will focus on product development with an ultimate aim of a product that improves cancer research data and clinical trials, enhances clinical care, and that can be used to engage patients in preventive health behaviors and treatment adherence. The Phase I goal is to develop a data-agnostic DigiBioMarCTM prototype for validation in Phase II. The Phase 1 Go/No-Go decision point to proceed to Phase II will be a working prototype with specified features for further development and validation in Phase II. n/a", SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track),9952269,61201800010C,"['Biological Markers', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Computer software', 'Contracts', 'Data', 'Data Aggregation', 'Development', 'Devices', 'Disease', 'Documentation', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Patients', 'Phase', 'Physiology', 'Preventive', 'Publishing', 'Reporting', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Standardization', 'Stream', 'System', 'Testing', 'Time', 'Validation', 'anticancer research', 'base', 'behavioral adherence', 'clinical care', 'cloud based', 'digital', 'flexibility', 'graphical user interface', 'improved', 'informatics\xa0tool', 'insight', 'knowledge base', 'machine learning algorithm', 'product development', 'prototype', 'sensor', 'skills', 'tool', 'treatment adherence', 'wearable sensor technology']",NCI,"MEDABLE, INC.",N43,2019,1499800,-0.011694717450635375
"PhendoPHL:A Data-Science Enabled Personal Health Library to Manage Endometriosis PROJECT SUMMARY Endometriosis is a chronic condition which is estimated to affect 10% of women in reproductive age. It has a very high burden on quality of life and productivity, and the self-management needs of women living with the disease are multiple. This project aims to design, develop, and evaluate a data-science enabled personal health library called PhendoPHL to support the self-management needs of women living with endometriosis. Grounded in self-determination theory, and informed by user-centered design methods PhendoPHL will enable exploration of health patterns through interactive visualizations of integrated clinical and self-tracked data, identify temporal personalized patterns and comparison to population norms through novel data-science methods, and provide actionable visualizations of data for shared decision making during patient-provider encounters. PhendoPHL builds on our existing work in novel informatics methods for endometriosis, and the extensive experience of our research team in designing and evaluating novel informatics interventions. The proposed work also fills a research gap in personal health informatics: the development and validation of novel computational methods to identify personalized and population- based patterns in clinical and self-monitoring data; both types of data which are critical to successful self- management and challenging from a computational standpoint because they are temporal, heterogeneous, and sparse. Using a mixed-methods evaluation study (standardized surveys, logfile analysis, Critical Incident Technique interviews, focus groups), we will study PhendoPHL’s usability, assess the factors critical to user engagement and perceived impact on self-determination and shared decision making, and the generalizability to other reproductive chronic conditions in women’s health. PROJECT NARRATIVE This project aims to design, develop, and validate a data-science enabled personal health library called PhendoPHL to support the self-management needs of women living with endometriosis. Grounded in self- determination theory, PhendoPHL will enable exploration of health patterns through interactive visualizations of integrated clinical and self-tracked data, identify temporal personalized patterns and comparison to population norms through novel data-science methods, and provide actionable visualizations of data for shared decision making during patient-provider encounters.",PhendoPHL:A Data-Science Enabled Personal Health Library to Manage Endometriosis,9670533,R01LM013043,"['Affect', 'Age', 'Anxiety', 'Arthralgia', 'Behavior', 'Chronic', 'Clinical', 'Clinical Data', 'Competence', 'Complex', 'Computing Methodologies', 'Critical Incident Technic', 'Data', 'Data Science', 'Development', 'Disease', 'Eating', 'Evaluation', 'Evaluation Studies', 'Fatigue', 'Focus Groups', 'Goals', 'Health', 'Imagery', 'Individual', 'Informatics', 'Information Systems', 'Intervention', 'Interview', 'Knowledge', 'Libraries', 'Machine Learning', 'Methodology', 'Methods', 'Monitor', 'Moods', 'Outcome', 'Pain', 'Participant', 'Patients', 'Pattern', 'Perception', 'Population', 'Productivity', 'Provider', 'Public Health Informatics', 'Quality of life', 'Reporting', 'Research', 'Self Determination', 'Self Management', 'Signs and Symptoms', 'Soy Sauce', 'Specialist', 'Standardization', 'Steam', 'Strategic Planning', 'Stream', 'Surveys', 'Symptoms', 'Time', 'Time Series Analysis', 'Time trend', 'United States National Institutes of Health', 'Validation', 'Vision', 'Visit', 'Woman', 'Women&apos', 's Health', 'Work', 'base', 'data visualization', 'design', 'endometriosis', 'experience', 'experimental study', 'girls', 'interest', 'novel', 'peer', 'population based', 'recruit', 'reproductive', 'shared decision making', 'theories', 'usability', 'user centered design']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,352350,-0.014142719637951627
"Objective assessment of surgical competence in a septoplasty model DESCRIPTION (provided by applicant): To ensure patient safety, educators must train surgeons to set standards of competency, public health officials should put in place policies to ensure surgeons remain competent and surgeons should only perform surgeries that they are competent to perform. Measuring surgeon's technical skill is crucial part of determining if they are competent. Traditionally surgical skill is assessed most commonly during training using subjective non-validated metrics. This leads to variation in the definition of competency. Recent policies set forth by the Accreditation Council of Graduate Medical Education- the governing body for graduate medical education, mandate that technical skill be measured objectively. Currently, there are few valid objective measures available to measure technical competence. Our research will yield a set of tools and methodologies that can be deployed to across medical training programs to objectively measure surgical skill and competence. This platform is also capable of developing new objective measure of skill and competence. Specifically, first, we will develop an objective skills assessment platform, and establish standard data collection and quality assurance protocols for systematic deployment of our platform across multiple institutions. Second, our work will result in automated algorithms and analytic tools to objectivel measure skill using data captured with our platform. Third, we will establish objective methods to determine whether a surgeon is competent to perform surgery. Fourth, we will test the reliability and validity of our assessment tools. We will conduct our study using septoplasty as the prototype test-bed procedure. Septoplasty is a commonly performed procedure (more than 260,000 cases per year) and is a key index surgery by which residents in otolaryngology are evaluated. Our project lays the groundwork for subsequent research to establish national standards for objective skill and competency using data aggregated from numerous training programs in the country. PUBLIC HEALTH RELEVANCE: Policies for graduate medical education require that surgical competency be objectively determined, but currently available technology and methods do not yield objective assessments for surgical skill. Our project aims to provide educators with an integrated objective skills assessment platform and tools for objective determination of competency, which can be readily deployed across graduate surgical training programs in the country.",Objective assessment of surgical competence in a septoplasty model,9751078,R01DE025265,"['Accreditation', 'Address', 'Algorithmic Software', 'American', 'Area', 'Assessment tool', 'Beds', 'Cessation of life', 'Competence', 'Computer Assisted', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Collection', 'Data Quality', 'Data Set', 'Ensure', 'Evaluation', 'Exploratory/Developmental Grant for Diagnostic Cancer Imaging', 'Foundations', 'Inferior', 'Infrastructure', 'Institution', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Otolaryngology', 'Patient Care', 'Patient-Focused Outcomes', 'Phase', 'Philosophy', 'Physicians', 'Pilot Projects', 'Policies', 'Postoperative Complications', 'Predictive Value', 'Procedures', 'Protocols documentation', 'Public Health', 'Quality Control', 'Repeat Surgery', 'Research', 'Research Support', 'Residencies', 'Site', 'Surgeon', 'System', 'Technical Expertise', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Validity and Reliability', 'Validity of Results', 'Variant', 'Work', 'analytical tool', 'base', 'graduate medical education', 'high risk', 'hospital readmission', 'indexing', 'inter-institutional', 'patient safety', 'portability', 'programs', 'prototype', 'public health relevance', 'quality assurance', 'skills', 'success', 'tool']",NIDCR,JOHNS HOPKINS UNIVERSITY,R01,2019,464082,0.004235940448360421
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9761481,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2019,873369,-0.006100154503884509
"Acceleration techniques for SimSET SPECT simulations Abstract The Simulation System for Emission Tomography (SimSET) is one of the foundational tools for emission tomography research, used by hundreds of researchers worldwide for both positron emission tomography (PET) and single photon emission computed tomography (SPECT). It has proven to be accurate and efficient for both PET and low energy SPECT studies; because SimSET uses a geometric model for its SPECT collimation, it is less accurate for high energy isotopes. This application proposes to address this with the use of angular response functions (ARFs), a technique that has proven to accurately model SPECT collimation and detection for high-energy isotopes more efficiently than full photon-tracking simulations. In addition, we propose a novel ARF-based importance sampling method that will speed these simulations by a factor of >50. The generation of ARF tables is another consideration: it is extremely compute intensive and has caused ARF to be used only when a large number of simulations are needed using the same isotope/collimator/detector combination. For this reason, we also propose application of importance sampling to speed the generation of ARF tables by a factor 5, and the creation of a library of angular response functions for popular isotope/collimator/detector combinations. The former will lessen the computational cost of generating the tables, the latter will, for many users/uses, eliminate the need to generate ARF tables at all. This will greatly expand the potential applications of ARF-based simulations. Our first aim is to accelerate SimSET SPECT simulations without sacrificing accuracy. This will be accomplished by synergistically utilizing two tools: variance reduction and angular response function (ARF) tables. Variance reduction includes importance sampling and forced detection. We hypothesis that these techniques combined with information from our angular response function tables will improve SimSET simulation efficiency by >50 times of SPECT simulations of specific radioisotopes (e.g., I-123, Y-90, etc.). Our second aim is to accelerate ARF table generation. This will be accomplished by using importance sampling methods in the generation of ARFs. We further propose to use an adaptive stratification scheme that will simulate photons for a given table position only as long as required to determine its value to a user-specified precision. Our third aim is to create a library of pre-calculated ARF tables for popular vendor isotope/collimator/detector configurations. These ARF tables will then be made publically available for download through the SimSET website. With a registered user base of >500, we believe that these enhancements to SimSET will have far reaching impact on research projects throughout the world. Narrative The overall goal of this work is to develop methods to speed up the SimSET Monte Carlo-based simulation software for single photon computed tomography (SPECT) imaging systems by greater than 50-fold. This type of speed up with enable new research that was previously impractical due to the computation time required for simulation. In addition, all software tools and tables developed within this project will be made available via a web-based host.",Acceleration techniques for SimSET SPECT simulations,9751297,R03EB026800,"['90Y', 'Acceleration', 'Address', 'Algorithms', 'Collimator', 'Communities', 'Consumption', 'Crystallization', 'Data', 'Detection', 'Foundations', 'Future', 'Generations', 'Goals', 'Industrialization', 'Institution', 'Isotopes', 'Libraries', 'Location', 'Machine Learning', 'Medical Research', 'Methods', 'Modeling', 'Online Systems', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Probability', 'Radioisotopes', 'Research', 'Research Personnel', 'Research Project Grants', 'Running', 'Sampling', 'Scheme', 'Software Tools', 'Specific qualifier value', 'Speed', 'Stratification', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Vendor', 'Weight', 'Work', 'X-Ray Computed Tomography', 'base', 'cost', 'detector', 'imaging system', 'improved', 'interest', 'novel', 'response', 'simulation', 'simulation software', 'single photon emission computed tomography', 'synergism', 'thallium-doped sodium iodide', 'tomography', 'tool', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R03,2019,77750,-0.04074236621731467
"Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation Project Summary Neonatal endotracheal intubation (ETI) is a time-sensitive resuscitation procedure! essential for ventilation of newborns. It requires an unusually high level of skill due to the narrow airways, relatively large tongue, anterior glottic position, and low respiratory reserve of neonates (Bercic, Pocajt et al. 1978). Given the difficulty of the procedure and the high rate of complications in untrained hands, effective training is crucial. However, intubation success rates for pediatric residents are low under current resuscitation training programs and show little improvement between years 1-3 of residency (23-25%) (O'Donnell, Kamlin et al. 2006; Haubner, Barry et al. 2013). There is a pressing need to understand the factors that lead to poor training results and for innovative training modalities that can bridge the gap left by traditional training and thereby allow rapid skill acquisition. We hypothesize that current training and assessment methods suffer from 4 key weaknesses: (1) Poor realism: manikin and simulator-based training typically provide little variation in anatomy or difficulty level—key requirements for developing expertise (Dreyfus, Athanasiou et al. 1986)—and do not realistically model the look, feel, and motions of real tissue. (2) Subjective, highly variable, and resource-intensive assessment methods: training opportunities are limited by the availability of expert instructors. (3) Poor visualization: learners have poor knowledge about what went wrong and how to improve; they cannot see exactly what is going on inside the manikin or the patient and cannot directly monitor their actions relative to idealized, expert performance. (4) Assessment under artificially ideal conditions: assessments of ETI performance in classroom settings likely overestimate trainees' skill level because they do not mimic the stressors and distractions that are inherent in the real clinical environment. Technology-enhanced ETI simulators can resolve all of these key weaknesses: We have conducted preliminary work (Hahn, Li et al. 2016; Soghier, Li et al. 2014) on an augmented reality (AR (Azuma 1997)) manikin simulator driven by the motions of the trainee and physical manikin in real time that 1) provides a quantitative assessment of ETI technique and 2) allows the trainee to visualize the motion of the laryngoscope inside the manikin. The assessment score can provide feedback during the performance, as well as constitute part of the evaluation of the trainee's skill. Work under this proposal will build on this preliminary work. The specific aims are to: extend the current augmented reality (AR) manikin simulator to a virtual reality (VR) computer simulator and validate, extend and validate automated assessment and visualization algorithm for ETI, study training effectiveness by testing groups of pediatric residents across 3 years to quantify the effect of technology-enhanced methods relative to the current training regimen in terms of both intubation performance on simulators and clinical outcomes in patients, and assess performance under more realistic conditions. Project Narrative The current training and assessment of neonatal endotracheal intubation (ETI) suffers from key weaknesses of 1) poor realism of task simulators, 2) subjective, highly variable, and resource-intensive assessment methods, 3) poor visualization during simulation, and 4) assessment methods under artificially ideal conditions. This high-yield proposal will bridge the gap between training and clinical practice by using quantitative assessment tools and technology-enhanced simulation to improve ETI performance prior to patient care.",Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation,9732337,R01HD091179,"['Algorithms', 'Anatomy', 'Anterior', 'Assessment tool', 'Attention', 'Augmented Reality', 'Biomedical Engineering', 'Biometry', 'Childhood', 'Clinical', 'Cognitive Science', 'Computer Simulation', 'Computers', 'Data', 'Effectiveness', 'Enhancement Technology', 'Environment', 'Environmental air flow', 'Evaluation', 'Feedback', 'Hand', 'Imagery', 'Intratracheal Intubation', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Lead', 'Learning', 'Left', 'Libraries', 'Machine Learning', 'Manikins', 'Measures', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Neonatal', 'Neonatology', 'Newborn Infant', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Procedures', 'Regimen', 'Residencies', 'Resources', 'Resuscitation', 'Scanning', 'Standardization', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Tongue', 'Training', 'Training Programs', 'Validation', 'Variant', 'Work', 'base', 'clinical practice', 'computer science', 'distraction', 'evidence base', 'haptics', 'improved', 'innovation', 'instructor', 'kinematics', 'multidisciplinary', 'neonate', 'respiratory', 'simulation', 'skill acquisition', 'skills', 'stressor', 'success', 'training opportunity', 'virtual reality']",NICHD,GEORGE WASHINGTON UNIVERSITY,R01,2019,318886,-0.0033003311910998917
"Stasys Medical: A Rapid, Microfluidic Blood Test Sensitive to Platelet Dysfunction PROJECT SUMMARY/ABSTRACT Antiplatelet medications are a critical component to manage cardiovascular diseases (CVD), which is a prevalent affliction in the US. While monitoring platelet therapy is of increasing importance for the identification of hypo- or hyper-responsive patients, there is not a clear picture of the medical value of tailored antiplatelet therapy using currently available platelet function tests. Currently, US FDA cleared assays of platelet function designed to be near the patient measure platelet adhesion and aggregation. Stasys Medical is developing a system based on patented platelet contraction sensors to assay platelet contraction force as a biomarker for platelet dysfunction. In the current project, the Company will build on preliminary data to demonstrate that the force biomarker is sensitive to platelet inhibition via multiple pathways. Specifically, aims are designed to 1) correlate the platelet contractile force measurements to inhibition of platelet activation and adhesion pathways, and 2) benchmark the force assay to standard platelet function tests. The go/no-go criteria for moving to Phase II is demonstration that platelet force is sensitive to specific inhibitors and that the assay can identify platelet dysfunction currently missed by existing standard platelet function assays. In the Phase II project we will leverage data generated in the current project to develop an algorithm that can automatically identify antiplatelet medications. Clinically, this will be a valuable tool to identify medication non-responders. Taken together, the project will be used to support the Company’s 510(k) submission to FDA with claims directed at evaluating platelet function to assess clinical conditions, such as bleeding risk, associated with the use of antiplatelet drugs, and during and following cardiovascular surgery. PROJECT NARRATIVE Antiplatelet medications are a critical component to manage cardiovascular diseases (CVD), which is a prevalent affliction in the US. In the Phase I project, Stasys Medical will build on preliminary data to show that the platelet contraction force biomarker reflects platelet function as proof-of-concept that the force assay can identify platelet dysfunction missed by existing assays. The Phase II project will leverage Phase I results to develop an algorithm using machine learning techniques that can automatically identify antiplatelet medications to identify medication non-responders.","Stasys Medical: A Rapid, Microfluidic Blood Test Sensitive to Platelet Dysfunction",9681062,R43HL142318,"['Acute Coronary Event', 'Adhesions', 'Adverse event', 'Affect', 'Agonist', 'Algorithms', 'Antiplatelet Drugs', 'Aspirin', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Blood Platelets', 'Blood Tests', 'Blood Volume', 'Blood specimen', 'Cardiovascular Diseases', 'Cardiovascular Surgical Procedures', 'Cardiovascular system', 'Catheterization', 'Clinical', 'Clot retraction', 'Consensus', 'Coronary', 'Data', 'Devices', 'Functional disorder', 'Generations', 'Hemorrhage', 'Hemostatic function', 'Impairment', 'Integrins', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Microfluidics', 'Monitor', 'Myosin ATPase', 'Optical Instrument', 'Pathway interactions', 'Patient risk', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Platelet Activation', 'Platelet Function Tests', 'Population', 'Procedures', 'Randomized', 'Receiver Operating Characteristics', 'Risk', 'Shapes', 'Site', 'Stents', 'System', 'Techniques', 'Testing', 'Thromboxanes', 'Training', 'Validation', 'Whole Blood', 'base', 'design', 'flexibility', 'high risk population', 'inhibitor/antagonist', 'injured', 'nanonewton', 'off-patent', 'operation', 'patient response', 'platelet function', 'point of care', 'response', 'sensor', 'success', 'tool', 'wound']",NHLBI,STASYS MEDICAL CORPORATION,R43,2019,224945,-0.009431966115597287
"Personalizing Glaucoma Diagnosis by Disease Specific Patterns and Individual Eye Anatomy Project Summary/Abstract Glaucoma is a disease of the optic nerve which is accompanied by visual ﬁeld (VF) loss. While accurate VF loss diagnosis and the detection of its progression over time is of high relevance to clinical practitioners as it indicates the initiation of or change in ocular therapy, there is no consensus on objective measures for this purpose, and VF measurements are known to be often unreliable. The main objective of this project is to develop clinically applicable measures to improve the diagnosis of glaucomatous VF loss and of its progression by two approaches: First, the identiﬁcation of representative loss patterns and their progression, achieved by large-scale, customized bioinformatical procedures applied to data from glaucoma patients from nine clinical centers and second, the inclusion of eye and patient speciﬁc personalized parameters. In total, 480,486 VFs, are available for this project. One major aim is to develop novel diagnostic indices based on computationally identiﬁed evolution patterns of VF loss, particularly (1) an index that denotes the probability of glaucomatous vision loss and (2) an index that assigns probabilities to a VF that follow-up measurements will be in a certain defect class. The indices will be statistically evaluated on separate VF samples and compared to existing approaches. Routinely available patient speciﬁc parameters which are candidates to impact glaucomatous vision loss are patient ethnicity, type of glaucoma, spherical equivalent (SE) of refractive error and the location of the blind spot relative to ﬁxation. The effect of these parameters on the vision loss patterns will be systematically studied. The impact of their inclusion in the novel diagnostic indices and their potential improvement on glaucoma diagnosis will be quantiﬁed on a separate data set. A further aim is the calculation of a spatial map speciﬁc to a measured VF that represents the preferred VF locations of future defects as well as their reliability as an aid to event-based progression diagnosis. A second major objective is the investigation of the relationship of VF loss and individual parameters related to retinal structure, based on retinal nerve ﬁber layer thickness (RNFLT) measurements around the optic disc. The inter-relationship of representative patterns of RNFLT and its decrease over time with trajectories of major retinal arteries, SE, and blind spot location is systematically studied, and the impact on patterns of VF loss is quantitatively analyzed with the goal to improve the interpretation of existing VF loss and to predict future glaucomatous vision loss. Main contributions of the project with relevance to clinical practice are publicly available open-source software implementations of new diagnostic indices and maps, enhanced by individual functional and structural parameters, and a detailed and personalized model for the relationship between retinal structure and glaucomatous vision loss. Project Narrative Glaucoma is an ocular disease accompanied by vision loss which may progress over time up to total blindness, but the assessment of glaucomatous vision loss is noisy, and it is often hard for clinical practitioners to decide whether changes over time reﬂect true changes of functional vision or are the result of normal measurement variations or artifacts. This project contributes directly and immediately to public health by exploring the impact of individual anatomical parameters on the spatial patterns of glaucomatous vision loss in order to improve the diagnosis of vision loss and of its progression. Main objective of the project is the development of new quantitative diagnostic indices, implemented as publicly available software.",Personalizing Glaucoma Diagnosis by Disease Specific Patterns and Individual Eye Anatomy,9802123,R01EY030575,"['Anatomy', 'Atrophic', 'Axon', 'Bioinformatics', 'Blindness', 'Clinical', 'Cluster Analysis', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Ethnic Origin', 'Event', 'Evolution', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Hemorrhage', 'Impairment', 'Individual', 'Investigation', 'Length', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Modeling', 'Morphologic artifacts', 'Nerve Fibers', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Probability', 'Procedures', 'Public Health', 'Refractive Errors', 'Retinal', 'Retinal Defect', 'Retinal Ganglion Cells', 'Retinal blind spot', 'Sampling', 'Structure', 'Structure-Activity Relationship', 'System', 'Thick', 'Time', 'Variant', 'Vision', 'Visual Fields', 'Work', 'base', 'central retinal artery', 'clinical application', 'clinical practice', 'disease diagnosis', 'follow-up', 'fovea centralis', 'improved', 'indexing', 'multidisciplinary', 'neglect', 'novel diagnostics', 'open source', 'optic nerve disorder', 'outcome forecast', 'retinal nerve fiber layer', 'sample fixation', 'sex']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,R01,2019,534037,-0.022499403816887954
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9741471,R01DE027027,"['3-Dimensional', 'Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2019,367570,-0.01246562605029165
"Elucidating Sensorial and Functional Characteristics of Topical Formulations Abstract In addition to the defined therapeutic effect caused by an active drug in a product, there is also a placebo and, potentially, a nocebo effect associated with that product. In topical products, these latter effects may account for 30% to 50% of the overall response for some products. They may also explain why some topical products with apparently identical bioavailability are associated with different patient outcomes. This application seeks to address the question of when do subtle excipient and manufacturing changes in a topical product cause a sensorial perception by subjects such that the “feel” of a product has changed either before and/or after it is applied to human skin. A second question is whether the “feel” of a product both before and after application can be quantified by instrumental rheology, tribology and texture analysis methods and whether these, in turn, can be related to the reported sensorial behaviour. We will manufacture topical formulations that systematically vary in Q1, Q2, and/or Q3 attributes and have large and borderline perceptive differences. We will then characterize these products using a range of rheology, tribology and texture analysis methods along with characterization of rate of drying, particle and globule size. In parallel, these products will be evaluated by perceptive testing focus groups, with controls, for their sensory properties or the ‘feel’ of the products. We will then relate these sensorial findings with the variations in formulation nature, composition and manufacture, and their resulting instrumental test results. Our goals are, firstly, to understand the relationships between product nature, instrumental findings and sensorial analyses and, secondly, to derive criteria for instrument tests that indicate what product composition subjects suggest do not differ, uncertain if they differ and do differ in their sensorial behaviour. It is anticipated that we can define the simplest, robust test that accurately and robustly aligns with sensory perceptions. A range of statistical methods, including (potentially) sophisticated, machine learning and deep learning tools will then be used to model the most appropriate instrumental analysis that can, with reasonable confidence predict perceptive attributes. A key outcome is a potential regulatory guideline advocating that generic products should exhibit similar sensorial behaviour as a reference listed drug product, giving boundaries in rheology, tribology and texture analysis as defined by Q1, Q2 and Q3 differences when sensorial behaviour between topical products is likely to be different. Narrative Generic and reference-listed topical products have the potential to have differing placebo and nocebo effects, i.e. effects beyond those of the active drug. This project aims to understand what subtle changes in Q1,Q2 or Q3 between different product formulations lead to a subject reporting sensorial perceptions suggesting that the “feel” of two product is either different or they can no longer perceive a meaningful difference. Compositions (reference and generic) will be manufactured with variations in Q1, Q2 and Q3, characterised by instrumental measures and the results related to sensorial analysis findings.",Elucidating Sensorial and Functional Characteristics of Topical Formulations,9913611,U01FD006700,[' '],FDA,UNIVERSITY OF QUEENSLAND,U01,2019,250000,-0.022596793836138662
"Augmented Reality Platform for Feedback and Assessment in STEM elementary education ABSTRACT This SBIR Phase I project will build evidence-based content, challenges and assessments that promote: simulation-based learning; troubleshooting and critical-thinking; and diversity and inclusion in STEM learning. The approach will be transferable by design to teaching and measuring learner performance across scientific disciplines. Emerging digital content in virtual (VR) and augmented reality (AR) is already transforming science, technology, engineering, and math (STEM) education from the abstract and static learning models of the past to the applied and dynamic learning experiences of the future. These technologies have promise in delivering simulation environments capable of nurturing deep learning and higher-level thinking in K-12 students through practical experience, hand-on exercises and real-life applications, such as troubleshooting. Digital AR and VR educational content is beginning to address and develop these skills, but a platform has yet to be developed to effectively enable broad adoption in elementary settings. Cost efficient methods to provide formative feedback and gather summative evaluations for Next Generation Science Standards (NGSS) is also an unmet need. The successful completion of the proposed project will provide an evidence-centered content delivery and assessment framework as well as tool for addressing NGSS performance expectations that is transferable across topic areas and readily scalable for large-scale national implementation. The content will intentionally incorporate aspects of context and diversity of characters to ensure inclusion of groups that are historically underrepresented – specifically females and ethnic minorities. NARRATIVE Success in the workforce of the future will require the high-level thinking skills that the Next Generation Science Standards (NGSS) emphasize. Emerging digital content in virtual (VR) and augmented reality (AR) is transforming science and engineering education from the abstract and static learning models of the past to the applied and dynamic learning experiences of the future, through practical simulation-based experiences, but these lack the capability for performance assessment crucial to teachers and decision makers. By providing a readily scalable and flexible platform, the proposed approach promises to accelerate access to high-quality, inclusive, and evidence-centered AR content delivery and assessment of NGSS standards which in turn provides students with the skills they need for success.",Augmented Reality Platform for Feedback and Assessment in STEM elementary education,9847434,R43GM134813,"['Address', 'Adoption', 'Area', 'Augmented Reality', 'Award', 'Businesses', 'Career Choice', 'Child', 'Critical Thinking', 'Data', 'Development', 'Discipline', 'E-learning', 'Education', 'Educational process of instructing', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Exercise', 'Feedback', 'Female', 'Funding', 'Future', 'Hand', 'Indiana', 'Industry', 'K-12 student', 'Learning', 'Life', 'Longevity', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Next Generation Science Standards', 'Output', 'Perception', 'Performance', 'Phase', 'Problem Solving', 'Process', 'Reporting', 'Research', 'SECTM1 gene', 'Science', 'Science, Technology, Engineering and Mathematics', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Small Business Innovation Research Grant', 'Students', 'System', 'Technology', 'Testing', 'Thinking', 'Translating', 'Universities', 'Validation', 'Woman', 'Writing', 'Youth', 'base', 'cost efficient', 'deep learning', 'design', 'digital', 'digital media', 'educational atmosphere', 'engineering design', 'ethnic minority population', 'evidence base', 'expectation', 'experience', 'flexibility', 'girls', 'innovation', 'interest', 'mathematical learning', 'mobile application', 'pedagogy', 'prototype', 'simulation', 'simulation game', 'skills', 'success', 'teacher', 'theories', 'tool', 'virtual', 'virtual reality']",NIGMS,"EXPLORE INTERACTIVE, LLC",R43,2019,295622,-0.03137648619186028
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9653180,R01EY025332,"['3-Dimensional', 'Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2019,416574,-0.012116934805377266
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,9881453,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2019,397500,-0.026444684081169328
"Socioeconomic status, stress, and smoking cessation PROJECT SUMMARY/ABSTRACT  The prevalence of electronic nicotine delivery systems (ENDS) is rising dramatically among both adults and youth and ENDS use is fast becoming a major public health issue. However, because of their recent emergence, researchers know little about ENDS, their use, their effects on human physiology and health, their risks and benefits, or their impact on tobacco control efforts. A common barrier to studying ENDS is the lack of data on objective, real world use of ENDS. Thus, the proposed project aims to adapt existing innovative mobile assessment tools that can be used to target critical ENDS research gaps by providing mobile sensing technology that can objectively collect precise data regarding ENDS use in real time in real world. Specifically, the proposed revision project will expand the scope of Project On Track (1R01CA190329-01A1, PI: Wetter) by extending the application of puffMarker, an existing tool that automatically detects smoking, for the assessment of ENDS use. The current project has three aims: 1) adapt and validate puffMarker to identify discrete episodes of ENDS use, 2) adapt and validate puffMarker to distinguish between cigarette smoking and ENDS use among dual users of ENDS and cigarettes, and 3) utilize the Project On Track protocol to collect real time, real world data investigating potential determinants of ENDS use among both exclusive ENDS users as well as dual users of cigarettes and ENDS. Altogether, 120 participants (30 for Aim 1, 30 for Aim 2, and 60 for Aim 3) will be enrolled. Participants recruited for Aims 1 and 2 will attend laboratory (three 2-hour sessions) and field (3 days) studies. In the laboratory sessions, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke a cigarette (Aim 2). Participants' ENDS and cigarette puffs will be recorded by an independent observer. In the field studies, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke cigarettes (Aim 2). Participants will be asked to record each instance of ENDS use or cigarette smoking on a SP. The goals of the laboratory studies are to collect data to train puffMarker to identify ENDS use and to distinguish between cigarette smoking and ENDS use. The goal of the field studies is to validate puffMarker in real-life, natural environments. Aim 3 will utilize the Project On Track protocol to collect the first real time, real world data on ENDS and dual use. Participants will be assessed for 6 days using AutoSense, EMA, and GPS to examine potential determinants of ENDS use. A validated puffMarker that detects ENDS use and distinguishes between ENDS use and smoking can enhance many areas of research inquiry on ENDS. Knowledge learned from Aim 3 will be essential for the development of comprehensive conceptual models with respect to ENDS use and smoking cessation. PROJECT NARRATIVE The proposed project aims to develop an innovative tool that targets important ENDS research gaps by offer- ing researchers the latest mobile sensing technology to objectively collect precise data regarding ENDS use and distinguish between ENDS use and smoking in real time and in real world.","Socioeconomic status, stress, and smoking cessation",9754578,R01CA190329,"['Abstinence', 'Acute', 'Address', 'Adult', 'Algorithms', 'Area', 'Assessment tool', 'Behavior', 'Behavioral', 'Benefits and Risks', 'Big Data to Knowledge', 'Breathing', 'Cellular Phone', 'Characteristics', 'Chest', 'Cigarette', 'Data', 'Detection', 'Development', 'Ecological momentary assessment', 'Electronic Nicotine Delivery Systems', 'Enrollment', 'Environment', 'Environmental Risk Factor', 'Geography', 'Gestures', 'Goals', 'Grain', 'Hand', 'Harm Reduction', 'Health', 'High School Student', 'Hour', 'Human', 'Individual', 'Infrastructure', 'Inhalation', 'Knowledge', 'Laboratories', 'Laboratory Study', 'Life', 'Longitudinal cohort study', 'Machine Learning', 'Measures', 'Modeling', 'Movement', 'Oral cavity', 'Participant', 'Patient Recruitments', 'Pattern', 'Physiological', 'Physiology', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Process', 'Protocols documentation', 'Public Health', 'Questionnaires', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Sensitivity and Specificity', 'Sensory', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Social Environment', 'Socioeconomic Status', 'Stress', 'System', 'Technology', 'Time', 'Training', 'United States National Institutes of Health', 'Wireless Technology', 'Wrist', 'Youth', 'addiction', 'arm movement', 'base', 'biobehavior', 'built environment', 'cigarette smoke', 'cigarette smoking', 'cigarette user', 'data to knowledge', 'experience', 'field study', 'innovation', 'novel', 'parent grant', 'population health', 'primary outcome', 'programs', 'psychosocial', 'real time monitoring', 'recruit', 'respiratory', 'sensor', 'sensor technology', 'smoking cessation', 'social', 'systems research', 'tobacco control', 'tobacco products', 'tool', 'uptake', 'wearable device', 'young adult']",NCI,UNIVERSITY OF UTAH,R01,2019,581251,-0.010792510623091122
"Socioeconomic status, stress, and smoking cessation PROJECT SUMMARY/ABSTRACT  The prevalence of electronic nicotine delivery systems (ENDS) is rising dramatically among both adults and youth and ENDS use is fast becoming a major public health issue. However, because of their recent emergence, researchers know little about ENDS, their use, their effects on human physiology and health, their risks and benefits, or their impact on tobacco control efforts. A common barrier to studying ENDS is the lack of data on objective, real world use of ENDS. Thus, the proposed project aims to adapt existing innovative mobile assessment tools that can be used to target critical ENDS research gaps by providing mobile sensing technology that can objectively collect precise data regarding ENDS use in real time in real world. Specifically, the proposed revision project will expand the scope of Project On Track (1R01CA190329-01A1, PI: Wetter) by extending the application of puffMarker, an existing tool that automatically detects smoking, for the assessment of ENDS use. The current project has three aims: 1) adapt and validate puffMarker to identify discrete episodes of ENDS use, 2) adapt and validate puffMarker to distinguish between cigarette smoking and ENDS use among dual users of ENDS and cigarettes, and 3) utilize the Project On Track protocol to collect real time, real world data investigating potential determinants of ENDS use among both exclusive ENDS users as well as dual users of cigarettes and ENDS. Altogether, 120 participants (30 for Aim 1, 30 for Aim 2, and 60 for Aim 3) will be enrolled. Participants recruited for Aims 1 and 2 will attend laboratory (three 2-hour sessions) and field (3 days) studies. In the laboratory sessions, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke a cigarette (Aim 2). Participants' ENDS and cigarette puffs will be recorded by an independent observer. In the field studies, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke cigarettes (Aim 2). Participants will be asked to record each instance of ENDS use or cigarette smoking on a SP. The goals of the laboratory studies are to collect data to train puffMarker to identify ENDS use and to distinguish between cigarette smoking and ENDS use. The goal of the field studies is to validate puffMarker in real-life, natural environments. Aim 3 will utilize the Project On Track protocol to collect the first real time, real world data on ENDS and dual use. Participants will be assessed for 6 days using AutoSense, EMA, and GPS to examine potential determinants of ENDS use. A validated puffMarker that detects ENDS use and distinguishes between ENDS use and smoking can enhance many areas of research inquiry on ENDS. Knowledge learned from Aim 3 will be essential for the development of comprehensive conceptual models with respect to ENDS use and smoking cessation. PROJECT NARRATIVE The proposed project aims to develop an innovative tool that targets important ENDS research gaps by offer- ing researchers the latest mobile sensing technology to objectively collect precise data regarding ENDS use and distinguish between ENDS use and smoking in real time and in real world.","Socioeconomic status, stress, and smoking cessation",9829886,R01CA190329,"['Abstinence', 'Acute', 'Address', 'Adult', 'Algorithms', 'Area', 'Assessment tool', 'Behavior', 'Behavioral', 'Benefits and Risks', 'Big Data to Knowledge', 'Breathing', 'Cellular Phone', 'Characteristics', 'Chest', 'Cigarette', 'Data', 'Detection', 'Development', 'Ecological momentary assessment', 'Electronic Nicotine Delivery Systems', 'Enrollment', 'Environment', 'Environmental Risk Factor', 'Geography', 'Gestures', 'Goals', 'Grain', 'Hand', 'Harm Reduction', 'Health', 'High School Student', 'Hour', 'Human', 'Individual', 'Infrastructure', 'Inhalation', 'Knowledge', 'Laboratories', 'Laboratory Study', 'Life', 'Longitudinal cohort study', 'Machine Learning', 'Measures', 'Modeling', 'Movement', 'Oral cavity', 'Participant', 'Patient Recruitments', 'Pattern', 'Physiological', 'Physiology', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Process', 'Protocols documentation', 'Public Health', 'Questionnaires', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Sensitivity and Specificity', 'Sensory', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Social Environment', 'Socioeconomic Status', 'Stress', 'System', 'Technology', 'Time', 'Training', 'United States National Institutes of Health', 'Wireless Technology', 'Wrist', 'Youth', 'addiction', 'arm movement', 'base', 'biobehavior', 'built environment', 'cigarette smoke', 'cigarette smoking', 'cigarette user', 'data to knowledge', 'experience', 'field study', 'innovation', 'novel', 'parent grant', 'population health', 'primary outcome', 'programs', 'psychosocial', 'real time monitoring', 'recruit', 'respiratory', 'sensor', 'sensor technology', 'smoking cessation', 'social', 'systems research', 'tobacco control', 'tobacco products', 'tool', 'uptake', 'wearable device', 'young adult']",NCI,UNIVERSITY OF UTAH,R01,2019,121299,-0.010792510623091122
"RADECT is developing a clinical guidance (CG) software for nurse education and practitioners to evaluate experiential case-files  for the purpose of augmenting health disparity/equity clinical care. Project Summary/Abstract Our NIH SBIR project is to validate a Clinical Guidance System to assist practitioners in underserved and health disparity environments. We will apply our Clinical Guidance System for nurse education. The Clinical Guidance System is being trained across diverse medical disciplines across various healthcare data. This will then guide practitioners in diagnosis and treatment knowledge. The Clinical Guidance System is to improve access to care for the underserved and health disparity without increasing cost. The specific aims are the following, 1) to demonstrate effective software learning algorithms, and 2) to relate the index patient to other patient case-files in accuracy and agility. This project supports the given NIH Mission in seeking better health for everyone. Project Narrative The relevance of our NIH SBIR project is to research and develop a Clinical Guidance System for nurse integrated education and practitioner use in clinical use. The software system will assist nurses and general medical practitioners by oﬀering greater clinical and specialist responsibility in underserved and health disparity environments.",RADECT is developing a clinical guidance (CG) software for nurse education and practitioners to evaluate experiential case-files  for the purpose of augmenting health disparity/equity clinical care.,9796210,R44MD014095,"['Address', 'Adopted', 'Augmented Reality', 'Automobile Driving', 'Back', 'Boston', 'Businesses', 'Cardiovascular system', 'Caregivers', 'Caring', 'Case Study', 'Chronic Disease Hospitals', 'Clinical', 'Clinics and Hospitals', 'Communities', 'Community Hospitals', 'Computer software', 'Computers', 'Data', 'Data Files', 'Data Set', 'Decision Making', 'Devices', 'Diagnosis', 'Dictionary', 'Discipline', 'Discipline of Nursing', 'Disease', 'Education', 'Environment', 'Faculty', 'Future', 'Genomics', 'Guidelines', 'Health', 'Health Care Costs', 'Health Services Accessibility', 'Healthcare', 'Human', 'Improve Access', 'Intervention', 'Knowledge', 'Language', 'Learning', 'Legal patent', 'Machine Learning', 'Massachusetts', 'Maternal Health', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Nurse Practitioners', 'Nurses', 'Nursing Education', 'Paper', 'Pathway interactions', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Play', 'Policies', 'Prevention', 'Primary Health Care', 'Protocols documentation', 'Psychological reinforcement', 'Quality Control', 'Quality of Care', 'Research', 'Site', 'Small Business Innovation Research Grant', 'Specialist', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transcend', 'United States National Institutes of Health', 'Universities', 'Update', 'Validation', 'Vocabulary', 'Writing', 'application programming interface', 'base', 'blockchain', 'cardiovascular risk factor', 'care costs', 'clinical care', 'clinically relevant', 'cost', 'cost effective', 'cost effectiveness', 'crowdsourcing', 'dashboard', 'disadvantaged population', 'health disparity', 'health equity', 'hospital readmission', 'improved', 'indexing', 'innovation', 'learning algorithm', 'learning strategy', 'mortality', 'nutrition', 'off-patent', 'programs', 'public health relevance', 'repository', 'respiratory', 'sensor', 'skills', 'socioeconomics', 'software systems', 'visual information']",NIMHD,"RADECT, INC.",R44,2019,224150,-0.025821740374661534
"PiNDA - Fully integrated software platform for Preimplantation Genetic Testing - Aneuploidy (PGT-A) PROJECT SUMMARY  Since its inception 40 years ago, in vitro fertilization (IVF) has resulted in the birth of more than 1 million babies in the United States, and has revolutionized the field of reproductive medicine. Unfortunately, the success rate of IVF is still exceedingly low, especially for women >40 years old, with only 15.5% of implanted embryos resulting in pregnancy. This is partly due to the cytological method used for pre-implantation screening, which cannot detect the most common genetic defect during IVF, aneuploidy (i.e. chromosomal copy-number variation). Aneuploidy is linked to higher rates of miscarriage, and occurs more often in women >40 years of age; thus, aneuploidy has been a frequent target for genetic screening to improve IVF outcomes.  Pre-implantation genetic testing for aneuploidy (PGT-A) refers to a variety of techniques aimed at detecting changes in chromosomal copy number, with the goal of identifying high-quality euploid embryos for implantation. Recent advances in next-generation sequencing (NGS) technologies have made it possible to screen embryos at higher levels of precision, and across a wider range of genetic defects, including mosaicism, triploidy and single nucleotide polymorphisms (SNPs). Despite these remarkable advances, there are still significant challenges with PGT-A sequencing. Indeed, the most commonly implemented software for PGT-A (i.e. BlueFuse® ) are bundled with specific sequencing platforms (i.e. VeriSeq®), and are only designed to test for aneuploidy. Furthermore, existing pipelines are not user-friendly or customizable, which is a serious obstacle prohibiting the use of NGS by clinicians / embryologists. A more accessible bioinformatics platform is desperately needed that will bridge the gap between PGT-A sequencing and IVF outcomes.  Basepair™ is an innovator in efficient, user-friendly, web-based NGS analysis systems, with fully automated ChIP-, RNA-, ATAC-, and DNA-Seq bioinformatics pipelines available online. Here, Basepair will deliver PiNDA™, the first fully integrated software solution for comprehensive PGT-A analysis. In Aim 1, we will develop modules to test for specific chromosomal abnormalities, including mosaicism and triploidy, and validate each model with training data derived from somatic cell lines with known chromosomal aberrations. In Aim 2, we will integrate our modules into the PiNDA software system, creating a user-friendly, web-based interface that will perform full data analysis (raw data to full summary report) in <15 minutes, with no manual input required. Final data will be accessible via Basepair’s online portal, facilitating rapid data transfer from embryologists to physicians, and supporting the integration of NGS tests in IVF. Our innovative bioinformatics platform will accelerate NGS analysis for IVF, improving rates of pregnancy and advancing research in the success of IVF procedures. PROJECT NARRATIVE  In vitro fertilization (IVF) methods have begun to leverage next-generation sequencing technologies for pre-implantation genetic testing of aneuploidy (PGT-A), expanding the array of chromosomal abnormalities that can be accurately detected. However, the vast majority of software can only distinguish one type of genetic defect (i.e. aneuploidy), are difficult to use, and are tied to distinct sequencing platforms, limiting the clinical utility of resulting analyses. Basepair™ Inc. is a pioneer in user-friendly, web-based bioinformatics pipelines, providing comprehensive services for a wide range of sequencing projects. Here, Basepair will develop an inclusive suite of software for PGT-A, compatible with sequencing data from multiple platforms. This product will be of high value to the field and will help bridge the gap between advances in DNA sequencing and IVF technology.",PiNDA - Fully integrated software platform for Preimplantation Genetic Testing - Aneuploidy (PGT-A),9846492,R43HD100280,"['ATAC-seq', 'Age-Years', 'Algorithms', 'Aneuploid Cells', 'Aneuploidy', 'Bioinformatics', 'Biopsy', 'Birth', 'Cell Line', 'Cell division', 'Centers for Disease Control and Prevention (U.S.)', 'ChIP-seq', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Copy Number Polymorphism', 'Culture Media', 'Cytology', 'DNA sequencing', 'Data', 'Data Analyses', 'Embryo', 'Feedback', 'Fertility Agents', 'Fertilization in Vitro', 'Genetic Screening', 'Goals', 'Harvest', 'Implant', 'Letters', 'Link', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Morphology', 'Mosaicism', 'Mutation', 'Online Systems', 'Outcome', 'Phase', 'Physicians', 'Polymorphism Analysis', 'Pregnancy', 'Pregnancy Rate', 'Preimplantation Diagnosis', 'Procedures', 'Reporting', 'Reproductive Medicine', 'Research', 'Role', 'Sampling', 'Services', 'Single Nucleotide Polymorphism', 'Somatic Cell', 'Specificity', 'Spontaneous abortion', 'Summary Reports', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Training', 'Triploidy', 'United States', 'Uterus', 'Woman', 'analysis pipeline', 'aneuploidy analysis', 'cell free DNA', 'design', 'early embryonic stage', 'egg', 'implantation', 'improved', 'innovation', 'natural Blastocyst Implantation', 'next generation sequencing', 'phase 1 study', 'preimplantation', 'screening', 'sequencing platform', 'software development', 'software systems', 'sperm cell', 'success', 'transcriptome sequencing', 'user-friendly', 'web based interface']",NICHD,"BASEPAIR, INC.",R43,2019,298717,-0.039638536573199455
"Immune Basis & Clinical implications of Threshold-Based Phenotypes of Peanut Allergy Summary: Immune Basis and Clinical Implications of Threshold-Based Phenotypes of Peanut Allergy Peanut allergy (PA) is common, affecting 2-5% of school-age children in the US. The characteristics of PA vary widely among individuals, with some reacting to 1/100th of a peanut and others not having symptoms until they have ingested many peanuts. Symptoms can vary from mild rashes to fatal anaphylaxis. There is no FDA- approved treatment, and all patients with PA are managed with strict allergen avoidance. Most research on PA has focused on those with the most exquisite sensitivity to peanut. Immunotherapy trials commonly exclude subjects with a threshold dose over 1/3 of a peanut (100mg). However, most individuals with PA have higher thresholds of reaction and are excluded from current research approaches. We hypothesize that the natural heterogeneity of PA is a valuable opportunity for investigation. We have shown that milk or egg allergic individuals with tolerance to baked forms of these foods not only tolerate their inclusion in the diet, but this exposure increases the rate of resolution 14-16-fold. We hypothesize that dietary exposure to sub-threshold levels of peanut in those with higher threshold levels of reactivity could lead to significant clinical improvement. Furthermore, studying the natural heterogeneity of PA is a valuable opportunity to elucidate mechanisms of disease. To study the clinical implications and mechanism of phenotypic heterogeneity in PA, we will conduct a randomized open feeding trial (CAFETERIA trial) to investigate a prototype approach where children with moderate PA (tolerating at least 100 mg of peanut) ingest a sub-threshold amount daily, with increasing levels tested every 3 months. The impact of dietary intervention will be tested at 1 and 2 years by oral food challenge. The CAFETERIA study will provide a rich biorepository of samples from highly phenotyped subjects. We anticipate screening 200-250 subjects, including low threshold, high threshold, and sensitized but not allergic, in order to enroll 98 subjects that meet the high threshold criteria for the CAFETERIA trial. We will obtain longitudinal samples from subjects randomized to dietary therapy or avoidance. We will comprehensively profile antibody responses by high-throughput epitope assay, peanut-specific T cell responses by flow cytometry, and whole blood activation by CyTOF to construct a detailed clinical-immune network of PA, and analyze the relationship between immune and clinical parameters. We will identify biomarkers and key causal drivers of PA by performing integrated network-based examination of peripheral blood transcriptomes from PA subjects, sampled before and after food challenge, and before and after dietary therapy. Successful completion of these aims will result in (1) a simple low-cost treatment option applicable to the majority of those with PA; (2) an identification of immune and molecular mechanisms of PA and response to dietary therapy; (3) peripheral blood biomarkers that will practically impact clinical care of PA; (4) the potential for personalized approaches to the treatment of PA; and (5) a tremendously rich resource of clinical, immune, and transcriptional data and analytic tools to be made publicly available to the research community. NARRATIVE This AADCR Center will investigate threshold-based phenotypic heterogeneity of peanut allergy. We will focus on an under-studied high-threshold phenotype of peanut allergy, and examine the impact of dietary therapy with sub-threshold amounts of peanut. We will use this clinically diverse cohort to perform high dimensional profiling in order to elucidate immune and molecular mechanisms of allergy and tolerance to peanut.",Immune Basis & Clinical implications of Threshold-Based Phenotypes of Peanut Allergy,9712868,U19AI136053,"['Affect', 'Allergens', 'Allergic', 'Allergy to eggs', 'Allergy to peanuts', 'Anaphylaxis', 'Antibodies', 'Antibody Response', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Biology', 'Characteristics', 'Child', 'Clinical', 'Clinical Data', 'Communities', 'Computational Biology', 'Data', 'Data Analytics', 'Diet', 'Dietary Intervention', 'Disease', 'Dose', 'Economic Burden', 'Enrollment', 'Epitopes', 'Exanthema', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Food', 'Food Hypersensitivity', 'Funding', 'Genetic Transcription', 'Genomics', 'Goals', 'Heterogeneity', 'Hypersensitivity', 'IgE', 'Immune', 'Immunologics', 'Immunology', 'Individual', 'Ingestion', 'Investigation', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Medical', 'Milk', 'Milk Hypersensitivity', 'Molecular', 'Network-based', 'Nutritional', 'Oral', 'Patients', 'Persons', 'Phase III Clinical Trials', 'Phenotype', 'Predictive Value', 'Proteins', 'Protocols documentation', 'Quality of life', 'Randomized', 'Reaction', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Schedule', 'School-Age Population', 'Severities', 'Speed', 'Symptoms', 'T cell response', 'T-Lymphocyte', 'Testing', 'Treatment Cost', 'Urticaria', 'Visit', 'Whole Blood', 'allergic response', 'analytical tool', 'base', 'biobank', 'biomarker identification', 'clinical care', 'clinical practice', 'cohort', 'cost', 'desensitization', 'egg', 'feeding', 'food allergen', 'food challenge', 'high dimensionality', 'immunotherapy trials', 'individualized medicine', 'intervention cost', 'learning network', 'neglect', 'oral diagnostics', 'oral immunotherapy', 'outcome prediction', 'peripheral blood', 'personalized approach', 'prototype', 'response', 'screening', 'transcriptome']",NIAID,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U19,2019,1612047,-0.0043109000220648026
"Automatic Quantification and Labeling of Cerebral Microbleeds, Oxygen Saturation and Sources of Abnormal Susceptibility ABSTRACT The detection, localization and quantification of cerebral microbleeds (CMBs) plays an important role in diagnosing and establishing appropriate treatment plans in neurodegenerative diseases specifically in vascular dementia (VaD). To date, evaluating CMBs is time consuming, inaccurate and sometimes not possible. We propose to mitigate these problems by developing our software, “qSPIN”, that will provide fast and easy-to-use methods for: 1) automatic identification of CMBs and veins, 2) automatic quantification of CMBs, 3) automatic quantification of oxygen saturation in veins, and 4) creation of a user-friendly software for the practicing radiologist. Recent developments in MRI have provided a new means by which to study the role of CMBs and venous abnormalities in neurological diseases such as Alzheimer’s Disease (AD), VaD, stroke and traumatic brain injury (TBI). Susceptibility weighted imaging (SWI) has proven to be a powerful tool by which to detect CMBs and quantitative susceptibility mapping (QSM) can be used to measure changes in oxygen saturation. Knowing how many CMBs there are can predict the onset of VaD, determine whether anti-platelet therapy in stroke should be used, and correlate with neuropsychological outcome for patients with TBI. Our recent version of multi-echo SWI makes it possible to obtain both an arteriogram and a venogram simultaneously. Oxygen saturation can also be used to monitor perfusion changes and extend the window of treatment in stroke.  Currently, most radiologists and technologists do not have time to perform such detailed quantitative processing and thus it is not being done clinically. Our qSPIN software will provide this quantitative data. With the number, size, and location of CMBs or venous abnormalities, a better diagnosis would be possible. Our group is uniquely positioned to address this problem having developed many of these techniques. The novelty of our approach is the marriage of SWI, QSM, STAGE and deep learning techniques to detect these vascular and functional abnormalities. To accomplish the goals of this proposal, we will develop user friendly software that incorporates all imaging information from SWI and QSM to label CMBs. We will also provide the location of the CMBs in Talairach coordinates using a template dataset. In the end, we will have a complete picture of the prevalence of CMBs, abnormal oxygen saturation and their locations in patients with neurodegenerative disease that will improve diagnosis and potentially change their treatment. PROJECT NARRATIVE There is a huge demand today for a comprehensive analysis of diseases with cerebral microbleeds, abnormal oxygen saturation and thrombosis such as vascular dementia. The quantification of these features will have major ramifications for the diagnosis and treatment of dementia as well hypertension, stroke and traumatic brain injury all of which can lead to dementia. Therefore, our major objective in this application is to design and develop advanced image processing software that can rapidly and accurately identify and quantify the presence of cerebral microbleeds and changes in oxygen saturation in dementia and related diseases.","Automatic Quantification and Labeling of Cerebral Microbleeds, Oxygen Saturation and Sources of Abnormal Susceptibility",9845173,R44HL145826,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Arteriogram', 'Arteriosclerosis', 'Basal Ganglia', 'Blood Vessels', 'Brain', 'Brain hemorrhage', 'Businesses', 'Cerebral Amyloid Angiopathy', 'Cerebral hemisphere hemorrhage', 'Clinical', 'Computer software', 'Consumption', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Diagnosis', 'Diffuse Axonal Injury', 'Disease', 'Feedback', 'Goals', 'Hemorrhage', 'Hypertension', 'Image', 'Image Analysis', 'Impaired cognition', 'Infarction', 'Iron', 'Label', 'Lead', 'Link', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Marriage', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Multiple Sclerosis', 'Neurodegenerative Disorders', 'Neuropsychology', 'Outcome', 'Oxygen', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Play', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Protocols documentation', 'Protons', 'Published Comment', 'Reporting', 'Role', 'Sampling', 'Site', 'Source', 'Spatial Distribution', 'Stroke', 'TBI Patients', 'Techniques', 'Testing', 'Thalamic structure', 'Thrombosis', 'Time', 'Training', 'Traumatic Brain Injury', 'Vascular Dementia', 'Veins', 'Venous', 'base', 'cerebral microbleeds', 'cerebral vein', 'computerized data processing', 'contrast imaging', 'deep learning', 'density', 'design', 'image processing', 'improved', 'innovation', 'mild traumatic brain injury', 'nervous system disorder', 'neurovascular', 'prototype', 'quantitative imaging', 'radiologist', 'stroke risk', 'tool', 'treatment planning', 'user friendly software']",NHLBI,"MAGNETIC RESONANCE INNOVATIONS, INC.",R44,2019,214510,-0.07922438522210506
"Associating retinal nerve fiber layer thickness with glucose metabolism and diabetic retinopathy Project Summary/Abstract Type 2 diabetes mellitus (T2DM), a metabolic disease that affects over 300 million people worldwide and that can be accompanied by serious health complications such as heart disease, kidney failure, stroke, and damage to the eyes, in particular diabetic retinopathy (DR), which is diagnosed in a third of people with diabetes and which is the leading cause of blindness within the age group between 20 and 64 years. T2DM is clinically diagnosed by parameters related to glucose metabolism obtained by blood tests. Due to its long pre- symptomatic phase, an estimate of 25% of diabetics in the US are undiagnosed. In this project, the relationship between spatial patterns of retinal nerve fiber layer (RNFL) thickness (RNFLT), measured by spectral-domain optical coherence tomography (OCT), and blood test levels as well as levels of DR severity is investigated in 9,261 participants of a population based study.  In a first step, OCT RNFLT measurements of the macular and the circumpapillary area around optic nerve head are segmented into spatial sectors, and representative spatial patterns of RNFLT are calculated by an unsupervised machine learning method. Afterwards, a multivariate linear model comparison is performed with the coefficients of the spatial RNFLT patterns as regressors and diagnostic blood test results as dependent variable. The optimal combination of the RNFLT patterns, determined by an established model selection criterion (Bayes Factor), is expected to reveal insight into the association between the specific retinal locations of RNFL thinning accompanying the change in parameters related glucose metabolism during the development and progression of T2DM. Furthermore, fundus images are graded by DR severity following a nine-step scale derived from the Early Treatment Diabetic Retinopathy Study from no DR to severe proliferative DR. The spatial RNFLT patterns and metabolic blood test scores are then compared with respect to modeling DR severity by linear regression. An optimal model of DR severity combining glucose metabolism parameters and RNFLT patterns is developed. Finally, in an analogous procedure, DR severity of the follow-up measurement, five years after baseline, is statistically predicted from RNFLT and metabolic blood parameters and from their change over time.  To summarize, the proposed research identifies spatial patterns of RNFLT associated with parameters of glucose metabolism and their development over DR severity. Once accomplished, the proposed project would provide the details to establish RNFLT as an alternative manifestation of T2DM that complements diagnostic blood tests and thereby, for instance, lay the foundations for the development of novel and more accurate T2DM progression monitoring or the prediction of the onset of DR. Project Narrative Parameters related to glucose metabolism obtained by blood tests are clinically used to diagnose diabetes, a metabolic disease that affects over 300 million people worldwide and that can be accompanied by serious health complications, such as diabetic retinopathy (DR), the leading cause of blindness within the age group between 20 and 64 years. Decreased levels of blood glucose tolerance have been associated with retinal nerve fiber layer (RNFL) thinning, but these results were based on comparisons between small populations of diagnosed diabetics and healthy controls, and RNFL was typically represented by coarse summary parameters which neglect retinal anatomy. This project contributes directly and immediately to public health by exploring the relationship between spatial patterns of RNFL thickness, present and future DR severity, and diagnostic blood test results in 9,261 participants of a population based study, with the final goal to establish and quantify RNFL thickness as an alternative manifestation of diabetes that complements diagnostic blood tests and lays the foundations for the development of novel and more accurate disease progression monitoring or the prediction of DR onset.",Associating retinal nerve fiber layer thickness with glucose metabolism and diabetic retinopathy,9809589,R21EY030631,"['Affect', 'Anatomy', 'Area', 'Bayesian Modeling', 'Blindness', 'Blood', 'Blood Glucose', 'Blood Tests', 'Clinical', 'Complement', 'Data', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Disease Progression', 'Early treatment', 'Eye', 'Foundations', 'Future', 'Glycosylated hemoglobin A', 'Goals', 'Health', 'Heart Diseases', 'Kidney Failure', 'Linear Models', 'Linear Regressions', 'Location', 'Maps', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Diseases', 'Modeling', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'OGTT', 'Optic Disk', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Pattern', 'Phase', 'Population', 'Population Study', 'Procedures', 'Public Health', 'Research', 'Retina', 'Retinal', 'Scanning', 'Selection Criteria', 'Severities', 'Severity of illness', 'Stroke', 'Sum', 'Techniques', 'Test Result', 'Testing', 'Thick', 'Thinness', 'Time', 'Validation', 'age group', 'base', 'clinical Diagnosis', 'diabetic', 'fasting plasma glucose', 'follow-up', 'fundus imaging', 'glucose metabolism', 'glucose tolerance', 'insight', 'learning strategy', 'macula', 'neglect', 'novel', 'predictive modeling', 'proliferative diabetic retinopathy', 'public health relevance', 'retinal nerve fiber layer', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,R21,2019,313837,-0.012313945732666335
"HABIT DESIGN: TESTING A NOVEL BEHAVIORAL APPROACH TO CORPORATE WELLNESS IN THE CONTEXT OF METABOLIC SYNDROME Abstract Metabolic syndrome (MetS) is a constellation of risk factors– elevated triglycerides (TG), insufficient high- density lipoprotein cholesterol (HDL-C), elevated blood pressure (BP), elevated fasting blood glucose (FBG), and above-threshold waist circumference (WC)–that is associated with increased cardiovascular disease, type 2 diabetes mellitus, and some forms of cancer. Research suggests that addressing MetS through the workplace could significantly benefit employee health and employer healthcare costs. Habit Design, Inc., has developed an enhanced behavioral health coaching system called Habit Design (HD) that is the first to integrate habit formation, contingency management, and social learning approaches within a smartphone app to support to behavior change in corporate or employee health contexts. In this Fast Track project, we will adapt the HD approach to address MetS. In Phase I, we will 1) refine and extend existing functional prototypes of the HD app to support the latest versions of iOS and Android, 2) conduct usability testing with 8 targeted end users, and 3) prepare standard treatment manuals for the Phase II clinical trial. In Phase II, we will 1) make indicated changes to the HD app based on findings from the Phase I usability test and 2) evaluate the effectiveness of HD coaching compared to standard health coaching in a randomized trial with 424 corporate wellness program participants who have MetS, with follow-up spanning one year. Participants will employees of TriHealth in Cincinnati who have completed a health screening as part of their corporate wellness program and been identified as having at least 3/5 of the following: 1) TG ≥150 mg/dL), 2) HDL-C <40 mg/dL in males and <50 mg/dL in females, 3) BP ≥130/85 mm Hg, 4) FBG ≥100 mg/dl, and 5) WC ≥102 cm in males and ≥80 cm in females.. All participants will be coached to increase physical activity, which will be monitored with a waist-worn FitBit and Fitabase software. Additionally, participants will choose prior to randomization a goal of increasing fruit and vegetable intake or substituting water for sugar-sweetened beverages. Conditions will be stratified by choice of goal and gender. In both conditions coaching will be monitored for fidelity and delivered in 12 weekly in-person 30-minute sessions followed by one 30-minute maintenance session per month for 4 months. The primary outcome will be average daily step count measured over the course of at least one week at baseline, 4 months, 8 months, and 12 months. The secondary outcome will be standard units increase of fruit/vegetable intake or water intake, according to the participant's choice. Tertiary outcomes will consist of FBG, TG, HDL, BP, WC, and body mass index, measured at each time point. Additionally, we will conduct web-based assessment of self-reported physical activity, junk food, and sugar-sweetened beverage consumption; automaticity of exercise and fruit, vegetable, and water consumption; self-efficacy and social support for target behaviors; and health-related quality of life. Ratings of usability and satisfaction and app usage metrics will be examined. Analyses will be intent-to-treat assuming 15% loss to follow-up. Project Narrative/Relevance Metabolic syndrome is a major public health problem that affects over one in three American adults and increases the risk of cardiovascular disease, type 2 diabetes, and some forms of cancer. Habit Design, Inc., has developed an integrated health coaching system that uses a smartphone app to promote healthy behaviors. We will adapt it for metabolic syndrome and evaluate its effectiveness in a corporate health setting.",HABIT DESIGN: TESTING A NOVEL BEHAVIORAL APPROACH TO CORPORATE WELLNESS IN THE CONTEXT OF METABOLIC SYNDROME,9776030,R44HL142328,"['Address', 'Adherence', 'Adult', 'Affect', 'American', 'Android', 'Behavior', 'Behavioral', 'Behavioral Model', 'Blood Glucose', 'Blood Pressure', 'Body mass index', 'Cardiovascular Diseases', 'Central obesity', 'Chronic', 'Companions', 'Computer software', 'Consumption', 'Cues', 'Development', 'Effectiveness', 'Employee', 'Employee Health', 'Environment', 'Exercise', 'Fasting', 'Feedback', 'Female', 'Food', 'Fostering', 'Gender', 'Goals', 'Habits', 'Health', 'Health Care Costs', 'Health behavior', 'High Density Lipoprotein Cholesterol', 'High Density Lipoproteins', 'Hypertension', 'Hypertriglyceridemia', 'Intake', 'Intervention', 'Link', 'Location', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Metabolic syndrome', 'Modeling', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Participant', 'Patient Self-Report', 'Persons', 'Phase', 'Phase II Clinical Trials', 'Physical activity', 'Psychological reinforcement', 'Psychology', 'Public Health', 'Randomized', 'Randomized Controlled Trials', 'Research', 'Rewards', 'Risk Factors', 'Science', 'Self Efficacy', 'Social support', 'System', 'Telephone', 'Test Result', 'Testing', 'Time', 'Translating', 'Triglycerides', 'Water', 'Water consumption', 'Wellness Program', 'Workplace', 'base', 'behavior change', 'behavioral health', 'cardiovascular disorder risk', 'contingency management', 'crowdsourcing', 'design', 'experience', 'financial incentive', 'fitbit', 'follow-up', 'fruits and vegetables', 'health related quality of life', 'improved', 'innovation', 'male', 'mobile computing', 'novel', 'peer coaching', 'peer support', 'primary outcome', 'programs', 'prototype', 'randomized trial', 'satisfaction', 'screening', 'secondary outcome', 'smartphone Application', 'social learning', 'standard care', 'sugar', 'sweetened beverage', 'usability', 'waist circumference', 'web-based assessment']",NHLBI,"HABIT DESIGN, INC.",R44,2019,224991,-0.02715427196471049
"A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities ﻿    DESCRIPTION (provided by applicant): Our ultimate goal is to improve our ability to create and measure 3D models derived from cone-beam computed tomography (CBCT). Our main motivation is to improve quality and reduce costs in care of patients with craniomaxillofacial (CMF) deformities. The resulted innovations will also impact other fields. CMF deformities involve congenital and acquired deformities of the jaws and face. A large number of patients in the US and around the world suffered from CMF deformities. The evaluation of these patients includes an assessment of CMF form on 3D models that are traditionally generated from segmented spiral multi-slice CTs (MSCTs). These models are also used to plan their treatment. The purpose of segmentation is to separate different anatomical structures and to remove the artifacts on the CTs. Once 3D models are generated from the segmented CTs, anatomical and teeth landmarks are manually digitized for measurements. Finally, diagnosis and treatment planning are performed based on measurements. Although MSCT provides high- quality images and thus allows relatively fast and easy post processing, many concerns have been raised on excessive radiation exposure to patients. Therefore, more doctors are now using CBCT scanners in their offices. CBCT has less radiation and is inexpensive compared to the MSCT, but their use in generating 3D models is greatly limited by the poor image quality, i.e., low contrast / signal-to-noise ratio and artifacts. Thus, the existing automated segmentation algorithms developed for MSCT are incapable of practically segmenting CBCTs. The current solution to CBCT segmentation entails an arduous and lengthy process that involves labor-intensive manual editing of hundreds of slices. Besides, another arduous and inaccurate task in the assessment of CMF deformities is the digitization of anatomical landmarks on 3D models - the first step to quantify the deformities. Currently a typical 3D cephalometric and teeth analysis requires the manual digitization of more than 200 landmarks, which is time consuming and has limited accuracy. We hypothesize that the creation and measurement of high-quality 3D models can be significantly improved by developing innovative CBCT-friendly post processing tools. Therefore, in this renewal project, we propose to develop and validate a novel CBCT analysis platform to automate the process of CBCT segmentation and landmark digitization. The feasibility of our approaches has already been proven by our preliminary studies. Our innovative CBCT analysis platform will significantly improve the quality and reduce the cost of care to the individuals with CMF conditions. It will change our dental/CMF fields in effectively utilizing CBCT as a guide for on-the-fly diagnosis and treatment planning. With minimal user intervention, the computer will accurately and effectively do the work, which is currently artistically done by the labor-intensive human operators. The resulted innovations may also impact other fields in the future, e.g., orthopedic surgery and cardiovascular surgery where intraoperative whole-body CBCT is acquired for image-guided surgery and intervention. PUBLIC HEALTH RELEVANCE: Cone-beam computed tomography (CBCT) is widely used in physician's offices for orthodontics, craniomaxillofacial (CMF) surgery, facial plastic surgery and dentistry, but its segmentation and landmark digitization have to be completed artistically by human operators, which is labor-intensive and with limited accuracy.  We propose to develop and validate an innovative CBCT post processing system to automate the processes of CBCT segmentation and landmark digitization with minimal user intervention.  The proposed system will significantly improve the quality and reduce the cost of care to the individuals  with CMF conditions, and also change 1) the fields of orthodontics, CMF surgery and general dentistry in  effectively utilizing CBCT as a guide for diagnosis and treatment planning, and 2) the fields of orthopedic  surgery, general surgery, and cardiovascular surgery where the quality and the speed of intraoperative  imaging is critical.",A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities,9624752,R01DE022676,"['3-Dimensional', 'Algorithms', 'American', 'Anatomy', 'Atlases', 'Back', 'Cardiovascular Surgical Procedures', 'Cephalometry', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Assisted', 'Computer software', 'Computers', 'Consultations', 'Consumption', 'Deformity', 'Dental Care', 'Dentistry', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Ensure', 'Evaluation', 'Exposure to', 'Face', 'Future', 'Goals', 'Head', 'Hour', 'Human', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Individual', 'Intervention', 'Jaw', 'Label', 'Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motivation', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Orthodontics', 'Orthopedic Surgery procedures', 'Patient Care', 'Patients', 'Phase', 'Physicians&apos', ' Offices', 'Plastic Surgical Procedures', 'Process', 'Quality of Care', 'Quantitative Evaluations', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Running', 'Scanning', 'Services', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Syncope', 'System', 'Technology', 'Three-Dimensional Image', 'Time', 'Tomography, Computed, Scanners', 'Tooth structure', 'Training', 'Validation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'base', 'care costs', 'cone-beam computed tomography', 'cost', 'craniofacial', 'craniomaxillofacial', 'design', 'detector', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'psychologic', 'public health relevance', 'random forest', 'simulation', 'three-dimensional modeling', 'tool', 'treatment planning', 'usability', 'user-friendly']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2019,490358,-0.025925338588439765
"ACTIVE: Abilities Captured Through Interactive Video Evaluation (DDT COA 000032) Project Summary/Abstract Technology has the potential to accelerate clinical research and reduce the burden of participation in rare diseases such as Duchenne Muscular Dystrophy (DMD). DMD is an x-linked genetic disorder that results in progressive muscle weakness with loss of ambulation by 10-12 years of age, progression of arm weakness resulting in difficulty with self-feeding and other self-care activities in adolescence, and death resulting from cardiopulmonary insufficiency by age 30 years. Studies in rare diseases are inherently difficult due to a small recruitment pool and a limited number of sites that possess the experience and resources to participate as a study site. An outcome measure that quantifies change in both ambulant and non-ambulant individuals with minimal evaluator training could enable more efficient data collection in multi-site clinical trials. Our upcoming submission, DDT COA 0032, Abilities Captured Through Interactive Video Evaluation (ACTIVE), has the potential to meet this need. ACTIVE is a 65-second game utilizing a skeletal-tracking algorithm to quantify workspace volume (WSV) elicited through maximal arm reaching overhead, side-to-side, and forward while also encouraging trunk lean in each direction. Our studies have shown that ACTIVE is valid and reliable in quantifying WSV in persons with DMD across the span of age and abilities. However, to increase access and portability of a tool for use across trial sites, it is critical that tool has sound scientific and technological construction. ACTIVE WSV was originally built upon the Microsoft Kinect and Kinect One for Xbox platforms. The skeletal tracking algorithm developed by Microsoft vastly exceeds all other programs as it had the full backing of the Microsoft machine. Unfortunately, the Kinect, in its additional sense, has been abandoned for more current artificial intelligence applications. The Microsoft Kinect Azure will soon be released with higher resolution and programming capabilities. Our full DDT submission has been delayed as each new camera release has required reprogramming of our software to ensure valid and reliable results. Our team has recently expanded to include software development partners, The Plan Works (thePlan), who have the technological expertise to alter our current codebase to ensure transfer of ACTIVE across camera sensor platforms is more efficient and reliable as we expect ongoing technological advances to provide opportunities for continued advances. To this end, our current application seeks support to verify the technology of the ACTIVE WSV system to 1) confirm the use of unique code that can be ported across platforms over time and 2) improving the ease of use and limit training needed at a growing number of inexperienced centers. Project Narrative Our upcoming submission, DDT COA 0032, Abilities Captured Through Interactive Video Evaluation (ACTIVE), is a 65-second outcome assessment that quantifies a person’s workspace volume and has the potential to expand the enrollment pool by measuring both ambulant and non-ambulant subjects. While the scientific construction of the tool is sound, ongoing technological advances and changes have made it challenging to port our software across camera platforms. Our proposal seeks funding to support final software updates to ensure changes in technology components (i.e. camera sensor systems) or coding instability will not interfere with clinical trial data collection and allow us to complete our final submission package.",ACTIVE: Abilities Captured Through Interactive Video Evaluation (DDT COA 000032),9989528,U01FD006883,[' '],FDA,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,U01,2019,215170,-0.0015494506626599867
"Improving the Pelvic Health of Women and Girls Through the Use of a Digital Coaching Platform ABSTRACT More than 50 million women suffer from pelvic health disorders (PHDs) in the United States, a number that is projected to nearly double by 2050. These conditions cost the healthcare system billions annually and negatively affect educational and employment opportunities, quality of life, and fertility of patients. While studies suggest that PHDs can be managed and improved with education, practitioners are often confronted with patients who delay seeking treatment until their symptoms and conditions are advanced. Below Your Belt (BYB) is developing a platform that disrupts the costly, painful, and stigmatizing cycle of poor pelvic health in the U.S. The platform is a mobile, web based, a consumer-facing chatbot, with a working name of CeCe, that delivers pelvic health information in a familiar, accessible manner. CeCe will engage Mom with interactive and medically accurate content, positioning her to become the central source of information for her family and her social network. BYB has developed and tested a functional prototype of CeCe, which is based on feedback received from hundreds of women surveyed. In Phase I, BYB, together with Northwestern University and a highly qualified team of consultants will optimize CeCe and test the feasibility and acceptability of a chatbot to deliver pelvic health information. In Aim 1, The current prototype will be examined and enhanced to a web-based platform. Simultaneously, verified conversational and educational material will be added to the existing content to make it more robust. Then, a round of usability testing will be conducted. Updates to content and functionality will be completed based on initial usability results, and if any issues are uncovered, they will be addressed before the start of Aim 2. In Aim 2, Northwestern University will conduct a larger usability and knowledge-gained study with 36 women (recruitment target of 30% low income women). Questionnaires will be used to ascertain whether participants had measurable increase in knowledge after completing the two-week interaction with CeCe and to assess ease of use/acceptance. Exit interviews will be conducted to gain qualitative data around ease of use, interest in CeCe, content preferences, perceptions of achievement in relation to increased awareness of pelvic health and confidence or comfort sharing pelvic health information. At the conclusion of Phase I, BYB will have successfully demonstrated that CeCe’s final prototype is an acceptable and feasible model for increasing pelvic health knowledge. In addition, BYB will have a complete assessment of CeCe’s acceptability and insight into participants’ 14-day experience with the chatbot, and an understanding of whether a mom might feel confident or comfortable sharing any information she has learned. NARRATIVE Over 50 million women suffer from pelvic health disorders in the U.S. (projected to nearly double by 2050), which negatively affects their physical, emotional and intimate well-being and costs the healthcare system billions annually. Practitioners often see patients who delay seeking treatment until their symptoms and conditions are advanced. Below Your Belt (BYB) is developing a mobile, web-based chatbot to deliver pelvic health information in a familiar, accessible manner with a goal of disrupting the costly, painful, and stigmatizing cycle of poor pelvic health.",Improving the Pelvic Health of Women and Girls Through the Use of a Digital Coaching Platform,9846454,R41HD097845,"['Achievement', 'Address', 'Adoption', 'Age', 'Android', 'Area', 'Awareness', 'Behavioral', 'Bladder', 'Cellular Phone', 'Code', 'Computer software', 'Concept Review', 'Data', 'Data Collection', 'Devices', 'Disease', 'Documentation', 'Ecosystem', 'Education', 'Educational Background', 'Educational Materials', 'Elements', 'Emotional', 'Employment Opportunities', 'Facebook', 'Family', 'Feedback', 'Fertility', 'Goals', 'Health', 'Health Care Costs', 'Healthcare Systems', 'Internet', 'Interview', 'Intestines', 'Knowledge', 'Low income', 'Market Research', 'Measurable', 'Medical', 'Minority', 'Modeling', 'Mothers', 'Motivation', 'Names', 'Natural Language Processing', 'Online Systems', 'Pain', 'Participant', 'Patients', 'Pelvis', 'Perception', 'Personal Satisfaction', 'Phase', 'Positioning Attribute', 'Quality of life', 'Questionnaires', 'Research', 'Social Network', 'Source', 'Stigmatization', 'Summary Reports', 'Surveys', 'Symptoms', 'Testing', 'Text', 'Text Messaging', 'United States', 'Universities', 'Update', 'Visual', 'Woman', 'Women&apos', 's Health', 'base', 'chatbot', 'cost', 'design', 'digital', 'education research', 'experience', 'girls', 'health knowledge', 'improved', 'insight', 'interest', 'negative affect', 'novel', 'preference', 'prototype', 'recruit', 'skills', 'tool', 'usability', 'virtual']",NICHD,RENALIS LLC,R41,2019,231368,-0.0146227699687453
"CANNABIS IMPAIRMENT DETECTION APPLICATION (CIDA) (T163). SBIR PHASE II. POP: 9/20/2019-9/19/2021. N44DA-19-1218. Under this Small Business Innovation Research (SBIR) Phase I project, Research Topic 163, the Contractor will develop a portable, easily applied system incorporating a neuropsychological test protocol to detect cannabis impairment. n/a",CANNABIS IMPAIRMENT DETECTION APPLICATION (CIDA) (T163). SBIR PHASE II. POP: 9/20/2019-9/19/2021. N44DA-19-1218.,10044153,5N95019C00052,"['Algorithm Design', 'Apple', 'Biological Markers', 'Cannabis', 'Clinical Research', 'Contractor', 'Data', 'Databases', 'Detection', 'Goals', 'Health Technology', 'Impairment', 'Law Enforcement', 'Neuropsychological Tests', 'Phase', 'Procedures', 'Protocols documentation', 'Research', 'Small Business Innovation Research Grant', 'Study Subject', 'System', 'digital', 'human subject', 'machine learning algorithm', 'novel', 'novel therapeutics', 'portability', 'potential biomarker']",NIDA,"ADVANCED BRAIN MONITORING, INC.",N44,2019,1499722,-0.0027827406164309446
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine No abstract available PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,10063300,U01LM012675,[' '],NLM,UNIVERSITY OF CENTRAL FLORIDA,U01,2019,375751,-0.018590165976741832
"Development of a computer-guided orthopedic laser surgical system – vision & measurement Spatial Surgical is developing a novel, first-in-class orthopedic laser system that rapidly and safely ablates soft tissue and bone through a single handpiece. Spatial’s technology couples a laser with a real-time digital video system to offer computer-guided surgery that stands to replace traditional orthopedic saws, drills, and cauterization tools. The digital 3D video system is two miniaturized CMOS-based cameras built into the laser hand- piece. By eliminating mechanical tools an unobstructed, intra-operative view of the surgical site is possible for the first time ever. In-between the laser pulses, the cameras flash to capture an unobstructed view of the surgical site. The dual cameras are connected to a 3D display. Advances in autostereoscopic 3D displays have eliminated the need for 3D glasses, referred to as “glasses-free”, and enabled wide angle viewing. 3D viewing of the surgical area promotes increased spatial understanding of complex/ambiguous scenes and enhances surgical efficiency (McIntire 2014). Coupling image recognition software with the 3D vision enables AI measurement and computer assisted navigation. Orthopedic surgical success, measured as less patient pain and fewer revisions, has been shown when measurement and navigation are used, but existing systems are expensive and slow. A laser surgical hand-piece coupled with HD 3D vision and measurement will enable more accurate implant placement and restored range of motion while reducing infections and decreasing surgical times. This SBIR program models, tests, and demonstrates 3D viewing including digital zoom. Initially a multi-element design is modeled to predict what lens assembles would match with the digital CMOS imager appropriate for the orthopedic HD 3D application. Secondly off-the-shelf, OTS, lens stacks are chosen based on the optical modeling, and are tested to define the balance between the FOV, focal length, object distance and image size. Lens stack stereo characteristics are recorded and subsequently derive the forward-looking design requirements. Additionally, various illumination levels are explored to determine the optimum lighting for each lens stack. A standard vision calibration chart, like Mil-Std-150A, is used for alignment and the edge response is used to define spatial resolution. Multiple bone cut samples are measured with a confocal microscope and then viewed in 2D with the various OTS lens stacks. Optical measurement software is used to process the OTS lens camera images and are graphed versus the microscope data to determine peak image performance for spatial resolution. The introduction of HD autostereoscopic monitors and high pixel count CMOS global imagers enable a 3D surgical vision system to aid in orthopedic surgical applications by providing 3D glasses-free and wide angle viewing to improve spatial understanding of joints for faster and more precise surgery.",Development of a computer-guided orthopedic laser surgical system – vision & measurement,9846664,R43AR075447,"['3-Dimensional', 'Acoustics', 'Anatomy', 'Architecture', 'Area', 'Articular Range of Motion', 'Artificial Intelligence', 'Budgets', 'Calibration', 'Cauterize', 'Cellular Phone', 'Characteristics', 'Color', 'Complex', 'Computer Assisted', 'Computer software', 'Computer-Assisted Surgery', 'Computers', 'Consumption', 'Coupled', 'Couples', 'Coupling', 'Data', 'Development', 'Elements', 'Equilibrium', 'Fracture', 'Graph', 'Hand', 'Healthcare', 'Image', 'Implant', 'Implantation procedure', 'Infection', 'Joints', 'Lasers', 'Lead', 'Length', 'Lighting', 'Liquid substance', 'Measurement', 'Measures', 'Mechanics', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Optics', 'Orthopedic Procedures', 'Orthopedic Surgery procedures', 'Orthopedics', 'Pain', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Process', 'Quality of life', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Robot', 'Robotics', 'Sampling', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'System', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Vision', 'base', 'bone', 'cost', 'cost effective', 'design', 'digital', 'flexibility', 'imager', 'imaging system', 'improved', 'lens', 'miniaturize', 'novel', 'preservation', 'programs', 'response', 'skills', 'soft tissue', 'solid state', 'success', 'tool', 'usability']",NIAMS,SPATIAL SURGICAL LLC,R43,2019,246510,-0.020499091736982996
"2020 Nanoscale Science and Engineering for Agriculture and Food Systems Gordon Research Conference and Gordon Research Seminar Project Summary The objectives of this GRC are: 1) To bring together experts and stakeholders to discuss nanotechnology advances, directions, and needs in food and agriculture; 2) To identify cutting-edge research and emerging opportunities to address global challenges of food security, environmental sustainability, food safety, and agricultural productivity. A major goal of this GRC is to promote exceptional early career and female investigators, as well as those of traditionally underrepresented populations, to ensure the continued growth in diversity of scholars in our vibrant community. A diverse range of invited speakers and discussion leaders will present a comprehensive vision of critical and emerging nanotechnology research advances across the field of agricultural science. The program illustrates a targeted excellent diversity of leadership (6), speakers (23), and discussion leaders (11) across the spectrum of: i) gender diversity (19 females, 21 males); ii) USA (24) /International participation (16), representing Austria, Brazil, Canada, Colombia, Denmark, Germany, India, Italy, Korea, Singapore, Spain, Switzerland, and Taiwan; and iii) industry and government (3), which includes the FDA, FAO, a founder of a blockchain startup company, and senior research scientist at a non-governmental organization. The following topics will be included in the program: Food and nutrition, bioinspired and targeted technologies, sensing and tracking, microbiomes, food contact materials and human health and disease. Discussions on the safe deployment of nanotechnology in these areas, public perception and policy, and influence on industry and entrepreneurship are integral to this GRC. The Center for Food Safety and Applied Nutrition (CFSAN), the FDA center responsible for protecting the health of US consumers, will find the following sessions of great interest, Convergence of Nanotechnology with Food & Agriculture; Advances in Nanomaterials; Environmental Nanotechnology; Nano-enabled Approaches to Improving Human & Animal Health; Translation of Nano-Based Science for Application in Food & Agriculture; Big Data, Machine Learning, AI & Modeling; and Nanotechnology's Impact on Food Safety. The significant contributions of this diverse population will provide the strong intellectual infrastructure required to develop safe and sustainable nano-enabled applications in food and agriculture in direct support of the FDA CFSAN goal of ensuring the safety, security, sanitation, and proper labeling of the U.S. food supply. Project Narrative Nanomaterials and nanotechnology are rapidly entering almost every industry around the world. The co-chairs of this GRC envision that the convergence between nanotechnology, biotechnology and information science within plant science, animal science, crop and food science/technology and environmental science will lead to revolutionary advances in improving public health. The successful achievement of this lofty vision requires the profound intellectual commitment of scientists and engineers in a highly integrated engagement across numerous disciplines. Some success examples with a focus on nanotechnology in food include: nano- biosensors for identification of pathogens, toxins and bacteria in foods; identification systems for tracking animal and plant materials from origination to consumption; development of nanotechnology-based foods with lower calories and with less fat, salt and sugar, while retaining flavor and texture; integrated systems for sensing, monitoring and active response intervention for plant and animal production; “smart field systems” to detect, locate, report and direct application of water; precision and controlled release of fertilizers and pesticides; development of plants that exhibit drought resistance and tolerance to salt and excess moisture; and nanoscale films for food packaging and contact materials that extend shelf life, retain quality, and reduce cooling requirements. Overall, nanoscale science and engineering has an important role in creating a safer and more productive agriculture and food system. Commercial advances and technological impacts have been limited somewhat due to the relative “newness” of nanotechnology in agriculture and food systems. Given that research at the nanoscale in agriculture and food systems is only into its second decade, safety of nano-enabled applications in agriculture are still up for debate. The Center for Food Safety and Applied Nutrition (CFSAN), the FDA center responsible for protecting the health of US consumers, will find the following sessions of great interest, Convergence of Nanotechnology with Food & Agriculture; Advances in Nanomaterials; Environmental Nanotechnology; Nano-enabled Approaches to Improving Human & Animal Health; Translation of Nano-Based Science for Application in Food & Agriculture; Big Data, Machine Learning, AI & Modeling; and Nanotechnology's Impact on Food Safety. In the spirit of the GRC mission, the 2020 Nano Ag & Food GRC and GRS will again bring together a diverse array of scientists and engineers, both senior and junior, postdocs, and graduate students from academia, as well as scientists and engineers from business, government, and Non-governmental organizations (NGOs); with an emphasis to attract researchers from around the world to engage in open scientific exchange. The significant contributions of this diverse population will provide the strong intellectual infrastructure required to develop safe and sustainable nano-enabled applications in food and agriculture in direct support of the FDA CFSAN goal of ensuring the safety, security, sanitation, and proper labeling of the U.S. food supply.",2020 Nanoscale Science and Engineering for Agriculture and Food Systems Gordon Research Conference and Gordon Research Seminar,9912335,R13FD006688,[' '],FDA,GORDON RESEARCH CONFERENCES,R13,2019,25000,-0.024472266610205278
"Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility Innovative Design Labs (IDL) proposes to create a system to improve the mobility and control of exoskeletons. Recent research has found that 3.86 million Americans require wheelchairs and the number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk, thus providing a way to more fully reintegrate these individuals into society. Our proposal seeks to address one of the hurdles limiting the widespread adoption of exoskeletons in the home and community—the inability of the user to dynamically control gait parameters. This concept has the potential to significantly change the way exoskeletons work and facilitate their adoption into the market. Hypothesis: We hypothesize that the proposed solution will provide users a practical way to adjust their suit’s gait to precisely achieve their navigational goals. Specific Aims: Phase I: 1) Build a prototype and Perform Preliminary Laboratory Testing; 2) Develop and Benchmark Algorithms; and 3) Perform Pilot Human Study of Prototype with Exoskeleton Subjects. Phase II: 1) Develop Customized, Production-Ready Hardware and Firmware 2) Integrate with Exoskeleton Control System; and 3) Perform an evaluation of the system through human study testing. Recent research has found that 3.86 million Americans require wheelchairs and that number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk thereby providing a way to more fully reintegrate these individuals into society.",Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility,9570624,R44AG053890,"['3-Dimensional', 'Address', 'Adoption', 'Algorithm Design', 'Algorithms', 'American', 'Benchmarking', 'Bionics', 'Caregivers', 'Chicago', 'Clinical', 'Collaborations', 'Communities', 'Community Participation', 'Computational algorithm', 'Computer Vision Systems', 'Crutches', 'Custom', 'Dependence', 'Devices', 'Electrical Engineering', 'Emotional', 'Environment', 'Evaluation', 'Exercise', 'Eye', 'Family', 'Feedback', 'Freedom', 'Friends', 'Gait', 'Goals', 'Health', 'Height', 'Home environment', 'Hospitals', 'Human', 'Image', 'Impairment', 'Individual', 'Industry', 'Institutes', 'Laboratories', 'Length', 'Location', 'Medical', 'Methods', 'Motion', 'Patients', 'Performance', 'Phase', 'Population', 'Process', 'Production', 'Quality of life', 'Ramp', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Safety', 'Small Business Innovation Research Grant', 'Social isolation', 'Societies', 'Software Engineering', 'System', 'Technology', 'Testing', 'Uncertainty', 'Vision', 'Walking', 'Wheelchairs', 'Work', 'commercialization', 'design', 'exoskeleton', 'experience', 'human study', 'image processing', 'improved', 'improved mobility', 'innovation', 'insight', 'member', 'product development', 'prototype', 'rehabilitation technology', 'robot exoskeleton', 'usability']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2019,814735,-0.015984814312059312
"The Adherence Promotion with Person-centered Technology (APPT) Project: Promoting Adherence to Enhance the Early Detection and Treatment of Cognitive Decline Many older adults experience declines in cognitive ability that can be substantial, including mild cognitive impairment and Alzheimer’s disease and AD-related dementia. Population aging, coupled with age-related cognitive impairment, including Alzheimer’s disease and other dementias, represents an unprecedented challenge. Early detection of cognitive impairment is a crucial goal. This would allow individuals at risk for mild cognitive impairment and/or AD/ADRD to adopt lifestyle changes to minimize decrements and the risk for acquired cognitive impairment. However, the massive potential of cognitive training and longitudinal assessment to detect and prevent age-related cognitive impairment and dementia are unlikely to be realized unless individuals are willing and able to engage with these protocols for an extended period of time. Adherence to cognitive assessment and training is often poor. Addressing the gap between potential and realized benefits of early detection and prevention of cognitive impairment is an urgent goal as the population ages. The aims of the Adherence Promotion with Person-centered Technology (APPT) project are to promote early detection and treatment of age-related cognitive impairment and dementia by 1) enhancing adherence to cognitive intervention and assessment protocols, 2) improving understanding of barriers to long-term adherence, and 3) assisting in the development of algorithms for predicting and preventing adherence failures. Projects aim to investigate these issues within samples of older adults with and without cognitive impairment. Two randomized controlled trials will test an adaptive, tailored, and integrated technology support system predicted to boost adherence to cognitive protocols, over and above a simpler scheduling and reminder system over 6 months. Studies will provide valuable and generalizable insight into not only the benefits of adherence support, but also the individual difference factors that shape protocol adherence (e.g., attitudes, cognitive ability, dementia status, health status, personality, technology proficiency). Data will inform the process of identifying individuals who would benefit from additional support, and predicting and preventing extended adherence failures before they happen. By increasing adherence, these studies will help improve early detection and treatment of cognitive impairment, which will ultimately extend older adults' functional independence, improving their lives and the lives of their families, and reducing care and support resources needed to address lost independence like that associated with Alzheimer’s disease and AD-related dementia. Further, intervention studies for dementia and Alzheimer’s disease can be made more efficient through tools for identifying individuals likely to experience decline before substantial cognitive impairment has occurred. Results have implications that extend far beyond cognitive impairment; the methods and mechanisms uncovered have broad implications for technology-mediated assessment and protocols to enhance health and well-being in general. The project consists of two large randomized controlled trials and smaller needs assessment and usability studies that will guide their development and deployment. PUBLIC HEALTH RELEVANCE: The aims of the Adherence Promotion with Person-centered Technology (APPT) project are to promote early detection and treatment of age-related cognitive impairment and dementia. This project will develop Artificial Intelligence-based reminder systems to help ensure long-term engagement to home-based cognitive assessment and cognitive training protocols to be able to detect and treat cognitive impairment as soon as possible.",The Adherence Promotion with Person-centered Technology (APPT) Project: Promoting Adherence to Enhance the Early Detection and Treatment of Cognitive Decline,9801140,R01AG064529,"['Address', 'Adherence', 'Adopted', 'Age', 'Age-associated memory impairment', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Artificial Intelligence', 'Attitude', 'Caring', 'Clinical Trials', 'Cognition', 'Cognitive', 'Cognitive aging', 'Computer software', 'Coupled', 'Data', 'Dementia', 'Development', 'Early Diagnosis', 'Early treatment', 'Elderly', 'Ensure', 'Failure', 'Family', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Home environment', 'Human', 'Impaired cognition', 'Individual', 'Individual Differences', 'Intervention', 'Intervention Studies', 'Interview', 'Life Style', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Needs Assessment', 'Participant', 'Personal Satisfaction', 'Personality', 'Population', 'Positioning Attribute', 'Prevention', 'Process', 'Protocols documentation', 'Randomized Controlled Trials', 'Reminder Systems', 'Research', 'Resources', 'Risk', 'Sampling', 'Schedule', 'Shapes', 'Structure', 'Support System', 'Technology', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Weight', 'aging population', 'base', 'behavioral adherence', 'cognitive ability', 'cognitive change', 'cognitive performance', 'cognitive testing', 'cognitive training', 'design', 'experience', 'functional independence', 'improved', 'insight', 'mild cognitive impairment', 'mobile computing', 'next generation', 'person centered', 'prediction algorithm', 'preference', 'prevent', 'public health relevance', 'success', 'therapy design', 'tool', 'usability']",NIA,FLORIDA STATE UNIVERSITY,R01,2019,554286,-0.06228162174597681
"Environmental Localization Mapping and Guidance for Visual Prosthesis Users Project Summary About 1.3 million Americans aged 40 and older are legally blind, a majority because of diseases with onset later in life, such as glaucoma and age-related macular degeneration. Second Sight has developed the world's first FDA approved retinal implant, Argus II, intended to restore some functional vision for people suffering from retinitis pigmentosa (RP). In this era of smart devices, generic navigation technology, such as GPS mapping apps for smartphones, can provide directions to help guide a blind user from point A to point B. However, these navigational aids do little to enable blind users to form an egocentric understanding of the surroundings, are not suited to navigation indoors, and do nothing to assist in avoiding obstacles to mobility. The Argus II, on the other hand, provides blind users with a limited visual representation of their surroundings that improves users' ability to orient themselves and traverse obstacles, yet lacks features for high-level navigation and semantic interpretation of the surroundings. The proposed research aims to address these limitations of the Argus II through a synergy of state-of-the-art stimultaneous localization and mapping (SLAM) and object recognition technologies. For the past three years, JHU/APL has collaborated with Second Sight to develop similar advanced vision-based capabilities for the Argus II, including capabilities for object recognition and obstacle detection by stereo vision. This proposal is driven by the hypothesis that navigation for users of retinal prosthetics can be greatly improved by incorporating SLAM and object recognition technology conveying environmental information via a retinal prosthesis and auditory feedback. SLAM enables the visual prosthesis system to construct a map of the user's environment and locate the user within that map. The system then provides object location and navigational cues via appropriate sensory modalities enabling the user to mentally form an egocentric map of the environment. We propose to develop and test a visual prosthesis system which 1) constructs a map of unfamiliar environments and localizes the user using SLAM technology 2) automatically identifies navigationally-relevant objects and landmarks using object recognition and 3) provides sensory feedback for navigation, obstacle avoidance, and object/landmark identification. Project Narrative The proposed system, when realized, will use advanced simultaneous localization and mapping, and object recognition techniques, to enable visual prosthesis users with unprecedented abilities to autonomously navigate and identify objects/landmarks in unfamiliar environments.",Environmental Localization Mapping and Guidance for Visual Prosthesis Users,9818350,R01EY029741,"['3-Dimensional', 'Address', 'Age related macular degeneration', 'Algorithms', 'American', 'Competence', 'Complex', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Detection', 'Development', 'Devices', 'Disease', 'Effectiveness', 'Environment', 'Evaluation', 'FDA approved', 'Feedback', 'Glaucoma', 'Goals', 'Image', 'Implant', 'Late-Onset Disorder', 'Lead', 'Learning', 'Life', 'Location', 'Maps', 'Medical Device', 'Modality', 'Motion', 'Ocular Prosthesis', 'Patients', 'Performance', 'Psyche structure', 'Research', 'Retinitis Pigmentosa', 'Running', 'Semantics', 'Sensory', 'Societies', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vision', 'Visual', 'Volition', 'aged', 'auditory feedback', 'base', 'behavior test', 'blind', 'cognitive load', 'falls', 'human subject', 'improved', 'innovation', 'legally blind', 'navigation aid', 'object recognition', 'portability', 'prosthesis wearer', 'prototype', 'research and development', 'retina implantation', 'retinal prosthesis', 'sensory feedback', 'smartphone Application', 'synergism', 'visual feedback', 'visual information']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2019,641060,-0.012224518482214154
"The Enzymatic Reader Project Summary At this point in time, it is generally understood and agreed upon that single-molecule sequencing (SMS) is the future of genomics, transcriptomics, epigenomics, and epitranscriptomics due to its significant advantages over other technologies and methods. However, in order for these advantages to be fully realized, and for SMS to become the “gold standard” sequencing approach, significant issues and hurdles must be solved and overcome. During this program, Electronic BioSciences, Inc. (EBS) aims to demonstrate a completely new and enabling SMS method that will possess the ability to directly and correctly identify individual nucleotides, including chemically modified nucleotides. During this project, we will both demonstrate the ability of this entirely new sequencing approach to sequence DNA with high accuracy (directly comparing the obtained accuracy, throughput, error mechanisms and associated rates to other SMS approaches) and correctly identify (and sequence) 5-methylcytosine (5mC) and its derivatives, at the single molecule level. At the conclusion of this Phase I project, we will have successfully demonstrated an entirely new and dramatically improved SMS approach, and reduced the associated risks involved with its full future commercial developments. There is a current need within the field of next generation sequencing (NGS) or so called third generation sequencing (TGS) for new, enabling instrumentation that is capable of high-accuracy, direct, native DNA sequencing, including the ability to correctly identify canonical and modified bases, homopolymer stretches, and sequence repeats. The entirely new SMS methodology that will be developed during this project will overcome known hurdles and limitations of currently available NGS, TGS, and SMS technologies, resulting in technology that is cost-efficient, highly accurate, easy to setup and utilize, capable of de novo sequencing and modified base calling, and yields highly simplistic data for easy analysis and post possessing. Through significant advancements made during this program, this resulting technology will revolutionize the use of the genome and epigenome, radically change standard R&D and clinical practices, and greatly advance clinical diagnostics, prognostics, and therapeutic decision making. Project Narrative The novel single-molecule sequencing (SMS) technology developed during this project will enable high- accuracy, direct, native DNA sequencing, including the ability to correctly identify canonical and modified bases, homopolymer stretches, and sequence repeats via a cost-efficient and easy-to-use methodology. The impact of these advances in SMS will eventually enable wide-scale, routine clinical care and diagnostics toward advanced precision medicine, not just R&D. The performance and accessibility of such technology will transform the understanding and application of genomics and epigenomics, the associated clinical practices, that ability to provide precision clinical diagnostics, prognostics, and therapeutic decision making for improved public healthcare and wellbeing.",The Enzymatic Reader,9677956,R43HG010427,"['Biological', 'Biological Sciences', 'Caliber', 'Chemicals', 'Chemistry', 'Church', 'Complex', 'DNA Primers', 'DNA Sequence', 'DNA polymerase A', 'DNA sequencing', 'DNA-Directed DNA Polymerase', 'Data', 'Data Set', 'Decision Making', 'Development', 'Devices', 'Disadvantaged', 'Drops', 'Electrodes', 'Enzymes', 'Evaluation', 'Future', 'Genome', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Ions', 'Label', 'Length', 'Lipid Bilayers', 'Logistics', 'Methodology', 'Methods', 'Motor', 'Movement', 'Noise', 'Nucleotides', 'Performance', 'Personal Satisfaction', 'Phase', 'Polymerase', 'Polymers', 'Preparation', 'Process', 'Proteins', 'RNA', 'Reader', 'Reading Frames', 'Reproducibility', 'Risk', 'Sampling', 'Side', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Tools', 'Speed', 'Stretching', 'System', 'Technology', 'Therapeutic', 'Third Generation Sequencing', 'Time', 'base', 'clinical care', 'clinical diagnostics', 'clinical practice', 'cost', 'cost efficient', 'electric field', 'epigenome', 'epigenomics', 'epitranscriptomics', 'improved', 'instrumentation', 'machine learning algorithm', 'nanopore', 'next generation sequencing', 'novel', 'precision medicine', 'prevent', 'prognostic', 'programs', 'research and development', 'single molecule', 'solid state', 'transcriptomics']",NHGRI,"ELECTRONIC BIOSCIENCES, INC.",R43,2019,247611,-0.03106182965487516
"Augmented Reality System for the Education of Clinical Caregivers of Older Adults Project Summary/Abstract Proposed is a system to combine and leverage the advantages of both existing physical mannequin-based training and virtual media to support clinical learning using Augmented Reality (AR). Significance: Education in clinical settings is often challenging, infeasible, risky, difficult to organize, time-consuming, and expensive. Due to these barriers, the value of mannequin-based simulation is well recognized and is incorporated extensively into medical education. In general, the purpose of mannequin use in education is to simulate a physical ""patient"" on which to learn, demonstrate, and test skill without fear of harming patients prior to entering clinical environments. Despite their substantial benefits, physical mannequins have several fundamental limitations that do not allow them to demonstrate the many unique phases and expressions of a disease or person-to-person differences in anatomy and physiology. This limits the ability for a learner to view dynamic changes over time and to explore disease progression and consequences of interventions. Hypothesis: This research hypothesizes that existing, current mannequins can be enhanced through an innovative and practical Augmented Reality solution. In the Phase I effort a prototype system and sample educational material covering Pressure Ulcer care was developed and analyzed through pilot studies with Nursing educators, Doctoral Degree in Nursing (DNP) students, and pre-licensure students. The pilot results of the technology demonstrated a high degree of positivity and exceptional enthusiasm and all Phase I metrics of success were met or exceeded. Specific Aims: In Phase II the following aims are proposed: 1) Design a comprehensive suite of course content and design the technology's integration into a College of Nursing course, 2) Develop a production-ready system, and 3) Validate the system utility through human subject testing and expert evaluation of the system. Project Narrative Over the past decade, medical simulation has been experiencing explosive growth and widespread adoption. There are now over 800 medical simulation centers in the US alone, located in medical schools, nursing schools, hospitals, military simulation centers, and schools of allied health professions. The global market for Mannequin-Based Simulation is projected to reach $1 Billion by 2020. It is hypothesized that the combination of existing physical mannequin-based training with virtual media will open new possibilities for exploration and enhanced learning interactions for medical education. 3T",Augmented Reality System for the Education of Clinical Caregivers of Older Adults,9778054,R44AG057257,"['Adoption', 'Adult', 'Algorithmic Software', 'Allied Health Profession', 'Anatomy', 'Area', 'Augmented Reality', 'Caregivers', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Course Content', 'Decubitus ulcer', 'Development', 'Discipline of Nursing', 'Disease', 'Disease Progression', 'Dissection', 'Doctor&apos', 's Degree', 'Education', 'Educational Curriculum', 'Educational Materials', 'Elderly', 'Environment', 'Evaluation', 'Focus Groups', 'Fright', 'Goals', 'Growth', 'Hospitals', 'Hour', 'Human', 'Image', 'Individual', 'Injury', 'Intervention', 'Laboratories', 'Learning', 'Licensure', 'Location', 'Manikins', 'Medical', 'Medical Education', 'Military Personnel', 'Minnesota', 'Modeling', 'Movement', 'Nursing Faculty', 'Nursing Schools', 'Nursing Students', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Production', 'Research', 'Sampling', 'School Nursing', 'Schools', 'Scientist', 'Severity of illness', 'Skin', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'animation', 'base', 'caregiver education', 'college', 'commercialization', 'cost', 'design', 'experience', 'flexibility', 'human subject', 'impression', 'innovation', 'medical schools', 'miniaturize', 'person centered', 'pressure', 'professor', 'programs', 'prototype', 'simulation', 'skills', 'success', 'teacher', 'virtual']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2019,779815,-0.020934318102256644
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9649188,U24DK112331,"['ATAC-seq', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Cost efficiency', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Infrastructure', 'Institutes', 'Knowledge', 'Lead', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'analysis pipeline', 'base', 'bisulfite sequencing', 'data resource', 'epigenomics', 'exercise intervention', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'individual response', 'insight', 'machine learning algorithm', 'medical schools', 'methylome', 'mortality risk', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2019,2593647,-0.016738689914551214
"The nGoggle: A portable brain-based device for assessment of visual function deficits PROJECT SUMMARY Assessment of loss of visual function outside the foveal area is an essential component of the management of numerous conditions, including glaucoma, retinal and neurological disorders. Despite the significant progress achieved with the development of standard automated perimetry (SAP) many decades ago, assessment of visual field loss with SAP still has significant drawbacks. SAP testing is limited by subjectivity of patient responses and high test-retest variability, frequently requiring many tests for effective detection of change over time. Moreover, as these tests are generally conducted in clinic-based settings, limited patient availability and health care resources often result in an insufficient number of tests acquired over time, with delayed diagnosis and detection of disease progression. The requirement for highly trained technicians, cost, complexity, and lack of portability of SAP also preclude its use for screening of visual field loss in underserved populations. To address shortcomings of current methods to assess visual function, we have developed the nGoggle, a wearable device that uses a head-mounted display (HMD) integrated with wireless electroencephalography (EEG), capable of objectively assessing visual field deficits using multifocal steady-state visual-evoked potentials (mfSSVEP). As part of the funded NEI SBIR Phase I, we developed the nGoggle prototype using a modified smartphone-based HMD display and non-disposable electrodes. In our Phase I studies, we conducted benchmarking tests on signal quality of EEG acquisition, developed methods for EEG data extraction and analysis, and conducted a pilot study demonstrating the ability of the device to detect visual field loss in glaucoma, a progressive neuropathy that results in characteristic damage to the optic nerve and resulting visual field defects. We also identified limitations of current existing displays and electrodes, as well as potential avenues for enhancing test reliability and improving user interface. Based on the encouraging results from Phase I and a clear delineation of the steps needed to bring the device into its final commercial product form, we now propose a series of Phase II studies. We hypothesize that optimization of nGoggle's accuracy and repeatability in detecting visual function loss can be achieved through the development of a customized head-mounted display with front-view eye/pupil tracking cameras and disposable no-prep electrodes, as well as enhancement of the visual stimulation protocol and data analytics. The specific aims of this proposal are: 1) To develop a customized head-mounted display and enhanced no-prep electrodes for improving nGoggle's ability to acquire users' mfSSVEP with high signal-to- noise ratios (SNR) in response to visual stimulation; 2) To optimize and validate mfSSVEP stimuli design and data analytics to enhance the accuracy and repeatability of assessing visual function loss with the nGoggle. 3) Complete pivotal clinical studies to support FDA approval. PROJECT NARRATIVE NGoggle Inc. has developed the nGoggle, a wearable device that uses a head-mounted display integrated with wireless electroencephalography, capable of objectively assessing visual field deficits using multifocal steady- state visual-evoked potentials. NGoggle Inc is now proposing to optimize nGoggle's accuracy and repeatability in detecting visual function loss with the use of a customized display, adherent no-prep electrodes, optimized visual stimuli and data analytics. It will also complete pivotal clinical studies to support FDA approval.",The nGoggle: A portable brain-based device for assessment of visual function deficits,9772484,R42EY027651,"['Address', 'Area', 'Base of the Brain', 'Benchmarking', 'Blindness', 'Brain', 'Cellular Phone', 'Characteristics', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Custom', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Elastomers', 'Electrodes', 'Electroencephalography', 'Electrooculogram', 'Exhibits', 'Eye', 'Funding', 'Glaucoma', 'Head', 'Healthcare', 'Methods', 'Neuropathy', 'Noise', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Perimetry', 'Phase', 'Photic Stimulation', 'Pilot Projects', 'Protocols documentation', 'Pupil', 'Resources', 'Retinal Diseases', 'Scotoma', 'Series', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Source', 'Stimulus', 'Testing', 'Time', 'Training', 'Underserved Population', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Wireless Technology', 'base', 'cost', 'design', 'field study', 'improved', 'loss of function', 'machine learning algorithm', 'nervous system disorder', 'patient response', 'phase 1 study', 'phase 2 study', 'portability', 'prototype', 'real world application', 'relating to nervous system', 'response', 'sample fixation', 'screening', 'virtual reality', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R42,2019,648557,-0.011206379197868346
Advancing a novel portable detection method for cannabis intoxication No abstract available n/a,Advancing a novel portable detection method for cannabis intoxication,9751264,R42DA043977,"['Acute', 'Adult', 'Age', 'Alcohols', 'Algorithms', 'Area', 'Base of the Brain', 'Biochemical', 'Biological', 'Biological Markers', 'Blood', 'Blood Circulation', 'Body Fluids', 'Brain', 'Cannabis', 'Collaborations', 'Comorbidity', 'Cross-Over Trials', 'Data', 'Detection', 'Devices', 'Dose', 'Double-Blind Method', 'Drug Kinetics', 'Ensure', 'Equipment', 'Evaluation', 'Formulation', 'Future', 'Goals', 'Gold', 'Hour', 'Human Resources', 'Impairment', 'Individual', 'Intoxication', 'Law Enforcement', 'Law Enforcement Officers', 'Letters', 'Licensing', 'Machine Learning', 'Marijuana', 'Measurement', 'Methods', 'Near-Infrared Spectroscopy', 'Oral', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Placebos', 'Population', 'Prefrontal Cortex', 'Property', 'Public Health', 'ROC Curve', 'Randomized', 'Readiness', 'Rest', 'Sensitivity and Specificity', 'Source', 'Specificity', 'System', 'THC exposure', 'Testing', 'Tetrahydrocannabinol', 'United States', 'Urine', 'Vendor', 'alcohol exposure', 'base', 'behavior test', 'commercialization', 'density', 'detector', 'driving under influence', 'drug testing', 'field sobriety tests', 'functional disability', 'hemodynamics', 'interest', 'marijuana legalization', 'marijuana use', 'marijuana user', 'novel', 'novel strategies', 'portability', 'response', 'spectroscopic imaging', 'tool', 'user-friendly', 'vehicular accident']",NIDA,"HIGHLIGHTI, INC",R42,2019,335711,-0.025289667464106144
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9731544,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'repository', 'research and development', 'software development', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,350620,-0.017386334266471508
"Development and Validation of a Collaborative Web/Cloud-Based Dosimetry System for Radiopharmaceutical Therapy. Project Summary  Radiopharmaceutical therapy (RPT) – the use of targeted radionuclides to deliver radiation specifically to cancer cells and their microenvironment – is a fundamentally different approach to cancer therapy that is growing, with a substantial number of large and small pharmaceuticals companies developing products in this area and radionuclide producers making substantial investments in scaling up production. This is especially true in the area of alpha emitters. The dosimetric evaluation of therapeutic radiopharmaceuticals is a key requirement for regulatory approval and optimal administration of RPTs, especially in combination with external beam radiation therapy. This project will provide a cloud-based dosimetry software service, delivered through a web-browser, that includes the full complement of methods needed for dosimetry in the context of obtaining regulatory approval of RPTs and, ultimately, for optimal clinical delivery. Providing this in a cloud-based system will enable a variety of models for selling the service that do not require a large up-front capital investment for clinics or radiopharmaceutical developers. It also will provide access to expert advice, customization, and dosimetry services, and allow for collaboration between developers, dosimetry experts, and clinical sites. To accomplish the goal of developing this cloud-based web-browser-delivered RPT dosimetry software service, we propose the following specific aims: (1) Design, develop and implement a web/cloud-based integrated software system for treatment planning of RPT therapy; (2) design and implement a full server-side framework for subscription, authentication, and granting collaborative privileges for the various processes and data in the dosimetry pipeline; (3) optimize and adapt the four most computationally intensive processes for a multi-processor cloud-based compute environment; (4) apply and evaluate the toolchain developed in aims 1-3 to phantom, simulated and existing patient data. Successful completion of this project will produce a cloud-based software system delivered to the user via a web browser that provides an integrated, streamlined, robust, state-of-the-art system for RPT treatment planning. This system would enable a collaborative approach to multi-center clinical trials and eventually to clinical delivery of optimally dosed RPT. Projective Narrative  Radiopharmaceutical therapy is an emerging cancer therapy modality involving the targeted delivery of radiation to tumors using tumor-targeting molecules. The dosimetric evaluation of the therapeutic radiopharmaceuticals is a key requirement for regulatory approval and optimal administration of RPTs. This project seeks to develop a cloud-based software system delivered to the user via a web browser that provides an integrated, streamlined, robust, state-of-the-art system for RPT treatment planning; and enables a collaborative approach to multi-center clinical trials and eventually to the clinical delivery of optimally dosed RPT.",Development and Validation of a Collaborative Web/Cloud-Based Dosimetry System for Radiopharmaceutical Therapy.,9909727,R44CA213782,"['3-Dimensional', 'Architecture', 'Area', 'Big Data', 'Biological', 'Businesses', 'Capital', 'Client', 'Clinic', 'Clinical', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Collection', 'Development', 'Dose', 'Dose-Rate', 'Environment', 'External Beam Radiation Therapy', 'Generations', 'Goals', 'Grant', 'Growth', 'Health', 'Individual', 'Infrastructure', 'Internet', 'Investments', 'Licensing', 'Methods', 'Modality', 'Modeling', 'Multi-Institutional Clinical Trial', 'Online Systems', 'Pathway interactions', 'Patients', 'Pharmacologic Substance', 'Phase', 'Privacy', 'Process', 'Production', 'Radiation', 'Radioisotopes', 'Radiopharmaceuticals', 'Research Personnel', 'Running', 'Services', 'Side', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'System', 'Systemic disease', 'Translating', 'Treatment Protocols', 'Uncertainty', 'Validation', 'Vendor', 'Work', 'analysis pipeline', 'base', 'cancer cell', 'cancer therapy', 'clinical application', 'clinical research site', 'cloud based', 'collaborative approach', 'computing resources', 'cost effective', 'data sharing', 'deep learning', 'design', 'dosimetry', 'experience', 'image reconstruction', 'image registration', 'imaging Segmentation', 'interest', 'medical specialties', 'multicore processor', 'neoplastic cell', 'precision medicine', 'prototype', 'quantitative imaging', 'radiation delivery', 'reconstruction', 'scale up', 'single photon emission computed tomography', 'software systems', 'targeted delivery', 'therapeutic evaluation', 'tool', 'treatment planning', 'treatment strategy', 'tumor', 'web services']",NCI,"RADIOPHARMACEUTICAL IMAGING AND DOSIMETRY, LLC",R44,2019,999998,-0.040805740269873485
"A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions Abstract. Melanoma is the third most common form of skin cancer with estimated 87,110 new cases diagnosed in the United States in the year 2017. Current routine diagnostic approaches utilize microscopic evaluation of thinly sectioned patient biopsies, but in certain cases diagnosis can be contentious even among experts. The overall goal of this multi-phase SBIR project is to develop, validate, and commercialize MelanoMap™, Frontier Diagnostics' patented assay for the diagnosis of melanoma using a matrix-assisted laser desorption/ionization imaging mass spectrometry (MALDI IMS) platform—and to have this assay available to pathologists in the U.S. as a laboratory developed test. MALDI IMS is a state-of-the-art technology that generates molecular images of tens to thousands of biomolecules from tissue sections in a single analysis. The assay uses formalin-fixed paraffin embedded (FFPE) biopsies used in routine histopathological diagnosis. The proposed assay has pathologists select regions of skin biopsies for analysis via a remote web interface. The acquired IMS data from those regions unambiguously identifies malignant melanoma or benign nevus.  Phase I of this proposal will demonstrate the feasibility of this technology platform to achieve cost-effective diagnosis of melanoma from patient skin biopsies at sample volumes acceptable for a clinical laboratory. Specific Aim 1 focuses on the development of a scalable and robust analytical protocol in both sample preparation and informatics to accurately diagnose melanoma with MALDI IMS. In specific aim 2, we will test the methodology developed in Specific Aim 1 on a cohort of melanocytic lesions with known clinical outcome and subsequently validate the classification accuracy of the proposed test  In Phase II, the protocols developed in Phase I will be integrated into a diagnostic service workflow. This phase will focus on quality control measures, client facing cloud software, clinical diagnostic reporting, and completing the analysis of a 500-patient sample set for final assay validation. Specific Aim 3 of this proposal (initial aim of Phase II) will establish and implement test tissues into standard workflows that will provide performance metrics for standard operation of a test meeting Clinical Laboratory Improvement Amendments (CLIA) standards. Protocols will be developed to monitor reagents, the reproducibility of sample preparation, and mass spectrometer performance on daily basis. Specific Aim 4 will expand software capabilities to include a secure web interface for clients ordering the test and the laboratory performing the test. The software will meet regulatory compliance, perform statistical analysis, and generate and communicate reports of the MALDI IMS analysis. Specific Aim 5 proposes to expand the sample set used in the initial assay from Specific Aim 2 to include a set of 300 patient samples from our clinical collaborators with 5 or more years follow-up data. The test will be independently validated by an additional 200 patient samples with definitive diagnoses. Project Narrative This multi-phase Fast Track SBIR project will develop and validate a new laboratory developed test to differentiate malignant melanocytic tumors from benign nevi and complete development of an imaging mass spectrometry-based diagnostic service platform for a clinical laboratory. The clinical assay developed under this proposal augments current practice by providing molecular measurements that are used as objective criteria in the diagnosis of melanoma. Successful completion of this Fast Track project will result in a fully documented and validated assay ready for launch as a laboratory developed test.",A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions,9905050,R44CA228897,"['Amendment', 'Antigens', 'Area', 'Benign', 'Biological Assay', 'Biopsy', 'Caliber', 'Cells', 'Classification', 'Client', 'Clinical', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Services', 'Digestion', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Formalin', 'Goals', 'Gold', 'Image', 'Incentives', 'Informatics', 'Laboratories', 'Legal patent', 'Lesion', 'Malignant - descriptor', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Melanocytic Neoplasm', 'Metadata', 'Methodology', 'Microscopic', 'Microtomy', 'Molecular', 'Monitor', 'Nevus', 'Outcome', 'Paraffin Embedding', 'Pathologist', 'Pathology Report', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Physical shape', 'Physicians', 'Preparation', 'Procedures', 'Proteins', 'Protocols documentation', 'Quality Control', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Retrieval', 'Sampling', 'Secure', 'Security', 'Sensitivity and Specificity', 'Side', 'Skin', 'Skin Cancer', 'Small Business Innovation Research Grant', 'Software Tools', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Standardization', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Treatment Cost', 'United States', 'Validation', 'accurate diagnosis', 'analytical method', 'base', 'clinical diagnostics', 'cloud software', 'cohort', 'cost', 'cost effective', 'data acquisition', 'diagnosis standard', 'diagnostic assay', 'disease classification', 'follow-up', 'frontier', 'histopathological examination', 'instrumentation', 'interest', 'machine learning algorithm', 'mass spectrometer', 'meetings', 'melanoma', 'molecular diagnostics', 'molecular imaging', 'mortality risk', 'off-patent', 'operation', 'prototype', 'quality assurance', 'skin lesion', 'tissue preparation', 'web interface']",NCI,"FRONTIER DIAGNOSTICS, LLC",R44,2019,998671,-0.00958595613243381
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),9700159,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,THE MIND RESEARCH NETWORK,P30,2019,1290517,-0.019932685566686148
"Synergistic integration of topology and machine learning for the predictions of protein-ligand binding affinities and mutation impacts Project Summary Fundamental challenges that hinder the current understanding of biomolecular systems are their tremendous complexity, high dimensionality and excessively large data sets associated with their geometric modeling and simulations. These challenges call for innovative strategies for handling massive biomolecular datasets. Topology, in contrast to geometry, provides a unique tool for dimensionality reduction and data simplification. However, traditional topology typically incurs with excessive reduction in geometric information. Persistent homology is a new branch of topology that is able to bridge traditional topology and geometry, but suffers from neglecting biological information. Built upon PI’s recent work in the topological data analysis of biomolecules, this project will explore how to integrate topological data analysis and machine learning to significantly improve the current state-of-the-art predictions of protein-ligand binding and mutation impact established in the PI’s preliminary studies. These improvements will be achieved through developing physics-embedded topological methodologies and advanced deep learning architectures for tackling heterogeneous biomolecular data sets arising from a variety of physical and biological considerations. Finally, the PI will establish robust databases and online servers for the proposed predictions. Project Narrative The project concerns the integration of topological data analysis and machine learning architectures for the predictions of protein-ligand binding affinities and mutation induced protein stability changes from massive data sets. This new data approach has considerable impact for future generation methods in computational biophysics and drug design.",Synergistic integration of topology and machine learning for the predictions of protein-ligand binding affinities and mutation impacts,9591863,R01GM126189,"['Address', 'Affinity', 'Algorithms', 'Architecture', 'Big Data', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biophysics', 'Characteristics', 'Chemicals', 'Classification', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Dimensions', 'Drug Design', 'Electrostatics', 'Elements', 'Free Energy', 'Freedom', 'Future Generations', 'Geometry', 'Handwriting', 'Image Analysis', 'Induced Mutation', 'Ions', 'Learning', 'Ligand Binding', 'Ligands', 'Lipids', 'Machine Learning', 'Medical', 'Membrane', 'Membrane Proteins', 'Metals', 'Methodology', 'Methods', 'Mutation', 'Physics', 'Plant Roots', 'Proteins', 'Psychological Transfer', 'Site', 'Speech', 'System', 'Techniques', 'Thermodynamics', 'Work', 'algebraic topology', 'base', 'cofactor', 'data warehouse', 'deep learning', 'direct application', 'high dimensionality', 'improved', 'innovation', 'language processing', 'learning strategy', 'metallicity', 'models and simulation', 'multitask', 'mutant', 'neglect', 'next generation', 'search engine', 'tool', 'trend', 'user-friendly']",NIGMS,MICHIGAN STATE UNIVERSITY,R01,2018,319737,-0.03634541068929208
"Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data NARRATIVE SUMMARY The landscape of data formats is rapidly expanding, with image, text and other complex formats becoming available for health related outcomes. By considering such data within the context of observational causal inference, they can be leveraged to improve clinical decisions, help evaluate treatment efficacy by estimating individualized treatment effects and help develop intelligent therapeutic systems where individualized treatments can be deployed. In R01EB025021, we concentrate on understanding how nearly exact matching can be achieved in the presence of a large number of categorical covariates. The proposed approach (called FLAME - Fast Large Almost Matching Exactly) is able to quickly learn which categorical covariates are important and to produce high quality matches \citep{wang2017flame,dieng2018collapsing}. The main shortfall in the proposed work for R01EB025021 is that it does not naturally extend to more complex data types, it only works for categorical data in which each feature is meaningful. {\bf This proposal will develop new statistical and computational tools for causal analysis of complex data structures.} Our new approach is called {\emph Matching After Learning to Stretch (MALTS)}. For each unit (e.g. patient), we propose learn a latent representation of their covariate information and a distance metric on the latent space such that units that are matched tend to provide accurate estimates of treatment effect. MALTS can use deep learning to encode the latent representations for the units, or it can learn basis transformations in linear space (stretching and rotation matrices) for simpler continuous data types. We will develop the MALTS algorithm, and apply it in a medical context. Our goal is to construct high quality matches for the following types of data: (i) medical images, such as x-rays and CT scans, (ii) medical record data, (iii) time series data (continuous EEG data), (iv) a combination of any of the first three types of data. We aim to leverage the newly developed tools to continue our evaluation of the efficacy of isolation for flu-like ailments as well as to apply them more broadly to publicly available modern datasets such as the MIMIC III database. Reliable and consistent causal analysis of public health interventions requires the use of massive previously unavailable datastreams. For example, evaluation of the efficacy of isolation interventions on flu-like-illness spread must include information on friendships and interactions between individuals, biometric information, imaging, longitudinal health record data as well as standard demographic data. The proposed research provides machine learning and deep learning tools for properly employing this data for the identification and quantification of causal effects of such treatments that can lead to the development of better public health interventions.",Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data,9750434,R01EB025021,"['Algorithms', 'Biometry', 'Categories', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Electroencephalography', 'Friendships', 'Goals', 'Health', 'Image', 'Individual', 'Intervention', 'Lead', 'Learning', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical Records', 'Methods', 'Modernization', 'Outcome', 'Patients', 'Research', 'Roentgen Rays', 'Rotation', 'Series', 'Stretching', 'Structure', 'System', 'Text', 'Therapeutic', 'Time', 'Treatment Efficacy', 'Work', 'X-Ray Computed Tomography', 'computerized tools', 'data format', 'deep learning', 'efficacy evaluation', 'flu', 'health record', 'improved', 'individualized medicine', 'novel strategies', 'public health intervention', 'tool', 'treatment effect']",NIBIB,DUKE UNIVERSITY,R01,2018,98714,-0.017313460824413658
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9527181,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,545116,-0.01865859727934722
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9507909,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Grain', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'cognitive development', 'computerized', 'cost', 'deep learning', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'sensor technology', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2018,203125,-0.02625008030543258
"Deep Learning to Transform Clinician Autism Diagnostic Assessments and More NODA Telehealth system improves access to an autism diagnostic assessment by guiding families to share video clips of their child at home, so diagnostic clinicians can directly observe and ‘tag’ video of any atypical behavior, and if warranted, render a diagnosis. This system is evidence-based and has been commercialized, with several published studies to discuss the benefits. We now propose to improve this service by developing a Deep (machine) Learning capability in a software product called ‘NODA DL Classifier’ to help clinicians more quickly identify and better quantify typical and atypical behaviors on videos they receive from families. If successful, this NODA DL feature within the NODA system will have a profound impact in the time to reach a firm diagnosis, and then the capability could be used subsequently to effectively monitor treatment progress of individuals diagnosed with autism. In this project, we will determine how much DL improves the diagnostic process. In Phase I, we will test our use previously generated datasets to qualify and quantify potential benefits. In Phase II, we will conduct a clinical study to document time-savings and other clinical benefits. Our proposed NODA DL innovation represents a large step change in identification and then the care for ASD individuals, not an incremental one. It will lead to a significant improvement in both health outcomes and in reduced time required by clinicians or psychologists for office visits and for analyzing video data. This reduced time can be translated into reduced costs. We anticipate that significant commercial benefits will result from the use of our innovative computer methodologies. The proposed computerized Deep Learning (DL) function within our current NODA Telehealth System will have a profound impact in saving time to reach a firm diagnosis of individuals with ASD, plus provide other important benefits.",Deep Learning to Transform Clinician Autism Diagnostic Assessments and More,9465737,R44MH115523,"['Address', 'Applications Grants', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Caring', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Clip', 'Computer Assisted', 'Computer software', 'Computers', 'Current Procedural Terminology Codes', 'DSM-V', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Environment', 'Family', 'Health', 'Health Professional', 'Home environment', 'Image', 'Improve Access', 'Individual', 'Industry', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Measures', 'Medicaid', 'Methodology', 'Modification', 'Monitor', 'Neurodevelopmental Disorder', 'Office Visits', 'Outcome', 'Patients', 'Pattern', 'Phase', 'Privatization', 'Procedures', 'Process', 'Psychologist', 'Publishing', 'Recommendation', 'Savings', 'Services', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Translating', 'Work', 'base', 'behavioral construct', 'clinically relevant', 'computerized', 'cost', 'deep learning', 'evidence base', 'human study', 'improved', 'innovation', 'prototype', 'satisfaction', 'telehealth', 'telehealth systems', 'user-friendly']",NIMH,"CARING TECHNOLOGIES, INC.",R44,2018,149124,-0.07164773604175238
"Development of Machine Learning Algorithms to Assess and Train Vesico-Urethral Anastomosis during Robot Assisted Radical Prostatectomy PROJECT SUMMARY/ABSTRACT CANDIDATE (Andrew J. Hung, MD): My long-term goal is to establish a career in innovating training methods for robotic surgery which will lead to curtailing surgeon learning curve, and maximize patient safety. My first step towards that goal focuses on understanding objective metrics that measure surgeon performance, and how machine learning algorithms can process that data to guide training. I have developed a career development program that builds on my clinical training in robotic urologic surgery and prior research in surgical training. Through mentorship, a fellowship, and formal coursework, this K23 award will provide me the necessary support to develop expertise in 3 areas where I do not have formal training, yet are critical to my success: (1) Machine learning; (2) Surgical education; (3) Advanced statistical skills and study design. MENTORING TEAM: My career development and research plans leverage existing institutional resources, including the USC Machine Learning Center, led by co-primary mentor Dr. Yan Liu; and Keck Hospital of USC, the second busiest robotic center by volume in the United States and the USC Institute of Urology (led by co- primary mentor and chairman Dr. Inderbir Gill), home to pioneers of several urologic surgical techniques with a robust research apparatus supporting several NIH-funded clinical scientists. My mentoring team is complemented by co-mentor Dr. Robert Sweet, a DOD-funded expert on surgical education; career mentor Dr. Larissa Rodriguez, a federally funded clinician/scientist experienced in mentoring K awardees; educational psychology collaborator Dr. Kenneth Yates, an authority on cognitive task analysis; and consultant Dr. Anthony Jarc, at Intuitive Surgical who has supported much of the pilot data on objective performance metrics. The proposed K23 work truly requires the robust collaboration of experts in robotic surgery, education, and machine learning. RESEARCH: The learning curve for surgeons performing robot assisted radical prostatectomy (RARP) is steep: over 100 cases. Current ‘gold standard’ methods of surgical assessment rely on subjective expert review, but such evaluations are time consuming and inconsistent. Nonetheless, credentialing a surgeon to perform robotic surgery has enormous implications - patient outcomes are at risk, and a surgeon’s career is on the line. Informed by my clinical expertise in robotic urological surgery and preliminary data, I will develop a novel method of utilizing machine learning (ML) algorithms to objectively assess robotic surgeon performance and to guide training for the vesico-urethral anastomosis (VUA), the most critical reconstructive part of the robot-assisted radical prostatectomy (RARP). I will develop and validate objective metrics directly captured from the da Vinci robot during the VUA (Aim 1), train machine learning algorithms to assess a surgeon’s performance of VUA (Aim 2), and utilize ML algorithms to guide surgeons learning the VUA (Aim 3). Armed with these data and skills from this award, I will be uniquely suited to utilize machine learning to generalize objective surgeon assessment for robot-assisted surgical procedures within and beyond urology. Finally, the results from this study will provide preliminary data for independent funding through mechanisms such as an NIH R01 grant. PROJECT NARRATIVE The learning curve for surgeons performing robot assisted radical prostatectomy (RARP) for prostate cancer is steep, and current methods of evaluating surgeons require subjective and time-consuming expert review. Streamlined training and assessment utilizing objective performance metrics and machine learning algorithms can significantly curtail learning curve with patients, and decrease the overall morbidity of prostate cancer treatment.",Development of Machine Learning Algorithms to Assess and Train Vesico-Urethral Anastomosis during Robot Assisted Radical Prostatectomy,9581712,K23EB026493,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Anastomosis - action', 'Area', 'Artificial Intelligence', 'Award', 'Chairperson', 'Characteristics', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Credentialing', 'Data', 'Data Analyses', 'Development', 'Education', 'Educational Intervention', 'Educational Psychology', 'Evaluation', 'Event', 'Fellowship', 'Foundations', 'Funding', 'Future', 'Gills', 'Goals', 'Gold', 'Grant', 'Hand', 'Home environment', 'Hospitals', 'Individual', 'Institutes', 'Intervention', 'Intuition', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Medical Research', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Meta-Analysis', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Positioning Attribute', 'Procedures', 'Process', 'Program Development', 'Prostate Cancer therapy', 'Radical Prostatectomy', 'Research', 'Research Design', 'Resources', 'Risk', 'Robot', 'Robotics', 'Scientist', 'Specialist', 'Surgeon', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Urethra', 'Urologic Surgical Procedures', 'Urology', 'Work', 'authority', 'base', 'burden of illness', 'career', 'career development', 'clinically significant', 'cognitive task', 'common treatment', 'computer program', 'data reduction', 'experience', 'feeding', 'functional outcomes', 'improved', 'innovation', 'kinematics', 'male', 'novel', 'patient safety', 'peer', 'reconstruction', 'research and development', 'robot assistance', 'simulation', 'skills', 'success', 'task analysis', 'urologic', 'virtual reality']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,K23,2018,193846,-0.013137163459120709
"Left Ventricular Distribution Patterns of the Regionally varying Ischemic Myocardial Contractile Substrates Associated with Ischemic Mitral Regurgitation PROJECT SUMMARY - ABSTRACT  The loss of mitral leaflet coaptation surface area caused by restrictive chordal tethering to dysfunctional myocardial wall segments is the well-recognized mechanism of ischemic mitral regurgitation (MR). An accurate characterization of the left ventricular (LV) distribution pattern, magnitude, and reversibility of the contractile injury substrates that predispose to the occurrence of ischemic MR may improve the accuracy of therapeutic intervention. Only recently have high-resolution LV regional contractile metrics become clinically available to map myocardial ischemic substrates (hibernating, infarcted) across patient-specific LV geometry. Application of MRI-based multiparametric strain analysis in our pilot ischemic MR study group suggested that high-resolution 3D topographical mapping of LV contractile injury may reveal a more complex array of associated regional contractile injury than is discernible from echocardiography. This initial study identified a “sentinel” LV region (basilar and mid subregions of the posterior and posterolateral LV regions) in which the presence of severe contractile injury clearly predisposes to the development of ischemic MR.  We will enroll ischemic coronary artery disease patients with (≥3+ MR; n=90) and without (≤1+ MR; n=90) ischemic MR who are scheduled for standardized surgery (ACC/AHA Clinical Guidelines). Preoperative MRI- based multiparametric strain analysis will provide high-resolution 3D LV topographical maps of regional contractile injury to statistically correlate to occurrence of ischemic MR and to postoperative studies obtained at 3-months and yearly. An independent core laboratory will catalogue all echocardiography-based metrics of ischemic MR for inclusion in Support Vector Machine analyses, along with all other identified clinical variables.  MRI-based LV displacement datasets are obtained in <30 minutes using Navigator-gated Spiral Displacement ENcoding with Stimulated Echoes (DENSE). Patient-specific LV strain fields are calculated using the recently developed Radial Point Interpolation Method (RPIM). Regional contractile function is “normalized” by comparing multiple patient-specific strain metric values (at each of 11,520 LV grid points) to their respective average +/- SD values from our normal human strain database, with z- score (SD) calculation (total computer analysis <20 seconds). Support Vector Machine analyses will search all metric variables (multiparametric strain, echo-based metrics, and all clinical variables) for patterns that predict ischemic MR recurrence.  We will use high-resolution 3D topographical mapping of “normalized” LV contractile function to characterize the distribution, magnitude, and reversibility of the regional contractile injury substrates (hibernating; infarcted) associated with ischemic MR. We will then test the hypothesis that the novel application of machine learning Support Vector Machine analyses can identify hybrid combinations of both regional contractile injury patterns and clinical variables that accurately predict post-repair recurrence of ischemic MR. PROJECT NARRATIVE  Since the loss of mitral leaflet coaptation surface area caused by restrictive chordal tethering to dysfunctional myocardial wall segments is the well-recognized mechanism of ischemic mitral regurgitation, an accurate characterization of the left ventricular distribution pattern, magnitude, and reversibility of the contractile injury substrates (hibernating/infarcted) that predispose to the occurrence of ischemic mitral regurgitation may improve the accuracy of therapeutic intervention. Only recently have high-resolution LV regional contractile metrics become clinically available to map these myocardial ischemic substrates across patient-specific LV geometry. We will test the hypothesis that in patients with ischemic CAD, the ischemic status of a 4-subregion “sentinel” zone (basilar/mid subregions of posterior/posterolateral regions) is the primary determinant of the presence of significant ischemic MR and that three defining ischemic substrate (infarcted, hibernating) characteristics (location, magnitude, and reversibility) can be used in a hybrid model to predict recurrence of ischemic MR.",Left Ventricular Distribution Patterns of the Regionally varying Ischemic Myocardial Contractile Substrates Associated with Ischemic Mitral Regurgitation,9769299,R56HL136619,"['Angiography', 'Anterolateral', 'Area', 'Cardiac', 'Catalogs', 'Characteristics', 'Clinical', 'Complex', 'Computer Analysis', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Vessels', 'Correlation Studies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dyskinetic syndrome', 'Echocardiography', 'Electrocardiogram', 'Enrollment', 'Geometry', 'Guidelines', 'Hibernation', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Infarction', 'Injury', 'Laboratories', 'Left', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Methodology', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Myocardial', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Postoperative Period', 'Radial', 'Recovery', 'Recurrence', 'Resolution', 'Schedule', 'Sentinel', 'Severities', 'Standardization', 'Surface', 'Testing', 'Therapeutic Intervention', 'Time', 'Troponin', 'Ventricular', 'base', 'improved', 'mathematical model', 'novel', 'papillary muscle', 'prognostic', 'repaired', 'response']",NHLBI,WASHINGTON UNIVERSITY,R56,2018,389375,-0.012587549655476921
"A Modular Automated Platform for Large-scale Drosophila Experiments and Handling PROJECT SUMMARY / ABSTRACT Animal model systems are a powerful tool researchers use to investigate almost all aspects of biology: genetics, development, neuroscience, disease, and more. And fruit flies – Drosophila melanogaster – with their small size, easy care, and remarkable array of available genetic toolkits, occupy a sweet spot on the model organism spectrum. Over 75% of human diseases with a genetic basis have an analogue in the fly, and Drosophila have been a part of the research for six Nobel prizes. Furthermore, the advent of CRISPR/cas9 and other modern genetic tools has opened the door to modeling other diseases and pathways, leading to greater use of Drosophila for drug screens. A great deal of the work (and the majority of the budget) involved in fly experiments is tedious manual labor, and with advances in computer vision, machine learning, and other analytic techniques, the stage is set to automate many phenotypic screens. In this Phase I SBIR, we propose a robotic system – modular automated platform for large-scale experiments (MAPLE) – that can accomplish a wide variety of fly-handling tasks in Drosophila labs. This robot is the fruit fly version of a liquid handling robot, with a large, open workspace that can house a plethora of modules and several manipulators that can move small parts and animals around that workspace. Building on a collaboration between the de Bivort Lab and FlySorter completed in 2017, we will design, fabricate and validate a commercial system that can collect virgin flies, run behavioral assays, conduct drug screens, and adapt to the needs of fly labs through easy-to-code Python scripts. By strategically combining modules and instructions to the robot, MAPLE can perform a wide variety of tasks in a fly lab, saving experimentalists from repetitive chores, cutting labor costs, and increasing scientific output. Just as pipette robots have become standard equipment in wet labs, we envision our fly handling robot will be the engine that powers Drosophila labs in academia and pharma, enabling new kinds of experiments and freeing researchers from the drudgery of fly pushing. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are a powerful model organism used in the study of disease, neuroscience, development, genetics, and recently in drug screens, too, largely through phenotypic screening. This labor-intensive work is time consuming and expensive, and ripe for automation. We propose a fly-handling robot – analogous to a liquid pipetting robot in a wet lab – that can perform a variety of tasks in Drosophila labs, free researchers from the drudgery of fly pushing, and enable a broader spectrum of experiments that will increase scientific knowledge.",A Modular Automated Platform for Large-scale Drosophila Experiments and Handling,9623017,R43MH119092,"['Academia', 'Address', 'Affect', 'Air', 'Anesthesia procedures', 'Animal Model', 'Animals', 'Architecture', 'Automation', 'Basic Science', 'Behavior', 'Behavioral Assay', 'Biological Models', 'Biology', 'Budgets', 'CRISPR/Cas technology', 'Carbon Dioxide', 'Caring', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Data Collection', 'Deposition', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Screening', 'Drug usage', 'Ensure', 'Equipment', 'Feedback', 'Genetic', 'Genetic Screening', 'Genetic study', 'Grant', 'Hand', 'Human', 'Instruction', 'Knowledge', 'Libraries', 'Liquid substance', 'Machine Learning', 'Manuals', 'Modeling', 'Modernization', 'Neurosciences', 'Nobel Prize', 'Organism', 'Output', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Protocols documentation', 'Pythons', 'Reagent', 'Research', 'Research Personnel', 'Robot', 'Robotics', 'Running', 'Savings', 'Scanning', 'Small Business Innovation Research Grant', 'Speed', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Transgenic Organisms', 'Travel', 'Universities', 'Update', 'Vacuum', 'Work', 'analog', 'bone', 'cost', 'design', 'drug discovery', 'experimental study', 'flexibility', 'fly', 'graduate student', 'health science research', 'human disease', 'improved', 'operation', 'programs', 'repository', 'robot control', 'screening', 'tool', 'touchscreen']",NIMH,"FLYSORTER, LLC",R43,2018,348007,-0.02730439981055369
"Smartphone phenotype collection for diagnostic screening of mild cognitive impairment Project Summary This project addresses a critical need for early detection of mild cognitive impairment (MCI) and other Alzheimer's-related dementias (ADRD). Advances in smartphone hardware, computer vision, and machine learning have enabled the possibility of producing smartphone-based cognitive testing applications able to collect electronic sensor data and transform it into highly informative phenotypes that can serve as early indicators of future disease progression. In this project, we aim to develop a revolutionary new smartphone- based cognitive testing platform, called CTX, that will enable the rapid development and deployment of smartphone-based tests that can capture raw sensor streams in a synchronized fashion, subsample and compress the combined streams, and transmit them to a cloud server for subsequent analysis and modeling. CTX will provide a high-level application development framework that will significantly reduce the time and technical knowledge required to produce a smartphone-based cognitive testing application by providing an application programming interface (API) that enables developers to simply declare what sensor data should be collected and when. The framework will handle all the details of collecting the sensor data, synchronizing it, and transmitting it to a back-end server. The API will also have a variety of other high-level features to facilitate development of cognitive test apps. To demonstrate the feasibility of our vision for CTX, in Aim 1 of this project we will develop the software framework, back-end server software and a prototype smartphone app to exercise and validate many of the platform's features. For Aim 2, we will develop three different tests for this app to test saccade (eye movement) latency, verbal recall, and wrist mobility, each collecting a different type of sensor data (video, audio, and inertial measurement). These tests were selected because their results have been been shown to be predictive of MCI. We will implement phenotype extraction pipelines that employ advanced signal processing, machine learning, and computer vision algorithms to extract the target phenotypes from the sensor data collected for these tests and demonstrate they operate with sufficient accuracy to replicate published experimental designs. Successful completion of this project will eliminate the need for expensive and cumbersome phenotype collection equipment (e.g., eye tracking stations) and create the possibility of generating data from which MCI onset can be predicted. Data collected in Phase II via these and other such tests will enable us to apply our machine learning expertise to produce models able to predict transition to MCI that are both sensitive and specific, transforming any smartphone into an MCI risk assessment tool available for at-home use by millions of people. Project Narrative This NIH Phase I project will address the critical need for early detection of Alzheimer's Disease (AD) and Alzheimer's-related dementias (ADRD) by developing a revolutionary new smartphone-based cognitive testing platform that will provide individuals with an ongoing status of their cognitive health. Doctors who are given access to the results of these tests will be able to monitor patients more closely and provide more timely diagnoses. By studying test results from many people, researchers may someday be able to identify patterns that can distinguish mild cognitive impairment from normative age-related cognitive decline.",Smartphone phenotype collection for diagnostic screening of mild cognitive impairment,9679400,R43AG062072,"['Achievement', 'Address', 'Adult', 'Age', 'Age-associated memory impairment', 'Algorithms', 'Alzheimer disease detection', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Apple', 'Assessment tool', 'Back', 'Big Data', 'Cellular Phone', 'Cognitive', 'Collection', 'Computer Vision Systems', 'Computer software', 'Cyclophosphamide', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic tests', 'Disease Progression', 'Early Diagnosis', 'Elderly', 'Emotional', 'Equipment', 'Exercise', 'Exhibits', 'Experimental Designs', 'Eye', 'Eye Movements', 'Face', 'Facial Expression', 'Forearm', 'Frequencies', 'Future', 'Genetic Risk', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Image', 'Individual', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Memory impairment', 'Methods', 'Modeling', 'Monitor', 'Patient Monitoring', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Publishing', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Risk Assessment', 'Rotation', 'Saccades', 'Scanning', 'Secure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Software Framework', 'Software Tools', 'Stream', 'Tablets', 'Telephone', 'Test Result', 'Testing', 'Time', 'United States National Institutes of Health', 'Vision', 'Visuospatial', 'Work', 'Wrist', 'Yang', 'age related', 'age related cognitive change', 'application programming interface', 'base', 'cloud platform', 'cognitive development', 'cognitive task', 'cognitive testing', 'cohort', 'cost', 'crowdsourcing', 'data modeling', 'diagnostic screening', 'interest', 'markov model', 'mild cognitive impairment', 'predictive modeling', 'prototype', 'response', 'screening', 'sensor', 'signal processing', 'smartphone Application', 'software development', 'success']",NIA,"PARABON NANOLABS, INC.",R43,2018,394297,-0.04348061054997155
"Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope Project​ ​Summary/Abstract This​ ​SBIR​ ​Phase​ ​I​ ​project​ ​will​ ​develop​ ​a​ ​deep​ ​learning-based​ ​clinical​ ​decision​ ​support​ ​algorithm for​ ​identifying​ ​aortic​ ​stenosis​ ​from​ ​heart​ ​sounds​ ​recorded​ ​using​ ​the​ ​Eko​ ​Core​ ​Digital Stethoscope.​ ​This​ ​screening​ ​tool​ ​will​ ​help​ ​to​ ​decrease​ ​the​ ​number​ ​of​ ​patients​ ​with​ ​severe asymptomatic​ ​aortic​ ​stenosis​ ​that​ ​remain​ ​undertreated​ ​simply​ ​because​ ​the​ ​condition​ ​is​ ​not diagnosed.​ ​Auscultation​ ​is​ ​commonly​ ​the​ ​method​ ​by​ ​which​ ​valvular​ ​heart​ ​disease​ ​is​ ​first detected,​ ​but​ ​cases​ ​often​ ​fail​ ​to​ ​be​ ​referred​ ​to​ ​echocardiography​ ​for​ ​diagnosis​ ​because clinicians​ ​fail​ ​to​ ​detect​ ​heart​ ​murmurs,​ ​particularly​ ​in​ ​noisy​ ​or​ ​rushed​ ​environments.​ ​To​ ​address this​ ​challenge,​ ​Eko​ ​had​ ​developed​ ​the​ ​Core,​ ​a​ ​digital​ ​stethoscope​ ​attachment​ ​that​ ​can​ ​be​ ​added in-line​ ​to​ ​a​ ​clinician’s​ ​existing​ ​stethoscope​ ​that​ ​amplifies​ ​heart​ ​sounds​ ​and​ ​streams​ ​digitized phonocardiograms​ ​to​ ​a​ ​smartphone,​ ​tablet​ ​or​ ​personal​ ​computer.​ ​There,​ ​the​ ​signal​ ​can​ ​be analyzed​ ​with​ ​the​ ​decision​ ​support​ ​algorithm​ ​we​ ​will​ ​develop​ ​as​ ​part​ ​of​ ​this​ ​project.​ ​The​ ​specific aims​ ​of​ ​this​ ​study​ ​are​ ​(1)​ ​to​ ​​collect​ ​a​ ​database​ ​with​ ​condition-specific​ ​recording​ ​labels​ ​to enable​ ​deep​ ​learning​ ​for​ ​heart​ ​sounds​ ​though​ ​clinical​ ​data​ ​collection​ ​at​ ​UCSF​ ​and​ ​(2)​ ​to develop​ ​and​ ​evaluate​ ​a​ ​deep​ ​convolutional​ ​neural​ ​network-based​ ​algorithm​ ​trained​ ​on​ ​the database.​ ​By​ ​integrating​ ​this​ ​deep​ ​learning​ ​algorithm​ ​into​ ​Eko’s​ ​mobile​ ​and​ ​cloud​ ​software platform,​ ​currently​ ​used​ ​by​ ​clinicians​ ​at​ ​over​ ​700​ ​institutions​ ​worldwide,​ ​we​ ​anticipate​ ​this algorithm​ ​will​ ​enable​ ​more​ ​accurate​ ​screening​ ​for​ ​aortic​ ​stenosis,​ ​leading​ ​to​ ​earlier​ ​diagnosis and​ ​better​ ​patient​ ​outcomes. SBIR​ ​Project​ ​Narrative Valvular​ ​heart​ ​disease,​ ​and​ ​aortic​ ​stenosis​ ​in​ ​particular,​ ​are​ ​becoming​ ​increasingly​ ​prevalent manifestations​ ​of​ ​poor​ ​cardiovascular​ ​health​ ​in​ ​both​ ​the​ ​developed​ ​and​ ​developing​ ​world.​ ​A highly-accurate​ ​clinical​ ​decision​ ​support​ ​algorithm​ ​that​ ​is​ ​able​ ​to​ ​detect​ ​aortic​ ​stenosis​ ​will impact​ ​public​ ​health​ ​by​ ​reducing​ ​unnecessary​ ​referrals​ ​for​ ​echocardiography​ ​and​ ​promoting early​ ​and​ ​accurate​ ​diagnosis​ ​in​ ​underserved​ ​areas​ ​with​ ​limited​ ​access​ ​to​ ​subspecialty​ ​care.",Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope,9621223,R43HL144297,"['Address', 'Algorithms', 'Aortic Valve Stenosis', 'Area', 'Auscultation', 'Benign', 'Biological Neural Networks', 'Cardiac', 'Caring', 'Cellular Phone', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Computer software', 'Data Collection', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Echocardiography', 'Eko', 'Environment', 'Evaluation', 'FDA approved', 'Future', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Heart Abnormalities', 'Heart Sounds', 'Heart Valve Diseases', 'Heart murmur', 'Hospitals', 'Human', 'Image', 'Imaging Techniques', 'Institution', 'Label', 'Learning', 'Medical Device', 'Medicare', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Monitor', 'Network-based', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Physicians', 'Positioning Attribute', 'Public Health', 'Resources', 'Screening procedure', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Specificity', 'Stethoscopes', 'Stream', 'Tablet Computer', 'Testing', 'Training', 'Weight', 'accurate diagnosis', 'base', 'cardiovascular health', 'clinical decision support', 'clinical development', 'clinically significant', 'cloud software', 'commercialization', 'cost', 'deep learning', 'deep neural network', 'diagnosis standard', 'digital', 'innovation', 'screening', 'speech recognition']",NHLBI,"EKO DEVICES, INC.",R43,2018,295881,-0.05215724066059703
"Automating Real-Time Localization of Target Sites in Catheter Ablation of Ventricular Tachycardia Project Summary Ventricular tachycardia (VT) is an important cause of mortality and morbidity in patients with heart diseases. The majority of life-threatening VT episodes are caused by an electrical ""short circuit” that travels through narrow strands of surviving tissue inside myocardial scar. Catheter ablation treats scar-related VT by “blocking” the surviving channel that forms the circuit, commonly at the site the circuit exits from the scar. To localize a VT exit, however, remains a significant challenge. A common approach, known as pace-mapping, utilizes the principle that the VT exit serves as the origin of ventricular activation and determines the QRS morphology on 12-lead electrocardiograms (ECGs). It thus involves repetitive electrical simulation at various sites of the heart, until locating the site that reproduces the QRS of the VT on all 12 ECG leads. While the principle behind pace- mapping is time tested, the current practice is of a ""trial-and-error"" nature and requires rapid qualitative interpretation of the ECG by clinicians, which can be time-consuming and inaccurate. This research proposes to leverage modern machine learning techniques to reform the way the principle behind pace-mapping is used. It aims to learn the relationship between the origin of ventricular activation and ECG morphology, and then use it to directly predict the exit of a VT from its ECG data. To this end, this project will include the following activities: 1) to develop a population-based model to provide pre-procedural initial localizations of VT exits using standard 12-lead ECG; 2) to integrate the population-based model with a patient-specific model in clinically-usable software to provide intra-procedural real-time guidance for localizing the exit site of a clinical VT; and 3) to assess the ability of the proposed software to improve the efficiency and accuracy of pace- mapping in a prospective clinical study. This project will be carried out by a multidisciplinary team of computational and clinical scientists with a fruitful record of collaboration. The software delivered by this project will provide real-time assistance to clinicians for narrowing down a VT exit with a minimum amount of time and localization errors. This will substantially reduce the workload for ablating multiple VTs, potentially allowing clinicians to ablate more or even all VTs seen in a procedure. This may reduce the duration of an ablation procedure while improving its outcome. The development and deployment of the software also adds minimal cost or distractions to routine workflow. With a low barrier to clinical implementation, it will have a real potential to challenge and improve the standard practice of catheter ablation. Project Narrative Catheter ablation treats ventricular arrhythmia by destroying the culprit tissue responsible for the arrhythmia. To localize the culprit tissue, however, remains a tedious process with limited success in current practice. This project will develop inexpensive software to guide clinicians towards the culprit tissue in real time during the procedure, helping narrow down the ablation target with a minimum amount of time and localization errors.",Automating Real-Time Localization of Target Sites in Catheter Ablation of Ventricular Tachycardia,9590857,R15HL140500,"['Ablation', 'Arrhythmia', 'Attention', 'Cardiac ablation', 'Cicatrix', 'Clinical', 'Clinical Research', 'Collaborations', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Data Set', 'Development', 'EKG QRS Complex', 'Electrocardiogram', 'Encapsulated', 'Goals', 'Heart', 'Heart Diseases', 'Hybrids', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Morphology', 'Myocardial', 'Nature', 'Outcome', 'Patients', 'Population Database', 'Procedures', 'Process', 'Recurrence', 'Research', 'Scientist', 'Site', 'Techniques', 'Testing', 'Time', 'Tissues', 'Travel', 'Variant', 'Ventricular', 'Ventricular Arrhythmia', 'Ventricular Tachycardia', 'Workload', 'clinical implementation', 'cost', 'deep learning', 'design', 'distraction', 'improved', 'interest', 'mortality', 'multidisciplinary', 'novel', 'population based', 'prevent', 'prospective', 'simulation', 'software development', 'success', 'sudden cardiac death', 'usability']",NHLBI,ROCHESTER INSTITUTE OF TECHNOLOGY,R15,2018,419810,-0.01002262020384767
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9499823,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Research Infrastructure', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radiofrequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2018,416374,-0.0062000952965249895
"IGF::OT::IGF SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track) The overall objective of this Fast-Track SBIR contract project is to develop DigiBioMarCTM (Digital BioMarkers for Clinical Impact), a scalable and flexible cloud-based platform to capture and analyze wearable, implantable, or external device data. This platform also provides an informatics tool for automated data aggregation, integration, and machine learning algorithms. It is based on the scalable user-centered Medable platform, which implements standardization and normalization of patient-generated data to drive health insights. DigiBioMarCTM will compare and combine disparate data streams to understand contextualized patient physiology in real time in order to identify disease and/or detect changes in disease/health status. It also will support cohort and clinical studies, particularly those testing digital biomarkers from wearable sensor technologies. This Fast-Track project will focus on product development with an ultimate aim of a product that improves cancer research data and clinical trials, enhances clinical care, and that can be used to engage patients in preventive health behaviors and treatment adherence. The Phase I goal is to develop a data-agnostic DigiBioMarCTM prototype for validation in Phase II. The Phase 1 Go/No-Go decision point to proceed to Phase II will be a working prototype with specified features for further development and validation in Phase II. n/a",IGF::OT::IGF SBIR Topic 379: DigiBioMarC: Digital BioMarkers for Clinical Impact- Moonshot Project(Fast Track),9788845,61201800010C,"['Algorithms', 'Biological Markers', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Computer software', 'Contracts', 'Data', 'Data Aggregation', 'Development', 'Devices', 'Disease', 'Documentation', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Informatics', 'Machine Learning', 'Patients', 'Phase', 'Physiology', 'Preventive', 'Publishing', 'Reporting', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Standardization', 'Stream', 'System', 'Testing', 'Time', 'Validation', 'anticancer research', 'base', 'clinical care', 'cloud based', 'digital', 'flexibility', 'graphical user interface', 'improved', 'insight', 'knowledge base', 'product development', 'prototype', 'sensor', 'skills', 'tool', 'treatment adherence', 'wearable sensor technology']",NCI,"MEDABLE, INC.",N01,2018,224294,-0.011694717450635375
"Development of label-free computational flow cytometry for high-throughput micro-organism classification The purpose of flow cytometers is to enable the classification of cells or organisms at high throughput. Label-free optical flow cytometers not based on fluorescence are generally based on scattering. The most common of these compares the amount of forward (FS) versus side (SS) scattering. Such two-parameter information permits rudimentary classification based on size or granularity, but it misses more subtle features that can be critical in defining organism identity. Nevertheless, FS/SS flow cytometry remains popular, largely because of its simplicity and capacity for high throughput.  We propose to develop a label-free computational flow cytometer that preserves much of the simplicity and high-throughput capacity of FS/SS flow cytometry, but provides significantly enhanced information. Instead of characterizing organisms based on scattering direction (as does FS/SS flow cytometry), we will characterize based on scattering patterns. We will insert a reconfigurable diffractive element in the imaging optics of a flow cytometer to route user-defined basis patterns to independent detectors. The basis patterns will be optimally matched to specific sample features. The respective weights of these basis patterns will serve as signatures to identify organisms of interest. The basis patterns themselves will be determined by machine learning algorithms. Both the device and the learning algorithms will be developed from scratch.  We anticipate that our flow cytometer will be able to operate at flow rates on the order of meters per second, commensurate with state-of-the-art FS/SS flow cytometers, while providing significantly more information for improved classification capacity. While our technique should be advantageous for any label-free flow cytometry application requiring high throughput, we will test it here by demonstrating high-throughput classification of microbial communities. NARRATIVE Our goal is to improve the information extraction capacity of label-free flow cytometers, while maintaining high throughput capacity. As such, our device should have a broad range of applications.",Development of label-free computational flow cytometry for high-throughput micro-organism classification,9510096,R21GM128020,"['Address', 'Algorithms', 'Awareness', 'Bioinformatics', 'Biological', 'Biology', 'Categories', 'Cells', 'Classification', 'Communities', 'Custom', 'Detection', 'Development', 'Devices', 'Elements', 'Flow Cytometry', 'Fluorescence', 'Goals', 'Image', 'Image Compression', 'Label', 'Learning', 'Light', 'Machine Learning', 'Measurement', 'Microbe', 'Modernization', 'Optics', 'Organism', 'Pattern', 'Performance', 'Pupil', 'Resolution', 'Route', 'Sampling', 'Side', 'Signal Transduction', 'Specificity', 'Speed', 'Techniques', 'Testing', 'Traction', 'Validation', 'Weight', 'base', 'cellular imaging', 'cost', 'cost effective', 'design', 'detector', 'improved', 'interest', 'meter', 'microbial community', 'microorganism', 'microorganism classification', 'optical imaging', 'prototype', 'recruit']",NIGMS,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2018,239527,-0.006478136599454918
"Patient specific 3D printed tissue engineered vascular graft for aortic reconstruction designed by artificial intelligence algorithm. 1 The goal of this study is to create patient-specific, hemodynamically optimized, tissue engineered  2 vascular grafts (TEVG) for use in aortic arch repair surgery. These TEVGs are optimized for high pressure  3 circulation using 3D printing technology and artificial intelligence, and will grow with the patient, in hopes of  4 obviating need for future surgeries to replace grafts, which can occur with contemporary arch reconstruction  5 materials. Congenital heart disease (CHD) is the leading cause of death due to congenital anomalies. Despite  6 significant advances in surgical management for CHD, one significant source of morbidity and mortality arises  7 from the complexity of surgery for diverse anatomies in the aortic arch. Previous studies have demonstrated  8 that the resultant arch geometry after surgical reconstruction of stenotic or hypoplastic aortas is important to  9 minimize reduce energy loss and undesirable flow inside the arch, which can lead to hypertension, abnormal 10 vascular response and ventricular dysfunction. Ensuring a patient-specific graft design for ideal reconstructed 11 route before surgery with minimum energy loss and wall shear stress may yield long-term benefits for patient 12 health and quality of life. 13 We have demonstrated native vessel like neotissue formation of TEVG in small and large animal 14 studies. Based on these experiences, we have developed a novel 3D printing technology combining 3D printed 15 metal mandrels with nanofiber electro-spun technology. With this 3D printing technology, we showed that 16 TEVG developed native like neovessel formation in venous circulation in a sheep model. For this next step, we 17 aim to develop grafts in arterial circulation that can be applied to aortic reconstruction. We will also develop 18 automatic design algorithms to design optimal graft shape in order to reduce time and cost of patient specific 19 design. We hypothesize that patient-specific TEVG using our 3D printing technology can be designed, 20 aided by pre-operative imaging and flow data, computer assisted design (CAD), automatic design 21 algorithms based on computation fluid dynamics (CFD) results, and will demonstrate proper neotissue 22 formation and growth while maintaining optimally designed hemodynamics. 23 This project will be an important step towards clinical application of patient-specific vascular grafts that 24 recapitulate the native anatomy and mechanical properties. The results of this work will have a broader impact 25 on the design and fabrication of other more complex cardiovascular structures for implantation. This paradigm 26 shift in vascular graft technology will improve the quality and safety of pediatric patient care. The goal of this study is to create patient-specific, hemodynamically optimized, tissue engineered vascular grafts using 3D printing technology and artificial intelligence for use in aortic arch repair surgery which demands a structured surgical approach in order to optimize hemodynamics postoperatively. We will optimize the design of an aortic graft automatically using computational flow dynamics, refine 3D printing manufacturing, evaluate grafts with in-vitro testing, and finally will test the performance of the grafts in vivo over time. This paradigm shift in vascular graft technology will improve the quality, safety and longevity of pediatric cardiovascular care.",Patient specific 3D printed tissue engineered vascular graft for aortic reconstruction designed by artificial intelligence algorithm.,9580526,R01HL143468,"['3D Print', 'Acute', 'Adult', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Animals', 'Aorta', 'Artificial Intelligence', 'Blood Circulation', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Cause of Death', 'Childhood', 'Clinic', 'Complex', 'Computer-Aided Design', 'Computers', 'Custom', 'Data', 'Descending aorta', 'Ensure', 'Experimental Animal Model', 'FDA approved', 'Future', 'Geometry', 'Goals', 'Growth', 'Health', 'Histologic', 'Hypertension', 'Image', 'Implant', 'In Vitro', 'Inferior vena cava structure', 'Lead', 'Liquid substance', 'Longevity', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Organ', 'Patient Care', 'Patients', 'Performance', 'Physiological', 'Postoperative Period', 'Printing', 'Process', 'Quality of life', 'Route', 'Safety', 'Shapes', 'Sheep', 'Source', 'Structure', 'Surgical Management', 'Technology', 'Time', 'Tissue Engineering', 'Tissues', 'Translating', 'Vascular Graft', 'Venous', 'Ventricular Dysfunction', 'Work', 'aortic arch', 'base', 'clinical application', 'congenital anomaly', 'congenital heart disorder', 'cost', 'design', 'experience', 'hemodynamics', 'implantation', 'improved', 'in vitro testing', 'in vivo', 'mechanical properties', 'model design', 'mortality', 'nanofiber', 'novel', 'pediatric patients', 'performance tests', 'pressure', 'reconstruction', 'repaired', 'response', 'scaffold', 'shear stress', 'surgery outcome', 'vascular tissue engineering']",NHLBI,JOHNS HOPKINS UNIVERSITY,R01,2018,776125,-0.011166571752904458
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9579149,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2018,314000,-0.022071014994134063
"Quantifying NETosis via Automated High Content Imaging Convolutional Neural Networks PROJECT SUMMARY NETosis was identified as a distinct mode of cell death in neutrophils more than a decade ago. Dysregulation of NETosis has been implicated in the etiology of human pathologies such as preeclampsia, sickle cell disease, systemic lupus erythematosus, multiple sclerosis, rheumatoid arthritis, sepsis, cystic fibrosis, lupus nephritis, and coagulopathies that include cancer-associated thrombosis. The literature consistently cites the lack of a standardized methodology for quantitation of NETosis as an impediment to basic and translational research. Thus, the premise is that there is a compelling, unmet need for a standardized, quantitative and automated method for the measurement of NETosis to accelerate neutrophil and inflammation-based research and facilitate the discovery and development of therapeutic compounds. The scope of this STTR project is to develop a high-throughput image analysis and quantitation method by using high content imaging and the revolutionary technology of convolutional neural networks (CNN) for the identification and quantitation of NETosis in human neutrophils. The target readout is based on the primary morphological difference between NETotic and non-NETotic nuclei--the decondensation of chromatin. This image-based quantitative method will be observer-independent and will enable robust and rapid evaluation of a large number of samples that would exceed any attempts at manual assessment. In Phase I we will complete the following Specific Aims: Aim 1: Optimize and standardize the high- throughput platform for quantitation of NETosis in adherent human neutrophils. This includes standard assay optimization procedures, training the CNN to identify and quantitate NETotic neutrophil, and demonstrating that the CNN reliably distinguishes between necrosis and NETosis, whose phenotypes appear similar to the human eye. Aim 2: Validate the NETosis assay biochemically and clinically. This includes concentration-response assays with NETosis agonists, assessment of NETosis inhibitors, and evaluation of the NETotic status of Sickle Cell Disease patient samples (a disease in which aberrant NETosis has been implicated). The expected outcome of this Phase I effort is to demonstrate proof-of-concept for this automated high- throughput NETosis assay. Further, we expect to provide insight into the utility of the assay for assessment of inhibitors of NETosis as therapeutic agents. Upon completion of our Phase I aims, our Phase II program will focus on further optimizing and validating this NETosis assay and preparing it for commercialization.   PROJECT NARRATIVE Aberrant NETosis has been implicated in the etiology of several inflammatory and autoimmune diseases. The lack of a standardized, quantitative and automated method for the measurement of NETosis is impeding basic and translational research. We have developed a high-throughput assay using convolutional neural networks to quantify NETosis in human neutrophils. This assay will accelerate neutrophil and inflammation-based research and facilitate the discovery and development of compounds with therapeutic potential.",Quantifying NETosis via Automated High Content Imaging Convolutional Neural Networks,9465292,R41AI131840,"['Agonist', 'Apoptosis', 'Autoimmune Diseases', 'Basic Science', 'Benchmarking', 'Biochemical', 'Biochemical Pathway', 'Biological Assay', 'Biological Neural Networks', 'Blood Coagulation Disorders', 'Caymans', 'Cell Death', 'Cell Death Process', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Clinical', 'Cystic Fibrosis', 'DNA', 'Data', 'Development', 'Diagnostic', 'Diagnostic tests', 'Diagnostics Research', 'Disease', 'Drug Screening', 'Ensure', 'Enzymes', 'Etiology', 'Evaluation', 'Eye', 'Histones', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Impairment', 'Infection', 'Inflammation', 'Inflammatory', 'Innate Immune Response', 'Letters', 'Literature', 'Lupus Nephritis', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Morphology', 'Multiple Sclerosis', 'Nature', 'Necrosis', 'Nuclear', 'Opportunistic Infections', 'Outcome', 'Pathway interactions', 'Patients', 'Peptide Hydrolases', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physical condensation', 'Population', 'Pre-Eclampsia', 'Predisposition', 'Procedures', 'Process', 'Publishing', 'Reproducibility', 'Research', 'Rheumatoid Arthritis', 'Sampling', 'Sepsis', 'Severity of illness', 'Sickle Cell Anemia', 'Side', 'Small Business Technology Transfer Research', 'Specificity', 'Stains', 'Standardization', 'Systemic Lupus Erythematosus', 'Technology', 'Therapeutic', 'Therapeutic Agents', 'Thrombosis', 'Training', 'Translational Research', 'antimicrobial', 'antimicrobial peptide', 'base', 'commercial application', 'commercialization', 'extracellular', 'high throughput screening', 'inhibitor/antagonist', 'innovation', 'insight', 'neutrophil', 'novel', 'patient population', 'predictive test', 'programs', 'response', 'suicidal', 'symptom management', 'therapeutic development', 'tool']",NIAID,"EPICYPHER, INC.",R41,2018,299751,-0.026644201578722514
"Predicting contrast enhancement in multiple sclerosis with real time texture analysis Description: Identification of active lesions is critical for the management of multiple sclerosis (MS) patients. Currently this identification is based on post-contrast T1-weighted magnetic resonance imaging (MRI). However, there are safety concerns with repeated administration of gadolinium –based contrast agents (GBCAs). Thus, there is critical need for identifying active lesions without the use of GBCA. In this application we propose to identify the active lesions without administering GBCA using texture analysis (TA) using multi- modal non-contrast MRI and support vector machine (SVM) learning. A unique feature of this proposal is that the results will be analyzed using MRI data acquired on a large cohort of MS patients (~1000) as a part of phase III, randomized, double-blinded clinical trial (CombiRx). In addition texture features will be identified that can predict lesions that convert into tissue destructive lesions, so called black holes. This has important clinical implications since there is correlative evidence that balk holes are associated with clinical disability. A novelty of this project lies in performing texture analysis in real time that allows the physician to make the decision about administering GBCA on the spot while the patient is still in the scanner. This greatly helps in eliminating and/or minimizing the number of times GBCA needs to be administered. For real time analysis, the necessary infrastructure that includes automatic processing pipeline and integration of the MRI scanner with high performance computational resources located at Texas Advanced Computing Center (TACC) in Austin. Finally to establish real time TA as a viable alternative to GBCA administration for identifying active lesions, the developed methods will be prospectively applied to MS patients undergoing MRI scans as a part of routine clinical management. Public health relevance: Gadolinium based contrast agents (GBCAs) are routinely used for identifying active lesions in multiple sclerosis patients. However, there are safety concerns with repeated administration of GBCA. This proposal uses novel real time analysis for identifying lesions that are likely to enhance on pre- contrast MRI. Considering the large number of MS patients who are frequently scanned with GBCA, this proposal has a high degree of clinical relevance.",Predicting contrast enhancement in multiple sclerosis with real time texture analysis,9650821,R56NS105857,"['Advanced Development', 'Clinical', 'Clinical Management', 'Clinical Trials', 'Computer software', 'Contrast Media', 'Cross-Sectional Studies', 'Data', 'Decision Making', 'Double-Blind Method', 'Effectiveness', 'Enhancing Lesion', 'Evaluation', 'Gadolinium', 'Generations', 'Gold', 'Gray unit of radiation dose', 'Image', 'Image Analysis', 'Left', 'Lesion', 'Liquid substance', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modality', 'Multiple Sclerosis', 'Neuraxis', 'Pathology', 'Patients', 'Performance', 'Phase', 'Physicians', 'Prospective Studies', 'Protons', 'Randomized', 'Recovery', 'Research Infrastructure', 'Role', 'Safety', 'Sample Size', 'Sampling', 'Scanning', 'Spottings', 'Techniques', 'Technology', 'Texas', 'Texture', 'Time', 'Tissues', 'Treatment Efficacy', 'Validation', 'attenuation', 'austin', 'base', 'black hole', 'clinically relevant', 'cohort', 'computing resources', 'contrast enhanced', 'density', 'disability', 'high end computer', 'imaging facilities', 'multiple sclerosis patient', 'novel', 'parallel processing', 'prospective', 'public health relevance']",NINDS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R56,2018,535749,-0.026863504256192737
"Automated Assessment of Cognitive Tests for Detecting Mild Cognitive Impairment SUMMARY Detecting the first and earliest stages of cognitive decline, conceptualized as “mild cognitive impairment” (MCI), has become increasingly important in recent years, as research focuses on delaying the manifestations of more severe stages of decline. It is now well recognized that changes in performance on cognitive tests begin up to ten years (or longer) before clinically apparent symptoms of dementia or functional impairment appear. Conventional assessment methods for assessing cognition Conventional assessment methods typically use the spoken response modality in which subjects are asked to verbally respond to prompts, and examiners carefully listen to these responses and apply test manuals to compute scores. These assessment methods require trained specialists and can be burdensome because they need to performed in clinics, especially so with frequent reassessment. Automating the scoring of assessment is important, not only for alleviating this burden but also for enabling large-scale studies on new intervention methods. Our research goal is to automate detection of MCI by developing, applying, and evaluating a system for automation of verbal (i.e., using spoken responses) cognitive-test scoring. Focusing on four verbal cognitive tests, we develop an extensible system comprising ASR and machine-learning algorithms to automatically score responses, and measure the efficacy of our proposed method by validating the accuracy of the automatically obtained scores against gold-standard, clinically obtained scores (Aim 1). Next, we develop classification methods for detecting individuals with MCI based on all information available in the verbal responses, and validating this classification against gold-standard clinical consensus. NARRATIVE Early detection of mild cognitive disease (MCI) is significantly important to delay more severe stages of cognitive decline. Conventional assessment methods require trained specialists and can be financially beyond the reach of most. We propose a tool for automatically scoring verbal cognitive tests. The proposed tool can be embedded in electronic devices providing the opportunity to assess large number of people in their homes, enabling clinicians to focus on those who are most at risk of cognitive decline.",Automated Assessment of Cognitive Tests for Detecting Mild Cognitive Impairment,9531223,R21AG055749,"['Adverse effects', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Automation', 'Classification', 'Clinic', 'Clinical', 'Cognition', 'Cognition Disorders', 'Complex', 'Consensus', 'Data', 'Dementia', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Digit structure', 'Early Diagnosis', 'Electronics', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Heart failure', 'Home environment', 'Impaired cognition', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Modality', 'Needs Assessment', 'Nerve Degeneration', 'Output', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Public Domains', 'Research', 'Risk', 'Sleep Disorders', 'Specialist', 'Structure', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Transcript', 'Vascular Cognitive Impairment', 'Work', 'base', 'cognitive testing', 'cooperative study', 'design', 'functional disability', 'healthy aging', 'mild cognitive impairment', 'response', 'speech recognition', 'statistics', 'tool', 'usability']",NIA,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2018,187784,-0.0285778622326824
"Predicting complicated grief from grief processing PROJECT SUMMARY Most people grieving the loss of a loved one will experience a period of intense pain and focusing on the loss lasting around 6 months, which is known as acute grief. Complicated grief (CG) occurs when the experiences of acute grief extend well past 6-months post-loss. Thoughts and feelings about the loss (i.e. grief processing) occurring during acute grief may play a role in healthy grieving and protect against CG development. Identification of the cognitive and emotional mechanisms of grief processing that contribute to healthy grief resolution would advance knowledge of the goals of grieving and assist the development of interventions for complicated grief. Two core components of grief processing are top-down regulation and balanced loss confrontation. Top-down pursue related emotional representations and recruit proportion regulation is the ability to suppress processing of intrusive emotional information to a stated goal. Top-down regulation may facilitate healthy grieving by allowing reprieve from intense loss thinking. Balanced loss confrontation refers to the processing of the loss in a way that protects against overload. Confrontation with the l oss may assist in the process of reforming one's mental of the deceased. This tudy will test extrinsic and intrinsic measures of top-down regulation balanced loss confrontation during acute grieving as predictors of CG development a year later We will a sample at high-risk for CG, the suicide-bereaved, in order to maximize the likeliness that a significant of the sample develops CG. The s . findings produced by this study may advance the knowledge of how CG develops, assist in the identification of people at high-risk for developing CG and potentially form the basis for targeted interventions.  The following K23 presents a research and training program that will support the applicant on the path of becoming an independent investigator of the role of grief processing in the development of complicated grief. The research mentorship, coursework, hands-on experience, seminars and classes ingrained in this training and plan will propel the applicant to independence in the domains of1) Clinical Research, 2) Psychometric Assessment of Grief Processing, 3) Machine Learning analysis of fMRI, 4) Biostatistics, 5) Scientific Independence. team independent and The combination of the environment, t raining plan, research strategy and mentorship will not only provide the candidate with a spectrum of new methods and skills that will establish him as an research scientist, but will also produce a body of knowledge that will clarify the specific cognitive emotional grief processes that contribute to the development of CG. PROJECT NARRATIVE Complicated grief describes an inability to adjust to the loss of a loved one over the course of the first year following the death. This study will identify cognitive, emotional and neural processes occurring in the early grieving period (3 to 5-months post-loss) that predict or protect against the development of complicated grief a year later in suicide bereaved subjects, a sample at high-risk for developing complicated grief. These findings may advance understanding of the process of grief, facilitate early identification of high-risk grievers and potentially form the basis for targeted treatment of complicated grief.",Predicting complicated grief from grief processing,9527376,K23MH114021,"['Acute', 'Age', 'Attention', 'Biometry', 'Cessation of life', 'Clinical', 'Clinical Research', 'Cognitive', 'Data', 'Depressed mood', 'Development', 'Down-Regulation', 'Early identification', 'Emotional', 'Emotions', 'Environment', 'Failure', 'Family member', 'Feeling', 'Functional Magnetic Resonance Imaging', 'Gender', 'Goals', 'Grief reaction', 'Guilt', 'High Prevalence', 'Individual', 'Instruction', 'Intervention', 'Interview', 'Knowledge', 'Machine Learning', 'Measures', 'Mental Depression', 'Mentorship', 'Methods', 'Modeling', 'Pain', 'Pathogenesis', 'Pattern', 'Play', 'Process', 'Psyche structure', 'Psychometrics', 'Questionnaires', 'Rain', 'Reaction Time', 'Recording of previous events', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Role', 'Sampling', 'Scientist', 'Severities', 'Shame', 'Stimulus', 'Suicide', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Training Programs', 'Trauma', 'Unconscious State', 'Validation', 'attentional bias', 'base', 'experience', 'high risk', 'indexing', 'intense pain', 'loved ones', 'neural patterning', 'recruit', 'relating to nervous system', 'response', 'sex', 'skills', 'sustained attention', 'targeted treatment', 'therapy development']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,K23,2018,199797,-0.03710232796114265
"Device for real-time streaming of preclinical research data into a central cloud-based platform Project Summary BehaviorCloud is a unified cloud platform where biomedical researchers can collect, analyze, and share preclinical research data – specifically behavioral and phenotype data from animal models. Traditionally researchers collect data from many disparate instruments and store data on PCs running single license software. Raw data is stored across several locations, analysis is restricted to the PC used to collect the data, and opportunities for collaboration, remote-participation, and data sharing are limited. BehaviorCloud is leveraging cloud data streaming and storage to overcome these barriers to discovery. In 2017 BehaviorCloud released a first version of the underlying cloud platform as well as BehaviorCloud Camera, an open-source “reference implementation” that demonstrates automated video tracking of animal behavior on the BehaviorCloud platform using a consumer-grade smartphone. This tool and the underlying platform are both in active use across academic and pharmaceutical labs. The aim of this Phase I SBIR application is to develop patent-pending “Bridge” technology that allows data streaming from third-party instrumentation into the central web platform. Researchers will bypass the original software and PCs associated with their instruments to control trials through their BehaviorCloud account and receive data back in real-time. BehaviorCloud will provide a public repository to aggregate all of these data and accelerate discovery by providing computational tools for large-scale meta-analysis and machine learning based predictive analytics. Project Narrative BehaviorCloud is a unified cloud platform where biomedical researchers can collect, analyze, and share preclinical research data – specifically behavioral and phenotype data from animal models. The goal of this Phase I SBIR application is to develop the technology to enable streaming of data from all kinds of behavioral and phenotyping instrumentation into the BehaviorCloud platform. BehaviorCloud will aggregate these data into a repository and accelerate discovery by providing tools for collaboration and meta-analysis.",Device for real-time streaming of preclinical research data into a central cloud-based platform,9621228,R43OD025448,"['Adoption', 'Animal Behavior', 'Animal Experimentation', 'Animal Model', 'Area', 'Back', 'Behavioral', 'Bypass', 'Carbon Dioxide', 'Cellular Phone', 'Collaborations', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Development', 'Devices', 'Goals', 'Heart Rate', 'Information Systems', 'Internet', 'Intervention', 'Legal patent', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Meta-Analysis', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physiological', 'Positioning Attribute', 'Predictive Analytics', 'Process', 'Research', 'Research Contracts', 'Research Personnel', 'Resources', 'Running', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Standardization', 'Stimulus', 'Stream', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'cloud based', 'cloud platform', 'computerized tools', 'control trial', 'data management', 'data sharing', 'data warehouse', 'design', 'experimental study', 'instrument', 'instrumentation', 'laptop', 'open source', 'phenotypic data', 'pre-clinical', 'pre-clinical research', 'prototype', 'repository', 'tool', 'wasting', 'web interface']",OD,"BEHAVIORCLOUD, LLC",R43,2018,220420,-0.012380987668528796
"Toward Automated Spike Sorting via Ground Truth Neural Recordings PROJECT​ ​SUMMARY Scaling extracellular electrophysiology to higher channel counts is hindered by the burden of data handling,storage, and especially preprocessing, e.g. spike sorting ​[1]​. The burden of spike sorting can in principle be reduced through a combination of high-density multielectrode array (probe) technology and algorithm optimization to yield a spike sorting method that is both highly accurate and fully automated [2–4]​. With a known-good spike sorting method in hand, the algorithm can be baked into the data stream as early as possible to allow for automatic data sorting and a massive reduction in data rate to downstream storage and processing. However, it takes an investment of considerable resources to implement this sort of large-scale real-time processing, and great confidence to throw away raw data and keep​ ​only​ ​processed​ ​data. Accuracy and automation of spike sorting increases with the spatial density of recording sites ​[5–7]​. Neural activity recorded from high-density probes can serve as a data corpus for testing the accuracy of spike sorting algorithms. However, to quantify spike sorting performance for comparison between algorithms, the ground truth spiking activity of neurons captured in the data corpus must be measured, such as by simultaneously recording via patch-clamp pipette or some other recording modality ​[8–10]​. Unfortunately, because ground truth recordings are so challenging to perform, they remain too rare to allow for this sort of analysis in a large-scale, meaningful way ​[11]​. Until this need is met, spike sorting development lacks a compass, and cutting-edge techniques such as supervised machine learning which require large amounts of labelled data remain out-of-reach ​[12]​. ​Accordingly, we propose a series of multimodal neural recordings combining multielectrode array and patch pipette techniques to generate​ ​a​ ​corpus​ ​of​ ​ground​ ​truth​ ​data​ ​for​ ​validation​ ​of​ ​spike​ ​sorting​ ​algorithms. PROJECT​ ​NARRATIVE Electrophysiological​ ​recording​ ​systems​ ​allow​ ​direct​ ​observation​ ​of​ ​neural​ ​activity​ ​in​ ​animal subjects.​ ​This​ ​facilitates​ ​the​ ​study​ ​of​ ​crucial​ ​neuroscientific​ ​topics​ ​such​ ​as​ ​development, learning​ ​and​ ​memory,​ ​and​ ​cognition,​ ​as​ ​well​ ​as​ ​brain​ ​diseases​ ​such​ ​as​ ​Alzheimer’s,​ ​epilepsy, Parkinson’s,​ ​and​ ​depression.​ ​LeafLabs’​ ​tools​ ​for​ ​characterizing​ ​and​ ​analyzing​ ​high-channel count​ ​electrophysiology​ ​recordings​ ​will​ ​allow​ ​researchers​ ​to​ ​more​ ​easily​ ​collect​ ​and​ ​interpret neural​ ​data​ ​at​ ​a​ ​large​ ​scale.",Toward Automated Spike Sorting via Ground Truth Neural Recordings,9558957,R41MH116752,"['Algorithm Design', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Automation', 'Brain', 'Brain Diseases', 'Cells', 'Cellular Morphology', 'Chronic', 'Cognition', 'Data', 'Development', 'Dyes', 'Electrophysiology (science)', 'Epilepsy', 'Failure', 'Future', 'Geometry', 'Hand', 'Head', 'Individual', 'Investments', 'Label', 'Learning', 'Location', 'Machine Learning', 'Measures', 'Memory', 'Mental Depression', 'Methods', 'Microelectrodes', 'Microscope', 'Modality', 'Morphology', 'Mus', 'Neurons', 'Outcome', 'Output', 'Parkinson Disease', 'Performance', 'Population', 'Process', 'Property', 'Quantitative Evaluations', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Series', 'Silicon', 'Site', 'Sorting - Cell Movement', 'Stream', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Validation', 'Visual Cortex', 'Width', 'Work', 'awake', 'base', 'cell assembly', 'data sharing', 'density', 'design', 'extracellular', 'image guided', 'information processing', 'multi-electrode arrays', 'multimodality', 'patch clamp', 'relating to nervous system', 'tool', 'two-photon']",NIMH,"LEAFLABS, LLC",R41,2018,438789,-0.021439205235209417
"Robust Control of the Stem Cell Niche Diana Arguijo has a unique background with a double major in biomedical engineering (BME) and electrical and computer engineering (ECE). Leveraging her strong mathematical background, she will develop computational techniques to identify patterns of epigenetic reprogramming during epithelial development and patterns of real- time electrical recoding of the GI tract reflective of sacral nerve modulation. Her work will provide insights into the robustness and plasticity of underlying biological control schemes. Diana Arguijo will develop machine-learning based computational techniques to analyze epigenetic reprogramming of epithelial development and electrical activities of the enteric nervous system. Her analyses will provide insights into the robustness and plasticity of tissue regulation.",Robust Control of the Stem Cell Niche,9731853,R35GM122465,"['Biological', 'Biomedical Engineering', 'Computational Technique', 'Computers', 'Development', 'Engineering', 'Enteric Nervous System', 'Epigenetic Process', 'Epithelial', 'Gastrointestinal tract structure', 'Machine Learning', 'Mathematics', 'Pattern', 'Regulation', 'Sacral nerve', 'Scheme', 'Time', 'Tissues', 'Work', 'base', 'insight', 'stem cell niche']",NIGMS,DUKE UNIVERSITY,R35,2018,42822,-0.04035706729494351
"Assay Classifier Engine (ACE) for enhancing splice sensor assay performance SUMMARY:  The goal of this proposal is to improve the sensitivity and specificity of the Spinach-based splice sensor platform by developing a novel multiprobe (MP) assay design and a companion machine learning-based classification algorithm called assay classifier engine (ACE). Improvement in sensitivity and specificity of the splice sensor platform enables its application to detect endogenous RNA isoforms with low copy number and distinguish alternative RNA isoforms that share high degree of sequence similarities.  The aim of any assay development effort is to achieve excellent assay specificity and sensitivity. However, this is often a futile endeavor since specificity and sensitivity are two inversely correlated factors. The underlying reason for poor sensitivity or specificity is due to the off-target signals generated by competing molecules present in the sample. In the field of diagnostics, one of the ways these issues are addressed is to perform multiple single probe testing instead of one single probe testing. While individual singe probe assays might have poor specificity and sensitivity, when combined, these assays synergistically improve the sensitivity and specificity of the ultimate diagnostic determination. In the field of research and drug discovery, researchers have employed a multitude of strategies (e.g. signal amplification, reaction cascades, or sample enrichment) to improve sensitivity and MP design or strand displacement strategies to improve specificity. Some of the PCR- based methods have combined both enzyme-based signal amplification and MP strategies to improve assay determination. However, when it comes to detecting targets that are highly similar to their competitors, such as detecting single nucleotide polymorphism, DNA methylation, RNA modification and alternative splicing, there is still an unmet need for more sensitive and specific analytical methods.  In the past few years, Lucerna has developed Spinach-based sensors to detect intractable metabolites and biomolecules. One such sensor is the splice sensor, which is a Spinach-based sensor that can generate fluorescence signal based on the alternative RNA isoform of interest. One of the challenges encountered during splice sensor assay development is the lack of sensitivity toward low copy number RNA isoforms and low specificity when distinguishing two splice isoforms that share a high sequence similarity. To overcome this challenge in this proposal, we will develop a MP assay panel comprised of splice sensor variants that recognize the target RNA and the competitor with varying binding affinities and differing signal responses. We will use data sets generated from the MP assay to train a ML-based ACE algorithm to make target determination in test samples. Further, we will develop a quantitative MP data set and re-train the ACE algorithm to classify the assay signals into various categories based on target concentrations in the test sample. This new ACE algorithm will then be tested against conventional single probe assays to determine specificity and sensitivity improvement of the MP assay platform. PROJECT NARRATIVE: Improved specificity and sensitivity are highly sought-after features in assays where there are high similarity between the target and its competitors or when the target exists naturally in very low abundance. To address this unmet need, we will develop a fluorescence sensor-based multiprobe assay approach and a companion machine learning-based assay classifier engine (ACE). The ACE algorithm will integrate the multiprobe assay data and classify them based on trained machine learning models to make sample determination with enhanced specificity, sensitivity, and dynamic range than possible with conventional single probe assays.",Assay Classifier Engine (ACE) for enhancing splice sensor assay performance,9622514,R43GM130258,"['Address', 'Adopted', 'Affinity', 'Algorithms', 'Alternative Splicing', 'Area Under Curve', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Assay', 'Categories', 'Cells', 'Characteristics', 'Classification', 'Companions', 'Custom', 'DNA Methylation', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Enzyme-Linked Immunosorbent Assay', 'Enzymes', 'Evaluation', 'Exhibits', 'Fluorescence', 'Goals', 'Individual', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Nerve Degeneration', 'Nucleotides', 'Output', 'Pattern', 'Performance', 'Process', 'Protein Isoforms', 'RNA', 'RNA Splicing', 'Reaction', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Series', 'Side', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Specificity', 'Spinach - dietary', 'Technology', 'Testing', 'Time', 'Titrations', 'Training', 'Variant', 'analytical method', 'aptamer', 'assay development', 'base', 'cost', 'design', 'drug discovery', 'experience', 'improved', 'interest', 'novel', 'outcome forecast', 'predictive modeling', 'response', 'sensor', 'targeted biomarker']",NIGMS,"LUCERNA, INC.",R43,2018,224925,-0.012896112464130008
"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis. PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.",Developing Classification Criteria for the Uveitides,9472335,R01EY026593,"['Acute', 'Adult', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Anterior uveitis', 'Antiviral Agents', 'Blindness', 'Child', 'Choroiditis', 'Chronic', 'Classification', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'Cytomegalovirus Retinitis', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Enrollment', 'Ensure', 'Epidemiology', 'Future', 'Genomics', 'Goals', 'Immune', 'Immunosuppression', 'Infection', 'Inflammation', 'Informatics', 'Intermediate Uveitis', 'Machine Learning', 'Mediating', 'Nomenclature', 'Outcomes Research', 'Panuveitis', 'Pathogenesis', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Pigments', 'Posterior Uveitis', 'Publications', 'Research', 'Retinitis', 'Risk Factors', 'Sensitivity and Specificity', 'Specificity', 'Standardization', 'Syndrome', 'Techniques', 'Terminology', 'United States', 'Uveitis', 'Vision', 'Visual impairment', 'Voting', 'age group', 'age related', 'aging population', 'antimicrobial', 'birdshot chorioretinitis', 'cost', 'outcome forecast', 'public health relevance', 'symposium', 'tool', 'web page', 'working group']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2018,418408,-0.013954191307579378
"An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography SUMMARY – OVERALL Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function. Although the basic electron cryo-tomography technique has been used for several decades, the technology is being revolutionized by recent advances in sample preparation, electron cryo-microscopy hardware, improved capabilities for automatic data collection, direct electron detection imaging devices, and phase plate technologies. Combined, these advances led to the ability to generate extraordinarily large numbers of cellular cryo-tomograms of exquisite quality. In principle, such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. However, collection of cellular data is now at a far faster rate than can currently be analyzed with existing methods, producing a serious barrier to progress: to match the data production rates of a single laboratory, at least 50 experienced scientists would need to handle the data analysis. The primary goal of this Program Project is to establish quantitative and highly automated tools for the reconstruction and interpretation of highly complex cellular tomographic data. We have assembled a highly synergistic team of PIs with complimentary expertise in cutting-edge computational and experimental electron microscopy techniques to achieve this goal through collaborative efforts. Project 1 (Hanein & Penczek) focuses on development and implementation of tomogram quality assessment and validation techniques and on experimentally guided optimization of data collection strategies. Project 2 focuses on automatic tomographic reconstruction technology, extraction of various features from the tomograms, and the analysis of distribution patterns derived from the extracted features. Project 3 focuses on development of quantitative tools for tomogram annotation through deep learning and sub-tomogram alignment as well as interactive visualization tools. The set of highly automated tools developed in this Program Project will permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study. NARRATIVE Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function and—with recent instrumental advances—it is now possible to image hundreds of cells per months, enabling collection of cellular data at a far faster rate than can currently be analyzed. Such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. This Program Project brings together an accomplished team of investigators to develop new strategies for effectively processing and interpreting this massive influx of data, developing a set of highly automated tools to permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study.",An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography,9416022,P01GM121203,"['Address', 'Algorithms', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biological Neural Networks', 'Biology', 'Cancer Diagnostics', 'Cell physiology', 'Cells', 'Classification', 'Collection', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Electrons', 'Environment', 'Floods', 'Goals', 'Health', 'Heart', 'Human', 'Image', 'Imaging Device', 'Individual', 'Knowledge', 'Laboratories', 'Methodology', 'Methods', 'Molecular', 'Molecular Structure', 'Morphology', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Preparation', 'Process', 'Production', 'Real-Time Systems', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Stimulus', 'System', 'Techniques', 'Technology', 'Tomogram', 'Validation', 'Variant', 'Visualization software', 'base', 'computer framework', 'deep learning', 'electron tomography', 'experience', 'imaging detection', 'improved', 'insight', 'knowledge base', 'learning strategy', 'nanomachine', 'novel diagnostics', 'particle', 'programs', 'reconstruction', 'response', 'software development', 'statistics', 'tomography', 'tool', 'virtual']",NIGMS,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,P01,2018,981617,-0.028101844664047523
"The next generation of RNA-Seq simulators for benchmarking analyses Abstract: RNA-Sequencing (RNA-Seq) has established itself as the primary method for studying transcription in basic research, with an emerging role in the clinic – currently upwards of 5,000 publications using the technology are indexed in PubMed. However, the interpretation of RNA-Seq requires several complex operations including alignment, quantification, normalization and statistical analyses of various types. Since its inception a large number of algorithms have appeared for each step, creating a very confusing landscape for investigators. In order to determine the best analysis practices, numerous benchmarking studies have emerged which leverage real RNA-Seq data made from well-studied RNA samples, such as the Genetic European Variation in Health and Disease (GEUVADIS) consortium data. These valuable RNA-Seq datasets contain the biases and errors introduced by sequencing biochemistry—factors that any analysis method must account for and overcome. However, the utility of such datasets for benchmarking analysis methods is limited by the fact that we do not know the underlying truth (e.g. the true number of RNA molecules from each transcript in the original sample). Therefore researchers tend to rely heavily on simulated data, since we know everything about the true composition of these samples. There are dozens of DNA simulators aimed at benchmarking applications such as variant calling. And while the need for simulators is just as strong in RNA analysis, there are only a scant few RNA-Seq simulators available. Furthermore, the available RNA- Seq simulators are based on simplifying assumptions that greatly restrict their utility for benchmarking anything but the most upstream steps in the analysis pipeline (e.g. alignment). The further downstream the analysis method is, the more accurately the true nature of real data and its technical biases need to be modeled in order to draw meaningful conclusions. For example, no simulator generates data from a diploid genome, which would be necessary to evaluate allele specific quantification. Given our extensive experience with RNA-Seq analysis and transcriptomics in general, and our success at building the BEERS simulator, and our track record of authorship on all comprehensive RNA-Seq aligner benchmarking studies published to date, we are ideally situated to develop the next generation of open-source RNA-Seq simulator which aims to model all sources of technical variability. Furthermore, the simulator will model biological variability with an empirical approach based on using real data to configure the simulator’s parameters, which is a natural problem for machine learning. There are eleven steps in RNA-Seq library preparation which introduce bias, all of which will be modeled by the software in an object-oriented modular framework. Project Narrative: There have been many algorithms developed for every step of the RNA-Seq analysis pipeline with no easy way to compare between them. Simulated data are useful for this purpose, but to date there are very few RNA-Seq simulators available and all make too many simplifying assumptions to be used for anything but the most upstream steps in the pipeline, e.g. alignment. We propose to develop the next generation of open-source RNA-Seq simulator, which will capture all of the biochemical processes in a modular fashion and model all of the sources of technical variation.",The next generation of RNA-Seq simulators for benchmarking analyses,9600808,R21LM012763,"['Affect', 'Algorithms', 'Alleles', 'Alternative Splicing', 'Authorship', 'Basic Science', 'Benchmarking', 'Biochemical', 'Biochemical Process', 'Biochemical Reaction', 'Biological', 'Biological Models', 'Clinic', 'Clinical', 'Communities', 'Complement', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'DNA-Directed DNA Polymerase', 'Data', 'Data Set', 'Development', 'Diploidy', 'Disease', 'Enzymes', 'European', 'Genetic', 'Genetic Transcription', 'Genome', 'Goals', 'Guanine + Cytosine Composition', 'Health', 'In Vitro', 'Libraries', 'Machine Learning', 'Methods', 'Modeling', 'Morphologic artifacts', 'Nature', 'Output', 'Preparation', 'Process', 'Protein Isoforms', 'Protocols documentation', 'PubMed', 'Public Domains', 'Publications', 'Publishing', 'RNA', 'RNA Splicing', 'RNA analysis', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Sequencing Biochemistry', 'Signal Transduction', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Transcript', 'Variant', 'Work', 'analog', 'base', 'biochemical model', 'design', 'digital', 'experience', 'experimental study', 'flexibility', 'indexing', 'next generation', 'open source', 'operation', 'power analysis', 'success', 'tool', 'transcriptome sequencing', 'transcriptomics']",NLM,UNIVERSITY OF PENNSYLVANIA,R21,2018,217350,-0.024434457774742617
"Retinal eye-tracking for the prognosis and monitoring of multiple sclerosis Abstract The goal of this project is to validate an innovative, highly sensitive retinal eye-tracking technology, the tracking scanning laser ophthalmoscope (TSLO), as a prognostic and monitoring tool for neurodegenerative disorders, namely multiple sclerosis (MS). The applications of effective treatments for multiple sclerosis are constrained by (1) the absence of methods for early detection and (2) quantitative, highly sensitive methods monitoring deficits early in disease course when treatment may have a better chance of success. As already demonstrated, the TSLO is capable of rapidly assessing and measuring the extraordinarily fine, microscopic motion of the human eye during fixation in MS patients. Fixational eye movements are neurally-encoded, involuntary movements that require the coordination of many areas of the central nervous system. Given the TSLO’s theoretical sensitivity to change (0.2 arcminutes) and its precision of measurement - fixational eye movements have the potential utility for tracking neurodegenerative disease progression at an unprecedented scale. With the advent of the new FDA-approved MS treatment targeting B-cells (ocrelizumab), clinical tools are now desperately needed to not only assess treatment efficacy, but to objectively assess patient disability at the earliest stage of disease in order to cut relapse rates and prevent irrevocable disability. In this project, we will determine the optimal fixational eye motion metrics to distinguish patients from controls, establish the relationship between clinical disease severity measures and fixational eye movement deficits as defined by the TSLO system, and to use machine learning algorithms to further strengthen our fixational metrics. Narrative The goal of our project is to clinically validate a retinal imaging and eye-tracking technology, the tracking scanning laser ophthalmoscope (TSLO), as a prognostic and monitoring tool for neurodegenerative disorders, particularly Multiple Sclerosis (MS). The TSLO system is capable of rapidly assessing and measuring the extraordinarily fine, microscopic motion of the human eye during fixation with an accuracy of 0.2 arcminutes. Given the numerous brain regions involved with eye motion and the TSLO’s precision of measurement - fixational eye movements now have the potential utility for tracking neurodegenerative disease progression for the MS patient population.",Retinal eye-tracking for the prognosis and monitoring of multiple sclerosis,9465579,R41NS100222,"['Age', 'Algorithms', 'Area', 'B-Lymphocytes', 'Brain', 'Brain region', 'Characteristics', 'Clinical', 'Cognition', 'Color Visions', 'Databases', 'Digit structure', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Early Intervention', 'Electrocardiogram', 'Eye', 'Eye Movements', 'FDA approved', 'Fatigue', 'Fingers', 'Frequencies', 'Goals', 'Hand', 'Human', 'Individual', 'Involuntary Movements', 'Lasers', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Microscopic', 'Modality', 'Monitor', 'Motion', 'Movement', 'Multiple Sclerosis', 'Muscle', 'Nerve Degeneration', 'Neuraxis', 'Neurodegenerative Disorders', 'Neurons', 'Ophthalmoscopes', 'Patient Care Team', 'Patients', 'Physicians', 'Pilot Projects', 'Population', 'Population Control', 'Relapse', 'Retinal', 'Running', 'Scanning', 'Series', 'Severity of illness', 'Signal Transduction', 'Small Business Technology Transfer Research', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Treatment Efficacy', 'Vision', 'Visual Fields', 'Visual system structure', 'Walking', 'base', 'cohort', 'cost', 'disability', 'effective therapy', 'foot', 'innovation', 'instrument', 'multiple sclerosis patient', 'multiple sclerosis treatment', 'neuroadaptation', 'oculomotor', 'outcome forecast', 'patient population', 'prevent', 'prognostic', 'programs', 'receptive field', 'relating to nervous system', 'retinal imaging', 'sample fixation', 'standard measure', 'success', 'tool', 'walking speed']",NINDS,"C. LIGHT TECHNOLOGIES, INC.",R41,2018,225392,-0.018334884250494614
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9570304,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Simulation', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Supervision', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in vivo', 'insight', 'intracranial artery', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'single photon emission computed tomography', 'spatiotemporal', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2018,528639,-0.016190259495739958
"An integrated neural network analysis and video microscopy platform for fully automated particle tracking Project Summary/Abstract  Particle tracking (PT) is a biophysical tool for elucidating molecular interactions, transport phenomena of diverse species, and rheological properties of complex materials. PT experiments involve first obtaining high resolution videos that capture time-resolved increments of particles, followed by extraction of traces of entities of interest from videos in the form of spatial locations over time, a process we refer to as path conversion. Finally, quantitative analysis of the traces will yield diffusivities, viscoelasticity, etc.  Lung diseases, such as cystic fibrosis and COPD, are characterized by a highly viscoelastic mucus layer that is incapable of being cleared by mucociliary clearance. Not surprisingly, the viscoelasticity of mucus often directly reflects disease progression. A variety of mucolytics are being investigated, but due to the variable composition and properties of mucus between patients, effective mucolytics treatment will likely be different between individuals; too little/inappropriate mucolytics will not be effective in restoring mucus clearance, whereas too much may result in bronchorrhea. Although microbeads-based rheology has been performed on a variety of mucus specimens in basic research, the capacity for high throughput characterization of rheological properties of biological specimens in a clinical setting is currently not available. This limitation can be attributed to inefficiencies of path conversion: current PT software requires extensive human supervision/intervention to achieve accurate path conversion, not only resulting in poor reproducibility and throughput but also restricting its use to only expert labs. Our vision is to make PT as objective and easy to use as a simple plate reader that can be readily utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening), and research professionals. Towards this goal, we have created a neural network tracker (NNT) that automatically determines the location of all particles in each frame with zero user-input (i.e. no parameter for users to change), and retains the identity of all particles from frame to frame. The innovation is that NNT can robustly, reproducibly, and accurately track a wide range of 2D/3D videos with virtually no need for human intervention, achieving unparalleled time savings. We have already successfully deployed NNT over the Google cloud, which offers exceptional scalability. Nevertheless, for time-sensitive applications, such as an automated PT rheometer, the transfer of large video data files is likely prohibitive. Therefore, in this Phase I STTR, we seek to enable real-time NNT-based PT analysis on the local machine while video microscopy data is being acquired by the microscope, and allow data from PT analysis to drive the operation of the microscope. In Aim 1, we will integrate our NNT with a single objective fluorescence microscope system called Monoptes. Aim 2 will evaluate the performance of our NNT- Monoptes system. If successful, our technology would form the basis of a fully automated PT system capable of measuring rheological properties of fluids/materials or distribution of particle sizes in a 96-well plate format. Project Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately, its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a software that can consistently provide superior and truly automated tracking performance compared to current alternatives. In this proposal, we will integrate this latest advance with sophisticated instrumentation to develop a microscope system capable of fully automated particle tracking microscopy in a 96-well plate format. If successful, the instrument will likely be utilized by clinicians (diagnostics, disease progression, therapy effectiveness), pharma (preclinical/clinical drug screening of patients), and research professionals.",An integrated neural network analysis and video microscopy platform for fully automated particle tracking,9620574,R41GM130202,"['Acceleration', 'Adopted', 'Antibodies', 'Artificial Intelligence', 'Basic Science', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Chronic Obstructive Airway Disease', 'Clinical', 'Clinical Trials', 'Code', 'Complex', 'Computer software', 'Cystic Fibrosis', 'Data', 'Data Files', 'Decision Making', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease Progression', 'Drug Carriers', 'Drug Screening', 'Effectiveness', 'Elasticity', 'Engineering', 'Gaussian model', 'Goals', 'HIV Infections', 'Heterogeneity', 'Human', 'Image', 'Individual', 'Intervention', 'Liquid substance', 'Location', 'Lung diseases', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Microspheres', 'Motion', 'Mucociliary Clearance', 'Mucolytics', 'Mucous body substance', 'Output', 'Particle Size', 'Particulate', 'Pathway Analysis', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Positioning Attribute', 'Process', 'Property', 'Radial', 'Reader', 'Reproducibility', 'Research', 'Resolution', 'Respiratory physiology', 'Rheology', 'Risk', 'Running', 'Sampling', 'Savings', 'Series', 'Small Business Technology Transfer Research', 'Software Tools', 'Specimen', 'Spottings', 'Supervision', 'System', 'Technology', 'TensorFlow', 'Time', 'Video Microscopy', 'Viscosity', 'Vision', 'Woman', 'base', 'biophysical tools', 'cloud based', 'drug development', 'experimental study', 'fluorescence microscope', 'innovation', 'instrument', 'instrumentation', 'interest', 'movie', 'novel', 'operation', 'particle', 'patient screening', 'physical science', 'pre-clinical', 'submicron', 'virtual', 'viscoelasticity']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2018,224894,-0.006587384821981979
"Enabling Technology for Safe Robot-assisted Surgical Micromanipulation Project Summary  The goal of this grant is to develop enabling technology and systems that address fundamental limitations in microsurgery with a specific focus on vitreoretinal surgery. Due to the inherent micro-scale and the fragility of the neurosensory retina, vitreoretinal surgeons can be challenged by physiological hand tremor where the tremor amplitude is larger than retinal structures, delicate movements that are below tactile sensation, and multiple cognitive decisions that are required when executing high-risk movements, such as during retinal vein cannulation (RVC). Nevertheless currently vitreoretinal surgery is at the limits of human physiological performance and lacks the adequate technology that could further improve the technical performance. This situation is less than optimal and can significantly benefit from the recent advances in medical robotics, sensor feedback and human machine interface design. Robotic assistance may be ideally suited to address common problems encountered in the performance of the demanding micromanipulations in retinal microsurgery.  We propose a robotic system with enhanced real-time multisensory feedback that assesses multiple points of instrument contact located both inside and outside of the eye. Our comprehensive system will enable the surgeon to manipulate tools based on quantitative feedback that will prevent mechanical injury by implementing safeguards against the application of excessive and previously unmeasurable forces at the eyewall and the tool tip. Our aims are: (1) Develop and demonstrate in vivo position/force hybrid control algorithms for enabling real- time high-fidelity sensorimotor capabilities at the sclerotomy for safe robot-assisted vitreoretinal microsurgery: real-time sensorimotor capabilities at the sclerotomy will be uniquely used to control the robot through a machine learning method that adaptively learns a nonlinear mapping from user behavior to sclera-force/position and predicts unsafe motions; (2) Develop and demonstrate in vivo force-input control algorithms for enabling real- time high-fidelity sensorimotor capabilities at the tool-tip for safe robot-assisted vein cannulation: real-time tool- tip-to-tissue interaction force sensing and non-linear robot control algorithms based on observing the user behavior will be used to control the tool-tip position and force and to prevent entry into subretinal areas during RVC; (3) Demonstrate safe robot-assisted RVC in rabbit model in vivo: real-time, position/force hybrid control algorithms based on dual-point (tool-shaft and tip) information fusion will provide sensorimotor guidance of surgical maneuvers during RVC. Statistically significant results in vivo, in clinically realistic conditions will demonstrate the feasibility of our approach.  This highly innovative system will enable surgeons to perform maneuvers in a tremor free environment with a higher level of precision than previously possible and with the ability to sense forces on a scale that have been previously imperceptible. We envision this development as a logical next step in the integration of man, machine and computer for the performance of unprecedented microsurgical maneuvers. Project Narrative  This R01 grant addresses fundamental limitations in current microsurgical practice, focusing on vitreoretinal surgery (VRS), which is the most technically demanding ophthalmologic surgery. Our goal is to develop a cooperatively controlled robotic system with enhanced sensorimotor capabilities that in conjunction with multifunction force-sensing microsurgical instruments could enable safe robot-assisted retinal surgery. Although focused on VRS, our results will be applicable to a broader range of microsurgical training and practice.",Enabling Technology for Safe Robot-assisted Surgical Micromanipulation,9449437,R01EB023943,"['Address', 'Algorithms', 'Area', 'Behavior', 'Cannulations', 'Clinic', 'Clinical', 'Cognitive', 'Computers', 'Development', 'Disadvantaged', 'Discipline', 'Environment', 'Eye', 'Eye Movements', 'Feedback', 'Future', 'Goals', 'Grant', 'Hand', 'Healthcare', 'Hemorrhage', 'Histology', 'Human', 'Hybrids', 'Iatrogenesis', 'Injury', 'Intervention', 'Learning', 'Machine Learning', 'Manuals', 'Mechanics', 'Medical', 'Micromanipulation', 'Microsurgery', 'Miniaturization', 'Monitor', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Ophthalmologic Surgical Procedures', 'Ophthalmology', 'Optics', 'Oryctolagus cuniculus', 'Otorhinolaryngologic Surgical Procedures', 'Patients', 'Perception', 'Performance', 'Phase', 'Physiological', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Property', 'Reporting', 'Research', 'Research Proposals', 'Retina', 'Retinal', 'Retinal Hemorrhage', 'Retinal Perforations', 'Retinal Vein Occlusion', 'Robot', 'Robotics', 'Safety', 'Sclera', 'Site', 'Sterilization', 'Structure', 'Structure of central vein of the retina', 'Surgeon', 'Surveys', 'System', 'Tactile', 'Techniques', 'Technology', 'Time', 'Tissues', 'Touch sensation', 'Training', 'Tremor', 'User-Computer Interface', 'Veins', 'Vision', 'Work', 'adaptive learning', 'base', 'design', 'dexterity', 'high risk', 'improved', 'in vivo', 'in vivo Model', 'innovation', 'instrument', 'interest', 'learning strategy', 'man', 'medical specialties', 'multisensory', 'neurosensory', 'neurosurgery', 'operation', 'prevent', 'research clinical testing', 'robot assistance', 'robot control', 'sensor', 'technological innovation', 'tool', 'trend', 'virtual']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2018,356307,-0.011089036486789144
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9465330,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,503162,-0.02209749712960596
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9698505,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,50000,-0.02209749712960596
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research PROJECT SUMMARY This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0™ that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud™ Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb’s DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently. PROJECT NARRATIVE PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9741597,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Communications Media', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Internet of Things', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Modernization', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'Transact', 'United States National Institutes of Health', 'analytical tool', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'experimental study', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'service learning', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2018,99999,-0.0391317190824975
"Characterizing Alzheimer's Disease with INSPECDS: Integrated Neurocognitive and Sleep-Behavior Profiler for the Endophenotypic Classification of Dementia Subtypes PROJECT SUMMARY AND ABSTRACT  It is estimated that Alzheimer's and other neurodegenerative diseases causing dementia will surpass cancer as the leading cause of death by the year 2040. Alzheimer's is the leading cause of dementia, followed by synucleinopathies, including dementia with Lewy bodies (DLB) and Parkinson's disease with dementia (PDD), Fronto-temporal dementia and Vascular dementia. Among clinical researchers focused on investigating the varying etiologies, genetic associations, biomarkers, and treatment options for Alzheimer's disease, there is an urgent need for effective tools to aid in the classification of dementia subtypes, in the earliest detectable stages of the pathophysiological process. To address this unmet need Advanced Brain Monitoring (ABM) proposes to leverage day and night assessment technologies to create an Integrated Neurocognitive and Sleep-Behavior Profiler for the Endophenotypic Classification of Dementia Subtypes (INSPECDS) to profile Alzheimer's and other dementias. The core components of the INSPECDS platform will be the Alertness and Memory Profiler (AMP), the Sleep Profiler, and integrated machine-learning, classification algorithms, hosted on a secure, cloud-based, infrastructure for automated data processing, analysis, and reporting. The AMP was developed and validated intially for the purpose of detecting the neurocognitive effects of sleep deprivation in adults diagnosed with obstructive sleep apnea but has more recently been applied to assess Alzheimer's and Parkinson's disease. The AMP is unique among neurocognitive testing platforms in that it is the only one which integrates advanced, electrophysiological measures (e.g., 24-channel, wireless EEG and ECG) during the performance of computerized neurocognitive tasks and has proven effective in characterizing cognitive decline in Alzheimer's. This advanced capability permits researchers to explore real- time relations between fluctuations in alertness, discrete cognitive functions, and specific neural processes believed to subserve observed performance deficits in Alzheimer's and other dementias. The Sleep Profiler is an FDA-cleared, easily applied, wireless-EEG device that was developed and validated to measure sleep architecture for in-home sleep studies with submental (chin) EMG and wireless accelerometers to monitor head and limb movements to quantify the characteristics of REM-sleep behavior disorder (RBD), considered to be a prodromal expression of synucleinopathy. Furthermore, the application of sophisticated, machine- learning, classification algorithms will streamline the processing and analyses of these data to derive statistical probabilities of Alzheimer's and other dementia subtypes. The overarching goal of the current, Direct-to-Phase II, SBIR project is to finalize implementation of a secure, cloud-based infrastructure to compile the data obtained from the AMP and Sleep Profiler, train classification algorithms to discriminate among Alzheimer's and other dementia subtypes, validate diagnostic accuracy, and integrate optimized classifiers within the cloud- based architecture. Once completed, the INSPECDS system will be the first clinical research tool of its kind and find immediate application in both university-based research settings and pharmaceutical industry clinical trials to aid in the endophenotypic stratification of Alzheimer's and other dementias. PROJECT NARRATIVE  Among clinical researchers focused on investigating the varying etiologies, genetic associations, clinical course, and treatment options for Alzheimer's and other neurodengenerative diseases, there is an urgent need for effective tools to aid in the classification of dementia subtypes, in the earliest detectable stages of the pathophysiological process. To address this unmet need, Advanced Brain Monitoring (Carlsbad, CA) is developing Integrated Neurocognitive and Sleep-Behavior Profilers for the Endophenotypic Classification of Dementia Subtypes (INSPECDS), which will provide an inexpensive, non-invasive solution combining neurocognitive, electrophysiological (EEG, ECG, EMG), and sleep-behavior assessment into a single, integrated system featuring automated scoring and classification algorithms. Once completed, the INSPECDS system will be the first clinical tool of its kind and find immediate application in clinical settings and pharmaceutical industry clinical trials to aid in the endophenotypic stratification of Alzheimer's and other dementia patients.",Characterizing Alzheimer's Disease with INSPECDS: Integrated Neurocognitive and Sleep-Behavior Profiler for the Endophenotypic Classification of Dementia Subtypes,9524766,R44AG054256,"['Accelerometer', 'Address', 'Adult', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Automatic Data Processing', 'Behavior', 'Behavior assessment', 'Biological Markers', 'Blinded', 'Brain', 'California', 'Cardiovascular Diseases', 'Cause of Death', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Data', 'Data Analyses', 'Dementia', 'Depressed mood', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Drug Industry', 'Economic Burden', 'Elderly', 'Electrocardiogram', 'Electroencephalography', 'Electrophysiology (science)', 'Enrollment', 'Etiology', 'Frontotemporal Dementia', 'Funding', 'General Hospitals', 'Goals', 'Head Movements', 'Home environment', 'Impaired cognition', 'Individual', 'Lewy Body Dementia', 'Machine Learning', 'Malignant Neoplasms', 'Massachusetts', 'Measures', 'Memory', 'Minor', 'Modification', 'Monitor', 'Neurocognitive', 'Neurodegenerative Disorders', 'Neurologic', 'Neuropsychological Tests', 'Obstructive Sleep Apnea', 'Parkinson Disease', 'Parkinson&apos', 's Dementia', 'Patients', 'Performance', 'Phase', 'Probability', 'Process', 'REM Sleep Behavior Disorder', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Sampling', 'Secure', 'Sleep', 'Sleep Architecture', 'Sleep Deprivation', 'Small Business Innovation Research Grant', 'Stratification', 'Stroke', 'Study Subject', 'System', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vascular Dementia', 'Wireless Technology', 'alertness', 'base', 'brain behavior', 'cloud based', 'cognitive function', 'cohort', 'computerized', 'data acquisition', 'data warehouse', 'diagnostic accuracy', 'genetic association', 'human subject', 'limb movement', 'mild cognitive impairment', 'neurocognitive test', 'relating to nervous system', 'synucleinopathy', 'tool']",NIA,"ADVANCED BRAIN MONITORING, INC.",R44,2018,548140,-0.11078430796942487
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9672008,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,347221,-0.01971324191279288
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9559873,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,300000,-0.01971324191279288
"Accelerating Multi-modal Biomarker Discovery in Translational Research with Cloud Data Integration Project Summary/Abstract Cytobank is the leading cloud-based platform for analysis and storage of single cell flow and mass cytometry data, technologies that are essential for investigating the interplay between the immune system and disease conditions including cancer. There are numerous data analysis steps between raw data and insight especially for many single-cell technologies, where the data analysis is complex, highly expert-driven and/or reliant on novel computational methodologies. Cytobank already makes major contributions (1) centralizing single-cell cytometry data, (2) providing data analysis traceability that removes knowledge sharing complexities, and (3) establishing a platform that increases access to cutting edge algorithms and makes complex machine learning methods easy for biologists to use. However, as the amount, complexity, and different types of single cell data and other associated data increases and the number of workflows and single-cell algorithms to analyze the data also increases, the need for open and easy access to existing and new tools and secure, complete storage of the workflows and the resulting data has increased to the point of being critical for supporting basic and translational research collaborations and enabling them to efficiently achieve their objectives including biomarker discovery and development. The proposed project significantly extends the capabilities of the Cytobank platform. This will benefit the community by (1) enabling scalable and secure access to a number of new single-cell data analysis tools that will result in new automated workflows, and (2) enable more efficient cross platform knowledge generation with increased meta-analysis capabilities across experiments and data types. The potential of this project is that thousands of scientists around the world will be able to more easily leverage additional single-cell cytometry, transcript, and other data in their translational research data analysis including automating analysis that has primarily been dominated by expert-driven annotation, thus providing a central repository and knowledge management framework that will accelerate biomarker discovery and precision medicine. Project Narrative Single-cell biology and Immunotherapy are exploding and generating larger and more complex datasets in combination clinical trials. To take full advantage of these revolutions, the iteration and dissemination of advanced single-cell data analysis algorithms (many of whose development was funded by the NIH) needs to scale at the same rate as single-cell data generation technologies are scaling, and multi-omics data analysis and visualization must be integrated and automated. This project will greatly accelerate scientific research, transparency, and reproducibility by significantly lowering the barrier to perform complex data analysis of multiple types of high-dimensional data, providing the biomedical research community with access to powerful tools needed in immuno-oncology, autoimmunity and other high-impact disease areas.",Accelerating Multi-modal Biomarker Discovery in Translational Research with Cloud Data Integration,9464486,R44GM117914,"['Acute Lymphocytic Leukemia', 'Algorithmic Analysis', 'Algorithms', 'Area', 'Autoimmunity', 'B-Lymphocytes', 'Basic Science', 'Biological Markers', 'Biomedical Research', 'Cells', 'Cellular biology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Follicular Lymphoma', 'Foundations', 'Funding', 'Generations', 'Immune System Diseases', 'Immune system', 'Immunologic Monitoring', 'Immunology', 'Immunooncology', 'Immunotherapy', 'Information Resources Management', 'Knowledge', 'Label', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Meta-Analysis', 'Modality', 'Modeling', 'Outcome', 'Patients', 'Phase', 'Population', 'Positioning Attribute', 'Regimen', 'Relapse', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Scientist', 'Secure', 'System', 'Target Populations', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Toxic effect', 'Transcript', 'Translational Research', 'Treatment Efficacy', 'United States National Institutes of Health', 'Work', 'anti-cancer', 'base', 'biomarker development', 'biomarker discovery', 'biomarker validation', 'clinically actionable', 'cloud based', 'cost effective', 'cytokine', 'data integration', 'data management', 'data visualization', 'experimental study', 'high dimensionality', 'immunotherapy trials', 'improved', 'insight', 'learning strategy', 'multiple omics', 'novel', 'outcome prediction', 'personalized medicine', 'population based', 'precision medicine', 'predict clinical outcome', 'predictive marker', 'predictive modeling', 'relapse prediction', 'repository', 'response', 'single cell analysis', 'single cell technology', 'single-cell RNA sequencing', 'synergism', 'tool', 'transcriptome sequencing', 'transcriptomics', 'tumor']",NIGMS,"CYTOBANK, INC.",R44,2018,613841,-0.026524607774253646
"Advancing a novel portable detection method for cannabis intoxication Intoxication from marijuana (MJ) impairs psychomotor performance and at least doubles the risk of motor vehicle accidents. The ongoing wave of legalization of MJ has brought increasing prevalence of driving while intoxicated with MJ. However, there is no quantitative biologic test that can accurately determine whether an individual is acutely impaired from MJ intoxication. Assays of the primary intoxicating substance in MJ, THC, in body fluids has a high false negative rate as THC is cleared from blood within 15 minutes, long before impairment is resolved. And assays of THC metabolites yield a high false positive rate because clearance of these metabolites can take weeks. Thus there is now no nor is there likely to ever be a test of blood, breath or body fluids that can accurately detect MJ intoxication. In response to this significant knowledge gap, this project aims to develop an accurate, portable method for detection of impairment due to MJ intoxication using functional near-infrared spectroscopy (fNIRS). fNIRS is a non-invasive, safe brain imaging technique that capitalizes on differences in the light absorption spectra of deoxygenated and oxygenated hemoglobin (Hb), that allows the measurement of relative changes in Hb concentration that reflect brain activity. fNIRS can be performed in natural environments at low cost, and thus can be used in real-world settings. In Phase I, we will develop an algorithm for individual-level detection of impairment from THC using fNIRS measurements. To do so, we will assess the effect of oral THC (or placebo) on fNIRS measurements, self-reported intoxication, and impairment as defined by the gold standard field sobriety test conducted by a Drug Recognition Expert (DRE) in 40 healthy MJ users. fNIRS assessments will examine (1) the effect of THC exposure on resting state and task-based activation in the prefrontal cortex, (2) the extent to which impairment in psychomotor functioning with THC administration correlates with THC-induced change in hemodynamic responses detected with fNIRS, and (3) the sensitivity and specificity and area under the ROC curve of fNIRS measurements and field sobriety test determinants of impairment. Milestone: Should machine learning applications to the data generate an algorithm that predicts impairment with >80% accuracy compared with a gold standard field sobriety test, we will proceed to Phase II. In Phase II, we will conduct fNIRS testing in 150 individuals under THC/placebo as in Phase I and in 50 individuals in a THC plus alcohol/placebo condition in order to further refine the algorithm for MJ impairment detection such that fNIRS detection concurs with field sobriety testing with >90% specificity. It is anticipated that this level of specificity could be used in legal definitions of impairment. This will warrant commercialization, which will be followed by prototype development and field testing. An accurate, quantitative, biological test that is user-friendly and enables law enforcement to detect impairment from MJ has the potential to dramatically change practice of law enforcement across the country and the world and thus has enormous commercial potential, as outlined in the Commercialization Plan and in accompanying letters of support. The goal of this project is to develop, test, and refine a method to accurately and reliably detect marijuana (MJ) impairment using a portable, user-friendly, non-invasive, brain-based modality. MJ doubles the chance of motor vehicle accidents, yet, there now exists no valid, biologically based method to detect whether an individual is acutely impaired from MJ. The development of a reliable, quantitative biological marker that enables law enforcement officers to screen individuals whom they suspect are impaired from MJ will have highly significant public health importance and enormous commercial potential.",Advancing a novel portable detection method for cannabis intoxication,9541180,R42DA043977,"['Acute', 'Adult', 'Age', 'Alcohols', 'Algorithms', 'Area', 'Base of the Brain', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Blood', 'Blood Circulation', 'Blood Tests', 'Body Fluids', 'Brain', 'Brain imaging', 'Cannabis', 'Collaborations', 'Comorbidity', 'Country', 'Cross-Over Trials', 'Data', 'Detection', 'Development', 'Devices', 'Dose', 'Double-Blind Method', 'Driving While Intoxicated', 'Drug Kinetics', 'Ensure', 'Environment', 'Equipment', 'Evaluation', 'Formulation', 'Future', 'Goals', 'Gold', 'Hemoglobin', 'Hour', 'Human Resources', 'Imaging Techniques', 'Impairment', 'Individual', 'Intoxication', 'Knowledge', 'Law Enforcement', 'Law Enforcement Officers', 'Legal', 'Letters', 'Licensing', 'Light', 'Machine Learning', 'Marijuana', 'Measurement', 'Methods', 'Modality', 'Near-Infrared Spectroscopy', 'Oral', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Placebos', 'Population', 'Prefrontal Cortex', 'Prevalence', 'Property', 'Psychomotor Impairments', 'Psychomotor Performance', 'Public Health', 'ROC Curve', 'Randomized', 'Readiness', 'Rest', 'Risk', 'Sensitivity and Specificity', 'Source', 'Specificity', 'System', 'THC exposure', 'Testing', 'Tetrahydrocannabinol', 'United States', 'Urine', 'Vendor', 'absorption', 'alcohol exposure', 'base', 'behavior test', 'commercialization', 'cost', 'density', 'detector', 'driving under influence', 'drug testing', 'field sobriety tests', 'field study', 'functional disability', 'hemodynamics', 'interest', 'marijuana legalization', 'marijuana use', 'marijuana user', 'novel', 'novel strategies', 'portability', 'prediction algorithm', 'prototype', 'response', 'spectroscopic imaging', 'tool', 'user-friendly', 'vehicular accident']",NIDA,"HIGHLIGHTI, INC",R42,2018,731789,-0.003358664687042394
"Understanding the impact of environmental disruption in biological timing systems through signal processing. Project Summary/Abstract.  Life on Earth evolved to take time cues from the Sun. Consequently, most or all cells in the mammalian body use genetic feedback loops to time their daily (circadian) rhythms. When a person or any mammal sees light, that winds an orchestrating circadian brain clock in the hypothalamic suprachiasmatic nucleus (SCN). The SCN in turn helps keep the myriad other tissue and endocrine rhythms in synchrony, enabling health. The modern environment is highly disruptive to this internal synchrony. Light at night from cell phones or urban light pollution, and social impositions like school start times or rotating work shifts all act as “temporal pollution,” causing loss of internal synchrony. The more severe the desynchrony, the higher the risk for a broad range of diseases, including obesity, cancer, infertility, depression and ultimately cognitive decline. Without knowing how these systems normally maintain synchrony or which systems are normally synchronized, it is hard to understand what happens in desynchrony to degrade health. This problem is complicated by the fact that some biological systems have ultradian (every few hours) and infradian (every few days) cycles in addition to circadian cycles. The hypothalamo-pituitary-adrenal axis (HPA) generates ultradian rhythms through negative feedback, but also shows a strong circadian cycle; the hypothalamo-pituitary-gonadal axis (HPG) shows the same negative feedback ultradian activity, circadian rhythmicity, and also infradian rhythms of ovulation and spermatogenesis. These two axes are regulated by the SCN. Recent work indicates that there is cross-talk between these axes, and that their hormonal outputs - corticosterone, and estradiol (in females) and testosterone (in males), respectively – work to synchronize extra-SCN tissues and behavioral rhythms of feeding and drinking (FaD). Finally, the SCN, HPA, and HPG axes all affect core body temperature (CBT), so that high temporal resolution recordings of CBT contain information about the cycling and synchrony of these systems across time scales.  There are three aims to this proposal, using rats as a model system: 1) Test at high temporal resolution the effects of changes to the HPA axis, HPG axis, and SCN on CBT. 2) Use these relationships to build a model that can back-predict the state of the HPA axis, HPG axis, and SCN from a high temporal resolution CBT record of a given individual. 3) Expose rats to environmental temporal disruption in the form of a 6 h “jetlag” phase advance of the light cycle, and use the model to predict the response across these systems at 1-minute temporal resolution. This work will employ within-animal comparisons before and after surgical and pharmacological manipulations of rats whose FaD, activity, and CBT are captured continuously at 1-minute resolution. These data will be analyzed using signal-processing and machine learning to define patterns and relationships. The resulting model will allow minimally-invasive exploration of environmental disruption across physiological systems in real time. The model will be used to quantify synchrony as it is disrupted and re-emerges, identifying markers for risk or resilience, and generating hypotheses for future work into preventive strategies and treatments. Project Narrative. Artificial lights and social obligation cause people living with modern infrastructure to suffer a loss of synchrony across their organs, which evolved to track the stable day and year light cycles. We know about internal synchrony mostly by the diseases that arise from its loss – everything from cancer to obesity, depression, and infertility. This work will develop a system for tracking the cycles of many body-systems at the same time with minute-to-minute accuracy, allowing rapid detection of desynchrony, and a potential way to study how synchrony works normally, and why its disruption by the modern environment causes disease.",Understanding the impact of environmental disruption in biological timing systems through signal processing.,9567170,K99ES027509,"['Address', 'Adrenal Glands', 'Affect', 'Animals', 'Automobile Driving', 'Back', 'Behavioral', 'Biological', 'Biological Models', 'Body Temperature', 'Body Temperature Changes', 'Brain', 'Cells', 'Cellular Phone', 'Chronic', 'Circadian Rhythms', 'Corticosterone', 'Coupling', 'Cues', 'Data', 'Development', 'Diabetes Mellitus', 'Disease', 'Dose', 'Dysmenorrhea', 'Dyspepsia', 'Endocrine', 'Endocrine system', 'Environment', 'Environmental Impact', 'Estradiol', 'Feedback', 'Female', 'Frequencies', 'Future', 'Genetic', 'Glucocorticoids', 'Health', 'Hormonal', 'Hormonal Change', 'Hour', 'Human', 'Hypothalamic structure', 'Impaired cognition', 'Impairment', 'Implant', 'Individual', 'Infertility', 'Inflammation', 'Investigation', 'Jet Lag Syndrome', 'Life', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Measures', 'Mental Depression', 'Modeling', 'Modernization', 'Monitor', 'Myocardial Infarction', 'Obesity', 'Operative Surgical Procedures', 'Organ', 'Orphan', 'Output', 'Ovulation', 'Pattern', 'Periodicity', 'Persons', 'Pharmacology', 'Phase', 'Physiological', 'Physiology', 'Pituitary-Adrenal System', 'Planet Earth', 'Pollution', 'Prevention strategy', 'Preventive treatment', 'Rattus', 'Records', 'Regulation', 'Research Infrastructure', 'Resolution', 'Risk', 'Risk Marker', 'Sampling', 'Schools', 'Shapes', 'Signal Transduction', 'Social Obligations', 'Spermatogenesis', 'Stress', 'Stroke', 'Structure', 'System', 'Testing', 'Testosterone', 'The Sun', 'Time', 'Tissues', 'Wireless Technology', 'Work', 'base', 'biological systems', 'body system', 'comparative', 'drinking', 'feeding', 'high risk', 'male', 'mathematical model', 'minimally invasive', 'pituitary gonadal axis', 'predicting response', 'predictive modeling', 'rapid detection', 'reconstruction', 'resilience', 'response', 'shift work', 'signal processing', 'social', 'suprachiasmatic nucleus', 'targeted treatment', 'temporal measurement', 'time use']",NIEHS,UNIVERSITY OF CALIFORNIA BERKELEY,K99,2018,104094,-0.017409427867655012
"Objective assessment of surgical competence in a septoplasty model DESCRIPTION (provided by applicant): To ensure patient safety, educators must train surgeons to set standards of competency, public health officials should put in place policies to ensure surgeons remain competent and surgeons should only perform surgeries that they are competent to perform. Measuring surgeon's technical skill is crucial part of determining if they are competent. Traditionally surgical skill is assessed most commonly during training using subjective non-validated metrics. This leads to variation in the definition of competency. Recent policies set forth by the Accreditation Council of Graduate Medical Education- the governing body for graduate medical education, mandate that technical skill be measured objectively. Currently, there are few valid objective measures available to measure technical competence. Our research will yield a set of tools and methodologies that can be deployed to across medical training programs to objectively measure surgical skill and competence. This platform is also capable of developing new objective measure of skill and competence. Specifically, first, we will develop an objective skills assessment platform, and establish standard data collection and quality assurance protocols for systematic deployment of our platform across multiple institutions. Second, our work will result in automated algorithms and analytic tools to objectivel measure skill using data captured with our platform. Third, we will establish objective methods to determine whether a surgeon is competent to perform surgery. Fourth, we will test the reliability and validity of our assessment tools. We will conduct our study using septoplasty as the prototype test-bed procedure. Septoplasty is a commonly performed procedure (more than 260,000 cases per year) and is a key index surgery by which residents in otolaryngology are evaluated. Our project lays the groundwork for subsequent research to establish national standards for objective skill and competency using data aggregated from numerous training programs in the country. PUBLIC HEALTH RELEVANCE: Policies for graduate medical education require that surgical competency be objectively determined, but currently available technology and methods do not yield objective assessments for surgical skill. Our project aims to provide educators with an integrated objective skills assessment platform and tools for objective determination of competency, which can be readily deployed across graduate surgical training programs in the country.",Objective assessment of surgical competence in a septoplasty model,9526465,R01DE025265,"['Accreditation', 'Address', 'Algorithmic Software', 'American', 'Area', 'Assessment tool', 'Beds', 'Cessation of life', 'Competence', 'Computer Assisted', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Collection', 'Data Quality', 'Data Set', 'Ensure', 'Evaluation', 'Exploratory/Developmental Grant for Diagnostic Cancer Imaging', 'Foundations', 'Inferior', 'Institution', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Otolaryngology', 'Patient Care', 'Patient-Focused Outcomes', 'Phase', 'Philosophy', 'Physicians', 'Pilot Projects', 'Policies', 'Postoperative Complications', 'Predictive Value', 'Procedures', 'Protocols documentation', 'Public Health', 'Quality Control', 'Repeat Surgery', 'Research', 'Research Infrastructure', 'Research Support', 'Residencies', 'Site', 'Surgeon', 'System', 'Technical Expertise', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Validity and Reliability', 'Validity of Results', 'Variant', 'Work', 'analytical tool', 'base', 'graduate medical education', 'high risk', 'hospital readmission', 'indexing', 'inter-institutional', 'patient safety', 'portability', 'programs', 'prototype', 'public health relevance', 'quality assurance', 'skills', 'success', 'tool']",NIDCR,JOHNS HOPKINS UNIVERSITY,R01,2018,503177,0.004235940448360421
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9622047,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Biological Neural Networks', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2018,1057846,-0.006100154503884509
"Acceleration techniques for SimSET SPECT simulations Abstract The Simulation System for Emission Tomography (SimSET) is one of the foundational tools for emission tomography research, used by hundreds of researchers worldwide for both positron emission tomography (PET) and single photon emission computed tomography (SPECT). It has proven to be accurate and efficient for both PET and low energy SPECT studies; because SimSET uses a geometric model for its SPECT collimation, it is less accurate for high energy isotopes. This application proposes to address this with the use of angular response functions (ARFs), a technique that has proven to accurately model SPECT collimation and detection for high-energy isotopes more efficiently than full photon-tracking simulations. In addition, we propose a novel ARF-based importance sampling method that will speed these simulations by a factor of >50. The generation of ARF tables is another consideration: it is extremely compute intensive and has caused ARF to be used only when a large number of simulations are needed using the same isotope/collimator/detector combination. For this reason, we also propose application of importance sampling to speed the generation of ARF tables by a factor 5, and the creation of a library of angular response functions for popular isotope/collimator/detector combinations. The former will lessen the computational cost of generating the tables, the latter will, for many users/uses, eliminate the need to generate ARF tables at all. This will greatly expand the potential applications of ARF-based simulations. Our first aim is to accelerate SimSET SPECT simulations without sacrificing accuracy. This will be accomplished by synergistically utilizing two tools: variance reduction and angular response function (ARF) tables. Variance reduction includes importance sampling and forced detection. We hypothesis that these techniques combined with information from our angular response function tables will improve SimSET simulation efficiency by >50 times of SPECT simulations of specific radioisotopes (e.g., I-123, Y-90, etc.). Our second aim is to accelerate ARF table generation. This will be accomplished by using importance sampling methods in the generation of ARFs. We further propose to use an adaptive stratification scheme that will simulate photons for a given table position only as long as required to determine its value to a user-specified precision. Our third aim is to create a library of pre-calculated ARF tables for popular vendor isotope/collimator/detector configurations. These ARF tables will then be made publically available for download through the SimSET website. With a registered user base of >500, we believe that these enhancements to SimSET will have far reaching impact on research projects throughout the world. Narrative The overall goal of this work is to develop methods to speed up the SimSET Monte Carlo-based simulation software for single photon computed tomography (SPECT) imaging systems by greater than 50-fold. This type of speed up with enable new research that was previously impractical due to the computation time required for simulation. In addition, all software tools and tables developed within this project will be made available via a web-based host.",Acceleration techniques for SimSET SPECT simulations,9583854,R03EB026800,"['90Y', 'Acceleration', 'Address', 'Algorithms', 'Collimator', 'Communities', 'Crystallization', 'Data', 'Detection', 'Foundations', 'Future', 'Generations', 'Goals', 'Industrialization', 'Institution', 'Isotopes', 'Libraries', 'Location', 'Machine Learning', 'Medical Research', 'Methods', 'Modeling', 'Online Systems', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Probability', 'Radioisotopes', 'Research', 'Research Personnel', 'Research Project Grants', 'Running', 'Sampling', 'Scheme', 'Software Tools', 'Specific qualifier value', 'Speed', 'Stratification', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Vendor', 'Weight', 'Work', 'X-Ray Computed Tomography', 'base', 'cost', 'detector', 'imaging system', 'improved', 'interest', 'novel', 'response', 'simulation', 'simulation software', 'single photon emission computed tomography', 'synergism', 'thallium-doped sodium iodide', 'tomography', 'tool', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R03,2018,74515,-0.04074236621731467
"SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data Abstract Over 30 million people in the US suffer from genetic diseases or cancers caused by mutations of which ~15% disrupt the regulation of splicing. Alternative splicing (AS) errors have been reported in literature to drive 370 genetic diseases out of ~800 described to date. In addition, due to the recent success of FDA-approved splicing modulators like Nusinersen, along with fascinating pre- clinical results underlining the importance of AS as therapeutic targets; splicing research has become of major interest to pharmaceutical companies. Envisagenics is developing SpliceCoreTM, an innovative cloud-based software platform using biomedical big data for AS analysis to discover new therapies and biomarkers for complex diseases. Our breakthrough platform combines algorithms and databases developed and experimentally validated at Cold Spring Harbor Laboratory (CSHL): SpliceTrapTM, for the detection of splicing activity using RNA-seq data; SpliceDuoTM, for the identification of significant splicing variation across biological samples; SpliceImpact2TM, for the prioritization of biologically relevant AS variants with therapeutic potential; and TXdbTM, a splicing isoform database that connects client’s proprietary data to public repositories such as the Cancer Genome Atlas (TCGA). Thanks to the Phase I award SpliceCore was adapted as a cloud-based software, accelerating scalability and adaptation to the fast- evolving market of biomedical Big Data. We now have deployed SpliceCore’s back-end on three cloud-service providers, increased its overall run-time by a factor of 12, developed tools to discover disease-specific AS isoforms, finalized and tested a machine-learning algorithm to predict the biological impact of AS, and experimentally validated some of our new predictions with a success rate of 82.5%. The goal for Phase II is to accelerate client acquisition through the development of user-interactive applications informed from client’s feedback by substantially expanding the platform’s knowledgebase and predictive functions with novel AS isoforms extracted from ~37,000 public datasets. Thus, a new version of SpliceCore will be developed to predict regulatory interactions between RNA-binding proteins and their RNA targets to assist in the interpretation of aberrant splicing factors through a collaboration with world renowned HHMI Professor Dr. Tom Tuschl from Rockefeller University and developer of Nusinersen, Professor Dr. Adrian Krainer from CSHL. Envisagenics is targeting the global bioinformatics market valued at $4 billion in 2014 with a CAGR of over 21%. SpliceCore could capture ~10% of the market, identify novel drug targets, and design RNA therapeutics from aberrant splicing events prevalent in cancer and a multitude of genetic diseases while increasing the efficiency of R&D in biopharma. Project Narrative In this SBIR Phase II, Envisagenics will advance the development of SpliceCoreTM, a cloud-based software platform for the discovery of drug-targets and biomarkers using biomedical big data. Therapeutic screens are increasingly focusing on Alternative Splicing (AS), a biological process that regulates gene-product structure and function. Strikingly, 50% of genetic diseases described in literature can be triggered by AS errors. The recent FDA approval of RNA-therapeutic compounds to correct AS errors, combined with increasingly available big datasets and groundbreaking cloud-computing provide a unique opportunity for computerized discovery of AS therapeutics. Envisagenics’ technology will help biomedical researchers to translate basic science into new therapeutic products for cancer and genetic diseases. By the completion of this project, we will deploy a user-friendly, secured and scalable SpliceCore software, with new functionalities ready for integration into biopharmaceutical Research & Development workflows.",SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data,9465337,R44GM116478,"['Achievement', 'Advanced Development', 'Affect', 'Algorithms', 'Alternative Splicing', 'Amyotrophic Lateral Sclerosis', 'Award', 'Back', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Products', 'Cancer Etiology', 'Client', 'Cloud Computing', 'Cloud Service', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Databases', 'Defect', 'Detection', 'Development', 'Disease', 'Drops', 'Drug Targeting', 'Dysmyelopoietic Syndromes', 'Ensure', 'Event', 'FDA approved', 'Face', 'Failure', 'Feedback', 'Food and Drug Administration Drug Approval', 'Frequencies', 'Genetic Diseases', 'Genotype-Tissue Expression Project', 'Goals', 'Growth', 'Imagery', 'Immunoprecipitation', 'Laboratories', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Meta-Analysis', 'Methods', 'Mutation', 'Nucleotides', 'Pathway interactions', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Predictive Analytics', 'Prevalence', 'Price', 'Privatization', 'Probability', 'Protein Binding Domain', 'Protein Isoforms', 'Protein Splicing', 'RNA', 'RNA Splicing', 'RNA-Binding Protein FUS', 'RNA-Binding Proteins', 'Regulation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Ribonucleosides', 'Risk', 'Running', 'SRSF2 gene', 'Sampling', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Specificity', 'Spinal Muscular Atrophy', 'Structure', 'System', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Universities', 'Validation', 'Variant', 'Work', 'big biomedical data', 'cancer genetics', 'case control', 'cloud based', 'commercial application', 'computerized', 'cost', 'crosslink', 'data mining', 'data warehouse', 'design', 'drug discovery', 'experimental study', 'fascinate', 'flexibility', 'gene product', 'human disease', 'improved', 'innovation', 'interest', 'knowledge base', 'learning strategy', 'new therapeutic target', 'novel', 'novel therapeutics', 'petabyte', 'pre-clinical', 'preclinical study', 'predictive modeling', 'professor', 'repository', 'research and development', 'service providers', 'success', 'system architecture', 'targeted biomarker', 'therapeutic RNA', 'therapeutic target', 'tool', 'transcriptome sequencing', 'user-friendly']",NIGMS,"ENVISAGENICS, INC.",R44,2018,982774,-0.04967716387576125
"SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data Abstract Over 30 million people in the US suffer from genetic diseases or cancers caused by mutations of which ~15% disrupt the regulation of splicing. Alternative splicing (AS) errors have been reported in literature to drive 370 genetic diseases out of ~800 described to date. In addition, due to the recent success of FDA-approved splicing modulators like Nusinersen, along with fascinating pre- clinical results underlining the importance of AS as therapeutic targets; splicing research has become of major interest to pharmaceutical companies. Envisagenics is developing SpliceCoreTM, an innovative cloud-based software platform using biomedical big data for AS analysis to discover new therapies and biomarkers for complex diseases. Our breakthrough platform combines algorithms and databases developed and experimentally validated at Cold Spring Harbor Laboratory (CSHL): SpliceTrapTM, for the detection of splicing activity using RNA-seq data; SpliceDuoTM, for the identification of significant splicing variation across biological samples; SpliceImpact2TM, for the prioritization of biologically relevant AS variants with therapeutic potential; and TXdbTM, a splicing isoform database that connects client’s proprietary data to public repositories such as the Cancer Genome Atlas (TCGA). Thanks to the Phase I award SpliceCore was adapted as a cloud-based software, accelerating scalability and adaptation to the fast- evolving market of biomedical Big Data. We now have deployed SpliceCore’s back-end on three cloud-service providers, increased its overall run-time by a factor of 12, developed tools to discover disease-specific AS isoforms, finalized and tested a machine-learning algorithm to predict the biological impact of AS, and experimentally validated some of our new predictions with a success rate of 82.5%. The goal for Phase II is to accelerate client acquisition through the development of user-interactive applications informed from client’s feedback by substantially expanding the platform’s knowledgebase and predictive functions with novel AS isoforms extracted from ~37,000 public datasets. Thus, a new version of SpliceCore will be developed to predict regulatory interactions between RNA-binding proteins and their RNA targets to assist in the interpretation of aberrant splicing factors through a collaboration with world renowned HHMI Professor Dr. Tom Tuschl from Rockefeller University and developer of Nusinersen, Professor Dr. Adrian Krainer from CSHL. Envisagenics is targeting the global bioinformatics market valued at $4 billion in 2014 with a CAGR of over 21%. SpliceCore could capture ~10% of the market, identify novel drug targets, and design RNA therapeutics from aberrant splicing events prevalent in cancer and a multitude of genetic diseases while increasing the efficiency of R&D in biopharma. Project Narrative In this SBIR Phase II, Envisagenics will advance the development of SpliceCoreTM, a cloud-based software platform for the discovery of drug-targets and biomarkers using biomedical big data. Therapeutic screens are increasingly focusing on Alternative Splicing (AS), a biological process that regulates gene-product structure and function. Strikingly, 50% of genetic diseases described in literature can be triggered by AS errors. The recent FDA approval of RNA-therapeutic compounds to correct AS errors, combined with increasingly available big datasets and groundbreaking cloud-computing provide a unique opportunity for computerized discovery of AS therapeutics. Envisagenics’ technology will help biomedical researchers to translate basic science into new therapeutic products for cancer and genetic diseases. By the completion of this project, we will deploy a user-friendly, secured and scalable SpliceCore software, with new functionalities ready for integration into biopharmaceutical Research & Development workflows.",SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data,9747570,R44GM116478,"['Achievement', 'Advanced Development', 'Affect', 'Algorithms', 'Alternative Splicing', 'Amyotrophic Lateral Sclerosis', 'Award', 'Back', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Products', 'Cancer Etiology', 'Client', 'Cloud Computing', 'Cloud Service', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Databases', 'Defect', 'Detection', 'Development', 'Disease', 'Drops', 'Drug Targeting', 'Dysmyelopoietic Syndromes', 'Ensure', 'Event', 'FDA approved', 'Face', 'Failure', 'Feedback', 'Food and Drug Administration Drug Approval', 'Frequencies', 'Genetic Diseases', 'Genotype-Tissue Expression Project', 'Goals', 'Growth', 'Imagery', 'Immunoprecipitation', 'Laboratories', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Meta-Analysis', 'Methods', 'Mutation', 'Nucleotides', 'Pathway interactions', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Predictive Analytics', 'Prevalence', 'Price', 'Privatization', 'Probability', 'Protein Binding Domain', 'Protein Isoforms', 'Protein Splicing', 'RNA', 'RNA Splicing', 'RNA-Binding Protein FUS', 'RNA-Binding Proteins', 'Regulation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Ribonucleosides', 'Risk', 'Running', 'SRSF2 gene', 'Sampling', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Specificity', 'Spinal Muscular Atrophy', 'Structure', 'System', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Universities', 'Validation', 'Variant', 'Work', 'big biomedical data', 'cancer genetics', 'case control', 'cloud based', 'commercial application', 'computerized', 'cost', 'crosslink', 'data mining', 'data warehouse', 'design', 'drug discovery', 'experimental study', 'fascinate', 'flexibility', 'gene product', 'human disease', 'improved', 'innovation', 'interest', 'knowledge base', 'learning strategy', 'new therapeutic target', 'novel', 'novel therapeutics', 'petabyte', 'pre-clinical', 'preclinical study', 'predictive modeling', 'professor', 'repository', 'research and development', 'service providers', 'success', 'system architecture', 'targeted biomarker', 'therapeutic RNA', 'therapeutic target', 'tool', 'transcriptome sequencing', 'user-friendly']",NIGMS,"ENVISAGENICS, INC.",R44,2018,125000,-0.04967716387576125
"Pre-cancer atlases of cutaneous and hematologic origin (PATCH Center) SUMMARY-ABSTRACT  The overall goal of this proposal is to construct two pre-cancer atlases (PCAs) from highly accessible pre- malignant diseases that impose high burdens on human health (i) one focused on progression of pre- melanoma lesions to invasive cancer and (ii) a second on progression from clonal hematopoiesis (CHIP) to myeloid neoplasms. Both of these involve expansion of specific clones in normal and diseased niches as shaped by complex interactions among immune and pre-cancer cells. The resulting Atlases developed by the Center for Pre-cancer Atlases of Cutaneous and Hematologic Origin (PATCH Center) present complementary technical challenges, avenues to scientific discovery, and opportunities for the development of precision prevention strategies and therapies. The key goal in both cases is to precisely delineate and understand the molecular mechanisms driving progression from pre-malignant to malignant disease, to identify high risk individuals, prioritize particular therapies and serve as the foundation for precision prevention clinical trials. This will be achieved by integrated characterization of single cell genotype and cell states using high-plex tissue imaging and omic characterization of cross-sectional and well-controlled longitudinal patient cohorts.  Aim 1 will establish an administrative core responsible for scientific management of the Center, coordination with HTAN members and dissemination of Atlases under the direction of an internal Executive Committee with three subcommittees. Aim 2 will establish a Biospecimen Unit under the leadership of pathologists, oncologists and a surgeon. The DFCI Pasquarello Tissue Repository will provide highly annotated hematological specimens for image-based and omic characterization of CHIP; the BWH dermatopathologic tissue repository will provide annotated FFPE samples for melanoma precursors. These services will also play a key role in prospective sample acquisition and analysis. Aim 3 will establish a Characterization Unit directed by an oncologist and pathologist to perform and integrate single-cell genomics, multiplex flow cytometry and high- plex imaging using two methods reduced to practice within the Center: tissue-based cyclic immunofluorescence (t-CyCIF) and DNA exchange imaging (DEI). The Characterization Unit will also validate reagents and associate all primary results with appropriate metadata, protocols and reagent specifications. Aim 4 will establish a Data Analysis Unit enlisting systems and computational biologists and data scientists to manage all aspects of data acquisition, interpretation and visualization. This is expected to be the most technically challenging aspect of the Atlas projects. The Data Analysis Unit will release Phase I/II atlases each in preliminary and final stages to facilitate collaborative and crowd-sourced approaches to algorithm development. The resulting human browsable and machine-readable atlases are expected to yield new scientific discoveries, demonstrate the feasibility and utility of new technologies and help to reduce the incidence of life-threatening cancers of the skin and blood. NARRATIVE Construction of Pre-Cancer Atlases comprising detailed spatial and molecular data on cell state and omic data in melanoma and clonal hematopoiesis will join together the two primary means of diagnosing human cancer: histology and genetics. The atlases we construct will help to identify patients with pre-cancer skin lesions and blood conditions at risk of progressing to malignancy at a sufficiently early stage that aggressive disease can be prevented.",Pre-cancer atlases of cutaneous and hematologic origin (PATCH Center),9627416,U2CCA233262,"['Algorithms', 'Antibodies', 'Area', 'Atlases', 'Automobile Driving', 'Back', 'Benchmarking', 'Biological Assay', 'Biopsy', 'Blood', 'Bone Marrow', 'Cancer Histology', 'Cell Line', 'Cells', 'Cellular Morphology', 'Clinical', 'Clinical Data', 'Code', 'Collaborations', 'Collection', 'Communication', 'Complex', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Cutaneous', 'DNA', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Science', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Engineering', 'Enrollment', 'Ensure', 'FAIR principles', 'Fee-for-Service Plans', 'Flow Cytometry', 'Formalin', 'Foundations', 'Freezing', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Head', 'Health', 'Hematopoiesis', 'Hematopoietic Neoplasms', 'Histologic', 'Human', 'Image', 'Imagery', 'Immune', 'Immunofluorescence Immunologic', 'Incidence', 'Individual', 'Industrialization', 'Laboratories', 'Lead', 'Leadership', 'Lesion', 'Life', 'Link', 'Liquid substance', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Maps', 'Metadata', 'Methods', 'Molecular', 'Monitor', 'Myeloproliferative disease', 'Oncologist', 'Paraffin Embedding', 'Pathologist', 'Patients', 'Performance', 'Periodicity', 'Pharmacology', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Premalignant', 'Prevention strategy', 'Prevention therapy', 'Prevention trial', 'Prospective cohort', 'Protocols documentation', 'Readability', 'Reagent', 'Research Personnel', 'Risk', 'Running', 'Sampling', 'Scientist', 'Services', 'Skin Cancer', 'Software Engineering', 'Solid', 'Specimen', 'Standardization', 'Stromal Cells', 'Surgeon', 'System', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'Tissue imaging', 'Tissues', 'Tumor Tissue', 'Validation', 'Visualization software', 'Work', 'base', 'cancer invasiveness', 'cell type', 'cohort', 'computing resources', 'crowdsourcing', 'data acquisition', 'data submission', 'data visualization', 'deep neural network', 'dimensional analysis', 'genetic analysis', 'high dimensionality', 'high risk', 'image visualization', 'individual patient', 'individualized prevention', 'insight', 'knowledge base', 'laser capture microdissection', 'learning strategy', 'melanoma', 'member', 'neoplastic', 'new technology', 'prevent', 'prevention clinical trial', 'prospective', 'repository', 'skin lesion', 'tumor microenvironment']",NCI,HARVARD MEDICAL SCHOOL,U2C,2018,6918530,-0.040020915795808784
"Novel Nanopore-based RNA Sequencing using Nucleobase-specific Tags Project Summary Cost-effective, and accurate sequencing of RNA, composed of both canonical and modified bases, of any length, without conversion to cDNA, and without amplification are the objectives of this project, and the ultimate goal is to sequence the transcriptome, and determine in a time-sensitive manner relative distribution of its components. Such accomplishment will directly impact prevention, diagnosis, and cure of disease and materialize the promise of personalized medicine. Current methods, such as Illumina's RNA-Seq, and the single molecule approaches of Pacific Biosciences and of Oxford Nanopore Technologies, still lag behind in many of the critical attributes mentioned above. The unresolved issue with nanopore-based sequencing is the observation that ion current vs. time recording does not refer to a single nucleobase, but to a short sequence of 4 or more bases. The problem, partially resolved with the use of sophisticated algorithms and learning machines, appears intractable for RNA that includes numerous post-transcriptional base modifications. As an illustration, if a nanopore reads a sequence of 4 bases and the specific RNA to be sequenced has a total of 8 different nucleobases (4 canonical and 4 modified), then 48 = 65,536 signals need to be discriminated from within an ion current range of 20 to 40 pA with a standard deviation of ±1 pA; this is an impossible computational task. However, if the nanopore could sense one base at a time and yield distinct ion current for each base, there will be only 8 different recordings to distinguish from, a much simpler task. Our own published results indicate that oligodeoxynucleotides conjugated with a pyrimidine-specific tag (Osmium tetroxide 2,2'-bipyrimidine or OsBp) yield enzyme-free, slow/readable translocation via α- Hemolysin, and distinct ion current levels for intact, T(OsBp), and C(OsBp) bases, suggesting that a single tag can yield sequencing information on purine, T, and C. The latter leads to the conjecture that the presence of a second, purine-specific, label would allow identification of all four canonical bases. Furthermore each tag has intrinsic selectivity for one base over another, and this will provide a handle for additional discrimination among the modified bases. In this phase I proposal we aim to demonstrate (i) near 100% labeling (true positives) with 0% internucleotide bond cleavage, and 0% false positives for RNA(OsBp), as we have already shown for DNA(OsBp), (ii) comparable labeling attributes for a purine-specific tag, and (iii) readable translocation with single pyrimidine base discrimination for RNA(OsBp). Success in these efforts will lead to single base discrimination and sequencing of RNA, including a number of post-transcriptionally modified bases, and pave the road for sequencing the transcriptome. ! PUBLIC HEALTH RELEVANCE: Advances in personalized medicine for diagnosis and treatment of disease require sequencing the RNA transcriptome with technologies that are currently unavailable. Nanopore-systems that exhibit single-base discrimination, like the one addressed in this proposal, will allow sequencing the transcriptome in an accurate, timely, and cost-effective manner.",Novel Nanopore-based RNA Sequencing using Nucleobase-specific Tags,9506880,R43HG010051,"['Address', 'Algorithmic Software', 'Algorithms', 'Base Sequence', 'Belief', 'Biological Assay', 'Biological Sciences', 'Cells', 'Complementary DNA', 'DNA', 'Development', 'Diagnosis', 'Digit structure', 'Discrimination', 'Disease', 'Enzymes', 'Exhibits', 'Genetic Transcription', 'Goals', 'Hemolysin', 'In Vitro', 'Individual', 'Investigation', 'Ions', 'Label', 'Length', 'Machine Learning', 'Measures', 'Methods', 'Modification', 'Monitor', 'Nucleic Acids', 'Nucleotides', 'Oligonucleotides', 'Osmium Tetroxide', 'Phase', 'Platinum', 'Platinum Compounds', 'Prevention', 'Protocols documentation', 'Publishing', 'Purines', 'Pyrimidine', 'Pyrimidines', 'RNA', 'RNA Sequences', 'Readability', 'Residual state', 'Signal Transduction', 'Site', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Transfer RNA', 'VDAC1 gene', 'analytical tool', 'base', 'constriction', 'cost effective', 'design', 'improved', 'nanopore', 'new technology', 'novel', 'nucleobase', 'personalized medicine', 'public health relevance', 'sensor', 'single molecule', 'success', 'transcriptome', 'transcriptome sequencing']",NHGRI,"YENOS ANALYTICAL, LLC",R43,2018,280000,-0.026456652678201437
"Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II Project Summary Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Clinical performance assessment emphasizes learner evaluation over learner development, lacks rigor and utility for developmental purposes, and clinical teachers have expressed particular difficulty with diagnosing reasoning deficits for remediation purposes. Further, medical students' diagnostic reasoning does not improve over the course of clinical training and senior medical students have highly variable diagnostic performance that is often rated below expectations according to theory-based and validated scoring criteria. Independent practice does not necessarily enhance the context for clinical reasoning; the majority of physicians' medical errors are thought to be diagnostic in nature. We propose to improve undergraduate medical education to minimize the time to clinical competency for first year residents through targeted diagnostic reasoning skill development that (1) integrates basic science and clinical instruction; (2) provides deliberate practice with structured, case-based learning opportunities; and (3) enables anytime/anywhere learning that fits with the demanding schedules of most medical students. Southern Illinois University School of Medicine (SIUSOM) is a recognized leader in using performance-based clinical competency exams to enhance reasoning skill acquisition among medical students. These exams feature clinical scenarios with standardized patients followed by diagnostic justification essays which require students to explicitly describe the thought process used to reach a final diagnosis. These essays are the most reliable method of assessing diagnostic strategies but are not in use in the majority of medical schools, though interest in improving diagnostic reasoning instruction and assessment during undergraduate medical education is widespread. Barriers to the widespread adoption of this approach are 1) the time-consuming need to hand score each essay; and 2) the difficulty in accurately and consistently identifying the causes of strategy failures. This project will develop an application to provide automated scoring of diagnostic justification essays, identification of the underlying causes of failure when students perform poorly, and feedback with instructional strategies for remediation specific to each deficit. We propose these specific aims: 1) Improve reliability of human scoring of DXJ essays. 2) Extend the automated scoring algorithms. 3) Automated reasoning failure categorization and remediation. 4) Complete the software development required for delivering the commercial product. 5) Evaluate predictive validity of automatically scored DXJ essays. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine. Project Narrative Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Better preparation during undergraduate medical education can shorten the time to competency of first year residents, improving patient outcomes. We propose to develop and test a technology-enabled, deliberate-practice approach to training diagnostic strategy that includes automated scoring of diagnostic justification essays, identification of specific diagnostic strategy failures and targeted remediation. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine.","Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II",9537633,R42GM108104,"['Address', 'Adopted', 'Adoption', 'Algorithms', 'Basic Science', 'Caring', 'Case Based Learning', 'Case Study', 'Charge', 'Classification', 'Clinical', 'Clinical Competence', 'Community Health Education', 'Competence', 'Consult', 'Custom', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Education', 'Educational Technology', 'Educational process of instructing', 'Ensure', 'Environment', 'Equation', 'Evaluation', 'Faculty', 'Failure', 'Feedback', 'Future', 'Goals', 'Hand', 'Hospitals', 'Human', 'Illinois', 'Incubators', 'Instruction', 'Leadership', 'Learning', 'Letters', 'Machine Learning', 'Measures', 'Medical', 'Medical Education', 'Medical Errors', 'Medical Students', 'Medicine', 'Methods', 'Modeling', 'Nature', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Preparation', 'Process', 'Recommendation', 'Role', 'Sales', 'Schedule', 'Semantics', 'Standardization', 'Structure', 'Students', 'Suggestion', 'Supervision', 'System', 'Taxonomy', 'Teaching Method', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validity and Reliability', 'Variant', 'base', 'educational atmosphere', 'essays', 'evidence base', 'expectation', 'improved', 'innovation', 'interest', 'medical schools', 'prototype', 'remediation', 'research and development', 'skill acquisition', 'skills', 'software development', 'teacher', 'theories', 'tool', 'undergraduate medical education', 'undergraduate student', 'virtual']",NIGMS,"PARALLEL CONSULTING, LLC",R42,2018,489952,-0.022438876250835408
"Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation Project Summary Neonatal endotracheal intubation (ETI) is a time-sensitive resuscitation procedure! essential for ventilation of newborns. It requires an unusually high level of skill due to the narrow airways, relatively large tongue, anterior glottic position, and low respiratory reserve of neonates (Bercic, Pocajt et al. 1978). Given the difficulty of the procedure and the high rate of complications in untrained hands, effective training is crucial. However, intubation success rates for pediatric residents are low under current resuscitation training programs and show little improvement between years 1-3 of residency (23-25%) (O'Donnell, Kamlin et al. 2006; Haubner, Barry et al. 2013). There is a pressing need to understand the factors that lead to poor training results and for innovative training modalities that can bridge the gap left by traditional training and thereby allow rapid skill acquisition. We hypothesize that current training and assessment methods suffer from 4 key weaknesses: (1) Poor realism: manikin and simulator-based training typically provide little variation in anatomy or difficulty level—key requirements for developing expertise (Dreyfus, Athanasiou et al. 1986)—and do not realistically model the look, feel, and motions of real tissue. (2) Subjective, highly variable, and resource-intensive assessment methods: training opportunities are limited by the availability of expert instructors. (3) Poor visualization: learners have poor knowledge about what went wrong and how to improve; they cannot see exactly what is going on inside the manikin or the patient and cannot directly monitor their actions relative to idealized, expert performance. (4) Assessment under artificially ideal conditions: assessments of ETI performance in classroom settings likely overestimate trainees' skill level because they do not mimic the stressors and distractions that are inherent in the real clinical environment. Technology-enhanced ETI simulators can resolve all of these key weaknesses: We have conducted preliminary work (Hahn, Li et al. 2016; Soghier, Li et al. 2014) on an augmented reality (AR (Azuma 1997)) manikin simulator driven by the motions of the trainee and physical manikin in real time that 1) provides a quantitative assessment of ETI technique and 2) allows the trainee to visualize the motion of the laryngoscope inside the manikin. The assessment score can provide feedback during the performance, as well as constitute part of the evaluation of the trainee's skill. Work under this proposal will build on this preliminary work. The specific aims are to: extend the current augmented reality (AR) manikin simulator to a virtual reality (VR) computer simulator and validate, extend and validate automated assessment and visualization algorithm for ETI, study training effectiveness by testing groups of pediatric residents across 3 years to quantify the effect of technology-enhanced methods relative to the current training regimen in terms of both intubation performance on simulators and clinical outcomes in patients, and assess performance under more realistic conditions. Project Narrative The current training and assessment of neonatal endotracheal intubation (ETI) suffers from key weaknesses of 1) poor realism of task simulators, 2) subjective, highly variable, and resource-intensive assessment methods, 3) poor visualization during simulation, and 4) assessment methods under artificially ideal conditions. This high-yield proposal will bridge the gap between training and clinical practice by using quantitative assessment tools and technology-enhanced simulation to improve ETI performance prior to patient care.",Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation,9547897,R01HD091179,"['Algorithms', 'Anatomy', 'Anterior', 'Assessment tool', 'Attention', 'Augmented Reality', 'Biomedical Engineering', 'Biometry', 'Childhood', 'Clinical', 'Cognitive Science', 'Computer Simulation', 'Computers', 'Data', 'Effectiveness', 'Enhancement Technology', 'Environment', 'Environmental air flow', 'Evaluation', 'Feedback', 'Hand', 'Imagery', 'Intratracheal Intubation', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Lead', 'Learning', 'Left', 'Libraries', 'Machine Learning', 'Manikins', 'Measures', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Neonatal', 'Neonatology', 'Newborn Infant', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Procedures', 'Regimen', 'Residencies', 'Resources', 'Resuscitation', 'Scanning', 'Standardization', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Tongue', 'Training', 'Training Programs', 'Validation', 'Variant', 'Work', 'base', 'clinical practice', 'computer science', 'distraction', 'evidence base', 'haptics', 'improved', 'innovation', 'instructor', 'kinematics', 'multidisciplinary', 'neonate', 'respiratory', 'simulation', 'skill acquisition', 'skills', 'stressor', 'success', 'training opportunity', 'virtual reality']",NICHD,GEORGE WASHINGTON UNIVERSITY,R01,2018,317404,-0.0033003311910998917
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9394010,U24DK112331,"['ATAC-seq', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Cost efficiency', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Lead', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Research Infrastructure', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'base', 'bisulfite sequencing', 'data resource', 'epigenomics', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'individual response', 'insight', 'medical schools', 'methylome', 'mortality', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2018,1639153,-0.016738689914551214
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9547376,R01DE027027,"['Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,362947,-0.01246562605029165
"Real-time prediction of marijuana use & effects of use on cognition in the natural environment ABSTRACT Some young adult marijuana (MJ) users report adverse effects of MJ use on cognition that impact daily functioning, with negative consequences such as injury and fatality due to driving while under the influence of MJ. Research on the effects of MJ use on cognition, however, has produced mixed findings. MJ effects on cognition may depend on factors such as history and current severity of marijuana use, time since last MJ use (including possible MJ withdrawal effects), and gender. This R21 aims to address limitations of existing research by (1) starting to develop an algorithm to predict MJ use using smartphone data in regular/heavy MJ users based on “routine” or “habitual use”, and (2) examining effects of MJ use on cognition using smartphone- based cognitive testing in the natural environment. Development of an algorithm to predict MJ use would facilitate systematic assessment of MJ effects on cognitive functioning through more efficient scheduling of smartphone cognitive testing among regular/heavy MJ users in relation to daily routines. Cognitive testing by smartphone in the natural environment is an innovative method that has shown validity, and permits sampling of cognitive functioning within and across days in relation to MJ use. This project will enroll non-treatment seeking young adult (ages 18-25) MJ users from the community, representing “low”, “regular”, and “heavy” MJ use, with 50% female at each level of use. Participants will complete a baseline lab assessment, 30-day data collection using smartphone and wearable devices (e.g., wristband), and a debriefing interview. Piloting will optimize the protocol and methods for compliance. Smartphones will collect continuously sensed data (e.g., geolocation) for input to an algorithm to predict MJ use in regular/heavy MJ users. This R21 will identify which types of data, available through smartphone, provide optimal detection of routines in MJ use among regular/heavy users. Smartphone cognitive testing will be administered at various times during acute MJ intoxication and various naturalistically occurring lengths of MJ abstinence to examine effects of MJ use on selected aspects of cognitive functioning in daily life. Development of an algorithm to predict MJ use in regular/heavy MJ users based on smartphone data could, for example, facilitate real-time assessment of MJ effects on cognition through improved sampling of cognition in relation to acute and non-acute effects of MJ use. This R21 will provide the foundation for a research program that aims to examine MJ effects on cognitive functioning in vivo, and could support the development of just-in-time intervention to reduce MJ use. This R21 aligns with NIDA's strategic goal of determining consequences of drug use, and cross-cutting themes of highlighting real-world relevance of research and leveraging mobile health technologies to reduce drug use. Project Narrative This exploratory project will initiate development of an algorithm to predict marijuana use using data from smartphone and ecological momentary assessment, and will examine effects of marijuana use on cognitive functioning in the natural environment using innovative smartphone-based cognitive tests. Developing an algorithm to predict marijuana use has substantial healthcare applications, specifically for timely intervention to reduce marijuana use. Further, examining effects of marijuana use on cognitive functioning daily life has important implications for determining possible adverse health consequences associated with marijuana use.",Real-time prediction of marijuana use & effects of use on cognition in the natural environment,9456715,R21DA043181,"['Abstinence', 'Acute', 'Address', 'Adverse effects', 'Age', 'Age of Onset', 'Algorithms', 'Attention', 'Automobile Driving', 'Awareness', 'Behavior', 'Cellular Phone', 'Cognition', 'Communities', 'Data', 'Data Collection', 'Detection', 'Development', 'Drug usage', 'Ecological momentary assessment', 'Enrollment', 'Environment', 'Female', 'Foundations', 'Frequencies', 'Gender', 'Geography', 'Goals', 'Health', 'Health Technology', 'Healthcare', 'Heart Rate', 'Hour', 'Injury', 'Intake', 'Intervention', 'Interview', 'Intoxication', 'Length', 'Life', 'Literature', 'Location', 'Machine Learning', 'Marijuana', 'Metadata', 'Methods', 'Modeling', 'Monitor', 'Moods', 'National Institute of Drug Abuse', 'Participant', 'Patient Self-Report', 'Performance', 'Positioning Attribute', 'Procedures', 'Protocols documentation', 'Recording of previous events', 'Relaxation', 'Reporting', 'Research', 'Sampling', 'Schedule', 'Severities', 'Short-Term Memory', 'System', 'Testing', 'Text', 'Time', 'Travel', 'Withdrawal', 'addiction', 'age group', 'base', 'cognitive function', 'cognitive task', 'cognitive testing', 'computer science', 'daily functioning', 'data mining', 'improved', 'in vivo', 'innovation', 'mHealth', 'male', 'marijuana use', 'marijuana use disorder', 'marijuana user', 'marijuana withdrawal', 'mobile computing', 'prediction algorithm', 'predictive modeling', 'programs', 'recruit', 'reduce marijuana use', 'wearable device', 'young adult']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2018,196166,-0.029593197196386402
"Characterization of Thyroid Nodules by Quantitative Ultrasound Project Summary Thyroid cancer is the most-common endocrine malignancy. Its incidence has tripled in the last thirty years. Diagnosis of thyroid cancer is difficult because 50% of people older than 65 have at least 1 thyroid nodule, but only 10% of the nodules are cancerous. Approximately 1.6 billion dollars are spent annually in the US to detect thyroid cancer. Conventional ultrasound is used to identify nodules that warrant a needle biopsy. However, 65% of needle biopsies are negative for cancer and 30% are “indeterminate.” The indeterminate nodules are surgically removed for definitive diagnosis and 75% of them prove to be benign. Therefore, well more than 80% of initially presenting nodules undergo unnecessary biopsies and more than 20% of them also undergo subsequent unnecessary surgery procedures. Accordingly, the broad objective of the proposed study is to assess the feasibility of using quantitative-ultrasound (QUS) methods to distinguish cancerous from benign nodules reliably and thereby to reduce the enormous cost and risks associated with unnecessary biopsies and surgical excisions. The first aim of the project is to develop and asses the ability of QUS to distinguish cancerous from benign nodules and to compare the ability of QUS to the ability of conventional methods to select nodules that warrant biopsies; the second aim is to expand QUS methods by combining existing QUS measures developed by Riverside Research with measures derived from so-called B-flow- imaging (BFI) and shear-wave-elasticity (SWE) techniques developed by GE; the third aim is to formulate an objective basis for planning future, prospective studies to translate the findings of the present study to a commercial instrument that can bring QUS-based nodule evaluation into the clinic. To achieve these three aims, QUS performance in classifying cancerous and benign nodules will be compared to the performance of conventional ultrasound and the results of fine needle cytology, molecular marker analyses, and, in the cases of that undergo surgical excision, histology, will used as gold standards. Classification will be performed using standard, well understood, linear, and non-linear methods, such as linear-discriminant analysis and support- vector machines respectively. If feasibility is successfully demonstrated in the proposed project, and if the demonstration of feasibility ultimately leads to future incorporation into an instrument capable of real-time QUS analysis for reliable nodule evaluation, then a highly significant technological advance will be realized that can provide valuable, risk-reducing, cost-effective health-care benefits for patients presenting with thyroid nodules.   PROJECT NARRATIVE: Thyroid cancer rates have tripled in the last thirty years, but current methods of diagnosis are very inefficient. Far too many thyroid biopsies and surgeries are performed with >80% of biopsies and >25% of thyroid surgeries being performed on benign nodules. The advanced ultrasound methods to be evaluated in this proposal seek to drastically reduce the number of unnecessary biopsies and surgeries of benign thyroid nodules.",Characterization of Thyroid Nodules by Quantitative Ultrasound,9405532,R21CA212744,"['Achievement', 'Age', 'Architecture', 'Area', 'Asses', 'Benign', 'Biopsy', 'Breast Microcalcification', 'Cancer Death Rates', 'Cancerous', 'Classification', 'Clinic', 'Clinical', 'Cytology', 'Cytology Histology', 'Data', 'Detection', 'Diagnosis', 'Discriminant Analysis', 'Elasticity', 'Endocrine', 'Evaluation', 'Excision', 'Fine-needle biopsy', 'Foundations', 'Future', 'Goals', 'Gold', 'Healthcare', 'Histology', 'Image', 'In Situ', 'Incidence', 'Investigation', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measures', 'Methods', 'Molecular', 'Needle biopsy procedure', 'Needles', 'Nodule', 'Non-Malignant', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Performance', 'Population', 'Probability', 'Procedures', 'Property', 'Prospective Studies', 'Prostate', 'ROC Curve', 'Research', 'Risk', 'Signal Transduction', 'Solid', 'Specificity', 'Techniques', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Time', 'Tissues', 'Training', 'Translating', 'Ultrasonography', 'United States', 'Unnecessary Surgery', 'base', 'calcification', 'care costs', 'cost', 'cost effective', 'design', 'elastography', 'improved', 'instrument', 'lymph nodes', 'molecular marker', 'novel', 'prevent', 'prospective', 'quantitative ultrasound', 'statistics']",NCI,BOSTON MEDICAL CENTER,R21,2018,190102,-0.062423136955017
"Partelligence Abstract Halo Labs proposes to develop “Partelligence” a particle ID technique that enables accurate and rapid identification of contaminating particles in biopharmaceutical formulations. Protein therapeutics currently represent between 15 and 30% of the overall pharmaceutical market. The primary concern for this class of therapeutics is that they can elicit an immune response from patients who develop anti- drug antibodies. The drug’s effect is therefore eliminated between 1 and 10 percent of patients who return to their original disease state. The presence of particulate matter in these therapeutics (e.g. shed glass from a syringe or a protein aggregate) can enhance this immune response and, due to the patient safety risk the FDA regulates the amount of particles that can be present. There are always some number of particles in each injected sample, and although their presence can be detected, they don’t know what the particles actually are. A QC tool that can identify the particles would help manufactures trace them back to their source (e.g. a bad lot of syringes) and eliminate them. Partelligence aims to make particle identification routine in biopharma QC. The technology builds off our current instrument, Horizon, which was launched in mid-2017 and already sold to some of the world’s largest pharmaceutical companies. The technique works by analyzing several combinatorial features including size, morphology, optical contrast, and intrinsic fluorescence, and in this proposal we will test which features are key to enable the most accurate and rapid particle recognition. To date, we have performed feasibility experiments validating our ability to identify a few commonly found particles in biopharma solutions. Given this, our goals in Phase I are to expand on these studies by building a comprehensive training set and by testing a number of different algorithms. We will first start with reference samples, and then move to real biopharmaceutical samples provided by our pharma collaborators. At the end of the study, we will do a feasibility analysis to determine if the throughput, specificity and reliability meets the needs of the industry. Narrative We propose to evaluate a particle recognition technique to enable accurate and rapid identification of unwanted contaminating particles in biopharmaceutical formulations. Successful development of this analytical technique would improve bioprocess control by identifying dangers early on in development and throughout the manufacturing process, resulting in safer protein drugs, reduced recalls and shortened time to market.",Partelligence,9679781,R43GM132995,"['Adverse effects', 'Algorithmic Analysis', 'Algorithms', 'Allergic Reaction', 'Alpha Particles', 'Anaphylaxis', 'Antibodies', 'Back', 'Biological Neural Networks', 'Biological Products', 'Cessation of life', 'Classification', 'Clinic', 'Dangerousness', 'Data', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Event', 'Failure', 'Fluorescence', 'Forensic Medicine', 'Formulation', 'Generations', 'Glass', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immune', 'Immune response', 'Industrialization', 'Industry', 'Investigation', 'Label', 'Learning', 'Letters', 'Machine Learning', 'Membrane', 'Morphology', 'Optics', 'Particulate', 'Particulate Matter', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Process', 'Proteins', 'Raman Spectrum Analysis', 'Regulation', 'Resistance development', 'Risk', 'Rubber', 'Sampling', 'Scientist', 'Shapes', 'Source', 'Specificity', 'Spectroscopy, Fourier Transform Infrared', 'Syringes', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Work', 'base', 'bioprocess', 'combinatorial', 'experience', 'experimental study', 'fluorescence imaging', 'forest', 'imaging modality', 'immunogenicity', 'improved', 'instrument', 'manufacturing process', 'microscopic imaging', 'particle', 'patient response', 'patient safety', 'predictive modeling', 'pressure', 'protein aggregate', 'small molecule', 'therapeutic protein', 'tool', 'trend']",NIGMS,"OPTOFLUIDICS, INC.",R43,2018,203830,-0.04324073480311666
"The nGoggle: A portable brain-based device for assessment of visual function deficits PROJECT SUMMARY Assessment of loss of visual function outside the foveal area is an essential component of the management of numerous conditions, including glaucoma, retinal and neurological disorders. Despite the significant progress achieved with the development of standard automated perimetry (SAP) many decades ago, assessment of visual field loss with SAP still has significant drawbacks. SAP testing is limited by subjectivity of patient responses and high test-retest variability, frequently requiring many tests for effective detection of change over time. Moreover, as these tests are generally conducted in clinic-based settings, limited patient availability and health care resources often result in an insufficient number of tests acquired over time, with delayed diagnosis and detection of disease progression. The requirement for highly trained technicians, cost, complexity, and lack of portability of SAP also preclude its use for screening of visual field loss in underserved populations. To address shortcomings of current methods to assess visual function, we have developed the nGoggle, a wearable device that uses a head-mounted display (HMD) integrated with wireless electroencephalography (EEG), capable of objectively assessing visual field deficits using multifocal steady-state visual-evoked potentials (mfSSVEP). As part of the funded NEI SBIR Phase I, we developed the nGoggle prototype using a modified smartphone-based HMD display and non-disposable electrodes. In our Phase I studies, we conducted benchmarking tests on signal quality of EEG acquisition, developed methods for EEG data extraction and analysis, and conducted a pilot study demonstrating the ability of the device to detect visual field loss in glaucoma, a progressive neuropathy that results in characteristic damage to the optic nerve and resulting visual field defects. We also identified limitations of current existing displays and electrodes, as well as potential avenues for enhancing test reliability and improving user interface. Based on the encouraging results from Phase I and a clear delineation of the steps needed to bring the device into its final commercial product form, we now propose a series of Phase II studies. We hypothesize that optimization of nGoggle's accuracy and repeatability in detecting visual function loss can be achieved through the development of a customized head-mounted display with front-view eye/pupil tracking cameras and disposable no-prep electrodes, as well as enhancement of the visual stimulation protocol and data analytics. The specific aims of this proposal are: 1) To develop a customized head-mounted display and enhanced no-prep electrodes for improving nGoggle's ability to acquire users' mfSSVEP with high signal-to- noise ratios (SNR) in response to visual stimulation; 2) To optimize and validate mfSSVEP stimuli design and data analytics to enhance the accuracy and repeatability of assessing visual function loss with the nGoggle. 3) Complete pivotal clinical studies to support FDA approval. PROJECT NARRATIVE NGoggle Inc. has developed the nGoggle, a wearable device that uses a head-mounted display integrated with wireless electroencephalography, capable of objectively assessing visual field deficits using multifocal steady- state visual-evoked potentials. NGoggle Inc is now proposing to optimize nGoggle's accuracy and repeatability in detecting visual function loss with the use of a customized display, adherent no-prep electrodes, optimized visual stimuli and data analytics. It will also complete pivotal clinical studies to support FDA approval.",The nGoggle: A portable brain-based device for assessment of visual function deficits,9559052,R42EY027651,"['Address', 'Algorithms', 'Area', 'Base of the Brain', 'Benchmarking', 'Blindness', 'Brain', 'Cellular Phone', 'Characteristics', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Custom', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Elastomers', 'Electrodes', 'Electroencephalography', 'Electrooculogram', 'Exhibits', 'Eye', 'Funding', 'Glaucoma', 'Head', 'Healthcare', 'Machine Learning', 'Methods', 'Neuropathy', 'Noise', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Perimetry', 'Phase', 'Photic Stimulation', 'Pilot Projects', 'Protocols documentation', 'Pupil', 'Resources', 'Retinal Diseases', 'Scotoma', 'Series', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Source', 'Stimulus', 'Testing', 'Time', 'Training', 'Underserved Population', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Wireless Technology', 'base', 'cost', 'design', 'field study', 'improved', 'loss of function', 'nervous system disorder', 'patient response', 'phase 1 study', 'phase 2 study', 'portability', 'prototype', 'real world application', 'relating to nervous system', 'response', 'sample fixation', 'screening', 'virtual reality', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R42,2018,849367,-0.011206379197868346
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9438535,R01EY025332,"['Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2018,416574,-0.012116934805377266
"Socioeconomic status, stress, and smoking cessation PROJECT SUMMARY/ABSTRACT  The prevalence of electronic nicotine delivery systems (ENDS) is rising dramatically among both adults and youth and ENDS use is fast becoming a major public health issue. However, because of their recent emergence, researchers know little about ENDS, their use, their effects on human physiology and health, their risks and benefits, or their impact on tobacco control efforts. A common barrier to studying ENDS is the lack of data on objective, real world use of ENDS. Thus, the proposed project aims to adapt existing innovative mobile assessment tools that can be used to target critical ENDS research gaps by providing mobile sensing technology that can objectively collect precise data regarding ENDS use in real time in real world. Specifically, the proposed revision project will expand the scope of Project On Track (1R01CA190329-01A1, PI: Wetter) by extending the application of puffMarker, an existing tool that automatically detects smoking, for the assessment of ENDS use. The current project has three aims: 1) adapt and validate puffMarker to identify discrete episodes of ENDS use, 2) adapt and validate puffMarker to distinguish between cigarette smoking and ENDS use among dual users of ENDS and cigarettes, and 3) utilize the Project On Track protocol to collect real time, real world data investigating potential determinants of ENDS use among both exclusive ENDS users as well as dual users of cigarettes and ENDS. Altogether, 120 participants (30 for Aim 1, 30 for Aim 2, and 60 for Aim 3) will be enrolled. Participants recruited for Aims 1 and 2 will attend laboratory (three 2-hour sessions) and field (3 days) studies. In the laboratory sessions, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke a cigarette (Aim 2). Participants' ENDS and cigarette puffs will be recorded by an independent observer. In the field studies, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke cigarettes (Aim 2). Participants will be asked to record each instance of ENDS use or cigarette smoking on a SP. The goals of the laboratory studies are to collect data to train puffMarker to identify ENDS use and to distinguish between cigarette smoking and ENDS use. The goal of the field studies is to validate puffMarker in real-life, natural environments. Aim 3 will utilize the Project On Track protocol to collect the first real time, real world data on ENDS and dual use. Participants will be assessed for 6 days using AutoSense, EMA, and GPS to examine potential determinants of ENDS use. A validated puffMarker that detects ENDS use and distinguishes between ENDS use and smoking can enhance many areas of research inquiry on ENDS. Knowledge learned from Aim 3 will be essential for the development of comprehensive conceptual models with respect to ENDS use and smoking cessation. PROJECT NARRATIVE The proposed project aims to develop an innovative tool that targets important ENDS research gaps by offer- ing researchers the latest mobile sensing technology to objectively collect precise data regarding ENDS use and distinguish between ENDS use and smoking in real time and in real world.","Socioeconomic status, stress, and smoking cessation",9547313,R01CA190329,"['Abstinence', 'Acute', 'Address', 'Adult', 'Algorithms', 'Area', 'Assessment tool', 'Behavior', 'Behavioral', 'Benefits and Risks', 'Big Data to Knowledge', 'Breathing', 'Cellular Phone', 'Characteristics', 'Chest', 'Cigarette', 'Data', 'Detection', 'Development', 'Ecological momentary assessment', 'Electronic Nicotine Delivery Systems', 'Enrollment', 'Environment', 'Environmental Risk Factor', 'Geography', 'Gestures', 'Goals', 'Grain', 'Hand', 'Harm Reduction', 'Health', 'High School Student', 'Hour', 'Human', 'Individual', 'Inhalation', 'Knowledge', 'Laboratories', 'Laboratory Study', 'Life', 'Longitudinal cohort study', 'Machine Learning', 'Measures', 'Modeling', 'Movement', 'Oral cavity', 'Participant', 'Patient Recruitments', 'Pattern', 'Physiological', 'Physiology', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Process', 'Protocols documentation', 'Public Health', 'Questionnaires', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Sensitivity and Specificity', 'Sensory', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Social Environment', 'Socioeconomic Status', 'Stress', 'System', 'Technology', 'Time', 'Tobacco', 'Training', 'United States National Institutes of Health', 'Wireless Technology', 'Wrist', 'Youth', 'addiction', 'arm movement', 'base', 'biobehavior', 'built environment', 'cigarette smoke', 'cigarette smoking', 'cigarette user', 'data to knowledge', 'experience', 'field study', 'innovation', 'novel', 'parent grant', 'population health', 'primary outcome', 'programs', 'psychosocial', 'real time monitoring', 'recruit', 'respiratory', 'sensor', 'sensor technology', 'smoking cessation', 'social', 'systems research', 'tobacco control', 'tool', 'uptake', 'wearable device', 'young adult']",NCI,UNIVERSITY OF UTAH,R01,2018,1,-0.010792510623091122
"Improving safety and efficacy of platelet transfusion through systems biology Project Summary Platelet transfusion is critical for severely bleeding patients and nearly 6 million units are transfused in the United States and Europe annually. In the United States, platelets are typically stored for 5 days resulting in a waste of 20% of their supply. Short storage duration is a consequence of bacterial contamination and platelet quality considerations. Though many methods have been developed for bacterial testing and pathogen inactivation, fewer have been developed for improving quality of stored platelets. Platelet additive solutions have the possibility to increase storage quality and duration, reduce plasma-related allergic reactions, impact the efficacy of pathogen reduction techniques, and save plasma which can then be used as an additional transfusion product. While the benefits are well known, there has been little progress in developing new platelet additive solutions for increasing quality and safety of platelet transfusion because there is a lack of broad understanding of biochemical and signaling changes during storage. There has been interest to utilize high-throughput metabolite profiling for global understanding of platelet metabolic decline but data analysis of complex datasets has been a daunting challenge. In Phase I of this program, we developed the first, robust computational platform involving statistical analysis and systems biology of metabolic and signaling networks to interpret and analyze PLT metabolomic and proteomic profiles in a complete network context. Using time- course global, quantitative metabolite profiling, we determined that PLTs undergo a non-linear decay process and computationally identified key metabolic enzymes and cellular process that drive this decay. Based on the computational results, we have devised two novel additive solution strategies to mitigate the decay process and improve the length of PLT units. In this Phase II proposal, we will validate the computationally determined additive solutions for efficacy in alleviating the non-linear decay process through 1) metabolomics experiments, and 2) non-metabolic PLT physiology experiments including cell activation and hemostatic effectiveness. A successful additive solution will be progressed to media refinement and preclinical testing. Project Narrative Platelet transfusion units are typically stored for five days in the United States leading to a waste of 20% of units and potential quality concerns. The field is open for innovation as most storage media technologies are derived from work from the early 1990s. This proposal will develop novel computational methods to comprehensively understand the degradation of platelets under storage conditions and experimentally validate new additive solutions for increasing platelet quality and extending shelf life, an area that accounts for $2.5 billion of hospital costs.",Improving safety and efficacy of platelet transfusion through systems biology,9506810,R44HL127843,"['Accounting', 'Agreement', 'Algorithms', 'Allergic Reaction', 'Area', 'Biochemical', 'Biological', 'Blood', 'Blood Component Removal', 'Blood Platelets', 'Cell physiology', 'Cells', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Effectiveness', 'Enzymes', 'Equipment and supply inventories', 'Europe', 'Formulation', 'Glutathione', 'Hemorrhage', 'Hemostatic Agents', 'Hospital Costs', 'In Vitro', 'Intervention', 'Length', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Mathematics', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Methods', 'Modeling', 'Pathway interactions', 'Patients', 'Phase', 'Physiology', 'Plasma', 'Platelet Transfusion', 'Preclinical Testing', 'Process', 'Production', 'Proteomics', 'Reaction', 'Recovery', 'Resources', 'Risk', 'Safety', 'Signal Pathway', 'Signal Transduction', 'State Hospitals', 'Statistical Data Interpretation', 'Supplementation', 'Surveys', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Transfusion', 'United States', 'Validation', 'Work', 'base', 'care costs', 'cost', 'design', 'experimental study', 'human subject', 'improved', 'insight', 'interest', 'metabolic profile', 'metabolomics', 'model design', 'novel', 'open innovation', 'oxidative damage', 'pathogen', 'predictive modeling', 'preservation', 'programs', 'statistics', 'success', 'time use', 'wasting']",NHLBI,"SINOPIA BIOSCIENCES, INC.",R44,2018,428727,-0.02077237442698936
"Insightful Surgical Vision Technology (ISVision) for intelligent real-time display of anatomic, physiologic, and pathologic information in surgery Abstract Intelligent intraoperative display of anatomic and physiologic information coupled to real time situational awareness to critical tissues will benefit all surgery. The current surgical vision is limited to naked human eyes in open surgery or more recently using laparoscopic digital imaging for minimally invasive surgery and robot assisted surgery. In laparoscopic vision, although the visualization of surface anatomy and tissue physiology in the surgical field-of-view has been enhanced by recent advances in optical imaging technology, the imaging paradigm still remains passive and still poses a significant challenge due to the inherent narrow peripheral vision and limited depth perception. We propose the next generation laparoscopic vision system that provides intelligent display of unrecognized tissue structures to human eyes. Our proposed use of a new paradigm and surgical vision technology (called ISVisionTM), equipped with modular plenoptic 3-D Color/HD camera and snapshot NIR hyperspectral imager, will permit a clear visualization of the critical target tissue-of-interest, surrounding anatomy into the operative field, and situational awareness for both the tool and tissue to the surgeon. Our Phase I effort comprises of engineering the clinically viable ISVision platform and testing the performance of its intraoperative use. Specifically, the ISVision system will clearly and precisely identify different tissue characteristics, accurately displaying physiologic information including tissue perfusion and blood flow. Following the Phase 1, we anticipate undertaking a Phase II project, during which we will develop a clinical grade ISVision system and investigate its performance and utility in the operating room. While the initial focus of the Phase I and II effort is on the complex surgery such as liver resection due to crucial nature of critical sub-surface structures located underneath liver hilum and parenchyma, the ISVision system will potentially play an enabling role in all surgeries and establish it as a vital component of the operating room of the future. Narrative Real-time display of the accurate anatomic and tissue physiology during surgery is necessary and crucial in improving surgical outcomes. This proposal aims to develop the next generation surgical vision system that provides intelligent display of unrecognized, unseen tissue structures to human eyes. The current state of the art technology still remains passive, focuses on anatomic display only. A new surgical vision technology, called ISVisionTM, will provide clear display of important anatomic structures, identify not only their distinct shape and position, and offer insightful intelligent function during surgical procedures. The academic partner in this proposal has developed a novel research prototype and has shown that the new imaging tool can enhance surgical vision beyond human visibility for preclinical testing. The small business partner backed by a Venture company from the Bay area has a strong background for successful commercialization. Together, we aim to convert the academic research prototype into a clinically viable market product that will significantly improve the safety, function, and outcome of surgery, not limited by surgeons’ visual perception, training or experience. The ISVision technology will make the surgery safer and more effective.","Insightful Surgical Vision Technology (ISVision) for intelligent real-time display of anatomic, physiologic, and pathologic information in surgery",9781563,R41EB026402,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anastomosis - action', 'Anatomy', 'Area', 'Awareness', 'Back', 'Blood flow', 'Businesses', 'Characteristics', 'Child', 'Clinical', 'Clinical Engineering', 'Cognitive', 'Color', 'Complex', 'Complication', 'Conventional Surgery', 'Coupled', 'Depth Perception', 'Development', 'Engineering', 'Environment', 'Excision', 'Eye', 'Family suidae', 'Fostering', 'Future', 'Goals', 'Health system', 'Hemorrhage', 'Hepatic artery', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Imaging technology', 'Incubators', 'Individual', 'Injury', 'Intestines', 'Investments', 'Laparoscopes', 'Laparoscopy', 'Liver', 'Machine Learning', 'Measures', 'Modeling', 'Nature', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pathologic', 'Pathway interactions', 'Pediatric Research', 'Performance', 'Perfusion', 'Peripheral', 'Phase', 'Physiological', 'Physiology', 'Play', 'Positioning Attribute', 'Pre-Clinical Model', 'Preclinical Testing', 'Process', 'Research', 'Robot', 'Robotics', 'Role', 'Safety', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Site', 'Small Business Technology Transfer Research', 'Structure', 'Surface', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Vision', 'Visual Perception', 'Work', 'base', 'bile duct', 'clinical translation', 'commercialization', 'data acquisition', 'design', 'digital', 'digital imaging', 'experience', 'fluorescence imaging', 'graphical user interface', 'image guided', 'image processing', 'imager', 'imaging system', 'improved', 'interest', 'meetings', 'millisecond', 'minimally invasive', 'next generation', 'novel', 'optical imaging', 'performance tests', 'pre-clinical', 'prototype', 'research and development', 'robot assistance', 'sensor', 'soft tissue', 'surgery outcome', 'tool']",NIBIB,"ACTIV SURGICAL, INC",R41,2018,42000,-0.003914286679059366
"A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions Abstract. Melanoma is the third most common form of skin cancer with estimated 87,110 new cases diagnosed in the United States in the year 2017. Current routine diagnostic approaches utilize microscopic evaluation of thinly sectioned patient biopsies, but in certain cases diagnosis can be contentious even among experts. The overall goal of this multi-phase SBIR project is to develop, validate, and commercialize MelanoMapTM, Frontier Diagnostics' patented assay for the diagnosis of melanoma using a matrix-assisted laser desorption/ionization imaging mass spectrometry (MALDI IMS) platform—and to have this assay available to pathologists in the U.S. as a laboratory developed test. MALDI IMS is a state-of-the-art technology that generates molecular images of tens to thousands of biomolecules from tissue sections in a single analysis. The assay uses formalin-fixed paraffin embedded (FFPE) biopsies used in routine histopathological diagnosis. The proposed assay has pathologists select regions of skin biopsies for analysis via a remote web interface. The acquired IMS data from those regions unambiguously identifies malignant melanoma or benign nevus.  Phase I of this proposal will demonstrate the feasibility of this technology platform to achieve cost-effective diagnosis of melanoma from patient skin biopsies at sample volumes acceptable for a clinical laboratory. Specific Aim 1 focuses on the development of a scalable and robust analytical protocol in both sample preparation and informatics to accurately diagnose melanoma with MALDI IMS. In specific aim 2, we will test the methodology developed in Specific Aim 1 on a cohort of melanocytic lesions with known clinical outcome and subsequently validate the classification accuracy of the proposed test  In Phase II, the protocols developed in Phase I will be integrated into a diagnostic service workflow. This phase will focus on quality control measures, client facing cloud software, clinical diagnostic reporting, and completing the analysis of a 500-patient sample set for final assay validation. Specific Aim 3 of this proposal (initial aim of Phase II) will establish and implement test tissues into standard workflows that will provide performance metrics for standard operation of a test meeting Clinical Laboratory Improvement Amendments (CLIA) standards. Protocols will be developed to monitor reagents, the reproducibility of sample preparation, and mass spectrometer performance on daily basis. Specific Aim 4 will expand software capabilities to include a secure web interface for clients ordering the test and the laboratory performing the test. The software will meet regulatory compliance, perform statistical analysis, and generate and communicate reports of the MALDI IMS analysis. Specific Aim 5 proposes to expand the sample set used in the initial assay from Specific Aim 2 to include a set of 300 patient samples from our clinical collaborators with 5 or more years follow-up data. The test will be independently validated by an additional 200 patient samples with definitive diagnoses. Project Narrative This multi-phase Fast Track SBIR project will develop and validate a new laboratory developed test to differentiate malignant melanocytic tumors from benign nevi and complete development of an imaging mass spectrometry-based diagnostic service platform for a clinical laboratory. The clinical assay developed under this proposal augments current practice by providing molecular measurements that are used as objective criteria in the diagnosis of melanoma. Successful completion of this Fast Track project will result in a fully documented and validated assay ready for launch as a laboratory developed test.",A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions,9557356,R44CA228897,"['Algorithms', 'Amendment', 'Antigens', 'Area', 'Benign', 'Biological Assay', 'Biopsy', 'Caliber', 'Cells', 'Cessation of life', 'Classification', 'Client', 'Clinical', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Services', 'Digestion', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Formalin', 'Goals', 'Gold', 'Image', 'Incentives', 'Informatics', 'Laboratories', 'Legal patent', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Melanocytic Neoplasm', 'Metadata', 'Methodology', 'Microscopic', 'Microtomy', 'Molecular', 'Monitor', 'Nevus', 'Outcome', 'Paraffin Embedding', 'Pathologist', 'Pathology Report', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Physical shape', 'Physicians', 'Preparation', 'Procedures', 'Proteins', 'Protocols documentation', 'Quality Control', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Retrieval', 'Risk', 'Sampling', 'Secure', 'Security', 'Sensitivity and Specificity', 'Side', 'Skin', 'Skin Cancer', 'Small Business Innovation Research Grant', 'Software Tools', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Standardization', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Treatment Cost', 'United States', 'Validation', 'accurate diagnosis', 'analytical method', 'base', 'clinical diagnostics', 'cloud software', 'cohort', 'cost', 'cost effective', 'data acquisition', 'diagnosis standard', 'diagnostic assay', 'disease classification', 'follow-up', 'frontier', 'histopathological examination', 'instrumentation', 'interest', 'mass spectrometer', 'meetings', 'melanoma', 'molecular diagnostics', 'molecular imaging', 'operation', 'prototype', 'quality assurance', 'skin lesion', 'tissue preparation', 'web interface']",NCI,"FRONTIER DIAGNOSTICS, LLC",R44,2018,299244,-0.00958595613243381
"Insightful Surgical Vision Technology (ISVision) for intelligent real-time display of anatomic, physiologic, and pathologic information in surgery Abstract Intelligent intraoperative display of anatomic and physiologic information coupled to real time situational awareness to critical tissues will benefit all surgery. The current surgical vision is limited to naked human eyes in open surgery or more recently using laparoscopic digital imaging for minimally invasive surgery and robot assisted surgery. In laparoscopic vision, although the visualization of surface anatomy and tissue physiology in the surgical field-of-view has been enhanced by recent advances in optical imaging technology, the imaging paradigm still remains passive and still poses a significant challenge due to the inherent narrow peripheral vision and limited depth perception. We propose the next generation laparoscopic vision system that provides intelligent display of unrecognized tissue structures to human eyes. Our proposed use of a new paradigm and surgical vision technology (called ISVisionTM), equipped with modular plenoptic 3-D Color/HD camera and snapshot NIR hyperspectral imager, will permit a clear visualization of the critical target tissue-of-interest, surrounding anatomy into the operative field, and situational awareness for both the tool and tissue to the surgeon. Our Phase I effort comprises of engineering the clinically viable ISVision platform and testing the performance of its intraoperative use. Specifically, the ISVision system will clearly and precisely identify different tissue characteristics, accurately displaying physiologic information including tissue perfusion and blood flow. Following the Phase 1, we anticipate undertaking a Phase II project, during which we will develop a clinical grade ISVision system and investigate its performance and utility in the operating room. While the initial focus of the Phase I and II effort is on the complex surgery such as liver resection due to crucial nature of critical sub-surface structures located underneath liver hilum and parenchyma, the ISVision system will potentially play an enabling role in all surgeries and establish it as a vital component of the operating room of the future. Narrative Real-time display of the accurate anatomic and tissue physiology during surgery is necessary and crucial in improving surgical outcomes. This proposal aims to develop the next generation surgical vision system that provides intelligent display of unrecognized, unseen tissue structures to human eyes. The current state of the art technology still remains passive, focuses on anatomic display only. A new surgical vision technology, called ISVisionTM, will provide clear display of important anatomic structures, identify not only their distinct shape and position, and offer insightful intelligent function during surgical procedures. The academic partner in this proposal has developed a novel research prototype and has shown that the new imaging tool can enhance surgical vision beyond human visibility for preclinical testing. The small business partner backed by a Venture company from the Bay area has a strong background for successful commercialization. Together, we aim to convert the academic research prototype into a clinically viable market product that will significantly improve the safety, function, and outcome of surgery, not limited by surgeons’ visual perception, training or experience. The ISVision technology will make the surgery safer and more effective.","Insightful Surgical Vision Technology (ISVision) for intelligent real-time display of anatomic, physiologic, and pathologic information in surgery",9622159,R41EB026402,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anastomosis - action', 'Anatomy', 'Area', 'Awareness', 'Back', 'Blood flow', 'Businesses', 'Characteristics', 'Child', 'Clinical', 'Clinical Engineering', 'Cognitive', 'Color', 'Complex', 'Complication', 'Conventional Surgery', 'Coupled', 'Depth Perception', 'Development', 'Engineering', 'Environment', 'Excision', 'Eye', 'Family suidae', 'Fostering', 'Future', 'Goals', 'Health system', 'Hemorrhage', 'Hepatic artery', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Imaging technology', 'Incubators', 'Individual', 'Injury', 'Intestines', 'Investments', 'Laparoscopes', 'Laparoscopy', 'Liver', 'Machine Learning', 'Measures', 'Modeling', 'Nature', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pathologic', 'Pathway interactions', 'Pediatric Research', 'Performance', 'Perfusion', 'Peripheral', 'Phase', 'Physiological', 'Physiology', 'Play', 'Positioning Attribute', 'Pre-Clinical Model', 'Preclinical Testing', 'Process', 'Research', 'Robot', 'Robotics', 'Role', 'Safety', 'Seeds', 'Sensitivity and Specificity', 'Shapes', 'Site', 'Small Business Technology Transfer Research', 'Structure', 'Surface', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Validation', 'Vision', 'Visual Perception', 'Work', 'base', 'bile duct', 'clinical translation', 'commercialization', 'data acquisition', 'design', 'digital', 'digital imaging', 'experience', 'fluorescence imaging', 'graphical user interface', 'image guided', 'image processing', 'imager', 'imaging system', 'improved', 'interest', 'meetings', 'millisecond', 'minimally invasive', 'next generation', 'novel', 'optical imaging', 'performance tests', 'pre-clinical', 'prototype', 'research and development', 'robot assistance', 'sensor', 'soft tissue', 'surgery outcome', 'tool']",NIBIB,"ACTIV SURGICAL, INC",R41,2018,200769,-0.003914286679059366
"Immune Basis & Clinical implications of Threshold-Based Phenotypes of Peanut Allergy Summary: Immune Basis and Clinical Implications of Threshold-Based Phenotypes of Peanut Allergy Peanut allergy (PA) is common, affecting 2-5% of school-age children in the US. The characteristics of PA vary widely among individuals, with some reacting to 1/100th of a peanut and others not having symptoms until they have ingested many peanuts. Symptoms can vary from mild rashes to fatal anaphylaxis. There is no FDA- approved treatment, and all patients with PA are managed with strict allergen avoidance. Most research on PA has focused on those with the most exquisite sensitivity to peanut. Immunotherapy trials commonly exclude subjects with a threshold dose over 1/3 of a peanut (100mg). However, most individuals with PA have higher thresholds of reaction and are excluded from current research approaches. We hypothesize that the natural heterogeneity of PA is a valuable opportunity for investigation. We have shown that milk or egg allergic individuals with tolerance to baked forms of these foods not only tolerate their inclusion in the diet, but this exposure increases the rate of resolution 14-16-fold. We hypothesize that dietary exposure to sub-threshold levels of peanut in those with higher threshold levels of reactivity could lead to significant clinical improvement. Furthermore, studying the natural heterogeneity of PA is a valuable opportunity to elucidate mechanisms of disease. To study the clinical implications and mechanism of phenotypic heterogeneity in PA, we will conduct a randomized open feeding trial (CAFETERIA trial) to investigate a prototype approach where children with moderate PA (tolerating at least 100 mg of peanut) ingest a sub-threshold amount daily, with increasing levels tested every 3 months. The impact of dietary intervention will be tested at 1 and 2 years by oral food challenge. The CAFETERIA study will provide a rich biorepository of samples from highly phenotyped subjects. We anticipate screening 200-250 subjects, including low threshold, high threshold, and sensitized but not allergic, in order to enroll 98 subjects that meet the high threshold criteria for the CAFETERIA trial. We will obtain longitudinal samples from subjects randomized to dietary therapy or avoidance. We will comprehensively profile antibody responses by high-throughput epitope assay, peanut-specific T cell responses by flow cytometry, and whole blood activation by CyTOF to construct a detailed clinical-immune network of PA, and analyze the relationship between immune and clinical parameters. We will identify biomarkers and key causal drivers of PA by performing integrated network-based examination of peripheral blood transcriptomes from PA subjects, sampled before and after food challenge, and before and after dietary therapy. Successful completion of these aims will result in (1) a simple low-cost treatment option applicable to the majority of those with PA; (2) an identification of immune and molecular mechanisms of PA and response to dietary therapy; (3) peripheral blood biomarkers that will practically impact clinical care of PA; (4) the potential for personalized approaches to the treatment of PA; and (5) a tremendously rich resource of clinical, immune, and transcriptional data and analytic tools to be made publicly available to the research community. NARRATIVE This AADCR Center will investigate threshold-based phenotypic heterogeneity of peanut allergy. We will focus on an under-studied high-threshold phenotype of peanut allergy, and examine the impact of dietary therapy with sub-threshold amounts of peanut. We will use this clinically diverse cohort to perform high dimensional profiling in order to elucidate immune and molecular mechanisms of allergy and tolerance to peanut.",Immune Basis & Clinical implications of Threshold-Based Phenotypes of Peanut Allergy,9464147,U19AI136053,"['Affect', 'Allergens', 'Allergic', 'Allergy to eggs', 'Allergy to peanuts', 'Anaphylaxis', 'Antibodies', 'Antibody Response', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Biology', 'Characteristics', 'Child', 'Clinical', 'Clinical Data', 'Communities', 'Computational Biology', 'Data', 'Data Analytics', 'Diet', 'Dietary Intervention', 'Disease', 'Dose', 'Economic Burden', 'Enrollment', 'Epitopes', 'Exanthema', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Food', 'Food Hypersensitivity', 'Funding', 'Genetic Transcription', 'Genomics', 'Goals', 'Heterogeneity', 'Hypersensitivity', 'IgE', 'Immune', 'Immunologics', 'Immunology', 'Individual', 'Ingestion', 'Investigation', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Medical', 'Milk', 'Milk Hypersensitivity', 'Molecular', 'Network-based', 'Nutritional', 'Oral', 'Patients', 'Persons', 'Phase III Clinical Trials', 'Phenotype', 'Predictive Value', 'Proteins', 'Protocols documentation', 'Quality of life', 'Randomized', 'Reaction', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Schedule', 'School-Age Population', 'Severities', 'Speed', 'Symptoms', 'T cell response', 'T-Lymphocyte', 'Testing', 'Treatment Cost', 'Urticaria', 'Visit', 'Whole Blood', 'allergic response', 'analytical tool', 'base', 'biobank', 'biomarker identification', 'clinical care', 'clinical practice', 'cohort', 'cost', 'desensitization', 'egg', 'feeding', 'food allergen', 'food challenge', 'high dimensionality', 'immunotherapy trials', 'individualized medicine', 'intervention cost', 'learning network', 'neglect', 'oral diagnostics', 'oral immunotherapy', 'outcome prediction', 'peripheral blood', 'personalized approach', 'prototype', 'response', 'screening', 'transcriptome']",NIAID,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U19,2018,1524997,-0.0043109000220648026
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9483579,R00AG046911,"['Address', 'Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Drug Screening', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'imaging modality', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'public health relevance', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2018,249000,-0.014493705446170704
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9465735,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Simulation', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'forest', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2018,178854,-0.020162373117959223
"Development and feasibility of prevention-minded oral health mobile App based on dietary selections and oral hygiene events. The number of decayed and filled tooth surfaces in primary dentition is on the rise in US children between the ages of 2 and 11 years old; in fact, 60% of adolescents (between 12 and 19 years old) and 9 out of 10 dentate seniors (age 65+) bear evidence of dental caries. Reinforced with a 2011-12 report stating 91% of those between the ages of 20 and 64 have dental caries, virtually all walks of life are thus affected – and this doesn’t even include those unreported, or those with significant dental erosion or gingival recession. Thus, these statistics could imply there is a significant unmet need in creating improved mechanisms for healthier dietary and hygienic habits. One way to achieve healthier habits and behavior is through effective communication. However, disconnects exist between oral health messaging and the patient’s understanding of clinical recommendations: in fact, oral health organizations recognize the need to improve and empower the public’s oral health literacy. Although adherence to preventive plans are critical to thwarting tooth decay, a patient’s poor oral health understanding and knowledge, even after a dental visit, persistently introduce factors that diminish preventive efforts and favorable oral health outcomes: for example, a clinical report revealed the average patient only recounts about half of the recommended dental advice. Oral health literacy is a relatively new area of research and there are few innovations in this space. Therefore, opportunities that address oral health illiteracy and behavioral barriers utilizing today’s 21st century technology may promote better oral health outcomes. Such approaches are already well-under way for systemic health, but thus far, prevention-minded oral health measures are lacking. We believe a unique approach exists that utilizes something most people, both young and old, access on a daily basis: a mobile device. Our approach is underlined by recent statistics released by the Pew Center: more than 8 out of 10 U.S. adults access mobile devices for information, including more than 67% of seniors (65+ years of age). Utilizing our proven strengths and successes in preventive dentistry innovations and mobile application (App) development, in this Phase I proposal we will determine feasibility of creating a prototype oral health App that scores dietary and oral hygiene events utilizing algorithms devised from libraries of empirical nutritional and scientific data (laboratory and clinical). In doing so, this Phase I proposal has three Specific Aims: empirical nutritional and scientific data mining; multi-tiered decision tree algorithm construction with putative scoring index based on Aim #1 data; and, development of a prototype mobile App based on Aims #1 and #2. If successful and with clinical testing expected in a Phase II proposal, the long-term goal of this research is to deploy and commercialize an oral health App that promotes clinically effective oral health behavior. The constant feed from mined data libraries and social-engineering aspects are expected to drive routine use of the App, thus engaging the user towards favorable habits and healthier outcomes. Reinforced with a 2011-12 report stating 91% of those between the ages of 20 and 64 have dental caries, virtually all walks of life are thus affected – and this doesn’t even include those unreported, or those with significant dental erosion or gingival recession. Although adherence to preventive plans are critical to thwarting tooth decay, a patient’s poor oral health understanding and knowledge, even after a dental visit, persistently introduce factors that diminish preventive efforts and favorable oral health outcomes: for example, a clinical report revealed the average patient only recounts about half of the recommended dental advice. Utilizing our strengths and successes in preventive dentistry innovations and mobile application (App) development, the long-term goal of this research is to deploy and commercialize an oral health App that promotes clinically effective oral health behavior, whereby the constant feed from mined data libraries and social-engineering aspects are expected to drive routine use of the App, thus engaging the user towards favorable habits and healthier outcomes.",Development and feasibility of prevention-minded oral health mobile App based on dietary selections and oral hygiene events.,9620406,R43DE028235,"['11 year old', '19 year old', 'Address', 'Adherence', 'Adolescent', 'Adult', 'Affect', 'Age', 'Age-Years', 'Algorithm Design', 'Algorithms', 'Area', 'Behavior', 'Behavioral', 'Cellular Phone', 'Characteristics', 'Child', 'Clinical', 'Communication', 'Data', 'Decision Trees', 'Dental', 'Dental Hygiene', 'Dental caries', 'Dentistry', 'Dentists', 'Dentition', 'Development', 'Diet', 'Engineering', 'Event', 'Feedback', 'Food', 'Gingival Recession', 'Goals', 'Habits', 'Health', 'Health behavior', 'Heart', 'Hygiene', 'Knowledge', 'Laboratories', 'Libraries', 'Life', 'Maps', 'Measures', 'Mind', 'Mobile Health Application', 'National Health and Nutrition Examination Survey', 'Nutritional', 'Oral', 'Oral health', 'Outcome', 'Patients', 'Phase', 'Positioning Attribute', 'Prevention', 'Preventive', 'Preventive Dentistry', 'Primary Dentition', 'Recommendation', 'Reporting', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Sorting - Cell Movement', 'Starch', 'Sugar Acids', 'Technology', 'Text', 'Therapeutic', 'Ursidae Family', 'Visit', 'Walking', 'base', 'clinical research site', 'data mining', 'feeding', 'handheld mobile device', 'health application', 'health literacy', 'health organization', 'illiteracy', 'improved', 'indexing', 'innovation', 'minimally invasive', 'mobile application', 'prototype', 'research clinical testing', 'smartphone Application', 'social', 'speech recognition', 'statistics', 'success', 'tooth surface', 'virtual']",NIDCR,"INDIANA NANOTECH, LLC",R43,2018,146837,-0.013001012501170457
"Individualized Signal Processing Strategy :Phase II This project describes a novel approach to automate and individualize the signal processing strategy for hearing aids (HA) that can result in improved speech intelligibility in background noise, greater user satisfaction and acceptance for HAs, and reduce barriers to affordable hearing health care. The proposed Individualized Signal Processing Strategy (ISPS) is based on individual performance on categorical perception tasks for speech stimuli. This differs from traditional methods based on sophisticated gain models built upon average perception, performance, and preference data. The ability to determine one’s ISPS automatically, rapidly and remotely can result in dramatic cost-savings and greater accessibility to hearing health care for patients who cannot afford it or for those who lack easy access to the necessary expertise. These technical achievements have the potential to radically change HA service delivery models yet can be implemented within existing business models and in concert with current practitioners. The ISPS method effectively replaces target-based HA fitting (e.g. NAL-NL2) with individualized speech-based parameter adjustment. The proposed work follows successful completion of our pilot project and builds upon the research team’s prior research on novel fitting methods for cochlear implant (CI) devices recently acquired by Cochlear, Ltd. Following the successful implementation of ISPS and integration with commercial HA software in the pilot study, we demonstrated feasibility including a field study in which performance outcomes for the ISPS method were as good as a conventional HA fitting method and only took a fraction of the time, despite ISPS having no prior knowledge of patient characteristics and no audiogram. Successful maturation and commercialization of the ISPS technology in Phase II will address several barriers identified in the previous RFA-DC-12-004 including physical, infrastructure, and knowledge barriers (by allowing remote or self-fitting HAs), economic barriers (by reducing overall costs), and cultural barriers (by providing easy access to HA fitting for patients who tend to avoid professional help). This Phase II project will develop an operational ISPS method by (1) integrating ISPS with hardware/software systems of our industry partners, (2) refine and enhance the ISPS method to improve efficiency and effectiveness of fitting hearing instruments, (3) build support for the use of ISPS in multiple marketplaces, and (4) evaluate the technology through field trials in different service delivery environments by comparing outcomes with ISPS fitting to those achieved with traditional prescriptive gain fitting within the same subjects. Following successful demonstration of these objectives, a Phase III project will focus on the transition of the technology to support remote and self-fitting of hearing instruments. This project seeks to develop, implement and test a novel automated method for fitting hearing aids based on real-time speech perception performance. This automated approach can improve hearing aid success while significant reducing costs of hearing health care. The automation of the fitting procedure can dramatically increase accessibility of hearing health care.",Individualized Signal Processing Strategy :Phase II,9472306,R44DC016249,"['Achievement', 'Address', 'Algorithms', 'Artificial Intelligence', 'Audiology', 'Audiometry', 'Auditory', 'Automation', 'Businesses', 'Categories', 'Characteristics', 'Cochlear Implants', 'Collaborations', 'Computer software', 'Cost Savings', 'Crossover Design', 'Data', 'Development', 'Devices', 'Economics', 'Effectiveness', 'Environment', 'Evaluation', 'Frequencies', 'Funding', 'Generic Drugs', 'Goals', 'Healthcare', 'Hearing', 'Hearing Aids', 'Individual', 'Instruction', 'Knowledge', 'Learning', 'Link', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Perception', 'Performance', 'Phase', 'Pilot Projects', 'Procedures', 'Process', 'Randomized', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Sensorineural Hearing Loss', 'Service delivery model', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Stimulus', 'Supervision', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'United States Department of Veterans Affairs', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'commercialization', 'cost', 'data modeling', 'experimental study', 'field study', 'graph theory', 'health care service', 'implantable device', 'improved', 'improved outcome', 'inclusion criteria', 'industry partner', 'instrument', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'preference', 'satisfaction', 'service delivery', 'signal processing', 'software systems', 'sound', 'success']",NIDCD,"SECURBORATION, INC.",R44,2018,732079,-0.05925994503237961
"Psychophysics of Reading - Normal and Low Vision DESCRIPTION (provided by applicant):  Psychophysics of Reading - Normal and Low Vision Abstract Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  Difficulty in accessing print imposes obstacles to education, employment, social interaction and recreation.  The ongoing transition to the production and distribution of digital documents brings about new opportunities for people with visual impairment.  Digital documents on computers and mobile devices permit easy manipulation of print size, contrast polarity, font, page layout and other attributes of text.  In short, we now hae unprecedented opportunities to adapt text format to meet the needs of visually impaired readers.  In recent years, our laboratory and others in the vision-science community have made major strides in understanding the impact of different forms of low vision on reading, and the dependence of reading performance on key text properties such as character size and contrast.  But innovations in reading technology have outstripped our knowledge about low-vision reading.  A major gap still exists in translating these laboratory findings into methods for customizing text displays for people with low vision.  The broad aim of the current proposal is to apply our knowledge about the impact of vision impairment on reading to provide tools and methods for enhancing reading accessibility in the modern world of digital reading technology.  Our research plan has three specific goals:   1) To develop and validate an electronic version of the MNREAD test of reading vision, to extend this technology to important text variables in addition to print size, and to develop methods for customizing the selection of text properties for low-vision readers.  MNREAD is the most widely used test of reading in vision research and was originally developed in our laboratory with NIH support.  2) To investigate the ecology of low-vision reading in order to better understand how modern technologies, such as iPad and Kindle are being used by people with low vision.  We plan to evaluate the feasibility of using internet methods to survey low-vision individuals concerning their reading behavior and goals, and of collecting approximate measures of visual function over the internet.  We also plan to develop an ""accessibility checker"" to help low-vision computer users and their families to evaluate the accessibility of specific text displays.  3) To enhance reading accessibility by developing methods for enlarging the visual span (the number of adjacent letters that can be recognized without moving the eyes).  A reduced visual span is thought to be a major factor limiting reading in low vision, especially for people with central-field loss from macular degeneration.  We have already demonstrated methods for enlarging the visual span in peripheral vision.  We plan to develop a more effective perceptual training method for enlarging the visual span, with the goal of improving reading performance for people with central-vision loss. PUBLIC HEALTH RELEVANCE:  Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  The ongoing transition to the use of digital documents on computers and mobile devices brings about new opportunities for customizing text for people with visual impairment.  We propose to apply findings from basic vision science on low vision and reading to develop tools and methods for enhancing reading accessibility for digital text.",Psychophysics of Reading - Normal and Low Vision,9474120,R01EY002934,"['American', 'Attention', 'Auditory', 'Behavior', 'Blindness', 'Books', 'Caring', 'Central Scotomas', 'Characteristics', 'Clinical Research', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Custom', 'Dependence', 'Development', 'Devices', 'Ecology', 'Education', 'Employment', 'Eye', 'Family', 'Galaxy', 'Goals', 'Government', 'Guidelines', 'Habits', 'Health', 'Individual', 'Internet', 'Knowledge', 'Laboratories', 'Laboratory Finding', 'Leg', 'Length', 'Letters', 'Life', 'Macular degeneration', 'Mainstreaming', 'Maps', 'Marshal', 'Measures', 'Methods', 'Modernization', 'Optics', 'Paper', 'Participant', 'Patients', 'Perceptual learning', 'Performance', 'Peripheral', 'Play', 'Policies', 'Printing', 'Production', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysics', 'Reader', 'Reading', 'Recreation', 'Reporting', 'Research', 'Resources', 'Role', 'Self-Help Devices', 'Social Interaction', 'Surveys', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Work', 'analog', 'base', 'design', 'digital', 'essays', 'handheld mobile device', 'improved', 'innovation', 'invention', 'large print', 'literate', 'public health relevance', 'reading difficulties', 'sound', 'symposium', 'tool', 'vision science', 'web-accessible']",NEI,UNIVERSITY OF MINNESOTA,R01,2018,364257,-0.00827571877025064
"Designing Visually Accessible Spaces DESCRIPTION (provided by applicant):  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions.  We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area).  This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement.  Our project addresses one of the National Eye Institute's program objectives:  ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals:  1) Empirical:  determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces.  2) Computational:  develop working models to predict low vision visibility and navigability in real-world spaces.  3) Deployment:  translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility.  The key scientific personnel in our partnership come from three institutions:  University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare.  This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare).  We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.",Designing Visually Accessible Spaces,9440421,R01EY017835,"['Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Fall injury', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Height', 'Human', 'Human Resources', 'Indiana', 'Individual', 'Industrialization', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Physically Handicapped', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'hazard', 'imaging system', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'public health relevance', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2018,585564,0.002364028872518691
"Deep Fractions Learning: A Core Curriculum of Games, Inquiry, and Collaboration Project​ ​Summary/Abstract  There​ ​is​ ​an​ ​enormous​ ​deficit​ ​in​ ​students’​ ​understanding​ ​of​ ​fractions​ ​in​ ​the​ ​United​ ​States. Fifth​ ​grade​ ​fraction​ ​knowledge​ ​predicts​ ​high​ ​school​ ​math​ ​performance,​ ​even​ ​when​ ​controlling for​ ​working​ ​memory,​ ​whole​ ​number​ ​knowledge,​ ​IQ,​ ​reading​ ​ability,​ ​and​ ​demographic​ ​factors (Siegler​ ​et​ ​al.,​ ​2012).​ ​Therefore,​ ​addressing​ ​this​ ​deficit​ ​is​ ​a​ ​particularly​ ​important​ ​area​ ​for​ ​early intervention.​ ​With​ ​this​ ​Fast-Track​ ​grant,​ ​​Deep​ ​Fractions​ ​Learning​,​ ​we​ ​propose​ ​to​ ​transform​ ​the way​ ​in​ ​which​ ​students​ ​learn​ ​core​ ​math​ ​curriculum​ ​so​ ​that​ ​materials​ ​are​ ​more​ ​interactive​ ​and engaging,​ ​promote​ ​deeper​ ​learning​ ​of​ ​content,​ ​and​ ​are​ ​aligned​ ​with​ ​the​ ​Common​ ​Core.​ ​More specifically,​ ​we​ ​will​ ​develop​ ​and​ ​evaluate​ ​a​ ​digital​ ​curriculum​ ​for​ ​grades​ ​3-5​ ​covering​ ​the fractions​ ​domain​ ​that​ ​combines​ ​games,​ ​collaboration,​ ​and​ ​an​ ​inquiry​ ​approach.​ ​We​ ​propose​ ​to develop​ ​an​ ​innovative​ ​technology​ ​infrastructure​ ​that​ ​will​ ​integrate​ ​Teachley​ ​learning​ ​games, Success​ ​for​ ​All’s​ ​(SFA)​ ​cooperative​ ​learning​ ​framework,​ ​and​ ​rigorous​ ​lesson​ ​content.​ ​We​ ​will integrate​ ​research​ ​into​ ​the​ ​design​ ​process​ ​and​ ​work​ ​with​ ​Johns​ ​Hopkins​ ​University​ ​to​ ​evaluate the​ ​efficacy​ ​of​ ​the​ ​intervention.  Outcomes.​ ​​The​ ​intervention​ ​will​ ​encourage​ ​four​ ​direct​ ​outcomes​ ​for​ ​students,​ ​namely improved:​ ​1)​ ​conceptual​ ​understanding​ ​of​ ​fractions,​ ​2)​ ​procedural​ ​fluency​ ​with​ ​fractions operations,​ ​3)​ ​mathematical​ ​justification,​ ​and​ ​4)​ ​motivation.​ ​First,​ ​the​ ​curriculum​ ​will​ ​build​ ​both conceptual​ ​understanding​ ​and​ ​procedural​ ​fluency,​ ​providing​ ​strong​ ​visual​ ​models​ ​within engaging​ ​games​ ​that​ ​motivate​ ​students​ ​to​ ​practice.​ ​The​ ​collaborative​ ​learning​ ​model​ ​and​ ​inquiry approach​​ ​​will​ ​improve​ ​students’​ ​mathematical​ ​justification.​ ​Finally,​ ​we​ ​encourage​ ​these outcomes​ ​within​ ​a​ ​motivational​ ​support​ ​structure​ ​designed​ ​to​ ​foster​ ​engagement​ ​and self-efficacy.  Improving​ ​students’​ ​academic​ ​outcomes​ ​and​ ​self-efficacy​ ​in​ ​the​ ​area​ ​of​ ​fractions​ ​during elementary​ ​school​ ​will​ ​promote​ ​later​ ​success​ ​in​ ​high​ ​school​ ​mathematics.​ ​Since​ ​each​ ​additional math​ ​class​ ​students​ ​complete​ ​in​ ​high​ ​school​ ​more​ ​than​ ​doubles​ ​the​ ​odds​ ​of​ ​college​ ​completion (Adelman,​ ​2006),​ ​the​ ​intervention​ ​has​ ​the​ ​potential​ ​to​ ​make​ ​a​ ​real​ ​difference​ ​in​ ​whether students​ ​achieve​ ​sustainable​ ​careers​ ​versus​ ​being​ ​stuck​ ​in​ ​low-wage​ ​jobs. Project​ ​Narrative  Fractions​ ​knowledge​ ​in​ ​the​ ​fifth​ ​grade​ ​strongly​ ​predicts​ ​high​ ​school​ ​math​ ​performance, even​ ​when​ ​controlling​ ​for​ ​working​ ​memory,​ ​whole​ ​number​ ​knowledge,​ ​IQ,​ ​reading​ ​ability,​ ​and demographic​ ​factors​ ​(Siegler​ ​et​ ​al.,​ ​2012).​ ​Intervention​ ​in​ ​this​ ​essential​ ​content​ ​area​ ​will improve​ ​students’​ ​math​ ​ability​ ​in​ ​the​ ​short​ ​and​ ​long​ ​term,​ ​which​ ​in​ ​turn​ ​will​ ​lead​ ​to​ ​several positive​ ​distal​ ​outcomes,​ ​such​ ​as​ ​greater​ ​high​ ​school​ ​graduation​ ​rates​ ​and​ ​college​ ​attendance.","Deep Fractions Learning: A Core Curriculum of Games, Inquiry, and Collaboration",9617983,R44GM130162,"['Active Learning', 'Address', 'Area', 'Behavior', 'Child', 'Childhood Cancer Survivor Study', 'Collaborations', 'Common Core', 'Control Groups', 'Demographic Factors', 'Distal', 'Early Intervention', 'Educational Curriculum', 'Ethnic Origin', 'Fostering', 'Goals', 'Graduation Rates', 'Grant', 'High School Student', 'Instruction', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Maps', 'Mathematics', 'Mathematics Curriculum', 'Measures', 'Modeling', 'Motivation', 'Occupations', 'Online Systems', 'Outcome', 'Performance', 'Phase', 'Privatization', 'Process', 'Research', 'Research Infrastructure', 'Sampling', 'Self Efficacy', 'Services', 'Short-Term Memory', 'Structure', 'Students', 'Treatment Efficacy', 'United States', 'Universities', 'Visual', 'Wages', 'Work', 'boys', 'career', 'college', 'dashboard', 'deep learning', 'design', 'digital', 'elementary school', 'fifth grade', 'fourth grade', 'girls', 'high school', 'improved', 'innovation', 'innovative technologies', 'mathematical ability', 'operation', 'prototype', 'reading ability', 'success', 'teacher', 'third grade', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2018,149650,-0.010148704070405941
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),9281577,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,THE MIND RESEARCH NETWORK,P30,2018,1320387,-0.019932685566686148
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9403171,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Learning', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2017,548068,-0.01865859727934722
"Artificial neural networks for high performance, fully automated particle tracking analysis even at low signal-to-noise regimes Abstract: Particle tracking (PT) is a powerful biophysical tool for elucidating molecular interactions, transport phenomena and rheological properties in complex biological environments. Unfortunately, PT remains a niche tool in life and physical sciences with a limited user base, in large part due to significant time and technical constraints in extracting accurate time-variant positional data from recorded movies. These constraints are exacerbated in experiments with low signal-to-noise ratios or substantial heterogeneity, as frequently encountered with nanoparticles and pathogens in biological fluids. Currently available software that attempts to automate the movie analysis process rely almost exclusively on assigning static image filters based on specific intensity, pixel size and signal-to-noise ratio thresholds. Unfortunately, when applied to actual experimental data with substantial spatial and temporal heterogeneity, the current software generally produces substantial numbers of false positives (i.e. tracking artifacts) or false negatives (i.e. missing actual traces), and frequently both. Frequent user intervention is thus required to ensure accurate tracking even when using sophisticated tracking software, markedly reducing experimental throughput and resulting in substantial user- to-user variations in analyzed data. The time required for accurate particle tracking analysis makes PT experiments exceedingly expensive compared to other commonly used experimental techniques in life sciences. These same tracking analysis limitations have effectively precluded investigators from undertaking more sophisticated 3D PT, even though the microscopy capability to obtain such movies is readily available and critical scientific insights can be gained from 3D PT. To circumvent the challenges with currently available particle tracking software, we have developed a new approach for particle identification and tracking, based on machine learning and convolutional neural networks (CNN). CNN is a type of feed-forward artificial neural network designed to process information in a layered network of connections that mimics the organization of real neural networks in the mammalian retina and visual cortex. Unlike most CNN imaging models that are trained to make predictions on static images, we have trained our CNN to input adjacent frames so that each prediction includes information from the past and future, thus effectively performing convolutions in both space and time to infer particle locations. Similar principles of image analysis are now being harnessed by developers of autonomous vehicle technologies to distinguish the motions of different objects on the road. We have applied our CNN tracking algorithm to a wide range of 2D movies capturing dynamic motions of nanoparticles, viruses and highly motile bacteria, achieving at least 30-fold time savings with virtually no need for human intervention while maintaining robust tracking performance (i.e. low false positive and low false negative rates). In this STTR proposal, we seek to focus on further optimization and testing of our neural network tracking platform for 2D PT, including the use of cloud computing (Aim 1), and extending our neural network tracker to enable accurate 3D PT (Aim 2). Our vision is to popularize PT as a research tool among researchers by minimizing the time and labor costs associated with PT analysis. Narrative Particle tracking is a powerful biophysical tool in life and physical sciences, but unfortunately its application has been strongly limited by inefficiencies in accurately extracting particle traces from raw movies. Unlike conventional particle tracking methods, we have combined artificial intelligence and machine learning to create a computational neural network that can recognize objects in much the same way as the human eye, and which consistently provided superior and truly automated tracking performance compared to current alternatives. This STTR will establish the feasibility of using our computational neural network for robust 2D and 3D particle tracking analysis.","Artificial neural networks for high performance, fully automated particle tracking analysis even at low signal-to-noise regimes",9347679,R41GM123897,"['Adopted', 'Advanced Development', 'Algorithms', 'Artificial Intelligence', 'Automobile Driving', 'Bacteria', 'Binding', 'Biological', 'Biological Neural Networks', 'Biological Sciences', 'Classification', 'Cloud Computing', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diffuse', 'Ensure', 'Environment', 'Eye', 'Future', 'Gaussian model', 'Generations', 'Goals', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intervention', 'Knowledge', 'Laboratories', 'Lead', 'Life', 'Link', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Performance', 'Phase', 'Photobleaching', 'Process', 'Property', 'Radial', 'Research', 'Research Personnel', 'Retina', 'Savings', 'Scientist', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Software Tools', 'Spottings', 'Students', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Variant', 'Virus', 'Vision', 'Visual Cortex', 'Work', 'base', 'biophysical tools', 'cell motility', 'cloud based', 'cost', 'design', 'experimental study', 'feeding', 'field study', 'graduate student', 'improved', 'insight', 'interest', 'macromolecule', 'movie', 'nanoparticle', 'novel strategies', 'particle', 'pathogen', 'physical science', 'response', 'spatiotemporal', 'submicron', 'terabyte', 'tool', 'virtual']",NIGMS,"AI TRACKING SOLUTIONS, LLC",R41,2017,224997,-0.01630670067628445
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9373088,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Cereals', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Darkness', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Technology', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'behavioral study', 'cognitive development', 'computerized', 'cost', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2017,243750,-0.02625008030543258
"Deep learning for representation of codes used for SEER-Medicare claims research ﻿    DESCRIPTION (provided by applicant):  We propose developing an algorithm and user-friendly software to better identify treatments using Medicare claims data. We will validate our approach using procedures listed in the Surveillance, Epidemiology, and End Results (SEER) database as a gold standard. In this way, we hope to better match procedures identified using Medicare claims data with SEER listed procedures.  The focus of this research is observational (i.e. non-randomized) data. Well-run randomized clinical trials can provide the best level of evidence of treatment effects. However, randomized trials in the United States have suffered from poor accrual for many interventions. Despite the fact that well-designed randomized clinical trials should be the gold standard, well-designed observational studies might be the only method of obtaining inferences concerning comparative effectiveness for some cancer interventions.  In cancer research, one of the most commonly used databases for observational research is the linked SEER-Medicare database. SEER-Medicare data has provided useful measurements of the effectiveness of a number of cancer therapies. Algorithms for identifying relevant treatment and diagnosis codes using Medicare data are often based on clinical reasoning and scientific evidence. One group of researchers, for example, developed an algorithm for identifying laparoscopic surgery among kidney cancer cases before claims codes for laparoscopic surgery were well developed. While such algorithms are useful for others pursuing similar investigations, there may still be substantial mismatch between treatment identified by the SEER cancer registry and treatment identified through Medicare claims. In this work, we propose developing a rigorous machine learning algorithm that can help researchers in better identifying treatments in Medicare claims data. Specifically, we will design a neural language modeling algorithm and implement a software system that finds vector representations of diagnosis and procedure codes.  We plan on using the neural language modeling algorithm to learn vector representations from SEER- Medicare claims data where related procedure and diagnosis codes are ""neighbors"" (i.e. closely related). We will investigate whether the codes we identify within neighborhoods correspond to the procedure codes used for published SEER-Medicare studies. We will then design a software assistant interface that will allow an investigator to explore which codes are related to a given seed of diagnosis or procedure codes. Finally, we will investigate the sensitivity and specificity of the algorithm by comparing procedures identified using Medicare claims with procedures listed in the SEER database. We will replicate analyses from a published SEER-Medicare paper to investigate if estimated treatment effects differ when using our novel algorithm compared to using the algorithm in the published paper. PUBLIC HEALTH RELEVANCE: In cancer research, one of the most commonly used databases for observational research is the linked Surveillance, Epidemiology, and End Results (SEER)-Medicare database. To improve the identification of procedures when using Medicare claims data, we will design a software assistant interface that will allow an investigator to explore which codes are related to a given seed of diagnosis or procedure codes. This should improve the identification of procedures when using Medicare claims data, and make conclusions drawn from analyses using the database more reliable and consistent.",Deep learning for representation of codes used for SEER-Medicare claims research,9188540,R21CA202130,"['Algorithms', 'Cancer Intervention', 'Clinical', 'Code', 'Computer software', 'Data', 'Databases', 'Diagnosis', 'Effectiveness', 'Ethical Issues', 'Funding', 'Future', 'Gold', 'International Classification of Diseases', 'Intervention', 'Investigation', 'Investigational Therapies', 'Language', 'Laparoscopic Surgical Procedures', 'Learning', 'Level of Evidence', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical', 'Medical Records', 'Medicare', 'Medicare claim', 'Methods', 'Modeling', 'Natural Language Processing', 'Neighborhoods', 'Observational Study', 'Outcome', 'Paper', 'Patients', 'Procedures', 'Process', 'Proxy', 'Publishing', 'Randomized Clinical Trials', 'Records', 'Renal carcinoma', 'Research', 'Research Personnel', 'Running', 'SEER Program', 'Seeds', 'Sensitivity and Specificity', 'Software Tools', 'Statistical Study', 'Terminology', 'Testing', 'Time', 'United States', 'Update', 'Work', 'anticancer research', 'base', 'cancer therapy', 'comparative effectiveness', 'design', 'health disparity', 'improved', 'interest', 'malignant breast neoplasm', 'neoplasm registry', 'novel', 'public health relevance', 'randomized trial', 'relating to nervous system', 'software systems', 'treatment effect', 'usability', 'user friendly software', 'vector', 'volunteer']",NCI,RESEARCH INST OF FOX CHASE CAN CTR,R21,2017,219753,-0.026842784154085416
"A high-throughput imaging and classification system for fruit flies PROJECT SUMMARY / ABSTRACT In this Phase I SBIR application, FlySorter proposes to development a high throughput imaging and classification system to aid research with fruit flies, a widely-used model organism relevant to both basic science as well as studies in human health. The use of animal model systems is essential for research in almost all aspects of biology: genetics, development, neuroscience, disease, physiology, and beyond. The fruit fly – Drosophila melanogaster – is small and easy to care for, but is complex enough an organism to provide a wealth of information that directly relates to human biology and health. Over 75% of human diseases with a genetic basis (including depression, alcoholism, certain forms of cancer, and many more) are either present or have an analog in Drosophila. Modern genetic tools, such as CRISPR/cas9, allow the creation of transgenic flies that provide the opportunity to study diseases, pathways and systems that don’t exist naturally in Drosophila. With these advances, fruit flies are becoming more frequently subjects for drugs screens. For all the advances in the biological tools and techniques applicable to flies, however, the limiting factor in many experiments is the manual labor involved in a few common tasks: moving flies from vial to vial or other lab equipment; classifying and sorting flies by sex, eye color and other phenotypes; and collecting virgin female flies before they mate so that they can be used in controlled crosses, etc. FlySorter’s patent-pending fly dispensing mechanism can reliably deliver a single organism from a vial containing hundreds of awake flies, and our novel FlyPlate system allows storage of individual flies in custom 96 well plates. FlySorter’s robotic fly handling system, co-developed with the de Bivort Lab at Harvard, is capable of manipulating and transporting those individual flies between vial, 96 well plate, and experimental apparatus. The next piece of the automation puzzle to solve is high throughput imaging and classification. To accomplish this goal, FlySorter will: 1) complete a prototype automated image capture hardware system; 2) adapt state-of-the-art computer vision and machine learning algorithms for use on Drosophila; and 3) build a module that can physically sort the classified flies into different vials. Once integrated into the existing FlySorter product ecosystem, this imaging and classification module will greatly expand the kinds of experiments and screens that can be automated, allowing for the study of larger populations or a wider variety of flies, reducing the impact of human error, and freeing up valuable time for researchers. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are one of the most widely used model organisms in biology, for research in genetics, development, neuroscience, disease, and much more. One of the most common tasks in Drosophila labs is sorting flies by various markers and phenotypes using a microscope and paintbrush. FlySorter aims to build an automated system for sorting flies using high resolution digital cameras and modern computer vision algorithms, which will obviate the need for such tedious manual labor.",A high-throughput imaging and classification system for fruit flies,9408980,R43OD023302,"['Air', 'Alcoholism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animal Model', 'Animals', 'Appearance', 'Automation', 'Basic Science', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Neural Networks', 'Biology', 'CRISPR/Cas technology', 'Caring', 'Classification', 'Code', 'Complex', 'Computer Vision Systems', 'Custom', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Pathway', 'Dorsal', 'Drosophila genus', 'Drosophila melanogaster', 'Ecosystem', 'Ensure', 'Eye', 'Eye Color', 'Female', 'Floor', 'Genes', 'Genetic', 'Genetic Screening', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Head', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Legal patent', 'Lighting', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mechanics', 'Mental Depression', 'Methodology', 'Microscope', 'Modernization', 'Motor', 'Mutation', 'Names', 'Neurosciences', 'Obesity', 'Optics', 'Organism', 'Partner in relationship', 'Phase', 'Phenotype', 'Physiology', 'Population', 'Preclinical Drug Evaluation', 'Pump', 'Research', 'Research Personnel', 'Resolution', 'Robot', 'Robotics', 'Sampling', 'Sclera', 'Shapes', 'Small Business Innovation Research Grant', 'Sorting - Cell Movement', 'Standardization', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transgenic Organisms', 'Universities', 'Vial device', 'Walking', 'Work', 'analog', 'awake', 'base', 'depression model', 'digital', 'digital imaging', 'experimental study', 'fly', 'genetic strain', 'human disease', 'improved', 'interest', 'laboratory equipment', 'male', 'meter', 'novel', 'phenotypic biomarker', 'prevent', 'prototype', 'sex', 'tool', 'virtual']",OD,"FLYSORTER, LLC",R43,2017,225000,-0.026479699063583592
"Leveraging Predictive Analytics Within Social Networks to Maximize Drug and Alcohol Treatment Efficacy and Relapse Prevention Sober Grid has built a smartphone-based, recovery-focused social network already in use by 50,297 recovering addicts and 13 addiction treatment facilities to help users achieve better health outcomes and reduce rates of relapse. The goal of this phase I SBIR study is to determine the feasibility of leveraging predictive analytics within the context of an addiction recovery focused social network to enable the system to identify users who are in need of support before they relapse. The specific aim is to assess the feasibility of using predictive modeling to identify those most vulnerable to relapse in order to advance phase II efforts.  Sober Grid will work with a team of addiction researchers including co-investigator Dr. Brenda Curtis, Assistant Professor at the Perlman School of Medicine at the University of Pennsylvania (U Penn), and consultant Dr. Warren Bickel, Director of Addiction Recovery Research Center and Professor of Psychiatry and Behavioral Medicine at the Virginia Tech Carilion School of Medicine (and Sober Grid advisor), to compile a database of known triggers (e.g., life stressors, environment/life changes, etc.), words and phrases, topics and lexica associated with relapse. The team will mine the data in order to identify the factors that correspond with relapse measures (e.g., change in sobriety status, content indicative of relapse, etc.) and employ supervised learning through support vector networks with labeled data as well as unsupervised learning through support vector clustering to identify patterns indicative of relapse within our unlabeled data. The team will build models on a training data set and assess them for prediction accuracy. Understanding the feasibility of mobile-based predictive capabilities and integrating the real-time adaptive interventions proposed shows significant potential for reducing relapse rates in populations regardless of whether they have attended treatment programs. These capabilities will not only increase treatment efficacy, they will also help to reduce overall costs within the healthcare system, including the Veteran’s Administration, and relieve pressure on already overburdened clinicians – a significant commercial opportunity for Sober Grid. Through the proposed project, Sober Grid will work to improve the efficacy and efficiency of its software and smartphone application for supporting peer groups and providers delivering drug and alcohol treatment to more than 22 million Americans who exhibit relapse rates as high as 90%. Applying predictive analytics within the context of Sober Grid’s addiction recovery focused social network will enable it to modify its system to predict relapse before it occurs, which will enable users and providers to realize greater treatment efficacy and health outcomes while significantly reducing costs to the system.",Leveraging Predictive Analytics Within Social Networks to Maximize Drug and Alcohol Treatment Efficacy and Relapse Prevention,9347303,R43DA044062,"['Alcohol dependence', 'American', 'Area Under Curve', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Behavioral Medicine', 'Cellular Phone', 'Climacteric', 'Computer software', 'Continuity of Patient Care', 'Cost Control', 'Cues', 'Data', 'Data Set', 'Databases', 'Drug Addiction', 'Environment', 'Exhibits', 'Feasibility Studies', 'Foundations', 'Goals', 'Health', 'Health Personnel', 'Healthcare Systems', 'Individual', 'Intervention', 'Label', 'Language', 'Learning', 'Life', 'Machine Learning', 'Measures', 'Modeling', 'Modification', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Peer Group', 'Pennsylvania', 'Pharmacotherapy', 'Phase', 'Population', 'Predictive Analytics', 'Provider', 'Psychiatry', 'Recovery', 'Relapse', 'Research', 'Research Personnel', 'Sampling', 'Small Business Innovation Research Grant', 'Social Network', 'Supervision', 'System', 'Time', 'Training', 'Treatment Efficacy', 'United States Department of Veterans Affairs', 'Universities', 'Virginia', 'Work', 'addiction', 'alcohol abuse therapy', 'base', 'cost', 'disorder later incidence prevention', 'improved', 'innovation', 'medical schools', 'mobile application', 'mobile computing', 'peer', 'peer support', 'phrases', 'predictive modeling', 'pressure', 'prevent', 'professor', 'relapse prediction', 'sobriety', 'stressor', 'success', 'tool', 'treatment center', 'treatment program', 'vector']",NIDA,"SOBER GRID, INC.",R43,2017,147889,-0.037335673721031776
"IGF::OT::IGF Constructed Environments for Successfully Sustaining Abstinence Through Immersive and On-Demand Treatment. Period of Performance: September 22, 2017 - March 21, 2018. N43DA-17-5583.   Charles River Analytics and our partners at Massachusetts General Hospital and Virtual Reality Medical Center propose to design and demonstrate Constructed Environments for Successfully Sustaining Abstinence Through Immersive and On-Demand Treatment (CESSATION). We will build VR environments using our in-house game engine and content (cues) that are diverse, realistic, and well-placed, bolstering traditional psychological therapy delivery, and use research-based principles of narrative and game design to produce immersive and engaging content to motivate continued use. We will use probabilistic models (e.g., Bayesian networks) and machine-learning (e.g., neural nets) to learn from patient data and clinician input to assist in selecting and combining therapies in a way that is tailored to the individual patient. Finally, CESSATION will communicate information to clinicians in a manner that is understandable, and gives them enough meta-information to foster appropriate trust in the system. The anticipated results of the proposed Phase I work are: (1) an initial domain analysis; (2) initial VR content; (3) initial motivational content; (4) prototype sensor capabilities; (5) a prototype Intervention Tailoring Component; (6) a prototype Clinician User Interface and Remote Patient Data Server; and (7) an initial Phase I CESSATION prototype demonstration and evaluation. n/a","IGF::OT::IGF Constructed Environments for Successfully Sustaining Abstinence Through Immersive and On-Demand Treatment. Period of Performance: September 22, 2017 - March 21, 2018. N43DA-17-5583.  ",9582496,71201700022C,"['Abstinence', 'Algorithms', 'Contractor', 'Cues', 'Data', 'Effectiveness', 'Elements', 'Ensure', 'Environment', 'Evaluation', 'Exposure to', 'Feedback', 'Fostering', 'Future', 'General Hospitals', 'Health Insurance Portability and Accountability Act', 'Immersion Investigative Technique', 'Intervention', 'Learning', 'Machine Learning', 'Massachusetts', 'Mathematics', 'Measures', 'Medical center', 'Motivation', 'Output', 'Patients', 'Performance', 'Phase', 'Quick Test for Liver Function', 'Recommendation', 'Regulation', 'Reporting', 'Research', 'Rivers', 'Secure', 'Statistical Models', 'Stimulus', 'Summary Reports', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Trust', 'Visit', 'Work', 'base', 'commercialization', 'computer based statistical methods', 'design', 'graphical user interface', 'individual patient', 'lens', 'prototype', 'psychologic', 'relating to nervous system', 'response', 'sensor', 'simulation', 'smoking cessation', 'therapy design', 'virtual reality']",NIDA,"CHARLES RIVER ANALYTICS, INC.",N43,2017,149987,-0.013971310120030264
"Automated Assessment of Cognitive Tests for Detecting Mild Cognitive Impairment SUMMARY Detecting the first and earliest stages of cognitive decline, conceptualized as “mild cognitive impairment” (MCI), has become increasingly important in recent years, as research focuses on delaying the manifestations of more severe stages of decline. It is now well recognized that changes in performance on cognitive tests begin up to ten years (or longer) before clinically apparent symptoms of dementia or functional impairment appear. Conventional assessment methods for assessing cognition Conventional assessment methods typically use the spoken response modality in which subjects are asked to verbally respond to prompts, and examiners carefully listen to these responses and apply test manuals to compute scores. These assessment methods require trained specialists and can be burdensome because they need to performed in clinics, especially so with frequent reassessment. Automating the scoring of assessment is important, not only for alleviating this burden but also for enabling large-scale studies on new intervention methods. Our research goal is to automate detection of MCI by developing, applying, and evaluating a system for automation of verbal (i.e., using spoken responses) cognitive-test scoring. Focusing on four verbal cognitive tests, we develop an extensible system comprising ASR and machine-learning algorithms to automatically score responses, and measure the efficacy of our proposed method by validating the accuracy of the automatically obtained scores against gold-standard, clinically obtained scores (Aim 1). Next, we develop classification methods for detecting individuals with MCI based on all information available in the verbal responses, and validating this classification against gold-standard clinical consensus. NARRATIVE Early detection of mild cognitive disease (MCI) is significantly important to delay more severe stages of cognitive decline. Conventional assessment methods require trained specialists and can be financially beyond the reach of most. We propose a tool for automatically scoring verbal cognitive tests. The proposed tool can be embedded in electronic devices providing the opportunity to assess large number of people in their homes, enabling clinicians to focus on those who are most at risk of cognitive decline.",Automated Assessment of Cognitive Tests for Detecting Mild Cognitive Impairment,9297093,R21AG055749,"['Adverse effects', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Automation', 'Classification', 'Clinic', 'Clinical', 'Cognition', 'Cognition Disorders', 'Complex', 'Consensus', 'Data', 'Dementia', 'Detection', 'Diabetes Mellitus', 'Diagnosis', 'Digit structure', 'Early Diagnosis', 'Electronics', 'Future', 'Genetic Transcription', 'Goals', 'Gold', 'Heart failure', 'Home environment', 'Impaired cognition', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Modality', 'Needs Assessment', 'Nerve Degeneration', 'Output', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Public Domains', 'Research', 'Risk', 'Sleep Disorders', 'Specialist', 'Structure', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Transcript', 'Vascular Cognitive Impairment', 'Work', 'base', 'cognitive testing', 'cooperative study', 'design', 'functional disability', 'healthy aging', 'mild cognitive impairment', 'response', 'speech recognition', 'statistics', 'tool', 'usability']",NIA,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2017,184739,-0.0285778622326824
"IGF::OT::IGF Base Award. Creation of an Accurate Model of the Topical Structure of PubMed and Associated Indicators. POP: 09/01/17 - 02/28/18. N43DA-17-1215. The Contractor will develop advanced and sophisticated analytical models, tools and metrics to enhance the professional evaluation and decision making in life sciences management and administration.  The intended result is a novel set of metrics that can be used by NGOs/disease foundations, advocacy groups, research funders, policy makers and by academic institutional bodies. n/a",IGF::OT::IGF Base Award. Creation of an Accurate Model of the Topical Structure of PubMed and Associated Indicators. POP: 09/01/17 - 02/28/18. N43DA-17-1215.,9583616,71201700041C,"['Advocacy', 'Award', 'Biological Sciences', 'Complement', 'Contractor', 'Data', 'Databases', 'Decision Making', 'Disease', 'Evaluation', 'Foundations', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Modeling', 'Policy Maker', 'PubMed', 'Quality Indicator', 'Records', 'Reproducibility', 'Research', 'Structure', 'Testing', 'Text', 'Translations', 'base', 'economic impact', 'novel', 'tool']",NIDA,"SCITECH STRATEGIES, INC.",N43,2017,225000,-0.014250794724312043
"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis. PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.",Developing Classification Criteria for the Uveitides,9250167,R01EY026593,"['Acute', 'Adult', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Anterior uveitis', 'Antiviral Agents', 'Blindness', 'Child', 'Choroiditis', 'Chronic', 'Classification', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'Cytomegalovirus Retinitis', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Enrollment', 'Ensure', 'Epidemiology', 'Future', 'Genomics', 'Goals', 'Immune', 'Immunosuppression', 'Infection', 'Inflammation', 'Informatics', 'Intermediate Uveitis', 'Machine Learning', 'Mediating', 'Nomenclature', 'Outcomes Research', 'Panuveitis', 'Pathogenesis', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Pigments', 'Posterior Uveitis', 'Publications', 'Research', 'Retinitis', 'Risk Factors', 'Sensitivity and Specificity', 'Specificity', 'Standardization', 'Syndrome', 'Techniques', 'Terminology', 'United States', 'Uveitis', 'Vision', 'Visual impairment', 'Voting', 'age group', 'age related', 'aging population', 'antimicrobial', 'birdshot chorioretinitis', 'cost', 'outcome forecast', 'public health relevance', 'symposium', 'tool', 'web page', 'working group']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2017,400107,-0.013954191307579378
"Automated Ecological Video Identification of Physical Activity (E-VIP) Software ﻿    DESCRIPTION (provided by applicant): This proposal addresses multiple priorities of PAR-12-197 ""Improving Diet and Physical Activity (PA) Assessment"" by advancing assessment of population PA in common settings. Physical inactivity is responsible for ≈200,000 deaths in the US and 5 million deaths worldwide annually. About 10% of breast and 10% of colon cancers are attributable to insufficient PA, and inactivity causes 9% of total premature mortality. Parks, schools and youth sports are important contributors of PA that are relevant to a majority of the population. Supporting PA in these settings would contribute to improvements in population levels of PA and disease prevention and control. We will develop a novel video analysis software system, named E-VIP (Ecological Video Identification of PA), which will estimate the number of people and aggregated volume of PA from video recordings of PA- relevant settings. E-VIP will provide automated and continuous (rather than momentary) assessment, which will allow ongoing feedback to inform adaptive interventions and decision making. E-VIP is based on computer science methods used to count crowds and identify behaviors. We will train the E-VIP machine learning algorithm on 32,400 seconds of video from 2 parks, 2 schools, and 2 youth sports settings. Participants will engage in a variety of activities while wearing accelerometers to capture PA intensity in Metabolic Equivalents (METs). The testing phase involves capturing 900, 5-minute videos of free-living behavior across 4 parks, 4 schools, and 4 youth sports settings, with half of the settings/zones being the same as from the training phase. A range of activities and density of people will be captured in both the training and testing phase to maximize coverage of more-difficult high-density situations. Systematic direct observation will be conducted on each time sample to provide the criterion measure for testing validity. The metrics that will be tested include the average number of people, average proportion of people in each activity category (sedentary, light, moderate, vigorous, very vigorous), and sum PA MET-minutes in the setting over the 5-minute (or any given) time period. A gender and age group classifier will be explored. PE classes taught by PE specialists vs classroom teachers will be compared to test construct validity of E-VIP. Bland Altman methods and intraclass correlation coefficients will be used to assess agreement. Potential sources of error such as occlusions (e.g., trees, shadows, other people) will be assessed using moderator analyses. By automating ecological PA assessment, E-VIP will be feasible for widespread use. E-VIP's capability of continuous assessment will improve precision by collecting higher resolution data than collected by existing direct observation tools. When embedded in specific settings through commonly-used security cameras or webcams, or by purposefully placing video recorders, E-VIP will be capable of ongoing assessment which will inform public health surveillance, intervention, and evidence-based decision making (e.g., optimizing intervention strategies, monitoring school Physical Education mandates, providing needs assessment prior to and evaluation after environmental modifications). PUBLIC HEALTH RELEVANCE: This study will develop and test a software for automated ongoing measurement of use and physical activity intensity from video recordings in specific settings such as parks, schools (including Physical Education), and youth sports. This innovative software will support adaptive multilevel interventions and evidence-based decision making in physical activity-relevant settings to optimize strategies for improving population health.",Automated Ecological Video Identification of Physical Activity (E-VIP) Software,9210068,R21CA194492,"['Accelerometer', 'Address', 'Adolescent', 'Adult', 'Agreement', 'Algorithmic Software', 'Algorithms', 'Area', 'Behavior', 'Breast', 'Categories', 'Cessation of life', 'Child', 'Colon Carcinoma', 'Complex', 'Computer software', 'Crowding', 'Data', 'Decision Making', 'Diet', 'Elderly', 'Engineering', 'Error Sources', 'Evaluation', 'Exhibits', 'Feedback', 'Future', 'Gender', 'Goals', 'Hour', 'Individual', 'Intervention', 'Light', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modification', 'Monitor', 'Movement', 'Names', 'Needs Assessment', 'Participant', 'Phase', 'Physical Education', 'Physical Education and Training', 'Physical activity', 'Population', 'Population Surveillance', 'Premature Mortality', 'Process', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Schools', 'Security', 'Source', 'Specialist', 'Sports', 'Sum', 'System', 'Testing', 'Time', 'Training', 'Trees', 'Validation', 'Variant', 'Video Recording', 'Visual', 'Work', 'Youth', 'age group', 'base', 'computer science', 'cost', 'density', 'digital', 'disorder control', 'disorder prevention', 'evidence base', 'improved', 'innovation', 'novel', 'physical inactivity', 'population health', 'prototype', 'public health relevance', 'sedentary', 'software systems', 'teacher', 'tool', 'trend']",NCI,"CHILDREN'S MERCY HOSP (KANSAS CITY, MO)",R21,2017,152937,-0.01406161781616264
"Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination Project Summary / Abstract Between 1.6 and 3.8 million people each year suffer a mild TBI in the US alone. Reliable diagnosis and prompt treatments are vital to managing the often-serious short and long-term sequelae resulting from mild TBI. However, a reliable objective and accurate method for mild TBI diagnosis outside of a hospital setting, and in particular for determining RTP readiness, has eluded the clinical community. Current diagnosis and RTP assessments are based on patient symptoms, neurocognitive evaluations, and / or physical performance testing. Use of symptom scales are problematic for several reasons including subjectivity and reliability. Neurocognitive evaluations and physical tests (such as balance tests), although less subjective, require pre- injury baseline testing of subjects due to inherently large subject-to-subject variations in evaluation performances. Due to these reasons, current mild TBI diagnostic methods have limited applications and are not suitable for a significant majority of patients who suffer mild TBI. This project is aimed at developing an objective diagnosis of mild traumatic brain injury (mild TBI) based on physiologic changes in a patient after injury and providing a platform capable of RTP guidance. The method is based on quantification of well-known physiologic changes after a concussion, i.e. the impairment of autonomic function and altered cerebral blood flow (CBF) as measured with transcranial Doppler (TCD). The novelty of the proposed approach is the use of a recently-developed analytical machine learning framework for the analysis of the CBF velocity (CBFV) waveforms. In contrast to previous methods used before, the proposed approach utilizes the entire shape of the complex CBFV waveform, thus obtaining subtle changes in blood flow that are lost in other analysis methods. Additionally, comprehensive verification between our platform and MRI will be performed following injury resulting in the first scientific experiments of this kind. The ultimate goal of this Phase II SBIR is to commercialize an objective and accurate software algorithm for reliable diagnosis and management of sports concussions which does not currently exist. The outcome will be a software suite integrated into existing TCD and will be marketed to emergency departments, neurology clinics, and other healthcare providers involved in mild TBI diagnosis and RTP management. Project Narrative Traumatic brain injury (TBI) is a serious public health problem in the United States contributing to a substantial number of deaths and cases of permanent disability. Mild TBI concussions account for over 80% of all TBIs sustained and a major problem is the high rate of mis-diagnosis due to lack of objective measures and delayed onset of symptoms. This project aims to develop the first objective concussion evaluation method using a novel analysis platform that can obtain subtle, physiologic changes in cerebral hemodynamics. Successful completion of this project will result in a portable diagnostic device suitable for use in many scenarios where concussion diagnosis is inaccurate or unavailable today.",Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination,9323604,R44NS092209,"['Accident and Emergency department', 'Acute', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Area Under Curve', 'Assessment tool', 'Blood flow', 'Brain Concussion', 'Cerebrovascular Circulation', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Controlled Study', 'Core-Binding Factor', 'Data', 'Data Analytics', 'Data Collection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Evaluation', 'Functional disorder', 'Future', 'Goals', 'Gold', 'Guidelines', 'Health Personnel', 'Hospitals', 'Image', 'Impairment', 'Injury', 'Letters', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Methods', 'Modeling', 'Morphology', 'Neurocognitive', 'Neurologist', 'Neurology', 'Outcome', 'Patients', 'Pediatric Neurology', 'Performance', 'Persons', 'Phase', 'Physical Performance', 'Physicians', 'Physiological', 'Play', 'Public Health', 'Publications', 'Readiness', 'Recovery', 'Research', 'Resolution', 'Risk', 'Severities', 'Shapes', 'Site', 'Small Business Innovation Research Grant', 'Spin Labels', 'Sports', 'Sports Medicine', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Traumatic Brain Injury', 'Ultrasonography', 'United States', 'Variant', 'balance testing', 'base', 'brain health', 'cerebral hemodynamics', 'clinical Diagnosis', 'diagnostic accuracy', 'disability', 'experimental study', 'hemodynamics', 'high school', 'injured', 'innovation', 'mild traumatic brain injury', 'novel', 'pediatric department', 'performance tests', 'portability', 'prevent', 'programs', 'relating to nervous system', 'success', 'tool']",NINDS,"NEURAL ANALYTICS, INC.",R44,2017,1500000,-0.01040101184822115
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability. PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.",Capti Screen Reading Assistant for Goal Directed Web Browsing,9199231,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2017,500000,-0.003447010608157535
"Enabling Technology for Safe Robot-assisted Surgical Micromanipulation Project Summary  The goal of this grant is to develop enabling technology and systems that address fundamental limitations in microsurgery with a specific focus on vitreoretinal surgery. Due to the inherent micro-scale and the fragility of the neurosensory retina, vitreoretinal surgeons can be challenged by physiological hand tremor where the tremor amplitude is larger than retinal structures, delicate movements that are below tactile sensation, and multiple cognitive decisions that are required when executing high-risk movements, such as during retinal vein cannulation (RVC). Nevertheless currently vitreoretinal surgery is at the limits of human physiological performance and lacks the adequate technology that could further improve the technical performance. This situation is less than optimal and can significantly benefit from the recent advances in medical robotics, sensor feedback and human machine interface design. Robotic assistance may be ideally suited to address common problems encountered in the performance of the demanding micromanipulations in retinal microsurgery.  We propose a robotic system with enhanced real-time multisensory feedback that assesses multiple points of instrument contact located both inside and outside of the eye. Our comprehensive system will enable the surgeon to manipulate tools based on quantitative feedback that will prevent mechanical injury by implementing safeguards against the application of excessive and previously unmeasurable forces at the eyewall and the tool tip. Our aims are: (1) Develop and demonstrate in vivo position/force hybrid control algorithms for enabling real- time high-fidelity sensorimotor capabilities at the sclerotomy for safe robot-assisted vitreoretinal microsurgery: real-time sensorimotor capabilities at the sclerotomy will be uniquely used to control the robot through a machine learning method that adaptively learns a nonlinear mapping from user behavior to sclera-force/position and predicts unsafe motions; (2) Develop and demonstrate in vivo force-input control algorithms for enabling real- time high-fidelity sensorimotor capabilities at the tool-tip for safe robot-assisted vein cannulation: real-time tool- tip-to-tissue interaction force sensing and non-linear robot control algorithms based on observing the user behavior will be used to control the tool-tip position and force and to prevent entry into subretinal areas during RVC; (3) Demonstrate safe robot-assisted RVC in rabbit model in vivo: real-time, position/force hybrid control algorithms based on dual-point (tool-shaft and tip) information fusion will provide sensorimotor guidance of surgical maneuvers during RVC. Statistically significant results in vivo, in clinically realistic conditions will demonstrate the feasibility of our approach.  This highly innovative system will enable surgeons to perform maneuvers in a tremor free environment with a higher level of precision than previously possible and with the ability to sense forces on a scale that have been previously imperceptible. We envision this development as a logical next step in the integration of man, machine and computer for the performance of unprecedented microsurgical maneuvers. Project Narrative  This R01 grant addresses fundamental limitations in current microsurgical practice, focusing on vitreoretinal surgery (VRS), which is the most technically demanding ophthalmologic surgery. Our goal is to develop a cooperatively controlled robotic system with enhanced sensorimotor capabilities that in conjunction with multifunction force-sensing microsurgical instruments could enable safe robot-assisted retinal surgery. Although focused on VRS, our results will be applicable to a broader range of microsurgical training and practice.",Enabling Technology for Safe Robot-assisted Surgical Micromanipulation,9291018,R01EB023943,"['Address', 'Algorithms', 'Area', 'Behavior', 'Cannulations', 'Clinic', 'Clinical', 'Cognitive', 'Computers', 'Development', 'Disadvantaged', 'Discipline', 'Environment', 'Eye', 'Eye Movements', 'Feedback', 'Future', 'Goals', 'Grant', 'Hand', 'Healthcare', 'Hemorrhage', 'Histology', 'Human', 'Hybrids', 'Iatrogenesis', 'Injury', 'Intervention', 'Learning', 'Machine Learning', 'Manuals', 'Mechanics', 'Medical', 'Micromanipulation', 'Microsurgery', 'Miniaturization', 'Monitor', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Ophthalmologic Surgical Procedures', 'Ophthalmology', 'Optics', 'Oryctolagus cuniculus', 'Otorhinolaryngologic Surgical Procedures', 'Patients', 'Perception', 'Performance', 'Phase', 'Physiological', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Property', 'Reporting', 'Research', 'Research Proposals', 'Retina', 'Retinal', 'Retinal Hemorrhage', 'Retinal Perforations', 'Retinal Vein Occlusion', 'Robot', 'Robotics', 'Safety', 'Sclera', 'Site', 'Sterilization', 'Structure', 'Structure of central vein of the retina', 'Surgeon', 'Surveys', 'System', 'Tactile', 'Techniques', 'Technology', 'Time', 'Tissues', 'Touch sensation', 'Training', 'Tremor', 'User-Computer Interface', 'Veins', 'Vision', 'Work', 'adaptive learning', 'base', 'design', 'dexterity', 'high risk', 'improved', 'in vivo', 'in vivo Model', 'innovation', 'instrument', 'interest', 'learning strategy', 'man', 'medical specialties', 'multisensory', 'neurosensory', 'neurosurgery', 'operation', 'prevent', 'research clinical testing', 'robot assistance', 'robot control', 'sensor', 'technological innovation', 'tool', 'trend', 'virtual']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2017,305007,-0.011089036486789144
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research ﻿    DESCRIPTION (provided by applicant): This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0(tm) that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud(tm) Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb's DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently. PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9354497,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Communications Media', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Internet of Things', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Modernization', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'Transact', 'United States National Institutes of Health', 'analytical tool', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'experimental study', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'service learning', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2017,739402,-0.03859110729903139
"Characterizing Alzheimer's Disease with INSPECDS: Integrated Neurocognitive and Sleep-Behavior Profiler for the Endophenotypic Classification of Dementia Subtypes PROJECT SUMMARY AND ABSTRACT  It is estimated that Alzheimer's and other neurodegenerative diseases causing dementia will surpass cancer as the leading cause of death by the year 2040. Alzheimer's is the leading cause of dementia, followed by synucleinopathies, including dementia with Lewy bodies (DLB) and Parkinson's disease with dementia (PDD), Fronto-temporal dementia and Vascular dementia. Among clinical researchers focused on investigating the varying etiologies, genetic associations, biomarkers, and treatment options for Alzheimer's disease, there is an urgent need for effective tools to aid in the classification of dementia subtypes, in the earliest detectable stages of the pathophysiological process. To address this unmet need Advanced Brain Monitoring (ABM) proposes to leverage day and night assessment technologies to create an Integrated Neurocognitive and Sleep-Behavior Profiler for the Endophenotypic Classification of Dementia Subtypes (INSPECDS) to profile Alzheimer's and other dementias. The core components of the INSPECDS platform will be the Alertness and Memory Profiler (AMP), the Sleep Profiler, and integrated machine-learning, classification algorithms, hosted on a secure, cloud-based, infrastructure for automated data processing, analysis, and reporting. The AMP was developed and validated intially for the purpose of detecting the neurocognitive effects of sleep deprivation in adults diagnosed with obstructive sleep apnea but has more recently been applied to assess Alzheimer's and Parkinson's disease. The AMP is unique among neurocognitive testing platforms in that it is the only one which integrates advanced, electrophysiological measures (e.g., 24-channel, wireless EEG and ECG) during the performance of computerized neurocognitive tasks and has proven effective in characterizing cognitive decline in Alzheimer's. This advanced capability permits researchers to explore real- time relations between fluctuations in alertness, discrete cognitive functions, and specific neural processes believed to subserve observed performance deficits in Alzheimer's and other dementias. The Sleep Profiler is an FDA-cleared, easily applied, wireless-EEG device that was developed and validated to measure sleep architecture for in-home sleep studies with submental (chin) EMG and wireless accelerometers to monitor head and limb movements to quantify the characteristics of REM-sleep behavior disorder (RBD), considered to be a prodromal expression of synucleinopathy. Furthermore, the application of sophisticated, machine- learning, classification algorithms will streamline the processing and analyses of these data to derive statistical probabilities of Alzheimer's and other dementia subtypes. The overarching goal of the current, Direct-to-Phase II, SBIR project is to finalize implementation of a secure, cloud-based infrastructure to compile the data obtained from the AMP and Sleep Profiler, train classification algorithms to discriminate among Alzheimer's and other dementia subtypes, validate diagnostic accuracy, and integrate optimized classifiers within the cloud- based architecture. Once completed, the INSPECDS system will be the first clinical research tool of its kind and find immediate application in both university-based research settings and pharmaceutical industry clinical trials to aid in the endophenotypic stratification of Alzheimer's and other dementias. PROJECT NARRATIVE  Among clinical researchers focused on investigating the varying etiologies, genetic associations, clinical course, and treatment options for Alzheimer's and other neurodengenerative diseases, there is an urgent need for effective tools to aid in the classification of dementia subtypes, in the earliest detectable stages of the pathophysiological process. To address this unmet need, Advanced Brain Monitoring (Carlsbad, CA) is developing Integrated Neurocognitive and Sleep-Behavior Profilers for the Endophenotypic Classification of Dementia Subtypes (INSPECDS), which will provide an inexpensive, non-invasive solution combining neurocognitive, electrophysiological (EEG, ECG, EMG), and sleep-behavior assessment into a single, integrated system featuring automated scoring and classification algorithms. Once completed, the INSPECDS system will be the first clinical tool of its kind and find immediate application in clinical settings and pharmaceutical industry clinical trials to aid in the endophenotypic stratification of Alzheimer's and other dementia patients.",Characterizing Alzheimer's Disease with INSPECDS: Integrated Neurocognitive and Sleep-Behavior Profiler for the Endophenotypic Classification of Dementia Subtypes,9345457,R44AG054256,"['Accelerometer', 'Address', 'Adult', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Automatic Data Processing', 'Behavior', 'Behavior assessment', 'Biological Markers', 'Blinded', 'Brain', 'California', 'Cardiovascular Diseases', 'Cause of Death', 'Characteristics', 'Chin', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Data', 'Data Analyses', 'Databases', 'Dementia', 'Depressed mood', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Drug Industry', 'Economic Burden', 'Elderly', 'Electrocardiogram', 'Electroencephalography', 'Electrophysiology (science)', 'Enrollment', 'Etiology', 'Frontotemporal Dementia', 'Funding', 'General Hospitals', 'Goals', 'Head Movements', 'Home environment', 'Impaired cognition', 'Individual', 'Lewy Body Dementia', 'Machine Learning', 'Malignant Neoplasms', 'Massachusetts', 'Measures', 'Memory', 'Minor', 'Modification', 'Monitor', 'Neurocognitive', 'Neurodegenerative Disorders', 'Neurologic', 'Neuropsychological Tests', 'Obstructive Sleep Apnea', 'Parkinson Disease', 'Parkinson&apos', 's Dementia', 'Patients', 'Performance', 'Phase', 'Probability', 'Process', 'REM Sleep Behavior Disorder', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Sampling', 'Secure', 'Sleep', 'Sleep Architecture', 'Sleep Deprivation', 'Small Business Innovation Research Grant', 'Stratification', 'Stroke', 'Study Subject', 'System', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vascular Dementia', 'Wireless Technology', 'alertness', 'base', 'brain behavior', 'cloud based', 'cognitive function', 'cohort', 'computerized', 'data acquisition', 'diagnostic accuracy', 'genetic association', 'human subject', 'limb movement', 'mild cognitive impairment', 'neurocognitive test', 'relating to nervous system', 'synucleinopathy', 'tool']",NIA,"ADVANCED BRAIN MONITORING, INC.",R44,2017,538507,-0.11078430796942487
"Advancing a novel portable detection method for cannabis intoxication Intoxication from marijuana (MJ) impairs psychomotor performance and at least doubles the risk of motor vehicle accidents. The ongoing wave of legalization of MJ has brought increasing prevalence of driving while intoxicated with MJ. However, there is no quantitative biologic test that can accurately determine whether an individual is acutely impaired from MJ intoxication. Assays of the primary intoxicating substance in MJ, THC, in body fluids has a high false negative rate as THC is cleared from blood within 15 minutes, long before impairment is resolved. And assays of THC metabolites yield a high false positive rate because clearance of these metabolites can take weeks. Thus there is now no nor is there likely to ever be a test of blood, breath or body fluids that can accurately detect MJ intoxication. In response to this significant knowledge gap, this project aims to develop an accurate, portable method for detection of impairment due to MJ intoxication using functional near-infrared spectroscopy (fNIRS). fNIRS is a non-invasive, safe brain imaging technique that capitalizes on differences in the light absorption spectra of deoxygenated and oxygenated hemoglobin (Hb), that allows the measurement of relative changes in Hb concentration that reflect brain activity. fNIRS can be performed in natural environments at low cost, and thus can be used in real-world settings. In Phase I, we will develop an algorithm for individual-level detection of impairment from THC using fNIRS measurements. To do so, we will assess the effect of oral THC (or placebo) on fNIRS measurements, self-reported intoxication, and impairment as defined by the gold standard field sobriety test conducted by a Drug Recognition Expert (DRE) in 40 healthy MJ users. fNIRS assessments will examine (1) the effect of THC exposure on resting state and task-based activation in the prefrontal cortex, (2) the extent to which impairment in psychomotor functioning with THC administration correlates with THC-induced change in hemodynamic responses detected with fNIRS, and (3) the sensitivity and specificity and area under the ROC curve of fNIRS measurements and field sobriety test determinants of impairment. Milestone: Should machine learning applications to the data generate an algorithm that predicts impairment with >80% accuracy compared with a gold standard field sobriety test, we will proceed to Phase II. In Phase II, we will conduct fNIRS testing in 150 individuals under THC/placebo as in Phase I and in 50 individuals in a THC plus alcohol/placebo condition in order to further refine the algorithm for MJ impairment detection such that fNIRS detection concurs with field sobriety testing with >90% specificity. It is anticipated that this level of specificity could be used in legal definitions of impairment. This will warrant commercialization, which will be followed by prototype development and field testing. An accurate, quantitative, biological test that is user-friendly and enables law enforcement to detect impairment from MJ has the potential to dramatically change practice of law enforcement across the country and the world and thus has enormous commercial potential, as outlined in the Commercialization Plan and in accompanying letters of support. The goal of this project is to develop, test, and refine a method to accurately and reliably detect marijuana (MJ) impairment using a portable, user-friendly, non-invasive, brain-based modality. MJ doubles the chance of motor vehicle accidents, yet, there now exists no valid, biologically based method to detect whether an individual is acutely impaired from MJ. The development of a reliable, quantitative biological marker that enables law enforcement officers to screen individuals whom they suspect are impaired from MJ will have highly significant public health importance and enormous commercial potential.",Advancing a novel portable detection method for cannabis intoxication,9334516,R42DA043977,"['Acute', 'Adult', 'Age', 'Alcohols', 'Algorithms', 'Area', 'Base of the Brain', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Blood', 'Blood Circulation', 'Blood Tests', 'Body Fluids', 'Brain', 'Brain imaging', 'Breath Tests', 'Cannabis', 'Collaborations', 'Comorbidity', 'Country', 'Cross-Over Trials', 'Data', 'Detection', 'Development', 'Devices', 'Dose', 'Double-Blind Method', 'Driving While Intoxicated', 'Drug Kinetics', 'Ensure', 'Environment', 'Equipment', 'Evaluation', 'Formulation', 'Future', 'Goals', 'Gold', 'Hemoglobin', 'Hour', 'Human Resources', 'Imaging Techniques', 'Impairment', 'Individual', 'Intoxication', 'Knowledge', 'Law Enforcement', 'Law Enforcement Officers', 'Legal', 'Letters', 'Licensing', 'Light', 'Machine Learning', 'Marijuana', 'Measurement', 'Methods', 'Modality', 'Near-Infrared Spectroscopy', 'Oral', 'Patient Self-Report', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Placebo Control', 'Placebos', 'Population', 'Prefrontal Cortex', 'Prevalence', 'Property', 'Psychomotor Impairments', 'Psychomotor Performance', 'Public Health', 'ROC Curve', 'Randomized', 'Readiness', 'Rest', 'Risk', 'Sensitivity and Specificity', 'Source', 'Specificity', 'System', 'THC exposure', 'Testing', 'Tetrahydrocannabinol', 'United States', 'Urine', 'Vendor', 'absorption', 'alcohol exposure', 'base', 'behavior test', 'commercialization', 'cost', 'density', 'detector', 'driving under influence', 'drug testing', 'field sobriety tests', 'field study', 'functional disability', 'hemodynamics', 'interest', 'marijuana legalization', 'marijuana use', 'marijuana user', 'novel', 'novel strategies', 'portability', 'prediction algorithm', 'prototype', 'response', 'spectroscopic imaging', 'tool', 'user-friendly', 'vehicular accident']",NIDA,"HIGHLIGHTI, INC",R42,2017,224973,-0.003358664687042394
"Objective assessment of surgical competence in a septoplasty model ﻿    DESCRIPTION (provided by applicant): To ensure patient safety, educators must train surgeons to set standards of competency, public health officials should put in place policies to ensure surgeons remain competent and surgeons should only perform surgeries that they are competent to perform. Measuring surgeon's technical skill is crucial part of determining if they are competent. Traditionally surgical skill is assessed most commonly during training using subjective non-validated metrics. This leads to variation in the definition of competency. Recent policies set forth by the Accreditation Council of Graduate Medical Education- the governing body for graduate medical education, mandate that technical skill be measured objectively. Currently, there are few valid objective measures available to measure technical competence. Our research will yield a set of tools and methodologies that can be deployed to across medical training programs to objectively measure surgical skill and competence. This platform is also capable of developing new objective measure of skill and competence. Specifically, first, we will develop an objective skills assessment platform, and establish standard data collection and quality assurance protocols for systematic deployment of our platform across multiple institutions. Second, our work will result in automated algorithms and analytic tools to objectivel measure skill using data captured with our platform. Third, we will establish objective methods to determine whether a surgeon is competent to perform surgery. Fourth, we will test the reliability and validity of our assessment tools. We will conduct our study using septoplasty as the prototype test-bed procedure. Septoplasty is a commonly performed procedure (more than 260,000 cases per year) and is a key index surgery by which residents in otolaryngology are evaluated. Our project lays the groundwork for subsequent research to establish national standards for objective skill and competency using data aggregated from numerous training programs in the country. PUBLIC HEALTH RELEVANCE: Policies for graduate medical education require that surgical competency be objectively determined, but currently available technology and methods do not yield objective assessments for surgical skill. Our project aims to provide educators with an integrated objective skills assessment platform and tools for objective determination of competency, which can be readily deployed across graduate surgical training programs in the country.",Objective assessment of surgical competence in a septoplasty model,9307777,R01DE025265,"['Accreditation', 'Address', 'Algorithmic Software', 'American', 'Area', 'Assessment tool', 'Beds', 'Cessation of life', 'Competence', 'Computer Assisted', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Collection', 'Data Quality', 'Data Set', 'Ensure', 'Evaluation', 'Exploratory/Developmental Grant for Diagnostic Cancer Imaging', 'Foundations', 'Inferior', 'Institution', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Otolaryngology', 'Patient Care', 'Patient-Focused Outcomes', 'Phase', 'Philosophy', 'Physicians', 'Pilot Projects', 'Policies', 'Postoperative Complications', 'Predictive Value', 'Procedures', 'Protocols documentation', 'Public Health', 'Quality Control', 'Repeat Surgery', 'Research', 'Research Infrastructure', 'Research Support', 'Residencies', 'Site', 'Surgeon', 'System', 'Technical Expertise', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Validity and Reliability', 'Validity of Results', 'Variant', 'Work', 'analytical tool', 'base', 'graduate medical education', 'high risk', 'indexing', 'inter-institutional', 'patient safety', 'portability', 'programs', 'prototype', 'public health relevance', 'quality assurance', 'skills', 'success', 'tool']",NIDCR,JOHNS HOPKINS UNIVERSITY,R01,2017,501850,0.004235940448360421
"Understanding the impact of environmental disruption in biological timing systems through signal processing. Project Summary/Abstract.  Life on Earth evolved to take time cues from the Sun. Consequently, most or all cells in the mammalian body use genetic feedback loops to time their daily (circadian) rhythms. When a person or any mammal sees light, that winds an orchestrating circadian brain clock in the hypothalamic suprachiasmatic nucleus (SCN). The SCN in turn helps keep the myriad other tissue and endocrine rhythms in synchrony, enabling health. The modern environment is highly disruptive to this internal synchrony. Light at night from cell phones or urban light pollution, and social impositions like school start times or rotating work shifts all act as “temporal pollution,” causing loss of internal synchrony. The more severe the desynchrony, the higher the risk for a broad range of diseases, including obesity, cancer, infertility, depression and ultimately cognitive decline. Without knowing how these systems normally maintain synchrony or which systems are normally synchronized, it is hard to understand what happens in desynchrony to degrade health. This problem is complicated by the fact that some biological systems have ultradian (every few hours) and infradian (every few days) cycles in addition to circadian cycles. The hypothalamo-pituitary-adrenal axis (HPA) generates ultradian rhythms through negative feedback, but also shows a strong circadian cycle; the hypothalamo-pituitary-gonadal axis (HPG) shows the same negative feedback ultradian activity, circadian rhythmicity, and also infradian rhythms of ovulation and spermatogenesis. These two axes are regulated by the SCN. Recent work indicates that there is cross-talk between these axes, and that their hormonal outputs - corticosterone, and estradiol (in females) and testosterone (in males), respectively – work to synchronize extra-SCN tissues and behavioral rhythms of feeding and drinking (FaD). Finally, the SCN, HPA, and HPG axes all affect core body temperature (CBT), so that high temporal resolution recordings of CBT contain information about the cycling and synchrony of these systems across time scales.  There are three aims to this proposal, using rats as a model system: 1) Test at high temporal resolution the effects of changes to the HPA axis, HPG axis, and SCN on CBT. 2) Use these relationships to build a model that can back-predict the state of the HPA axis, HPG axis, and SCN from a high temporal resolution CBT record of a given individual. 3) Expose rats to environmental temporal disruption in the form of a 6 h “jetlag” phase advance of the light cycle, and use the model to predict the response across these systems at 1-minute temporal resolution. This work will employ within-animal comparisons before and after surgical and pharmacological manipulations of rats whose FaD, activity, and CBT are captured continuously at 1-minute resolution. These data will be analyzed using signal-processing and machine learning to define patterns and relationships. The resulting model will allow minimally-invasive exploration of environmental disruption across physiological systems in real time. The model will be used to quantify synchrony as it is disrupted and re-emerges, identifying markers for risk or resilience, and generating hypotheses for future work into preventive strategies and treatments. Project Narrative. Artificial lights and social obligation cause people living with modern infrastructure to suffer a loss of synchrony across their organs, which evolved to track the stable day and year light cycles. We know about internal synchrony mostly by the diseases that arise from its loss – everything from cancer to obesity, depression, and infertility. This work will develop a system for tracking the cycles of many body-systems at the same time with minute-to-minute accuracy, allowing rapid detection of desynchrony, and a potential way to study how synchrony works normally, and why its disruption by the modern environment causes disease.",Understanding the impact of environmental disruption in biological timing systems through signal processing.,9386306,K99ES027509,"['Address', 'Adrenal Glands', 'Affect', 'Animals', 'Automobile Driving', 'Back', 'Behavioral', 'Biological', 'Biological Models', 'Body Temperature', 'Body Temperature Changes', 'Brain', 'Cells', 'Cellular Phone', 'Chronic', 'Circadian Rhythms', 'Corticosterone', 'Coupling', 'Cues', 'Darkness', 'Data', 'Development', 'Diabetes Mellitus', 'Disease', 'Dose', 'Dysmenorrhea', 'Dyspepsia', 'Endocrine', 'Endocrine system', 'Environment', 'Environmental Impact', 'Estradiol', 'Feedback', 'Female', 'Frequencies', 'Future', 'Genetic', 'Glucocorticoids', 'Health', 'Hormonal', 'Hormonal Change', 'Hour', 'Human', 'Hypothalamic structure', 'Impaired cognition', 'Impairment', 'Implant', 'Individual', 'Infertility', 'Inflammation', 'Investigation', 'Jet Lag Syndrome', 'Life', 'Light', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Measures', 'Mental Depression', 'Modeling', 'Modernization', 'Monitor', 'Myocardial Infarction', 'Obesity', 'Operative Surgical Procedures', 'Organ', 'Orphan', 'Output', 'Ovulation', 'Pattern', 'Periodicity', 'Persons', 'Pharmacology', 'Phase', 'Physiological', 'Physiology', 'Pituitary-Adrenal System', 'Planet Earth', 'Pollution', 'Prevention strategy', 'Preventive treatment', 'Rattus', 'Records', 'Regulation', 'Research Infrastructure', 'Resolution', 'Risk', 'Risk Marker', 'Sampling', 'Schools', 'Shapes', 'Signal Transduction', 'Social Obligations', 'Spermatogenesis', 'Stress', 'Stroke', 'Structure', 'System', 'Testing', 'Testosterone', 'The Sun', 'Time', 'Tissues', 'Wireless Technology', 'Work', 'base', 'biological systems', 'body system', 'comparative', 'drinking', 'feeding', 'high risk', 'male', 'mathematical model', 'minimally invasive', 'pituitary gonadal axis', 'predicting response', 'predictive modeling', 'rapid detection', 'reconstruction', 'resilience', 'response', 'shift work', 'signal processing', 'social', 'suprachiasmatic nucleus', 'targeted treatment', 'temporal measurement', 'time use']",NIEHS,UNIVERSITY OF CALIFORNIA BERKELEY,K99,2017,98712,-0.017409427867655012
"Development of Deep Learning Models for Biomarker Identification and Classification Nearly half of all biomedical publications ever written have been published in the last 15 years— the era since the completion of the human genome project. The rate of increase is exponential, shows no signs of slowing down, and can be seen in all of the information sources relevant to precision medicine development. This constitutes a nearly insurmountable burden for the drug-development and diagnostics professionals who develop precision medicines. Next-generation automated evaluation of this data that will enable rapid, supportable, and innovative product-development decisions would lead to the development and approval of many more precision medicines, resulting in improved public health, decreased precision medicine time-to-market, and increased efficiency and profitability for drug-development and diagnostics companies. Developing precision medicines is exceedingly difficult due to an underlying chicken-and-egg problem: patient populations for whom a drug will be effective cannot be identified without a test, but test development is notworth justifying without a drug that is demonstrated to be effective in that population. No system for the identification of actionable precision medicine opportunities exists. The ideal approach would 1) examine multiple systems of record that impact marketplace decisions; 2) be aware of the identify of individual molecular biomarkers mentioned therein, as well as bring in technical details such as measurability and measurement method; and 3) be accessible to drug-development companies looking to define a patient population and diagnostics companies looking to develop a test to provide that definition. Therefore, the overall goal of this multi-phase SBIR project is to capitalize on our preliminary success in building a biomarker database (BiomarkerBase™) that supports this critical interface of precision medicine development decisions. Amplion's highly qualified data science R&D team will collaborate with Dr. Parag Mallick of Stanford University to pursue three Aims: 1) train a Deep Learning Model for biomarker identification in clinical trials, 2) extend Model application and prove performance for classification of biomarker usage intent, and 3) prove that Model-identified and classified biomarkers match and expand expert opinions. Showing that we can identify biomarkers and their usage classifications in clinical trials and publications will establish the predictive potential of our unique algorithms within the limited scope of this Phase I feasibility project and will set the stage for a larger Phase II demonstration. Phase I will provide data that can be incorporated directly into Amplion's BiomarkerBase™ product and will allow us to assess how well our Model meets user requirements for this data. Phase II work will allow us to expand/extend this Model to cover additional sources. Phase III work (with Industry partners) will allow us to integrate this commercial service directly into customer work flows. Our next-generation capabilities will provide a critical linkage at the challenging interface between the diagnostics and drug-development efforts and will accelerate the development of novel precision medicines. The development of precision medicines requires the synthesis of information from multiple sources to identify the opportunities that are technically feasible and likely to succeed in the marketplace. Current methods for analyzing this information are too slow, too non-specific, or too focused on only a small fraction of the information required to make a good decision. The overall goal of this project is to develop, validate, and commercialize Amplion's proprietary algorithms for identifying precision medicine development opportunities from publicly available sources.",Development of Deep Learning Models for Biomarker Identification and Classification,9348166,R43GM123851,"['Address', 'Algorithms', 'Area', 'Awareness', 'Biological', 'Biological Markers', 'Chickens', 'Classification', 'Clinical Trials', 'Consult', 'Data', 'Data Analyses', 'Data Science', 'Data Sources', 'Databases', 'Development', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Evaluation', 'Expert Opinion', 'Explosion', 'Feedback', 'Goals', 'Grant', 'Human Genome Project', 'Individual', 'Industry', 'Knowledge', 'Label', 'Lead', 'Learning', 'Legal patent', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Names', 'New Drug Approvals', 'Output', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Positioning Attribute', 'Public Health', 'Publications', 'Publishing', 'Report (document)', 'Research', 'Research Personnel', 'Services', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'System', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Training', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'biomarker identification', 'commercialization', 'companion diagnostics', 'drug development', 'egg', 'experience', 'improved', 'industry partner', 'innovation', 'insight', 'journal article', 'molecular marker', 'next generation', 'novel', 'patient population', 'precision medicine', 'product development', 'research and development', 'search engine', 'success']",NIGMS,"AMPLION, INC.",R43,2017,150000,-0.011232600711914533
"Software for OCT Analysis of Vascular Stents Software for OCT Analysis of Vascular Stents PI: Ronny Shalev, PhD, Dyad Medical Summary Dyad Medical, Inc. will create intravascular OCT (IVOCT) software for clinical, live time determination of stent apposition (OCTivat-live, the live time OCT image visualization and analysis tool) and for offline analysis of stent implantation (OCTivat-stent). Every year, 100s of thousands of patients in the US are treated with intra- vascular stents creating an opportunity for both solutions. Although advancements such as drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent design parameters include drug, material (bioresorbable vs metal), polymer composition, coatings to stimulate cell coverage, etc. To opti- mize designs, sensitive, in vivo assessments are needed for preclinical and clinical evaluations. Intravascular OCT (IVOCT) is the lone imaging modality with the resolution and contrast to meet this challenge. The Core Lab at CWRU is the premiere site in the world for manual analysis of IVOCT image data. A cardiologist analyst takes 6-16 hrs to analyze manually a single stent, and despite training and quality assurance measures, inter- analyst variability can limit the power to determine changes between stent designs. Building upon work at CWRU, we will develop advanced, highly automated software to greatly speed analysis, improve reproducibil- ity, increase accuracy, and harmonize analysis. Software will reduce costs by decreasing manual labor, and with improved reproducibility, possibly enable the use of historical data, eliminating cost of a control arm. Re- garding live time analysis, rather than manually reviewing >500 images in a pullback, with fast software, it will be possible to present the number and location of malapposed struts in 3D, providing instant feedback to phy- sicians on the need for additional dilatation with a larger balloon or higher pressure. In addition, we will auto- matically determine stent and vessel area along the length of the pullback, allowing us to compute stent ex- pansion and eccentricity, quantitative measures related to successful stent deployment, the most important de- terminant of outcome. IVOCT could also play a role at patient follow up. If a stent is well covered, then long- term anti-platelet therapy might be unnecessary, minimizing bleeding risk. If a stent has many uncovered struts, a therapeutic might prevent stent thrombosis or stimulate healing. Project Narrative: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies and improved deployment for improved treatment of vascular dis- ease.",Software for OCT Analysis of Vascular Stents,9407267,R43HL137500,"['Agreement', 'Algorithms', 'Area', 'Blinded', 'Blood Vessels', 'Cells', 'Classification', 'Clinical', 'Clinical Trials', 'Code', 'Computer software', 'Data', 'Detection', 'Devices', 'Dilatation - action', 'Doctor of Philosophy', 'Feedback', 'Follow-Up Studies', 'Heart', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Implant', 'Institutes', 'International', 'Ions', 'Laboratories', 'Length', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Metals', 'Methods', 'Myocardial Ischemia', 'Needs Assessment', 'Outcome', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Play', 'Polymers', 'Process', 'Reproducibility', 'Research Personnel', 'Resolution', 'Risk', 'Role', 'Services', 'Site', 'Speed', 'Stents', 'Surrogate Markers', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Variant', 'Vascular Diseases', 'Work', 'arm', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'image visualization', 'imaging modality', 'implantation', 'improved', 'in vivo', 'personalized diagnostics', 'preclinical evaluation', 'pressure', 'prevent', 'prototype', 'quality assurance', 'research clinical testing', 'restenosis', 'statistics', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,"DYAD MEDICAL, INC.",R43,2017,224744,-0.027675198519579006
"Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation Project Summary Neonatal endotracheal intubation (ETI) is a time-sensitive resuscitation procedure! essential for ventilation of newborns. It requires an unusually high level of skill due to the narrow airways, relatively large tongue, anterior glottic position, and low respiratory reserve of neonates (Bercic, Pocajt et al. 1978). Given the difficulty of the procedure and the high rate of complications in untrained hands, effective training is crucial. However, intubation success rates for pediatric residents are low under current resuscitation training programs and show little improvement between years 1-3 of residency (23-25%) (O'Donnell, Kamlin et al. 2006; Haubner, Barry et al. 2013). There is a pressing need to understand the factors that lead to poor training results and for innovative training modalities that can bridge the gap left by traditional training and thereby allow rapid skill acquisition. We hypothesize that current training and assessment methods suffer from 4 key weaknesses: (1) Poor realism: manikin and simulator-based training typically provide little variation in anatomy or difficulty level—key requirements for developing expertise (Dreyfus, Athanasiou et al. 1986)—and do not realistically model the look, feel, and motions of real tissue. (2) Subjective, highly variable, and resource-intensive assessment methods: training opportunities are limited by the availability of expert instructors. (3) Poor visualization: learners have poor knowledge about what went wrong and how to improve; they cannot see exactly what is going on inside the manikin or the patient and cannot directly monitor their actions relative to idealized, expert performance. (4) Assessment under artificially ideal conditions: assessments of ETI performance in classroom settings likely overestimate trainees' skill level because they do not mimic the stressors and distractions that are inherent in the real clinical environment. Technology-enhanced ETI simulators can resolve all of these key weaknesses: We have conducted preliminary work (Hahn, Li et al. 2016; Soghier, Li et al. 2014) on an augmented reality (AR (Azuma 1997)) manikin simulator driven by the motions of the trainee and physical manikin in real time that 1) provides a quantitative assessment of ETI technique and 2) allows the trainee to visualize the motion of the laryngoscope inside the manikin. The assessment score can provide feedback during the performance, as well as constitute part of the evaluation of the trainee's skill. Work under this proposal will build on this preliminary work. The specific aims are to: extend the current augmented reality (AR) manikin simulator to a virtual reality (VR) computer simulator and validate, extend and validate automated assessment and visualization algorithm for ETI, study training effectiveness by testing groups of pediatric residents across 3 years to quantify the effect of technology-enhanced methods relative to the current training regimen in terms of both intubation performance on simulators and clinical outcomes in patients, and assess performance under more realistic conditions. Project Narrative The current training and assessment of neonatal endotracheal intubation (ETI) suffers from key weaknesses of 1) poor realism of task simulators, 2) subjective, highly variable, and resource-intensive assessment methods, 3) poor visualization during simulation, and 4) assessment methods under artificially ideal conditions. This high-yield proposal will bridge the gap between training and clinical practice by using quantitative assessment tools and technology-enhanced simulation to improve ETI performance prior to patient care.",Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation,9288629,R01HD091179,"['Algorithms', 'Anatomy', 'Anterior', 'Assessment tool', 'Attention', 'Augmented Reality', 'Biomedical Engineering', 'Biometry', 'Childhood', 'Clinical', 'Cognitive Science', 'Computer Simulation', 'Computers', 'Data', 'Effectiveness', 'Enhancement Technology', 'Environment', 'Environmental air flow', 'Evaluation', 'Feedback', 'Hand', 'Imagery', 'Intratracheal Intubation', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Lead', 'Learning', 'Left', 'Libraries', 'Machine Learning', 'Manikins', 'Measures', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Neonatal', 'Neonatology', 'Newborn Infant', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Procedures', 'Regimen', 'Residencies', 'Resources', 'Resuscitation', 'Scanning', 'Standardization', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Tongue', 'Training', 'Training Programs', 'Validation', 'Variant', 'Work', 'base', 'clinical practice', 'computer science', 'distraction', 'evidence base', 'haptics', 'improved', 'innovation', 'instructor', 'kinematics', 'multidisciplinary', 'neonate', 'respiratory', 'simulation', 'skill acquisition', 'skills', 'stressor', 'success', 'training opportunity', 'virtual reality']",NICHD,GEORGE WASHINGTON UNIVERSITY,R01,2017,313412,-0.0033003311910998917
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9246108,U24DK112331,"['ATAC-seq', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Lead', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Research Infrastructure', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'base', 'bisulfite sequencing', 'cost', 'data resource', 'epigenomics', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'insight', 'medical schools', 'methylome', 'mortality', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2017,93230,-0.016738689914551214
"Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II Project Summary Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Clinical performance assessment emphasizes learner evaluation over learner development, lacks rigor and utility for developmental purposes, and clinical teachers have expressed particular difficulty with diagnosing reasoning deficits for remediation purposes. Further, medical students' diagnostic reasoning does not improve over the course of clinical training and senior medical students have highly variable diagnostic performance that is often rated below expectations according to theory-based and validated scoring criteria. Independent practice does not necessarily enhance the context for clinical reasoning; the majority of physicians' medical errors are thought to be diagnostic in nature. We propose to improve undergraduate medical education to minimize the time to clinical competency for first year residents through targeted diagnostic reasoning skill development that (1) integrates basic science and clinical instruction; (2) provides deliberate practice with structured, case-based learning opportunities; and (3) enables anytime/anywhere learning that fits with the demanding schedules of most medical students. Southern Illinois University School of Medicine (SIUSOM) is a recognized leader in using performance-based clinical competency exams to enhance reasoning skill acquisition among medical students. These exams feature clinical scenarios with standardized patients followed by diagnostic justification essays which require students to explicitly describe the thought process used to reach a final diagnosis. These essays are the most reliable method of assessing diagnostic strategies but are not in use in the majority of medical schools, though interest in improving diagnostic reasoning instruction and assessment during undergraduate medical education is widespread. Barriers to the widespread adoption of this approach are 1) the time-consuming need to hand score each essay; and 2) the difficulty in accurately and consistently identifying the causes of strategy failures. This project will develop an application to provide automated scoring of diagnostic justification essays, identification of the underlying causes of failure when students perform poorly, and feedback with instructional strategies for remediation specific to each deficit. We propose these specific aims: 1) Improve reliability of human scoring of DXJ essays. 2) Extend the automated scoring algorithms. 3) Automated reasoning failure categorization and remediation. 4) Complete the software development required for delivering the commercial product. 5) Evaluate predictive validity of automatically scored DXJ essays. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine. Project Narrative Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Better preparation during undergraduate medical education can shorten the time to competency of first year residents, improving patient outcomes. We propose to develop and test a technology-enabled, deliberate-practice approach to training diagnostic strategy that includes automated scoring of diagnostic justification essays, identification of specific diagnostic strategy failures and targeted remediation. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine.","Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II",9339455,R42GM108104,"['Address', 'Adopted', 'Adoption', 'Algorithms', 'Basic Science', 'Caring', 'Case Based Learning', 'Case Study', 'Charge', 'Classification', 'Clinical', 'Clinical Competence', 'Community Health Education', 'Competence', 'Consult', 'Custom', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Education', 'Educational Technology', 'Educational process of instructing', 'Ensure', 'Environment', 'Equation', 'Evaluation', 'Faculty', 'Failure', 'Feedback', 'Future', 'Goals', 'Hand', 'Hospitals', 'Human', 'Illinois', 'Incubators', 'Instruction', 'Leadership', 'Learning', 'Letters', 'Machine Learning', 'Measures', 'Medical', 'Medical Education', 'Medical Errors', 'Medical Students', 'Medicine', 'Methods', 'Modeling', 'Nature', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Preparation', 'Process', 'Recommendation', 'Role', 'Sales', 'Schedule', 'Semantics', 'Standardization', 'Structure', 'Students', 'Suggestion', 'Supervision', 'System', 'Taxonomy', 'Teaching Method', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validity and Reliability', 'Variant', 'base', 'educational atmosphere', 'essays', 'evidence base', 'expectation', 'improved', 'innovation', 'interest', 'medical schools', 'prototype', 'remediation', 'research and development', 'skill acquisition', 'skills', 'software development', 'teacher', 'theories', 'tool', 'undergraduate medical education', 'undergraduate student', 'virtual']",NIGMS,"PARALLEL CONSULTING, LLC",R42,2017,500000,-0.022438876250835408
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9508669,U24DK112331,"['ATAC-seq', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Lead', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Research Infrastructure', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'base', 'bisulfite sequencing', 'cost', 'data resource', 'epigenomics', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'insight', 'medical schools', 'methylome', 'mortality', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2017,162828,-0.016738689914551214
"Real-time prediction of marijuana use & effects of use on cognition in the natural environment ABSTRACT Some young adult marijuana (MJ) users report adverse effects of MJ use on cognition that impact daily functioning, with negative consequences such as injury and fatality due to driving while under the influence of MJ. Research on the effects of MJ use on cognition, however, has produced mixed findings. MJ effects on cognition may depend on factors such as history and current severity of marijuana use, time since last MJ use (including possible MJ withdrawal effects), and gender. This R21 aims to address limitations of existing research by (1) starting to develop an algorithm to predict MJ use using smartphone data in regular/heavy MJ users based on “routine” or “habitual use”, and (2) examining effects of MJ use on cognition using smartphone- based cognitive testing in the natural environment. Development of an algorithm to predict MJ use would facilitate systematic assessment of MJ effects on cognitive functioning through more efficient scheduling of smartphone cognitive testing among regular/heavy MJ users in relation to daily routines. Cognitive testing by smartphone in the natural environment is an innovative method that has shown validity, and permits sampling of cognitive functioning within and across days in relation to MJ use. This project will enroll non-treatment seeking young adult (ages 18-25) MJ users from the community, representing “low”, “regular”, and “heavy” MJ use, with 50% female at each level of use. Participants will complete a baseline lab assessment, 30-day data collection using smartphone and wearable devices (e.g., wristband), and a debriefing interview. Piloting will optimize the protocol and methods for compliance. Smartphones will collect continuously sensed data (e.g., geolocation) for input to an algorithm to predict MJ use in regular/heavy MJ users. This R21 will identify which types of data, available through smartphone, provide optimal detection of routines in MJ use among regular/heavy users. Smartphone cognitive testing will be administered at various times during acute MJ intoxication and various naturalistically occurring lengths of MJ abstinence to examine effects of MJ use on selected aspects of cognitive functioning in daily life. Development of an algorithm to predict MJ use in regular/heavy MJ users based on smartphone data could, for example, facilitate real-time assessment of MJ effects on cognition through improved sampling of cognition in relation to acute and non-acute effects of MJ use. This R21 will provide the foundation for a research program that aims to examine MJ effects on cognitive functioning in vivo, and could support the development of just-in-time intervention to reduce MJ use. This R21 aligns with NIDA's strategic goal of determining consequences of drug use, and cross-cutting themes of highlighting real-world relevance of research and leveraging mobile health technologies to reduce drug use. Project Narrative This exploratory project will initiate development of an algorithm to predict marijuana use using data from smartphone and ecological momentary assessment, and will examine effects of marijuana use on cognitive functioning in the natural environment using innovative smartphone-based cognitive tests. Developing an algorithm to predict marijuana use has substantial healthcare applications, specifically for timely intervention to reduce marijuana use. Further, examining effects of marijuana use on cognitive functioning daily life has important implications for determining possible adverse health consequences associated with marijuana use.",Real-time prediction of marijuana use & effects of use on cognition in the natural environment,9329948,R21DA043181,"['Abstinence', 'Acute', 'Address', 'Adverse effects', 'Age', 'Age of Onset', 'Algorithms', 'Attention', 'Automobile Driving', 'Awareness', 'Behavior', 'Cellular Phone', 'Cognition', 'Communities', 'Data', 'Data Collection', 'Detection', 'Development', 'Devices', 'Drug usage', 'Ecological momentary assessment', 'Enrollment', 'Environment', 'Female', 'Foundations', 'Frequencies', 'Gender', 'Geography', 'Goals', 'Health', 'Health Technology', 'Healthcare', 'Heart Rate', 'Hour', 'Injury', 'Intake', 'Intervention', 'Interview', 'Intoxication', 'Length', 'Life', 'Literature', 'Location', 'Machine Learning', 'Marijuana', 'Metadata', 'Methods', 'Modeling', 'Monitor', 'Moods', 'National Institute of Drug Abuse', 'Participant', 'Patient Self-Report', 'Performance', 'Positioning Attribute', 'Procedures', 'Protocols documentation', 'Recording of previous events', 'Recruitment Activity', 'Relaxation', 'Reporting', 'Research', 'Sampling', 'Schedule', 'Severities', 'Short-Term Memory', 'System', 'Testing', 'Text', 'Time', 'Travel', 'Withdrawal', 'addiction', 'age group', 'base', 'cognitive function', 'cognitive task', 'cognitive testing', 'computer science', 'daily functioning', 'data mining', 'improved', 'in vivo', 'innovation', 'mHealth', 'male', 'marijuana use', 'marijuana use disorder', 'marijuana user', 'marijuana withdrawal', 'mobile computing', 'prediction algorithm', 'programs', 'reduce marijuana use', 'young adult']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2017,234230,-0.029593197196386402
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9360750,R01DE027027,"['Accounting', 'Affect', 'Algorithms', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,372360,-0.01246562605029165
"Characterization of Thyroid Nodules by Quantitative Ultrasound Project Summary Thyroid cancer is the most-common endocrine malignancy. Its incidence has tripled in the last thirty years. Diagnosis of thyroid cancer is difficult because 50% of people older than 65 have at least 1 thyroid nodule, but only 10% of the nodules are cancerous. Approximately 1.6 billion dollars are spent annually in the US to detect thyroid cancer. Conventional ultrasound is used to identify nodules that warrant a needle biopsy. However, 65% of needle biopsies are negative for cancer and 30% are “indeterminate.” The indeterminate nodules are surgically removed for definitive diagnosis and 75% of them prove to be benign. Therefore, well more than 80% of initially presenting nodules undergo unnecessary biopsies and more than 20% of them also undergo subsequent unnecessary surgery procedures. Accordingly, the broad objective of the proposed study is to assess the feasibility of using quantitative-ultrasound (QUS) methods to distinguish cancerous from benign nodules reliably and thereby to reduce the enormous cost and risks associated with unnecessary biopsies and surgical excisions. The first aim of the project is to develop and asses the ability of QUS to distinguish cancerous from benign nodules and to compare the ability of QUS to the ability of conventional methods to select nodules that warrant biopsies; the second aim is to expand QUS methods by combining existing QUS measures developed by Riverside Research with measures derived from so-called B-flow- imaging (BFI) and shear-wave-elasticity (SWE) techniques developed by GE; the third aim is to formulate an objective basis for planning future, prospective studies to translate the findings of the present study to a commercial instrument that can bring QUS-based nodule evaluation into the clinic. To achieve these three aims, QUS performance in classifying cancerous and benign nodules will be compared to the performance of conventional ultrasound and the results of fine needle cytology, molecular marker analyses, and, in the cases of that undergo surgical excision, histology, will used as gold standards. Classification will be performed using standard, well understood, linear, and non-linear methods, such as linear-discriminant analysis and support- vector machines respectively. If feasibility is successfully demonstrated in the proposed project, and if the demonstration of feasibility ultimately leads to future incorporation into an instrument capable of real-time QUS analysis for reliable nodule evaluation, then a highly significant technological advance will be realized that can provide valuable, risk-reducing, cost-effective health-care benefits for patients presenting with thyroid nodules.   PROJECT NARRATIVE: Thyroid cancer rates have tripled in the last thirty years, but current methods of diagnosis are very inefficient. Far too many thyroid biopsies and surgeries are performed with >80% of biopsies and >25% of thyroid surgeries being performed on benign nodules. The advanced ultrasound methods to be evaluated in this proposal seek to drastically reduce the number of unnecessary biopsies and surgeries of benign thyroid nodules.",Characterization of Thyroid Nodules by Quantitative Ultrasound,9224641,R21CA212744,"['Achievement', 'Age', 'Architecture', 'Area', 'Asses', 'Benign', 'Biopsy', 'Breast Microcalcification', 'Calcified', 'Cancer Death Rates', 'Cancerous', 'Classification', 'Clinic', 'Clinical', 'Cytology', 'Cytology Histology', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Discriminant Analysis', 'Elasticity', 'Endocrine', 'Evaluation', 'Excision', 'Fine-needle biopsy', 'Foundations', 'Future', 'Goals', 'Gold', 'Healthcare', 'Histology', 'Image', 'In Situ', 'Incidence', 'Investigation', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measures', 'Methods', 'Molecular', 'Needle biopsy procedure', 'Needles', 'Nodule', 'Non-Malignant', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Performance', 'Population', 'Probability', 'Procedures', 'Property', 'Prospective Studies', 'Prostate', 'ROC Curve', 'Research', 'Risk', 'Signal Transduction', 'Solid', 'Specificity', 'Techniques', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Time', 'Tissues', 'Training', 'Translating', 'Ultrasonography', 'United States', 'Unnecessary Surgery', 'base', 'calcification', 'cost', 'cost effective', 'design', 'elastography', 'improved', 'instrument', 'lymph nodes', 'molecular marker', 'novel', 'prevent', 'prospective', 'quantitative ultrasound', 'statistics']",NCI,BOSTON MEDICAL CENTER,R21,2017,274504,-0.062423136955017
"Improving safety and efficacy of platelet transfusion through systems biology Project Summary Platelet transfusion is critical for severely bleeding patients and nearly 6 million units are transfused in the United States and Europe annually. In the United States, platelets are typically stored for 5 days resulting in a waste of 20% of their supply. Short storage duration is a consequence of bacterial contamination and platelet quality considerations. Though many methods have been developed for bacterial testing and pathogen inactivation, fewer have been developed for improving quality of stored platelets. Platelet additive solutions have the possibility to increase storage quality and duration, reduce plasma-related allergic reactions, impact the efficacy of pathogen reduction techniques, and save plasma which can then be used as an additional transfusion product. While the benefits are well known, there has been little progress in developing new platelet additive solutions for increasing quality and safety of platelet transfusion because there is a lack of broad understanding of biochemical and signaling changes during storage. There has been interest to utilize high-throughput metabolite profiling for global understanding of platelet metabolic decline but data analysis of complex datasets has been a daunting challenge. In Phase I of this program, we developed the first, robust computational platform involving statistical analysis and systems biology of metabolic and signaling networks to interpret and analyze PLT metabolomic and proteomic profiles in a complete network context. Using time- course global, quantitative metabolite profiling, we determined that PLTs undergo a non-linear decay process and computationally identified key metabolic enzymes and cellular process that drive this decay. Based on the computational results, we have devised two novel additive solution strategies to mitigate the decay process and improve the length of PLT units. In this Phase II proposal, we will validate the computationally determined additive solutions for efficacy in alleviating the non-linear decay process through 1) metabolomics experiments, and 2) non-metabolic PLT physiology experiments including cell activation and hemostatic effectiveness. A successful additive solution will be progressed to media refinement and preclinical testing. Project Narrative Platelet transfusion units are typically stored for five days in the United States leading to a waste of 20% of units and potential quality concerns. The field is open for innovation as most storage media technologies are derived from work from the early 1990s. This proposal will develop novel computational methods to comprehensively understand the degradation of platelets under storage conditions and experimentally validate new additive solutions for increasing platelet quality and extending shelf life, an area that accounts for $2.5 billion of hospital costs.",Improving safety and efficacy of platelet transfusion through systems biology,9347295,R44HL127843,"['Accounting', 'Agreement', 'Algorithms', 'Allergic Reaction', 'Area', 'Biochemical', 'Biological', 'Biological Preservation', 'Blood', 'Blood Component Removal', 'Blood Platelets', 'Caring', 'Cell physiology', 'Cells', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Effectiveness', 'Enzymes', 'Equipment and supply inventories', 'Europe', 'Formulation', 'Glutathione', 'Hemorrhage', 'Hemostatic Agents', 'Hospital Costs', 'In Vitro', 'Intervention', 'Length', 'Lesion', 'Life', 'Literature', 'Machine Learning', 'Mathematics', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Methods', 'Modeling', 'Pathway interactions', 'Patients', 'Phase', 'Physiology', 'Plasma', 'Platelet Transfusion', 'Preclinical Testing', 'Process', 'Production', 'Proteomics', 'Reaction', 'Recovery', 'Resources', 'Risk', 'Safety', 'Signal Pathway', 'Signal Transduction', 'State Hospitals', 'Statistical Data Interpretation', 'Supplementation', 'Surveys', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Transfusion', 'United States', 'Validation', 'Work', 'base', 'cost', 'design', 'experimental study', 'human subject', 'improved', 'insight', 'interest', 'metabolic profile', 'metabolomics', 'model design', 'novel', 'open innovation', 'oxidative damage', 'pathogen', 'programs', 'statistics', 'success', 'time use', 'wasting']",NHLBI,"SINOPIA BIOSCIENCES, INC.",R44,2017,1099022,-0.02077237442698936
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software. PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9238777,R01EY025332,"['Access to Information', 'Adoption', 'Algorithms', 'American', 'Architecture', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image Enhancement', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'experimental study', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2017,416574,-0.012116934805377266
"Socioeconomic status, stress, and smoking cessation PROJECT SUMMARY/ABSTRACT  The prevalence of electronic nicotine delivery systems (ENDS) is rising dramatically among both adults and youth and ENDS use is fast becoming a major public health issue. However, because of their recent emergence, researchers know little about ENDS, their use, their effects on human physiology and health, their risks and benefits, or their impact on tobacco control efforts. A common barrier to studying ENDS is the lack of data on objective, real world use of ENDS. Thus, the proposed project aims to adapt existing innovative mobile assessment tools that can be used to target critical ENDS research gaps by providing mobile sensing technology that can objectively collect precise data regarding ENDS use in real time in real world. Specifically, the proposed revision project will expand the scope of Project On Track (1R01CA190329-01A1, PI: Wetter) by extending the application of puffMarker, an existing tool that automatically detects smoking, for the assessment of ENDS use. The current project has three aims: 1) adapt and validate puffMarker to identify discrete episodes of ENDS use, 2) adapt and validate puffMarker to distinguish between cigarette smoking and ENDS use among dual users of ENDS and cigarettes, and 3) utilize the Project On Track protocol to collect real time, real world data investigating potential determinants of ENDS use among both exclusive ENDS users as well as dual users of cigarettes and ENDS. Altogether, 120 participants (30 for Aim 1, 30 for Aim 2, and 60 for Aim 3) will be enrolled. Participants recruited for Aims 1 and 2 will attend laboratory (three 2-hour sessions) and field (3 days) studies. In the laboratory sessions, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke a cigarette (Aim 2). Participants' ENDS and cigarette puffs will be recorded by an independent observer. In the field studies, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke cigarettes (Aim 2). Participants will be asked to record each instance of ENDS use or cigarette smoking on a SP. The goals of the laboratory studies are to collect data to train puffMarker to identify ENDS use and to distinguish between cigarette smoking and ENDS use. The goal of the field studies is to validate puffMarker in real-life, natural environments. Aim 3 will utilize the Project On Track protocol to collect the first real time, real world data on ENDS and dual use. Participants will be assessed for 6 days using AutoSense, EMA, and GPS to examine potential determinants of ENDS use. A validated puffMarker that detects ENDS use and distinguishes between ENDS use and smoking can enhance many areas of research inquiry on ENDS. Knowledge learned from Aim 3 will be essential for the development of comprehensive conceptual models with respect to ENDS use and smoking cessation. PROJECT NARRATIVE The proposed project aims to develop an innovative tool that targets important ENDS research gaps by offer- ing researchers the latest mobile sensing technology to objectively collect precise data regarding ENDS use and distinguish between ENDS use and smoking in real time and in real world.","Socioeconomic status, stress, and smoking cessation",9490765,R01CA190329,"['Abstinence', 'Acute', 'Address', 'Adult', 'Algorithms', 'Area', 'Assessment tool', 'Behavior', 'Behavioral', 'Benefits and Risks', 'Big Data to Knowledge', 'Breathing', 'Cellular Phone', 'Cereals', 'Characteristics', 'Chest', 'Cigarette', 'Data', 'Detection', 'Development', 'Ecological momentary assessment', 'Electronic Nicotine Delivery Systems', 'Enrollment', 'Environment', 'Environmental Risk Factor', 'Geography', 'Gestures', 'Goals', 'Hand', 'Harm Reduction', 'Health', 'High School Student', 'Hour', 'Human', 'Individual', 'Knowledge', 'Laboratories', 'Laboratory Study', 'Life', 'Longitudinal cohort study', 'Machine Learning', 'Measures', 'Modeling', 'Monitor', 'Movement', 'Oral cavity', 'Participant', 'Pattern', 'Physiological', 'Physiology', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Process', 'Protocols documentation', 'Public Health', 'Questionnaires', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Sensitivity and Specificity', 'Sensory', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Social Environment', 'Socioeconomic Status', 'Stress', 'System', 'Technology', 'Time', 'Tobacco', 'Training', 'United States National Institutes of Health', 'Wireless Technology', 'Wrist', 'Youth', 'addiction', 'arm movement', 'base', 'biobehavior', 'built environment', 'cigarette smoking', 'data to knowledge', 'experience', 'field study', 'innovation', 'novel', 'parent grant', 'population health', 'primary outcome', 'programs', 'psychosocial', 'respiratory', 'sensor', 'smoking cessation', 'social', 'systems research', 'tobacco control', 'tool', 'uptake', 'young adult']",NCI,UNIVERSITY OF UTAH,R01,2017,641479,-0.010792510623091122
"Optimizing electrical impedance myography outcomes through data mining Project summary  Electrical impedance myography (EIM) is a non-invasive technology for the assessment of muscle that is based on the application of a weak, high frequency electrical current to a muscle and the measurement of the resulting surface voltages. The further development and application of EIM remains the main business focus of Skulpt, Inc, a small business concern based in Boston and San Francisco (Specific Aims just say San Francisco). Alterations to the condition of the muscle, including myocyte atrophy, fat and connective tissue deposition, and inflammation all alter the EIM data in predictable and consistent ways. To date, through Skulpt, EIM has been applied as a potential biomarker for assessing disease progression and response to therapy in a wide variety of neuromuscular disorders, including amyotrophic lateral sclerosis, Duchenne muscular dystrophy, and spinal muscular atrophy, as well as other disorders that impact muscle condition, such as disuse atrophy and sarcopenia (age related muscle loss); over 1000 people have been studied with Skulpt’s EIM technology. Whereas the results of these applications are promising, the analytic approaches taken to the data sets have been fairly basic, utilizing only simple single frequency or simplistic multifrequency values. However, with every single muscle measurement, over 240 individual data points are acquired at different frequencies, different depths of muscle penetration, and at different angles to the major muscle fiber direction. Moreover, each of the above studies has been done in isolation, and thus how results differ between diseases is unknown. Given the plethora of data, applying more sophisticated analytic approaches has the potential of yielding improved EIM measures. Moreover, collaborators have already collected an associated wealth of animal EIM data that will help further inform this analysis. Thus, in this proposed Phase 1 SBIR, we plan to apply a variety of data mining techniques to the vast set of data already accumulated at Skulpt, Inc such that improved EIM outcomes can be developed and implemented. In Specific Aim 1, we will study human data across all disease types evaluated to determine which data sets are most effective at discriminating diseased from healthy muscle as well as distinguishing between diseases. In Specific Aim 2, we will focus on finding the metrics that are most sensitive to the degree of muscle pathology in a specific disease. In both of these aims, we will evaluate how these new metrics are mirrored in already obtained animal data. In Specific Aim 3, we will study these metrics in a new set of data (a test set) that was not used to develop the analytical paradigms so as to ensure their robustness. With the conclusion of this work, we will plan to pursue a Phase 2 SBIR that will focus on the development of a software suite to assist in EIM data interpretation based upon these results followed by a prospective observational clinical study to evaluate the efficacy of these newly developed metrics for disease diagnosis and tracking of progression/response to therapy. Project Narrative  Electrical impedance myography (EIM) is a non-invasive technology for the assessment of muscle that remains the main focus of Skulpt, Inc. Considerable EIM data has already been collected in a variety of neuromuscular diseases. In this study, the investigators plan to perform a more detailed analysis of all data collected to date (so-called “data mining”), such that improved EIM outcomes can be developed that will be applied to future studies.",Optimizing electrical impedance myography outcomes through data mining,9466075,R43AR073114,"['Age', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Animals', 'Area', 'Atrophic', 'Back Pain', 'Boston', 'Businesses', 'Categories', 'Characteristics', 'Clinical', 'Clinical Research', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Set', 'Deposition', 'Development', 'Diagnostic', 'Disease', 'Disease Progression', 'Disease model', 'Disease remission', 'Disuse Atrophy', 'Duchenne muscular dystrophy', 'Electrodes', 'Electrophysiology (science)', 'Ensure', 'Fatty acid glycerol esters', 'Fiber', 'Frequencies', 'Functional disorder', 'Funding', 'Future', 'Glycogen storage disease type II', 'Health', 'Inclusion Bodies', 'Individual', 'Inflammation', 'Laboratories', 'Machine Learning', 'Measurement', 'Measures', 'Medical Technology', 'Methods', 'Mining', 'Muscle', 'Muscle Cells', 'Muscle Fibers', 'Muscular Dystrophies', 'Musculoskeletal', 'Myography', 'Myopathy', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Penetration', 'Phase', 'Play', 'Positioning Attribute', 'Radiculopathy', 'Research Personnel', 'Role', 'San Francisco', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Tissues', 'Validation', 'Work', 'animal data', 'base', 'commercialization', 'data mining', 'disease classification', 'disease diagnosis', 'electric impedance', 'human data', 'improved', 'indexing', 'neuromuscular', 'potential biomarker', 'prospective', 'response', 'sarcopenia', 'voltage']",NIAMS,"MYOLEX, INC.",R43,2017,149998,-0.008353778850457494
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9303234,R00AG046911,"['Address', 'Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'imaging modality', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'public health relevance', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2017,249000,-0.014493705446170704
"Individualized Signal Processing Strategy :Phase II This project describes a novel approach to automate and individualize the signal processing strategy for hearing aids (HA) that can result in improved speech intelligibility in background noise, greater user satisfaction and acceptance for HAs, and reduce barriers to affordable hearing health care. The proposed Individualized Signal Processing Strategy (ISPS) is based on individual performance on categorical perception tasks for speech stimuli. This differs from traditional methods based on sophisticated gain models built upon average perception, performance, and preference data. The ability to determine one’s ISPS automatically, rapidly and remotely can result in dramatic cost-savings and greater accessibility to hearing health care for patients who cannot afford it or for those who lack easy access to the necessary expertise. These technical achievements have the potential to radically change HA service delivery models yet can be implemented within existing business models and in concert with current practitioners. The ISPS method effectively replaces target-based HA fitting (e.g. NAL-NL2) with individualized speech-based parameter adjustment. The proposed work follows successful completion of our pilot project and builds upon the research team’s prior research on novel fitting methods for cochlear implant (CI) devices recently acquired by Cochlear, Ltd. Following the successful implementation of ISPS and integration with commercial HA software in the pilot study, we demonstrated feasibility including a field study in which performance outcomes for the ISPS method were as good as a conventional HA fitting method and only took a fraction of the time, despite ISPS having no prior knowledge of patient characteristics and no audiogram. Successful maturation and commercialization of the ISPS technology in Phase II will address several barriers identified in the previous RFA-DC-12-004 including physical, infrastructure, and knowledge barriers (by allowing remote or self-fitting HAs), economic barriers (by reducing overall costs), and cultural barriers (by providing easy access to HA fitting for patients who tend to avoid professional help). This Phase II project will develop an operational ISPS method by (1) integrating ISPS with hardware/software systems of our industry partners, (2) refine and enhance the ISPS method to improve efficiency and effectiveness of fitting hearing instruments, (3) build support for the use of ISPS in multiple marketplaces, and (4) evaluate the technology through field trials in different service delivery environments by comparing outcomes with ISPS fitting to those achieved with traditional prescriptive gain fitting within the same subjects. Following successful demonstration of these objectives, a Phase III project will focus on the transition of the technology to support remote and self-fitting of hearing instruments. This project seeks to develop, implement and test a novel automated method for fitting hearing aids based on real-time speech perception performance. This automated approach can improve hearing aid success while significant reducing costs of hearing health care. The automation of the fitting procedure can dramatically increase accessibility of hearing health care.",Individualized Signal Processing Strategy :Phase II,9347562,R44DC016249,"['Achievement', 'Address', 'Algorithms', 'Artificial Intelligence', 'Audiology', 'Audiometry', 'Auditory', 'Automation', 'Businesses', 'Categories', 'Characteristics', 'Cochlear Implants', 'Collaborations', 'Computer software', 'Cost Savings', 'Crossover Design', 'Data', 'Development', 'Devices', 'Economics', 'Effectiveness', 'Environment', 'Evaluation', 'Frequencies', 'Funding', 'Generic Drugs', 'Goals', 'Healthcare', 'Hearing', 'Hearing Aids', 'Individual', 'Instruction', 'Knowledge', 'Learning', 'Link', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Outcome', 'Patient Care', 'Patients', 'Perception', 'Performance', 'Phase', 'Pilot Projects', 'Procedures', 'Process', 'Randomized', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Sensorineural Hearing Loss', 'Services', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Stimulus', 'Supervision', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'United States Department of Veterans Affairs', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'commercialization', 'cost', 'data modeling', 'experimental study', 'field study', 'graph theory', 'health care service', 'implantable device', 'improved', 'improved outcome', 'inclusion criteria', 'industry partner', 'instrument', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'preference', 'satisfaction', 'signal processing', 'software systems', 'sound', 'success']",NIDCD,"SECURBORATION, INC.",R44,2017,758924,-0.05925994503237961
"Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility Innovative Design Labs (IDL) proposes to create a system to improve the mobility and control of exoskeletons. Recent research has found that 3.86 million Americans require wheelchairs and the number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk, thus providing a way to more fully reintegrate these individuals into society. Our proposal seeks to address one of the hurdles limiting the widespread adoption of exoskeletons in the home and community—the inability of the user to dynamically control gait parameters. This concept has the potential to significantly change the way exoskeletons work and facilitate their adoption into the market. Hypothesis: We hypothesize that the proposed solution will provide users a practical way to adjust their suit’s gait to precisely achieve their navigational goals. Specific Aims: Phase I: 1) Build a prototype and Perform Preliminary Laboratory Testing; 2) Develop and Benchmark Algorithms; and 3) Perform Pilot Human Study of Prototype with Exoskeleton Subjects. Phase II: 1) Develop Customized, Production-Ready Hardware and Firmware 2) Integrate with Exoskeleton Control System; and 3) Perform an evaluation of the system through human study testing. Recent research has found that 3.86 million Americans require wheelchairs and that number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk thereby providing a way to more fully reintegrate these individuals into society.",Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility,9474743,R44AG053890,"['Address', 'Adoption', 'Algorithm Design', 'Algorithms', 'American', 'Benchmarking', 'Bionics', 'Caregivers', 'Chicago', 'Clinical', 'Collaborations', 'Communities', 'Community Participation', 'Computational algorithm', 'Computer Vision Systems', 'Crutches', 'Custom', 'Dependence', 'Devices', 'Electrical Engineering', 'Emotional', 'Environment', 'Evaluation', 'Exercise', 'Eye', 'Family', 'Feedback', 'Freedom', 'Friends', 'Gait', 'Goals', 'Health', 'Height', 'Home environment', 'Hospitals', 'Human', 'Image', 'Impairment', 'Individual', 'Industry', 'Institutes', 'Laboratories', 'Length', 'Location', 'Medical', 'Methods', 'Motion', 'Patients', 'Performance', 'Phase', 'Population', 'Process', 'Production', 'Quality of life', 'Ramp', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Safety', 'Small Business Innovation Research Grant', 'Social isolation', 'Societies', 'Software Engineering', 'System', 'Technology', 'Testing', 'Uncertainty', 'Vision', 'Walking', 'Wheelchairs', 'Work', 'commercialization', 'design', 'exoskeleton', 'experience', 'human study', 'image processing', 'improved', 'improved mobility', 'innovation', 'insight', 'member', 'product development', 'prototype', 'rehabilitation technology', 'robot exoskeleton', 'usability']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2017,562410,-0.015984814312059312
"Psychophysics of Reading - Normal and Low Vision DESCRIPTION (provided by applicant):  Psychophysics of Reading - Normal and Low Vision Abstract Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  Difficulty in accessing print imposes obstacles to education, employment, social interaction and recreation.  The ongoing transition to the production and distribution of digital documents brings about new opportunities for people with visual impairment.  Digital documents on computers and mobile devices permit easy manipulation of print size, contrast polarity, font, page layout and other attributes of text.  In short, we now hae unprecedented opportunities to adapt text format to meet the needs of visually impaired readers.  In recent years, our laboratory and others in the vision-science community have made major strides in understanding the impact of different forms of low vision on reading, and the dependence of reading performance on key text properties such as character size and contrast.  But innovations in reading technology have outstripped our knowledge about low-vision reading.  A major gap still exists in translating these laboratory findings into methods for customizing text displays for people with low vision.  The broad aim of the current proposal is to apply our knowledge about the impact of vision impairment on reading to provide tools and methods for enhancing reading accessibility in the modern world of digital reading technology.  Our research plan has three specific goals:   1) To develop and validate an electronic version of the MNREAD test of reading vision, to extend this technology to important text variables in addition to print size, and to develop methods for customizing the selection of text properties for low-vision readers.  MNREAD is the most widely used test of reading in vision research and was originally developed in our laboratory with NIH support.  2) To investigate the ecology of low-vision reading in order to better understand how modern technologies, such as iPad and Kindle are being used by people with low vision.  We plan to evaluate the feasibility of using internet methods to survey low-vision individuals concerning their reading behavior and goals, and of collecting approximate measures of visual function over the internet.  We also plan to develop an ""accessibility checker"" to help low-vision computer users and their families to evaluate the accessibility of specific text displays.  3) To enhance reading accessibility by developing methods for enlarging the visual span (the number of adjacent letters that can be recognized without moving the eyes).  A reduced visual span is thought to be a major factor limiting reading in low vision, especially for people with central-field loss from macular degeneration.  We have already demonstrated methods for enlarging the visual span in peripheral vision.  We plan to develop a more effective perceptual training method for enlarging the visual span, with the goal of improving reading performance for people with central-vision loss. PUBLIC HEALTH RELEVANCE:  Reading difficulty is one of the most disabling consequences of vision loss for five million Americans with low vision.  The ongoing transition to the use of digital documents on computers and mobile devices brings about new opportunities for customizing text for people with visual impairment.  We propose to apply findings from basic vision science on low vision and reading to develop tools and methods for enhancing reading accessibility for digital text.",Psychophysics of Reading - Normal and Low Vision,9292314,R01EY002934,"['American', 'Attention', 'Auditory', 'Behavior', 'Blindness', 'Books', 'Caring', 'Central Scotomas', 'Characteristics', 'Clinical Research', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Custom', 'Dependence', 'Development', 'Devices', 'Ecology', 'Education', 'Employment', 'Eye', 'Family', 'Galaxy', 'Goals', 'Government', 'Guidelines', 'Habits', 'Health', 'Individual', 'Internet', 'Knowledge', 'Laboratories', 'Laboratory Finding', 'Leg', 'Length', 'Letters', 'Life', 'Macular degeneration', 'Mainstreaming', 'Maps', 'Marshal', 'Measures', 'Methods', 'Modernization', 'Optics', 'Paper', 'Participant', 'Patients', 'Perceptual learning', 'Performance', 'Peripheral', 'Play', 'Policies', 'Printing', 'Production', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysics', 'Reader', 'Reading', 'Recreation', 'Reporting', 'Research', 'Resources', 'Role', 'Self-Help Devices', 'Social Interaction', 'Surveys', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Work', 'analog', 'base', 'design', 'digital', 'essays', 'handheld mobile device', 'improved', 'innovation', 'invention', 'large print', 'literate', 'public health relevance', 'reading difficulties', 'sound', 'symposium', 'tool', 'vision science', 'web-accessible']",NEI,UNIVERSITY OF MINNESOTA,R01,2017,364423,-0.00827571877025064
"Designing Visually Accessible Spaces DESCRIPTION (provided by applicant):  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions.  We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area).  This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement.  Our project addresses one of the National Eye Institute's program objectives:  ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals:  1) Empirical:  determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces.  2) Computational:  develop working models to predict low vision visibility and navigability in real-world spaces.  3) Deployment:  translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility.  The key scientific personnel in our partnership come from three institutions:  University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare.  This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare).  We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.",Designing Visually Accessible Spaces,9251284,R01EY017835,"['Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Fall injury', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Height', 'Human', 'Human Resources', 'Indiana', 'Individual', 'Industrialization', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Physically Handicapped', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'hazard', 'imaging system', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'public health relevance', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2017,580671,0.002364028872518691
"Augmented Reality System for the Education of Clinical Caregivers of Older Adults Project Summary/Abstract The value of mannequin-based simulation is well recognized and is incorporated extensively into medical education. In general, their primary purpose is to simulate a physical ""patient"" on which to learn, demonstrate, and test skill without fear of harming patients prior to entering clinical environments. Despite their substantial benefits, they have several fundamental limitations. Proposed is a system to combine and leverage the advantages of both existing physical mannequin-based training and virtual media to support clinical learning using Augmented Reality (AR). This Phase I project will focus on creating and evaluating a proof of concept system. An engaging, interactive training course using the prototype system will be developed as a case study for clinical nursing training on pressure injuries – an oftentimes preventable injury that is attributed to tremendous human suffering and represents a significant cost burden on our health care system. The course will leverage existing mannequin-based training used at the UMN and be evaluated by both instructors and students at the School of Nursing. Project Narrative Over the past decade, medical simulation has been experiencing explosive growth and widespread adoption. There are now over 800 medical simulation centers in the US alone, located in medical schools, nursing schools, hospitals, military simulation centers, and schools of allied health professions. The global market for Mannequin-Based Simulation is projected to reach $1 Billion by 2020. It is hypothesized that the combination of existing physical mannequin-based training with virtual media will opens new possibilities for exploration and enhanced learning interactions for medical education.",Augmented Reality System for the Education of Clinical Caregivers of Older Adults,9409513,R43AG057257,"['Adoption', 'Algorithmic Software', 'Allied Health Profession', 'Anatomy', 'Augmented Reality', 'Caregivers', 'Case Study', 'Clinical', 'Clinical Nursing', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Development', 'Devices', 'Disease Progression', 'Dissection', 'Education', 'Educational Curriculum', 'Elderly', 'Environment', 'Fright', 'Growth', 'Healthcare Systems', 'Hospitals', 'Human', 'Hybrids', 'Image', 'Injury', 'Intervention', 'Lead', 'Learning', 'Location', 'Manikins', 'Medical', 'Medical Education', 'Military Personnel', 'Minnesota', 'Modeling', 'Movement', 'Nursing Schools', 'Patients', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Sampling', 'School Nursing', 'Schools', 'Scientist', 'Severity of illness', 'Skin', 'Small Business Innovation Research Grant', 'Structure', 'Students', 'Support Groups', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'Vision', 'Visual', 'animation', 'base', 'caregiver education', 'cost', 'design', 'experience', 'flexibility', 'human study', 'innovation', 'instructor', 'medical schools', 'pressure', 'professor', 'prototype', 'simulation', 'skills', 'teacher', 'virtual', 'virtual reality']",NIA,"INNOVATIVE DESIGN LABS, INC.",R43,2017,224952,-0.030675033713470072
"Deep learning for representation of codes used for SEER-Medicare claims research ﻿    DESCRIPTION (provided by applicant):  We propose developing an algorithm and user-friendly software to better identify treatments using Medicare claims data. We will validate our approach using procedures listed in the Surveillance, Epidemiology, and End Results (SEER) database as a gold standard. In this way, we hope to better match procedures identified using Medicare claims data with SEER listed procedures.  The focus of this research is observational (i.e. non-randomized) data. Well-run randomized clinical trials can provide the best level of evidence of treatment effects. However, randomized trials in the United States have suffered from poor accrual for many interventions. Despite the fact that well-designed randomized clinical trials should be the gold standard, well-designed observational studies might be the only method of obtaining inferences concerning comparative effectiveness for some cancer interventions.  In cancer research, one of the most commonly used databases for observational research is the linked SEER-Medicare database. SEER-Medicare data has provided useful measurements of the effectiveness of a number of cancer therapies. Algorithms for identifying relevant treatment and diagnosis codes using Medicare data are often based on clinical reasoning and scientific evidence. One group of researchers, for example, developed an algorithm for identifying laparoscopic surgery among kidney cancer cases before claims codes for laparoscopic surgery were well developed. While such algorithms are useful for others pursuing similar investigations, there may still be substantial mismatch between treatment identified by the SEER cancer registry and treatment identified through Medicare claims. In this work, we propose developing a rigorous machine learning algorithm that can help researchers in better identifying treatments in Medicare claims data. Specifically, we will design a neural language modeling algorithm and implement a software system that finds vector representations of diagnosis and procedure codes.  We plan on using the neural language modeling algorithm to learn vector representations from SEER- Medicare claims data where related procedure and diagnosis codes are ""neighbors"" (i.e. closely related). We will investigate whether the codes we identify within neighborhoods correspond to the procedure codes used for published SEER-Medicare studies. We will then design a software assistant interface that will allow an investigator to explore which codes are related to a given seed of diagnosis or procedure codes. Finally, we will investigate the sensitivity and specificity of the algorithm by comparing procedures identified using Medicare claims with procedures listed in the SEER database. We will replicate analyses from a published SEER-Medicare paper to investigate if estimated treatment effects differ when using our novel algorithm compared to using the algorithm in the published paper.         PUBLIC HEALTH RELEVANCE: In cancer research, one of the most commonly used databases for observational research is the linked Surveillance, Epidemiology, and End Results (SEER)-Medicare database. To improve the identification of procedures when using Medicare claims data, we will design a software assistant interface that will allow an investigator to explore which codes are related to a given seed of diagnosis or procedure codes. This should improve the identification of procedures when using Medicare claims data, and make conclusions drawn from analyses using the database more reliable and consistent.            ",Deep learning for representation of codes used for SEER-Medicare claims research,9023921,R21CA202130,"['Algorithms', 'Cancer Intervention', 'Clinical', 'Code', 'Computer software', 'Data', 'Databases', 'Diagnosis', 'Effectiveness', 'Ethical Issues', 'Funding', 'Future', 'Gold', 'International Classification of Diseases', 'Intervention', 'Investigation', 'Language', 'Laparoscopic Surgical Procedures', 'Learning', 'Level of Evidence', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical', 'Medical Records', 'Medical Surveillance', 'Medicare', 'Medicare claim', 'Methods', 'Modeling', 'Natural Language Processing', 'Neighborhoods', 'Observational Study', 'Outcome', 'Paper', 'Patients', 'Procedures', 'Process', 'Proxy', 'Publishing', 'Randomized', 'Randomized Clinical Trials', 'Records', 'Renal carcinoma', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sensitivity and Specificity', 'Software Tools', 'Statistical Study', 'Terminology', 'Testing', 'Time', 'United States', 'Update', 'Work', 'abstracting', 'anticancer research', 'base', 'cancer therapy', 'comparative effectiveness', 'design', 'health disparity', 'improved', 'interest', 'malignant breast neoplasm', 'neoplasm registry', 'novel', 'public health relevance', 'randomized trial', 'relating to nervous system', 'software systems', 'treatment effect', 'usability', 'user friendly software', 'vector', 'volunteer']",NCI,RESEARCH INST OF FOX CHASE CAN CTR,R21,2016,178072,-0.026842784154085416
"Calculation of Percent Body Fat by Analyzing Virtual Body Models ﻿    DESCRIPTION (provided by applicant):  Excess body fat is a key underlying factor in the development of numerous chronic diseases, including type II diabetes, heart disease, stroke, and cancer. The AMA recently declared that obesity, itself, is a disease. Most epidemiologic studies utilize Body Mass Index (BMI) to classify people as underweight, normal, overweight, or obese because it is a convenient and simple method that has been shown to correlate with disease risk. Since the majority of the health risks associated with obesity are more directly linked to an overabundance of body fat than weight, measuring body fat is essential for more precise guidelines. However, accurate methods of assessing body fat are expensive, inconvenient, and require immobile equipment. Consequently, the AMA has called for more cost effective and convenient methods to assess body composition to assist doctors in their assessment and treatment. Virtual modeling of humans in particular has provided ways to scan and analyze the body and its motion. Supervised Machine Learning (SML), a sub-field of artificial intelligence, has made great progress in taking measured data to infer new relationships. It is our belief that virtual modeling and SML can provide the techniques necessary to conveniently and accurately calculate the percentage of body fat (%BF) and to provide new tools in treating obesity based on body shapes. The project will develop a system that uses commercially available depth cameras such as the Microsoft Kinect(r) to capture the surface of the human body. This will be accomplished by developing a new algorithm to perform deformable registration of several RGB-Depth views of the body. A new algorithm that uses SML will be developed to calculate percentage body fat using the surface data. The system will be trained and validated by collecting data from a number of subjects. The surface captured will be used to explore the role of visual body representation in motivation and adherence. The developed systems can be implemented in clinical or personal settings and be utilized as a public health research tool and deployed widely given the low-cost of the hardware required. In addition to the immediate impact that the system will have on managing obesity, the project will have a broad impact on a number of areas. A large database of such shapes captured over time may lead to ways to predict how an individual's body shape will change given a particular intervention. Certain medical conditions that result in body shape change, such as those involving lymphatic circulations, may be diagnosed and tracked more easily. Growth patterns of children may be tracked by change of body shapes. Further research can be conducted to determine the effect of body shape on %BF using data mining techniques. PUBLIC HEALTH RELEVANCE: The project will develop a new method to capture the 3D surface and shape of a human body and a new method to use these data to calculate percent body fat. By making these tools widely available and economical, the proposed approach has the potential for major contributions in the assessment and treatment of obesity.",Calculation of Percent Body Fat by Analyzing Virtual Body Models,9099872,R21HL124443,"['Adherence', 'Age', 'Air', 'Algorithms', 'Area', 'Artificial Intelligence', 'Behavior Therapy', 'Belief', 'Body Composition', 'Body Size', 'Body Surface', 'Body Weight decreased', 'Body fat', 'Body mass index', 'Child', 'Chronic Disease', 'Client', 'Clinical', 'Clinical Research', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Epidemiologic Studies', 'Equipment', 'Fatty acid glycerol esters', 'Future', 'Goals', 'Growth', 'Guidelines', 'Health', 'Health Care Costs', 'Heart Diseases', 'Human', 'Human body', 'Imagery', 'Incentives', 'Individual', 'Intervention', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Motivation', 'Muscle', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Overweight', 'Participant', 'Patients', 'Pattern', 'Perception', 'Plethysmography', 'Public Health', 'Reporting', 'Research', 'Risk', 'Role', 'Scanning', 'Self Perception', 'Series', 'Shapes', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Underweight', 'Variant', 'Visual', 'Water', 'Weight', 'Weights and Measures', 'base', 'body density', 'body volume', 'cost', 'cost effective', 'data mining', 'density', 'disorder risk', 'lymphatic circulation', 'novel', 'novel strategies', 'obesity treatment', 'preference', 'public health research', 'reconstruction', 'sex', 'study population', 'tool', 'virtual', 'weight loss intervention']",NHLBI,GEORGE WASHINGTON UNIVERSITY,R21,2016,194340,-0.009712037374189445
"Machine learning with generative mixture models for fetal monitoring DESCRIPTION (provided by applicant): For many years, there has been a concerted effort to automate the analysis of fetal heart rate (FHR) rhythms. However, despite significant advances in biomedical signal analysis, there has not been any significant improvement in automated decision support systems. FHR monitoring is now ubiquitous throughout delivery rooms, especially using the non-invasive Doppler monitor, but also using the fetal scalp electrode. Physician classification of fetal heart rate patterns is known to be a non-trivial problem because of significant inter and intra-observer variability of diagnosis. This has led to a marked increase in the number of caesarean deliveries, thereby increasing risk to the fetus and mother in many cases. This has further motivated the machine learning community to automate the classification procedure in the interest of accuracy and consistency as well as robustness with respect to noise. Usual approaches to this involve some type of supervised classification procedure, where the algorithm output on training data is compared with a ""gold-standard"" physician classification, followed by testing and validation on new datasets. However, since physician classification can be unreliable in the presence of the aforementioned diagnostic variability, as well as significant tracing noise, we propose the use of unsupervised algorithms to cluster FHR data records into clinically useful categories. We use nonparametric Bayes theory and Markov-time-dependence models for the evolution of feature sequences to propose methods that will achieve improved accuracy. The methods involve extraction of feature sequences from FHR time series data, which are modeled as samples from finite or infinite Dirichlet mixture models. We then use Gibbs sampling to obtain the cluster probabilities for each dataset. Clustering outcomes are compared against direct physician diagnosis and our current results are seen to be in broad agreement with them, while still giving new information on the character of different sub-groups of FHR records. With the proposed research, further gains in classification performance will be made. PUBLIC HEALTH RELEVANCE: Fetal heart rate monitoring is now commonly used during childbirth and, at present, physicians read and interpret these data to classify fetal heart rate patterns and make sure that the baby is not in distress during the course of labor. However, there is great variability in how individual doctors interpret the tracings and this has led increases in the number of caesarean deliveries, thereby potentially increasing risk to both mothers and babies. Thus there has been a concerted effort from the machine learning community to develop an accurate automatic reading and classification procedure so that correct interpretation of fetal heart rates during labor is more diagnostic and consistent.",Machine learning with generative mixture models for fetal monitoring,9018050,R21HD080025,"['Agreement', 'Algorithms', 'Apgar Score', 'Bayesian Method', 'Behavioral', 'Birth', 'Categories', 'Cesarean section', 'Childbirth', 'Classification', 'Clinical', 'Consensus', 'Data', 'Data Set', 'Decision Support Systems', 'Delivery Rooms', 'Dependence', 'Dependency', 'Diagnosis', 'Diagnostic', 'Distress', 'Electrodes', 'Evolution', 'Feedback', 'Fetal Heart', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Freedom', 'Gold', 'Health', 'Individual', 'Intraobserver Variability', 'Joints', 'Knowledge', 'Label', 'Learning', 'Litigation', 'Machine Learning', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Monte Carlo Method', 'Mothers', 'Motivation', 'Noise', 'Outcome', 'Outcome Measure', 'Output', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Probability', 'Procedures', 'Process', 'Reading', 'Records', 'Research', 'Risk', 'Sampling', 'Scalp structure', 'Series', 'Signal Transduction', 'System', 'Testing', 'Time', 'Training', 'Umbilical cord structure', 'Uncertainty', 'Uterine Contraction', 'Validation', 'Work', 'base', 'cost', 'fetal', 'heart rate monitor', 'improved', 'interest', 'learning community', 'pressure', 'stem', 'theories', 'vector']",NICHD,STATE UNIVERSITY NEW YORK STONY BROOK,R21,2016,193120,-0.030959764117938757
"Impact of Crouch Gait and Surgical Treatment on Knee Mechanics and Function DESCRIPTION (provided by applicant):  Children with Cerebral Palsy (CP) often exhibit crouch gait, which is characterized by excessive knee flexion during stance. This form of walking is extremely fatiguing and tends to progress until eventually walking ability ceases. A newly revived surgical procedure, distal femoral extension osteotomy (DFEO) and patellar tendon advancement (PTA), simultaneously addresses both knee flexion contractures and patella alta (superiorly displaced patella) that often co-exist in those with crouch. Initial outcoe studies demonstrate greater improvements in gait than conventional surgical treatments. However, complication rates remain high and some patients exhibit little to no improvement in gait after surgery. The first aim of this study is to investigate the effects of patella position, crouch and surgical parameters on functional knee mechanics. Computational knee models will be created that include detailed representations of ligament and articular cartilage geometry within the tibiofemoral and patellofemoral joints. Patella alta and knee flexion contractures will be introduced, and surgical simulations will be performed virtually. The computational models will then be used to simulate knee mechanics when walking in normal, and mild, moderate, and severe crouch gait postures. Probabilistic simulations will then be used to investigate how variability in physical characteristics and surgical factors can contribute to variable outcomes. The effects of surgery and crouch gait on cartilage pressure patterns will also be determined, which is relevant for understanding subsequent skeletal growth and long-term cartilage health. The second aim investigates whether a combination of quantitative measures of physical characteristics and surgical parameters can retrospectively classify post-surgical gait performance. Pre- and post-surgical x- rays will be used to quantitatively measure the Koshino index (metric of patella alta/baja), the magnitude and location of the DFEO, and the PTA advancement distance in patients who previously underwent DFEO+PTA. Pre-surgical measures of knee flexion contracture and spasticity will also be obtained. Pre- and post-operative gait analysis data will be used to assess changes in gait mechanics, while functional surveys will assess changes in performance on activities of daily living. The random forest algorithm will then be used to identify decision trees and associate predictor variables that can classify those patients whose gait and overall function improved after surgery. These results will be interpreted in the context of modeling results from Aim 1, thereby providing a potential mechanistic explanation for clinical observations. The research will impact innumerable CP patients as the DFEO+PTA surgical procedures are adopted around the world, and will also set the groundwork for more rigorous scientific study of other procedures used to treat gait disorders. PUBLIC HEALTH RELEVANCE:  Children with Cerebral Palsy (CP) often exhibit a crouch walking posture, which can be extremely fatiguing, painful and disabling as a child grows. Orthopedic surgical procedures are used to correct the physical abnormalities that contribute to crouch, but clinical outcomes remain variable and difficult to predict. This study uses a combination of computational models and retrospective analyses of clinical data to identify the physical and surgical treatment factors that can best restore more normal walking function in CP patients.",Impact of Crouch Gait and Surgical Treatment on Knee Mechanics and Function,8975231,R21HD084213,"['Activities of Daily Living', 'Address', 'Adopted', 'Adoption', 'Aftercare', 'Age', 'Algorithms', 'Biomechanics', 'Bone Growth', 'Cartilage', 'Cerebral Palsy', 'Characteristics', 'Child', 'Clinical', 'Clinical Data', 'Clinical Research', 'Complication', 'Computer Simulation', 'Contracture', 'Coupled', 'Data', 'Decision Trees', 'Distal', 'Exhibits', 'Fatigue', 'Gait', 'Gait abnormality', 'Geometry', 'Growth', 'Health', 'Height', 'Individual', 'Inferior', 'Joints', 'Knee', 'Knee bone', 'Ligaments', 'Location', 'Machine Learning', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Motion', 'Musculoskeletal', 'Operative Surgical Procedures', 'Orthopedic Surgical Procedures', 'Osteotomy', 'Outcome', 'Outcome Study', 'Pain', 'Patient Selection', 'Patients', 'Pattern', 'Performance', 'Phase', 'Positioning Attribute', 'Postoperative Period', 'Posture', 'Procedures', 'Research', 'Research Personnel', 'Selection Criteria', 'Severities', 'Surveys', 'Techniques', 'Tendon structure', 'Testing', 'Treatment Factor', 'Walking', 'Work', 'articular cartilage', 'crouch gait', 'forest', 'functional outcomes', 'gait examination', 'human subject', 'improved functioning', 'indexing', 'knee mechanics', 'pressure', 'prevent', 'quadriceps muscle', 'restoration', 'simulation', 'skeletal', 'spasticity']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R21,2016,168604,-0.011602120963319168
"IGF::OT::IGF ARTIFICIAL INTELLIGENCE IN MEDICINE INC: HHSN261201500033I- TASK ORDER 2; POP 9/26/2016-9/25/2017 The purpose of this acquisition is to 1) maintain and update the existing Surveillance Epidemiology and End Results (SEER) ePath network; 2) expand the SEER network to additional pathology laboratories; 3) expand electronic data capture to include electronic reports from diagnostic imaging, and 4) install cancer data forwarding module in previously installed ePath laboratories n/a",IGF::OT::IGF ARTIFICIAL INTELLIGENCE IN MEDICINE INC: HHSN261201500033I- TASK ORDER 2; POP 9/26/2016-9/25/2017,9361217,61201500033I,"['Artificial Intelligence', 'Data', 'Diagnostic Imaging', 'Electronics', 'Laboratories', 'Malignant Neoplasms', 'Medical Surveillance', 'Medicine', 'Pathology', 'Reporting', 'Update', 'electronic data']",NCI,"ARTIFICIAL INTELLIGENCE IN MEDICINE, INC",N03,2016,1999910,-0.021804999269604122
"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis.         PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.            ",Developing Classification Criteria for the Uveitides,9081760,R01EY026593,"['Acute', 'Adult', 'Affect', 'Age', 'Agreement', 'Anatomy', 'Anterior uveitis', 'Antiviral Agents', 'Blindness', 'Child', 'Choroiditis', 'Chronic', 'Classification', 'Clinical Research', 'Clinical Trials', 'Collection', 'Complex', 'Consensus', 'Cytomegalovirus Retinitis', 'Data', 'Data Analyses', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Disease', 'Enrollment', 'Ensure', 'Epidemiology', 'Future', 'Genomics', 'Goals', 'Immune', 'Immunosuppression', 'Infection', 'Inflammation', 'Informatics', 'Intermediate Uveitis', 'Machine Learning', 'Mediating', 'Nomenclature', 'Outcomes Research', 'Panuveitis', 'Pathogenesis', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Pigments', 'Population', 'Posterior Uveitis', 'Publications', 'Research', 'Retinitis', 'Risk Factors', 'Sensitivity and Specificity', 'Specificity', 'Standardization', 'Syndrome', 'Techniques', 'Terminology', 'Translational Research', 'United States', 'Uveitis', 'Vision', 'Visual impairment', 'Voting', 'Work', 'age group', 'age related', 'antimicrobial', 'birdshot chorioretinitis', 'cost', 'outcome forecast', 'public health relevance', 'symposium', 'tool', 'web page', 'working group']",NEI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2016,428590,-0.013954191307579378
"Automated Ecological Video Identification of Physical Activity (E-VIP) Software ﻿    DESCRIPTION (provided by applicant): This proposal addresses multiple priorities of PAR-12-197 ""Improving Diet and Physical Activity (PA) Assessment"" by advancing assessment of population PA in common settings. Physical inactivity is responsible for ≈200,000 deaths in the US and 5 million deaths worldwide annually. About 10% of breast and 10% of colon cancers are attributable to insufficient PA, and inactivity causes 9% of total premature mortality. Parks, schools and youth sports are important contributors of PA that are relevant to a majority of the population. Supporting PA in these settings would contribute to improvements in population levels of PA and disease prevention and control. We will develop a novel video analysis software system, named E-VIP (Ecological Video Identification of PA), which will estimate the number of people and aggregated volume of PA from video recordings of PA- relevant settings. E-VIP will provide automated and continuous (rather than momentary) assessment, which will allow ongoing feedback to inform adaptive interventions and decision making. E-VIP is based on computer science methods used to count crowds and identify behaviors. We will train the E-VIP machine learning algorithm on 32,400 seconds of video from 2 parks, 2 schools, and 2 youth sports settings. Participants will engage in a variety of activities while wearing accelerometers to capture PA intensity in Metabolic Equivalents (METs). The testing phase involves capturing 900, 5-minute videos of free-living behavior across 4 parks, 4 schools, and 4 youth sports settings, with half of the settings/zones being the same as from the training phase. A range of activities and density of people will be captured in both the training and testing phase to maximize coverage of more-difficult high-density situations. Systematic direct observation will be conducted on each time sample to provide the criterion measure for testing validity. The metrics that will be tested include the average number of people, average proportion of people in each activity category (sedentary, light, moderate, vigorous, very vigorous), and sum PA MET-minutes in the setting over the 5-minute (or any given) time period. A gender and age group classifier will be explored. PE classes taught by PE specialists vs classroom teachers will be compared to test construct validity of E-VIP. Bland Altman methods and intraclass correlation coefficients will be used to assess agreement. Potential sources of error such as occlusions (e.g., trees, shadows, other people) will be assessed using moderator analyses. By automating ecological PA assessment, E-VIP will be feasible for widespread use. E-VIP's capability of continuous assessment will improve precision by collecting higher resolution data than collected by existing direct observation tools. When embedded in specific settings through commonly-used security cameras or webcams, or by purposefully placing video recorders, E-VIP will be capable of ongoing assessment which will inform public health surveillance, intervention, and evidence-based decision making (e.g., optimizing intervention strategies, monitoring school Physical Education mandates, providing needs assessment prior to and evaluation after environmental modifications).         PUBLIC HEALTH RELEVANCE: This study will develop and test a software for automated ongoing measurement of use and physical activity intensity from video recordings in specific settings such as parks, schools (including Physical Education), and youth sports. This innovative software will support adaptive multilevel interventions and evidence-based decision making in physical activity-relevant settings to optimize strategies for improving population health.                ",Automated Ecological Video Identification of Physical Activity (E-VIP) Software,9035822,R21CA194492,"['Accelerometer', 'Address', 'Adolescent', 'Adult', 'Agreement', 'Algorithmic Software', 'Algorithms', 'Area', 'Behavior', 'Breast', 'Categories', 'Cessation of life', 'Child', 'Colon Carcinoma', 'Complex', 'Computer software', 'Crowding', 'Data', 'Decision Making', 'Diet', 'Educational process of instructing', 'Elderly', 'Engineering', 'Error Sources', 'Evaluation', 'Evidence based intervention', 'Exhibits', 'Feedback', 'Future', 'Gender', 'Goals', 'Hour', 'Individual', 'Intervention', 'Life', 'Light', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metabolic', 'Methods', 'Modification', 'Monitor', 'Movement', 'Names', 'Needs Assessment', 'Participant', 'Phase', 'Physical Education', 'Physical Education and Training', 'Physical activity', 'Population', 'Population Surveillance', 'Premature Mortality', 'Process', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Schools', 'Security', 'Source', 'Specialist', 'Sports', 'Sum', 'System', 'Testing', 'Time', 'Training', 'Trees', 'Validation', 'Variant', 'Video Recording', 'Visual', 'Work', 'Youth', 'age group', 'base', 'computer science', 'cost', 'density', 'digital', 'disorder control', 'disorder prevention', 'improved', 'innovation', 'novel', 'physical inactivity', 'population health', 'prototype', 'public health relevance', 'sedentary', 'software systems', 'teacher', 'tool', 'trend']",NCI,"CHILDREN'S MERCY HOSP (KANSAS CITY, MO)",R21,2016,199277,-0.01406161781616264
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability.         PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.        ",Capti Screen Reading Assistant for Goal Directed Web Browsing,9048176,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Learning', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'empowered', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2016,500000,-0.003447010608157535
"Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research ﻿    DESCRIPTION (provided by applicant): This Phase II project aims to continue development of a commercial quality, innovative cloud hosted information management system, called Climb 2.0(tm) that will increase laboratory efficiency and provide improved capabilities for research laboratories. Climb is designed to offer integrated laboratory process management modules that include mobile communications tools data monitoring and alert systems, and integrated access to Microsoft Azure Cloud(tm) Machine Learning and Stream Analytics services. Initially, Climb 2.0 will target animal model research laboratories; however, the core of the platform is designed to be adaptable to nearly any research type or related industry. Current research information management systems are primarily designed as record-keeping tools with little or no direct focus on laboratory efficiency or in enhancing value of the research data. They also do not leverage emergent mobile device technologies, social media frameworks, and data analysis and storage capabilities of cloud computing. Many laboratories still use paper as their primary recording system. Paper data logging is then followed by secondary data entry into a laboratory database. These systems are error prone, time consuming and lead to laboratory databases with significant time lags between data acquisition and data entry. Moreover, they do not recognized cumulative data relationships, which may identify important trends, and researchers often miss windows of opportunity to take action on time-sensitive events. In Phase I, RockStep Solutions demonstrated feasibility of an innovative Cloud Information Management Bundle system, Climb, which will increase efficiency and improve capabilities in animal model data management. During Phase I, a beta version of Climb was successfully developed and tested against strict performance metrics as a proof of concept. We successfully built a prototype with working interfaces that integrates real-time communication technologies with media capabilities of mobile devices. Phase II proposes four specific Aims: 1) Develop the technology infrastructure to support the secure and scalable Software as a Service (SaaS) deployment of Climb for enterprise commercial release; 2) Develop and extend the Phase-I prototype Data Monitoring and Messaging System (DMMS) into a platform ready for production use; 3) Extend Climb's DMMS adding a Stream Analytics engine to support Internet of Things (IoT) devices and streaming media; 4) Deploy a beta release of Climb at partner research labs, test and refine the product for final commercialization. To ensure Climb is developed with functionality and tools relevant to research organizations, RockStep Solutions has established collaborations with key beta sites to test all of the major functionality developed in this proposal. IMPACT: By leveraging emergent technologies and cloud computing, Climb offers several advantages: 1) enables real-time communications using familiar tools among members of research groups; 2) reduces the risk of experimental setbacks, and 3) enables complex experiments to be conducted efficiently.         PUBLIC HEALTH RELEVANCE: The NIH Invests approximately $12 billion each year in animal model research that is central to both understanding basic biological processes and for developing applications directly related to improving human health. More cost-effective husbandry and colony management techniques, equipment, and new approaches to improve laboratory animal welfare and assure efficient and appropriate research use (e.g., through cost savings and reduced animal burden) are high priorities for NIH. RockStep Solutions proposes to meet this need by integrating existing and emergent software and communication technologies to create a novel solution, Climb 2.0, for research animal data management. Climb 2.0 extracts immediate value of data in animal research laboratories and extends the database into a multimedia communication network, thus enabling science that would be impractical to conduct with traditional methods.        ",Novel Use of Emergent Technologies to Improve Efficiency of Animal Model Research,9138555,R44GM112206,"['Address', 'Algorithms', 'Animal Experimentation', 'Animal Model', 'Animal Welfare', 'Animals', 'Biological Process', 'Biomedical Research', 'Clinical Laboratory Information Systems', 'Cloud Computing', 'Collaborations', 'Communication', 'Communication Tools', 'Complex', 'Computer software', 'Computers', 'Consumption', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Security', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Devices', 'Emerging Technologies', 'Ensure', 'Equipment', 'Equipment and supply inventories', 'Event', 'Feedback', 'Future', 'Goals', 'Health', 'Health system', 'Human', 'Industry', 'Information Management', 'Internet', 'Investments', 'Laboratories', 'Laboratory Animals', 'Laboratory Research', 'Lead', 'Machine Learning', 'Management Information Systems', 'Methods', 'Monitor', 'Motion', 'Multimedia', 'Notification', 'Paper', 'Performance', 'Phase', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Science', 'Secure', 'Services', 'Site', 'Stream', 'System', 'Techniques', 'Technology', 'Testing', 'The Jackson Laboratory', 'Time', 'United States National Institutes of Health', 'Work', 'analytical tool', 'animal data', 'base', 'cloud based', 'commercialization', 'computerized data processing', 'cost', 'cost effective', 'data acquisition', 'data management', 'design', 'encryption', 'good laboratory practice', 'graphical user interface', 'handheld mobile device', 'improved', 'innovation', 'laptop', 'meetings', 'member', 'novel', 'novel strategies', 'predictive modeling', 'programs', 'prototype', 'public health relevance', 'research study', 'social media', 'software as a service', 'success', 'time interval', 'tool', 'trend', 'usability']",NIGMS,"ROCKSTEP SOLUTIONS, INC.",R44,2016,750063,-0.03859110729903139
"Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination Project Summary / Abstract Between 1.6 and 3.8 million people each year suffer a mild TBI in the US alone. Reliable diagnosis and prompt treatments are vital to managing the often-serious short and long-term sequelae resulting from mild TBI. However, a reliable objective and accurate method for mild TBI diagnosis outside of a hospital setting, and in particular for determining RTP readiness, has eluded the clinical community. Current diagnosis and RTP assessments are based on patient symptoms, neurocognitive evaluations, and / or physical performance testing. Use of symptom scales are problematic for several reasons including subjectivity and reliability. Neurocognitive evaluations and physical tests (such as balance tests), although less subjective, require pre- injury baseline testing of subjects due to inherently large subject-to-subject variations in evaluation performances. Due to these reasons, current mild TBI diagnostic methods have limited applications and are not suitable for a significant majority of patients who suffer mild TBI. This project is aimed at developing an objective diagnosis of mild traumatic brain injury (mild TBI) based on physiologic changes in a patient after injury and providing a platform capable of RTP guidance. The method is based on quantification of well-known physiologic changes after a concussion, i.e. the impairment of autonomic function and altered cerebral blood flow (CBF) as measured with transcranial Doppler (TCD). The novelty of the proposed approach is the use of a recently-developed analytical machine learning framework for the analysis of the CBF velocity (CBFV) waveforms. In contrast to previous methods used before, the proposed approach utilizes the entire shape of the complex CBFV waveform, thus obtaining subtle changes in blood flow that are lost in other analysis methods. Additionally, comprehensive verification between our platform and MRI will be performed following injury resulting in the first scientific experiments of this kind. The ultimate goal of this Phase II SBIR is to commercialize an objective and accurate software algorithm for reliable diagnosis and management of sports concussions which does not currently exist. The outcome will be a software suite integrated into existing TCD and will be marketed to emergency departments, neurology clinics, and other healthcare providers involved in mild TBI diagnosis and RTP management. Project Narrative Traumatic brain injury (TBI) is a serious public health problem in the United States contributing to a substantial number of deaths and cases of permanent disability. Mild TBI concussions account for over 80% of all TBIs sustained and a major problem is the high rate of mis-diagnosis due to lack of objective measures and delayed onset of symptoms. This project aims to develop the first objective concussion evaluation method using a novel analysis platform that can obtain subtle, physiologic changes in cerebral hemodynamics. Successful completion of this project will result in a portable diagnostic device suitable for use in many scenarios where concussion diagnosis is inaccurate or unavailable today.",Advanced morphological analysis of cerebral blood flow for acute concussion diagnosis and return-to-play determination,9202982,R44NS092209,"['Accident and Emergency department', 'Accounting', 'Acute', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Area Under Curve', 'Assessment tool', 'Blood Flow Velocity', 'Blood flow', 'Brain Concussion', 'Cerebrovascular Circulation', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Controlled Study', 'Core-Binding Factor', 'Data', 'Data Analytics', 'Data Collection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Evaluation', 'Functional disorder', 'Future', 'Goals', 'Gold', 'Guidelines', 'Health Personnel', 'Hospitals', 'Image', 'Impairment', 'Injury', 'Letters', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Marketing', 'Measures', 'Methods', 'Modeling', 'Neurocognitive', 'Neurologist', 'Neurology', 'Outcome', 'Patients', 'Pediatric Neurology', 'Performance', 'Persons', 'Phase', 'Physical Performance', 'Physicians', 'Physiological', 'Play', 'Public Health', 'Publications', 'Readiness', 'Recovery', 'Research', 'Resolution', 'Risk', 'Severities', 'Shapes', 'Site', 'Small Business Innovation Research Grant', 'Spin Labels', 'Sports', 'Sports Medicine', 'Symptoms', 'Syndrome', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Traumatic Brain Injury', 'Ultrasonography', 'United States', 'Variant', 'abstracting', 'balance testing', 'base', 'brain health', 'cerebral hemodynamics', 'clinical Diagnosis', 'diagnostic accuracy', 'disability', 'hemodynamics', 'high school', 'injured', 'innovation', 'mild traumatic brain injury', 'novel', 'performance tests', 'prevent', 'programs', 'relating to nervous system', 'research study', 'success', 'tool']",NINDS,"NEURAL ANALYTICS, INC.",R44,2016,1500000,-0.01040101184822115
"Objective assessment of surgical competence in a septoplasty model ﻿    DESCRIPTION (provided by applicant): To ensure patient safety, educators must train surgeons to set standards of competency, public health officials should put in place policies to ensure surgeons remain competent and surgeons should only perform surgeries that they are competent to perform. Measuring surgeon's technical skill is crucial part of determining if they are competent. Traditionally surgical skill is assessed most commonly during training using subjective non-validated metrics. This leads to variation in the definition of competency. Recent policies set forth by the Accreditation Council of Graduate Medical Education- the governing body for graduate medical education, mandate that technical skill be measured objectively. Currently, there are few valid objective measures available to measure technical competence. Our research will yield a set of tools and methodologies that can be deployed to across medical training programs to objectively measure surgical skill and competence. This platform is also capable of developing new objective measure of skill and competence. Specifically, first, we will develop an objective skills assessment platform, and establish standard data collection and quality assurance protocols for systematic deployment of our platform across multiple institutions. Second, our work will result in automated algorithms and analytic tools to objectivel measure skill using data captured with our platform. Third, we will establish objective methods to determine whether a surgeon is competent to perform surgery. Fourth, we will test the reliability and validity of our assessment tools. We will conduct our study using septoplasty as the prototype test-bed procedure. Septoplasty is a commonly performed procedure (more than 260,000 cases per year) and is a key index surgery by which residents in otolaryngology are evaluated. Our project lays the groundwork for subsequent research to establish national standards for objective skill and competency using data aggregated from numerous training programs in the country. PUBLIC HEALTH RELEVANCE: Policies for graduate medical education require that surgical competency be objectively determined, but currently available technology and methods do not yield objective assessments for surgical skill. Our project aims to provide educators with an integrated objective skills assessment platform and tools for objective determination of competency, which can be readily deployed across graduate surgical training programs in the country.",Objective assessment of surgical competence in a septoplasty model,9112985,R01DE025265,"['Accreditation', 'Address', 'Algorithms', 'American', 'Area', 'Assessment tool', 'Beds', 'Cessation of life', 'Competence', 'Computer Assisted', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Collection', 'Data Quality', 'Data Set', 'Ensure', 'Evaluation', 'Exploratory/Developmental Grant for Diagnostic Cancer Imaging', 'Foundations', 'Health', 'Inferior', 'Institution', 'Learning', 'Life', 'Machine Learning', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Otolaryngology', 'Patient Care', 'Patient-Focused Outcomes', 'Phase', 'Philosophy', 'Physicians', 'Pilot Projects', 'Policies', 'Postoperative Complications', 'Predictive Value', 'Procedures', 'Protocols documentation', 'Public Health', 'Quality Control', 'Repeat Surgery', 'Research', 'Research Infrastructure', 'Research Support', 'Residencies', 'Site', 'Surgeon', 'System', 'Technical Expertise', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Validity and Reliability', 'Variant', 'Work', 'base', 'graduate medical education', 'high risk', 'indexing', 'inter-institutional', 'patient safety', 'programs', 'prototype', 'quality assurance', 'skills', 'success', 'tool']",NIDCR,JOHNS HOPKINS UNIVERSITY,R01,2016,505672,0.004235940448360421
"In vivo Characterization of Stents using Intravascular OCT Imaging DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel. PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,9097737,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Health', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shapes', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Surrogate Markers', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'preclinical trial', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2016,447440,-0.010901879233420527
"Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired ﻿    DESCRIPTION (provided by applicant):  Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired Summary CamIO (""Camera Input-Output"") is a novel camera system designed to make physical objects (including documents, maps and 3D objects such as architectural models) fully accessible to people who are blind or visually impaired.  It works by providing real-time audio-haptic feedback in response to the location on an object that the user is pointing to, which is visible to the camera mounted above the workspace.  While exploring the object, the user can move it freely; a gesture such as ""double-tapping"" with a finger signals for the system to provide audio feedback about the location on the object currently pointed to by the finger (or an enhanced image of the selected location for users with low vision).  Compared with other approaches to making objects accessible to people who are blind or visually impaired, CamIO has several advantages:  (a) there is no need to modify or augment existing objects (e.g., with Braille labels or special touch-sensitive buttons), requiring only a low- cost camera and laptop computer; (b) CamIO is accessible even to those who are not fluent in Braille; and (c) it permits natural exploration of the object with all fingers (in contrast with approaches that rely on the use of a special stylus).  Note also that existing approaches to making graphics on touch-sensitive tablets (such as the iPad) accessible can provide only limited haptic feedback - audio and vibration cues - which is severely impoverished compared with the haptic feedback obtained by exploring a physical object with the fingers.  We propose to develop the necessary computer vision algorithms for CamIO to learn and recognize objects, estimate each object's pose to help determine where the fingers are pointing on the object, track the fingers, recognize gestures and perform OCR (optical character recognition) on text printed on the object surface.  The system will be designed with special user interface features that enable blind or visually impaired users to freely explore an object of interest and interact with it naturally to access the information they want, which will be presented in a modality appropriate for their needs (e.g., text-to-speech or enhanced images of text on the laptop screen).  Additional functions will allow sighted assistants (either in person or remote) to contribute object annotation information.  Finally, people who are blind or visually impaired - the target users of the CamIO system - will be involved in all aspects of this proposed research, to maximize the impact of the research effort.  At the conclusion of the grant we plan to release CamIO software as a free and open source (FOSS) project that anyone can download and use, and which can be freely built on or modified for use in 3rd-party software.         PUBLIC HEALTH RELEVANCE:  For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is insufficient access to a wide range of everyday objects needed for daily activities that require visual inspection on the part of the user.  Such objects include printed documents, maps, infographics, and 3D models used in science, technology, engineering, and mathematics (STEM), and are abundant in schools, the home and the workplace.  The proposed research would result in an inexpensive camera-based assistive technology system to provide increased access to such objects for the approximately 10 million Americans with significant vision impairments or blindness.                ",Enabling Audio-Haptic Interaction with Physical Objects for the Visually Impaired,9030162,R01EY025332,"['3D Print', 'Access to Information', 'Adoption', 'Algorithms', 'American', 'Blindness', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Development', 'Economics', 'Employment', 'Ensure', 'Evaluation', 'Feedback', 'Fingers', 'Focus Groups', 'Gestures', 'Goals', 'Grant', 'Home environment', 'Image', 'Information Systems', 'Label', 'Lasers', 'Learning', 'Location', 'Maps', 'Modality', 'Modeling', 'Output', 'Performance', 'Persons', 'Printing', 'Procedures', 'Process', 'Research', 'Rotation', 'Running', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self-Help Devices', 'Signal Transduction', 'Speech', 'Surface', 'System', 'Tablets', 'Tactile', 'Technology', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Translations', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'braille', 'cost', 'design', 'experience', 'haptics', 'heuristics', 'interest', 'laptop', 'novel', 'open source', 'optical character recognition', 'public health relevance', 'research study', 'response', 'three-dimensional modeling', 'vibration']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2016,416574,-0.012116934805377266
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,9213710,R00AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R00,2016,249000,-0.014493705446170704
"The oral microbiome and enterosalivary circulation of nitric oxide in HIV. ﻿    DESCRIPTION (provided by applicant): Chronic HIV is associated with increased risk of pulmonary and cardiovascular complications. Despite use of antiretroviral therapy, rates of even rare vascular complications such as pulmonary hypertension occur upwards of 25 times that in HIV- individuals. The cause for such a high rate of vascular complications in HIV is unknown. Nitric oxide (NO) is a critically important signaling molecule that is produced by the vascular endothelium and acts as a vasodilator and regulator of cardiovascular health. Reduction of nitrate to nitrite and nitric oxide by commensal oral bacteria has recently been implicated in the maintenance of vascular function. The enterosalivary NO pathway is an important component of nitric oxide generation as nitrate is converted to nitrite by a series of bacterial enzymes in the mouth, which is then swallowed and either directly converted to NO or absorbed into the bloodstream where it exerts systemic NO-like effects. The enterosalivary NO pathway depends on viable populations of oral bacteria and helps regulate blood pressure and mitigate vascular injury. However, little is known about the specific bacterial populations involved or the contribution to systemic NO availability and vascular injury and disease. Our preliminary studies suggest that HIV+ individuals have a different profile of oral commensal bacteria (oral microbiome) than HIV- individuals that involves key nitrate reduction pathways. This study proposes the novel hypothesis that the accelerated cardio- and pulmonary vascular disease seen in HIV is due in part to changes in the oral microbiome that favor a disruption of the enterosalivary NO pathway, reduced NO availability, and chronic vascular injury. To test this hypothesis, the oral microbiome of an established cohort of 315 HIV+ and HIV- participants will be characterized using culture-independent sequencing techniques in banked oral wash samples. Expression of specific bacterial nitrate-reducing enzymes will be measured, and results correlated with available serological markers of vascular damage, echocardiographic testing, and radiographic measures of vascular injury. Results will directly inform future clinical enrollment of a prospective trial examining real-time nitrate metabolism, systemic NO distribution, and associated physiological effects. These investigations will offer the first stepsin understanding a novel pathway of HIV-associated vascular disease and inform development of targeted therapies. Additionally, this NRSA award will provide the candidate, a pulmonary medicine fellow, the opportunity for further training in pulmonary vascular medicine and for developing skills in HIV/AIDS and microbiome research. The candidate will acquire extensive training in basic and advanced laboratory techniques, biostatistics, and clinical study design through labwork, conferences, and a master's degree in clinical/translational research. The resources and experience of mentors Dr. Morris, an expert in HIV-related lung disease and the microbiome, and Dr. Gladwin, an expert in NO and pulmonary vascular disease, combined with the expansive array of resources available at the University of Pittsburgh, will support the candidate's successful development.         PUBLIC HEALTH RELEVANCE: Pulmonary vascular and cardiovascular diseases remain a major source of morbidity and mortality in HIV-infected individuals in the current era of effective antiretroviral therapy. Reduction of nitrate to nitrite and nitric oxide by commensal oral bacteria has recently been implicated in the maintenance of vascular function. Normal populations of bacteria that live in the mouth are key in maintaining adequate levels of nitric oxide and thus important in vascular function, but these key bacteria may be altered in those with HIV and contribute to excess pulmonary vascular and cardiovascular risk. This proposal will determine changes in the oral microbiome in HIV, the impact of these changes on nitrate reduction pathways, and relationship to markers of vascular function.            ",The oral microbiome and enterosalivary circulation of nitric oxide in HIV.,9103887,F32HL128165,"['3-nitrotyrosine', 'AIDS/HIV problem', 'Activities of Daily Living', 'Affect', 'Antioxidants', 'Arginine', 'Atherosclerosis', 'Award', 'Bacteria', 'Bioavailable', 'Biology', 'Biometry', 'Blood Circulation', 'Blood Vessels', 'Brain natriuretic peptide', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Physiology', 'Cardiovascular system', 'Catalytic Domain', 'Cerebrovascular Disorders', 'Chest', 'Chronic', 'Clinical', 'Clinical Research', 'Communities', 'DNA Sequence', 'Data', 'Deglutition', 'Development', 'Diet', 'Disease', 'Echocardiography', 'Enrollment', 'Enzymes', 'Exhibits', 'Fingerprint', 'Future', 'Generations', 'Glutathione', 'Goals', 'HIV', 'HIV Infections', 'Human', 'Hypoxia', 'IL6 gene', 'Immune', 'Individual', 'Inflammation', 'Injury', 'Interruption', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Lead', 'Life', 'Link', 'Lung', 'Lung diseases', 'Machine Learning', 'Maintenance', 'Maps', 'Master&apos', 's Degree', 'Measures', 'Mediating', 'Medicine', 'Mentors', 'Metabolism', 'Metagenomics', 'Methods', 'Mitochondria', 'Modeling', 'Morbidity - disease rate', 'Mucosal Immunity', 'Myocardial Infarction', 'N,N-dimethylarginine', 'N-terminal', 'NBL1 gene', 'NOS3 gene', 'National Research Service Awards', 'Nitrate Reductases', 'Nitrates', 'Nitric Oxide', 'Nitric Oxide Pathway', 'Nitric Oxide Synthase', 'Nitrite Reductase', 'Nitrites', 'Nitrogen', 'Oral', 'Oral cavity', 'Oxidative Stress', 'Oxygen', 'Participant', 'Pathogenesis', 'Pathway interactions', 'Phylogenetic Analysis', 'Physiological', 'Population', 'Production', 'Pulmonary Hypertension', 'Pulmonary artery structure', 'Pulmonology', 'Reperfusion Injury', 'Research', 'Research Design', 'Resources', 'Ribosomal DNA', 'Risk', 'Role', 'Salts', 'Sampling', 'Series', 'Serological', 'Signaling Molecule', 'Source', 'Stomach', 'Stress', 'Stretching', 'Supplementation', 'Taxon', 'Techniques', 'Testing', 'Time', 'Training', 'Translational Research', 'Universities', 'Vascular Diseases', 'Vascular Endothelium', 'Vasodilator Agents', 'antiretroviral therapy', 'base', 'blood pressure reduction', 'blood pressure regulation', 'cardiovascular health', 'cardiovascular risk factor', 'career', 'cohort', 'commensal microbes', 'experience', 'high risk', 'immune activation', 'improved', 'microbial', 'microbial community', 'microbiome', 'mortality', 'new therapeutic target', 'nitrogen metabolism', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'oral bacteria', 'oral commensal', 'oral microbiome', 'pressure', 'prevent', 'prospective', 'public health relevance', 'pyrosequencing', 'reconstruction', 'serological marker', 'skills', 'stem', 'symposium', 'targeted treatment']",NHLBI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F32,2016,70854,-0.056059233759827104
"Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility ﻿    DESCRIPTION (provided by applicant): Innovative Design Labs (IDL) proposes to create a system to improve the mobility and control of exoskeletons. Recent research has found that 3.86 million Americans require wheelchairs and the number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk, thus providing a way to more fully reintegrate these individuals into society. Our proposal seeks to address one of the hurdles limiting the widespread adoption of exoskeletons in the home and community-the inability of the user to dynamically control gait parameters. This concept has the potential to significantly change the way exoskeletons work and facilitate their adoption into the market. Hypothesis: We hypothesize that the proposed solution will provide users a practical way to adjust their suit's gait to precisely achieve their navigational goals. Specific Aims: Phase I: 1) Build a prototype and Perform Preliminary Laboratory Testing; 2) Develop and Benchmark Algorithms; and 3) Perform Pilot Human Study of Prototype with Exoskeleton Subjects. Phase II: 1) Develop Customized, Production-Ready Hardware and Firmware 2) Integrate with Exoskeleton Control System; and 3) Perform an evaluation of the system through human study testing.         PUBLIC HEALTH RELEVANCE: Recent research has found that 3.86 million Americans require wheelchairs and that number has been increasing annually by an average annual rate of 5.9% per year. While wheelchairs provide freedom, allowing users to be independent as well as reducing dependence upon others, wheelchair use is not physically or emotionally equivalent to walking and is often thought to limit community participation and thus exacerbate social isolation. Robotic exoskeletons/bionic suits have the potential to enable these individuals to stand up and walk thereby providing a way to more fully reintegrate these individuals into society.        ",Environmental Imaging and Control for Exoskeletons to Improve Safety and Mobility,9140712,R44AG053890,"['Address', 'Adoption', 'Algorithm Design', 'Algorithms', 'American', 'Benchmarking', 'Bionics', 'Caregivers', 'Chicago', 'Clinical', 'Collaborations', 'Communities', 'Community Participation', 'Computational algorithm', 'Computer Vision Systems', 'Crutches', 'Dependence', 'Devices', 'Electrical Engineering', 'Environment', 'Evaluation', 'Exercise', 'Eye', 'Family', 'Feedback', 'Freedom', 'Friends', 'Gait', 'Goals', 'Health', 'Height', 'Home environment', 'Hospitals', 'Human', 'Image', 'Individual', 'Industry', 'Institutes', 'Laboratories', 'Length', 'Location', 'Marketing', 'Medical', 'Methods', 'Motion', 'Patients', 'Performance', 'Phase', 'Population', 'Process', 'Production', 'Quality of life', 'Ramp', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Research', 'Safety', 'Small Business Innovation Research Grant', 'Social isolation', 'Societies', 'Software Engineering', 'System', 'Technology', 'Testing', 'Uncertainty', 'Walking', 'Wheelchairs', 'Work', 'commercialization', 'design', 'exoskeleton', 'experience', 'human study', 'image processing', 'improved', 'improved mobility', 'innovation', 'insight', 'member', 'product development', 'prototype', 'public health relevance', 'rehabilitation technology', 'robot exoskeleton', 'usability', 'vision aid']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2016,224990,-0.0170867652998682
"Second Harmonic Generation analysis of the ECM in idiopathic pulmonary fibrosis ﻿    DESCRIPTION (provided by applicant): Second Harmonic Generation analysis of the ECM in idiopathic pulmonary fibrosis Idiopathic pulmonary fibrosis (IPF) is a disorder characterized by unrelenting scarring and stiffening of the lungs that leads to the death of an estimated 34,000 individuals in the U.S. each year. Unfortunately, individuals with IPF have extremely limited treatment options, as no effective drugs have been identified to halt the progression of fibrosis. Despite the importance of collagens to the structural organization both normal and remodeled ECM, little is known about how collagen structure in IPF differs from that of normal tissue architecture. There is a clear need to develop highly specific/sensitive techniques to probe collagen structure and organization in IPF tissues. In this project we will implement new collagen specific analyses using the high resolution microscopy technique of Second Harmonic Generation (SHG). This method is sensitive to both the fibrillar organization and also sub-resolution aspects of macro and supramolecular assembly. Here we will utilize SHG microscopy to: 1) determine the how pathologic collagen organization (seen in IPF) differs from normal tissue; 2) identify and quantify areas of active fibrosis (enriched in collagen III) from ""old"" or mature fibrosis (high in collagen I) in IPF lung specimens; 3) assess changes in elastin and collagen distribution during disease progression; and 4) correlate areas of high collagen III/I signal in IPF histologic samples with clinical markers of disease activity. As part of the project, we will develop customized automated machine vision routines to automatically classify tissues in terms of severity. We will specifically focus all of our efforts on studying structure around fibroblastic foci, which will be identified by other microscope modalities. These foci are thought to be at the leading edge of ECM remodeling but the dynamics of their formation in relationship to the overall fibrotic process remain unclear. We hypothesize that these structural changes will serve as label- free biomarkers of IPF and further hypothesize that the collagen is altered specifically around foci in a manner which is associated with disease progression. The information gained may form the basis of future prognostic/diagnostic schemes. We propose 2 Aims: Aim 1 Polarization resolved SHG to determine distribution of Col I/III and other ECM changes in different stages of IPF.  Aim 2. Develop classification system of morphological changes in IPF visualized by SHG. PUBLIC HEALTH RELEVANCE: Second Harmonic Generation analysis of the ECM in idiopathic pulmonary fibrosis Narrative Idiopathic fibrosis (IPF) patients have poor survival rates and there is also a lack of diagnostic/prognostic tools that have sufficient sensitivity and specificity to evaluate changes in collagen in the extracellular matrix. The methods developed here will improve upon these limitations and may lay the groundwork for eventual non- invasive in vivo imaging.",Second Harmonic Generation analysis of the ECM in idiopathic pulmonary fibrosis,9122490,R21HL126190,"['Architecture', 'Area', 'Biological Markers', 'Biomedical Engineering', 'Cessation of life', 'Cicatrix', 'Classification', 'Clinical', 'Clinical Markers', 'Collagen', 'Computer Vision Systems', 'Computers', 'Diagnostic', 'Disease', 'Disease Progression', 'Elastin', 'Equilibrium', 'Extracellular Matrix', 'Fibrosis', 'Future', 'Generations', 'Hamman-Rich syndrome', 'Health', 'Histologic', 'Image', 'Individual', 'Label', 'Lung', 'Maintenance', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modeling', 'Monitor', 'Morphology', 'Normal tissue morphology', 'Pathologic', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protein Isoforms', 'Resolution', 'Sampling', 'Scheme', 'Scientist', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Specimen', 'Staging', 'Structure', 'Survival Rate', 'System', 'Techniques', 'Texture', 'Thick', 'Three-Dimensional Imaging', 'Tissue Sample', 'Tissues', 'Vision', 'base', 'improved', 'in vivo imaging', 'interdisciplinary approach', 'prognostic', 'prognostic tool', 'second harmonic', 'tool']",NHLBI,UNIVERSITY OF WISCONSIN-MADISON,R21,2016,182770,-0.0323888560624361
"Designing Visually Accessible Spaces DESCRIPTION (provided by applicant):  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions.  We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area).  This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement.  Our project addresses one of the National Eye Institute's program objectives:  ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals:  1) Empirical:  determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces.  2) Computational:  develop working models to predict low vision visibility and navigability in real-world spaces.  3) Deployment:  translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility.  The key scientific personnel in our partnership come from three institutions:  University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare.  This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare).  We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.",Designing Visually Accessible Spaces,9024545,R01EY017835,"['Accounting', 'Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Central Scotomas', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Fall injury', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Health', 'Height', 'Human', 'Human Resources', 'Indiana', 'Individual', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Lobbying', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Physically Handicapped', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Thinking', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'hazard', 'imaging system', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2016,576055,0.002364028872518691
"A Strength Analysis Tool for Studying Healthy Aging via Exercise in C. elegans ﻿    DESCRIPTION (provided by applicant): Exercise is arguably the most potent approach we can take to defer physical decline associated with aging and to protect against late onset diseases such as diabetes, cancer, and Alzheimer's disease. Molecular understanding of how exercise benefits translate into healthy aging is thus of definitive medical interest. We study fundamental processes relevant to healthy aging in the 959-celled nematode C. elegans. Recently we made a fascinating discovery-C. elegans can exercise (swim) to exhibit training benefits, and appear to gain benefits by molecular pathways conserved in humans. Our initial model development opens up a new research area for understanding how tissue-specific and organism-wide health benefits are induced by exercise, and creates a novel paradigm for identifying exercise mimetic drugs that might promote healthy aging. To really harvest the potential of this model, we need to measure the strength of the tiny C. elegans. We collaborated to develop a strength test in which trained animals thread through a matrix of deformable pillars, and the extent of pillar deflection is used to calculate force. Our ""NemaFlex"" force detection device is the quantitative foundation with which we expect to break new ground in understanding exercise impact on healthy aging. Here we propose required development to enhance assay throughput and pursue applications that will not only anchor this technology as an essential component of C. elegans exercise evaluation but also accelerate studies on exercise biology and healthy aging in this powerful model. Aim 1 is to develop a novel high throughput tool for direct strength evaluation in C. elegans.  This aim will generate an essential tool for analysis of C. elegans strength at multiple life stages, define the exercise regimen that will become the anchor protocol in the field, and reveal features of training in this model. Aim 2 is to use NemaFlex to evaluate exercise mimetic drugs & to facilitate focused pilot genetic screens. This aim will establish critical proof-of-principle for genetic and drug discovery using the NemaFlex. Aim 3 is to initiate dissection of the functional and molecular relationship between exercise and healthy aging, grounded in NemaFlex force measures of training benefits.  To begin, we will test how optimized strength training tracks with a broad spectrum of healthspan indicators that decline with age, we will investigate impact of cessation of training on aging quality, and we will ask if exercise mimetic drugs extend healthspan in the absence of training. Our goals will create novel technology that for the first time permits facile quantitativ analysis of exercise adaptations in the powerful C. elegans genetic model. Accomplishment of our tractable aims will anchor a new subfield of genetic investigation of exercise and healthy aging that may influence design of interventions that broadly promote health and defer aging. PUBLIC HEALTH RELEVANCE: Exercise has a profound positive impact on health of the aging population in that it protects against age-associated diseases including cancer, diabetes, and cardiovascular disease, at the same time it maintains muscle, immune system, and nervous system function in aging. We are developing the first exercise model in the simple animal C. elegans, in which training benefits appear mediated by conserved mechanisms and exercise promotes healthy aging. We will optimize a novel tool for direct strength measurement of these tiny 959-celled animals and show how our device can facilitate searches for exercise mimetic drugs and genes that are associated with training adaptations, and can also help define exercise impact on a broad range of healthy aging measures. The experimental advantages of C. elegans may yield unexpected insights that inspire development of novel interventions that protect against age-associated disease and age-associated decline.",A Strength Analysis Tool for Studying Healthy Aging via Exercise in C. elegans,9116734,R21AG050503,"['Address', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Animals', 'Area', 'Automation', 'Biological Assay', 'Biology', 'Biology of Aging', 'Caenorhabditis elegans', 'Cardiac', 'Cardiovascular Diseases', 'Cells', 'Collaborations', 'Computer Vision Systems', 'Detection', 'Development', 'Device Designs', 'Devices', 'Diabetes Mellitus', 'Disease', 'Dissection', 'Elderly', 'Engineering', 'Evaluation', 'Exercise', 'Exhibits', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Engineering', 'Genetic Models', 'Genetic Screening', 'Goals', 'Harvest', 'Health', 'Health Benefit', 'Human', 'Immune system', 'Intervention', 'Investigation', 'Late-Onset Disorder', 'Life', 'Longevity', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediating', 'Mediator of activation protein', 'Medical', 'Modeling', 'Molecular', 'Molecular Genetics', 'Muscle', 'Muscle function', 'Nematoda', 'Nervous System Physiology', 'Organism', 'Outcome', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Protocols documentation', 'Pump', 'Regimen', 'Reporting', 'Research', 'Staging', 'Swimming', 'System', 'Technology', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translating', 'Work', 'age-related muscle loss', 'aging population', 'anti aging', 'base', 'cognitive function', 'design', 'drug discovery', 'exercise regimen', 'exercise training', 'experience', 'fascinate', 'healthy aging', 'immune function', 'improved', 'insight', 'interest', 'mimetics', 'model development', 'new technology', 'novel', 'programs', 'strength training', 'therapy design', 'tool']",NIA,TEXAS TECH UNIVERSITY,R21,2016,184503,-0.022938930115809195
"Calculation of Percent Body Fat by Analyzing Virtual Body Models ﻿    DESCRIPTION (provided by applicant):  Excess body fat is a key underlying factor in the development of numerous chronic diseases, including type II diabetes, heart disease, stroke, and cancer. The AMA recently declared that obesity, itself, is a disease. Most epidemiologic studies utilize Body Mass Index (BMI) to classify people as underweight, normal, overweight, or obese because it is a convenient and simple method that has been shown to correlate with disease risk. Since the majority of the health risks associated with obesity are more directly linked to an overabundance of body fat than weight, measuring body fat is essential for more precise guidelines. However, accurate methods of assessing body fat are expensive, inconvenient, and require immobile equipment. Consequently, the AMA has called for more cost effective and convenient methods to assess body composition to assist doctors in their assessment and treatment. Virtual modeling of humans in particular has provided ways to scan and analyze the body and its motion. Supervised Machine Learning (SML), a sub-field of artificial intelligence, has made great progress in taking measured data to infer new relationships. It is our belief that virtual modeling and SML can provide the techniques necessary to conveniently and accurately calculate the percentage of body fat (%BF) and to provide new tools in treating obesity based on body shapes. The project will develop a system that uses commercially available depth cameras such as the Microsoft Kinect(r) to capture the surface of the human body. This will be accomplished by developing a new algorithm to perform deformable registration of several RGB-Depth views of the body. A new algorithm that uses SML will be developed to calculate percentage body fat using the surface data. The system will be trained and validated by collecting data from a number of subjects. The surface captured will be used to explore the role of visual body representation in motivation and adherence. The developed systems can be implemented in clinical or personal settings and be utilized as a public health research tool and deployed widely given the low-cost of the hardware required. In addition to the immediate impact that the system will have on managing obesity, the project will have a broad impact on a number of areas. A large database of such shapes captured over time may lead to ways to predict how an individual's body shape will change given a particular intervention. Certain medical conditions that result in body shape change, such as those involving lymphatic circulations, may be diagnosed and tracked more easily. Growth patterns of children may be tracked by change of body shapes. Further research can be conducted to determine the effect of body shape on %BF using data mining techniques.         PUBLIC HEALTH RELEVANCE: The project will develop a new method to capture the 3D surface and shape of a human body and a new method to use these data to calculate percent body fat. By making these tools widely available and economical, the proposed approach has the potential for major contributions in the assessment and treatment of obesity.        ",Calculation of Percent Body Fat by Analyzing Virtual Body Models,8970310,R21HL124443,"['Adherence', 'Age', 'Air', 'Algorithms', 'Area', 'Artificial Intelligence', 'Behavior Therapy', 'Belief', 'Body Composition', 'Body Size', 'Body Surface', 'Body Weight decreased', 'Body fat', 'Body mass index', 'Child', 'Chronic Disease', 'Client', 'Clinical', 'Clinical Research', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Epidemiologic Studies', 'Equipment', 'Fatty acid glycerol esters', 'Future', 'Goals', 'Growth', 'Guidelines', 'Health', 'Health Care Costs', 'Heart Diseases', 'Human', 'Human body', 'Imagery', 'Incentives', 'Individual', 'Intervention', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Motion', 'Motivation', 'Muscle', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Overweight', 'Participant', 'Patients', 'Pattern', 'Perception', 'Plethysmography', 'Population Study', 'Public Health', 'Reporting', 'Research', 'Risk', 'Role', 'Scanning', 'Self Perception', 'Series', 'Shapes', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'Underweight', 'Variant', 'Visual', 'Water', 'Weight', 'Weights and Measures', 'base', 'body density', 'body volume', 'cost', 'cost effective', 'data mining', 'density', 'disorder risk', 'lymphatic circulation', 'novel', 'novel strategies', 'obesity treatment', 'preference', 'public health relevance', 'public health research', 'reconstruction', 'sex', 'tool', 'virtual', 'weight loss intervention']",NHLBI,GEORGE WASHINGTON UNIVERSITY,R21,2015,227680,-0.009712037374189445
"Machine learning with generative mixture models for fetal monitoring     DESCRIPTION (provided by applicant): For many years, there has been a concerted effort to automate the analysis of fetal heart rate (FHR) rhythms. However, despite significant advances in biomedical signal analysis, there has not been any significant improvement in automated decision support systems. FHR monitoring is now ubiquitous throughout delivery rooms, especially using the non-invasive Doppler monitor, but also using the fetal scalp electrode. Physician classification of fetal heart rate patterns is known to be a non-trivial problem because of significant inter and intra-observer variability of diagnosis. This has led to a marked increase in the number of caesarean deliveries, thereby increasing risk to the fetus and mother in many cases. This has further motivated the machine learning community to automate the classification procedure in the interest of accuracy and consistency as well as robustness with respect to noise. Usual approaches to this involve some type of supervised classification procedure, where the algorithm output on training data is compared with a ""gold-standard"" physician classification, followed by testing and validation on new datasets. However, since physician classification can be unreliable in the presence of the aforementioned diagnostic variability, as well as significant tracing noise, we propose the use of unsupervised algorithms to cluster FHR data records into clinically useful categories. We use nonparametric Bayes theory and Markov-time-dependence models for the evolution of feature sequences to propose methods that will achieve improved accuracy. The methods involve extraction of feature sequences from FHR time series data, which are modeled as samples from finite or infinite Dirichlet mixture models. We then use Gibbs sampling to obtain the cluster probabilities for each dataset. Clustering outcomes are compared against direct physician diagnosis and our current results are seen to be in broad agreement with them, while still giving new information on the character of different sub-groups of FHR records. With the proposed research, further gains in classification performance will be made.         PUBLIC HEALTH RELEVANCE: Fetal heart rate monitoring is now commonly used during childbirth and, at present, physicians read and interpret these data to classify fetal heart rate patterns and make sure that the baby is not in distress during the course of labor. However, there is great variability in how individual doctors interpret the tracings and this has led increases in the number of caesarean deliveries, thereby potentially increasing risk to both mothers and babies. Thus there has been a concerted effort from the machine learning community to develop an accurate automatic reading and classification procedure so that correct interpretation of fetal heart rates during labor is more diagnostic and consistent.            ",Machine learning with generative mixture models for fetal monitoring,8816208,R21HD080025,"['Agreement', 'Algorithms', 'Apgar Score', 'Bayesian Method', 'Behavioral', 'Birth', 'Categories', 'Childbirth', 'Classification', 'Clinical', 'Communities', 'Consensus', 'Data', 'Data Set', 'Decision Support Systems', 'Delivery Rooms', 'Dependence', 'Dependency', 'Diagnosis', 'Diagnostic', 'Distress', 'Electrodes', 'Evolution', 'Feedback', 'Fetal Heart', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Freedom', 'Gold', 'Individual', 'Intraobserver Variability', 'Joints', 'Knowledge', 'Label', 'Learning', 'Litigation', 'Machine Learning', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Monte Carlo Method', 'Mothers', 'Motivation', 'Noise', 'Outcome', 'Outcome Measure', 'Output', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Probability', 'Procedures', 'Process', 'Reading', 'Records', 'Research', 'Risk', 'Sampling', 'Scalp structure', 'Series', 'Signal Transduction', 'System', 'Testing', 'Time', 'Training', 'Umbilical cord structure', 'Uncertainty', 'Uterine Contraction', 'Validation', 'Work', 'base', 'cost', 'fetal', 'improved', 'interest', 'pressure', 'public health relevance', 'stem', 'theories', 'vector']",NICHD,STATE UNIVERSITY NEW YORK STONY BROOK,R21,2015,234571,-0.030959764117938757
"Automatically Creating and Updating Meta-Studies of Randomized Controlled Trials ﻿    DESCRIPTION (provided by applicant):  A ""meta-study"" (or ""meta-analysis"") collects and analyzes many studies on the same topic to understand if there is a meaningful, overall result. Meta-studies can support (or refute) interventions, spur new investigations, and lead to novel clinical guidelines. However, constructing meta-studies is a time intensive process of searching the literature, compiling the results, and performing the statistical analysis. Due to the time commitment that is required, many topics are unexplored, and many meta-studies are not kept up-to-date with the latest published results. Finally, a number of (unknown) biases, via subjective choices during the meta-study, may influence the results. Our long-term goal is to automate, as much as possible, the meta-study process. This should decrease subjective bias; increase the dissemination of evidence, especially for diseases and interventions that receive less attention; and allow for the automatic updating of meta-studies as new results are published. We propose a computer system that uses statistical machine learning to gather and group studies focused on similar interventions and outcomes; extract the necessary results from the text; and analyze the results using standard meta-analysis techniques. The final output will be presented in a spreadsheet-like Web-interface where users can explore and even change the data and meta-analyses. Our team uniquely blends technical expertise in machine learning with leadership in publishing meta-studies about Inflammatory Bowel Disease (IBD), our disease of focus for our Phase I feasibility study. We are therefore qualified technically and able to ensure that the techniques generate valid and accurate meta-studies. Our Phase I results will define the current state-of-the-art for this novel task. Further, although we will initially focus n IBD, our Phase I results will demonstrate that our approach can generalize to other diseases, eventually applying to any intervention and any disease. The feasibility shown by our Phase I results will motivate our Phase II effort where we will focus on dramatically improving the approach, yielding broad coverage of all medical literature and generating human-quality meta-studies. We note that by the end of Phase I we should have a viable end-to-end prototype, focused on IBD, which we can begin taking to market. The final product should significantly benefit our target markets given the Phase II emphasis to improve the technology, user experience, and scope of covered diseases. PUBLIC HEALTH RELEVANCE:  A meta-analysis collects and analyzes the results from multiple studies that are all focused on the same topic, and it can confirm (or refute) the overall effect across the studies, lead to changes in clinical guidelines, or spur new directions for research. However, generating a meta-analysis is an extremely time-consuming process, so many diseases are not covered, and most meta-analyses are not updated to reflect the latest published studies. This work begins to automate the process of creating meta-analyses, overcoming these difficulties in order to make the results published in the medical literature more accessible.",Automatically Creating and Updating Meta-Studies of Randomized Controlled Trials,8977531,R43LM012210,"['Adverse event', 'Algorithms', 'Attention', 'Clinical', 'Computer Systems', 'Computer software', 'Data', 'Data Aggregation', 'Diabetes Mellitus', 'Disease', 'Disease remission', 'Dourine', 'Ensure', 'Evidence Based Medicine', 'Feasibility Studies', 'Goals', 'Grouping', 'Guidelines', 'Hand', 'Health', 'Human', 'Inflammatory Bowel Diseases', 'Intervention', 'Intervention Studies', 'Investigation', 'Lead', 'Leadership', 'Literature', 'Lupus', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Meta-Analysis', 'Modeling', 'Odds Ratio', 'Outcome', 'Outcome Study', 'Output', 'Pattern', 'Performance', 'Phase', 'Placebos', 'Population Sizes', 'Process', 'Publishing', 'Qualifying', 'Randomized Controlled Trials', 'Research', 'Research Personnel', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Text', 'Time', 'Update', 'Work', 'abstracting', 'base', 'experience', 'falls', 'improved', 'novel', 'primary outcome', 'programs', 'prototype', 'software development', 'text searching', 'web interface']",NLM,INFERLINK CORPORATION,R43,2015,150000,-0.023682571366718325
"Reproducibility Assessment for Multivariate Assays DESCRIPTION (provided by applicant): This Small Business Innovation Research project addresses the problem of assessing reproducibility in analyzing high-throughput data. In feature selection for data with large numbers of features, it is well known that some features will appear to affect an outcome by chance, and that subsequent predictions based on these features may not be as successful as initial results would seem to indicate. Similarly, there are often multiple stages, and many parameters, involved in the multivariate assays de- signed to analyze high-throughput profiles. For example, good results achieved with a particular combination of settings for an instance of cross-validation may not generalize to other instances. The objective of this proposal is to extend new statistical methods for assessing reproducibility in replicate experiments to the context of machine learning, and demonstrate effectiveness in this application. The machine-learning methods to be investigated will include random forests, supervised principal components, lasso penalization and support vector machines. We will use simulated and real data from genomic applications to show the potential of this approach for providing reproducibility assessments that are not confounded with prespecified choices, for determining biologically relevant thresholds, for improving the accuracy of signal identification, and for identifying suboptimal results. Relevance. Although today's high-throughput technologies offer the possibility of revolutionizing clinical practice, the analytical tools availble for extracting information from this amount of data are not yet sufficiently developed for targeted exploration of the underlying biology. This project directly addresses the need to make what the FDA terms IVDMIA (In-Vitro Diagnostic Multivariate Index Assays) transparent, interpretable, and reproducible, and is thus an opportunity to improve analysis products and services provided to companies that identify, characterize, and validate biomarkers for clinical diagnostics and drug development decision points. The long-term goal of the proposed project is to develop a platform for biomarker discovery and integrative genomic analysis, with reproducibility assessment incorporated into multivariate assays. This will enable evaluation and improvement of approaches to detecting the biological factors that affect a particular outcome, and lead to more efficient and more effective methods for disease diagnosis, treatment monitoring, and therapeutic drug development. PUBLIC HEALTH RELEVANCE: Statistical models play a key role in medical research in uncovering information from data that leads to new diagnostics and therapies. However, development of standards for reliability in biomedical data mining has not kept up with the rapid pace at which new data types and modeling approaches are being devised. This proposal is for new methods for quantifying reproducibility in biomedical data analyses that will have a far-reaching impact on public health by streamlining protocols, reducing costs and offering more effective clinical support systems.",Reproducibility Assessment for Multivariate Assays,8828718,R43GM109503,"['Address', 'Affect', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Biological Factors', 'Biological Markers', 'Biology', 'ChIP-seq', 'Clinical', 'Cloud Computing', 'Data', 'Data Analyses', 'Decision Trees', 'Development', 'Diagnostic', 'Dimensions', 'Effectiveness', 'Evaluation', 'Evolution', 'Genomics', 'Goals', 'Guidelines', 'Health', 'In Vitro', 'Investigation', 'Lasso', 'Lead', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Performance', 'Phase', 'Play', 'Protocols documentation', 'Public Health', 'Publishing', 'ROC Curve', 'Reproducibility', 'Research Project Grants', 'Scheme', 'Services', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Source', 'Specific qualifier value', 'Staging', 'Statistical Methods', 'Statistical Models', 'Support System', 'Techniques', 'Technology', 'Therapeutic', 'Trees', 'Validation', 'analytical tool', 'base', 'clinical practice', 'cost', 'data mining', 'design', 'disease diagnosis', 'drug development', 'follow-up', 'forest', 'high throughput technology', 'improved', 'indexing', 'novel diagnostics', 'research study']",NIGMS,INSILICOS,R43,2015,64005,-0.02435381742096961
"Impact of Crouch Gait and Surgical Treatment on Knee Mechanics and Function     DESCRIPTION (provided by applicant):  Children with Cerebral Palsy (CP) often exhibit crouch gait, which is characterized by excessive knee flexion during stance. This form of walking is extremely fatiguing and tends to progress until eventually walking ability ceases. A newly revived surgical procedure, distal femoral extension osteotomy (DFEO) and patellar tendon advancement (PTA), simultaneously addresses both knee flexion contractures and patella alta (superiorly displaced patella) that often co-exist in those with crouch. Initial outcoe studies demonstrate greater improvements in gait than conventional surgical treatments. However, complication rates remain high and some patients exhibit little to no improvement in gait after surgery. The first aim of this study is to investigate the effects of patella position, crouch and surgical parameters on functional knee mechanics. Computational knee models will be created that include detailed representations of ligament and articular cartilage geometry within the tibiofemoral and patellofemoral joints. Patella alta and knee flexion contractures will be introduced, and surgical simulations will be performed virtually. The computational models will then be used to simulate knee mechanics when walking in normal, and mild, moderate, and severe crouch gait postures. Probabilistic simulations will then be used to investigate how variability in physical characteristics and surgical factors can contribute to variable outcomes. The effects of surgery and crouch gait on cartilage pressure patterns will also be determined, which is relevant for understanding subsequent skeletal growth and long-term cartilage health. The second aim investigates whether a combination of quantitative measures of physical characteristics and surgical parameters can retrospectively classify post-surgical gait performance. Pre- and post-surgical x- rays will be used to quantitatively measure the Koshino index (metric of patella alta/baja), the magnitude and location of the DFEO, and the PTA advancement distance in patients who previously underwent DFEO+PTA. Pre-surgical measures of knee flexion contracture and spasticity will also be obtained. Pre- and post-operative gait analysis data will be used to assess changes in gait mechanics, while functional surveys will assess changes in performance on activities of daily living. The random forest algorithm will then be used to identify decision trees and associate predictor variables that can classify those patients whose gait and overall function improved after surgery. These results will be interpreted in the context of modeling results from Aim 1, thereby providing a potential mechanistic explanation for clinical observations. The research will impact innumerable CP patients as the DFEO+PTA surgical procedures are adopted around the world, and will also set the groundwork for more rigorous scientific study of other procedures used to treat gait disorders.         PUBLIC HEALTH RELEVANCE:  Children with Cerebral Palsy (CP) often exhibit a crouch walking posture, which can be extremely fatiguing, painful and disabling as a child grows. Orthopedic surgical procedures are used to correct the physical abnormalities that contribute to crouch, but clinical outcomes remain variable and difficult to predict. This study uses a combination of computational models and retrospective analyses of clinical data to identify the physical and surgical treatment factors that can best restore more normal walking function in CP patients.                ",Impact of Crouch Gait and Surgical Treatment on Knee Mechanics and Function,8815132,R21HD084213,"['Activities of Daily Living', 'Address', 'Adopted', 'Adoption', 'Aftercare', 'Age', 'Algorithms', 'Biomechanics', 'Bone Growth', 'Cartilage', 'Cerebral Palsy', 'Characteristics', 'Child', 'Clinical', 'Clinical Data', 'Clinical Research', 'Complication', 'Computer Simulation', 'Contracture', 'Coupled', 'Data', 'Decision Trees', 'Distal', 'Exhibits', 'Fatigue', 'Gait', 'Gait abnormality', 'Geometry', 'Growth', 'Health', 'Height', 'Individual', 'Inferior', 'Joints', 'Knee', 'Knee bone', 'Ligaments', 'Location', 'Machine Learning', 'Measures', 'Mechanics', 'Methods', 'Modeling', 'Motion', 'Musculoskeletal', 'Operative Surgical Procedures', 'Orthopedic Surgical Procedures', 'Osteotomy', 'Outcome', 'Outcome Study', 'Pain', 'Patient Selection', 'Patients', 'Pattern', 'Performance', 'Phase', 'Positioning Attribute', 'Postoperative Period', 'Posture', 'Procedures', 'Research', 'Research Personnel', 'Selection Criteria', 'Severities', 'Surveys', 'Techniques', 'Tendon structure', 'Testing', 'Treatment Factor', 'Walking', 'Work', 'articular cartilage', 'crouch gait', 'forest', 'functional outcomes', 'gait examination', 'human subject', 'improved functioning', 'indexing', 'knee mechanics', 'pressure', 'prevent', 'public health relevance', 'quadriceps muscle', 'restoration', 'simulation', 'skeletal']",NICHD,UNIVERSITY OF WISCONSIN-MADISON,R21,2015,217599,-0.011602120963319168
"Development of real-time, automated 3D ultrasound tools for the study of placental invasion and morphology ﻿    DESCRIPTION (provided by applicant) Among the most intractable pregnancy pathologies are those related to aberrant trophoblast invasion and the subsequent remodeling of maternal vasculature at the utero-placental interface (UPI). These include preeclampsia (PE), intrauterine growth restriction (IUGR) and abnormally invasive placenta (AIP, aka placenta accreta). Despite this, tools to measure placental structure and function in the crucial late first to early second trimester period have yet to be developed that can be translated from the research environment to routine clinical use. We are now constructing 3D power Doppler ultrasound technologies that provide real-time, quantitative assessment of placental structural and vascular development. We have developed novel semi- automated methods for calculation of placental volume (PlaV) and new methods to measure gross placental morphology (GPM; dimensions, surface area etc.) and to assess the vasculature at the UPI (Fractional Moving Blood Volume, FMBV). We propose four Aims intended to move the field towards routine imaging of placental structure and function in real time and to generate clinically useful tests for monitoring significant placental pathologies. In Aim 1, using machine learning techniques and an extant database of ~2800 1st trimester placental scans, we will fully automate the novel tools developed for measurement of PlaV into a real-time analytical package. Aim 2 will focus on 3D ultrasound techniques to interrogate the vasculature at the UPI through refinement of our new method for determining FMBV, a quantitative measure of vascularity. This will lead to a tool that can assess the entire UPI, a major site of pathology in PE, IUGR and AIP. We also aim to develop 3D power Doppler ultrasound tools for the examination of the size and distribution of the spiral artery jets feeding the intervillous space, enabling us to explore normal and pathological development of the intervillous supply in real-time. Aims 3 and 4 are prospective validation studies designed to test the utility of the tools described above. Aim 3 extends our recently published study of over-invasion of the maternal vasculature to the 1 /2 trimester. The presence and severity of AIP is assessed using Acon, the largest area of standard 3D power Doppler signal at the UPI. Under-invasion will be addressed via analysis of prospectively collected 11-13 week 3D-PD scans in women who develop PE. We will compare PlaV, GPM, FMBV and spiral artery jets in normotensive and preeclamptic pregnancies. The prospective study in Aim 4 will address the environmental impact of smoking by comparing structural and vascular parameters between smokers and non-smokers at weekly intervals from 8-18 wks. These powerful longitudinal studies will map the development of morphologic and vascular features in smokers and non-smokers and provide new insights into the factors responsible for smoking-induced growth restriction. The strong investigative team, composed of bioengineers, maternal-fetal medicine specialists and placental biologists, is delivering these new tools in the research setting and is poised to generate new methods for clinical measurement of placental structure and vascular function in real-time.          PUBLIC HEALTH RELEVANCE: If the placenta does not develop normally, complications like poor fetal growth and preeclampsia in the mother occur. We are developing new ultrasound techniques to measure the placenta early in pregnancy. This could permit early detection of problems that occur months later in the pregnancy. This would allow doctors to monitor the pregnancy and to prevent or treat problems quickly, before they have serious effects on the fetus.        ","Development of real-time, automated 3D ultrasound tools for the study of placental invasion and morphology",9076751,U01HD087209,"['Address', 'Area', 'Biomedical Engineering', 'Blood Vessels', 'Blood Volume', 'Clinical', 'Data', 'Databases', 'Decidua', 'Dependence', 'Development', 'Dimensions', 'Doppler Ultrasound', 'Early Diagnosis', 'Environment', 'Environmental Impact', 'Fetal Growth', 'Fetal Growth Retardation', 'Fetus', 'Generations', 'Goals', 'Gold', 'Growth', 'Growth and Development function', 'Hand', 'Image', 'Lead', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Mothers', 'Pathology', 'Placenta', 'Placenta Accreta', 'Placentation', 'Plant Roots', 'Pre-Eclampsia', 'Pregnancy', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Research', 'Research Design', 'Resources', 'Scanning', 'Second Pregnancy Trimester', 'Severities', 'Shapes', 'Signal Transduction', 'Site', 'Smoker', 'Smoking', 'Specialist', 'Spiral Artery of the Endometrium', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Validation', 'Vascularization', 'Woman', 'feeding', 'fetal', 'fetal medicine', 'implantation', 'in vivo', 'indexing', 'insight', 'model development', 'myometrium', 'non-smoker', 'normotensive', 'novel', 'prevent', 'prospective', 'public health relevance', 'screening', 'tool', 'trophoblast', 'validation studies']",NICHD,HACKENSACK UNIVERSITY MEDICAL CENTER,U01,2015,3271021,-0.01642511275157008
"Objective assessment of surgical competence in a septoplasty model ﻿    DESCRIPTION (provided by applicant): To ensure patient safety, educators must train surgeons to set standards of competency, public health officials should put in place policies to ensure surgeons remain competent and surgeons should only perform surgeries that they are competent to perform. Measuring surgeon's technical skill is crucial part of determining if they are competent. Traditionally surgical skill is assessed most commonly during training using subjective non-validated metrics. This leads to variation in the definition of competency. Recent policies set forth by the Accreditation Council of Graduate Medical Education- the governing body for graduate medical education, mandate that technical skill be measured objectively. Currently, there are few valid objective measures available to measure technical competence. Our research will yield a set of tools and methodologies that can be deployed to across medical training programs to objectively measure surgical skill and competence. This platform is also capable of developing new objective measure of skill and competence. Specifically, first, we will develop an objective skills assessment platform, and establish standard data collection and quality assurance protocols for systematic deployment of our platform across multiple institutions. Second, our work will result in automated algorithms and analytic tools to objectivel measure skill using data captured with our platform. Third, we will establish objective methods to determine whether a surgeon is competent to perform surgery. Fourth, we will test the reliability and validity of our assessment tools. We will conduct our study using septoplasty as the prototype test-bed procedure. Septoplasty is a commonly performed procedure (more than 260,000 cases per year) and is a key index surgery by which residents in otolaryngology are evaluated. Our project lays the groundwork for subsequent research to establish national standards for objective skill and competency using data aggregated from numerous training programs in the country.         PUBLIC HEALTH RELEVANCE: Policies for graduate medical education require that surgical competency be objectively determined, but currently available technology and methods do not yield objective assessments for surgical skill. Our project aims to provide educators with an integrated objective skills assessment platform and tools for objective determination of competency, which can be readily deployed across graduate surgical training programs in the country.            ",Objective assessment of surgical competence in a septoplasty model,8944969,R01DE025265,"['Accreditation', 'Address', 'Algorithms', 'American', 'Area', 'Beds', 'Cessation of life', 'Competence', 'Computer Assisted', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Quality', 'Data Set', 'Ensure', 'Evaluation', 'Exploratory/Developmental Grant for Diagnostic Cancer Imaging', 'Foundations', 'Inferior', 'Institution', 'Learning', 'Life', 'Machine Learning', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Otolaryngology', 'Outcome', 'Patient Care', 'Patients', 'Phase', 'Philosophy', 'Physicians', 'Pilot Projects', 'Policies', 'Postoperative Complications', 'Predictive Value', 'Procedures', 'Protocols documentation', 'Public Health', 'Quality Control', 'Repeat Surgery', 'Research', 'Research Infrastructure', 'Research Support', 'Residencies', 'Site', 'Surgeon', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Validity and Reliability', 'Variant', 'Work', 'base', 'graduate medical education', 'high risk', 'indexing', 'patient safety', 'programs', 'prototype', 'public health relevance', 'quality assurance', 'skills', 'success', 'tool']",NIDCR,JOHNS HOPKINS UNIVERSITY,R01,2015,582025,0.004235940448360421
"In vivo Characterization of Stents using Intravascular OCT Imaging DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel. PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,8885879,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Health', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'stent thrombosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2015,457216,-0.010901879233420527
IGF::OT::IGF TASK ORDER 1 - CORE & ADMINISTRATION; MAINTENANCE & INSTALLATION FOR THE SURVEILLANCE EPIDEMIOLOGY AND END RESULTS (SEER) ELECTRONIC DATA CAPTURE SOFTWARE SUPPORT AND INSTALLATIONS. Surveillance Epidemiology and End Results (SEER) Electronic Data Capture Software Support and Installations. n/a,IGF::OT::IGF TASK ORDER 1 - CORE & ADMINISTRATION; MAINTENANCE & INSTALLATION FOR THE SURVEILLANCE EPIDEMIOLOGY AND END RESULTS (SEER) ELECTRONIC DATA CAPTURE SOFTWARE SUPPORT AND INSTALLATIONS.,9162089,61201500033I,"['Artificial Intelligence', 'Award', 'Computer software', 'Contracts', 'Data', 'Diagnostic Imaging', 'Electronics', 'Hour', 'Laboratories', 'Maintenance', 'Malignant Neoplasms', 'Medical Surveillance', 'Medicine', 'Pathology', 'Reporting', 'Update', 'electronic data']",NCI,"ARTIFICIAL INTELLIGENCE IN MEDICINE, INC",N03,2015,1135265,-0.016749724065225555
"Intraocular Robotic Interventional Surgical System for Cataract Surgery Project DESCRIPTION (provided by applicant): Surgical outcomes have been dramatically improved in the last 2 decades through the integration of new technologies including among other innovative visualization systems and robotic assistance. We think that cataract surgery can also benefit from these advancements and we envision that cataract surgery will possibly be entirely performed in fifteen years from now by an automated robotic surgical platform. The goal of the present proposal is to develop automated capabilities of the Intraocular Robotic Interventional Surgical System (IRISS) based on its new abilities to reconstruct in real time the anatomical structures of the anterior segment of the eye. This 3D real time reconstruction of the anterior segment of the eye is made possible by the joint use of Computer Vision techniques and Optical Coherence Tomography (OCT) acquisition and analysis. Cataracts are the number one cause of blindness in the world and cataract surgery is the most frequently performed operation totaling 3 million operations every year in the United States. The procedure accounts for the single largest expenditure for any Part B procedure in the Medicare Program. The modern cataract surgical procedure involves several steps each with significant potential for complicated inadvertent tissue manipulation possibly resulting in intraocular trauma. Previous studies have shown that undesired tissue manipulation can be significantly decreased using robotic systems that attenuate undesirable movement, and possibly collision, of surgical tools both intraocularly and at the site of incision. Thus, we have developed IRISS, the first dual arm, intraocular robotic surgical system designed for performing intraocular surgeries with a primary focus on cataract surgery. Preliminary results have shown an optimization of vibration reduction, a controlled remote center of motion (RCM) for both robotic arms and the ability to mount multiple surgical instruments to either arm with automated surgical instrument replacement. The system has been used to perform successfully Ex Vivo cataract surgeries on pig eyes by teleoperation, completing capsulorhexis, lens aspiration, as well as maneuvers even more technically challenging than cataract removal such as vitrectomy and retinal vein cannulation To achieve automated cataract surgery, the present study will develop new vision- based object tracking system utilizing real time local gradient orientation analysis algorithms and develop an OCT guided 3D real-time reconstruction of the anterior segment of the eye to offer feedback to the robotic system. We hypothesize that an improved anatomical detection system will decrease the incidence of undesirable trauma to ocular tissues by creating restrictions on the proximity of surgical tools to ocular structures. By performing Ex Vivo testing of cataract extraction surgeries on harvested pig eyes, the efficacy and accuracy of the system will be assessed by the evaluation of the corneal endothelial cell, the iris and the capsular bag integrity and of the complete removal of the lens material. PUBLIC HEALTH RELEVANCE: This project will develop new capabilities of the robotic manipulated platform to perform an automated cataract extraction surgical procedure. Automated lens extraction will be achieved using real-time tracking and 3D reconstruction of the ocular structures. In automating the surgical procedure we believe that the incidence of inadvertent tissue manipulation, and the associated intraocular tissue trauma, will decline.",Intraocular Robotic Interventional Surgical System for Cataract Surgery Project,8935826,R21EY024065,"['Accounting', 'Algorithms', 'Anatomy', 'Anterior eyeball segment structure', 'Attenuated', 'Automation', 'Blindness', 'Cannulations', 'Capsulorhexis', 'Cataract', 'Cataract Extraction', 'Computer Vision Systems', 'Cornea', 'Corneal Endothelium', 'Detection', 'Endothelial Cells', 'Environment', 'Evaluation', 'Excision', 'Expenditure', 'Eye', 'Family suidae', 'Feedback', 'Goals', 'Hand', 'Harvest', 'Health', 'Human', 'Image', 'Imagery', 'Incidence', 'Iris', 'Irrigation', 'Joints', 'Lasers', 'Manuals', 'Medicare', 'Modeling', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Ophthalmologic Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Procedures', 'Reproducibility', 'Risk', 'Robotics', 'Site', 'Stress', 'Structure', 'Structure of central vein of the retina', 'Surgical Instruments', 'Surgical complication', 'Surgical incisions', 'System', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'United States', 'Vision', 'Visual', 'Vitrectomy', 'arm', 'base', 'capsule', 'design', 'image guided', 'improved', 'innovation', 'instrument', 'lens', 'new technology', 'operation', 'optical imaging', 'programs', 'reconstruction', 'research study', 'robot assistance', 'tissue trauma', 'tomography', 'tool', 'vibration']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2015,369679,0.0012902921859160078
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,8775624,K99AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,GEORGIA INSTITUTE OF TECHNOLOGY,K99,2015,90000,-0.014493705446170704
"Context Understanding Technology to improve internet accessibility for users with DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization. PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.",Context Understanding Technology to improve internet accessibility for users with,8795182,R44EY020082,"['Advertisements', 'Area', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Government', 'Grouping', 'Health', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Persons', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2015,195445,0.0001256083561111442
"Informatic tools for predicting an ordinal response for high-dimensional data DESCRIPTION (provided by applicant):        Health status and outcomes are frequently measured on an ordinal scale. Examples include scoring methods for liver biopsy specimens from patients with chronic hepatitis, including the Knodell hepatic activity index, the Ishak score, and the METAVIR score. In addition, tumor-node-metasis stage for cancer patients is an ordinal scaled measure. Moreover, the more recently advocated method for evaluating response to treatment in target tumor lesions is the Response Evaluation Criteria In Solid Tumors method, with ordinal outcomes defined as complete response, partial response, stable disease, and progressive disease. Traditional ordinal response modeling methods assume independence among the predictor variables and require that the number of samples (n) exceed the number of covariates (p). These are both violated in the context of high-throughput genomic studies. Recently, penalized models have been successfully applied to high-throughput genomic datasets in fitting linear, logistic, and Cox proportional hazards models with excellent performance. However, extension of penalized models to the ordinal response setting has not been fully described nor has software been made generally available. Herein we propose to apply the L1 penalization method to ordinal response models to enable modeling of common ordinal response data when a high-dimensional genomic data comprise the predictor space. This study will expand the scope of our current research by providing additional model-based ordinal classification methodologies applicable for high-dimensional datasets to accompany the heuristic based classification tree and random forest ordinal methodologies we have previously described. The specific aims of this application are to: (1) Develop R functions for implementing the stereotype logit model as well as an L1 penalized stereotype logit model for modeling an ordinal response. (2) Empirically examine the performance of the L1 penalized stereotype logit model and competitor ordinal response models by performing a simulation study and applying the models to publicly available microarray datasets. (3) Develop an R package for fitting a random-effects ordinal regression model for clustered ordinal response data. (4) Extend the random-effects ordinal regression model to include an L1 penalty term to accomodate high-dimensional covariate spaces and empirically examine the performance of the L1random-effects ordinal regression model through application to microarray data. Studies involving protocol biopsies where both histopathological assessment and microarray studies are performed at the same time point are increasingly being performed, so that the methodology and software developed in this application will provide unique informatic methods for analyzing such data. Moreover, the ordinal response extensions proposed in this application, though initially conceived of by considering microarray applications, will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect human preference data and other responses on an ordinal scale. Most histopathological variables are reported on an ordinal scale. Studies involving protocol biopsies where both histopathological assessment and microarray studies are performed at the same time point are increasingly being performed, and the software developed in this application will provide unique informatic tools for analyzing such data. Moreover, the informatic methods proposed in this application, though initially conceived of by con- sidering microarray applications, will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect human preference data and other responses on an ordinal scale.",Informatic tools for predicting an ordinal response for high-dimensional data,8900334,R01LM011169,"['Advocate', 'Behavioral Research', 'Bioconductor', 'Biopsy', 'Biopsy Specimen', 'Breast Cancer Patient', 'Cancer Patient', 'Cancer Prognosis', 'Categories', 'Chronic Hepatitis', 'Classification', 'Client satisfaction', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Diagnostic Neoplasm Staging', 'Environment', 'Evaluation', 'Event', 'Gene Chips', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Health', 'Health Status', 'Hepatic', 'Human', 'In complete remission', 'Informatics', 'Lesion', 'Logistics', 'Logit Models', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nodal', 'Outcome', 'Patients', 'Performance', 'Progressive Disease', 'Protocols documentation', 'Quality of life', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scoring Method', 'Solid Neoplasm', 'Specimen', 'Stable Disease', 'Staging', 'Stereotyping', 'Techniques', 'Time', 'Trees', 'base', 'forest', 'functional status', 'heuristics', 'indexing', 'liver biopsy', 'malignant breast neoplasm', 'novel', 'partial response', 'preference', 'programs', 'response', 'simulation', 'social', 'software development', 'tool', 'tumor']",NLM,VIRGINIA COMMONWEALTH UNIVERSITY,R01,2015,121902,-0.024074484038140883
"The oral microbiome and enterosalivary circulation of nitric oxide in HIV. ﻿    DESCRIPTION (provided by applicant): Chronic HIV is associated with increased risk of pulmonary and cardiovascular complications. Despite use of antiretroviral therapy, rates of even rare vascular complications such as pulmonary hypertension occur upwards of 25 times that in HIV- individuals. The cause for such a high rate of vascular complications in HIV is unknown. Nitric oxide (NO) is a critically important signaling molecule that is produced by the vascular endothelium and acts as a vasodilator and regulator of cardiovascular health. Reduction of nitrate to nitrite and nitric oxide by commensal oral bacteria has recently been implicated in the maintenance of vascular function. The enterosalivary NO pathway is an important component of nitric oxide generation as nitrate is converted to nitrite by a series of bacterial enzymes in the mouth, which is then swallowed and either directly converted to NO or absorbed into the bloodstream where it exerts systemic NO-like effects. The enterosalivary NO pathway depends on viable populations of oral bacteria and helps regulate blood pressure and mitigate vascular injury. However, little is known about the specific bacterial populations involved or the contribution to systemic NO availability and vascular injury and disease. Our preliminary studies suggest that HIV+ individuals have a different profile of oral commensal bacteria (oral microbiome) than HIV- individuals that involves key nitrate reduction pathways. This study proposes the novel hypothesis that the accelerated cardio- and pulmonary vascular disease seen in HIV is due in part to changes in the oral microbiome that favor a disruption of the enterosalivary NO pathway, reduced NO availability, and chronic vascular injury. To test this hypothesis, the oral microbiome of an established cohort of 315 HIV+ and HIV- participants will be characterized using culture-independent sequencing techniques in banked oral wash samples. Expression of specific bacterial nitrate-reducing enzymes will be measured, and results correlated with available serological markers of vascular damage, echocardiographic testing, and radiographic measures of vascular injury. Results will directly inform future clinical enrollment of a prospective trial examining real-time nitrate metabolism, systemic NO distribution, and associated physiological effects. These investigations will offer the first stepsin understanding a novel pathway of HIV-associated vascular disease and inform development of targeted therapies. Additionally, this NRSA award will provide the candidate, a pulmonary medicine fellow, the opportunity for further training in pulmonary vascular medicine and for developing skills in HIV/AIDS and microbiome research. The candidate will acquire extensive training in basic and advanced laboratory techniques, biostatistics, and clinical study design through labwork, conferences, and a master's degree in clinical/translational research. The resources and experience of mentors Dr. Morris, an expert in HIV-related lung disease and the microbiome, and Dr. Gladwin, an expert in NO and pulmonary vascular disease, combined with the expansive array of resources available at the University of Pittsburgh, will support the candidate's successful development.         PUBLIC HEALTH RELEVANCE: Pulmonary vascular and cardiovascular diseases remain a major source of morbidity and mortality in HIV-infected individuals in the current era of effective antiretroviral therapy. Reduction of nitrate to nitrite and nitric oxide by commensal oral bacteria has recently been implicated in the maintenance of vascular function. Normal populations of bacteria that live in the mouth are key in maintaining adequate levels of nitric oxide and thus important in vascular function, but these key bacteria may be altered in those with HIV and contribute to excess pulmonary vascular and cardiovascular risk. This proposal will determine changes in the oral microbiome in HIV, the impact of these changes on nitrate reduction pathways, and relationship to markers of vascular function.            ",The oral microbiome and enterosalivary circulation of nitric oxide in HIV.,8924325,F32HL128165,"['3-nitrotyrosine', 'AIDS/HIV problem', 'Activities of Daily Living', 'Affect', 'Antioxidants', 'Arginine', 'Atherosclerosis', 'Award', 'Bacteria', 'Bioavailable', 'Biology', 'Biometry', 'Blood Circulation', 'Blood Vessels', 'Brain natriuretic peptide', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Physiology', 'Cardiovascular system', 'Catalytic Domain', 'Cerebrovascular Disorders', 'Chest', 'Chronic', 'Clinical', 'Clinical Research', 'Communities', 'DNA Sequence', 'Data', 'Deglutition', 'Development', 'Diet', 'Disease', 'Echocardiography', 'Enrollment', 'Enzymes', 'Exhibits', 'Fingerprint', 'Future', 'Generations', 'Glutathione', 'Goals', 'HIV', 'HIV Infections', 'Human', 'Hypoxia', 'IL6 gene', 'Immune', 'Individual', 'Inflammation', 'Injury', 'Interruption', 'Investigation', 'K-Series Research Career Programs', 'Laboratories', 'Lead', 'Life', 'Link', 'Lung', 'Lung diseases', 'Machine Learning', 'Maintenance', 'Maps', 'Master&apos', 's Degree', 'Measures', 'Mediating', 'Medicine', 'Mentors', 'Metabolism', 'Metagenomics', 'Methods', 'Mitochondria', 'Modeling', 'Morbidity - disease rate', 'Mucosal Immunity', 'Myocardial Infarction', 'N,N-dimethylarginine', 'N-terminal', 'NBL1 gene', 'National Research Service Awards', 'Nitrate Reductases', 'Nitrates', 'Nitric Oxide', 'Nitric Oxide Pathway', 'Nitric Oxide Synthase', 'Nitrite Reductase', 'Nitrites', 'Nitrogen', 'Oral', 'Oral cavity', 'Oxidative Stress', 'Oxygen', 'Participant', 'Pathogenesis', 'Pathway interactions', 'Phylogenetic Analysis', 'Physiological', 'Population', 'Production', 'Pulmonary Hypertension', 'Pulmonary artery structure', 'Pulmonology', 'Relative (related person)', 'Reperfusion Injury', 'Research', 'Research Design', 'Resources', 'Ribosomal DNA', 'Risk', 'Role', 'Salts', 'Sampling', 'Series', 'Serological', 'Signaling Molecule', 'Source', 'Stomach', 'Stress', 'Stretching', 'Supplementation', 'Taxon', 'Techniques', 'Testing', 'Time', 'Training', 'Translational Research', 'Universities', 'Vascular Diseases', 'Vascular Endothelium', 'Vasodilator Agents', 'antiretroviral therapy', 'base', 'blood pressure reduction', 'blood pressure regulation', 'cardiovascular health', 'cardiovascular risk factor', 'career', 'cohort', 'commensal microbes', 'experience', 'high risk', 'human NOS3 protein', 'immune activation', 'improved', 'microbial', 'microbial community', 'microbiome', 'mortality', 'new therapeutic target', 'nitrate reductase', 'nitrogen metabolism', 'novel', 'novel diagnostics', 'novel therapeutic intervention', 'oral bacteria', 'oral commensal', 'oral microbiome', 'pressure', 'prevent', 'prospective', 'public health relevance', 'pyrosequencing', 'reconstruction', 'serological marker', 'skills', 'stem', 'symposium', 'targeted treatment']",NHLBI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F32,2015,66566,-0.056059233759827104
"Second Harmonic Generation analysis of the ECM in idiopathic pulmonary fibrosis ﻿    DESCRIPTION (provided by applicant): Second Harmonic Generation analysis of the ECM in idiopathic pulmonary fibrosis Idiopathic pulmonary fibrosis (IPF) is a disorder characterized by unrelenting scarring and stiffening of the lungs that leads to the death of an estimated 34,000 individuals in the U.S. each year. Unfortunately, individuals with IPF have extremely limited treatment options, as no effective drugs have been identified to halt the progression of fibrosis. Despite the importance of collagens to the structural organization both normal and remodeled ECM, little is known about how collagen structure in IPF differs from that of normal tissue architecture. There is a clear need to develop highly specific/sensitive techniques to probe collagen structure and organization in IPF tissues. In this project we will implement new collagen specific analyses using the high resolution microscopy technique of Second Harmonic Generation (SHG). This method is sensitive to both the fibrillar organization and also sub-resolution aspects of macro and supramolecular assembly. Here we will utilize SHG microscopy to: 1) determine the how pathologic collagen organization (seen in IPF) differs from normal tissue; 2) identify and quantify areas of active fibrosis (enriched in collagen III) from ""old"" or mature fibrosis (high in collagen I) in IPF lung specimens; 3) assess changes in elastin and collagen distribution during disease progression; and 4) correlate areas of high collagen III/I signal in IPF histologic samples with clinical markers of disease activity. As part of the project, we will develop customized automated machine vision routines to automatically classify tissues in terms of severity. We will specifically focus all of our efforts on studying structure around fibroblastic foci, which will be identified by other microscope modalities. These foci are thought to be at the leading edge of ECM remodeling but the dynamics of their formation in relationship to the overall fibrotic process remain unclear. We hypothesize that these structural changes will serve as label- free biomarkers of IPF and further hypothesize that the collagen is altered specifically around foci in a manner which is associated with disease progression. The information gained may form the basis of future prognostic/diagnostic schemes. We propose 2 Aims: Aim 1 Polarization resolved SHG to determine distribution of Col I/III and other ECM changes in different stages of IPF.  Aim 2. Develop classification system of morphological changes in IPF visualized by SHG.         PUBLIC HEALTH RELEVANCE: Second Harmonic Generation analysis of the ECM in idiopathic pulmonary fibrosis Narrative Idiopathic fibrosis (IPF) patients have poor survival rates and there is also a lack of diagnostic/prognostic tools that have sufficient sensitivity and specificity to evaluate changes in collagen in the extracellular matrix. The methods developed here will improve upon these limitations and may lay the groundwork for eventual non- invasive in vivo imaging.            ",Second Harmonic Generation analysis of the ECM in idiopathic pulmonary fibrosis,8969087,R21HL126190,"['Architecture', 'Area', 'Biological Markers', 'Biomedical Engineering', 'Cessation of life', 'Cicatrix', 'Classification', 'Clinical', 'Clinical Markers', 'Collagen', 'Computer Vision Systems', 'Computers', 'Diagnostic', 'Disease', 'Disease Progression', 'Elastin', 'Equilibrium', 'Extracellular Matrix', 'Fibrosis', 'Future', 'Generations', 'Hamman-Rich syndrome', 'Histologic', 'Image', 'Individual', 'Label', 'Lung', 'Maintenance', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modeling', 'Monitor', 'Morphology', 'Normal tissue morphology', 'Pathologic', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protein Isoforms', 'Resolution', 'Sampling', 'Scheme', 'Scientist', 'Sensitivity and Specificity', 'Severities', 'Signal Transduction', 'Specimen', 'Staging', 'Structure', 'Survival Rate', 'System', 'Techniques', 'Texture', 'Thick', 'Three-Dimensional Imaging', 'Tissue Sample', 'Tissues', 'Vision', 'base', 'improved', 'in vivo imaging', 'interdisciplinary approach', 'prognostic', 'prognostic tool', 'public health relevance', 'second harmonic', 'tool']",NHLBI,UNIVERSITY OF WISCONSIN-MADISON,R21,2015,218370,-0.0323888560624361
"EMERGING TECHNOLOGIES: ASSESSING PHYSICAL ACTIVITY WITH WEBCAMS AND CROWDSOURCING DESCRIPTION (provided by applicant): Obesity is associated with numerous health outcomes including diabetes, heart disease, and cancer. Over 30% of adults and 17% of children in the US are obese, with lack of physical activity (PA) and constraints in the built environment (BE) common culprits. As such, the US Guide to Community Preventive Services currently recommends the following BE interventions to increase PA and reduce obesity: (1) community and street-scale urban design and land use policies; (2) creation of, or enhanced access to places for physical activity; and (3) transportation policies and practices. The proposed project will use an archive of 23,000 publically-available, online, outdoor webcams and crowdsourcing to develop reliable and valid tools to improve the capture of global PA patterns and BE characteristics. The specific aims are to: 1) Develop and test the reliability of using publically-available, outdoor webcams to enumerate BE characteristics and PA patterns across thousands of global outdoor environments; and 2) Develop and test the reliability and validity of using crowdsourcing to enumerate BE characteristics and PA patterns. (13) The aims will be accomplished by using the Archive of Many Outdoor Scenes (AMOS) that has collected over 325 million images of outdoor environments from more than 23,000 webcam since 2006. Every identified, outdoor, publically-available online webcam is added to the AMOS dataset with an image taken and archived every 30 minutes from the webcam thereafter. Scenes include street intersections, plazas, and parks. We will use crowdsourcing to annotate each webcam scene. The crowdsourcing platform is Amazon Mechanical Turk (AMT), an Internet marketplace allowing people to be paid to complete small, computer-based tasks. The individual tasks are posted to the AMT website. We will use AMT tasks to annotate each AMOS webcam scene by identifying BE characteristics (established from the Active Neighborhood Checklist and Public Open Space Tool) and patterns of PA (established from SOPARC). This study is significant in its ability to increase by orders of magnitude the amount and quality of global recorded measurements of PA patterns and associated BE characteristics. This project is innovative by: 1) combining two distinct disciplines to use public, outdoor webcams to evaluate PA patterns and BE characteristics; 2) utilizing crowdsourcing to provide simple PA counts and indication of BE characteristics; and 3) its ability to greatly improve the generalizability of public health surveillance. Our results will yield actionable knowledge regarding the use of webcams and crowdsourcing to assess PA and the BE. PUBLIC HEALTH RELEVANCE: This project aims to combine computer science and public health to use online, outdoor webcams and crowdsourcing to enumerate global physical activity patterns and built environment characteristics. Webcams and crowdsourcing will be evaluated for reliability and validity. Results will yield actionable knowledge regarding the use of webcams and crowdsourcing to assess PA patterns and BE characteristics.",EMERGING TECHNOLOGIES: ASSESSING PHYSICAL ACTIVITY WITH WEBCAMS AND CROWDSOURCING,9129822,R21CA186481,"['Address', 'Adult', 'Archives', 'Censuses', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Child', 'Collaborations', 'Communication', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Data Set', 'Diabetes Mellitus', 'Discipline', 'Emerging Technologies', 'Environment', 'Ethics', 'Evaluation', 'Feeds', 'Goals', 'Guidelines', 'Health', 'Health Sciences', 'Healthy People 2020', 'Heart Diseases', 'Hour', 'Image', 'Individual', 'Interdisciplinary Study', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Malignant Neoplasms', 'Measurement', 'Mechanics', 'Neighborhoods', 'Obesity', 'Online Systems', 'Outcome', 'Pattern', 'Physical activity', 'Policies', 'Population', 'Population Surveillance', 'Preventive', 'Public Health', 'Research', 'Sampling', 'Schools', 'Seasons', 'Services', 'Social Sciences', 'Technology', 'Testing', 'Time', 'Training', 'Transportation', 'Validity and Reliability', 'Weather', 'Work', 'base', 'built environment', 'cancer risk', 'computer science', 'design', 'experience', 'improved', 'innovation', 'land use', 'meetings', 'new technology', 'novel', 'tool', 'web site']",NCI,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R21,2015,123045,-0.007876391220330096
"EMERGING TECHNOLOGIES: ASSESSING PHYSICAL ACTIVITY WITH WEBCAMS AND CROWDSOURCING DESCRIPTION (provided by applicant): Obesity is associated with numerous health outcomes including diabetes, heart disease, and cancer. Over 30% of adults and 17% of children in the US are obese, with lack of physical activity (PA) and constraints in the built environment (BE) common culprits. As such, the US Guide to Community Preventive Services currently recommends the following BE interventions to increase PA and reduce obesity: (1) community and street-scale urban design and land use policies; (2) creation of, or enhanced access to places for physical activity; and (3) transportation policies and practices. The proposed project will use an archive of 23,000 publically-available, online, outdoor webcams and crowdsourcing to develop reliable and valid tools to improve the capture of global PA patterns and BE characteristics. The specific aims are to: 1) Develop and test the reliability of using publically-available, outdoor webcams to enumerate BE characteristics and PA patterns across thousands of global outdoor environments; and 2) Develop and test the reliability and validity of using crowdsourcing to enumerate BE characteristics and PA patterns. (13) The aims will be accomplished by using the Archive of Many Outdoor Scenes (AMOS) that has collected over 325 million images of outdoor environments from more than 23,000 webcam since 2006. Every identified, outdoor, publically-available online webcam is added to the AMOS dataset with an image taken and archived every 30 minutes from the webcam thereafter. Scenes include street intersections, plazas, and parks. We will use crowdsourcing to annotate each webcam scene. The crowdsourcing platform is Amazon Mechanical Turk (AMT), an Internet marketplace allowing people to be paid to complete small, computer-based tasks. The individual tasks are posted to the AMT website. We will use AMT tasks to annotate each AMOS webcam scene by identifying BE characteristics (established from the Active Neighborhood Checklist and Public Open Space Tool) and patterns of PA (established from SOPARC). This study is significant in its ability to increase by orders of magnitude the amount and quality of global recorded measurements of PA patterns and associated BE characteristics. This project is innovative by: 1) combining two distinct disciplines to use public, outdoor webcams to evaluate PA patterns and BE characteristics; 2) utilizing crowdsourcing to provide simple PA counts and indication of BE characteristics; and 3) its ability to greatly improve the generalizability of public health surveillance. Our results will yield actionable knowledge regarding the use of webcams and crowdsourcing to assess PA and the BE. PUBLIC HEALTH RELEVANCE: This project aims to combine computer science and public health to use online, outdoor webcams and crowdsourcing to enumerate global physical activity patterns and built environment characteristics. Webcams and crowdsourcing will be evaluated for reliability and validity. Results will yield actionable knowledge regarding the use of webcams and crowdsourcing to assess PA patterns and BE characteristics.",EMERGING TECHNOLOGIES: ASSESSING PHYSICAL ACTIVITY WITH WEBCAMS AND CROWDSOURCING,8787459,R21CA186481,"['Address', 'Adult', 'Archives', 'Censuses', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Child', 'Collaborations', 'Communication', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Data Set', 'Diabetes Mellitus', 'Discipline', 'Emerging Technologies', 'Environment', 'Ethics', 'Evaluation', 'Feeds', 'Goals', 'Guidelines', 'Health', 'Health Sciences', 'Healthy People 2020', 'Heart Diseases', 'Hour', 'Image', 'Individual', 'Interdisciplinary Study', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Malignant Neoplasms', 'Measurement', 'Mechanics', 'Neighborhoods', 'Obesity', 'Online Systems', 'Outcome', 'Pattern', 'Physical activity', 'Policies', 'Population', 'Population Surveillance', 'Preventive', 'Public Health', 'Research', 'Sampling', 'Schools', 'Seasons', 'Services', 'Social Sciences', 'Technology', 'Testing', 'Time', 'Training', 'Transportation', 'Validity and Reliability', 'Weather', 'Work', 'base', 'built environment', 'cancer risk', 'computer science', 'design', 'experience', 'improved', 'innovation', 'land use', 'meetings', 'new technology', 'novel', 'tool', 'web site']",NCI,WASHINGTON UNIVERSITY,R21,2015,16530,-0.007876391220330096
"Designing Visually Accessible Spaces DESCRIPTION (provided by applicant):  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions.  We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area).  This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement.  Our project addresses one of the National Eye Institute's program objectives:  ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals:  1) Empirical:  determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces.  2) Computational:  develop working models to predict low vision visibility and navigability in real-world spaces.  3) Deployment:  translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility.  The key scientific personnel in our partnership come from three institutions:  University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare.  This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare).  We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.",Designing Visually Accessible Spaces,8815314,R01EY017835,"['Accounting', 'Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Central Scotomas', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Health', 'Height', 'Human', 'Human Resources', 'Indiana', 'Individual', 'Injury', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Lobbying', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Physically Handicapped', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'falls', 'hazard', 'imaging system', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2015,550561,0.002364028872518691
"A Strength Analysis Tool for Studying Healthy Aging via Exercise in C. elegans ﻿    DESCRIPTION (provided by applicant): Exercise is arguably the most potent approach we can take to defer physical decline associated with aging and to protect against late onset diseases such as diabetes, cancer, and Alzheimer's disease. Molecular understanding of how exercise benefits translate into healthy aging is thus of definitive medical interest. We study fundamental processes relevant to healthy aging in the 959-celled nematode C. elegans. Recently we made a fascinating discovery-C. elegans can exercise (swim) to exhibit training benefits, and appear to gain benefits by molecular pathways conserved in humans. Our initial model development opens up a new research area for understanding how tissue-specific and organism-wide health benefits are induced by exercise, and creates a novel paradigm for identifying exercise mimetic drugs that might promote healthy aging. To really harvest the potential of this model, we need to measure the strength of the tiny C. elegans. We collaborated to develop a strength test in which trained animals thread through a matrix of deformable pillars, and the extent of pillar deflection is used to calculate force. Our ""NemaFlex"" force detection device is the quantitative foundation with which we expect to break new ground in understanding exercise impact on healthy aging. Here we propose required development to enhance assay throughput and pursue applications that will not only anchor this technology as an essential component of C. elegans exercise evaluation but also accelerate studies on exercise biology and healthy aging in this powerful model. Aim 1 is to develop a novel high throughput tool for direct strength evaluation in C. elegans.  This aim will generate an essential tool for analysis of C. elegans strength at multiple life stages, define the exercise regimen that will become the anchor protocol in the field, and reveal features of training in this model. Aim 2 is to use NemaFlex to evaluate exercise mimetic drugs & to facilitate focused pilot genetic screens. This aim will establish critical proof-of-principle for genetic and drug discovery using the NemaFlex. Aim 3 is to initiate dissection of the functional and molecular relationship between exercise and healthy aging, grounded in NemaFlex force measures of training benefits.  To begin, we will test how optimized strength training tracks with a broad spectrum of healthspan indicators that decline with age, we will investigate impact of cessation of training on aging quality, and we will ask if exercise mimetic drugs extend healthspan in the absence of training. Our goals will create novel technology that for the first time permits facile quantitativ analysis of exercise adaptations in the powerful C. elegans genetic model. Accomplishment of our tractable aims will anchor a new subfield of genetic investigation of exercise and healthy aging that may influence design of interventions that broadly promote health and defer aging.         PUBLIC HEALTH RELEVANCE: Exercise has a profound positive impact on health of the aging population in that it protects against age-associated diseases including cancer, diabetes, and cardiovascular disease, at the same time it maintains muscle, immune system, and nervous system function in aging. We are developing the first exercise model in the simple animal C. elegans, in which training benefits appear mediated by conserved mechanisms and exercise promotes healthy aging. We will optimize a novel tool for direct strength measurement of these tiny 959-celled animals and show how our device can facilitate searches for exercise mimetic drugs and genes that are associated with training adaptations, and can also help define exercise impact on a broad range of healthy aging measures. The experimental advantages of C. elegans may yield unexpected insights that inspire development of novel interventions that protect against age-associated disease and age-associated decline.              ",A Strength Analysis Tool for Studying Healthy Aging via Exercise in C. elegans,8936078,R21AG050503,"['Address', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Animals', 'Area', 'Automation', 'Biological Assay', 'Biology', 'Biology of Aging', 'Caenorhabditis elegans', 'Cardiac', 'Cardiovascular Diseases', 'Cells', 'Collaborations', 'Computer Vision Systems', 'Detection', 'Development', 'Device Designs', 'Devices', 'Diabetes Mellitus', 'Disease', 'Dissection', 'Elderly', 'Engineering', 'Evaluation', 'Exercise', 'Exhibits', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Engineering', 'Genetic Models', 'Genetic Screening', 'Goals', 'Harvest', 'Health', 'Health Benefit', 'Human', 'Immune system', 'Intervention', 'Investigation', 'Late-Onset Disorder', 'Life', 'Longevity', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediating', 'Mediator of activation protein', 'Medical', 'Modeling', 'Molecular', 'Molecular Genetics', 'Muscle', 'Muscle function', 'Nematoda', 'Nervous System Physiology', 'Organism', 'Outcome', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Protocols documentation', 'Pump', 'Regimen', 'Reporting', 'Research', 'Staging', 'Swimming', 'System', 'Technology', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translating', 'Work', 'aging population', 'anti aging', 'base', 'cognitive function', 'design', 'drug discovery', 'experience', 'fascinate', 'healthy aging', 'immune function', 'improved', 'insight', 'interest', 'mimetics', 'model development', 'new technology', 'novel', 'programs', 'public health relevance', 'strength training', 'therapy design', 'tool']",NIA,TEXAS TECH UNIVERSITY,R21,2015,235630,-0.022938930115809195
"Translating from Rats to Humans: A Human Foraging Model of Decision-Making No abstract available PUBLIC HEALTH RELEVANCE:  Animal models of addiction are some of the most highly regarded models of psychopathology; however, there remains a disconnection between these pre-clinical models and treatment outcomes.  This division may be, in part, due to untested assumptions that different species recruit the same cognitive systems in the compared tasks.  The novel research outlined in this proposal will help improve the translation between human and nonhuman animal models, and in turn, improve treatment efficacy for these disorders.                ",Translating from Rats to Humans: A Human Foraging Model of Decision-Making,8977868,F31DA040335,"['Accounting', 'Advanced Development', 'Aggressive behavior', 'Alcohol or Other Drugs use', 'Animal Model', 'Animals', 'Back', 'Basic Science', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Categories', 'Chronic', 'Clinical', 'Clinical Psychology', 'Clinical Research', 'Clinical Sciences', 'Clip', 'Cognitive', 'Data', 'Decision Making', 'Development', 'Disease', 'Disinhibition', 'Economics', 'Emotional', 'Evaluation', 'Event', 'Exhibits', 'Faculty', 'Food', 'Human', 'Impulsivity', 'Individual Differences', 'Internet', 'Intervention', 'Investigation', 'Linear Models', 'Literature', 'Machine Learning', 'Magnetic Resonance', 'Maps', 'Measures', 'Mentorship', 'Methods', 'Minnesota', 'Modeling', 'Neurosciences', 'Participant', 'Patient Self-Report', 'Pattern', 'Pre-Clinical Model', 'Process', 'Psychology', 'Psychopathology', 'Rattus', 'Recruitment Activity', 'Regrets', 'Research', 'Research Personnel', 'Resources', 'Restaurants', 'Rewards', 'Sampling', 'Series', 'Staging', 'Stimulus', 'Students', 'Substance abuse problem', 'System', 'Task Performances', 'Testing', 'Time', 'Translating', 'Translations', 'Travel', 'Treatment Efficacy', 'Treatment outcome', 'Universities', 'Variant', 'Ventral Striatum', 'Work', 'addiction', 'analog', 'base', 'behavior test', 'cognitive process', 'cognitive system', 'design', 'effective therapy', 'experience', 'graduate student', 'human ethology', 'human subject', 'improved', 'neuroimaging', 'neurophysiology', 'novel', 'pleasure', 'pre-clinical', 'preference', 'public health relevance', 'relating to nervous system', 'research study', 'stem', 'trait', 'trait impulsivity', 'willingness']",NIDA,UNIVERSITY OF MINNESOTA,F31,2015,38875,-0.02001637602549929
"GPU COMPUTING RESOURCE TO ENABLE INNOVATION IN IMAGING AND NETWORK BIOLOGY     DESCRIPTION:  Many complex diseases such as cancer, cardiovascular disorders, and schizophrenia may be understood as failures in the functioning of nested hierarchies of biomolecular and cellular networks. These nested hierarchies control a range of processes including the differentiation and migration of cells, remodeling of extracellular matrices and tissues, and information encoding in neuronal subsystems. Washington University has established expertise in cutting edge imaging, molecular biology and genomic technologies synergistic with computational approaches such as machine learning and unraveling the principles of hierarchical organization and dynamics of complex systems. This collective expertise is being leveraged to develop new drugs, improve our ability to interpret sophisticated imaging data, understand how populations of neurons act collectively to accomplish complex tasks, and model the onset and progression of complex diseases as dynamical rewiring of hierarchical, multi-scale networks. Biological network analyses provide a rich set of tools for organizing and interpreting the vast quantities of data produced by state-of-the-art experimental protocols. The rapid advancement of computationally intensive research in these areas is outstripping the capabilities of CPU-based high performance computing (HPC) systems. This application would support the acquisition and integration of a large-scale IBM high performance cluster of Graphics Processor Units (GPUs) to be added as an upgrade to the existing IBM-designed Heterogeneous High Performance Computing environment to form a state-of-the-art hybrid computing capability. Such a resource is essential to match the growing need for high performance computing at Washington University and to support state of the art research software applications that are optimized for GPU computing. The acquisition and integration of a high performance GPU cluster will solve critical computing challenges that exist within Washington University's growing NIH research portfolio. The proposed state-of-the-art hybrid GPU/CPU computing capabilities will be deployed within the framework of a stable, productive and rapidly growing resource center. The addition of high-capacity GPU computing capabilities will allow critical calculation to be performed in hours instead of days and enable substantial increases in productivity for existing projects covering a broad range of application areas as well as enabling new research directions.             n/a",GPU COMPUTING RESOURCE TO ENABLE INNOVATION IN IMAGING AND NETWORK BIOLOGY,8640341,S10OD018091,"['Area', 'Biological', 'Biology', 'Cardiovascular Diseases', 'Complex', 'Computer Systems', 'Computer software', 'Data', 'Disease', 'Environment', 'Extracellular Matrix', 'Failure', 'Genomics', 'High Performance Computing', 'Hour', 'Hybrids', 'Image', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular Biology', 'Neurons', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Productivity', 'Protocols documentation', 'Research', 'Resources', 'Schizophrenia', 'System', 'Technology', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'cell motility', 'computing resources', 'design', 'improved', 'innovation', 'tool']",OD,WASHINGTON UNIVERSITY,S10,2014,597700,-0.026100173408700154
"Reproducibility Assessment for Multivariate Assays  Project Summary. This Small Business Innovation Research project addresses the problem of assessing reproducibility in analyzing high-throughput data. In feature selection for data with large numbers of fea- tures, it is well known that some features will appear to affect an outcome by chance, and that subsequent predictions based on these features may not be as successful as initial results would seem to indicate. Similarly, there are often multiple stages, and many parameters, involved in the multivariate assays de- signed to analyze high-throughput profiles. For example, good results achieved with a particular combina- tion of settings for an instance of cross-validation may not generalize to other instances. The objective of this proposal is to extend new statistical methods for assessing reproducibility in replicate experiments to the context of machine learning, and demonstrate effectiveness in this application. The machine-learning methods to be investigated will include random forests, supervised principal components, lasso penal- ization and support vector machines. We will use simulated and real data from genomic applications to show the potential of this approach for providing reproducibility assessments that are not confounded with prespecified choices, for determining biologically relevant thresholds, for improving the accuracy of signal identification, and for identifying suboptimal results. Relevance. Although today's high-throughput technologies offer the possibility of revolutionizing clinical practice, the analytical tools available for extracting information from this amount of data are not yet sufficiently developed for targeted exploration of the underlying biology. This project directly addresses the need to make what the FDA terms IVDMIA (In-Vitro Diagnostic Multivariate Index Assays) transparent, interpretable, and reproducible, and is thus an opportunity to improve analysis products and services provided to companies that identify, characterize, and validate biomarkers for clinical diagnostics and drug development decision points. The long-term goal of the proposed project is to develop a platform for biomarker discovery and integrative genomic analysis, with reproducibility assessment incorporated into multivariate assays. This will enable evaluation and improvement of approaches to detecting the biological factors that affect a particular outcome, and lead to more efficient and more effective methods for disease diagnosis, treatment monitoring, and therapeutic drug development. PUBLIC HEALTH RELEVANCE: Statistical models play a key role in medical research in uncovering information from data that leads to new diagnostics and therapies. However, development of standards for reliability in biomedical data mining has not kept up with the rapid pace at which new data types and modeling approaches are being devised. This proposal is for new methods for quantifying reproducibility in biomedical data analyses that will have a far-reaching impact on public health by streamlining protocols, reducing costs and offering more effective clinical support systems.            ",Reproducibility Assessment for Multivariate Assays,8647816,R43GM109503,"['Address', 'Affect', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Assay', 'Biological Factors', 'Biological Markers', 'Biology', 'ChIP-seq', 'Clinical', 'Cloud Computing', 'Data', 'Data Analyses', 'Decision Trees', 'Development', 'Diagnostic', 'Dimensions', 'Effectiveness', 'Evaluation', 'Evolution', 'Genomics', 'Goals', 'Guidelines', 'In Vitro', 'Investigation', 'Lasso', 'Lead', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Performance', 'Phase', 'Play', 'Protocols documentation', 'Public Health', 'Publishing', 'ROC Curve', 'Reproducibility', 'Research Project Grants', 'Scheme', 'Services', 'Signal Transduction', 'Simulate', 'Small Business Innovation Research Grant', 'Source', 'Specific qualifier value', 'Staging', 'Statistical Methods', 'Statistical Models', 'Support System', 'Techniques', 'Technology', 'Therapeutic', 'Trees', 'Validation', 'analytical tool', 'base', 'clinical practice', 'cost', 'data mining', 'design', 'disease diagnosis', 'drug development', 'follow-up', 'forest', 'high throughput technology', 'improved', 'indexing', 'novel diagnostics', 'public health relevance', 'research study']",NIGMS,INSILICOS,R43,2014,131071,-0.02411663254097265
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8704932,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild cognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'screening', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2014,338287,-0.034864782956803675
"Hand Sensorimotor Function and Carpal Tunnel Syndrome    DESCRIPTION (provided by applicant): The median nerve is susceptible to compression in the wrist, leading to carpal tunnel syndrome (CTS). CTS is the most common compression neuropathy and have an immense impact on national health care, worker productivity, and quality of life. Despite its high prevalence and public health cost, our understanding of CTS is limited, and the management of CTS awaits improvement. The central notion of this project is that hand sensorimotor function is sensitive to peripheral median neuropathy and that the central nervous system is affected by CTS, causing the associated sensorimotor deficit. We will investigate this notion with quantifiable sensorimotor data from novel biomechanical and neurophysiological studies. This project has three aims consisting of biomechanical, neurophysiological and translational research. The first aim is to investigate CTS-induced pathokinematic and pathokinetic performance using dexterous manual tasks of thumb opposition, reach-to-pinch, precision grip, and finger pressing. The second aim is to investigate the neurophysiological implications of chronic peripheral neuropathy (i.e., CTS) on the central nervous system by evaluating corticomuscular coupling and stretch reflex. The third aim is to identify novel biomechanical and neurophysiological markers for CTS cases using machine learning and classification algorithms. The results of this project will elucidate the pathological mechanisms and behavioral manifestations of CTS and aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder. More generally, CTS as a chronic neuropathy serves as an effective model to study sensorimotor mechanisms of the peripheral and central nervous systems. In addition, the methodology developed in this project is applicable to other neuromuscular disorders.       PUBLIC HEALTH RELEVANCE:   Carpal tunnel syndrome is highly prevalent and costly. One of the distinct consequences of carpal tunnel syndrome is that patients experience inexplicable dropping of objects and clumsiness while performing simple daily tasks. In this project, we propose to study the sensorimotor deficit using novel biomechanical and neurophysiological experiments. The results of this project will elucidate the pathological mechanisms and manifestations of carpal tunnel syndrome. This project is clinically translational to aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder.               ",Hand Sensorimotor Function and Carpal Tunnel Syndrome,8627111,R01AR056964,"['Abnormal coordination', 'Affect', 'Algorithms', 'Behavioral Mechanisms', 'Biomechanics', 'Carpal Tunnel Syndrome', 'Carpometacarpal joint structure', 'Chronic', 'Classification', 'Clinical', 'Coupling', 'Data', 'Development', 'Disease', 'Drops', 'Electroencephalography', 'Electromyography', 'Exertion', 'Eye', 'Fingers', 'Hand', 'Health Care Costs', 'Health Personnel', 'High Prevalence', 'Human', 'Individual', 'Joints', 'Lasso', 'Machine Learning', 'Manuals', 'Measures', 'Median Neuropathy', 'Metacarpophalangeal joint structure', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Cortex', 'Neural Conduction', 'Neuraxis', 'Neuromuscular Diseases', 'Neuropathy', 'Patients', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Production', 'Productivity', 'Pronation', 'Public Health', 'Quality of life', 'Questionnaires', 'Reaction', 'Rehabilitation therapy', 'Reproducibility', 'Research', 'Response Latencies', 'Sensorimotor functions', 'Sensory', 'Techniques', 'Testing', 'Thumb structure', 'Time', 'Translational Research', 'Trees', 'Validation', 'Wrist', 'data mining', 'diagnosis evaluation', 'experience', 'grasp', 'improved', 'indexing', 'median nerve', 'motor control', 'neurophysiology', 'novel', 'programs', 'public health relevance', 'research study', 'response', 'stretch reflex', 'tool', 'vector']",NIAMS,CLEVELAND CLINIC LERNER COM-CWRU,R01,2014,346185,-0.014588068691494203
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8689173,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2014,202714,-0.01788055663546809
"Scalable Biomedical Pattern Recognition Via Deep Learning DESCRIPTION (provided by applicant): Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.  The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is  being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.  Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.  In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes. Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,9302040,R21LM011664,[' '],NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R21,2014,7696,-0.01788055663546809
"In vivo Characterization of Stents using Intravascular OCT Imaging     DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel.         PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,8724992,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Simulate', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thrombosis', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'public health relevance', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2014,402534,-0.010901879233420527
"Image-guided planning system for skull correction in children with craniosynostos     DESCRIPTION (provided by applicant): Craniosynostosis is the premature fusion of cranial sutures and occurs in approximately one in 2000 live births. It results in cranial malformation that can lead to elevated intra-cranial pressure, brain growth impairment, and developmental deficiency. The most common treatment option for craniosynostosis is surgery. Currently, surgical treatment planning of craniosynostosis is mostly qualitative, subjective and irreproducible guided mainly by the surgeon's experience. While virtual planning has been successfully introduced in niche areas of craniofacial surgery, such as corrective jaw surgery applications, clinical tools that provide accurate and reproducible evaluation of cranial morphology to guide cranial vault remodeling do not yet exist. To cover this gap in current clinical practice, we will develop personalized preoperative planning for infants with craniosynostosis that allows for decreased operative time and blood loss, thereby reducing perioperative morbidity, but also facilitates an optimized and more durable long-term outcome.  In this Phase I STTR project, our goal is to design, develop and validate a virtual surgery system for optimal treatment planning for cranial remodeling. The plan includes creating a normative multi-atlas database to capture a wide breadth of normal variations on cranial shape and patient ages, developing image processing and statistical shape analysis algorithms to identify desirable post-operative skull shapes, and analyzing biomechanical properties of cranial bones to evaluate osteotomy plans. The surgeon will be presented with a visual and quantitative map of the patient's cranial malformations, the desired post-treatment cranial shape, and a personalized plan of how cranial shape should be altered in the least invasive fashion to most accurately approach the normal head shape. The impact of our technology is reduced perioperative morbidity and lower treatment costs. The technology will also enable the precise, quantitative comparison of measurements before and after cranial vault reconstruction to determine the efficacy and durability of specific reconstructive techniques.         PUBLIC HEALTH RELEVANCE: Craniosynostosis is the premature fusion of cranial sutures and occurs in approximately one in 2000 live births. It results in cranial malformation that can lead to elevated intra-cranial pressure, brain growth impairment, and developmental deficiency. The most common treatment option for craniosynostosis is surgery. The standard planning techniques for surgical treatment of craniosynostosis are qualitative and subjective and guided mainly by surgeon's experience. For precise and reproducible outcomes, we will create and validate a software technology for treatment planning and evaluation of craniosynostosis using image analysis techniques.            ",Image-guided planning system for skull correction in children with craniosynostos,8778815,R41HD081712,"['Address', 'Adult', 'Aftercare', 'Age', 'Algorithms', 'Area', 'Atlases', 'Biomechanics', 'Brain', 'Cephalic', 'Child', 'Clinical', 'Clinical Trials', 'Clinical assessments', 'Collaborations', 'Complex', 'Computer software', 'Craniosynostosis', 'Data', 'Databases', 'Development', 'Ethnic Origin', 'Evaluation', 'Goals', 'Growth', 'Head', 'Helmet', 'Hemorrhage', 'Hospitals', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Infant', 'Institution', 'Intervention', 'Jaw', 'Joint structure of suture of skull', 'Lead', 'Live Birth', 'Machine Learning', 'Maps', 'Measurement', 'Medical Imaging', 'Medical center', 'Methods', 'Molds', 'Morbidity - disease rate', 'Morphology', 'Operative Surgical Procedures', 'Osteotomy', 'Outcome', 'Patients', 'Pediatric Research', 'Perioperative', 'Phase', 'Planning Techniques', 'Postoperative Period', 'Property', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Shapes', 'Simulate', 'Small Business Technology Transfer Research', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Translations', 'Treatment Cost', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'age group', 'base', 'bone', 'clinical application', 'clinical practice', 'commercialization', 'common treatment', 'craniofacial', 'cranium', 'design', 'experience', 'graphical user interface', 'image processing', 'improved', 'innovation', 'interest', 'malformation', 'premature', 'pressure', 'public health relevance', 'reconstruction', 'research and development', 'shape analysis', 'success', 'tool', 'treatment planning', 'virtual']",NICHD,"KITWARE, INC.",R41,2014,224798,-0.0190000748008209
"Intraocular Robotic Interventional Surgical System for Cataract Surgery Project     DESCRIPTION (provided by applicant): Surgical outcomes have been dramatically improved in the last 2 decades through the integration of new technologies including among other innovative visualization systems and robotic assistance. We think that cataract surgery can also benefit from these advancements and we envision that cataract surgery will possibly be entirely performed in fifteen years from now by an automated robotic surgical platform. The goal of the present proposal is to develop automated capabilities of the Intraocular Robotic Interventional Surgical System (IRISS) based on its new abilities to reconstruct in real time the anatomical structures of the anterior segment of the eye. This 3D real time reconstruction of the anterior segment of the eye is made possible by the joint use of Computer Vision techniques and Optical Coherence Tomography (OCT) acquisition and analysis. Cataracts are the number one cause of blindness in the world and cataract surgery is the most frequently performed operation totaling 3 million operations every year in the United States. The procedure accounts for the single largest expenditure for any Part B procedure in the Medicare Program. The modern cataract surgical procedure involves several steps each with significant potential for complicated inadvertent tissue manipulation possibly resulting in intraocular trauma. Previous studies have shown that undesired tissue manipulation can be significantly decreased using robotic systems that attenuate undesirable movement, and possibly collision, of surgical tools both intraocularly and at the site of incision. Thus, we have developed IRISS, the first dual arm, intraocular robotic surgical system designed for performing intraocular surgeries with a primary focus on cataract surgery. Preliminary results have shown an optimization of vibration reduction, a controlled remote center of motion (RCM) for both robotic arms and the ability to mount multiple surgical instruments to either arm with automated surgical instrument replacement. The system has been used to perform successfully Ex Vivo cataract surgeries on pig eyes by teleoperation, completing capsulorhexis, lens aspiration, as well as maneuvers even more technically challenging than cataract removal such as vitrectomy and retinal vein cannulation To achieve automated cataract surgery, the present study will develop new vision- based object tracking system utilizing real time local gradient orientation analysis algorithms and develop an OCT guided 3D real-time reconstruction of the anterior segment of the eye to offer feedback to the robotic system. We hypothesize that an improved anatomical detection system will decrease the incidence of undesirable trauma to ocular tissues by creating restrictions on the proximity of surgical tools to ocular structures. By performing Ex Vivo testing of cataract extraction surgeries on harvested pig eyes, the efficacy and accuracy of the system will be assessed by the evaluation of the corneal endothelial cell, the iris and the capsular bag integrity and of the complete removal of the lens material.         PUBLIC HEALTH RELEVANCE: This project will develop new capabilities of the robotic manipulated platform to perform an automated cataract extraction surgical procedure. Automated lens extraction will be achieved using real-time tracking and 3D reconstruction of the ocular structures. In automating the surgical procedure we believe that the incidence of inadvertent tissue manipulation, and the associated intraocular tissue trauma, will decline.            ",Intraocular Robotic Interventional Surgical System for Cataract Surgery Project,8773508,R21EY024065,"['Accounting', 'Algorithms', 'Anatomy', 'Anterior eyeball segment structure', 'Attenuated', 'Automation', 'Blindness', 'Cannulations', 'Capsulorhexis', 'Cataract', 'Cataract Extraction', 'Computer Vision Systems', 'Cornea', 'Corneal Endothelium', 'Detection', 'Endothelial Cells', 'Environment', 'Evaluation', 'Excision', 'Expenditure', 'Eye', 'Family suidae', 'Feedback', 'Goals', 'Hand', 'Harvest', 'Human', 'Image', 'Imagery', 'Incidence', 'Iris', 'Irrigation', 'Joints', 'Lasers', 'Manuals', 'Medicare', 'Modeling', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Ophthalmologic Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Procedures', 'Reproducibility', 'Risk', 'Robotics', 'Site', 'Stress', 'Structure', 'Structure of central vein of the retina', 'Surgical Instruments', 'Surgical complication', 'Surgical incisions', 'System', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Trauma', 'United States', 'Vision', 'Visual', 'Vitrectomy', 'arm', 'base', 'capsule', 'design', 'improved', 'innovation', 'instrument', 'lens', 'new technology', 'operation', 'optical imaging', 'programs', 'public health relevance', 'reconstruction', 'research study', 'robot assistance', 'tissue trauma', 'tomography', 'tool', 'vibration']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2014,46275,0.0012902921859160078
"Elucidating Synaptic Regulators via High-Throughput Morphology Characterization DESCRIPTION (provided by applicant): Many neurological diseases occur in the absence of neurodegenerative pathology, such as neurotransmission disorders. Deficient neurotransmission is a hallmark of many neurological diseases, such as depression, schizophrenia and autism. Moreover, deterioration in synaptic function also appears during ageing, accompanied by a decline in cognitive and behavioral function. Synaptic strength and plasticity, important in cognitive functions such as memory, are affected by synaptic activity. However, the regulators of synaptic strength, either activity-dependent or independent, are far from understood. Here, I propose to explore how environmental cues and ageing can affect synaptic morphology in the nematode C. elegans, and how this correlates to synaptic function and activity. In C. elegans, which is an excellent model for neuroscience, synaptic sites can be observed with fluorescent fusion proteins. However, fluorescently labeled synaptic sites are small and faint, and obtaining large number of high-content data poses many experimental limitations. The main goal of this proposal is to elucidate regulators of synaptic function through  multidimensional morphological profiling of synaptic sites. This work is composed of a mentored and an independent research phase. During the mentored phase, I will develop tools that allow high-throughput quantitative multidimensional profiling of synaptic morphology in large populations of animals. These tools are based on combining microfluidics, automation, and computer vision methods for image analysis, which enable streamlined quantitative morphological characterization of synaptic sites. In addition to this, tools to determine synaptic function in the motor circuit through the quantification of locomotive activity and controlled stimulation of excitatory neurons will be developed to correlate synaptic morphology to function. The mentored phase will also include extensive training in various aspects: technology development, biology and neuroscience, and career development. The scientific environment at the institution of the mentored phase is highly collaborative and provides excellent support in terms of facilities and intellectual opportunities. During the independent research phase, I plan to apply the developed tools during the mentored phase to uncover how environmental cues can affect synaptic function through activity dependent or independent mechanisms. I will also utilize these tools to study synaptic decline during aging, and how exposure to environmental regulators of synaptic function during development can alter synaptic decline during aging. In this way, we will be able to address a biological question unapproachable with conventional methods. This approach is innovative not only because the technology developed will greatly increase the throughput and quality of characterization, but also because it proposes studying the links between form and function in synaptic sites. This project is significant because it will enable streamlined morphological studies in neuroscience, which should lead to uncovering pathways, genes and potential therapies for synaptic function deficiencies due to disease or age-related decline. PUBLIC HEALTH RELEVANCE: Defective neurotransmission is the cause of many neurological diseases ranging from depression to autism. Understanding the regulators of synaptic strength can shed light on pathways that play a role in establishing healthy synaptic function, and treatments for neurotransmission-related diseases.",Elucidating Synaptic Regulators via High-Throughput Morphology Characterization,8618418,K99AG046911,"['Address', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Autistic Disorder', 'Automation', 'Behavioral', 'Biological', 'Biology', 'Caenorhabditis elegans', 'Chimeric Proteins', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Defect', 'Descriptor', 'Deterioration', 'Development', 'Disease', 'Docking', 'Electron Microscopy', 'Engineering', 'Environment', 'Epigenetic Process', 'Exposure to', 'Fluorescence', 'Genes', 'Genetic', 'Genetic Screening', 'Goals', 'Health', 'Heterogeneity', 'Huntington Disease', 'Image', 'Image Analysis', 'Impaired cognition', 'Institution', 'Ion Channel', 'Label', 'Lead', 'Life', 'Light', 'Link', 'Locomotion', 'Longevity', 'Measures', 'Memory', 'Mental Depression', 'Mentors', 'Methods', 'Microfluidics', 'Microscopy', 'Modeling', 'Mood Disorders', 'Morphology', 'Motor', 'Movement', 'Mutation', 'Nematoda', 'Nerve Degeneration', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurotransmitters', 'Parkinson Disease', 'Pathology', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Play', 'Population', 'Preclinical Drug Evaluation', 'Presynaptic Terminals', 'Research', 'Role', 'Sampling', 'Schizophrenia', 'Signal Transduction', 'Site', 'Synapses', 'Synaptic Cleft', 'Synaptic Transmission', 'Synaptic Vesicles', 'Syncope', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Work', 'age related', 'base', 'career development', 'cognitive function', 'excitatory neuron', 'in vivo', 'innovation', 'nervous system disorder', 'neurotransmission', 'neurotransmitter release', 'neurotransmitter uptake', 'normal aging', 'optogenetics', 'post-doctoral training', 'postsynaptic', 'presynaptic', 'receptor', 'relating to nervous system', 'response', 'synaptic function', 'technology development', 'tissue fixing', 'tool']",NIA,GEORGIA INSTITUTE OF TECHNOLOGY,K99,2014,90000,-0.014493705446170704
"Context Understanding Technology to improve internet accessibility for users with DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a  web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization. PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.",Context Understanding Technology to improve internet accessibility for users with,8609036,R44EY020082,"['Advertisements', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Grouping', 'Health', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2014,357073,0.0001256083561111442
"Individualized Signal Processing Strategy to Reduce Hearing Health Care Cost/Disp  This project describes a novel approach to automate and individualize the signal processing strategy for hearing aids that can result in improved speech intelligibility in background noise, greater user satisfaction and acceptance for hearing aids, and reduce barriers to affordable hearing health care. The proposed Individualized Signal Processing Strategy (ISPS) is based upon individual performance on categorical perception tasks for speech stimuli. This differs from traditional methods based on sophisticated gain models built upon average perception, performance, and preference data. The ability to determine one's ISPS automatically, rapidly and remotely results in dramatic cost-savings and greater accessibility to hearing health care for patients who cannot afford it or for those who lack easy access to the necessary expertise. These technical achievements have the potential to radically change the hearing aid sales and delivery models yet can also be implemented within existing business models by replacing contemporary hearing aid fitting methods (e.g. adjusting to gain-frequency targets followed by subjective fine tuning) with individualized speech-based parameter adjustment. Successful implementation of the ISPS technology will impact several barriers identified in RFA-DC-12-004 including physical, infrastructure and knowledge barriers (by allowing remote or self-fitting hearing aids and minimizing the need for highly skilled expertise), economic barriers (by reducing overall costs) and cultural barriers (by providing easy access to hearing aid fitting for patients who tend to avoid seeking professional help). This Phase I project will demonstrate the feasibility for the ISPS approach by (1) implementing the ISPS on a standard personal computer, (2) integrating the ISPS with a commercially available hearing aid, and (3) completing a pilot clinical study comparing outcomes with ISPS fitting to those achieved with traditional prescriptive gain fitting within the same subjects. Following successful demonstration of these objectives, a Phase II project will be proposed to enable extension of the technology to a wide range of hearing aids, patient characteristics and listening environments, including innovations supporting the use for remote and self-fitting applications. PUBLIC HEALTH RELEVANCE: This project seeks to develop, implement and test a novel approach for fitting hearing aids using an individual's speech perception abilities. This automated approach can improved listener performance while significant reducing costs of hearing health care. The automation of the fitting procedure can dramatically increase accessibility of hearing health care.                ",Individualized Signal Processing Strategy to Reduce Hearing Health Care Cost/Disp,8626066,R43DC013623,"['Achievement', 'Acoustics', 'Artificial Intelligence', 'Audiology', 'Automation', 'Behavioral', 'Businesses', 'Canada', 'Characteristics', 'Clinical Research', 'Cochlear Implants', 'Collection', 'Computer software', 'Cost Savings', 'Crossover Design', 'Data', 'Devices', 'Economics', 'Effectiveness', 'Environment', 'Frequencies', 'Generations', 'Goals', 'Graph', 'Health Care Costs', 'Healthcare', 'Hearing', 'Hearing Aids', 'Individual', 'Knowledge', 'Learning', 'Letters', 'Manufacturer Name', 'Maps', 'Measures', 'Methods', 'Metric', 'Modeling', 'Modification', 'Noise', 'Outcome', 'Output', 'Patients', 'Pattern', 'Perception', 'Performance', 'Personal Computers', 'Persons', 'Phase', 'Pilot Projects', 'Procedures', 'Process', 'Randomized', 'Research', 'Research Infrastructure', 'Sales', 'Services', 'Solutions', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Stimulus', 'Technology', 'Testing', 'Time', 'Training', 'Translations', 'Work', 'base', 'cost', 'design', 'experience', 'implantable device', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'novel', 'novel strategies', 'preference', 'public health relevance', 'satisfaction', 'signal processing', 'sound', 'success', 'theories']",NIDCD,"SECURBORATION, INC.",R43,2014,149994,-0.05755189683701448
"Computer-based simulation Pediatric disaster Triage Training for Emergency Medica  ABSTRACT Children are not small adults. Nowhere is this understanding more critical than in the aftermath of a disaster event, when the strained resources of healthcare providers must be directed where they can do the most good in the least time. Frontline responders are unfortunately rarely trained in the principles and practice of pediatric disaster triage and often do not understand the special pediatric needs and considerations they must take into account when acting decisively and quickly to direct actions in a stressful situation that is often chaotic and always taxing. Researchers at Yale University School of Medicine (YSM) have developed a live simulation training protocol on pediatric disaster triage that has been shown to be effective but also relatively expensive, resource-intensive and therefore difficult to disseminate widely. The Yale New Haven Health System Center for Healthcare Solutions (YNHHS-CHS) has taken up this challenge, proposing to use YNHHS-CHS expertise with online training solutions and web development to create and implement a computer-based simulation that will build on the live simulation model and carry the research into a new medium that will be more cost-effective and able to more broadly engage and educate greater numbers of emergency medical service providers (EMSPs). YNHHS-CHS specialists with design and training skills will use the expertise of YSM pediatric emergency medicine specialists Mark Cicero, MD, who developed the live simulation training, and Marc Auerbach, MD, and the YNHHS-CHS network of emergency management contacts to engage EMSPs in this learning process. The computer- based simulation training will be delivered to 600 EMSPs in southern New England (Connecticut, Rhode Island and Massachusetts) and evaluated for future broader dissemination. Multiple retention evaluations, scenario-based and decision-tree driven, will be conducted: immediately at the end of the online training and at three- and six-month intervals post-training to determine the value of the training in delivering information and fostering the ability to apply it in simulated scenarios. A 10% random sampling of participants will also take an in-person live simulation retention evaluation to further assess and demonstrate the usefulness of the training. The project objective is to achieve a success rate of >80% of learners performing pediatric disaster triage with accuracy that is >/=90%. PUBLIC HEALTH RELEVANCE: Emergency planners often focus on large-scale disaster events, but smaller-scale local events are far more common and together have a much greater impact on the health and well-being of communities - particularly events involving children, such as bus accidents or school-related crises. Children are often present at a disaster site and sorting out their needs and requirements can be a significant challenge to emergency medical service providers. This project brings together Yale School of Medicine pediatric emergency medicine specialists and Yale New Haven Health System Center for Healthcare Solutions instructional design and emergency management experts who are committed to developing a training that delivers the greatest possible efficiency and effectiveness with the greatest possibl accuracy in making choices and directing appropriate healthcare resources to improve disaster event outcomes and mitigate negative consequences for children, disasters' most vulnerable and often least understood victims.            ",Computer-based simulation Pediatric disaster Triage Training for Emergency Medica,8664515,R18HS022837,[' '],AHRQ,YALE UNIVERSITY,R18,2014,720455,-0.02117646195836672
"Informatic tools for predicting an ordinal response for high-dimensional data    DESCRIPTION (provided by applicant):        Health status and outcomes are frequently measured on an ordinal scale. Examples include scoring methods for liver biopsy specimens from patients with chronic hepatitis, including the Knodell hepatic activity index, the Ishak score, and the METAVIR score. In addition, tumor-node-metasis stage for cancer patients is an ordinal scaled measure. Moreover, the more recently advocated method for evaluating response to treatment in target tumor lesions is the Response Evaluation Criteria In Solid Tumors method, with ordinal outcomes defined as complete response, partial response, stable disease, and progressive disease. Traditional ordinal response modeling methods assume independence among the predictor variables and require that the number of samples (n) exceed the number of covariates (p). These are both violated in the context of high-throughput genomic studies. Recently, penalized models have been successfully applied to high-throughput genomic datasets in fitting linear, logistic, and Cox proportional hazards models with excellent performance. However, extension of penalized models to the ordinal response setting has not been fully described nor has software been made generally available. Herein we propose to apply the L1 penalization method to ordinal response models to enable modeling of common ordinal response data when a high-dimensional genomic data comprise the predictor space. This study will expand the scope of our current research by providing additional model-based ordinal classification methodologies applicable for high-dimensional datasets to accompany the heuristic based classification tree and random forest ordinal methodologies we have previously described. The specific aims of this application are to: (1) Develop R functions for implementing the stereotype logit model as well as an L1 penalized stereotype logit model for modeling an ordinal response. (2) Empirically examine the performance of the L1 penalized stereotype logit model and competitor ordinal response models by performing a simulation study and applying the models to publicly available microarray datasets. (3) Develop an R package for fitting a random-effects ordinal regression model for clustered ordinal response data. (4) Extend the random-effects ordinal regression model to include an L1 penalty term to accomodate high-dimensional covariate spaces and empirically examine the performance of the L1random-effects ordinal regression model through application to microarray data. Studies involving protocol biopsies where both histopathological assessment and microarray studies are performed at the same time point are increasingly being performed, so that the methodology and software developed in this application will provide unique informatic methods for analyzing such data. Moreover, the ordinal response extensions proposed in this application, though initially conceived of by considering microarray applications, will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect human preference data and other responses on an ordinal scale.               Most histopathological variables are reported on an ordinal scale. Studies involving protocol biopsies where both histopathological assessment and microarray studies are performed at the same time point are increasingly being performed, and the software developed in this application will provide unique informatic tools for analyzing such data. Moreover, the informatic methods proposed in this application, though initially conceived of by con- sidering microarray applications, will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect human preference data and other responses on an ordinal scale.",Informatic tools for predicting an ordinal response for high-dimensional data,8714054,R01LM011169,"['Advocate', 'Behavioral Research', 'Bioconductor', 'Biopsy', 'Biopsy Specimen', 'Cancer Patient', 'Cancer Prognosis', 'Categories', 'Chronic Hepatitis', 'Classification', 'Client satisfaction', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Diagnostic Neoplasm Staging', 'Environment', 'Evaluation', 'Event', 'Gene Chips', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Health', 'Health Status', 'Hepatic', 'Human', 'In complete remission', 'Informatics', 'Lesion', 'Logistics', 'Logit Models', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nodal', 'Outcome', 'Patients', 'Performance', 'Progressive Disease', 'Protocols documentation', 'Quality of life', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scoring Method', 'Solid Neoplasm', 'Specimen', 'Stable Disease', 'Staging', 'Stereotyping', 'Techniques', 'Time', 'Trees', 'base', 'forest', 'functional status', 'heuristics', 'indexing', 'liver biopsy', 'malignant breast neoplasm', 'novel', 'partial response', 'preference', 'programs', 'response', 'simulation', 'social', 'software development', 'tool', 'tumor']",NLM,VIRGINIA COMMONWEALTH UNIVERSITY,R01,2014,227026,-0.024074484038140883
"EMERGING TECHNOLOGIES: ASSESSING PHYSICAL ACTIVITY WITH WEBCAMS AND CROWDSOURCING  PROJECT ABSTRACT Obesity is associated with numerous health outcomes including diabetes, heart disease, and cancer. Over 30% of adults and 17% of children in the US are obese, with lack of physical activity (PA) and constraints in the built environment (BE) common culprits. As such, the US Guide to Community Preventive Services currently recommends the following BE interventions to increase PA and reduce obesity: (1) community and street-scale urban design and land use policies; (2) creation of, or enhanced access to places for physical activity; and (3) transportation policies and practices. The proposed project will use an archive of 23,000 publically-available, online, outdoor webcams and crowdsourcing to develop reliable and valid tools to improve the capture of global PA patterns and BE characteristics. The specific aims are to: 1) Develop and test the reliability of using publically-available, outdoor webcams to enumerate BE characteristics and PA patterns across thousands of global outdoor environments; and 2) Develop and test the reliability and validity of using crowdsourcing to enumerate BE characteristics and PA patterns. (13) The aims will be accomplished by using the Archive of Many Outdoor Scenes (AMOS) that has collected over 325 million images of outdoor environments from more than 23,000 webcam since 2006. Every identified, outdoor, publically-available online webcam is added to the AMOS dataset with an image taken and archived every 30 minutes from the webcam thereafter. Scenes include street intersections, plazas, and parks. We will use crowdsourcing to annotate each webcam scene. The crowdsourcing platform is Amazon Mechanical Turk (AMT), an Internet marketplace allowing people to be paid to complete small, computer-based tasks. The individual tasks are posted to the AMT website. We will use AMT tasks to annotate each AMOS webcam scene by identifying BE characteristics (established from the Active Neighborhood Checklist and Public Open Space Tool) and patterns of PA (established from SOPARC). This study is significant in its ability to increase by orders of magnitude the amount and quality of global recorded measurements of PA patterns and associated BE characteristics. This project is innovative by: 1) combining two distinct disciplines to use public, outdoor webcams to evaluate PA patterns and BE characteristics; 2) utilizing crowdsourcing to provide simple PA counts and indication of BE characteristics; and 3) its ability to greatly improve the generalizability of public health surveillance. Our results will yield actionable knowledge regarding the use of webcams and crowdsourcing to assess PA and the BE. PUBLIC HEALTH RELEVANCE: This project aims to combine computer science and public health to use online, outdoor webcams and crowdsourcing to enumerate global physical activity patterns and built environment characteristics. Webcams and crowdsourcing will be evaluated for reliability and validity. Results will yield actionable knowledge regarding the use of webcams and crowdsourcing to assess PA patterns and BE characteristics.            ",EMERGING TECHNOLOGIES: ASSESSING PHYSICAL ACTIVITY WITH WEBCAMS AND CROWDSOURCING,8620889,R21CA186481,"['Address', 'Adult', 'Archives', 'Censuses', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Child', 'Collaborations', 'Communication', 'Communities', 'Computer Vision Systems', 'Computers', 'Data', 'Data Set', 'Diabetes Mellitus', 'Discipline', 'Emerging Technologies', 'Environment', 'Ethics', 'Evaluation', 'Feeds', 'Goals', 'Guidelines', 'Health', 'Health Sciences', 'Healthy People 2020', 'Heart Diseases', 'Hour', 'Image', 'Individual', 'Interdisciplinary Study', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Malignant Neoplasms', 'Measurement', 'Mechanics', 'Neighborhoods', 'Obesity', 'Online Systems', 'Outcome', 'Pattern', 'Physical activity', 'Policies', 'Population', 'Population Surveillance', 'Preventive', 'Public Health', 'Research', 'Sampling', 'Schools', 'Seasons', 'Services', 'Social Sciences', 'Technology', 'Testing', 'Time', 'Training', 'Transportation', 'Validity and Reliability', 'Weather', 'Work', 'base', 'cancer risk', 'computer science', 'design', 'experience', 'improved', 'innovation', 'land use', 'meetings', 'new technology', 'novel', 'public health relevance', 'tool', 'web site']",NCI,WASHINGTON UNIVERSITY,R21,2014,198360,-0.007745014678675323
"Designing Visually Accessible Spaces  Title: Designing Visually Accessible Spaces NIH Program Announcement: 10-234 Bioengineering Research Partnerships (BRP)[R01] Abstract Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals, including those with physical disabilities, and to enhance safety for older people and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool enabling architectural design professionals to assess the visual accessibility of a wide range of environments (such as a hotel lobby, subway station, or eye-clinic reception area). This tool will simulate such environments with sufficient accuracy to predict the visibility of key landmarks or hazards, such as steps or benches, for different levels and types of low vision, and for spaces varying in lighting, surface properties and geometric arrangement. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments."" Our research plan has three specific goals: 1) Empirical: determine factors that influence low-vision accessibility related to hazard detection and navigation in real-world spaces. 2) Computational: develop working models to predict low vision visibility and navigability in real-world spaces. 3) Deployment: translate findings from basic vision science and clinical low vision into much needed industrial usage by producing a set of open source software modules to enhance architectural and lighting design for visual accessibility. The key scientific personnel in our partnership come from three institutions: University of Minnesota -- Gordon Legge and Daniel Kersten; University of Utah -- William Thompson and Sarah Creem-Regehr; and Indiana University -- Robert Shakespeare. This interdisciplinary team has expertise in the necessary areas required for programmatic research on visual accessibility -- empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), computer graphics and photometrically accurate rendering (Thompson & Shakespeare) and architectural lighting design (Shakespeare). We have collaborative arrangements with additional architectural design professionals who will participate in the translation of our research and development into practice. PUBLIC HEALTH RELEVANCE:  Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision.  We define visual accessibility as the use of vision to travel efficiently and safely through an environment, o perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment.  Our BRP partnership, with interdisciplinary expertise in vision science, computer science and lighting design, plans to develop computer-based tools enabling architecture professionals to assess the visual accessibility of their designs.                ",Designing Visually Accessible Spaces,8630772,R01EY017835,"['Accounting', 'Address', 'Age', 'American', 'Architecture', 'Area', 'Biological Models', 'Blindness', 'Central Scotomas', 'Characteristics', 'Clinic', 'Clinical', 'Complement', 'Complex', 'Computer Analysis', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Computers', 'Contrast Sensitivity', 'Cues', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Disorientation', 'Distance Perception', 'Effectiveness', 'Environment', 'Evaluation', 'Eye', 'Geometry', 'Glare', 'Goals', 'Grant', 'Guidelines', 'Height', 'Human', 'Human Resources', 'Image', 'Indiana', 'Individual', 'Injury', 'Institution', 'Investigation', 'Judgment', 'Learning', 'Light', 'Lighting', 'Lobbying', 'Location', 'Minnesota', 'Modeling', 'Modification', 'National Eye Institute', 'Nature', 'Optics', 'Perception', 'Peripheral', 'Phase', 'Photometry', 'Physical environment', 'Positioning Attribute', 'Process', 'Production', 'Property', 'Research', 'Risk', 'Safety', 'Shapes', 'Simulate', 'Source', 'Specific qualifier value', 'Stimulus', 'Structure', 'Subway', 'Surface', 'Surface Properties', 'System', 'Test Result', 'Testing', 'Translating', 'Translations', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'base', 'computer science', 'design', 'disability', 'falls', 'hazard', 'improved', 'knowledge base', 'luminance', 'novel strategies', 'open source', 'programs', 'public health relevance', 'research and development', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2014,595880,0.0028999542453029313
"Virtual Fly-Over Colonoscopy System for Clinical Test-SBIR Phase 1     DESCRIPTION (provided by applicant): Colorectal cancer is the third most common form of cancer and the second leading cause of cancer-related death in the US. Yet, if polyps are detected and removed early, colorectal cancer is largely preventable. Although optical colonoscopy (OC), the current gold standard, detects more than 90% of colorectal neoplasms; it is invasive and can be uncomfortable, inconvenient, and perceived as undesirable by patients. Furthermore, even experienced endoscopists may have difficulty reaching the cecum, resulting in incomplete visualizations of the colon. As a consequence, virtual colonoscopy (VC) has emerged as an alternative to OC. During VC, a virtual camera is used to view the internal walls of a virtual colon, reconstructed from CT scans of the abdominal cavity. However, current VC systems have had limited clinical appeal, as they are limited to specific types of polyps, may generate a large number of false positives, or have poor detection rates for significant polyps in the size range of 5-9 mm. The new technology we propose to commercialize through this SBIR work is a game changing, patented, visualization technique for VC, called the ""virtual fly-over"" technique. The technique is sensitive, effective, and efficient for detecting colon polyps. The overall objective of this proposal is to complete the development and validation of a novel visualization technique for virtual colonoscopy, which was patented by the University of Louisville. The hypothesis is that the new visualization technique will enable better viewing of the complex colonic topology, and hence a better capability to detect polyps, especially those that may be hidden behind haustral folds. The current prototype has been utilized to evaluate twenty clinical datasets, with excellent results. However, artifact removal and user friendly features must be incorporated prior to Phase II, in which the technology will be utilized in a larg scale clinical validation trial leading to a commercial product. Also, we propose to (1) generate more convincing preliminary data in a pilot study of 160 datasets, and (2) introduce several phantom polyps, in the size range of 5-9 mm, into the clinical datasets, in order to provide statistical significance of the technology's effectiveness. The phantom polyps will be placed in traditionally difficult-to-analyze positions, which pose significant detection problems for both OC and current VC methods. According to the literature, current OC methods result in a 61-91% (average 80%) viewing of the Colon. The University of Louisville's work in the ""fly-through VC method"", which mimics classic OC, results in 93.4 percent viewing, and the new ""fly-over"" method results in 97.5% percent viewing. Even more important is the improved point of view (""eye-in-the-sky""), the lack of optical distortion, and enhanced CAD functionality that will increase polyp recognition dramatically, especially when detecting small colon polyps, polyps hidden behind haustral folds, and polyps in folded colonic segments at anatomical inflection points. We anticipate the overall improvement in the ability to visualize difficult polyps to be upwards of 30% compared to today's methods, and we are excited about commercializing this technology with the University of Louisville.         PUBLIC HEALTH RELEVANCE: Colorectal cancer is the third most common form of cancer and the second leading cause of cancer-related death in the US with only approximately 50% of the eligible population take advantage of current screening methods. The importance of this proposed technology is the early detection of colon cancer, in an acceptable manner that the general population will agree to, and without the associated morbidity of sedation that is required for the vast majority of endoscopic colonoscopy. We believe our technology has the potential to serve as a foundation for a huge step forward in automating and facilitating large scale screening of human colons, providing a more effective and much more acceptable method to the general population, than the currently invasive optical colonoscopy, which 50 % of the population still refuses to undergo.            ",Virtual Fly-Over Colonoscopy System for Clinical Test-SBIR Phase 1,8735905,R43CA179911,"['Abdominal Cavity', 'Area', 'Cancer Etiology', 'Cecum', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Colon', 'Colon Carcinoma', 'Colonic Polyps', 'Colonoscopy', 'Colorectal Cancer', 'Colorectal Neoplasms', 'Complex', 'Computational Geometry', 'Computed Tomographic Colonography', 'Computer Graphics', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Early Diagnosis', 'Effectiveness', 'Engineering', 'Excision', 'Eye', 'Flying body movement', 'Foundations', 'Funding', 'General Population', 'Goals', 'Gold', 'Helicopter', 'Human', 'Imagery', 'Implant', 'Kentucky', 'Lead', 'Legal patent', 'Literature', 'Location', 'Medial', 'Medical center', 'Methods', 'Morbidity - disease rate', 'Morphologic artifacts', 'Optical Methods', 'Optics', 'Patients', 'Phase', 'Pilot Projects', 'Polyps', 'Population', 'Positioning Attribute', 'Procedures', 'Reading', 'Rivers', 'Science', 'Second Primary Cancers', 'Sedation procedure', 'Small Business Innovation Research Grant', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Universities', 'Validation', 'Work', 'X-Ray Computed Tomography', 'base', 'clinically significant', 'design', 'experience', 'fly', 'improved', 'new technology', 'novel', 'prototype', 'public health relevance', 'research clinical testing', 'screening', 'three-dimensional modeling', 'user-friendly', 'virtual']",NCI,"KENTUCKY IMAGING TECHNOLOGIES, LLC",R43,2014,143335,-0.05922858955266282
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8514601,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild cognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'screening', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2013,328871,-0.034864782956803675
"Hand Sensorimotor Function and Carpal Tunnel Syndrome    DESCRIPTION (provided by applicant): The median nerve is susceptible to compression in the wrist, leading to carpal tunnel syndrome (CTS). CTS is the most common compression neuropathy and have an immense impact on national health care, worker productivity, and quality of life. Despite its high prevalence and public health cost, our understanding of CTS is limited, and the management of CTS awaits improvement. The central notion of this project is that hand sensorimotor function is sensitive to peripheral median neuropathy and that the central nervous system is affected by CTS, causing the associated sensorimotor deficit. We will investigate this notion with quantifiable sensorimotor data from novel biomechanical and neurophysiological studies. This project has three aims consisting of biomechanical, neurophysiological and translational research. The first aim is to investigate CTS-induced pathokinematic and pathokinetic performance using dexterous manual tasks of thumb opposition, reach-to-pinch, precision grip, and finger pressing. The second aim is to investigate the neurophysiological implications of chronic peripheral neuropathy (i.e., CTS) on the central nervous system by evaluating corticomuscular coupling and stretch reflex. The third aim is to identify novel biomechanical and neurophysiological markers for CTS cases using machine learning and classification algorithms. The results of this project will elucidate the pathological mechanisms and behavioral manifestations of CTS and aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder. More generally, CTS as a chronic neuropathy serves as an effective model to study sensorimotor mechanisms of the peripheral and central nervous systems. In addition, the methodology developed in this project is applicable to other neuromuscular disorders.       PUBLIC HEALTH RELEVANCE:   Carpal tunnel syndrome is highly prevalent and costly. One of the distinct consequences of carpal tunnel syndrome is that patients experience inexplicable dropping of objects and clumsiness while performing simple daily tasks. In this project, we propose to study the sensorimotor deficit using novel biomechanical and neurophysiological experiments. The results of this project will elucidate the pathological mechanisms and manifestations of carpal tunnel syndrome. This project is clinically translational to aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder.               ",Hand Sensorimotor Function and Carpal Tunnel Syndrome,8452605,R01AR056964,"['Abnormal coordination', 'Affect', 'Algorithms', 'Behavioral Mechanisms', 'Biomechanics', 'Carpal Tunnel Syndrome', 'Carpometacarpal joint structure', 'Chronic', 'Classification', 'Clinical', 'Coupling', 'Data', 'Development', 'Disease', 'Drops', 'Electroencephalography', 'Electromyography', 'Exertion', 'Eye', 'Fingers', 'Hand', 'Health Care Costs', 'Health Personnel', 'High Prevalence', 'Human', 'Individual', 'Joints', 'Lasso', 'Machine Learning', 'Manuals', 'Measures', 'Median Neuropathy', 'Metacarpophalangeal joint structure', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Cortex', 'Neural Conduction', 'Neuraxis', 'Neuromuscular Diseases', 'Neuropathy', 'Patients', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Production', 'Productivity', 'Pronation', 'Public Health', 'Quality of life', 'Questionnaires', 'Reaction', 'Rehabilitation therapy', 'Reproducibility', 'Research', 'Response Latencies', 'Sensorimotor functions', 'Sensory', 'Techniques', 'Testing', 'Thumb structure', 'Time', 'Translational Research', 'Trees', 'Validation', 'Wrist', 'data mining', 'diagnosis evaluation', 'experience', 'grasp', 'improved', 'indexing', 'median nerve', 'motor control', 'neurophysiology', 'novel', 'programs', 'public health relevance', 'research study', 'response', 'stretch reflex', 'tool', 'vector']",NIAMS,CLEVELAND CLINIC LERNER COM-CWRU,R01,2013,335588,-0.014588068691494203
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8566062,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2013,175500,-0.01788055663546809
"Reduced-Order Constrained Optimization for Rapid IMRT and VMAT Treatment Planning    DESCRIPTION (provided by applicant): Intensity-modulated radiotherapy (IMRT) has revolutionized the treatment of cancers in the last decade, since it can tightly conform and escalate radiation dose to a tumor while simultaneously protecting nearby radiation- sensitive normal tissues, resulting in better local control and fewer post-treatment complications than previous techniques. However, the process of obtaining a clinically acceptable IMRT plan for a difficult site is still extremely slow, requiring many hours of a busy expert's time in a manual trial-and-error loop of parameter adjustment. The goal of this project is to drastically reduce the amount of time to obtain a clinically acceptable IMRT plan using a new automated method that directly applies constrained optimization in a computationally tractable and clinically meaningful way. The hypothesis is that clinical treatment planning times using this technique will be reduced from several hours to a matter of minutes.  The new approach, called ROCO (Reduced-Order Constrained Optimization) translates well-established concepts from optimization and machine learning theory to the novel application of IMRT planning, exploiting the speed and ease of unconstrained optimizations and introducing a dimensionality reduction step that makes true constrained optimization tractable. The Specific Aims of the proposal are to (1) apply Reduced-Order Con- strained Optimization to IMRT planning for non-small cell lung cancers and nasopharynx cancers, where the planning process is highly time-consuming; (2) develop and extend the Reduced-Order Constrained Optimization paradigm to a promising IMRT variant called Volumetric Modulated Arc Therapy (VMAT) for the prostate site, which is currently nearly clinically intractable to plan; and (3) integrate the new tools into the clinical IMRT planning process at Memorial Sloan-Kettering Cancer Center, using a powered study to verify the hypothesis that the proposed method significantly improves planning speed. The experiments will be designed in consultation with an expert clinical treatment planner and biostatistician, and carefully validated using anonymized data from approximately 50 patients for each site.  The main benefit of the proposed approach is to drastically reduce planning times, which is critical if IMRT and VMAT are to reach their full potential in clinical application. In a busy clinic, long planning times place a severe stress on available resources, and can result in treatment delays, acceptance of sub-optimal plans or - in the worst case - errors due to time pressure. In the longer term, the proposed approach will provide deeper insight into the critical elements of the dose optimization problem, significantly reduce the trial-and-error effort characteristic of current IMRT planning, and reduce subjectivity in treatment plan selection.       PUBLIC HEALTH RELEVANCE: Intensity-modulated radiation therapy (IMRT) is an extremely promising cancer treatment, but currently requires many hours of an expert treatment planner's time to obtain a plan that meets all the clinical constraints specified by the physician. This proposal describes a new, automatic method for treatment plan optimization that is very fast, requiring only minutes to produce a plan that directly meets all the physician's constraints, potentially saving much time for a busy clinic.         ",Reduced-Order Constrained Optimization for Rapid IMRT and VMAT Treatment Planning,8444578,R01CA148876,"['Acute', 'Address', 'Aftercare', 'Algorithms', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Treatment', 'Code', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'Consultations', 'Data', 'Development', 'Dose', 'Dose-Limiting', 'Drug Formulations', 'Effectiveness', 'Elements', 'Goals', 'Head and Neck Neoplasms', 'Head and neck structure', 'Hour', 'Housing', 'Human', 'Intensity-Modulated Radiotherapy', 'Journals', 'Linear Accelerator Radiotherapy Systems', 'Lung', 'Machine Learning', 'Malignant neoplasm of nasopharynx', 'Manuals', 'Measures', 'Medical', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Nasopharynx', 'Non-Small-Cell Lung Carcinoma', 'Normal tissue morphology', 'Organ', 'Paper', 'Parotid Gland', 'Patients', 'Phase', 'Physicians', 'Physics', 'Process', 'Prostate', 'Quality of life', 'Radiation', 'Radiation therapy', 'Resources', 'Risk', 'Sampling', 'Site', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Stress', 'Sum', 'System', 'Techniques', 'Technology', 'Time', 'To specify', 'Toxic effect', 'Translating', 'Variant', 'Weight', 'Xerostomia', 'base', 'cancer therapy', 'clinical application', 'clinical practice', 'design', 'experience', 'image processing', 'improved', 'insight', 'meetings', 'novel', 'novel strategies', 'pressure', 'process optimization', 'public health relevance', 'rectal', 'research study', 'symposium', 'theories', 'time use', 'tool', 'treatment planning', 'tumor']",NCI,RENSSELAER POLYTECHNIC INSTITUTE,R01,2013,334665,-0.03334213403641838
"Developing a Virtual Basic Laparoscopic Skill Trainer (VBLaST)    DESCRIPTION (provided by applicant):  Development and Validation of a Virtual Basic Laparoscopic Skill Trainer (VBLaST) For the first time in the history of surgical education, a comprehensive program to teach and evaluate the cognitive and psychomotor aspects unique to laparoscopic surgery - the Fundamentals of Laparoscopic Surgery (FLS) developed originally by the Society of American Gastrointestinal Endoscopic Surgery (SAGES) and subsequently by a joint committee which includes the American College of Surgeons (ACS) - is being embraced nationally for training and credentialing laparoscopic surgeons. As an example of its growing acceptance by the medical community, starting in 2009, the American Board of Surgeons has mandated that passing the FLS certifying examination will be required for taking the board examination in surgery. While the cognitive assessment in FLS is based on 75 multiple-choice questions, a proctored examination is used for the manual skills assessment which includes five tasks to be performed in a portable pelvic trainer box with built-in video camera: bimanual peg transfer, precise pattern cutting, use of ligating loops and suturing with intracorporeal and extracorporeal knot tying. In spite of the growing popularity of the FLS, there are several major problems with this box trainer paradigm: (1) the assessment is subjective, (2) there is no feedback during learning except when an experienced trainer is present, (3) a large number of qualified proctors must be engaged during test taking, (4) the training material must be constantly replaced, and (5) the test-takers must travel to one of the 27 Regional Test Centers or the Annual SAGES meeting or the ACS Clinical Congress. To overcome these problems and to enable greater dissemination, we propose to develop and validate a Virtual Basic Laparoscopic Skill Trainer (VBLaST) whereby tasks available in the FLS may be performed on PCs and laptops with inexpensive haptic (touch) interface devices, such as the Phantom(R) OmniTM. To develop the VBLaST a novel set of technologies must be developed including rapid, but highly realistic physics-based virtual interaction paradigms and statistical machine learning techniques to develop a ""virtual mentor"" which will provide real time automated feedback to the trainees. A comprehensive set of studies involving students, residents, fellows and practicing surgeons at Boston area hospitals (e.g., BIDMC, Tufts Medical Center, Cambridge Health Alliance, Harvard, MGH, Brigham & Women's, Lahey Clinic) will be undertaken to test the validity of the VBLaST as a training tool and establish its usefulness in transferring the acquired skills to the operating room. Once validated, the VBLaST will have exponential impact in reducing training costs and training time while improving patient safety and outcomes, A multidisciplinary team with collective expertise in physics-based interactive medical simulation, laparoscopic surgery and surgical education, and human factors engineering has been assembled to achieve the following Specific Aims: SA1) To develop a realistic virtual basic laparoscopic skill trainer (VBLaST) platform to perform all the tasks available in the FLS training tool box. SA2) To establish the validity of the VBLaST as a training tool. SA3) To evaluate the usefulness of the VBLaST as a training tool. SA4) To develop a web-based interface for the VBLaST.       PUBLIC HEALTH RELEVANCE: The goal of this research is to develop a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills and to take standardized tests on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.         ",Developing a Virtual Basic Laparoscopic Skill Trainer (VBLaST),8470093,R01EB010037,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'American', 'American College of Surgeons', 'Area', 'Attention', 'Auditory', 'Boston', 'Boxing', 'Clinic', 'Clinical', 'Cognitive', 'Communities', 'Complication', 'Computer Simulation', 'Computers', 'Congresses', 'Credentialing', 'Cues', 'Development', 'Devices', 'Education', 'Educational process of instructing', 'Endoscopic Gastrointestinal Surgical Procedures', 'Engineering', 'Ensure', 'Feedback', 'Funding', 'Goals', 'Group Practice', 'Healed', 'Health Alliance', 'Hospitals', 'Human', 'Industry', 'Information Sciences', 'Information Technology', 'Institutes', 'Israel', 'Joints', 'Laparoscopic Cholecystectomy', 'Laparoscopic Surgical Procedures', 'Learning', 'Length of Stay', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Errors', 'Medical center', 'Mentors', 'Metric', 'Minimally Invasive Surgical Procedures', 'Morbidity - disease rate', 'National Institute of Biomedical Imaging and Bioengineering', 'Online Systems', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Pattern', 'Pelvis', 'Physicians', 'Physics', 'Procedures', 'Qualifying', 'Recording of previous events', 'Reporting', 'Research', 'Research Activity', 'Research Project Grants', 'Risk', 'Societies', 'Students', 'Surgeon', 'Surgical Error', 'Surgical complication', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Training', 'Translating', 'Travel', 'Treatment Cost', 'United States National Institutes of Health', 'Universities', 'Validation', 'Visual', 'Woman', 'bariatric surgery', 'base', 'cost', 'experience', 'haptics', 'healing', 'improved', 'laptop', 'malignant breast neoplasm', 'meetings', 'multidisciplinary', 'new technology', 'novel', 'patient safety', 'programs', 'public health relevance', 'research study', 'simulation', 'skills', 'success', 'tool', 'vehicular accident', 'virtual', 'virtual reality', 'web based interface']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R01,2013,470451,-0.00206803428916591
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8541017,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'elastography', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response', 'screening']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2013,328138,-0.019957456934419228
"In vivo Characterization of Stents using Intravascular OCT Imaging     DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel.         PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.            ",In vivo Characterization of Stents using Intravascular OCT Imaging,8529140,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Goals', 'Graph', 'Healed', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Simulate', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thrombosis', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'public health relevance', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2013,412883,-0.010901879233420527
"Context Understanding Technology to improve internet accessibility for users with     DESCRIPTION (provided by applicant): The purpose of this SBIR project is to develop a new tool to improve the ability of blind and visually impaired people to quickly get to the right web pages, to avoid ending up on the wrong web pages, and to reach the desired part of each web page efficiently. The motivation for this effort is that getting a 'big picture' understanding of a web page is one of the biggest challenges facing this population of computer users. Existing tools for blind and visually impaired people, such as screen readers and screen magnifiers, present the entire web page serially, in full detail, either by textual output of the details, or b providing a magnified view of a small part of the page. However, if the user is not already familiar with the website, the resulting lack of context requires a laborious and time-consuming process to scan through sometimes hundreds of details before knowing whether anything of interest even exists on the page in question. In contrast, the proposed technology analyzes web pages in a similar way that sighted users quickly scan pages before reading in detail, to provide a succinct, informative guidance on the context and layout of the page, so that a user quickly gains a much richer ""big-picture"" understanding. The proposed Phase II project builds on a successful Phase I user evaluation of a proof- of-concept of the software, in which users expressed a strong preference for the contextual cues provided by the approach. Phase II includes creating a fully-functional prototype of the software tool. Throughout the technology development, feedback from users and practitioners will guide the path of the R&D for maximum usability. At the conclusion of Phase II, an end-user, in-home evaluation study will verify the effectiveness of the tool, providing the starting point for full-scale commercialization.         PUBLIC HEALTH RELEVANCE: The R&D in this Phase II SBIR project will result in an improved way to use the Internet for individuals with visual disabilities. The technology will help to overcome the lack of accessibility and high level of frustration currently found among blind and visually impaired users. The results of the project will enable such individuals to explore new opportunities and be more productive, thus providing improved employment potential and an increase in the quality of life.                ",Context Understanding Technology to improve internet accessibility for users with,8459121,R44EY020082,"['Advertisements', 'Area', 'Arizona', 'Artificial Intelligence', 'Boxing', 'Characteristics', 'Color', 'Computer software', 'Computers', 'Cues', 'Effectiveness', 'Employment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Frustration', 'Generations', 'Government', 'Grouping', 'Home environment', 'Individual', 'Interest Group', 'Internet', 'Literature', 'Marketing', 'Motivation', 'Mus', 'Output', 'Persons', 'Phase', 'Population', 'Process', 'Quality of life', 'Reader', 'Reading', 'Research', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'Speech', 'System', 'Technology', 'Text', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'base', 'blind', 'commercialization', 'disability', 'experience', 'improved', 'interest', 'natural language', 'phrases', 'preference', 'prototype', 'public health relevance', 'research and development', 'technology development', 'tool', 'usability', 'web page', 'web site']",NEI,"VORTANT TECHNOLOGIES, LLC",R44,2013,371933,0.0001256083561111442
"Advanced training platform and methodologies for emergency responders and skilled     DESCRIPTION (provided by applicant): There is a need to be able to deliver just-in-time training and reference materials for first responders and skilled support personnel. Mobile computing platforms are becoming ubiquitous and provide an ideal means to reach users at any time in any location. The process of translating existing reference materials into mobile-friendly formats is currently manual and very labor intensive. Nicolalde R&D LLC is well under way to commercialize its mTraining mobile technology and service prototyped during a phase I SBIR from NIEHS. The mTraining technology is an objective and checklist-based method for delivering just-in-time training and reference materials, making it an effective Electronic Performance Support System (EPSS) for providing workers easy access to information after training, and on site prior to or during an assignment. It provides short, incident specific awareness and safety training that can be delivered prior to responding to an emergency situation. The proposed development under this phase II SBIR includes: a) a back-end document processing engine that is able to automatically parse, analyze, mark-up, and organize documents so that their content is easily cross-referenced, linked and re-organized for effective delivery on a mobile training platform or other electronic medium. This will be connected to a server and database architecture to facilitate its operation and support storing and accessing content; b) the front-end interface for the mobile training platform (mTraining) was prototyped in Phase I of this project for delivering training content to emergency responders, skilled support personnel, and volunteers before or during an incident. The improved back-end architecture will support intelligent search capabilities for a large repository of training documents with different structures. This capability relies on the document processing engine's ability to semi-automatically extract relevant data and automatically translate this data into a structured format. This data can then be used for display in the mobile application, stored into databases, and automatically populated into ontologies. Throughout this project the participatory-based design paradigm has been used for facilitating the integration of user requirements and the fast prototyping and testing of design alternatives. This approach will continue to be utilized in Phase 2 of the project.         PUBLIC HEALTH RELEVANCE: The proposed research and development will advance the field of environmental health and safety training by bringing to it new and innovative advanced training technologies that are based on the mobile and just-in-time paradigm. Furthermore, the research and development proposed herein will advance the mobile information technology field by developing robust and scalable tools for processing and linking information residing in different source documents that are semantically related.            ",Advanced training platform and methodologies for emergency responders and skilled,8518023,R44ES020135,"['Access to Information', 'Architecture', 'Awareness', 'Back', 'Case Study', 'Data', 'Databases', 'Development', 'Educational Curriculum', 'Educational Materials', 'Electronics', 'Emergency Situation', 'Environmental Health', 'Focus Groups', 'Human Resources', 'Information Technology', 'Link', 'Location', 'Manuals', 'Medical', 'Medical Students', 'Methodology', 'Methods', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Ontology', 'Performance', 'Phase', 'Process', 'Provider', 'Research Infrastructure', 'Retrieval', 'Safety', 'Semantics', 'Services', 'Simulate', 'Site', 'Small Business Innovation Research Grant', 'Source', 'Specific qualifier value', 'Structure', 'Support System', 'Technology', 'Testing', 'Time', 'Time Management', 'Training', 'Training and Education', 'Translating', 'Update', 'base', 'computer based Semantic Analysis', 'design', 'emergency service responder', 'improved', 'innovation', 'interest', 'operation', 'public health relevance', 'repository', 'research and development', 'response', 'tool', 'usability', 'volunteer']",NIEHS,"NICOLALDE R AND D, LLC",R44,2013,142612,-0.01702418540881372
"Informatic tools for predicting an ordinal response for high-dimensional data    DESCRIPTION (provided by applicant):        Health status and outcomes are frequently measured on an ordinal scale. Examples include scoring methods for liver biopsy specimens from patients with chronic hepatitis, including the Knodell hepatic activity index, the Ishak score, and the METAVIR score. In addition, tumor-node-metasis stage for cancer patients is an ordinal scaled measure. Moreover, the more recently advocated method for evaluating response to treatment in target tumor lesions is the Response Evaluation Criteria In Solid Tumors method, with ordinal outcomes defined as complete response, partial response, stable disease, and progressive disease. Traditional ordinal response modeling methods assume independence among the predictor variables and require that the number of samples (n) exceed the number of covariates (p). These are both violated in the context of high-throughput genomic studies. Recently, penalized models have been successfully applied to high-throughput genomic datasets in fitting linear, logistic, and Cox proportional hazards models with excellent performance. However, extension of penalized models to the ordinal response setting has not been fully described nor has software been made generally available. Herein we propose to apply the L1 penalization method to ordinal response models to enable modeling of common ordinal response data when a high-dimensional genomic data comprise the predictor space. This study will expand the scope of our current research by providing additional model-based ordinal classification methodologies applicable for high-dimensional datasets to accompany the heuristic based classification tree and random forest ordinal methodologies we have previously described. The specific aims of this application are to: (1) Develop R functions for implementing the stereotype logit model as well as an L1 penalized stereotype logit model for modeling an ordinal response. (2) Empirically examine the performance of the L1 penalized stereotype logit model and competitor ordinal response models by performing a simulation study and applying the models to publicly available microarray datasets. (3) Develop an R package for fitting a random-effects ordinal regression model for clustered ordinal response data. (4) Extend the random-effects ordinal regression model to include an L1 penalty term to accomodate high-dimensional covariate spaces and empirically examine the performance of the L1random-effects ordinal regression model through application to microarray data. Studies involving protocol biopsies where both histopathological assessment and microarray studies are performed at the same time point are increasingly being performed, so that the methodology and software developed in this application will provide unique informatic methods for analyzing such data. Moreover, the ordinal response extensions proposed in this application, though initially conceived of by considering microarray applications, will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect human preference data and other responses on an ordinal scale.               Most histopathological variables are reported on an ordinal scale. Studies involving protocol biopsies where both histopathological assessment and microarray studies are performed at the same time point are increasingly being performed, and the software developed in this application will provide unique informatic tools for analyzing such data. Moreover, the informatic methods proposed in this application, though initially conceived of by con- sidering microarray applications, will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect human preference data and other responses on an ordinal scale.",Informatic tools for predicting an ordinal response for high-dimensional data,8538496,R01LM011169,"['Advocate', 'Behavioral Research', 'Bioconductor', 'Biopsy', 'Biopsy Specimen', 'Cancer Patient', 'Cancer Prognosis', 'Categories', 'Chronic Hepatitis', 'Classification', 'Client satisfaction', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Diagnostic Neoplasm Staging', 'Environment', 'Evaluation', 'Event', 'Gene Chips', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Health', 'Health Status', 'Hepatic', 'Human', 'In complete remission', 'Informatics', 'Lesion', 'Logistics', 'Logit Models', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nodal', 'Outcome', 'Patients', 'Performance', 'Progressive Disease', 'Protocols documentation', 'Quality of life', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scoring Method', 'Solid Neoplasm', 'Specimen', 'Stable Disease', 'Staging', 'Stereotyping', 'Techniques', 'Time', 'Trees', 'base', 'forest', 'functional status', 'heuristics', 'indexing', 'liver biopsy', 'malignant breast neoplasm', 'novel', 'partial response', 'preference', 'programs', 'response', 'simulation', 'social', 'software development', 'tool', 'tumor']",NLM,VIRGINIA COMMONWEALTH UNIVERSITY,R01,2013,234332,-0.024074484038140883
"Virtual Fly-Over Colonoscopy System for Clinical Test-SBIR Phase 1     DESCRIPTION (provided by applicant): Colorectal cancer is the third most common form of cancer and the second leading cause of cancer-related death in the US. Yet, if polyps are detected and removed early, colorectal cancer is largely preventable. Although optical colonoscopy (OC), the current gold standard, detects more than 90% of colorectal neoplasms; it is invasive and can be uncomfortable, inconvenient, and perceived as undesirable by patients. Furthermore, even experienced endoscopists may have difficulty reaching the cecum, resulting in incomplete visualizations of the colon. As a consequence, virtual colonoscopy (VC) has emerged as an alternative to OC. During VC, a virtual camera is used to view the internal walls of a virtual colon, reconstructed from CT scans of the abdominal cavity. However, current VC systems have had limited clinical appeal, as they are limited to specific types of polyps, may generate a large number of false positives, or have poor detection rates for significant polyps in the size range of 5-9 mm. The new technology we propose to commercialize through this SBIR work is a game changing, patented, visualization technique for VC, called the ""virtual fly-over"" technique. The technique is sensitive, effective, and efficient for detecting colon polyps. The overall objective of this proposal is to complete the development and validation of a novel visualization technique for virtual colonoscopy, which was patented by the University of Louisville. The hypothesis is that the new visualization technique will enable better viewing of the complex colonic topology, and hence a better capability to detect polyps, especially those that may be hidden behind haustral folds. The current prototype has been utilized to evaluate twenty clinical datasets, with excellent results. However, artifact removal and user friendly features must be incorporated prior to Phase II, in which the technology will be utilized in a larg scale clinical validation trial leading to a commercial product. Also, we propose to (1) generate more convincing preliminary data in a pilot study of 160 datasets, and (2) introduce several phantom polyps, in the size range of 5-9 mm, into the clinical datasets, in order to provide statistical significance of the technology's effectiveness. The phantom polyps will be placed in traditionally difficult-to-analyze positions, which pose significant detection problems for both OC and current VC methods. According to the literature, current OC methods result in a 61-91% (average 80%) viewing of the Colon. The University of Louisville's work in the ""fly-through VC method"", which mimics classic OC, results in 93.4 percent viewing, and the new ""fly-over"" method results in 97.5% percent viewing. Even more important is the improved point of view (""eye-in-the-sky""), the lack of optical distortion, and enhanced CAD functionality that will increase polyp recognition dramatically, especially when detecting small colon polyps, polyps hidden behind haustral folds, and polyps in folded colonic segments at anatomical inflection points. We anticipate the overall improvement in the ability to visualize difficult polyps to be upwards of 30% compared to today's methods, and we are excited about commercializing this technology with the University of Louisville.         PUBLIC HEALTH RELEVANCE: Colorectal cancer is the third most common form of cancer and the second leading cause of cancer-related death in the US with only approximately 50% of the eligible population take advantage of current screening methods. The importance of this proposed technology is the early detection of colon cancer, in an acceptable manner that the general population will agree to, and without the associated morbidity of sedation that is required for the vast majority of endoscopic colonoscopy. We believe our technology has the potential to serve as a foundation for a huge step forward in automating and facilitating large scale screening of human colons, providing a more effective and much more acceptable method to the general population, than the currently invasive optical colonoscopy, which 50 % of the population still refuses to undergo.            ",Virtual Fly-Over Colonoscopy System for Clinical Test-SBIR Phase 1,8586142,R43CA179911,"['Abdominal Cavity', 'Area', 'Cancer Etiology', 'Cecum', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Colon', 'Colon Carcinoma', 'Colonic Polyps', 'Colonoscopy', 'Colorectal Cancer', 'Colorectal Neoplasms', 'Complex', 'Computed Tomographic Colonography', 'Computer Graphics', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Early Diagnosis', 'Effectiveness', 'Engineering', 'Excision', 'Eye', 'Flying body movement', 'Foundations', 'Funding', 'General Population', 'Goals', 'Gold', 'Helicopter', 'Human', 'Imagery', 'Implant', 'Kentucky', 'Lead', 'Legal patent', 'Literature', 'Location', 'Medial', 'Medical center', 'Methods', 'Morbidity - disease rate', 'Morphologic artifacts', 'Optical Methods', 'Optics', 'Patients', 'Phase', 'Pilot Projects', 'Polyps', 'Population', 'Positioning Attribute', 'Procedures', 'Reading', 'Rivers', 'Science', 'Second Primary Cancers', 'Sedation procedure', 'Small Business Innovation Research Grant', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Universities', 'Validation', 'Work', 'X-Ray Computed Tomography', 'base', 'clinically significant', 'design', 'experience', 'fly', 'improved', 'new technology', 'novel', 'prototype', 'public health relevance', 'research clinical testing', 'screening', 'three-dimensional modeling', 'user-friendly', 'virtual']",NCI,"KENTUCKY IMAGING TECHNOLOGIES, LLC",R43,2013,148821,-0.05922858955266282
Regulation of Alternative Cleavage and Polyadenylation No abstract available n/a,Regulation of Alternative Cleavage and Polyadenylation,8720197,R01GM084089,"['3&apos', ' Untranslated Regions', 'Address', 'Affect', 'Biochemical', 'Biological', 'Biological Assay', 'Cell Line', 'Classification', 'Code', 'Complementary DNA', 'Computational Molecular Biology', 'DNA Microarray Chip', 'Data', 'Databases', 'Elements', 'Event', 'Evolution', 'Exons', 'Expressed Sequence Tags', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Gene Mutation', 'Genes', 'Genetic Polymorphism', 'Genome', 'Goals', 'Human', 'Indium', 'Introns', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Messenger RNA', 'Metabolism', 'MicroRNAs', 'Modeling', 'Molecular Biology', 'Molecular Biology Techniques', 'Mus', 'Mutagenesis', 'Mutation', 'Pattern', 'Phylogenetic Analysis', 'Poly A', 'Polyadenylation', 'Polyadenylation Pathway', 'Proteins', 'RNA', 'RNA Binding', 'RNA Interference', 'RNA Splicing', 'RNA-Binding Proteins', 'Regulation', 'Regulatory Element', 'Relative (related person)', 'Reporter', 'Site', 'Statistical Models', 'Structure', 'System', 'Technology', 'Tissues', 'Trees', 'Untranslated Regions', 'Validation', 'Variant', 'base', 'human disease', 'improved', 'preference', 'research study', 'serial analysis of gene expression', 'tool']",NIGMS,RBHS-NEW JERSEY MEDICAL SCHOOL,R01,2013,259660,-0.022209877303221624
"Machine Learning Tools for Prognostication in Melanoma    DESCRIPTION (provided by applicant): The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.  Cutaneous melanoma is the sixth most common cancer in the United States, and its incidence rate is increasing faster than any other cancer. Nearly 69,000 new cases are expected be diagnosed in this country in 2010. While thin melanomas are typically cured with excision alone, thicker melanomas have a greater tendency to metastasize to the regional lymph nodes.  A diagnosis of Stage III melanoma is made if there is spread to the regional lymph nodes. Unfortunately, there is marked diversity in the natural history of Stage III melanoma, and outcomes within this group are extremely heterogeneous, with 5- year survival rates ranging from 23% to 87%. Similarly, treatment options range from intensive forms of systemic therapy to observation. Understanding patients' differences in clinical outcome is critical not only for calibrating therapeutic intensity to metastatic risk but also in the design and analysis of clinical trials.  There is a real void of reliable prognostic tools for Stage III melanoma. Based on novel machine learning approaches, the purpose of this study will be to develop and validate a reliable and individualized tool for prognostication of Stage III melanoma patients that can be used in the clinical setting.        The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.         ",Machine Learning Tools for Prognostication in Melanoma,8335369,R21CA152775,"['Address', 'American Joint Committee on Cancer', 'Cancer Prognosis', 'Classification', 'Clinical', 'Clinical Trials', 'Complex', 'Country', 'Cutaneous Melanoma', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Pathway', 'Dose', 'Evaluation', 'Excision', 'Heterogeneity', 'Incidence', 'Individual', 'Interferons', 'Logic', 'Lymph Node Dissections', 'Machine Learning', 'Malignant Neoplasms', 'Metastatic to', 'Methodology', 'Methods', 'Michigan', 'Modeling', 'Multivariate Analysis', 'Natural History', 'Neoplasm Metastasis', 'Nodal', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Proportional Hazards Models', 'Publications', 'Reporting', 'Risk', 'Sentinel Lymph Node Biopsy', 'Staging', 'Statistical Methods', 'Subgroup', 'Survival Rate', 'Systemic Therapy', 'Therapeutic', 'Thick', 'Trees', 'United States', 'Universities', 'Validation', 'advanced disease', 'base', 'cancer risk', 'clinical decision-making', 'design', 'editorial', 'flexibility', 'forest', 'hazard', 'lymph nodes', 'melanoma', 'minimally invasive', 'novel', 'outcome forecast', 'prognostic', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2012,159977,-0.03402501868051896
"A New Approach to Compute PM2.5 for Health Impact Analysis    DESCRIPTION (provided by applicant): Environmental air quality impacts human well-being and disease, but the availability of air quality data is limited to selected locations because of the complexity involved in its measurement. Among air pollutants, PM2.5 is of the greatest concern. These particles are not captured by the lungs' natural defenses and can be inhaled deeply, where they can cause health problems ranging from asthma attacks to heart disease.  PM2.5 currently is measured primarily by ground monitoring stations located at approximately 320 EPA sites, providing limited local geographic coverage. However, there are satellites that make a variety of aerosol observations and provide a daily global picture of atmospheric particulates in the form of aerosol optical depth (AOD). Scientists have attempted to compute ground-level PM2.5 (GLP) from these AOD data. However, the multivariate nonlinear relationship between AOD and PM2.5 imposes limitations in computing GLP using satellite data. This project proposes to overcome these limitations by computing reliable GLP via a new methodology which has already been tested and validated.  The study has two specific aims: (1) develop satellite-derived daily GLP estimates for the contiguous U.S., and (2) examine spatial and temporal associations between GLP exposure and hospital visits for asthma exacerbation in Mississippi. Using our methodology, we will generate daily GLP data for a 12-month period at a resolution of 0.10x0.10 (~10x10km2), providing approximately 82,000 data points as opposed to about 300 data points available daily from EPA ground monitoring stations within the contiguous U.S. We will address the nonlinear relationship between PM2.5 and AOD which is a function of humidity, temperature, surface pressure, surface wind speed, surface type, boundary layer height, and AOD by accounting for these variables using a machine learning process. The AOD that will be used in this process will be generated by merging AOD data from multiple satellite sensors. Meteorological data will come from NOAA NCEP. Surface type data will be obtained from the satellite-identified vegetation index. Boundary layer height, which is the mixed layer of the atmosphere closest to the ground where people live and work, will come from CALIPSO data which provides vertical profiles of atmospheric aerosol extinction.  Information on GLP levels will allow the scientific community to better understand health impacts from exposure to low, moderate, or high levels of PM2.5. Moreover, in places where PM2.5 levels are elevated only occasionally, such as Mississippi, the short-term health impact of increases in PM2.5 can be studied more precisely. National GLP data will be made available to other researchers to facilitate future explorations of how PM2.5 exposure impacts a wide range of health conditions, thereby making possible more timely prophylactic treatment, improving healthcare system preparedness, and better informing public health policymaking.          Among air pollutants, particulates 2.5 micrometers in diameter and smaller (PM2.5) have the greatest impact on human health because they are small enough to be inhaled deeply into the lungs, making allergies, asthma, and other respiratory conditions worse. The proposed study will provide daily estimates of ground-level PM2.5 for the entire contiguous U.S. so that researchers can study how it affects disease at various locations in the country. The knowledge that results can be used to better inform people about the links between air pollution and disease, and to guide the development of air quality standards to improve public health.            ",A New Approach to Compute PM2.5 for Health Impact Analysis,8319377,R21ES019713,"['Accounting', 'Address', 'Admission activity', 'Aerosols', 'Affect', 'Air', 'Air Pollutants', 'Air Pollution', 'Area', 'Artificial Intelligence', 'Asthma', 'Birth Rate', 'Breathing', 'Caliber', 'Cardiovascular Diseases', 'Chronic Obstructive Airway Disease', 'Communities', 'Country', 'Data', 'Data Quality', 'Data Sources', 'Development', 'Disease', 'Emergency Medicine', 'Environmental Wind', 'Epidemiology', 'Exposure to', 'Extinction (Psychology)', 'Future', 'Goals', 'Health', 'Healthcare Systems', 'Heart Diseases', 'Height', 'Hospitals', 'Human', 'Humidity', 'Hypersensitivity', 'Life', 'Link', 'Location', 'Lung', 'Machine Learning', 'Malignant neoplasm of lung', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Mississippi', 'Modeling', 'Monitor', 'National Institute of Environmental Health Sciences', 'Optics', 'Particulate', 'Particulate Matter', 'Personal Satisfaction', 'Process', 'Property', 'Prophylactic treatment', 'Proxy', 'Public Health', 'Readiness', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Scientist', 'Site', 'Source', 'Speed', 'Surface', 'Surveillance Program', 'System', 'Techniques', 'Temperature', 'Testing', 'Time', 'United States National Aeronautics and Space Administration', 'Variant', 'Visit', 'Work', 'base', 'burden of illness', 'design', 'hazard', 'improved', 'indexing', 'interest', 'knowledge of results', 'novel', 'novel strategies', 'particle', 'planetary Atmosphere', 'pressure', 'prototype', 'respiratory', 'sensor', 'statistics', 'web based interface']",NIEHS,UNIVERSITY OF MISSISSIPPI MED CTR,R21,2012,145856,-0.09776844211444195
"Developing an online educational curriculum to enhance parent-supervised driving     DESCRIPTION (provided by applicant): Motor vehicle crashes are the leading cause of death and injury for teens, accounting annually for over 3000 deaths, 100 times as many injuries, and over 14 billion dollars in associated costs. The CDC has identified traffic crashes and associated injuries as a top public health priority. Inexperience is the leading cause of crashes among novice teen drivers, but accumulating the necessary experiences to become a safe driver can take many years. Fortunately, evidence from driving and other domains suggests that it is possible to increase experiential knowledge through scenario-based training. Current methods for providing teens with practice focus on parent-supervised driving. However, parents are ill-prepared to handle this role, with many focusing only on the mechanics of driving, laws and general safety advice. Few parents discuss decision-making aspects of driving and may even pass on inaccurate information. Many parents limit the range of driving situations teens are exposed to mistakenly believing that this increases safety rather than dangerously limiting teens' ability to accumulate important driving experience. Our long-term objective is to design and validate an innovative tool that aims to accelerate the acquisition of critical safety knowledge for teen drivers. We propose to extend our team's past work by developing scenarios appropriate for parents to use to mentor their inexperienced teen drivers. The scenarios will be part of an online educational curriculum designed to help parents provide teens with guided practice as they learn how to drive. The online tool will combine scenario- based training with innovative applications of machine learning technology to evaluate scenario responses and provide tailored feedback containing practical, developmentally appropriate strategies for improving safety as well as recommendations for parent-supervised on-the-road practice. Phase I will address these specific aims: 1) Conduct foundational research to identify realistic scenarios commonly encountered by novice teen drivers through semi-structured interviews with teen drivers aged 15-18. 2) Collect representative responses to scenarios from teens with different levels of driving experience and adults to identify the progression of knowledge and identify developmentally appropriate strategies to use as feedback. 3) Create machine learning algorithms to provide tailored feedback and recommend on-the-road driving experiences based on responses to the scenarios. 4) Develop prototype online system. Phase II will focus on additional specific aims: 5) Develop the Phase I proof of concept into a complete online curriculum with refined algorithms. 6) Evaluate the online curriculum for usability, acceptance via focus groups, and effectiveness via a driving simulator experiment and limited field trial with novice teen drivers. The proposed product represents a significant shift in trainig approaches for teen drivers and through Phase III dissemination it will fill a critical need for evidence- based parent-taught driver's education.        PUBLIC HEALTH RELEVANCE: Motor vehicle crashes are the leading cause of death and injury for teens, accounting annually for over 3000 deaths, 100 times as many injuries, and over 14 billion dollars in associated costs; despite this, many teens' primary source of driver's education is their parents. In Phase I we propose to extend our past work for teaching experiential knowledge and develop a prototype online educational curriculum that allows parents to provide teens with guided practice by utilizing innovative machine learning technologies, while Phase II will allow us to complete the prototype and evaluate its effectiveness. The proposed application represents a significant shift in training approaches that has the potential, through Phase III dissemination, to improve teen driving safety.              Motor vehicle crashes are the leading cause of death and injury for teens, accounting annually for over 3000 deaths, 100 times as many injuries, and over 14 billion dollars in associated costs; despite this, many teens' primary source of driver's education is their parents. In Phase I we propose to extend our past work for teaching experiential knowledge and develop a prototype online educational curriculum that allows parents to provide teens with guided practice by utilizing innovative machine learning technologies, while Phase II will allow us to complete the prototype and evaluate its effectiveness. The proposed application represents a significant shift in training approaches that has the potential, through Phase III dissemination, to improve teen driving safety.            ",Developing an online educational curriculum to enhance parent-supervised driving,8392844,R41HD074300,"['Accounting', 'Address', 'Adult', 'Agreement', 'Algorithms', 'Automobile Driving', 'Behavioral', 'Cause of Death', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Collection', 'Decision Making', 'Development', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Focus Groups', 'Human', 'Injury', 'Interview', 'Knowledge', 'Laws', 'Lead', 'Learning', 'Licensing', 'Machine Learning', 'Mechanics', 'Mentors', 'Methods', 'Motor Vehicles', 'Online Systems', 'Parents', 'Performance', 'Phase', 'Preparation', 'Recommendation', 'Research', 'Risk', 'Role', 'Safety', 'Sampling', 'Semantics', 'Site', 'Source', 'Staging', 'Structure', 'Surveys', 'System', 'Teaching Method', 'Techniques', 'Technology', 'Teenagers', 'Time', 'Training', 'Vehicle crash', 'Work', 'aged', 'base', 'cost', 'design', 'evidence base', 'experience', 'improved', 'innovation', 'instrument', 'prospective', 'prototype', 'public health priorities', 'research and development', 'research study', 'response', 'success', 'teen driving', 'tool', 'trafficking', 'usability', 'web page']",NICHD,"PARALLEL CONSULTING, LLC",R41,2012,116895,-0.022559804179273373
"High-Throughput Computing for a Multi-Plan Framework in Radiotherapy  PROJECT SUMMARY/ABSTRACT Computerized planning for radiation delivery via either external beam radiation therapy (EBRT) or intensity- modulated radiation therapy (IMRT) from linear accelerators is a complex process involving a large amount of input data and vast numbers of decision variables. Such large-scale combinatorial optimization problems are typically intractable for conventional approaches such as the direct application of the best available commercial algorithms, and thus specialized methods that take advantage of problem structure are required. Radiation treatment planning (RTP) problems are further complicated by the fact that they are multi-objective, that is, the RTP optimization process must take into account a trade-off between the competing goals of delivering appropriate doses to the tumor and avoiding the delivery of harmful radiation to nearby healthy organs. The goal of this proposal is to harness distributive computing via the Condor system for High Throughput Computing (HTC) within an RTP environment. The specific aims for this proposal are: 1) To develop a Nested Partitions (NP) framework that guides a global search process for optimal IMRT delivery parameters using HTC. 2) To develop parallel HTC-based linear programming (LP) methods to efficiently solve the dose optimization problem in IMRT for each given set of beam angles or beam apertures. (3) To exploit a high-throughput computing (HTC) environment and the developed NP/LP/segmentation framework to efficiently generate multiple plans for each given patient case. (4) To couple this multi-plan framework with a decision support system (DSS) that includes planning surface models, a graphical-user-interface (GUI) and machine learning tools to prediction OAR complication in order to aid in the ranking and selection of the generated treatment plans. This proposal requires a multi-disciplinary approach that is best conducted within the framework of the Innovations in Biomedical Computational Science and Technology program announcement. It brings together an interdisciplinary team of investigators with expertise in medical physics, mathematical programming, industrial engineering and clinical radiation oncology that is crucial to the development of the proposed multi- plan framework using HTC in radiation therapy.  PROJECT NARRATIVE The goal of this proposal is to develop a multi-dimensional platform for sophisticated treatment planning of radiation delivery. It will develop novel algorithms that will enable generation of superior treatment plans with the added advantage of increasing the speed of treatment planning. Further, it will allow physicians to know beforehand the quality of the treatment plan relative to the multiple treatment objectives and be able to determine the treatment complication scenario beforehand.",High-Throughput Computing for a Multi-Plan Framework in Radiotherapy,8271284,R01CA130814,"['Accounting', 'Algorithms', 'Behavior', 'Clinical Engineering', 'Collection', 'Complex', 'Complication', 'Computational Science', 'Data', 'Decision Support Systems', 'Dependence', 'Development', 'Dose', 'Engineering', 'Environment', 'External Beam Radiation Therapy', 'Generations', 'Genetic Programming', 'Goals', 'Intensity-Modulated Radiotherapy', 'Knowledge', 'Lead', 'Linear Accelerator Radiotherapy Systems', 'Linear Programming', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Modeling', 'Monte Carlo Method', 'NIH Program Announcements', 'Organ', 'Patients', 'Physicians', 'Physics', 'Process', 'Property', 'Radiation', 'Radiation Oncology', 'Radiation therapy', 'Relative (related person)', 'Research Personnel', 'Risk', 'Sampling', 'Shapes', 'Simulate', 'Solutions', 'Speed', 'Structure', 'Surface', 'System', 'Technology', 'Time', 'Toxic effect', 'base', 'cluster computing', 'combinatorial', 'computer science', 'computerized', 'computing resources', 'direct application', 'graphical user interface', 'heuristics', 'improved', 'innovation', 'insight', 'novel', 'novel strategies', 'predictive modeling', 'process optimization', 'programs', 'research clinical testing', 'tool', 'treatment planning', 'tumor']",NCI,UNIVERSITY OF MARYLAND BALTIMORE,R01,2012,297329,-0.034676289104541555
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.           Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8320160,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'metagenome', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2012,204974,-0.03721412155059692
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.        Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8294581,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Screening procedure', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild neurocognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2012,348750,-0.034864782956803675
"Hand Sensorimotor Function and Carpal Tunnel Syndrome    DESCRIPTION (provided by applicant): The median nerve is susceptible to compression in the wrist, leading to carpal tunnel syndrome (CTS). CTS is the most common compression neuropathy and have an immense impact on national health care, worker productivity, and quality of life. Despite its high prevalence and public health cost, our understanding of CTS is limited, and the management of CTS awaits improvement. The central notion of this project is that hand sensorimotor function is sensitive to peripheral median neuropathy and that the central nervous system is affected by CTS, causing the associated sensorimotor deficit. We will investigate this notion with quantifiable sensorimotor data from novel biomechanical and neurophysiological studies. This project has three aims consisting of biomechanical, neurophysiological and translational research. The first aim is to investigate CTS-induced pathokinematic and pathokinetic performance using dexterous manual tasks of thumb opposition, reach-to-pinch, precision grip, and finger pressing. The second aim is to investigate the neurophysiological implications of chronic peripheral neuropathy (i.e., CTS) on the central nervous system by evaluating corticomuscular coupling and stretch reflex. The third aim is to identify novel biomechanical and neurophysiological markers for CTS cases using machine learning and classification algorithms. The results of this project will elucidate the pathological mechanisms and behavioral manifestations of CTS and aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder. More generally, CTS as a chronic neuropathy serves as an effective model to study sensorimotor mechanisms of the peripheral and central nervous systems. In addition, the methodology developed in this project is applicable to other neuromuscular disorders.      PUBLIC HEALTH RELEVANCE:   Carpal tunnel syndrome is highly prevalent and costly. One of the distinct consequences of carpal tunnel syndrome is that patients experience inexplicable dropping of objects and clumsiness while performing simple daily tasks. In this project, we propose to study the sensorimotor deficit using novel biomechanical and neurophysiological experiments. The results of this project will elucidate the pathological mechanisms and manifestations of carpal tunnel syndrome. This project is clinically translational to aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder.                 Project Narrative Carpal tunnel syndrome is highly prevalent and costly. One of the distinct consequences of carpal tunnel syndrome is that patients experience inexplicable dropping of objects and clumsiness while performing simple daily tasks. In this project, we propose to study the sensorimotor deficit using novel biomechanical and neurophysiological experiments. The results of this project will elucidate the pathological mechanisms and manifestations of carpal tunnel syndrome. This project is clinically translational to aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder.",Hand Sensorimotor Function and Carpal Tunnel Syndrome,8249044,R01AR056964,"['Abnormal coordination', 'Affect', 'Algorithms', 'Behavioral Mechanisms', 'Biomechanics', 'Carpal Tunnel Syndrome', 'Carpometacarpal joint structure', 'Chronic', 'Classification', 'Clinical', 'Coupling', 'Data', 'Development', 'Disease', 'Drops', 'Electroencephalography', 'Electromyography', 'Exertion', 'Eye', 'Fingers', 'Hand', 'Health Care Costs', 'Health Personnel', 'High Prevalence', 'Human', 'Individual', 'Joints', 'Lasso', 'Machine Learning', 'Manuals', 'Measures', 'Median Neuropathy', 'Metacarpophalangeal joint structure', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Cortex', 'Neural Conduction', 'Neuraxis', 'Neuromuscular Diseases', 'Neuropathy', 'Patients', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Production', 'Productivity', 'Pronation', 'Public Health', 'Quality of life', 'Questionnaires', 'Reaction', 'Rehabilitation therapy', 'Reproducibility', 'Research', 'Response Latencies', 'Sensorimotor functions', 'Sensory', 'Techniques', 'Testing', 'Thumb structure', 'Time', 'Translational Research', 'Trees', 'Validation', 'Wrist', 'data mining', 'diagnosis evaluation', 'experience', 'grasp', 'improved', 'indexing', 'median nerve', 'motor control', 'neurophysiology', 'novel', 'programs', 'public health relevance', 'research study', 'response', 'stretch reflex', 'tool', 'vector']",NIAMS,CLEVELAND CLINIC LERNER COM-CWRU,R01,2012,353250,-0.011934699275213406
"Reduced-Order Constrained Optimization for Rapid IMRT and VMAT Treatment Planning    DESCRIPTION (provided by applicant): Intensity-modulated radiotherapy (IMRT) has revolutionized the treatment of cancers in the last decade, since it can tightly conform and escalate radiation dose to a tumor while simultaneously protecting nearby radiation- sensitive normal tissues, resulting in better local control and fewer post-treatment complications than previous techniques. However, the process of obtaining a clinically acceptable IMRT plan for a difficult site is still extremely slow, requiring many hours of a busy expert's time in a manual trial-and-error loop of parameter adjustment. The goal of this project is to drastically reduce the amount of time to obtain a clinically acceptable IMRT plan using a new automated method that directly applies constrained optimization in a computationally tractable and clinically meaningful way. The hypothesis is that clinical treatment planning times using this technique will be reduced from several hours to a matter of minutes.  The new approach, called ROCO (Reduced-Order Constrained Optimization) translates well-established concepts from optimization and machine learning theory to the novel application of IMRT planning, exploiting the speed and ease of unconstrained optimizations and introducing a dimensionality reduction step that makes true constrained optimization tractable. The Specific Aims of the proposal are to (1) apply Reduced-Order Con- strained Optimization to IMRT planning for non-small cell lung cancers and nasopharynx cancers, where the planning process is highly time-consuming; (2) develop and extend the Reduced-Order Constrained Optimization paradigm to a promising IMRT variant called Volumetric Modulated Arc Therapy (VMAT) for the prostate site, which is currently nearly clinically intractable to plan; and (3) integrate the new tools into the clinical IMRT planning process at Memorial Sloan-Kettering Cancer Center, using a powered study to verify the hypothesis that the proposed method significantly improves planning speed. The experiments will be designed in consultation with an expert clinical treatment planner and biostatistician, and carefully validated using anonymized data from approximately 50 patients for each site.  The main benefit of the proposed approach is to drastically reduce planning times, which is critical if IMRT and VMAT are to reach their full potential in clinical application. In a busy clinic, long planning times place a severe stress on available resources, and can result in treatment delays, acceptance of sub-optimal plans or - in the worst case - errors due to time pressure. In the longer term, the proposed approach will provide deeper insight into the critical elements of the dose optimization problem, significantly reduce the trial-and-error effort characteristic of current IMRT planning, and reduce subjectivity in treatment plan selection.      PUBLIC HEALTH RELEVANCE: Intensity-modulated radiation therapy (IMRT) is an extremely promising cancer treatment, but currently requires many hours of an expert treatment planner's time to obtain a plan that meets all the clinical constraints specified by the physician. This proposal describes a new, automatic method for treatment plan optimization that is very fast, requiring only minutes to produce a plan that directly meets all the physician's constraints, potentially saving much time for a busy clinic.           Project Narrative Intensity-modulated radiation therapy (IMRT) is an extremely promising cancer treatment, but currently requires many hours of an expert treatment planner's time to obtain a plan that meets all the clinical constraints specified by the physician. This proposal describes a new, automatic method for treatment plan optimization that is very fast, requiring only minutes to produce a plan that directly meets all the physician's constraints, potentially saving much time for a busy clinic.",Reduced-Order Constrained Optimization for Rapid IMRT and VMAT Treatment Planning,8234172,R01CA148876,"['Acute', 'Address', 'Aftercare', 'Algorithms', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Treatment', 'Code', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'Consultations', 'Data', 'Development', 'Dose', 'Dose-Limiting', 'Drug Formulations', 'Effectiveness', 'Elements', 'Goals', 'Head and Neck Neoplasms', 'Head and neck structure', 'Hour', 'Housing', 'Human', 'Intensity-Modulated Radiotherapy', 'Journals', 'Linear Accelerator Radiotherapy Systems', 'Lung', 'Machine Learning', 'Malignant neoplasm of nasopharynx', 'Manuals', 'Measures', 'Medical', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Nasopharynx', 'Non-Small-Cell Lung Carcinoma', 'Normal tissue morphology', 'Organ', 'Paper', 'Parotid Gland', 'Patients', 'Phase', 'Physicians', 'Physics', 'Process', 'Prostate', 'Quality of life', 'Radiation', 'Radiation therapy', 'Resources', 'Risk', 'Sampling', 'Site', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Stress', 'Sum', 'System', 'Techniques', 'Technology', 'Time', 'To specify', 'Toxic effect', 'Translating', 'Variant', 'Weight', 'Xerostomia', 'base', 'cancer therapy', 'clinical application', 'clinical practice', 'design', 'experience', 'image processing', 'improved', 'insight', 'meetings', 'novel', 'novel strategies', 'pressure', 'process optimization', 'public health relevance', 'rectal', 'research study', 'symposium', 'theories', 'time use', 'tool', 'treatment planning', 'tumor']",NCI,RENSSELAER POLYTECHNIC INSTITUTE,R01,2012,383930,-0.03311628413920534
"Developing a Virtual Basic Laparoscopic Skill Trainer (VBLaST)    DESCRIPTION (provided by applicant):  Development and Validation of a Virtual Basic Laparoscopic Skill Trainer (VBLaST) For the first time in the history of surgical education, a comprehensive program to teach and evaluate the cognitive and psychomotor aspects unique to laparoscopic surgery - the Fundamentals of Laparoscopic Surgery (FLS) developed originally by the Society of American Gastrointestinal Endoscopic Surgery (SAGES) and subsequently by a joint committee which includes the American College of Surgeons (ACS) - is being embraced nationally for training and credentialing laparoscopic surgeons. As an example of its growing acceptance by the medical community, starting in 2009, the American Board of Surgeons has mandated that passing the FLS certifying examination will be required for taking the board examination in surgery. While the cognitive assessment in FLS is based on 75 multiple-choice questions, a proctored examination is used for the manual skills assessment which includes five tasks to be performed in a portable pelvic trainer box with built-in video camera: bimanual peg transfer, precise pattern cutting, use of ligating loops and suturing with intracorporeal and extracorporeal knot tying. In spite of the growing popularity of the FLS, there are several major problems with this box trainer paradigm: (1) the assessment is subjective, (2) there is no feedback during learning except when an experienced trainer is present, (3) a large number of qualified proctors must be engaged during test taking, (4) the training material must be constantly replaced, and (5) the test-takers must travel to one of the 27 Regional Test Centers or the Annual SAGES meeting or the ACS Clinical Congress. To overcome these problems and to enable greater dissemination, we propose to develop and validate a Virtual Basic Laparoscopic Skill Trainer (VBLaST) whereby tasks available in the FLS may be performed on PCs and laptops with inexpensive haptic (touch) interface devices, such as the Phantom(R) OmniTM. To develop the VBLaST a novel set of technologies must be developed including rapid, but highly realistic physics-based virtual interaction paradigms and statistical machine learning techniques to develop a ""virtual mentor"" which will provide real time automated feedback to the trainees. A comprehensive set of studies involving students, residents, fellows and practicing surgeons at Boston area hospitals (e.g., BIDMC, Tufts Medical Center, Cambridge Health Alliance, Harvard, MGH, Brigham & Women's, Lahey Clinic) will be undertaken to test the validity of the VBLaST as a training tool and establish its usefulness in transferring the acquired skills to the operating room. Once validated, the VBLaST will have exponential impact in reducing training costs and training time while improving patient safety and outcomes, A multidisciplinary team with collective expertise in physics-based interactive medical simulation, laparoscopic surgery and surgical education, and human factors engineering has been assembled to achieve the following Specific Aims: SA1) To develop a realistic virtual basic laparoscopic skill trainer (VBLaST) platform to perform all the tasks available in the FLS training tool box. SA2) To establish the validity of the VBLaST as a training tool. SA3) To evaluate the usefulness of the VBLaST as a training tool. SA4) To develop a web-based interface for the VBLaST.      PUBLIC HEALTH RELEVANCE: The goal of this research is to develop a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills and to take standardized tests on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.           Relevance: The goal of this research is to develop a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills and to take standardized tests on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.",Developing a Virtual Basic Laparoscopic Skill Trainer (VBLaST),8274880,R01EB010037,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'American', 'American College of Surgeons', 'Area', 'Attention', 'Auditory', 'Boston', 'Boxing', 'Clinic', 'Clinical', 'Cognitive', 'Communities', 'Complication', 'Computer Simulation', 'Computers', 'Congresses', 'Credentialing', 'Cues', 'Development', 'Devices', 'Education', 'Educational process of instructing', 'Endoscopic Gastrointestinal Surgical Procedures', 'Engineering', 'Ensure', 'Feedback', 'Funding', 'Goals', 'Group Practice', 'Healed', 'Health Alliance', 'Hospitals', 'Human', 'Industry', 'Information Sciences', 'Information Technology', 'Institutes', 'Israel', 'Joints', 'Laparoscopic Cholecystectomy', 'Laparoscopic Surgical Procedures', 'Learning', 'Length of Stay', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Errors', 'Medical center', 'Mentors', 'Metric', 'Minimally Invasive Surgical Procedures', 'Morbidity - disease rate', 'National Institute of Biomedical Imaging and Bioengineering', 'Online Systems', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Pattern', 'Pelvis', 'Physicians', 'Physics', 'Procedures', 'Qualifying', 'Recording of previous events', 'Reporting', 'Research', 'Research Activity', 'Research Project Grants', 'Risk', 'Societies', 'Students', 'Surgeon', 'Surgical Error', 'Surgical complication', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Training', 'Translating', 'Travel', 'Treatment Cost', 'United States National Institutes of Health', 'Universities', 'Validation', 'Visual', 'Woman', 'bariatric surgery', 'base', 'cost', 'experience', 'haptics', 'healing', 'improved', 'laptop', 'malignant breast neoplasm', 'meetings', 'multidisciplinary', 'new technology', 'novel', 'patient safety', 'programs', 'public health relevance', 'research study', 'simulation', 'skills', 'success', 'tool', 'vehicular accident', 'virtual', 'virtual reality', 'web based interface']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R01,2012,499239,-0.006277253060118782
"Fractal Identification System for Medication     DESCRIPTION (provided by applicant): Ai Cure Technologies LLC, was established in 2009 to develop computer vision solutions to ensure safer medication usage. This SBIR Phase I will allow Ai Cure Technologies to prove feasibility of an innovative identification and anti-counterfei labeling solution that replaces traditional barcodes and utilizes the self-similarity properties of fractals to encode and print unique secure fractal patterns directly onto pills or capsules. This SBIR Phase I will allow technical feasibility of this solution, Fractal-ID"", to be demonstrated and will test if a fractal pattern can be printed onto a pill and then recognized with computer vision software. The ability to accurately identify and authenticate pills enables medication to be correctly prescribed and administered. Yet a drug's packaging and labeling is not a stamp of authenticity. It is almost impossible for patients and healthcare professionals to identify pills based on their physical characteristics and to decipher the pill's imprint, its unique identifying code. As a result, the twin problems of counterfeit medication and medication errors - both of which depend upon pill identification - are very difficult to stem. Medication errors contribute heavily to the public health burden. 1.5 million people are harmed every year in the US because of medication errors and the cost for hospitals alone is approximately $3.5 billion. The physical appearances of pills play a large part - it is estimated that a pill's packaging and labeling are responsible for one third of medication errors. More than 10% of the world's drugs are counterfeit, rising to 50% for certain drugs in developing countries. The counterfeit drug market is estimated to be between $75 and $200 billion per year and is growing in countries with strict regulations. 100,000 deaths are attributed to counterfeit drugs every year and there is an unknown morbidity toll since substandard or counterfeit medicines are also responsible for drug resistance, therapeutic failure and dangerous health outcomes. Since medications are repackaged and change hands many times in the supply chain, direct pill and capsule labeling offers a more robust solution to medication identification. While barcodes may be used to serialize individual pills, their fixed designs are unsuitable for the shape, color, texture variablity found in pills and capsules. Furthermore, barcodes are easy to replicate, require fixed surface areas and specific alignment for printing, and are rendered unusable if occlusion occurs due to handling or damage. In addition, the item's physical attributes are distinct from the barcode itself. Ai Cure Technologies will offer pharmaceutical manufacturers, Fractal-ID(tm), a medication identification and authentication solution. The solution will equip manufacturers with printers and a license to a secure fractal label library; consumers will have access to a free computer vision software application to identify fractal pills; and investigators will be provided with higher resolution authentication tools.         PUBLIC HEALTH RELEVANCE: The ability to accurately identify and authenticate pills enables medication to be correctly prescribed and administered. As a result, the twin problems of counterfeit medication and medication errors - both of which depend upon pill identification - are very difficult to stem. Ai Cure Technologies will offer a medication identification solution for pils and capsules that will allow manufacturers, anti-counterfeit investigators, and patients to identif and authenticate medication.                       The ability to accurately identify and authenticate pills enables medication to be correctly prescribed and administered. As a result, the twin problems of counterfeit medication and medication errors - both of which depend upon pill identification - are very difficult to stem. Ai Cure Technologies will offer a medication identification solution for pils and capsules that will allow manufacturers, anti-counterfeit investigators, and patients to identif and authenticate medication.                     ",Fractal Identification System for Medication,8394091,R43TR000190,"['Address', 'Algorithms', 'Appearance', 'Area', 'Biomedical Research', 'Cessation of life', 'Characteristics', 'Code', 'Color', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Country', 'Data', 'Data Protection', 'Data Security', 'Developing Countries', 'Development', 'Devices', 'Drug Industry', 'Drug Packaging', 'Drug resistance', 'Ensure', 'Environment', 'Failure', 'Fingerprint', 'Fractals', 'Goals', 'Hand', 'Health', 'Health Professional', 'Health system', 'Hospital Costs', 'Image', 'Imaging technology', 'Individual', 'Label', 'Libraries', 'Licensing', 'Lighting', 'Manufacturer Name', 'Marketing', 'Medical', 'Medication Errors', 'Medication Systems', 'Medicine', 'Morbidity - disease rate', 'New York', 'Outcome', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Play', 'Printing', 'Process', 'Property', 'Public Health', 'Regulation', 'Research Personnel', 'Resolution', 'Secure', 'Security', 'Shapes', 'Small Business Innovation Research Grant', 'Solutions', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Twin Multiple Birth', 'Work', 'base', 'capsule', 'commercial application', 'design', 'drug market', 'imprint', 'innovation', 'lens', 'phase 1 study', 'pill', 'stem', 'tool', 'transmission process']",NCATS,"AI CURE TECHNOLOGIES, LLC",R43,2012,227209,-0.03740891400610928
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8320255,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2012,345408,-0.019957456934419228
"Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements    DESCRIPTION (provided by applicant): Thyroid nodules are present in a large fraction of healthy individuals. Between 4% and 7% of the United States adult population has palpable thyroid nodules, and up to 50% of American women older than age 50 have nodules that can be depicted on ultrasound. The vast majority (>95%) of thyroid nodules are benign. However, cancer risk increases with male gender, nodule size, extremes of age (< 30 and > 60 years), underlying autoimmune disease, nodule growth, personal or family history of thyroid cancer, and radiation exposure. Ultrasound imaging and Fine Needle Aspiration Biopsy (FNAB) remain the mainstays of thyroid nodule evaluation. Unfortunately, 25% of patients who ultimately undergo FNAB of a thyroid nodule have indeterminate cytology. Many of these patients will require at least partial thyroidectomy purely for the purpose of obtaining a definitive diagnosis. Given that only 30% of these will ultimately prove to be malignant on surgical pathology, the majority of these lobectomies could potentially be avoided if better non-invasive methods existed to evaluate indeterminate nodules. Electrical Impedance Scanning (EIS) has been previously investigated for non-invasive evaluation of thyroid nodules. The overall diagnostic accuracy of EIS was encouraging but not sufficient for routine clinical use. We have developed a modified approach termed here Resonance Electrical Impedance Spectroscopy (REIS) that should have substantially higher sensitivity and specificity for this very purpose. When using REIS technology to examine the breast, we obtained initial results that are significantly better in all respects than those obtained with traditional EIS. We believe that REIS technology will similarly improve the assessment of thyroid nodules. REIS hold promise as a reproducible modality for the risk stratification of the many patients with indeterminate thyroid nodules. It is a new non- invasive modality that may help reduce the number of diagnostic lobectomies and would be welcomed by patients with non-diagnostic FNA results. The purpose of this application is to design, assemble, and test in a preliminary clinical study a unique REIS based device for the assessment of thyroid nodules.      PUBLIC HEALTH RELEVANCE: We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.           Project narrative:  We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.",Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements,8207850,R21CA154262,"['Address', 'Adult', 'Age', 'American', 'Aspirate substance', 'Autoimmune Diseases', 'Benign', 'Biopsy', 'Breast', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Consent', 'Cytology', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Endocrine', 'Endocrinologist', 'Evaluation', 'Excision', 'Family history of', 'Fine needle aspiration biopsy', 'Follicular thyroid carcinoma', 'Frequencies', 'Gender', 'General Anesthesia', 'Growth', 'Human', 'Image', 'Incidence', 'Individual', 'Lesion', 'Lobectomy', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measurement', 'Measures', 'Methods', 'Modality', 'Neck', 'Nodule', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Palpable', 'Papillary', 'Papillary Carcinoma', 'Participant', 'Patients', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Procedures', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Radiation', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Spectrum Analysis', 'Stratification', 'Surgeon', 'Surgical Pathology', 'System', 'Techniques', 'Technology', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Thyroidectomy', 'Triage', 'Ultrasonography', 'United States', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer risk', 'clinical practice', 'design', 'diagnostic accuracy', 'electric impedance', 'imaging modality', 'improved', 'male', 'malignant breast neoplasm', 'men', 'older women', 'phase change', 'prospective', 'prototype', 'public health relevance', 'radiologist', 'tool', 'web site']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2012,164756,-0.061801839128610654
"Sensory based CNS diagnostics for the clinic    DESCRIPTION (provided by applicant): There is currently a significant gap that exists between fundamental neuroscience research and translation of the findings of that research into everyday practice. Experimental findings at the genetic, cellular, molecular and systems level often take a fairly long and frequently circuitous route to make an impact on a particular neurological disease or disorder. The goal of our work is to bridge the neuroscientific gap at the systems level of study by developing standardized sensory measures that can be not only utilized in clinical or clinical research settings, but can be directly correlated with the observations obtained directly from sensory cortex in non-human primates via high resolution imaging and extracellular recording. Successful development of an experimental model that iteratively evaluates the relationship of clinical measures and systemic CNS responses to specific mechanistic alterations will be quite significant. Such an evaluation of an individual's CNS status could be directly linked to systemic mechanistic deficiencies or alterations observed in animal experimentation.  Towards that goal, we have successfully designed and fabricated a tactile sensory diagnostic device. In parallel with that development, we designed a number of protocols - based on experimental neurophysiological findings from both our non human primate research and that of others - that could be rapidly and efficiently delivered (1-3 minutes) to a number of subject populations. The tactile diagnostic system that we have developed was conceptually designed to investigate differences in cortical information processing strategies between people with autism and people without. In this proposal we ask whether or not the strategy that we have devised for investigating a population with a neurodevelopmental disorder could be broadly applied to a number of neurological disorders. In other words, we consider the changes manifested by the neurodevelpmental disorder autism to be systemic, and if systemic cortical alterations occur in other neurological disorders, could they also be detected in the same manner?  Proof-of-concept studies in a number of clinical research areas demonstrated that these newly developed metrics were sensitive to systemic cortical alterations. One question that emerges from this data is that most of these neurological disorders result in some type of altered central sensitization, no matter what the cause - whether it be neurodevelopmental, neurodegenerative, pharmacological or trauma induced - in which there is a significant change in the balance between excitation and inhibition. This application proposes to determine if sensory perceptual metrics, similar to those that were used to successfully distinguish subjects with autism from healthy control populations (with 90% accuracy using SVM to assess the results of a 25 minute battery of 9 protocols), could be used to reliably distinguish - on an individual basis - subjects with neurological disorders that are not neurodevelopmental in nature. Towards this goal, we target subjects from one broad category of neurological disorders - chronic pain. More specifically, we will examine the differences and commonalities from observations of pain patients diagnosed with one of the following: fibromyalgia, vulvodynia, TMJD, IBS and migraine.        The overall goal of the proposed work is to investigate the utility of novel sensory-based methodologies that are currently being used in both basic and clinical research. Recently, utilizing state-of-the-art technology, we built a multi-site tactile stimulator that allows for investigation of central nervous system (CNS) health and advanced methods in sensory perceptual metrics. These metrics have been demonstrated to be sensitive to changes in centrally mediated mechanisms; and systemic alterations of cortical health (via neurodegenerational, neurodevelopmental, pharmacological or trauma induced changes) robustly change the measures. It is anticipated that clinicians will be able to utilize these measures to improve diagnostic performance and enable assessment of efficacy of treatment. The study itself will serve to validate the utility of a number of these measures in several types of pain, specifically fibromyalgia, TMJD, IBS, vulvodynia and migraine. The information from this study could aid in understanding centrally mediated mechanisms that undergo significant alterations with chronic pain.         ",Sensory based CNS diagnostics for the clinic,8293088,R21NS072811,"['Address', 'Age', 'Animal Experimentation', 'Area', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Brain Concussion', 'Caregivers', 'Categories', 'Cerebrum', 'Clinic', 'Clinical', 'Clinical Research', 'Data', 'Databases', 'Development', 'Devices', 'Dextromethorphan', 'Diagnosis', 'Diagnostic', 'Disease', 'Equilibrium', 'Evaluation', 'Experimental Models', 'Fibromyalgia', 'GABA Agonists', 'Genetic', 'Goals', 'Health', 'Image', 'Individual', 'Investigation', 'Laboratory Animals', 'Lead', 'Letters', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Metric', 'Migraine', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Nature', 'Nerve Degeneration', 'Neuraxis', 'Neurodevelopmental Disorder', 'Neurons', 'Neurosciences Research', 'Ophthalmic examination and evaluation', 'Pain', 'Patients', 'Performance', 'Physiological', 'Play', 'Population', 'Population Control', 'Primary Health Care', 'Process', 'Protocols documentation', 'Recruitment Activity', 'Research', 'Resolution', 'Role', 'Route', 'Sensory', 'Site', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Technology', 'Temporomandibular Joint Disorders', 'Testing', 'Translations', 'Trauma', 'Treatment Efficacy', 'United States National Institutes of Health', 'Vulvodynia', 'Work', 'analytical tool', 'base', 'central sensitization', 'chronic pain', 'cohort', 'cost effective', 'data mining', 'demographics', 'design', 'extracellular', 'gamma-Aminobutyric Acid', 'improved', 'in vivo', 'information processing', 'nervous system disorder', 'neurophysiology', 'neurotransmission', 'nonhuman primate', 'novel', 'process optimization', 'protocol development', 'response', 'sensory cortex', 'white matter damage']",NINDS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2012,181885,-0.07674455059489381
"A photographic method for human body composition assessment     DESCRIPTION (provided by applicant): The assessment of body composition, particularly fat and fat free mass, is vital to understanding many health-related conditions including obesity and sarcopenia, whose very definitions depend on assessment of fat and fat free mass, but also cachexia induced by HIV, cancer, and other diseases; multiple sclerosis; wasting in neurological disorders such as Parkinson's, Alzheimer's, muscular dystrophy; eating disorders; proper growth in children; and yet others still. Nevertheless, challenges remain in measuring body composition. Existing methods beyond height, weight, and very simple anthropometry are still not the norm in large-scale epidemiologic studies and clinical studies. This is because of concerns, depending on method, about cost, portability, time, radiation exposure, and accuracy. Calculation of body mass index (BMI; kg/m2) is a commonly used alternative, but is limited in that it is an assessment of body weight relative to height and not of body fatness per se. A hand-held device that could be carried by any individual, accurately assess fat mass and skeletal muscle mass, and be utilized without any discomfort to the subject, inexpensively, and without radiation exposure would be highly desirable. Evidence suggests that highly experienced trained observers can accurately estimate percentage of body fat by visual examination of subjects, but concerns about accuracy and subjectivity predominate. We hypothesize that we can develop a computer algorithm which can perform as or more accurately when analyzing photographic imagery data, will require no repeated retraining, and eliminate subjectivity. Our first specific aim is to develop a computer image analysis algorithm to accurately estimate adiposity and skeletal muscle mass from standardized photographic images in a bi-ethnic sample of men, women, and children. Our second specific aim is to validate the algorithm in a large diverse sample of men, women, and children.        PUBLIC HEALTH RELEVANCE: Obesity, loss of skeletal muscle with aging, and other body composition alterations are of profound public health importance. We propose a novel method for measuring the quantity of fat and skeletal muscle mass in humans quickly, painlessly, safely, accurately, and inexpensively that can subsequently be used in many large scale and remote studies.                  Obesity, loss of skeletal muscle with aging, and other body composition alterations are of profound public health importance. We propose a novel method for measuring the quantity of fat and skeletal muscle mass in humans quickly, painlessly, safely, accurately, and inexpensively that can subsequently be used in many large scale and remote studies.                ",A photographic method for human body composition assessment,8295495,R01HL107916,"['Abbreviations', 'Advisory Committees', 'Age', 'Aging', 'Air', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anthropometry', 'Body Composition', 'Body Size', 'Body Weight', 'Body fat', 'Body mass index', 'Cachexia', 'Categories', 'Child', 'Clinical', 'Clinical Research', 'Computational algorithm', 'Data', 'Devices', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Eating Disorders', 'Epidemiologic Studies', 'Equipment', 'Exercise', 'Fatty acid glycerol esters', 'Growth', 'HIV', 'Hand', 'Health', 'Height', 'Home environment', 'Human', 'Human body', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Laboratories', 'Laboratory Study', 'Lead', 'Longevity', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Methods', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Obesity', 'Painless', 'Parkinson Disease', 'Participant', 'Persons', 'Plethysmography', 'Population', 'Public Health', 'Race', 'Radiation', 'Relative (related person)', 'Research', 'Sampling', 'Skeletal Muscle', 'Skin', 'Strategic Planning', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Visual', 'Weight', 'Woman', 'Work', 'Writing', 'X-Ray Computed Tomography', 'cost', 'digital', 'digital imaging', 'electric impedance', 'experience', 'field study', 'frailty', 'improved', 'interest', 'light weight', 'men', 'muscle form', 'nervous system disorder', 'novel', 'portability', 'primary outcome', 'response', 'sarcopenia', 'sex', 'waist circumference', 'wasting']",NHLBI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2012,504654,-0.018085802636628425
"Informatic tools for predicting an ordinal response for high-dimensional data    DESCRIPTION (provided by applicant):        Health status and outcomes are frequently measured on an ordinal scale. Examples include scoring methods for liver biopsy specimens from patients with chronic hepatitis, including the Knodell hepatic activity index, the Ishak score, and the METAVIR score. In addition, tumor-node-metasis stage for cancer patients is an ordinal scaled measure. Moreover, the more recently advocated method for evaluating response to treatment in target tumor lesions is the Response Evaluation Criteria In Solid Tumors method, with ordinal outcomes defined as complete response, partial response, stable disease, and progressive disease. Traditional ordinal response modeling methods assume independence among the predictor variables and require that the number of samples (n) exceed the number of covariates (p). These are both violated in the context of high-throughput genomic studies. Recently, penalized models have been successfully applied to high-throughput genomic datasets in fitting linear, logistic, and Cox proportional hazards models with excellent performance. However, extension of penalized models to the ordinal response setting has not been fully described nor has software been made generally available. Herein we propose to apply the L1 penalization method to ordinal response models to enable modeling of common ordinal response data when a high-dimensional genomic data comprise the predictor space. This study will expand the scope of our current research by providing additional model-based ordinal classification methodologies applicable for high-dimensional datasets to accompany the heuristic based classification tree and random forest ordinal methodologies we have previously described. The specific aims of this application are to: (1) Develop R functions for implementing the stereotype logit model as well as an L1 penalized stereotype logit model for modeling an ordinal response. (2) Empirically examine the performance of the L1 penalized stereotype logit model and competitor ordinal response models by performing a simulation study and applying the models to publicly available microarray datasets. (3) Develop an R package for fitting a random-effects ordinal regression model for clustered ordinal response data. (4) Extend the random-effects ordinal regression model to include an L1 penalty term to accomodate high-dimensional covariate spaces and empirically examine the performance of the L1random-effects ordinal regression model through application to microarray data. Studies involving protocol biopsies where both histopathological assessment and microarray studies are performed at the same time point are increasingly being performed, so that the methodology and software developed in this application will provide unique informatic methods for analyzing such data. Moreover, the ordinal response extensions proposed in this application, though initially conceived of by considering microarray applications, will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect human preference data and other responses on an ordinal scale.               Most histopathological variables are reported on an ordinal scale. Studies involving protocol biopsies where both histopathological assessment and microarray studies are performed at the same time point are increasingly being performed, and the software developed in this application will provide unique informatic tools for analyzing such data. Moreover, the informatic methods proposed in this application, though initially conceived of by con- sidering microarray applications, will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect human preference data and other responses on an ordinal scale.",Informatic tools for predicting an ordinal response for high-dimensional data,8216289,R01LM011169,"['Advocate', 'Behavioral Research', 'Bioconductor', 'Biopsy', 'Biopsy Specimen', 'Cancer Patient', 'Cancer Prognosis', 'Categories', 'Chronic Hepatitis', 'Classification', 'Client satisfaction', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Diagnostic Neoplasm Staging', 'Environment', 'Evaluation', 'Event', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Health', 'Health Status', 'Hepatic', 'Human', 'In complete remission', 'Informatics', 'Lesion', 'Logistics', 'Logit Models', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nodal', 'Outcome', 'Patients', 'Performance', 'Progressive Disease', 'Protocols documentation', 'Quality of life', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scoring Method', 'Solid Neoplasm', 'Specimen', 'Stable Disease', 'Staging', 'Stereotyping', 'Techniques', 'Time', 'Trees', 'base', 'forest', 'functional status', 'heuristics', 'indexing', 'liver biopsy', 'malignant breast neoplasm', 'novel', 'partial response', 'preference', 'programs', 'response', 'simulation', 'social', 'software development', 'tool', 'tumor']",NLM,VIRGINIA COMMONWEALTH UNIVERSITY,R01,2012,255679,-0.024074484038140883
"Machine-Learning Approach to Label-free Detection of new Bacterial Pathogens DESCRIPTION (provided by applicant): We appreciate the time and effort spent by all the reviewers, and we are grateful for the useful comments and provided suggestions. We have carefully reviewed the critiques and we are happy to see that the panel was receptive to our proposal. The reviewers expressed three major concerns in the summary statement: (1) although the investigating team is well qualified our history of collaboration is short; (2) details regarding the practical constraints of the BARDOT system are lacking; (3) the machine learning techniques employed in the project are considered fairly standard.  Below we briefly discuss the reviewers comments and indicate how we have changed our revised application to address the critique.  (1) Dr. Dundar moved from industry to academia in the fall of 2008, at which point Dr. Rajwa (one of the original inventors of BARDOT) and Dr. Dundar began their collaboration on new approaches to the problem of non-exhaustively defined classes in phenotypic screening. This scientific partnership immediately produced interesting results, and at the time of submission of the original application, Dr. Dundar and Dr. Rajwa had their first manuscript under review. The approach presented in the original proposal was tested and the results were submitted to the ACM 15th Annual SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'09), which is the largest and one of the most respected conferences in this field. The manuscript was accepted after a full peer review as one of the 50 regular papers selected from 551 submissions [20]. Following the proposal submission, research efforts continued and produced yet another approach to the problem described in this grant application. The preliminary findings are reported in a new manuscript which is currently under review [4].  (2) We rewrote the background and research methods sections of our proposal to include information re- quested by the reviewers regarding practical aspects of the BARDOT system, such as accuracy issues (Section D.3.2), frequency of encountering new, unknown classes (Section B.3.1), and validation (Section D.3.1).  (3) The problem of phenotypic screening and classification of bacteria can be defined within exhaustive (stan- dard) or non-exhaustive learning frameworks. Although we agree that the implementation of an exhaustive clas- sification approach for BARDOT does require only fairly standard tools, the problem of the non-exhaustive nature of training libraries cannot be addressed by straightforward use of any textbook-level technique. In fact, the presence of non-exhaustively defined set of classes violates basic assumptions for most supervised learning systems. The issue of non-exhaustively defined classes is the major obstacle for application of machine learning in phenotypic analysis since the number of possible phenotypes may be infinite. In our original proposal we argued that learning with a non-exhaustively defined set of classes remains a very challenging problem, and presented evidence demonstrating that simple extensions of standard techniques cannot provide an acceptable solution. Subsequently, we proposed a new approach based on Bayesian simulation of classes and showed that preliminary results outperformed benchmark techniques [4].  Although these initial results looked promising, we did not consider the described preliminary algorithms final and definitive, and we do not believe that at this point we are able to provide an exact algorithmic solution to this complex problem. If we were able to do that, it would mean that we had already accomplished all the grant goals. The very essence of the proposed research is finding the answer to the defined problem, and the answer will remain unknown until after the work has been done. However, positive reviews and an acceptance of our work by KDD'09 conference judges, tell us that we are heading in the right direction.  In the amended version of this application we propose a modified Bayesian approach based on Wishart priors (Section D.2.3). The algorithm creates new classes on the fly and evaluates maximum likelihood with the updated set of classes, gradually improving detection accuracy for future samples. We believe that this offers a substantial improvement over the previous method. Consequently, the preliminary results in Section C are updated to reflect our progress. Since the modified technique allows for classification with non-exhaustive and exhaustive sets using the same algorithm, we consolidated the previous specific aims 3 and 5 into one in the revised application. PUBLIC HEALTH RELEVANCE: A Machine Learning Approach to Label-free Detection of Bacterial Pathogens using Laser Light Scattering PIs: Dr. M. Murat Dundar and Dr. Bartek Rajwa Successful implementation of this project will allow for a label-free detection and identification of food pathogens and their mutated subclasses not yet seen earlier. This will reduce the number of food related outbreaks and will help secure public food supply.",Machine-Learning Approach to Label-free Detection of new Bacterial Pathogens,8070004,R21AI085531,"['Academia', 'Accounting', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Bacteria', 'Benchmarking', 'Biochemical Process', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Classification', 'Collaborations', 'Complex', 'Computer Vision Systems', 'Critiques', 'Data Set', 'Detection', 'Disease', 'Disease Outbreaks', 'Escherichia coli', 'Food', 'Food Supply', 'Frequencies', 'Future', 'Genus staphylococcus', 'Goals', 'Grant', 'Head', 'Health', 'Industry', 'Infection', 'International', 'Knowledge Discovery', 'Label', 'Lasers', 'Learning', 'Libraries', 'Listeria', 'Machine Learning', 'Manuscripts', 'Medical', 'Methods', 'Modeling', 'Mutate', 'Mutation', 'Nature', 'Optics', 'Paper', 'Pathogenicity', 'Pattern', 'Pattern Recognition', 'Peer Review', 'Phenotype', 'Process', 'Productivity', 'Public Health', 'Published Comment', 'Qualifying', 'Reagent', 'Recording of previous events', 'Reporting', 'Research', 'Research Methodology', 'Safety', 'Salmonella', 'Sampling', 'Screening procedure', 'Secure', 'Serotyping', 'Solutions', 'Suggestion', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Textbooks', 'Time', 'Training', 'Update', 'Validation', 'Vibrio', 'Work', 'base', 'cost', 'data mining', 'disorder prevention', 'falls', 'foodborne', 'foodborne pathogen', 'image processing', 'improved', 'interest', 'light scattering', 'new technology', 'novel strategies', 'optical sensor', 'pathogen', 'pathogenic bacteria', 'rapid detection', 'sensor', 'simulation', 'symposium', 'text searching', 'tool']",NIAID,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R21,2011,147939,-0.010325954427050234
"Machine Learning Tools for Prognostication in Melanoma    DESCRIPTION (provided by applicant): The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.  Cutaneous melanoma is the sixth most common cancer in the United States, and its incidence rate is increasing faster than any other cancer. Nearly 69,000 new cases are expected be diagnosed in this country in 2010. While thin melanomas are typically cured with excision alone, thicker melanomas have a greater tendency to metastasize to the regional lymph nodes.  A diagnosis of Stage III melanoma is made if there is spread to the regional lymph nodes. Unfortunately, there is marked diversity in the natural history of Stage III melanoma, and outcomes within this group are extremely heterogeneous, with 5- year survival rates ranging from 23% to 87%. Similarly, treatment options range from intensive forms of systemic therapy to observation. Understanding patients' differences in clinical outcome is critical not only for calibrating therapeutic intensity to metastatic risk but also in the design and analysis of clinical trials.  There is a real void of reliable prognostic tools for Stage III melanoma. Based on novel machine learning approaches, the purpose of this study will be to develop and validate a reliable and individualized tool for prognostication of Stage III melanoma patients that can be used in the clinical setting.      PUBLIC HEALTH RELEVANCE: The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.           The purpose of the study is to develop and validate a tool for reliable individualized prognostication of Stage III melanoma patients for use in the clinical setting.         ",Machine Learning Tools for Prognostication in Melanoma,8114413,R21CA152775,"['Address', 'American Joint Committee on Cancer', 'Cancer Prognosis', 'Classification', 'Clinical', 'Clinical Trials', 'Complex', 'Country', 'Cutaneous Melanoma', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Pathway', 'Dose', 'Evaluation', 'Excision', 'Heterogeneity', 'Incidence', 'Individual', 'Interferons', 'Logic', 'Lymph Node Dissections', 'Machine Learning', 'Malignant Neoplasms', 'Metastatic to', 'Methodology', 'Methods', 'Michigan', 'Modeling', 'Multivariate Analysis', 'Natural History', 'Neoplasm Metastasis', 'Nodal', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Proportional Hazards Models', 'Publications', 'Reporting', 'Risk', 'Sentinel Lymph Node Biopsy', 'Staging', 'Statistical Methods', 'Subgroup', 'Survival Rate', 'Systemic Therapy', 'Therapeutic', 'Thick', 'Trees', 'United States', 'Universities', 'Validation', 'advanced disease', 'base', 'cancer risk', 'clinical decision-making', 'design', 'editorial', 'flexibility', 'forest', 'hazard', 'lymph nodes', 'melanoma', 'minimally invasive', 'novel', 'outcome forecast', 'prognostic', 'tool']",NCI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R21,2011,193798,-0.031607581402283515
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.          PROJECT NARRATIVE:  There is a considerable need for improved educational software for mathematics in general, but the problem of  quality educational software materials for the blind and visually impaired is particularly acute. A weak  mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or  even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of  science, technology, engineering and mathematics. Through previous federally-supported research, Quantum  Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI)  tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power  and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,8055353,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Health', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2011,394165,-0.016835232443886648
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.           Project Narrative The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.",Scalable Learning with Ensemble Techniques and Parallel Computing,8045486,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Biological Sciences', 'Biomedical Research', 'Classification', 'Communication', 'Communities', 'Community Financing', 'Companions', 'Complex', 'Computer software', 'Consult', 'Crowding', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Health', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'new technology', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2011,374673,-0.024204796259999647
"Optimizing Peripheral Nerve Regeneration using Computational Intelligence based T    DESCRIPTION (provided by applicant):  Peripheral nerve injuries are common diseases that affect a large amount of patients every year.  Tissue engineering has emerged as a powerful approach for developing alternative nerve grafts for peripheral nerve regeneration.  Since tissue engineering strategies in peripheral nerve regeneration involve various possible combinations of variables, it is necessary to develop efficient tools to identify optimal tissue engineering strategies and predict the experimental results based on these tissue engineering strategies for peripheral nerve regeneration.  Some research groups have applied artificial neural networks and decision trees to obtain the best model configuration for the prediction of the tissue engineering strategies.  For the decision trees based methods, it is hard to tell which classification tree is better than the other.  Furthermore, the prediction system using the decision tree algorithm lacks the capability of accumulating the learning experience over time.  On the other hand, Artificial Neural Networks (ANNs) exhibit some remarkable properties, but only the connection weights are trained with fixed topology.  It is hard to find the best fixed topology in advance for each specific tissue engineering strategy.  In this proposal, swarm intelligence (SI) based evolving ANNs technique is proposed to tackle this challenge.  Two swarm intelligence based methods, Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO), will be applied in this project to train the ANN model.  More specifically, ACO will be used to optimize the topology structure of the ANN models, while the PSO is used to adjust the connection weights of the ANN models based on the optimized topology structure.  For this SWarm Intelligence based Reinforcement Learning method for ANNs (SWIRL-ANN) system, both topology and connection weight of artificial neural networks can be evolved automatically and simultaneously so that an optimal classifier for tissue engineering strategies in peripheral nerve regeneration can be achieved.  The research project will include the following phases:  Aim 1:  Predict tissue engineering strategies in peripheral nerve regeneration using SWarm Intelligence based Reinforcement Learning method for ANNs (SWIRL-ANN) analytical and prediction system.  Aim 2:  Validate the efficacy of novel unknown tissue engineered nerve grafts as predicted by using SWIRL-ANN based analytical and prediction system for bridging peripheral nerve gaps in rat sciatic nerve injury model in vivo.      PUBLIC HEALTH RELEVANCE:  Tissue engineering has emerged as a powerful approach for developing nerve grafts for peripheral nerve regeneration.  Since tissue engineering strategies in peripheral nerve regeneration involve various possible combinations of variables, it is necessary to develop efficient tools to identify optimal tissue engineering strategies and predict the experimental results based on these tissue engineering strategies for peripheral nerve regeneration.  In this proposal, swarm intelligence (SI) based evolving artificial neural networks (ANNs) technique is proposed to tackle this challenge.  The proposed research will be helpful to efficiently develop tissue engineered products for tissue and organ replacement.               Tissue engineering has emerged as a powerful approach for developing nerve grafts for peripheral nerve regeneration.  Since tissue engineering strategies in peripheral nerve regeneration involve various possible combinations of variables, it is necessary to develop efficient tools to identify optimal tissue engineering strategies and predict the experimental results based on these tissue engineering strategies for peripheral nerve regeneration.  In this proposal, swarm intelligence (SI) based evolving artificial neural networks (ANNs) technique is proposed to tackle this challenge.  The proposed research will be helpful to efficiently develop tissue engineered products for tissue and organ replacement.            ",Optimizing Peripheral Nerve Regeneration using Computational Intelligence based T,8232817,R15NS074404,"['Advanced Development', 'Affect', 'Algorithms', 'Animal Experiments', 'Animals', 'Ants', 'Area', 'Artificial Intelligence', 'Autologous Transplantation', 'Biocompatible Materials', 'Biological', 'Biological Neural Networks', 'Biomedical Research', 'Breathing', 'Cells', 'Characteristics', 'Classification', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Defect', 'Disease', 'Exhibits', 'Foundations', 'Future', 'Generic Drugs', 'Individual', 'Insecta', 'Intelligence', 'Knowledge', 'Learning', 'Maps', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Nerve', 'Nerve Regeneration', 'Network-based', 'Neural Network Simulation', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Pattern', 'Perception', 'Peripheral Nerves', 'Peripheral nerve injury', 'Phase', 'Physicians', 'Process', 'Property', 'Psychological reinforcement', 'Rattus', 'Research', 'Research Personnel', 'Research Project Grants', 'Sampling', 'Social Behavior', 'Structure', 'Surgical incisions', 'System', 'Techniques', 'Time', 'Tissue Engineering', 'Tissues', 'Training', 'Treatment Protocols', 'Trees', 'Vertebrates', 'Weight', 'Work', 'base', 'experience', 'in vivo', 'in vivo Model', 'insight', 'nerve gap', 'nerve injury', 'novel', 'particle', 'relating to nervous system', 'sciatic nerve', 'social', 'tool', 'vector']",NINDS,STEVENS INSTITUTE OF TECHNOLOGY,R15,2011,423840,-0.010383008186969857
"A New Approach to Compute PM2.5 for Health Impact Analysis    DESCRIPTION (provided by applicant): Environmental air quality impacts human well-being and disease, but the availability of air quality data is limited to selected locations because of the complexity involved in its measurement. Among air pollutants, PM2.5 is of the greatest concern. These particles are not captured by the lungs' natural defenses and can be inhaled deeply, where they can cause health problems ranging from asthma attacks to heart disease.  PM2.5 currently is measured primarily by ground monitoring stations located at approximately 320 EPA sites, providing limited local geographic coverage. However, there are satellites that make a variety of aerosol observations and provide a daily global picture of atmospheric particulates in the form of aerosol optical depth (AOD). Scientists have attempted to compute ground-level PM2.5 (GLP) from these AOD data. However, the multivariate nonlinear relationship between AOD and PM2.5 imposes limitations in computing GLP using satellite data. This project proposes to overcome these limitations by computing reliable GLP via a new methodology which has already been tested and validated.  The study has two specific aims: (1) develop satellite-derived daily GLP estimates for the contiguous U.S., and (2) examine spatial and temporal associations between GLP exposure and hospital visits for asthma exacerbation in Mississippi. Using our methodology, we will generate daily GLP data for a 12-month period at a resolution of 0.10x0.10 (~10x10km2), providing approximately 82,000 data points as opposed to about 300 data points available daily from EPA ground monitoring stations within the contiguous U.S. We will address the nonlinear relationship between PM2.5 and AOD which is a function of humidity, temperature, surface pressure, surface wind speed, surface type, boundary layer height, and AOD by accounting for these variables using a machine learning process. The AOD that will be used in this process will be generated by merging AOD data from multiple satellite sensors. Meteorological data will come from NOAA NCEP. Surface type data will be obtained from the satellite-identified vegetation index. Boundary layer height, which is the mixed layer of the atmosphere closest to the ground where people live and work, will come from CALIPSO data which provides vertical profiles of atmospheric aerosol extinction.  Information on GLP levels will allow the scientific community to better understand health impacts from exposure to low, moderate, or high levels of PM2.5. Moreover, in places where PM2.5 levels are elevated only occasionally, such as Mississippi, the short-term health impact of increases in PM2.5 can be studied more precisely. National GLP data will be made available to other researchers to facilitate future explorations of how PM2.5 exposure impacts a wide range of health conditions, thereby making possible more timely prophylactic treatment, improving healthcare system preparedness, and better informing public health policymaking.      PUBLIC HEALTH RELEVANCE:   Among air pollutants, particulates 2.5 micrometers in diameter and smaller (PM2.5) have the greatest impact on human health because they are small enough to be inhaled deeply into the lungs, making allergies, asthma, and other respiratory conditions worse. The proposed study will provide daily estimates of ground-level PM2.5 for the entire contiguous U.S. so that researchers can study how it affects disease at various locations in the country. The knowledge that results can be used to better inform people about the links between air pollution and disease, and to guide the development of air quality standards to improve public health.                Among air pollutants, particulates 2.5 micrometers in diameter and smaller (PM2.5) have the greatest impact on human health because they are small enough to be inhaled deeply into the lungs, making allergies, asthma, and other respiratory conditions worse. The proposed study will provide daily estimates of ground-level PM2.5 for the entire contiguous U.S. so that researchers can study how it affects disease at various locations in the country. The knowledge that results can be used to better inform people about the links between air pollution and disease, and to guide the development of air quality standards to improve public health.            ",A New Approach to Compute PM2.5 for Health Impact Analysis,8191561,R21ES019713,"['Accounting', 'Address', 'Admission activity', 'Aerosols', 'Affect', 'Air', 'Air Pollutants', 'Air Pollution', 'Area', 'Artificial Intelligence', 'Asthma', 'Birth Rate', 'Breathing', 'Caliber', 'Cardiovascular Diseases', 'Chronic Obstructive Airway Disease', 'Communities', 'Country', 'Data', 'Data Quality', 'Data Sources', 'Development', 'Disease', 'Emergency Medicine', 'Environmental Wind', 'Epidemiology', 'Exposure to', 'Extinction (Psychology)', 'Future', 'Goals', 'Health', 'Healthcare Systems', 'Heart Diseases', 'Height', 'Hospitals', 'Human', 'Humidity', 'Hypersensitivity', 'Life', 'Link', 'Location', 'Lung', 'Machine Learning', 'Malignant neoplasm of lung', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Mississippi', 'Modeling', 'Monitor', 'National Institute of Environmental Health Sciences', 'Optics', 'Particulate', 'Particulate Matter', 'Personal Satisfaction', 'Process', 'Property', 'Prophylactic treatment', 'Proxy', 'Public Health', 'Readiness', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Scientist', 'Site', 'Source', 'Speed', 'Surface', 'Surveillance Program', 'System', 'Techniques', 'Temperature', 'Testing', 'Time', 'United States National Aeronautics and Space Administration', 'Variant', 'Visit', 'Work', 'base', 'burden of illness', 'design', 'hazard', 'improved', 'indexing', 'interest', 'knowledge of results', 'novel', 'novel strategies', 'particle', 'planetary Atmosphere', 'pressure', 'prototype', 'respiratory', 'sensor', 'statistics', 'web based interface']",NIEHS,UNIVERSITY OF MISSISSIPPI MED CTR,R21,2011,219458,-0.10973622423886503
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,8062031,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Dimensions', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Health', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2011,359403,-0.018900775503569247
"High-Throughput Computing for a Multi-Plan Framework in Radiotherapy    DESCRIPTION (provided by applicant):    Computerized planning for radiation delivery via either external beam radiation therapy (EBRT) or intensity- modulated radiation therapy (IMRT) from linear accelerators is a complex process involving a large amount of input data and vast numbers of decision variables. Such large-scale combinatorial optimization problems are typically intractable for conventional approaches such as the direct application of the best available commercial algorithms, and thus specialized methods that take advantage of problem structure are required. Radiation treatment planning (RTP) problems are further complicated by the fact that they are multi-objective, that is, the RTP optimization process must take into account a trade-off between the competing goals of delivering appropriate doses to the tumor and avoiding the delivery of harmful radiation to nearby healthy organs. The goal of this proposal is to harness distributive computing via the Condor system for High Throughput Computing (HTC) within an RTP environment. The specific aims for this proposal are: 1) To develop a Nested Partitions (NP) framework that guides a global search process for optimal IMRT delivery parameters using HTC. 2) To develop parallel HTC-based linear programming (LP) methods to efficiently solve the dose optimization problem in IMRT for each given set of beam angles or beam apertures. (3) To exploit a high-throughput computing (HTC) environment and the developed NP/LP/segmentation framework to efficiently generate multiple plans for each given patient case. (4) To couple this multi-plan framework with a decision support system (DSS) that includes planning surface models, a graphical-user-interface (GUI) and machine learning tools to prediction OAR complication in order to aid in the ranking and selection of the generated treatment plans. This proposal requires a multi-disciplinary approach that is best conducted within the framework of the Innovations in Biomedical Computational Science and Technology program announcement. It brings together an interdisciplinary team of investigators with expertise in medical physics, mathematical programming, industrial engineering and clinical radiation oncology that is crucial to the development of the proposed multi- plan framework using HTC in radiation therapy. PUBLIC HEALTH RELEVANCE: The goal of this proposal is to develop a multi-dimensional platform for sophisticated treatment planning of radiation delivery. It will develop novel algorithms that will enable generation of superior treatment plans with the added advantage of increasing the speed of treatment planning. Further, it will allow physicians to know beforehand the quality of the treatment plan relative to the multiple treatment objectives and be able to determine the treatment complication scenario beforehand.           PROJECT NARRATIVE The goal of this proposal is to develop a multi-dimensional platform for sophisticated treatment planning of radiation delivery. It will develop novel algorithms that will enable generation of superior treatment plans with the added advantage of increasing the speed of treatment planning. Further, it will allow physicians to know beforehand the quality of the treatment plan relative to the multiple treatment objectives and be able to determine the treatment complication scenario beforehand.",High-Throughput Computing for a Multi-Plan Framework in Radiotherapy,8077861,R01CA130814,"['Accounting', 'Algorithms', 'Behavior', 'Clinical Engineering', 'Collection', 'Complex', 'Complication', 'Computational Science', 'Data', 'Decision Support Systems', 'Dependence', 'Development', 'Dose', 'Engineering', 'Environment', 'External Beam Radiation Therapy', 'Generations', 'Genetic Programming', 'Goals', 'Health', 'Intensity-Modulated Radiotherapy', 'Knowledge', 'Lead', 'Linear Accelerator Radiotherapy Systems', 'Linear Programming', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Modeling', 'Monte Carlo Method', 'NIH Program Announcements', 'Organ', 'Patients', 'Physicians', 'Physics', 'Process', 'Property', 'Radiation', 'Radiation Oncology', 'Radiation therapy', 'Relative (related person)', 'Research Personnel', 'Risk', 'Sampling', 'Shapes', 'Simulate', 'Solutions', 'Speed', 'Structure', 'Surface', 'System', 'Technology', 'Time', 'Toxic effect', 'base', 'cluster computing', 'combinatorial', 'computer science', 'computerized', 'computing resources', 'direct application', 'graphical user interface', 'heuristics', 'improved', 'innovation', 'insight', 'novel', 'novel strategies', 'predictive modeling', 'process optimization', 'programs', 'research clinical testing', 'tool', 'treatment planning', 'tumor']",NCI,UNIVERSITY OF MARYLAND BALTIMORE,R01,2011,297451,-0.034234854755252044
"Neurointensive Care and Assessment Facility    DESCRIPTION (provided by applicant): The overall goal of this G20 proposal is to create a shared Neurointensive Care and Assessment Facility (NCAF) to study acute and long-term responses in large animal models of disease and injury to enable the development and translation of new treatments and technologies that promote and preserve neurological function. This revised proposal responds specifically and substantively to each comment raised in the initial review. The NCAF will be a one-of-a-kind shared porcine facility for the study of neurological injury and recovery after stroke, cardiac arrest, cardiopulmonary bypass, and traumatic brain injury in pigs/piglets d 25kg. The facility will consist of 5 components: (1) a non-sterile procedure room for closed head injuries and terminal procedures, (2) an intensive care housing room, (3) a cognitive and behavioral assessment laboratory, (4) a survival surgical room, and (5) animal prep area. Facilities will be upgraded to allow survival surgery on USDA-regulated species and meet requirements of the Guide for the Care and Use of Laboratory Animals (ILAR, 1996; pre-publication, 2010), and provide a state-of-the art intensive care unit for monitoring and housing animals. Additional space will be renovated to serve as procedural space for cognitive and behavioral assessment using a battery of porcine-specific tests developed by the Facility Director. Finally, the NCAF facility will be upgraded to meet federal and other regulatory requirements that ensure safety, sanitization, security, vermin control and environmental control for surgery, experimental procedure, intensive care housing and behavioral study areas. The NCAF will be used for the study of more than 800 piglets/pigs per year, and will be shared by 25 investigators spanning the School of Medicine (SOM) and School of Engineering and Applied Science (SEAS) with over $42, million in current and pending funding. Moreover, this new facility will be a unique opportunity to create synergy between SOM faculty investigating cell and molecular approaches to therapeutic interventions that preserve neurofunction, with SEAS faculty who are innovators in device development, data integration, data processing, machine learning, biosensors and minimally invasive surgical technology. Thus, these renovations will enhance PHS-funded research, will advance the conduct of animal welfare in experimental research, and will positively impact the scope and pace of the preclinical research at Penn.          n/a",Neurointensive Care and Assessment Facility,8188836,G20RR029785,"['Acute', 'Animal Disease Models', 'Animal Housing', 'Animal Welfare', 'Animals', 'Applied Research', 'Area', 'Behavior assessment', 'Behavioral', 'Biosensor', 'Cardiopulmonary Bypass', 'Caring', 'Cells', 'Closed head injuries', 'Cognitive', 'Development', 'Device or Instrument Development', 'Engineering', 'Ensure', 'Faculty', 'Family suidae', 'Funding', 'Goals', 'Heart Arrest', 'Housing', 'Injury', 'Intensive Care', 'Intensive Care Units', 'Laboratories', 'Machine Learning', 'Molecular', 'Monitor', 'Nervous System Physiology', 'Nervous System Trauma', 'Operative Surgical Procedures', 'Procedures', 'Publications', 'Published Comment', 'Research', 'Research Personnel', 'Safety', 'Schools', 'Security', 'Stroke', 'Technology', 'Testing', 'Therapeutic Intervention', 'Translations', 'Traumatic Brain Injury', 'computerized data processing', 'data integration', 'guide for the care and use of laboratory animals', 'medical schools', 'meetings', 'minimally invasive', 'neurological recovery', 'pre-clinical research', 'research study', 'response']",NCRR,UNIVERSITY OF PENNSYLVANIA,G20,2011,500000,-0.03177282928448034
"Position Sensitive P-Mer Frequency Clustering with Applications to Classification    DESCRIPTION (provided by applicant):    Position Sensitive P-Mer Frequency Clustering with  Applications to Classification and Differentiation Recent genomic sequencing advances, such as next generation sequencing, and projects like the Human Microbiome Project create extremely large genomic databases. Even though the length of any specific sequence may be much shorter than that of the complete DNA sequence of an organism, looking at enormous libraries of sequences, such as 16S rRNA, presents an equally (if not greater) computational challenge. In traditional genomic analysis, only one sequence may be analyzed at a time. When dealing with metagenomics, thousands (or more) sequences need to be analyzed at the same time. However, to study such problems as environmental biological diversity and human microbiome diversity this is exactly what is needed. Current techniques have several shortcomings which need to be addressed. Techniques involving sequence alignment are typically based on selection of one representative sequence (as is typically done when looking at 16S rRNA data) which introduces selection bias. Genomic databases involving multiple copies of 16S per organism across thousands of organisms, will soon grow too large to practically process just using computationally expensive alignment methods to match sequences, but faster alignment-free methods currently do not provide the needed accuracy and sensitivity. As a complement to existing methods we introduce a novel class of fast high-throughput algorithms based on quasi-alignment using position specific p-mer frequency clustering. Organisms are represented by a directed graph structure that summarizes the ordering between clusters of p-mer frequency histograms at different positions in sequences. This model can be learned using all available 16S copies of an organism and thus eliminates selection bias. Due to the added position information, these algorithms can be used for species (and even strain) classification facilitating the study of strain diversity within species. Our prototype implementation of this new technique shows that it is able to produce compact profiles which can be efficiently stored and used for large scale classification and differentiation down to the strain level. Since the technique incorporates high-throughput data stream clustering, a proven technique in high performance computing, it scales well for very large scale DNA/RNA sequence data as well as massive sets of short sequence snippets collected during metagenomic research. In this project we will develop a suite of tools, profile models, and scoring techniques to model RNA/DNA sequences providing applications of organism classification, and intra/inter-organism similarity/diversity. Our approach provides both the specificity needed to perform strain classification and still avoid the computational overhead of alignment. It is important to note that this is accomplished through dynamic online machine learning techniques without human intervention.      PUBLIC HEALTH RELEVANCE:    Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.                 Recent advances in Metagenomics and the Human Microbiome provide a complex landscape for dealing with a multitude of genomes all at once. One of the many challenges in this field is classification of the genomes present in the sample. Effective metagenomic classification and diversity analysis require complex representations of taxa. The significance of our research is that we develop a suite of tools, based on novel alignment free techniques that will be applied to environmental metagenomics samples as well as human microbiome samples. Providing such methods to rapidly classify organisms using our new approach on a laptop computer instead of several multi-processor servers will facilitate the rapid development of microbiome-based health screening in the near future.            ",Position Sensitive P-Mer Frequency Clustering with Applications to Classification,8192895,R21HG005912,"['Address', 'Algorithms', 'Biodiversity', 'Classification', 'Complement', 'Complex', 'Computational Technique', 'Computers', 'DNA', 'DNA Sequence', 'Data', 'Databases', 'Development', 'Effectiveness', 'Family', 'Frequencies', 'Future', 'Genome', 'Genomics', 'Grant', 'Graph', 'Habitats', 'Health', 'High Performance Computing', 'Human', 'Human Microbiome', 'Intervention', 'Lead', 'Learning', 'Length', 'Libraries', 'Link', 'Machine Learning', 'Metagenomics', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Organism', 'Positioning Attribute', 'Probability', 'Process', 'Property', 'RNA', 'RNA Sequences', 'Research', 'Ribosomal RNA', 'Sampling', 'Screening procedure', 'Selection Bias', 'Sequence Alignment', 'Sequence Analysis', 'Specificity', 'Stream', 'Structure', 'Taxon', 'Techniques', 'Testing', 'Time', 'Update', 'Work', 'base', 'computing resources', 'cost', 'improved', 'laptop', 'microbial', 'microbiome', 'next generation', 'novel', 'novel strategies', 'prototype', 'research study', 'statistics', 'success', 'tool', 'user-friendly', 'web site']",NHGRI,SOUTHERN METHODIST UNIVERSITY,R21,2011,180669,-0.04015742493878172
"Rational design of cytokine releasing angiogenic constructs    DESCRIPTION (provided by applicant): The development of organized vascular networks necessitates a tightly regulated interplay between variable cells, growth factors and soluble mediators. The applicant's long-term goal is to develop therapeutic angiogenic strategies based on the rational design of cytokine releasing constructs that promote vascular patterning and vessel stability. The objective of this proposal is to i) develop electrospun, three-dimensional constructs with patterned architecture, ii) demonstrate that the spatial and temporal delivery of two model angiogenic growth factors promotes the formation of an organized capillary network and iii) develop a computational model that can predict the biological effect of a growth factor releasing construct as a function of specified fabrication parameters. We hypothesize that guided therapeutic angiogenesis (i.e. patterned vascular networks) can be obtained by controlling the spatial and temporal presentation of soluble mediators at the site of ischemia. In AIM I, we will synthesize bFGF and G-CSF releasing electrospun constructs and determine their programmed delivery as a function of fabrication parameters. In AIM II, we will demonstrate the effect of spatial and temporal control of cytokine delivery in promoting directed angiogenesis in a three-dimensional in vitro angiogenesis model and we will develop a computational model/software that can predict the biological effect of different scaffold configurations. We will validate our model by assessing the angiogenic potential of our growth factor releasing constructs in a murine critical limb ischemic model.      PUBLIC HEALTH RELEVANCE: We are proposing to a) fabricate a growth factor releasing construct that regulates the spatio- temporal delivery of angiogenic cytokines and promotes the formation of organized capillary networks and b) develop a machine learning computational model that can predict the angiogenic potential of our construct as a function of fabrication parameters.           Project narrative We are proposing to a) fabricate a growth factor releasing construct that regulates the spatio- temporal delivery of angiogenic cytokines and promotes the formation of organized capillary networks and b) develop a machine learning computational model that can predict the angiogenic potential of our construct as a function of fabrication parameters.",Rational design of cytokine releasing angiogenic constructs,8112574,R21EB012136,"['Animal Model', 'Animals', 'Architecture', 'Biological', 'Blood Vessels', 'Blood capillaries', 'CSF3 gene', 'Cell Proliferation', 'Cell Transplantation', 'Clinical', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Fiber', 'Fibroblast Growth Factor 2', 'Gelatin', 'Goals', 'Growth', 'Growth Factor', 'In Vitro', 'Ischemia', 'Kinetics', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Mediator of activation protein', 'Modeling', 'Mus', 'Natural regeneration', 'Needles', 'Operative Surgical Procedures', 'Output', 'Pattern', 'Pharmacotherapy', 'Polymers', 'Process', 'Research', 'Series', 'Site', 'Specific qualifier value', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Effect', 'Tissue Engineering', 'angiogenesis', 'base', 'capillary', 'cell growth', 'cell motility', 'cytokine', 'design', 'electric field', 'high risk', 'interest', 'mathematical model', 'minimally invasive', 'multitask', 'nanofiber', 'novel', 'pre-clinical', 'programs', 'public health relevance', 'repaired', 'scaffold', 'spatiotemporal', 'success', 'therapeutic angiogenesis', 'tissue regeneration']",NIBIB,UNIVERSITY OF MIAMI CORAL GABLES,R21,2011,176524,-0.013425534797139775
"Automated Web-Based Behavioral Diagnostics of Cognitive Impairment    DESCRIPTION (provided by applicant): Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based method for early diagnosis of cognitive decline and memory loss. We will build on current research that has demonstrated a clear link between performance on the Visual Paired- Comparison Task (VPC) and diagnosis of MCI, and we will extend the impact of this finding by developing a suite of software tools and analysis methods that will improve the accuracy and extend the accessibility of cognitive diagnostics with a web-based VPC task that can be widely deployed. Although the VPC task is promising as a diagnostic aid, clinical application is severely limited by the need to use an eye tracker to precisely monitor subjects' eye movements. Unfortunately, eye trackers are expensive, require trained personnel, and are not widely available. However, our preliminary findings show that it is possible to produce picture examination behavior that is similar to eye-movements, using modified versions of the VPC task that could be administered by anyone, on any computer with an internet connection. In addition, powerful machine learning techniques from computer science can help accurately analyze and diagnose the resulting behavior. An important contribution from this work will be the possibility of predicting oncoming cognitive decline in MCI patients sooner than is now possible, that is, at a time when the nervous system is less compromised and more likely to benefit from therapeutic intervention. In support of this objective, we propose three aims: 1) Develop and investigate appropriate representation of eye movement characteristics and corresponding machine learning-based classification techniques for effective identification of the patient status, 2) Develop and validate a web-based version of the VPC task, and 3) explore the feasibility of our task as an automatic screening instrument for the general elderly population. Successful completion of these aims has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable thousands and potentially millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.      PUBLIC HEALTH RELEVANCE: Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.           Alzheimer's disease affects an estimated 5.3 million Americans currently, and this number is expected to grow significantly in the coming decade. A critical goal of Alzheimer's disease research is to improve current methods of diagnosis so that patients can be identified sooner and, therefore, obtain greater advantage from available therapies. The major goal of this project is to develop and validate an automated, web-based, and widely accessible behavioral screening test for early diagnosis of cognitive decline and memory loss. Successful completion of this project has the potential to dramatically alter the current practice of clinical translational research as well as the current methods used for diagnosing cognitive deficits. This would enable millions of patients and potential research subjects to take the test as part of their routine checkup, requiring nothing more than a computer with an internet connection.         ",Automated Web-Based Behavioral Diagnostics of Cognitive Impairment,8116342,R01EB014266,"['Affect', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'American', 'Behavior', 'Behavioral', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Cognitive', 'Cognitive deficits', 'Computer software', 'Computers', 'Data', 'Dementia', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Elderly', 'Exhibits', 'Eye', 'Eye Movements', 'Future', 'General Practitioners', 'Goals', 'Human Resources', 'Image', 'Impaired cognition', 'Individual', 'Internet', 'Length', 'Link', 'Machine Learning', 'Measures', 'Memory', 'Memory Loss', 'Memory impairment', 'Methods', 'Monitor', 'Movement', 'Mus', 'Nervous system structure', 'Neurodegenerative Disorders', 'Online Systems', 'Paired Comparison', 'Patients', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Proxy', 'Recruitment Activity', 'Research', 'Research Subjects', 'Saccades', 'Screening procedure', 'Software Tools', 'Specificity', 'Stimulus', 'Structure', 'Supervision', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Translational Research', 'Visual', 'Work', 'aged', 'base', 'checkup examination', 'clinical application', 'clinical practice', 'cognitive neuroscience', 'computer science', 'cost', 'cost effective', 'gaze', 'improved', 'instrument', 'memory recognition', 'mild neurocognitive impairment', 'novel', 'older patient', 'preference', 'sample fixation', 'tool', 'tool development', 'visual adaptation']",NIBIB,EMORY UNIVERSITY,R01,2011,324000,-0.04078378027654962
"Hand Sensorimotor Function and Carpal Tunnel Syndrome    DESCRIPTION (provided by applicant): The median nerve is susceptible to compression in the wrist, leading to carpal tunnel syndrome (CTS). CTS is the most common compression neuropathy and have an immense impact on national health care, worker productivity, and quality of life. Despite its high prevalence and public health cost, our understanding of CTS is limited, and the management of CTS awaits improvement. The central notion of this project is that hand sensorimotor function is sensitive to peripheral median neuropathy and that the central nervous system is affected by CTS, causing the associated sensorimotor deficit. We will investigate this notion with quantifiable sensorimotor data from novel biomechanical and neurophysiological studies. This project has three aims consisting of biomechanical, neurophysiological and translational research. The first aim is to investigate CTS-induced pathokinematic and pathokinetic performance using dexterous manual tasks of thumb opposition, reach-to-pinch, precision grip, and finger pressing. The second aim is to investigate the neurophysiological implications of chronic peripheral neuropathy (i.e., CTS) on the central nervous system by evaluating corticomuscular coupling and stretch reflex. The third aim is to identify novel biomechanical and neurophysiological markers for CTS cases using machine learning and classification algorithms. The results of this project will elucidate the pathological mechanisms and behavioral manifestations of CTS and aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder. More generally, CTS as a chronic neuropathy serves as an effective model to study sensorimotor mechanisms of the peripheral and central nervous systems. In addition, the methodology developed in this project is applicable to other neuromuscular disorders.      PUBLIC HEALTH RELEVANCE:   Carpal tunnel syndrome is highly prevalent and costly. One of the distinct consequences of carpal tunnel syndrome is that patients experience inexplicable dropping of objects and clumsiness while performing simple daily tasks. In this project, we propose to study the sensorimotor deficit using novel biomechanical and neurophysiological experiments. The results of this project will elucidate the pathological mechanisms and manifestations of carpal tunnel syndrome. This project is clinically translational to aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder.                   Carpal tunnel syndrome is highly prevalent and costly. One of the distinct consequences of carpal tunnel syndrome is that patients experience inexplicable dropping of objects and clumsiness while performing simple daily tasks. In this project, we propose to study the sensorimotor deficit using novel biomechanical and neurophysiological experiments. The results of this project will elucidate the pathological mechanisms and manifestations of carpal tunnel syndrome. This project is clinically translational to aid in the development of new strategies for diagnosis, evaluation, rehabilitation, and treatment of this disorder.               ",Hand Sensorimotor Function and Carpal Tunnel Syndrome,8102684,R01AR056964,"['Abnormal coordination', 'Affect', 'Algorithms', 'Behavioral Mechanisms', 'Biomechanics', 'Carpal Tunnel Syndrome', 'Carpometacarpal joint structure', 'Chronic', 'Classification', 'Clinical', 'Coupling', 'Data', 'Development', 'Disease', 'Drops', 'Electroencephalography', 'Electromyography', 'Exertion', 'Eye', 'Fingers', 'Hand', 'Health Care Costs', 'Health Personnel', 'High Prevalence', 'Human', 'Individual', 'Joints', 'Lasso', 'Machine Learning', 'Manuals', 'Measures', 'Median Neuropathy', 'Metacarpophalangeal joint structure', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Cortex', 'Neural Conduction', 'Neuraxis', 'Neuromuscular Diseases', 'Neuropathy', 'Patients', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Production', 'Productivity', 'Pronation', 'Public Health', 'Quality of life', 'Questionnaires', 'Reaction', 'Rehabilitation therapy', 'Reproducibility', 'Research', 'Response Latencies', 'Sensorimotor functions', 'Sensory', 'Techniques', 'Testing', 'Thumb structure', 'Time', 'Translational Research', 'Trees', 'Validation', 'Wrist', 'data mining', 'diagnosis evaluation', 'experience', 'grasp', 'improved', 'indexing', 'median nerve', 'motor control', 'neurophysiology', 'novel', 'programs', 'research study', 'response', 'stretch reflex', 'tool', 'vector']",NIAMS,CLEVELAND CLINIC LERNER COM-CWRU,R01,2011,353250,-0.011818360810341298
"Reduced-Order Constrained Optimization for Rapid IMRT and VMAT Treatment Planning    DESCRIPTION (provided by applicant): Intensity-modulated radiotherapy (IMRT) has revolutionized the treatment of cancers in the last decade, since it can tightly conform and escalate radiation dose to a tumor while simultaneously protecting nearby radiation- sensitive normal tissues, resulting in better local control and fewer post-treatment complications than previous techniques. However, the process of obtaining a clinically acceptable IMRT plan for a difficult site is still extremely slow, requiring many hours of a busy expert's time in a manual trial-and-error loop of parameter adjustment. The goal of this project is to drastically reduce the amount of time to obtain a clinically acceptable IMRT plan using a new automated method that directly applies constrained optimization in a computationally tractable and clinically meaningful way. The hypothesis is that clinical treatment planning times using this technique will be reduced from several hours to a matter of minutes.  The new approach, called ROCO (Reduced-Order Constrained Optimization) translates well-established concepts from optimization and machine learning theory to the novel application of IMRT planning, exploiting the speed and ease of unconstrained optimizations and introducing a dimensionality reduction step that makes true constrained optimization tractable. The Specific Aims of the proposal are to (1) apply Reduced-Order Con- strained Optimization to IMRT planning for non-small cell lung cancers and nasopharynx cancers, where the planning process is highly time-consuming; (2) develop and extend the Reduced-Order Constrained Optimization paradigm to a promising IMRT variant called Volumetric Modulated Arc Therapy (VMAT) for the prostate site, which is currently nearly clinically intractable to plan; and (3) integrate the new tools into the clinical IMRT planning process at Memorial Sloan-Kettering Cancer Center, using a powered study to verify the hypothesis that the proposed method significantly improves planning speed. The experiments will be designed in consultation with an expert clinical treatment planner and biostatistician, and carefully validated using anonymized data from approximately 50 patients for each site.  The main benefit of the proposed approach is to drastically reduce planning times, which is critical if IMRT and VMAT are to reach their full potential in clinical application. In a busy clinic, long planning times place a severe stress on available resources, and can result in treatment delays, acceptance of sub-optimal plans or - in the worst case - errors due to time pressure. In the longer term, the proposed approach will provide deeper insight into the critical elements of the dose optimization problem, significantly reduce the trial-and-error effort characteristic of current IMRT planning, and reduce subjectivity in treatment plan selection.      PUBLIC HEALTH RELEVANCE: Intensity-modulated radiation therapy (IMRT) is an extremely promising cancer treatment, but currently requires many hours of an expert treatment planner's time to obtain a plan that meets all the clinical constraints specified by the physician. This proposal describes a new, automatic method for treatment plan optimization that is very fast, requiring only minutes to produce a plan that directly meets all the physician's constraints, potentially saving much time for a busy clinic.           Project Narrative Intensity-modulated radiation therapy (IMRT) is an extremely promising cancer treatment, but currently requires many hours of an expert treatment planner's time to obtain a plan that meets all the clinical constraints specified by the physician. This proposal describes a new, automatic method for treatment plan optimization that is very fast, requiring only minutes to produce a plan that directly meets all the physician's constraints, potentially saving much time for a busy clinic.",Reduced-Order Constrained Optimization for Rapid IMRT and VMAT Treatment Planning,8066714,R01CA148876,"['Acute', 'Address', 'Aftercare', 'Algorithms', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Treatment', 'Code', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'Consultations', 'Data', 'Development', 'Dose', 'Dose-Limiting', 'Drug Formulations', 'Effectiveness', 'Elements', 'Goals', 'Head and Neck Neoplasms', 'Head and neck structure', 'Hour', 'Housing', 'Human', 'Intensity-Modulated Radiotherapy', 'Journals', 'Linear Accelerator Radiotherapy Systems', 'Lung', 'Machine Learning', 'Malignant neoplasm of nasopharynx', 'Manuals', 'Measures', 'Medical', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Nasopharynx', 'Non-Small-Cell Lung Carcinoma', 'Normal tissue morphology', 'Organ', 'Paper', 'Parotid Gland', 'Patients', 'Phase', 'Physicians', 'Physics', 'Process', 'Prostate', 'Quality of life', 'Radiation', 'Radiation therapy', 'Resources', 'Risk', 'Sampling', 'Site', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Stress', 'Sum', 'System', 'Techniques', 'Technology', 'Time', 'To specify', 'Toxic effect', 'Translating', 'Variant', 'Weight', 'Xerostomia', 'base', 'cancer therapy', 'clinical application', 'clinical practice', 'design', 'experience', 'image processing', 'improved', 'insight', 'meetings', 'novel', 'novel strategies', 'pressure', 'process optimization', 'public health relevance', 'rectal', 'research study', 'symposium', 'theories', 'time use', 'tool', 'treatment planning', 'tumor']",NCI,RENSSELAER POLYTECHNIC INSTITUTE,R01,2011,250094,-0.03311628413920534
"Developing a Virtual Basic Laparoscopic Skill Trainer (VBLaST)    DESCRIPTION (provided by applicant):  Development and Validation of a Virtual Basic Laparoscopic Skill Trainer (VBLaST) For the first time in the history of surgical education, a comprehensive program to teach and evaluate the cognitive and psychomotor aspects unique to laparoscopic surgery - the Fundamentals of Laparoscopic Surgery (FLS) developed originally by the Society of American Gastrointestinal Endoscopic Surgery (SAGES) and subsequently by a joint committee which includes the American College of Surgeons (ACS) - is being embraced nationally for training and credentialing laparoscopic surgeons. As an example of its growing acceptance by the medical community, starting in 2009, the American Board of Surgeons has mandated that passing the FLS certifying examination will be required for taking the board examination in surgery. While the cognitive assessment in FLS is based on 75 multiple-choice questions, a proctored examination is used for the manual skills assessment which includes five tasks to be performed in a portable pelvic trainer box with built-in video camera: bimanual peg transfer, precise pattern cutting, use of ligating loops and suturing with intracorporeal and extracorporeal knot tying. In spite of the growing popularity of the FLS, there are several major problems with this box trainer paradigm: (1) the assessment is subjective, (2) there is no feedback during learning except when an experienced trainer is present, (3) a large number of qualified proctors must be engaged during test taking, (4) the training material must be constantly replaced, and (5) the test-takers must travel to one of the 27 Regional Test Centers or the Annual SAGES meeting or the ACS Clinical Congress. To overcome these problems and to enable greater dissemination, we propose to develop and validate a Virtual Basic Laparoscopic Skill Trainer (VBLaST) whereby tasks available in the FLS may be performed on PCs and laptops with inexpensive haptic (touch) interface devices, such as the Phantom(R) OmniTM. To develop the VBLaST a novel set of technologies must be developed including rapid, but highly realistic physics-based virtual interaction paradigms and statistical machine learning techniques to develop a ""virtual mentor"" which will provide real time automated feedback to the trainees. A comprehensive set of studies involving students, residents, fellows and practicing surgeons at Boston area hospitals (e.g., BIDMC, Tufts Medical Center, Cambridge Health Alliance, Harvard, MGH, Brigham & Women's, Lahey Clinic) will be undertaken to test the validity of the VBLaST as a training tool and establish its usefulness in transferring the acquired skills to the operating room. Once validated, the VBLaST will have exponential impact in reducing training costs and training time while improving patient safety and outcomes, A multidisciplinary team with collective expertise in physics-based interactive medical simulation, laparoscopic surgery and surgical education, and human factors engineering has been assembled to achieve the following Specific Aims: SA1) To develop a realistic virtual basic laparoscopic skill trainer (VBLaST) platform to perform all the tasks available in the FLS training tool box. SA2) To establish the validity of the VBLaST as a training tool. SA3) To evaluate the usefulness of the VBLaST as a training tool. SA4) To develop a web-based interface for the VBLaST.      PUBLIC HEALTH RELEVANCE: The goal of this research is to develop a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills and to take standardized tests on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.           Relevance: The goal of this research is to develop a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills and to take standardized tests on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.",Developing a Virtual Basic Laparoscopic Skill Trainer (VBLaST),8077223,R01EB010037,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'American', 'American College of Surgeons', 'Area', 'Attention', 'Auditory', 'Boston', 'Boxing', 'Clinic', 'Clinical', 'Cognitive', 'Communities', 'Complication', 'Computer Simulation', 'Computers', 'Congresses', 'Credentialing', 'Cues', 'Development', 'Devices', 'Education', 'Educational process of instructing', 'Endoscopic Gastrointestinal Surgical Procedures', 'Engineering', 'Ensure', 'Feedback', 'Funding', 'Goals', 'Group Practice', 'Healed', 'Health Alliance', 'Hospitals', 'Human', 'Industry', 'Information Sciences', 'Information Technology', 'Institutes', 'Israel', 'Joints', 'Laparoscopic Cholecystectomy', 'Laparoscopic Surgical Procedures', 'Learning', 'Length of Stay', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Errors', 'Medical center', 'Mentors', 'Metric', 'Minimally Invasive Surgical Procedures', 'Morbidity - disease rate', 'National Institute of Biomedical Imaging and Bioengineering', 'Online Systems', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Pattern', 'Pelvis', 'Physicians', 'Physics', 'Procedures', 'Qualifying', 'Recording of previous events', 'Reporting', 'Research', 'Research Activity', 'Research Project Grants', 'Risk', 'Societies', 'Students', 'Surgeon', 'Surgical Error', 'Surgical complication', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Training', 'Translating', 'Travel', 'Treatment Cost', 'United States National Institutes of Health', 'Universities', 'Validation', 'Visual', 'Woman', 'bariatric surgery', 'base', 'cost', 'experience', 'haptics', 'healing', 'improved', 'laptop', 'malignant breast neoplasm', 'meetings', 'multidisciplinary', 'new technology', 'novel', 'patient safety', 'programs', 'public health relevance', 'research study', 'simulation', 'skills', 'success', 'tool', 'vehicular accident', 'virtual', 'virtual reality', 'web based interface']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R01,2011,499624,-0.006277253060118782
"Micro-environment Glasses as a Treatment for CVS Computer Vision Syndrome (CVS) refers to a collection of eye problems associated with computer use, and  about three-quarters of computer users have it. Conservative estimates indicate that over $2 billion is  currently spent on examinations and special eyewear for CVS treatment. The most common symptoms of  CVS include: eyestrain or eye fatigue, dry eyes, burning eyes, sensitivity to light, and blurred vision. Non-  ocular symptoms include headaches, pain in the shoulders, neck, or back. As diverse as the symptoms are,  they may be related and can be subdivided into to three potential pathophysiological causes:   1) Ocular Surface Mechanisms  2) Accommodative Mechanisms  3) Extra-Ocular Mechanisms  There is a significant gap in the fund of knowledge regarding the diagnosis of this disease. In the near-term,  we plan to focus on the ocular surface category of disorders as a cause of CVS, identify clinical conditions  associated with this syndrome and develop a treatment that addresses this cause. In phase t, we propose to:  ¿Clinically define CVS by observing the incidence of ocular surface abnormalities in symptomatic subjects  and compare them with an age and sex matched non-symptomatic control population  ¿Develop specialized micro-environment glasses to combat CVS symptoms  ¿Study the efficacy of micro-environment glasses in symptomatic and control populations  ¿Critically evaluate viability of CVS micro-environment glasses as a commercial product using both statistical   methods and subjective questionnaires n/a",Micro-environment Glasses as a Treatment for CVS,8203808,R41EY015023,"['Address', 'Age', 'Asthenopia', 'Back', 'Blurred vision', 'Categories', 'Clinical', 'Collection', 'Computer Vision Systems', 'Computers', 'Devices', 'Disease', 'Environment', 'Eye', 'Eye Burns', 'Funding', 'Glass', 'Headache', 'Incidence', 'Knowledge', 'Light', 'Neck', 'Pain', 'Phase', 'Population Control', 'Process', 'Questionnaires', 'Shoulder', 'Statistical Methods', 'Symptoms', 'Syndrome', 'combat', 'disease diagnosis', 'effective therapy', 'eye dryness', 'improved', 'ocular surface', 'sex']",NEI,"SEEFIT, INC.",R41,2011,47724,-0.034076813827843014
CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation No abstract available n/a,CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8089310,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2011,252290,-0.006062469384756679
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8138459,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2011,345408,-0.019957456934419228
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,8139155,R44RR024094,"['AIDS/HIV problem', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cell physiology', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2011,449663,-0.04144687062054633
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,8143297,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'animal tissue', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2011,132786,-0.013769378297851992
"Replacement Ocular Battery (ROBatt)    DESCRIPTION (provided by applicant): The objective of this grant project is the development and pre-validation of the Replacement Ocular Battery (ROBatt), a tiered testing strategy consisting of a battery of four alternative ocular irritancy assays, which will replace regulatory mandated acute ocular irritation testing using the Draize Rabbit Eye test. ROBatt consists of the Bovine Corneal Opacity and Permeability Assay (BCOP), the Chorioallantoic Membrane Vascular Assay using 10-day fertile chicken eggs (CAMVA), the Porcine Corneal Reversibility Assay (PorCORA) and the Porcine Confocal Assay (PorFocal). This tiered strategy follows a decision tree that allows for a thorough interrogation of possible ocular irritants. Although four assays are recommended, in most cases only two or three will be used depending on the degree of irritation. The Specific Aim of the ROBatt project is to validate the decision tree variables using at least 50 chemicals listed in the European Center for Ecotoxicology and Toxicology of Chemicals (ECETOC) data bank, including Corrosive (EEC R41, GHS/EPA Cat 1), Severe (EEC R36, GHS CaL 2, HMIS 2), Moderate (EPA Cat. 3, HMIS 2), Mild (HMIS 1) and Non-irritating (EPA Cat 4, HMIS 0). The long-term project goal is to submit the ROBatt testing strategy to iCCVAM/ECVAM for consideration as a standalone alternative to the Draize Rabbit Eye test. Validation and acceptance of the ROBatt testing strategy will significantly reduce the number of rabbits used in the toxicological assessment of consumer products, chemicals and raw materials by replacing rabbits with four robust alternative assays.       PUBLIC HEALTH RELEVANCE: Ocular irritation testing is extremely relevant to assuring adequate safety levels of public health as new formulations of chemicals and products are introduced. In most cases, these safety assessments are performed using the Draize Rabbit Eye test, resulting in thousands of rabbits used in testing every year. Alternatives have been discussed since the 80s without any appreciable acceptance from regulators.           n/a",Replacement Ocular Battery (ROBatt),8150947,U01NS073481,"['Acute', 'Biological Assay', 'Blood Vessels', 'Cattle', 'Chemicals', 'Chickens', 'Cornea', 'Corneal Opacity', 'Corrosives', 'Databases', 'Decision Trees', 'Development', 'Drug Formulations', 'European', 'Eye', 'Family suidae', 'Felis catus', 'Goals', 'Grant', 'Irritants', 'Oryctolagus cuniculus', 'Permeability', 'Public Health', 'Safety', 'Test Result', 'Testing', 'Toxicology', 'Validation', 'chorioallantoic membrane', 'consumer product', 'egg', 'irritation', 'public health relevance']",NINDS,"MB RESEARCH LABORATORIES, INC.",U01,2011,483139,-0.009635371826356192
"Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements    DESCRIPTION (provided by applicant): Thyroid nodules are present in a large fraction of healthy individuals. Between 4% and 7% of the United States adult population has palpable thyroid nodules, and up to 50% of American women older than age 50 have nodules that can be depicted on ultrasound. The vast majority (>95%) of thyroid nodules are benign. However, cancer risk increases with male gender, nodule size, extremes of age (< 30 and > 60 years), underlying autoimmune disease, nodule growth, personal or family history of thyroid cancer, and radiation exposure. Ultrasound imaging and Fine Needle Aspiration Biopsy (FNAB) remain the mainstays of thyroid nodule evaluation. Unfortunately, 25% of patients who ultimately undergo FNAB of a thyroid nodule have indeterminate cytology. Many of these patients will require at least partial thyroidectomy purely for the purpose of obtaining a definitive diagnosis. Given that only 30% of these will ultimately prove to be malignant on surgical pathology, the majority of these lobectomies could potentially be avoided if better non-invasive methods existed to evaluate indeterminate nodules. Electrical Impedance Scanning (EIS) has been previously investigated for non-invasive evaluation of thyroid nodules. The overall diagnostic accuracy of EIS was encouraging but not sufficient for routine clinical use. We have developed a modified approach termed here Resonance Electrical Impedance Spectroscopy (REIS) that should have substantially higher sensitivity and specificity for this very purpose. When using REIS technology to examine the breast, we obtained initial results that are significantly better in all respects than those obtained with traditional EIS. We believe that REIS technology will similarly improve the assessment of thyroid nodules. REIS hold promise as a reproducible modality for the risk stratification of the many patients with indeterminate thyroid nodules. It is a new non- invasive modality that may help reduce the number of diagnostic lobectomies and would be welcomed by patients with non-diagnostic FNA results. The purpose of this application is to design, assemble, and test in a preliminary clinical study a unique REIS based device for the assessment of thyroid nodules.      PUBLIC HEALTH RELEVANCE: We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.           We propose to design, assemble, and test in technical and preliminary human studies a non-invasive, easy to use device for measuring Resonance Electrical Impedance Spectroscopy (REIS) of FNA indeterminate thyroid nodules. We will assess the ability of this technology to accurately characterize these indeterminate nodules as benign or malignant prior to a ""diagnostic"" surgery.         ",Assessing Indeterminate Thyroid Nodules With Electrical Impedance Measurements,8015458,R21CA154262,"['Address', 'Adult', 'Age', 'American', 'Aspirate substance', 'Autoimmune Diseases', 'Benign', 'Biopsy', 'Breast', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Research', 'Consent', 'Cytology', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Endocrine', 'Endocrinologist', 'Evaluation', 'Excision', 'Family history of', 'Fine needle aspiration biopsy', 'Follicular thyroid carcinoma', 'Frequencies', 'Gender', 'General Anesthesia', 'Growth', 'Human', 'Image', 'Incidence', 'Individual', 'Lesion', 'Lobectomy', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of thyroid', 'Measurement', 'Measures', 'Methods', 'Modality', 'Neck', 'Nodule', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Palpable', 'Papillary', 'Papillary Carcinoma', 'Participant', 'Patients', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Procedures', 'Prospective Studies', 'Protocols documentation', 'Publishing', 'Radiation', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Spectrum Analysis', 'Stratification', 'Surgeon', 'Surgical Pathology', 'System', 'Techniques', 'Technology', 'Testing', 'Thyroid Gland', 'Thyroid Nodule', 'Thyroidectomy', 'Triage', 'Ultrasonography', 'United States', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer risk', 'clinical practice', 'design', 'diagnostic accuracy', 'electric impedance', 'imaging modality', 'improved', 'male', 'malignant breast neoplasm', 'men', 'older women', 'phase change', 'prospective', 'prototype', 'radiologist', 'tool', 'web site']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2011,195019,-0.06185664162050802
"Sensory based CNS diagnostics for the clinic    DESCRIPTION (provided by applicant): There is currently a significant gap that exists between fundamental neuroscience research and translation of the findings of that research into everyday practice. Experimental findings at the genetic, cellular, molecular and systems level often take a fairly long and frequently circuitous route to make an impact on a particular neurological disease or disorder. The goal of our work is to bridge the neuroscientific gap at the systems level of study by developing standardized sensory measures that can be not only utilized in clinical or clinical research settings, but can be directly correlated with the observations obtained directly from sensory cortex in non-human primates via high resolution imaging and extracellular recording. Successful development of an experimental model that iteratively evaluates the relationship of clinical measures and systemic CNS responses to specific mechanistic alterations will be quite significant. Such an evaluation of an individual's CNS status could be directly linked to systemic mechanistic deficiencies or alterations observed in animal experimentation.  Towards that goal, we have successfully designed and fabricated a tactile sensory diagnostic device. In parallel with that development, we designed a number of protocols - based on experimental neurophysiological findings from both our non human primate research and that of others - that could be rapidly and efficiently delivered (1-3 minutes) to a number of subject populations. The tactile diagnostic system that we have developed was conceptually designed to investigate differences in cortical information processing strategies between people with autism and people without. In this proposal we ask whether or not the strategy that we have devised for investigating a population with a neurodevelopmental disorder could be broadly applied to a number of neurological disorders. In other words, we consider the changes manifested by the neurodevelpmental disorder autism to be systemic, and if systemic cortical alterations occur in other neurological disorders, could they also be detected in the same manner?  Proof-of-concept studies in a number of clinical research areas demonstrated that these newly developed metrics were sensitive to systemic cortical alterations. One question that emerges from this data is that most of these neurological disorders result in some type of altered central sensitization, no matter what the cause - whether it be neurodevelopmental, neurodegenerative, pharmacological or trauma induced - in which there is a significant change in the balance between excitation and inhibition. This application proposes to determine if sensory perceptual metrics, similar to those that were used to successfully distinguish subjects with autism from healthy control populations (with 90% accuracy using SVM to assess the results of a 25 minute battery of 9 protocols), could be used to reliably distinguish - on an individual basis - subjects with neurological disorders that are not neurodevelopmental in nature. Towards this goal, we target subjects from one broad category of neurological disorders - chronic pain. More specifically, we will examine the differences and commonalities from observations of pain patients diagnosed with one of the following: fibromyalgia, vulvodynia, TMJD, IBS and migraine.      PUBLIC HEALTH RELEVANCE: The overall goal of the proposed work is to investigate the utility of novel sensory-based methodologies that are currently being used in both basic and clinical research. Recently, utilizing state-of-the-art technology, we built a multi-site tactile stimulator that allows for investigation of central nervous system (CNS) health and advanced methods in sensory perceptual metrics. These metrics have been demonstrated to be sensitive to changes in centrally mediated mechanisms; and systemic alterations of cortical health (via neurodegenerational, neurodevelopmental, pharmacological or trauma induced changes) robustly change the measures. It is anticipated that clinicians will be able to utilize these measures to improve diagnostic performance and enable assessment of efficacy of treatment. The study itself will serve to validate the utility of a number of these measures in several types of pain, specifically fibromyalgia, TMJD, IBS, vulvodynia and migraine. The information from this study could aid in understanding centrally mediated mechanisms that undergo significant alterations with chronic pain.           The overall goal of the proposed work is to investigate the utility of novel sensory-based methodologies that are currently being used in both basic and clinical research. Recently, utilizing state-of-the-art technology, we built a multi-site tactile stimulator that allows for investigation of central nervous system (CNS) health and advanced methods in sensory perceptual metrics. These metrics have been demonstrated to be sensitive to changes in centrally mediated mechanisms; and systemic alterations of cortical health (via neurodegenerational, neurodevelopmental, pharmacological or trauma induced changes) robustly change the measures. It is anticipated that clinicians will be able to utilize these measures to improve diagnostic performance and enable assessment of efficacy of treatment. The study itself will serve to validate the utility of a number of these measures in several types of pain, specifically fibromyalgia, TMJD, IBS, vulvodynia and migraine. The information from this study could aid in understanding centrally mediated mechanisms that undergo significant alterations with chronic pain.         ",Sensory based CNS diagnostics for the clinic,8190617,R21NS072811,"['Address', 'Age', 'Animal Experimentation', 'Area', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Brain Concussion', 'Caregivers', 'Categories', 'Cerebrum', 'Clinic', 'Clinical', 'Clinical Research', 'Data', 'Databases', 'Development', 'Devices', 'Dextromethorphan', 'Diagnosis', 'Diagnostic', 'Disease', 'Equilibrium', 'Evaluation', 'Experimental Models', 'Fibromyalgia', 'GABA Agonists', 'Genetic', 'Goals', 'Health', 'Image', 'Individual', 'Investigation', 'Laboratory Animals', 'Lead', 'Letters', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Metric', 'Migraine', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'N-Methylaspartate', 'Nature', 'Nerve Degeneration', 'Neuraxis', 'Neurodevelopmental Disorder', 'Neurons', 'Neurosciences Research', 'Ophthalmic examination and evaluation', 'Pain', 'Patients', 'Performance', 'Physiological', 'Play', 'Population', 'Population Control', 'Primary Health Care', 'Process', 'Protocols documentation', 'Recruitment Activity', 'Research', 'Resolution', 'Role', 'Route', 'Sensory', 'Site', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Technology', 'Temporomandibular Joint Disorders', 'Testing', 'Translations', 'Trauma', 'Treatment Efficacy', 'United States National Institutes of Health', 'Vulvodynia', 'Work', 'analytical tool', 'base', 'central sensitization', 'chronic pain', 'cohort', 'cost effective', 'data mining', 'demographics', 'design', 'extracellular', 'gamma-Aminobutyric Acid', 'improved', 'in vivo', 'information processing', 'nervous system disorder', 'neurophysiology', 'neurotransmission', 'nonhuman primate', 'novel', 'process optimization', 'protocol development', 'response', 'sensory cortex', 'white matter damage']",NINDS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2011,218946,-0.09300871164808898
"Computational Methods for Analysis of Mouth Shapes in Sign Languages    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hand) and by the nonmanual components (the face). These facial articulations perform significant semantic, prosodic, pragmatic, and syntactic functions. This proposal will systematically study mouth positions in ASL. Our hypothesis is that ASL mouth positions are more extensive than those used in speech. To study this hypothesis, this project is divided into three aims. In our first aim, we hypothesize that mouth positions are fundamental for the understanding of signs produced in context because they are very distinct from signs seen in isolation. To study this we have recently collected a database of ASL sentences and nonmanuals in over 3600 video clips from 20 Deaf native signers. Our experiments will use this database to identify potential mappings from visual to linguistic features. To successfully do this, our second aim is to design a set of shape analysis and discriminant analysis algorithms that can efficiently analyze the large number of frames in these video clips. The goal is to define a linguistically useful model, i.e., the smallest model that contains the main visual features from which further predictions can be made. Then, in our third aim, we will explore the hypothesis that the linguistically distinct mouth positions are also visually distinct. In particular, we will use the algorithms defined in the second aim to determine if distinct visual features are used to define different linguistic categories. This result will show whether linguistically meaningful mouth positions are not only necessary in ASL (as hypothesized in aim 1), but whether they are defined using non-overlapping visual features (as hypothesized in aim 3). These aims address a critical need. At present, the study of nonmanuals must be carried out manually, that is, the shape and position of each facial feature in each frame must be recorded by hand. Furthermore, to be able to draw conclusive results for the design of a linguistic model, it is necessary to study many video sequences of related sentences as produced by different signers. It has thus proven nearly impossible to continue this research manually. The algorithms designed in the course of this grant will facilitate this analysis of ASL nonmanuals and lead to better teaching materials.      PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.           Project Narrative Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for Analysis of Mouth Shapes in Sign Languages,8109271,R21DC011081,"['Academic achievement', 'Access to Information', 'Address', 'Adult', 'Algorithms', 'Applications Grants', 'Categories', 'Child', 'Clip', 'Communication', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Databases', 'Devices', 'Discriminant Analysis', 'Educational process of instructing', 'Emotions', 'Excision', 'Eye', 'Face', 'Funding', 'Goals', 'Grant', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Joints', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Manuals', 'Modeling', 'Oral cavity', 'Parents', 'Pattern Recognition', 'Positioning Attribute', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Shapes', 'Sign Language', 'Social Interaction', 'Specific qualifier value', 'Speech', 'Teaching Materials', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visual', 'Work', 'computerized tools', 'deafness', 'design', 'experience', 'innovation', 'instructor', 'interest', 'novel', 'prevent', 'public health relevance', 'research study', 'shape analysis', 'success', 'syntax', 'teacher', 'tool', 'visual map']",NIDCD,OHIO STATE UNIVERSITY,R21,2011,205267,-0.07739442121905131
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,8037680,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Blindness', 'Central Scotomas', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Data', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2011,513228,0.0016032855615153504
"Recursive partitioning and ensemble methods for classifying an ordinal response    DESCRIPTION (provided by applicant):       Classification methods applied to microarray data have largely been those developed by the machine learning community, since the large p (number of covariates) problem is inherent in high-throughput genomic experiments. The random forest (RF) methodology has been demonstrated to be competitive with other machine learning approaches (e.g., neural networks and support vector machines). Apart from improved accuracy, a clear advantage of the RF method in comparison to most machine learning approaches is that variable importance measures are provided by the algorithm. Therefore, one can assess the relative importance each gene has on the predictive model. In a large number of applications, the class to be predicted may be inherently ordinal. Examples of ordinal responses include TNM stage (I,II,III, IV); drug toxicity (none, mild, moderate, severe); or response to treatment classified as complete response, partial response, stable disease, and progressive disease. These responses are ordinal; while there is an inherent ordering among the responses, there is no known underlying numerical relationship between them. While one can apply standard nominal response methods to ordinal response data, in so doing one loses the ordered information inherent in the data. Since ordinal classification methods have been largely neglected in the machine learning literature, the specific aims of this proposal are to (1) extend the recursive partitioning and RF methodologies for predicting an ordinal response by developing computational tools for the R programming environment; (2) evaluate the proposed ordinal classification methods against alternative methods using simulated, benchmark, and gene expression datasets; (3) develop and evaluate methods for assessing variable importance when interest is in predicting an ordinal response. Novel splitting criteria for classification tree growing and methods for estimating variable importance are proposed, which appropriately take the nature of the ordinal response into consideration. In addition, the Generalized Gini index and ordered twoing methods will be studied under the ensemble learning framework, which has not been previously conducted. This project is significant to the scientific community since the ordinal classification methods to be made available from this project will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect responses on an ordinal scale.           n/a",Recursive partitioning and ensemble methods for classifying an ordinal response,8049892,R03LM009347,"['Algorithms', 'Behavioral Research', 'Benchmarking', 'Biological Neural Networks', 'Classification', 'Communities', 'Data', 'Data Analyses', 'Data Set', 'Discriminant Analysis', 'Drug toxicity', 'Environment', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Health', 'Health Surveys', 'Image Analysis', 'In complete remission', 'Individual', 'Learning', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Neoplasm Metastasis', 'Northern Blotting', 'Outcome', 'Performance', 'Process', 'Progressive Disease', 'Relative (related person)', 'Simulate', 'Stable Disease', 'Staging', 'Structure', 'Technology', 'Time', 'Trees', 'computerized tools', 'forest', 'improved', 'indexing', 'interest', 'neglect', 'novel', 'partial response', 'predictive modeling', 'programs', 'research study', 'response', 'social', 'tumor']",NLM,VIRGINIA COMMONWEALTH UNIVERSITY,R03,2010,5742,-0.020803573164579776
"Machine-Learning Approach to Label-free Detection of new Bacterial Pathogens    DESCRIPTION (provided by applicant): We appreciate the time and effort spent by all the reviewers, and we are grateful for the useful comments and provided suggestions. We have carefully reviewed the critiques and we are happy to see that the panel was receptive to our proposal. The reviewers expressed three major concerns in the summary statement: (1) although the investigating team is well qualified our history of collaboration is short; (2) details regarding the practical constraints of the BARDOT system are lacking; (3) the machine learning techniques employed in the project are considered fairly standard.  Below we briefly discuss the reviewers comments and indicate how we have changed our revised application to address the critique.  (1) Dr. Dundar moved from industry to academia in the fall of 2008, at which point Dr. Rajwa (one of the original inventors of BARDOT) and Dr. Dundar began their collaboration on new approaches to the problem of non-exhaustively defined classes in phenotypic screening. This scientific partnership immediately produced interesting results, and at the time of submission of the original application, Dr. Dundar and Dr. Rajwa had their first manuscript under review. The approach presented in the original proposal was tested and the results were submitted to the ACM 15th Annual SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'09), which is the largest and one of the most respected conferences in this field. The manuscript was accepted after a full peer review as one of the 50 regular papers selected from 551 submissions [20]. Following the proposal submission, research efforts continued and produced yet another approach to the problem described in this grant application. The preliminary findings are reported in a new manuscript which is currently under review [4].  (2) We rewrote the background and research methods sections of our proposal to include information re- quested by the reviewers regarding practical aspects of the BARDOT system, such as accuracy issues (Section D.3.2), frequency of encountering new, unknown classes (Section B.3.1), and validation (Section D.3.1).  (3) The problem of phenotypic screening and classification of bacteria can be defined within exhaustive (stan- dard) or non-exhaustive learning frameworks. Although we agree that the implementation of an exhaustive clas- sification approach for BARDOT does require only fairly standard tools, the problem of the non-exhaustive nature of training libraries cannot be addressed by straightforward use of any textbook-level technique. In fact, the presence of non-exhaustively defined set of classes violates basic assumptions for most supervised learning systems. The issue of non-exhaustively defined classes is the major obstacle for application of machine learning in phenotypic analysis since the number of possible phenotypes may be infinite. In our original proposal we argued that learning with a non-exhaustively defined set of classes remains a very challenging problem, and presented evidence demonstrating that simple extensions of standard techniques cannot provide an acceptable solution. Subsequently, we proposed a new approach based on Bayesian simulation of classes and showed that preliminary results outperformed benchmark techniques [4].  Although these initial results looked promising, we did not consider the described preliminary algorithms final and definitive, and we do not believe that at this point we are able to provide an exact algorithmic solution to this complex problem. If we were able to do that, it would mean that we had already accomplished all the grant goals. The very essence of the proposed research is finding the answer to the defined problem, and the answer will remain unknown until after the work has been done. However, positive reviews and an acceptance of our work by KDD'09 conference judges, tell us that we are heading in the right direction.  In the amended version of this application we propose a modified Bayesian approach based on Wishart priors (Section D.2.3). The algorithm creates new classes on the fly and evaluates maximum likelihood with the updated set of classes, gradually improving detection accuracy for future samples. We believe that this offers a substantial improvement over the previous method. Consequently, the preliminary results in Section C are updated to reflect our progress. Since the modified technique allows for classification with non-exhaustive and exhaustive sets using the same algorithm, we consolidated the previous specific aims 3 and 5 into one in the revised application.      PUBLIC HEALTH RELEVANCE: A Machine Learning Approach to Label-free Detection of Bacterial Pathogens  using Laser Light Scattering  PIs: Dr. M. Murat Dundar and Dr. Bartek Rajwa Successful implementation of this project will allow for a label-free detection and identification of food pathogens and their mutated subclasses not yet seen earlier. This will reduce the number of food related outbreaks and will help secure public food supply.           Public Health Relevance Title: A Machine Learning Approach to Label-free Detection of Bacterial Pathogens  using Laser Light Scattering  PIs: Dr. M. Murat Dundar and Dr. Bartek Rajwa Successful implementation of this project will allow for a label-free detection and identification of food pathogens and their mutated subclasses not yet seen earlier. This will reduce the number of food related outbreaks and will help secure public food supply.",Machine-Learning Approach to Label-free Detection of new Bacterial Pathogens,7896355,R21AI085531,"['Academia', 'Accounting', 'Address', 'Algorithms', 'American', 'Applications Grants', 'Bacteria', 'Benchmarking', 'Biochemical Process', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Classification', 'Collaborations', 'Complex', 'Computer Vision Systems', 'Critiques', 'Data Set', 'Detection', 'Disease', 'Disease Outbreaks', 'Escherichia coli', 'Food', 'Food Supply', 'Frequencies', 'Future', 'Genus staphylococcus', 'Goals', 'Grant', 'Head', 'Industry', 'Infection', 'International', 'Knowledge', 'Label', 'Lasers', 'Learning', 'Libraries', 'Listeria', 'Machine Learning', 'Manuscripts', 'Medical', 'Methods', 'Modeling', 'Mutate', 'Mutation', 'Nature', 'Optics', 'Paper', 'Pathogenicity', 'Pattern', 'Pattern Recognition', 'Peer Review', 'Phenotype', 'Process', 'Productivity', 'Public Health', 'Published Comment', 'Qualifying', 'Reagent', 'Recording of previous events', 'Reporting', 'Research', 'Research Methodology', 'Safety', 'Salmonella', 'Sampling', 'Screening procedure', 'Secure', 'Serotyping', 'Solutions', 'Suggestion', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Textbooks', 'Time', 'Training', 'Update', 'Validation', 'Vibrio', 'Work', 'base', 'cost', 'data mining', 'falls', 'fly', 'foodborne', 'foodborne pathogen', 'image processing', 'improved', 'interest', 'light scattering', 'new technology', 'novel strategies', 'optical sensor', 'pathogen', 'pathogenic bacteria', 'public health relevance', 'rapid detection', 'sensor', 'simulation', 'symposium', 'tool']",NIAID,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R21,2010,234831,-0.011543834539075128
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.           PROJECT NARRATIVE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,8043275,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'public health relevance', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'stem', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2010,394165,-0.016835232443886648
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,8013208,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2010,376899,-0.022147034685075173
"Robust BCT for Clinical Use    DESCRIPTION (provided by applicant): Osteoporosis is a major public health threat for over 50% of the population over age 50. Despite its importance, osteoporosis is largely under-treated, with less than 20% of those recommended for testing being screened. With substantial reimbursement cuts being introduced by Medicare for bone densitometry by dual energy X-ray absorptiometry (DXA, the current clinical standard), with a sensitivity of DXA for fracture prediction of less than 50%, and with the rapidly increasing size of the aging population of the U.S., there is an urgent need for additional and more sensitive modalities than DXA for clinical assessment of fracture risk. Biomechanical Computed Tomography (BCT) has emerged as a powerful alternative to DXA. This CT-based technology creates a structural ""finite element"" model of a patient's bone from their CT scans, and subjects that model to virtual forces in order to provide an estimate of the strength of the bone. Well validated in cadaver studies and being a better predictor of bone strength than is bone mineral density by DXA, BCT has also been shown to be highly predictive of osteoporotic fractures in clinical research studies. However, robustness remains an issue - can the technique be used easily by non-experts in research and clinical environments? Addressing this issue, the overall goal of this research is to improve the robustness of our software, such that it can automatically analyze scans from a wide range of CT scanners and using a wide variety of CT acquisition protocols, including new low-dose protocols that limit radiation exposure to the patient. Such a robust BCT diagnostic tool could then be offered as a supplementary ""add-on"" analysis to many types of CT exams taken for other purposes such as CT colonography, pelvic, abdominal, and spine exams, thus reducing hospital costs, incurring no addition radiation to the patient, requiring no change in the CT acquisition protocols, and therefore greatly increasing the number of patients that could be screened at low cost. Specifically, we propose in this Phase-I project to combine expertise in computer vision, CT scanning, and biomechanics in order to develop an automated method of ""phantomless"" cross-calibration of CT scans for robust vertebral strength assessment. Focusing on the spine, our major tasks are to perform a series of clinical studies in which patients are scanned twice using a variety of CT acquisition protocols; develop a custom external-calibration phantom and use that to determine the effects of various CT acquisition parameters on scanning standardization; and use machine learning techniques to develop a ""statistical atlas"" of the spine for automation of all image processing. We will combine these efforts to develop a phantomless BCT method that accounts for differences in image quality due to variations in CT scanners and acquisition protocols, including low-dose protocols, and that does so in a highly automated fashion requiring minimal user expertise and input. Should this project be successful, future work will further refine the techniques, extend them to the hip and quantitative analysis of muscle and other soft tissues, and address robustness of longitudinal changes for clinical monitoring.  PUBLIC HEALTH RELEVANCE: With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.",Robust BCT for Clinical Use,7902171,R43AR057616,"['Abdomen', 'Accounting', 'Address', 'Adoption', 'Affect', 'Age', 'Aging', 'Algorithms', 'Angiography', 'Atlases', 'Automation', 'Biomechanics', 'Bone Density', 'Businesses', 'Cadaver', 'Calibration', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Densitometry', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Dose', 'Dual-Energy X-Ray Absorptiometry', 'Early identification', 'Economic Burden', 'Elderly', 'Elements', 'Environment', 'Exposure to', 'Fracture', 'Future', 'Goals', 'Growth', 'Guide prevention', 'Healthcare', 'Healthcare Systems', 'Hip Fractures', 'Hip region structure', 'Hospital Costs', 'Image', 'Individual', 'Intervertebral disc structure', 'Low Dose Radiation', 'Lung', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Medicare', 'Methods', 'Minerals', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Muscle', 'Osteoporosis', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Phase', 'Population', 'Postmenopause', 'Protocols documentation', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Risk', 'Scanning', 'Screening procedure', 'Second lumbar vertebra', 'Sensitivity and Specificity', 'Series', 'Societies', 'Standardization', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Tube', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'aging population', 'base', 'bone', 'bone strength', 'cohort', 'cost', 'cost effective', 'image processing', 'improved', 'meetings', 'mortality', 'novel', 'osteoporosis with pathological fracture', 'product development', 'public health relevance', 'reconstruction', 'research study', 'soft tissue', 'spine bone structure', 'tool', 'treatment effect', 'virtual', 'voltage']",NIAMS,"O. N. DIAGNOSTICS, LLC",R43,2010,350000,-0.02329080324127971
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,8068069,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2010,51400,-0.018900775503569247
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7828142,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2010,338802,-0.018900775503569247
"High-Throughput Computing for a Multi-Plan Framework in Radiotherapy    DESCRIPTION (provided by applicant):    Computerized planning for radiation delivery via either external beam radiation therapy (EBRT) or intensity- modulated radiation therapy (IMRT) from linear accelerators is a complex process involving a large amount of input data and vast numbers of decision variables. Such large-scale combinatorial optimization problems are typically intractable for conventional approaches such as the direct application of the best available commercial algorithms, and thus specialized methods that take advantage of problem structure are required. Radiation treatment planning (RTP) problems are further complicated by the fact that they are multi-objective, that is, the RTP optimization process must take into account a trade-off between the competing goals of delivering appropriate doses to the tumor and avoiding the delivery of harmful radiation to nearby healthy organs. The goal of this proposal is to harness distributive computing via the Condor system for High Throughput Computing (HTC) within an RTP environment. The specific aims for this proposal are: 1) To develop a Nested Partitions (NP) framework that guides a global search process for optimal IMRT delivery parameters using HTC. 2) To develop parallel HTC-based linear programming (LP) methods to efficiently solve the dose optimization problem in IMRT for each given set of beam angles or beam apertures. (3) To exploit a high-throughput computing (HTC) environment and the developed NP/LP/segmentation framework to efficiently generate multiple plans for each given patient case. (4) To couple this multi-plan framework with a decision support system (DSS) that includes planning surface models, a graphical-user-interface (GUI) and machine learning tools to prediction OAR complication in order to aid in the ranking and selection of the generated treatment plans. This proposal requires a multi-disciplinary approach that is best conducted within the framework of the Innovations in Biomedical Computational Science and Technology program announcement. It brings together an interdisciplinary team of investigators with expertise in medical physics, mathematical programming, industrial engineering and clinical radiation oncology that is crucial to the development of the proposed multi- plan framework using HTC in radiation therapy. PUBLIC HEALTH RELEVANCE: The goal of this proposal is to develop a multi-dimensional platform for sophisticated treatment planning of radiation delivery. It will develop novel algorithms that will enable generation of superior treatment plans with the added advantage of increasing the speed of treatment planning. Further, it will allow physicians to know beforehand the quality of the treatment plan relative to the multiple treatment objectives and be able to determine the treatment complication scenario beforehand.           PROJECT NARRATIVE The goal of this proposal is to develop a multi-dimensional platform for sophisticated treatment planning of radiation delivery. It will develop novel algorithms that will enable generation of superior treatment plans with the added advantage of increasing the speed of treatment planning. Further, it will allow physicians to know beforehand the quality of the treatment plan relative to the multiple treatment objectives and be able to determine the treatment complication scenario beforehand.",High-Throughput Computing for a Multi-Plan Framework in Radiotherapy,7845650,R01CA130814,"['Accounting', 'Algorithms', 'Behavior', 'Clinical Engineering', 'Collection', 'Complex', 'Complication', 'Computational Science', 'Data', 'Decision Support Systems', 'Dependence', 'Development', 'Dose', 'Engineering', 'Environment', 'External Beam Radiation Therapy', 'Generations', 'Genetic Programming', 'Goals', 'Intensity-Modulated Radiotherapy', 'Knowledge', 'Lead', 'Linear Accelerator Radiotherapy Systems', 'Linear Programming', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Modeling', 'Monte Carlo Method', 'NIH Program Announcements', 'Organ', 'Patients', 'Physicians', 'Physics', 'Process', 'Property', 'Radiation', 'Radiation Oncology', 'Radiation therapy', 'Relative (related person)', 'Research Personnel', 'Risk', 'Sampling', 'Shapes', 'Simulate', 'Solutions', 'Speed', 'Structure', 'Surface', 'System', 'Technology', 'Time', 'Toxic effect', 'base', 'cluster computing', 'combinatorial', 'computer science', 'computerized', 'computing resources', 'direct application', 'graphical user interface', 'heuristics', 'improved', 'innovation', 'insight', 'novel', 'novel strategies', 'predictive modeling', 'process optimization', 'programs', 'public health relevance', 'research clinical testing', 'tool', 'treatment planning', 'tumor']",NCI,UNIVERSITY OF MARYLAND BALTIMORE,R01,2010,306826,-0.034234854755252044
"Rational design of cytokine releasing angiogenic constructs    DESCRIPTION (provided by applicant): The development of organized vascular networks necessitates a tightly regulated interplay between variable cells, growth factors and soluble mediators. The applicant's long-term goal is to develop therapeutic angiogenic strategies based on the rational design of cytokine releasing constructs that promote vascular patterning and vessel stability. The objective of this proposal is to i) develop electrospun, three-dimensional constructs with patterned architecture, ii) demonstrate that the spatial and temporal delivery of two model angiogenic growth factors promotes the formation of an organized capillary network and iii) develop a computational model that can predict the biological effect of a growth factor releasing construct as a function of specified fabrication parameters. We hypothesize that guided therapeutic angiogenesis (i.e. patterned vascular networks) can be obtained by controlling the spatial and temporal presentation of soluble mediators at the site of ischemia. In AIM I, we will synthesize bFGF and G-CSF releasing electrospun constructs and determine their programmed delivery as a function of fabrication parameters. In AIM II, we will demonstrate the effect of spatial and temporal control of cytokine delivery in promoting directed angiogenesis in a three-dimensional in vitro angiogenesis model and we will develop a computational model/software that can predict the biological effect of different scaffold configurations. We will validate our model by assessing the angiogenic potential of our growth factor releasing constructs in a murine critical limb ischemic model.      PUBLIC HEALTH RELEVANCE: We are proposing to a) fabricate a growth factor releasing construct that regulates the spatio- temporal delivery of angiogenic cytokines and promotes the formation of organized capillary networks and b) develop a machine learning computational model that can predict the angiogenic potential of our construct as a function of fabrication parameters.           Project narrative We are proposing to a) fabricate a growth factor releasing construct that regulates the spatio- temporal delivery of angiogenic cytokines and promotes the formation of organized capillary networks and b) develop a machine learning computational model that can predict the angiogenic potential of our construct as a function of fabrication parameters.",Rational design of cytokine releasing angiogenic constructs,7961101,R21EB012136,"['Animal Model', 'Animals', 'Architecture', 'Biological', 'Blood Vessels', 'Blood capillaries', 'CSF3 gene', 'Cell Proliferation', 'Cell Transplantation', 'Clinical', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Fiber', 'Fibroblast Growth Factor 2', 'Gelatin', 'Goals', 'Growth', 'Growth Factor', 'In Vitro', 'Ischemia', 'Kinetics', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Mediator of activation protein', 'Modeling', 'Mus', 'Natural regeneration', 'Needles', 'Operative Surgical Procedures', 'Output', 'Pattern', 'Pharmacotherapy', 'Polymers', 'Process', 'Research', 'Series', 'Site', 'Specific qualifier value', 'Techniques', 'Testing', 'Therapeutic', 'Therapeutic Effect', 'Tissue Engineering', 'angiogenesis', 'base', 'capillary', 'cell growth', 'cell motility', 'cytokine', 'design', 'electric field', 'high risk', 'interest', 'mathematical model', 'minimally invasive', 'multitask', 'nanofiber', 'novel', 'pre-clinical', 'programs', 'public health relevance', 'repaired', 'scaffold', 'success', 'therapeutic angiogenesis', 'tissue regeneration']",NIBIB,UNIVERSITY OF MIAMI CORAL GABLES,R21,2010,221192,-0.013425534797139775
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7754089,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2010,2037327,-0.019472393955964073
"Reduced-Order Constrained Optimization for Rapid IMRT and VMAT Treatment Planning    DESCRIPTION (provided by applicant): Intensity-modulated radiotherapy (IMRT) has revolutionized the treatment of cancers in the last decade, since it can tightly conform and escalate radiation dose to a tumor while simultaneously protecting nearby radiation- sensitive normal tissues, resulting in better local control and fewer post-treatment complications than previous techniques. However, the process of obtaining a clinically acceptable IMRT plan for a difficult site is still extremely slow, requiring many hours of a busy expert's time in a manual trial-and-error loop of parameter adjustment. The goal of this project is to drastically reduce the amount of time to obtain a clinically acceptable IMRT plan using a new automated method that directly applies constrained optimization in a computationally tractable and clinically meaningful way. The hypothesis is that clinical treatment planning times using this technique will be reduced from several hours to a matter of minutes.  The new approach, called ROCO (Reduced-Order Constrained Optimization) translates well-established concepts from optimization and machine learning theory to the novel application of IMRT planning, exploiting the speed and ease of unconstrained optimizations and introducing a dimensionality reduction step that makes true constrained optimization tractable. The Specific Aims of the proposal are to (1) apply Reduced-Order Con- strained Optimization to IMRT planning for non-small cell lung cancers and nasopharynx cancers, where the planning process is highly time-consuming; (2) develop and extend the Reduced-Order Constrained Optimization paradigm to a promising IMRT variant called Volumetric Modulated Arc Therapy (VMAT) for the prostate site, which is currently nearly clinically intractable to plan; and (3) integrate the new tools into the clinical IMRT planning process at Memorial Sloan-Kettering Cancer Center, using a powered study to verify the hypothesis that the proposed method significantly improves planning speed. The experiments will be designed in consultation with an expert clinical treatment planner and biostatistician, and carefully validated using anonymized data from approximately 50 patients for each site.  The main benefit of the proposed approach is to drastically reduce planning times, which is critical if IMRT and VMAT are to reach their full potential in clinical application. In a busy clinic, long planning times place a severe stress on available resources, and can result in treatment delays, acceptance of sub-optimal plans or - in the worst case - errors due to time pressure. In the longer term, the proposed approach will provide deeper insight into the critical elements of the dose optimization problem, significantly reduce the trial-and-error effort characteristic of current IMRT planning, and reduce subjectivity in treatment plan selection.      PUBLIC HEALTH RELEVANCE: Intensity-modulated radiation therapy (IMRT) is an extremely promising cancer treatment, but currently requires many hours of an expert treatment planner's time to obtain a plan that meets all the clinical constraints specified by the physician. This proposal describes a new, automatic method for treatment plan optimization that is very fast, requiring only minutes to produce a plan that directly meets all the physician's constraints, potentially saving much time for a busy clinic.           Project Narrative Intensity-modulated radiation therapy (IMRT) is an extremely promising cancer treatment, but currently requires many hours of an expert treatment planner's time to obtain a plan that meets all the clinical constraints specified by the physician. This proposal describes a new, automatic method for treatment plan optimization that is very fast, requiring only minutes to produce a plan that directly meets all the physician's constraints, potentially saving much time for a busy clinic.",Reduced-Order Constrained Optimization for Rapid IMRT and VMAT Treatment Planning,7862840,R01CA148876,"['Acute', 'Address', 'Aftercare', 'Algorithms', 'Cancer Center', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Treatment', 'Code', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'Consultations', 'Data', 'Development', 'Dose', 'Dose-Limiting', 'Drug Formulations', 'Effectiveness', 'Elements', 'Goals', 'Head and Neck Neoplasms', 'Head and neck structure', 'Hour', 'Housing', 'Human', 'Intensity-Modulated Radiotherapy', 'Journals', 'Linear Accelerator Radiotherapy Systems', 'Lung', 'Machine Learning', 'Malignant neoplasm of nasopharynx', 'Manuals', 'Measures', 'Medical', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Nasopharynx', 'Non-Small-Cell Lung Carcinoma', 'Normal tissue morphology', 'Organ', 'Paper', 'Parotid Gland', 'Patients', 'Phase', 'Physicians', 'Physics', 'Process', 'Prostate', 'Quality of life', 'Radiation', 'Radiation therapy', 'Resources', 'Risk', 'Sampling', 'Site', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Stress', 'Sum', 'System', 'Techniques', 'Technology', 'Time', 'To specify', 'Toxic effect', 'Translating', 'Variant', 'Weight', 'Xerostomia', 'base', 'cancer therapy', 'clinical application', 'clinical practice', 'design', 'experience', 'image processing', 'improved', 'insight', 'meetings', 'novel', 'novel strategies', 'pressure', 'process optimization', 'public health relevance', 'rectal', 'research study', 'symposium', 'theories', 'time use', 'tool', 'treatment planning', 'tumor']",NCI,RENSSELAER POLYTECHNIC INSTITUTE,R01,2010,297596,-0.03311628413920534
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,8115481,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'intelligence genetics', 'novel', 'operation', 'programs', 'resistant strain', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2010,99989,-0.016881666087739864
"Novel Analytic Techniques to Assess Physical Activity    DESCRIPTION (provided by applicant): Progress has been made in developing and using accelerometer-based motion sensors for physical activity research. However, traditional methods of processing activity monitor data do not provide sufficient accuracy to satisfy current trends in the use of objective physical activity data in the research arena. The aims of this proposal address this weakness in accelerometer- based PA assessment methodologies: The specific aims are: 1) To develop and validate novel methods to process Actigraph accelerometer data to improve estimates of PA using powerful modern classification methods (classification trees, discriminant analyses, hidden Markov models, neural networks, regression splines, and support vector machines); 2) To compare these classification methods and traditional approaches for assessing PA in a controlled setting; 3) To compare the classification methods and traditional approaches for quantifying PA in free living PA conditions and to select a recommended method; and 4) To correct for measurement error in summary estimates of habitual PA from the novel classification methods and traditional approaches for quantifying PA. Our uniquely qualified multidisciplinary research group will address these aims by first developing innovative classification methods to identify specific activities in a laboratory setting, and then validating the models using data collected from known activities performed in both controlled laboratory environments and free- living situations. Based on the results of these studies, the classification methods will be refined, and estimates of PA behavior will be adjusted using statistical measurement error methods to derive more accurate estimates of PA. We have chosen the classification methods to include publicly available ""off-the shelf"" classification methods that others can easily use. The resulting data processing programs will be implemented in popular commercial software packages and made freely available. The results of the proposed investigations will move the field of PA assessment forward by providing innovative approaches to derive more accurate and detailed estimates of PA using a popular accelerometer-based PA monitor. This systematic approach will provide information leading to a clearer understanding of the dose-response relationship between PA and health and the physiological basis of this relationship.           n/a",Novel Analytic Techniques to Assess Physical Activity,7825424,R01CA121005,"['Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Chronic Disease', 'Classification', 'Computer software', 'Data', 'Diet', 'Discriminant Analysis', 'Dose', 'Environment', 'Health', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Laboratories', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Motion', 'NIH Program Announcements', 'Nature', 'Outcome', 'Output', 'Participant', 'Pattern', 'Performance', 'Physical activity', 'Physiological', 'Population', 'Principal Investigator', 'Process', 'Qualifying', 'Recommendation', 'Research', 'Scientist', 'Series', 'Techniques', 'Time', 'Time Study', 'Trees', 'Validation', 'Walking', 'Work', 'base', 'computerized data processing', 'improved', 'innovation', 'intervention effect', 'markov model', 'meetings', 'novel', 'novel strategies', 'nutritional epidemiology', 'programs', 'response', 'sensor', 'trend']",NCI,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,2010,185505,-0.003283028183983256
"Developing a Virtual Basic Laparoscopic Skill Trainer (VBLaST)    DESCRIPTION (provided by applicant):  Development and Validation of a Virtual Basic Laparoscopic Skill Trainer (VBLaST) For the first time in the history of surgical education, a comprehensive program to teach and evaluate the cognitive and psychomotor aspects unique to laparoscopic surgery - the Fundamentals of Laparoscopic Surgery (FLS) developed originally by the Society of American Gastrointestinal Endoscopic Surgery (SAGES) and subsequently by a joint committee which includes the American College of Surgeons (ACS) - is being embraced nationally for training and credentialing laparoscopic surgeons. As an example of its growing acceptance by the medical community, starting in 2009, the American Board of Surgeons has mandated that passing the FLS certifying examination will be required for taking the board examination in surgery. While the cognitive assessment in FLS is based on 75 multiple-choice questions, a proctored examination is used for the manual skills assessment which includes five tasks to be performed in a portable pelvic trainer box with built-in video camera: bimanual peg transfer, precise pattern cutting, use of ligating loops and suturing with intracorporeal and extracorporeal knot tying. In spite of the growing popularity of the FLS, there are several major problems with this box trainer paradigm: (1) the assessment is subjective, (2) there is no feedback during learning except when an experienced trainer is present, (3) a large number of qualified proctors must be engaged during test taking, (4) the training material must be constantly replaced, and (5) the test-takers must travel to one of the 27 Regional Test Centers or the Annual SAGES meeting or the ACS Clinical Congress. To overcome these problems and to enable greater dissemination, we propose to develop and validate a Virtual Basic Laparoscopic Skill Trainer (VBLaST) whereby tasks available in the FLS may be performed on PCs and laptops with inexpensive haptic (touch) interface devices, such as the Phantom(R) OmniTM. To develop the VBLaST a novel set of technologies must be developed including rapid, but highly realistic physics-based virtual interaction paradigms and statistical machine learning techniques to develop a ""virtual mentor"" which will provide real time automated feedback to the trainees. A comprehensive set of studies involving students, residents, fellows and practicing surgeons at Boston area hospitals (e.g., BIDMC, Tufts Medical Center, Cambridge Health Alliance, Harvard, MGH, Brigham & Women's, Lahey Clinic) will be undertaken to test the validity of the VBLaST as a training tool and establish its usefulness in transferring the acquired skills to the operating room. Once validated, the VBLaST will have exponential impact in reducing training costs and training time while improving patient safety and outcomes, A multidisciplinary team with collective expertise in physics-based interactive medical simulation, laparoscopic surgery and surgical education, and human factors engineering has been assembled to achieve the following Specific Aims: SA1) To develop a realistic virtual basic laparoscopic skill trainer (VBLaST) platform to perform all the tasks available in the FLS training tool box. SA2) To establish the validity of the VBLaST as a training tool. SA3) To evaluate the usefulness of the VBLaST as a training tool. SA4) To develop a web-based interface for the VBLaST.      PUBLIC HEALTH RELEVANCE: The goal of this research is to develop a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills and to take standardized tests on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.           Relevance: The goal of this research is to develop a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills and to take standardized tests on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.",Developing a Virtual Basic Laparoscopic Skill Trainer (VBLaST),7766328,R01EB010037,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'American', 'American College of Surgeons', 'Area', 'Attention', 'Auditory', 'Boston', 'Boxing', 'Clinic', 'Clinical', 'Cognitive', 'Communities', 'Complication', 'Computer Simulation', 'Computers', 'Congresses', 'Credentialing', 'Cues', 'Development', 'Devices', 'Education', 'Educational process of instructing', 'Endoscopic Gastrointestinal Surgical Procedures', 'Engineering', 'Ensure', 'Feedback', 'Funding', 'Goals', 'Group Practice', 'Healed', 'Health Alliance', 'Hospitals', 'Human', 'Industry', 'Information Sciences', 'Institutes', 'Israel', 'Joints', 'Laparoscopic Cholecystectomy', 'Laparoscopic Surgical Procedures', 'Learning', 'Length of Stay', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Errors', 'Medical center', 'Mentors', 'Metric', 'Minimally Invasive Surgical Procedures', 'Morbidity - disease rate', 'National Institute of Biomedical Imaging and Bioengineering', 'Online Systems', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Pattern', 'Pelvis', 'Physicians', 'Physics', 'Procedures', 'Qualifying', 'Recording of previous events', 'Reporting', 'Research', 'Research Activity', 'Research Project Grants', 'Risk', 'Societies', 'Students', 'Surgeon', 'Surgical Error', 'Surgical complication', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Touch sensation', 'Training', 'Translating', 'Travel', 'Treatment Cost', 'United States National Institutes of Health', 'Universities', 'Validation', 'Visual', 'Woman', 'bariatric surgery', 'base', 'cost', 'experience', 'haptics', 'healing', 'improved', 'malignant breast neoplasm', 'meetings', 'multidisciplinary', 'new technology', 'novel', 'patient safety', 'programs', 'public health relevance', 'research study', 'simulation', 'skills', 'success', 'tool', 'vehicular accident', 'virtual', 'virtual reality', 'web based interface']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R01,2010,558119,-0.006277253060118782
"Camera-based Text Recognition from Complex Backgrounds for the Blind or Visually There are more than 10 million blind and visually impaired people living in America today. Recent technology developments in computer vision, digital cameras, and portable computers make it possible to assist these individuals by developing camera-based products that combine computer vision technology with other existing products.  Although a number of reading assistants have been designed specifically for people who are blind or visually impaired, reading text from complex backgrounds or non-flat surfaces is very challenging and has not yet been successfully addressed. Many everyday tasks involve these challenging conditions, such as reading instructions on vending machines, titles of books aligned on a shelf, instructions on medicine bottles or labels on soup cans.  This proposal focuses on the development of new computer vision algorithms to recognize text from complex backgrounds: 1) from backgrounds with multiple different colors (e.g .. the titles of books lined up on a shelf) and 2) from non-flat surfaces (e.g .. labels on medicine bottles or soup cans). The newly developed computer vision techniques will be integrated with off-the-shelf optical character recognition (OCR) and speech-synthesis software products. Visual information will be captured via a head-mounted camera (on sunglasses or hat) and analyzed by a portable computer (PDA or cell phone), while the speech display will be outputted via mini speakers, earphones, or Bluetooth device. A practical reading system prototype will be produced to read text from complex backgrounds and non-flat surfaces. The system will be cost-effective since it requires only a head mounted camera (<US$100 for 1M resolution), a wearable computer (<US$300), and two mini-speakers or earphones. The price of ""ReadIRlS"" [74] OCR software is under $150 and the ""TextAloud"" speech synthesis software is about $30 [75].  This project will be executed over two years at the City College of New York (CCNY) and Lighthouse International, New York. CCNY, located in the Harlem neighborhood of New York City, is designated as both a Minority Institution and a Hispanic-serving Institution (37% Hispanic and 27% African American). Lighthouse International is a leading non-profit organization dedicated to preserving vision and to providing critically needed vision and rehabilitation services to help people of all ages overcome the challenges of vision loss. During the two years, we will 1) develop new algorithms to recognize text from backgrounds with multiple different colors; 2) develop new algorithms to recognize text from non-flat surfaces; and 3) develop a cost-effective prototype reading system for blind users by integrating with off-the-shelf optical character recognition (OCR) and speech-synthesis software products. The effectiveness of the prototype and algorithms will be evaluated by people with normal vision and people with vision impairment. A database of text on complex backgrounds (multiple colors and non-flat surfaces) will be created for algorithm and system evaluation. The database will be made available to research communities in the areas of computer vision and vision rehabilitation science. In summary, this effort will provide a research-based foundation to inform the design of next generation reading assistants for blind persons, as well as produce a practical prototype to help the blind user read text from complex backgrounds in real-world environments. PROJECT NARRATIVE  The goal of the proposed research is to develop new computer vision algorithms for camera-based text recognition from complex backgrounds and non-flat surfaces, as well as produce a practical reading system prototype in combination with off-the-shelf  optical character recognition (OCR) and speech-synthesis software products, to help blind or visually impaired people read instructions on vending machines, titles of books aligned on a shelf, labels on medicine bottles or soup cans, etc. Visual information will be captured via a head-mounted camera (on sunglasses or hat) and analyzed in realtime through a portable computer, such as a mini laptop or a personal digital assistant (PDA). The speech display will be outputted via mini speakers, earphones, or Bluetooth device.",Camera-based Text Recognition from Complex Backgrounds for the Blind or Visually,7977496,R21EY020990,"['Address', 'African American', 'Age', 'Algorithms', 'Americas', 'Area', 'Blindness', 'Books', 'Cellular Phone', 'Cities', 'Color', 'Communities', 'Complex', 'Computer Systems Development', 'Computer Vision Systems', 'Computer software', 'Computers', 'Databases', 'Development', 'Devices', 'Effectiveness', 'Environment', 'Evaluation', 'Event', 'Facial Expression Recognition', 'Foundations', 'Goals', 'Grant', 'Head', 'Hispanics', 'Image', 'Impairment', 'Individual', 'Institution', 'Instruction', 'International', 'Label', 'Letters', 'Life', 'Mails', 'Marketing', 'Medicine', 'Methods', 'Minority', 'Neighborhoods', 'New York', 'New York City', 'Nonprofit Organizations', 'Output', 'Personal Digital Assistant', 'Price', 'Printing', 'Reading', 'Rehabilitation therapy', 'Research', 'Research Project Grants', 'Resolution', 'Running', 'Scientist', 'Shapes', 'Solutions', 'Speech', 'Surface', 'System', 'Techniques', 'Technology', 'Text', 'Thick', 'Time', 'United States National Institutes of Health', 'Vertebral column', 'Vision', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Writing', 'base', 'blind', 'college', 'computer generated', 'computer human interaction', 'cost', 'design', 'digital', 'experience', 'laptop', 'next generation', 'optical character recognition', 'prototype', 'rehabilitation science', 'rehabilitation service', 'research and development', 'sunglasses', 'technology development', 'visual information']",NEI,CITY COLLEGE OF NEW YORK,R21,2010,190000,-0.02233144143164637
CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation No abstract available n/a,CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8055745,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Arts', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2010,256288,-0.006062469384756679
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,7940934,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Arts', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'public health relevance', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,356202,-0.019957456934419228
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7941984,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2010,303186,-0.013769378297851992
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,7999420,R44RR024094,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'HIV', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2010,449663,-0.04144687062054633
"Replacement Ocular Battery (ROBatt)    DESCRIPTION (provided by applicant): The objective of this grant project is the development and pre-validation of the Replacement Ocular Battery (ROBatt), a tiered testing strategy consisting of a battery of four alternative ocular irritancy assays, which will replace regulatory mandated acute ocular irritation testing using the Draize Rabbit Eye test. ROBatt consists of the Bovine Corneal Opacity and Permeability Assay (BCOP), the Chorioallantoic Membrane Vascular Assay using 10-day fertile chicken eggs (CAMVA), the Porcine Corneal Reversibility Assay (PorCORA) and the Porcine Confocal Assay (PorFocal). This tiered strategy follows a decision tree that allows for a thorough interrogation of possible ocular irritants. Although four assays are recommended, in most cases only two or three will be used depending on the degree of irritation. The Specific Aim of the ROBatt project is to validate the decision tree variables using at least 50 chemicals listed in the European Center for Ecotoxicology and Toxicology of Chemicals (ECETOC) data bank, including Corrosive (EEC R41, GHS/EPA Cat 1), Severe (EEC R36, GHS CaL 2, HMIS 2), Moderate (EPA Cat. 3, HMIS 2), Mild (HMIS 1) and Non-irritating (EPA Cat 4, HMIS 0). The long-term project goal is to submit the ROBatt testing strategy to iCCVAM/ECVAM for consideration as a standalone alternative to the Draize Rabbit Eye test. Validation and acceptance of the ROBatt testing strategy will significantly reduce the number of rabbits used in the toxicological assessment of consumer products, chemicals and raw materials by replacing rabbits with four robust alternative assays.       PUBLIC HEALTH RELEVANCE: Ocular irritation testing is extremely relevant to assuring adequate safety levels of public health as new formulations of chemicals and products are introduced. In most cases, these safety assessments are performed using the Draize Rabbit Eye test, resulting in thousands of rabbits used in testing every year. Alternatives have been discussed since the 80s without any appreciable acceptance from regulators.           n/a",Replacement Ocular Battery (ROBatt),8068095,U01NS073481,"['Acute', 'Biological Assay', 'Blood Vessels', 'Cattle', 'Chemicals', 'Chickens', 'Cornea', 'Corneal Opacity', 'Corrosives', 'Databases', 'Decision Trees', 'Development', 'Drug Formulations', 'European', 'Eye', 'Family suidae', 'Felis catus', 'Goals', 'Grant', 'Instruction', 'Irritants', 'Oryctolagus cuniculus', 'Permeability', 'Public Health', 'Safety', 'Test Result', 'Testing', 'Toxicology', 'Validation', 'chorioallantoic membrane', 'consumer product', 'egg', 'irritation']",NINDS,"MB RESEARCH LABORATORIES, INC.",U01,2010,562935,-0.009635371826356192
"Validation of a Vascular Health Profile for Cardiovascular Disease    DESCRIPTION (provided by applicant):  This application address broad challenge area ""(03) Biomarker Discovery and Validation"" and specific challenge research topic ""03-HL-101* Identify and validate clinically relevant, quantifiable biomarkers of diagnostic and therapeutic responses for blood, vascular, cardiac, and respiratory tract dysfunction."" Treatment paradigms have evolved from studies of patients who, despite similar presentations, may have experienced disparate environmental exposures or clinical courses and may have varied underlying pathobiologies. A developing and exciting biomarker strategy is the measurement of microparticles (MPs) and assessment of circulating progenitor and mature endothelial cells. All eukaryotic cells shed MPs in response to activation or apoptosis and elevation of plasma MPs, particularly those of endothelial origin, reflects cellular injury and is a surrogate marker for vascular dysfunction. Microparticles have been enumerated in a number of conditions where vascular dysfunction and inflammation are important pathophysiological mechanisms, for example coronary artery disease or thrombotic microangiopathies. We recently completed a pilot study evaluating levels of MPs in patients with diabetes mellitus (DM) and compared flow cytometry results with those of a non cell specific Enzyme Linked ImmunoSorbent assay (ELISA). The ELISA assay results correlated with flow cytometry results but did not distinguish the cell of origin where the micoparticle originated. The overall goal of this study is to develop and validate a novel cell-based high throughput, high content, vascular health profile analysis that provides a signature for individuals at high risk for cardiovascular events. A unique biocomputational approach at Penn called cytometric fingerprinting will be used to identify populations of cells. The aims are: 1: To develop and validate a single platform high throughput, multiplexed flow cytometry assay for cell specific MPs, endothelial progenitor cells and hematopoietic progenitors. 2: To develop and validate a cell specific ELISA biomarker assay for MPs in healthy group of subjects and patients with DM and correlate with an independent flow cytometry test for EPCs and HSCs as a dual platform measure of vascular health. 3: To use high order informatics to derive a signature profile from the results of Aims 1 and 2. Such a high throughput high information content approach may prove to be clinically useful in discerning laboratory markers that would be useful for guiding therapy of patients with DM. Penn Medicine contributes substantially to the local economy. In 2008, Penn Medicine created 37,000 jobs and $5.4 billion in regional economic activity, with the area's highly trained workforce producing more than 24,600 applications for just 840 open Penn staff research positions. The current proposal will create or retain 3 jobs. If successfully validated, the biomarker technology proposed could be commercialized, create thousands of jobs in the health care industry and potentially prevent costly hospital admissions. Also, an ELISA for MPs could provide an early evaluation of impact of novel pharmaceutical compounds on vascular health. If successfully validated, the biomarker technology proposed could be commercialized, create thousands of jobs in the health care industry and potentially prevent costly hospital admissions. Also, an ELISA for MPs could provide an early evaluation of impact of novel pharmaceutical compounds on vascular health.       PUBLIC HEALTH RELEVANCE:  If successfully validated, the biomarker technology proposed could be commercialized, create thousands of jobs in the health care industry and potentially prevent costly hospital admissions. Also, an ELISA for MPs could provide an early evaluation of impact of novel pharmaceutical compounds on vascular health.           If successfully validated, the biomarker technology proposed could be commercialized, create thousands of jobs in the health care industry and potentially prevent costly hospital admissions. Also, an ELISA for MPs could provide an early evaluation of impact of novel pharmaceutical compounds on vascular health.",Validation of a Vascular Health Profile for Cardiovascular Disease,7933875,RC1HL099528,"['Address', 'Admission activity', 'Age', 'Apoptosis', 'Area', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Platelets', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cell Count', 'Cell Line', 'Cells', 'Cessation of life', 'Characteristics', 'Clinical', 'Complex', 'Computer Analysis', 'Consensus Development', 'Coronary Arteriosclerosis', 'Data', 'Databases', 'Diabetes Mellitus', 'Diabetic Angiopathies', 'Diagnostic', 'Economics', 'Endothelial Cells', 'Environmental Exposure', 'Enzyme-Linked Immunosorbent Assay', 'Eukaryotic Cell', 'Evaluation', 'Event', 'Fingerprint', 'Flow Cytometry', 'Functional disorder', 'Gender', 'Goals', 'Health', 'Healthcare Industry', 'Hematopoietic stem cells', 'Hospitals', 'Impact evaluation', 'Individual', 'Inflammation', 'Informatics', 'Knowledge', 'Laboratory Markers', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Monitor', 'Occupations', 'Pathogenesis', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pilot Projects', 'Plasma', 'Play', 'Population', 'Populations at Risk', 'Positioning Attribute', 'Process', 'Publishing', 'Reporting', 'Research', 'Respiratory System', 'Respiratory tract structure', 'Risk', 'Role', 'Stem cells', 'Surrogate Markers', 'Systems Analysis', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Validation', 'Venous blood sampling', 'Work', 'base', 'cardiovascular risk factor', 'cell injury', 'clinical practice', 'clinically relevant', 'disease classification', 'experience', 'flexibility', 'high risk', 'macrovascular disease', 'monocyte', 'novel', 'prevent', 'progenitor', 'public health relevance', 'response', 'success']",NHLBI,UNIVERSITY OF PENNSYLVANIA,RC1,2010,476051,-0.042607654390878644
"Automated Biodosimetry The Unites States Government and Federal agencies have estimated that over 1 million people may seek information on their personal risk (radiation exposure level), if an event (such as a 10 kiloton detonation of an improvised nuclear device) occurs in a large metropolitan area. There will be a need for immediate triage and rapid cytogenetic biodosimetry for estimation of whole-body dose (<2Gy, 2-4Gy, >4Gy) of individuals within 48 hours, to determine and categorize the exposed cohorts for dose based stratification and effective medical management. Individuals exposed at levels exceeding 2 Gy will need immediate treatment and further evaluation with more sophisticated and precise dosimetry tools (such as devices, bioassays, biomarkers etc) to ascertain their absorbed dose.    Several of these established available assays are very labor intensive (demands skilled personnel; cytogeneticist) and time consuming (days to weeks), which serves to be a bane during a mass-casualty event. Effective medical management, response and treatment to the exposed cohort (within a short time window) can only be maximized and achieved with the aid of robotic tools and automated system. Automated cytogenetic systems can also reduce significant level of human error caused by fatigue due to the magnitude of samples to be processed. The Automated Cytogenetics Laboratory at AFRRI, focuses on automation of various classical biodosimerty assays (Dicentric Chromosomes, Micronuclei, PCC assays etc) to effectively enhance the throughput of sample analysis, thereby medical management. n/a",Automated Biodosimetry,8172179,1OD0505,"['Area', 'Artificial Intelligence', 'Automation', 'Biological Assay', 'Biological Markers', 'Biological Neural Networks', 'Cytogenetics', 'Devices', 'Dicentric chromosome', 'Documentation', 'Dose', 'Evaluation', 'Event', 'Fatigue', 'Hour', 'Human', 'Human Resources', 'Image Analysis', 'Individual', 'Laboratories', 'Medical', 'Metaphase', 'Modeling', 'Nuclear', 'Process', 'Radiation', 'Risk', 'Robotics', 'Sampling', 'State Government', 'Stratification', 'System', 'Systems Analysis', 'Testing', 'Time', 'Triage', 'United States', 'Variant', 'base', 'biodosimetry', 'cohort', 'dosimetry', 'handheld mobile device', 'metropolitan', 'micronucleus', 'tool', 'treatment response']",OD,"OFFICE OF THE DIRECTOR, NATIONAL INSTITUTES OF HEALTH",Y01,2010,698597,-0.013952253278928512
"Enhancing 3dsvm to improve its interoperability and dissemination    DESCRIPTION (provided by applicant): This research plan outlines crucial software enhancements to a program called 3dsvm, which is a command line program and graphical user interface (gui) plugin for AFNI (Cox, 1996). 3dsvm performs support vector machine (SVM) analysis on fMRI data, which constitutes one important approach to performing multivariate supervised learning of neuroimaging data. 3dsvm originally provided the ability to analyze fMRI data as described in (LaConte et al., 2005). Since its first distribution as a part of AFNI, it has been steadily extended to provide new functionality including regression and non-linear kernels, as well as multiclass classification capabilities. In addition to its integration into AFNI, features that make 3dsvm particularly well suited for fMRI analysis are that it is easy to spatially mask voxels (to include/exclude them in the SVM analysis) as well as to flexibly select subsets of a dataset to use as training or testing samples. It has been used to generate results for our own work and for collaborative efforts and has been cited as a resource by others (Mur et al. 2009; Hanke et al. 2009). Despite many positive aspects of 3dsvm, the priorities of PAR-07-417 address a genuine need that this software project has - the ability to focus on improvements that will increase its dissemination and interoperability. A major motivation for PAR-07-417 is to facilitate the improved interface, characterization, and documentation to enhance the extent of sharing and to provide the groundwork for future extensions. Our aims are well aligned with this program announcement. Further, there is a growing need in the neuroimaging community for tools such as 3dsvm. Since 3dsvm is not a new project, is tightly integrated into the software environment of AFNI, and can be further integrated to enable better functionality to support needs as diverse as NIfTI format capabilities to rtFMRI, this proposed project will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.      PUBLIC HEALTH RELEVANCE: This proposal focuses on improving, characterizing, and documenting an existing neuroinformatics software tool. The project described will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.           NARRATIVE This proposal focuses on improving, characterizing, and documenting an existing neuroinformatics software tool. The project described will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.",Enhancing 3dsvm to improve its interoperability and dissemination,8278135,R03EB012464,[' '],NIBIB,VIRGINIA POLYTECHNIC INST AND ST UNIV,R03,2010,156500,-0.016668093651692566
"Measuring real time decision-making about UVR Protection    DESCRIPTION (provided by applicant): The development of interventions to maximize consistency in ultraviolet radiation (UVR) protection rests on improved understanding of decision-making factors that contribute to daily variation in UVR protection. In this study, we use Ethnographic Decision Tree Modeling to examine decision-making regarding sunscreen use, shade-seeking, and UVR protection behavior in melanoma first-degree relatives (FDRs). In Phase I, we will generate the models via qualitative ethnographic interviews with 25 melanoma FDRs, and then will construct a composite decision-making model for each of the three UVR protection outcomes. In Phase II we will establish the validity of the models using ecological momentary assessment of UVR protection (over 14 summer days, at 1 pm and 5 pm daily) in 60 FDRs. We will recruit equal numbers of women and men, and equal numbers of those who perceive high and low advantages of tanning, given the importance of these predictors for UVR protection. Specific Aim I is to generate and establish the validity of the models explaining decision-making about three UVR protection behaviors (sunscreen use, shade-seeking, use of protective clothing) in melanoma FDRs, and Specific Aim II is to examine theory-driven affective and cognitive predictors of sun protection maintenance (sunscreen use, shade-seeking, and use of sun protective clothing) assessed in real time. We adopt a theory-informed approach to decision-making, and so expect that the factors identified inductively in Phase I, as well as between- and within-subject variation in melanoma threat, efficacy beliefs, and satisfaction with UVR protection drawn from Witte's Extended Parallel Processing Model and Rothman's theory of health behavior maintenance will predict UVR protection behaviors. We will also examine gender and tanning attitudes as covariates of these effects. The study findings will increase our understanding of the decision- making context for behavioral maintenance of UVR protection, and dictate novel intervention strategies to reduce behavioral inconsistency - and increase behavioral maintenance - of UVR protection in those at high risk for melanoma. PUBLIC HEALTH RELEVANCE: This study will examine daily UVR protection and decision-making about protection in 60 first degree family members of melanoma patients who complete 14-day diaries via personal digital assistants and audio-taped narratives. We will employ qualitative and quantitative research strategies and determine between and within- person variability in UVR protection and decision-making that will inform the development of interventions to increase UVR protection maintenance among those who are at risk for melanoma.                    Narrative This study will examine daily UVR protection and decision-making about protection in 60 first degree family members of melanoma patients who complete 14-day diaries via personal digital assistants and audio-taped narratives. We will employ qualitative and quantitative research strategies and determine between and within- person variability in UVR protection and decision-making that will inform the development of interventions to increase UVR protection maintenance among those who are at risk for melanoma.",Measuring real time decision-making about UVR Protection,7884453,R21CA137532,"['Adopted', 'Affective', 'Anthropology', 'Area', 'Attitude', 'Behavior', 'Behavioral', 'Belief', 'Clothing', 'Cognitive', 'Decision Making', 'Decision Trees', 'Development', 'Ethnography', 'Family member', 'First Degree Relative', 'Gender', 'General Population', 'Guidelines', 'Health', 'Health behavior', 'Individual', 'Intervention', 'Interview', 'Maintenance', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Outcome Study', 'Patients', 'Performance', 'Personal Digital Assistant', 'Persons', 'Phase', 'Physical activity', 'Process', 'Protective Clothing', 'Psychology', 'Radiation Protection', 'Recruitment Activity', 'Reporting', 'Research', 'Rest', 'Risk', 'Risk Factors', 'Risk Reduction', 'Role', 'Skin Cancer', 'Skin tanning', 'Sunburn', 'Sunscreening Agents', 'Technology Assessment', 'The Sun', 'Time', 'Ultraviolet Rays', 'Variant', 'Woman', 'behavioral/social science', 'cancer risk', 'design', 'diaries', 'good diet', 'high risk', 'improved', 'innovation', 'melanoma', 'men', 'modifiable risk', 'novel', 'parallel processing', 'public health relevance', 'satisfaction', 'success', 'sun protection', 'theories', 'therapy development', 'uptake']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R21,2010,125136,-0.023601287443234135
"Computational Methods for Analysis of Mouth Shapes in Sign Languages    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hand) and by the nonmanual components (the face). These facial articulations perform significant semantic, prosodic, pragmatic, and syntactic functions. This proposal will systematically study mouth positions in ASL. Our hypothesis is that ASL mouth positions are more extensive than those used in speech. To study this hypothesis, this project is divided into three aims. In our first aim, we hypothesize that mouth positions are fundamental for the understanding of signs produced in context because they are very distinct from signs seen in isolation. To study this we have recently collected a database of ASL sentences and nonmanuals in over 3600 video clips from 20 Deaf native signers. Our experiments will use this database to identify potential mappings from visual to linguistic features. To successfully do this, our second aim is to design a set of shape analysis and discriminant analysis algorithms that can efficiently analyze the large number of frames in these video clips. The goal is to define a linguistically useful model, i.e., the smallest model that contains the main visual features from which further predictions can be made. Then, in our third aim, we will explore the hypothesis that the linguistically distinct mouth positions are also visually distinct. In particular, we will use the algorithms defined in the second aim to determine if distinct visual features are used to define different linguistic categories. This result will show whether linguistically meaningful mouth positions are not only necessary in ASL (as hypothesized in aim 1), but whether they are defined using non-overlapping visual features (as hypothesized in aim 3). These aims address a critical need. At present, the study of nonmanuals must be carried out manually, that is, the shape and position of each facial feature in each frame must be recorded by hand. Furthermore, to be able to draw conclusive results for the design of a linguistic model, it is necessary to study many video sequences of related sentences as produced by different signers. It has thus proven nearly impossible to continue this research manually. The algorithms designed in the course of this grant will facilitate this analysis of ASL nonmanuals and lead to better teaching materials.      PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.           Project Narrative Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the non-manuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for Analysis of Mouth Shapes in Sign Languages,8101448,R21DC011081,"['Academic achievement', 'Access to Information', 'Address', 'Adult', 'Algorithms', 'Applications Grants', 'Arts', 'Categories', 'Child', 'Clip', 'Communication', 'Communities', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Databases', 'Devices', 'Discriminant Analysis', 'Educational process of instructing', 'Emotions', 'Excision', 'Eye', 'Face', 'Funding', 'Goals', 'Grant', 'Hand', 'Hearing', 'Hearing Impaired Persons', 'Human', 'Image', 'Individual', 'Joints', 'Knowledge', 'Language', 'Lead', 'Learning', 'Life', 'Linguistics', 'Manuals', 'Modeling', 'Oral cavity', 'Parents', 'Pattern Recognition', 'Positioning Attribute', 'Process', 'Regulation', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Science', 'Scientist', 'Semantics', 'Shapes', 'Sign Language', 'Social Interaction', 'Specific qualifier value', 'Speech', 'Teaching Materials', 'Technology', 'Testing', 'Training', 'United States National Institutes of Health', 'Visual', 'Work', 'computerized tools', 'deafness', 'design', 'experience', 'innovation', 'instructor', 'interest', 'novel', 'prevent', 'public health relevance', 'research study', 'shape analysis', 'success', 'syntax', 'teacher', 'tool', 'visual map']",NIDCD,OHIO STATE UNIVERSITY,R21,2010,187999,-0.07739442121905131
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,7777764,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Arts', 'Blindness', 'Central Scotomas', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Data', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2010,527186,0.0016032855615153504
"Recursive partitioning and ensemble methods for classifying an ordinal response    DESCRIPTION (provided by applicant):       Classification methods applied to microarray data have largely been those developed by the machine learning community, since the large p (number of covariates) problem is inherent in high-throughput genomic experiments. The random forest (RF) methodology has been demonstrated to be competitive with other machine learning approaches (e.g., neural networks and support vector machines). Apart from improved accuracy, a clear advantage of the RF method in comparison to most machine learning approaches is that variable importance measures are provided by the algorithm. Therefore, one can assess the relative importance each gene has on the predictive model. In a large number of applications, the class to be predicted may be inherently ordinal. Examples of ordinal responses include TNM stage (I,II,III, IV); drug toxicity (none, mild, moderate, severe); or response to treatment classified as complete response, partial response, stable disease, and progressive disease. These responses are ordinal; while there is an inherent ordering among the responses, there is no known underlying numerical relationship between them. While one can apply standard nominal response methods to ordinal response data, in so doing one loses the ordered information inherent in the data. Since ordinal classification methods have been largely neglected in the machine learning literature, the specific aims of this proposal are to (1) extend the recursive partitioning and RF methodologies for predicting an ordinal response by developing computational tools for the R programming environment; (2) evaluate the proposed ordinal classification methods against alternative methods using simulated, benchmark, and gene expression datasets; (3) develop and evaluate methods for assessing variable importance when interest is in predicting an ordinal response. Novel splitting criteria for classification tree growing and methods for estimating variable importance are proposed, which appropriately take the nature of the ordinal response into consideration. In addition, the Generalized Gini index and ordered twoing methods will be studied under the ensemble learning framework, which has not been previously conducted. This project is significant to the scientific community since the ordinal classification methods to be made available from this project will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect responses on an ordinal scale.           n/a",Recursive partitioning and ensemble methods for classifying an ordinal response,7670456,R03LM009347,"['Algorithms', 'Behavioral Research', 'Benchmarking', 'Biological Neural Networks', 'Classification', 'Communities', 'Data', 'Data Analyses', 'Data Set', 'Discriminant Analysis', 'Drug toxicity', 'Environment', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Health', 'Health Surveys', 'Image Analysis', 'In complete remission', 'Individual', 'Learning', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Neoplasm Metastasis', 'Northern Blotting', 'Outcome', 'Performance', 'Process', 'Progressive Disease', 'Relative (related person)', 'Simulate', 'Stable Disease', 'Staging', 'Structure', 'Technology', 'Time', 'Trees', 'computerized tools', 'forest', 'improved', 'indexing', 'interest', 'neglect', 'novel', 'partial response', 'predictive modeling', 'programs', 'research study', 'response', 'social', 'tumor']",NLM,VIRGINIA COMMONWEALTH UNIVERSITY,R03,2009,74750,-0.020803573164579776
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7560409,R01NS051826,"['Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Back', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Disease', 'Disease Progression', 'Evaluation', 'Fetal Growth Retardation', 'Goals', 'Gold', 'Human', 'Image', 'Imagery', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Modeling', 'Neonatal', 'Normal Range', 'Operative Surgical Procedures', 'Patients', 'Population', 'Population Study', 'Process', 'Research', 'Schizophrenia', 'Shapes', 'Statistical Distributions', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'Variant', 'base', 'computer studies', 'disease classification', 'feeding', 'improved', 'neonate', 'nervous system disorder', 'normal aging', 'novel', 'shape analysis', 'tool']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2009,280500,-0.01091487786835338
"Accessible Artificial Intelligence Tutoring Software for Mathematics    DESCRIPTION (provided by applicant): This Fast-Track application focuses on developing the first artificial intelligence (AI) educational software to teach developmental mathematics to the blind and visually impaired. This project responds to the National Eye Institute's General Research Topics for ""teaching tools"" and the Visual Impairment and Blindness Program for ""other devices that meet the rehabilitative and everyday living needs of persons who are blind or have low vision."" The intervention being developed will place a comprehensive set of AI mathematics tutoring systems with integrated AI assessment capabilities in the hands of the blind K-12, college and adult student, for use on demand during study at home and at school. The formulation of an advanced AI tutoring methodology with accessibility inherent to its design will have broad implications for development in many subject areas beyond mathematics. Project objectives include: Horizontal Expansion of Accessible Curriculum Content Coverage (Ratio and Proportion, Percentages, Linear Equations, Metric Units, Scientific Notation) 1) Conduct initial accessibility review and analysis of AI tutor's existing user interface. 2) Implement accessibility requirements and recommendations from NFB, instructors and other partners. 3) Conduct final review to gain NFB accessibility certification after implementation of requirements. 4) Develop and issue survey of instructors on mathematics pedagogy and technology. Vertical Expansion of Accessible Features and Technological Capability 5) Implement Braille support in AI technology. 6) Develop additional AI tutor on Fractions that is automatically accessible from first principles using accessible AI framework. Evaluation of Accessible AI Educational Technology 7) Field evaluation of accessible AI technology with blind students and their instructors. 8) Continued demonstration and review of accessible AI technology by partners and other stakeholders. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum already has long-term partnerships established with McGraw- Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as a major science education catalog company, CyberEd, Inc., a PLATO Learning Company. PUBLIC HEALTH RELEVANCE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.           PROJECT NARRATIVE: There is a considerable need for improved educational software for mathematics in general, but the problem of quality educational software materials for the blind and visually impaired is particularly acute. A weak mathematics background can cause unnecessary limitations in daily living activities and seriously hinder or even preclude effective pursuit of more advanced mathematics education and careers in the STEM fields of science, technology, engineering and mathematics. Through previous federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom artificial intelligence (AI) tutoring systems for developmental mathematics. The goal of this Fast-Track project is to bring the full power and benefit of this cutting-edge educational technology to students who are blind and visually impaired.",Accessible Artificial Intelligence Tutoring Software for Mathematics,7608855,R44EY019414,"['Activities of Daily Living', 'Acute', 'Address', 'Adult', 'American', 'Area', 'Artificial Intelligence', 'Blindness', 'Businesses', 'Cataloging', 'Catalogs', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Collaborations', 'Computer software', 'Country', 'Development', 'Development Plans', 'Devices', 'Dimensions', 'Drug Formulations', 'Dyslexia', 'Education', 'Educational Curriculum', 'Educational Technology', 'Educational process of instructing', 'Elements', 'Engineering', 'Ensure', 'Equation', 'Equilibrium', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Language', 'Learning', 'Letters', 'Life', 'Mathematics', 'Measures', 'Mediation', 'Methodology', 'Metric', 'Mission', 'Modeling', 'National Eye Institute', 'Nature', 'Outcome', 'Performance', 'Persons', 'Phase', 'Philosophy', 'Play', 'Preparation', 'Printing', 'Process', 'Publishing', 'Reader', 'Reading Disabilities', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Research Support', 'Role', 'Schools', 'Science', 'Small Business Innovation Research Grant', 'Software Tools', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Visual impairment', 'Work', 'blind', 'braille', 'career', 'college', 'commercial application', 'commercialization', 'design', 'disability', 'high school', 'improved', 'innovation', 'innovative technologies', 'instructor', 'meetings', 'middle school', 'programs', 'prospective', 'prototype', 'public health relevance', 'quantum', 'quantum chemistry', 'remediation', 'research and development', 'science education', 'simulation', 'stem', 'success', 'teacher', 'technological innovation', 'tool']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2009,164486,-0.016835232443886648
"Recursive partitioning and ensemble methods for classifying an ordinal response    DESCRIPTION (provided by applicant): This proposal is submitted in response to NOT-OD-09-058 NIH Announces the Availability of Recovery Act Funds for Competitive Revision Applications. Health status and outcomes are frequently measured on an ordinal scale. Examples include scoring methods for liver biopsy specimens from patients with chronic hepatitis, including the Knodell hepatic activity index, the Ishak score, and the METAVIR score. In addition, tumor-node-metasis stage for cancer patients is an ordinal scaled measure. Moreover, the more recently advocated method for evaluating response to treatment in target tumor lesions is the Response Evaluation Criteria In Solid Tumors method, with ordinal outcomes defined as complete response, partial response, stable disease, and progressive disease. Traditional ordinal response modeling methods assume independence among the predictor variables and require that the number of samples (n) exceed the number of covariates (p). These are both violated in the context of high-throughput genomic studies. Our currently funded R03 grant, ""Recursive partitioning and ensemble methods for classifying an ordinal response,"" consists of the following three specific aims (SA.1) extend the recursive partitioning and random forest classification methodologies for predicting an ordinal response by developing computational tools for the R programming environment including implementing our ordinal impurity criteria in rpart and implementing the ordinal impurity criteria in randomForest; (SA.2) evaluate the proposed ordinal classification methods in comparison to existing nominal and continuous response methods using simulated, benchmark, and gene expression datasets; and (SA.3) develop and evaluate methods for assessing variable importance when interest is in predicting an ordinal response. Recently, penalized models have been successfully applied to high-throughput genomic datasets in fitting linear, logistic, and Cox proportional hazards models with excellent performance. However, extension of penalized models to the ordinal response setting has not been described. Herein we propose to extend the L1 penalized method to ordinal response models to enable modeling of common ordinal response data when a high-dimensional genomic data comprise the predictor space. This study will expand the scope of our current research by providing a model-based ordinal classification methodology applicable for high-dimensional datasets to accompany the heuristic based classification tree and random forest ordinal methodologies considered in the parent grant. The specific aims of this competitive revision application are to: Aim 1) Extend the L1 penalized methodology to enable predicting an ordinal response by developing computational tools for the R programming environment; Aim 2) Using simulated, benchmark, and gene expression datasets, evaluate L1 penalized ordinal response models by comparing error rates from our L1 fitting algorithm to those obtained when using a forward variable selection modeling strategy and our ordinal random forest approach; and Aim 3) Evaluate methods for assessing important covariates from L1 penalized ordinal response models.           This project will develop L1 penalized ordinal response models and implement them in the R programming environment. By conducting extensive comparisons of various ordinal response modeling methods using simulated, benchmark, and gene expression datasets, we will be able to make a recommendation regarding ordinal response modeling to the scientific community. This research is significant since the ordinal response modeling methods developed during the project period will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect responses on an ordinal scale.",Recursive partitioning and ensemble methods for classifying an ordinal response,7805045,R03LM009347,"['Advocate', 'Algorithms', 'Applications Grants', 'Area', 'Behavioral Research', 'Benchmarking', 'Bioconductor', 'Biopsy Specimen', 'Cancer Patient', 'Chronic Hepatitis', 'Classification', 'Clinical', 'Communities', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Data Set', 'Drug toxicity', 'Economics', 'Education', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Gene Expression', 'Genomics', 'Grant', 'Health', 'Health Status', 'Health Surveys', 'Hepatic', 'Human', 'In complete remission', 'Informatics', 'Lesion', 'Literature', 'Location', 'Logistics', 'Machine Learning', 'Mathematics', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neoplasm Metastasis', 'Occupations', 'Outcome', 'Patients', 'Performance', 'Positioning Attribute', 'Progressive Disease', 'Recommendation', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Sample Size', 'Sampling', 'Science', 'Scoring Method', 'Simulate', 'Solid Neoplasm', 'Stable Disease', 'Staging', 'Technology', 'Translational Research', 'Travel', 'Trees', 'United States National Institutes of Health', 'base', 'computerized tools', 'cost', 'forest', 'heuristics', 'improved', 'indexing', 'interest', 'liver biopsy', 'meetings', 'neglect', 'novel', 'parent grant', 'partial response', 'preference', 'programs', 'research study', 'response', 'simulation', 'social', 'software development', 'symposium', 'tool', 'tumor']",NLM,VIRGINIA COMMONWEALTH UNIVERSITY,R03,2009,75000,-0.032509469390520865
"Robust BCT for Clinical Use    DESCRIPTION (provided by applicant): Osteoporosis is a major public health threat for over 50% of the population over age 50. Despite its importance, osteoporosis is largely under-treated, with less than 20% of those recommended for testing being screened. With substantial reimbursement cuts being introduced by Medicare for bone densitometry by dual energy X-ray absorptiometry (DXA, the current clinical standard), with a sensitivity of DXA for fracture prediction of less than 50%, and with the rapidly increasing size of the aging population of the U.S., there is an urgent need for additional and more sensitive modalities than DXA for clinical assessment of fracture risk. Biomechanical Computed Tomography (BCT) has emerged as a powerful alternative to DXA. This CT-based technology creates a structural ""finite element"" model of a patient's bone from their CT scans, and subjects that model to virtual forces in order to provide an estimate of the strength of the bone. Well validated in cadaver studies and being a better predictor of bone strength than is bone mineral density by DXA, BCT has also been shown to be highly predictive of osteoporotic fractures in clinical research studies. However, robustness remains an issue - can the technique be used easily by non-experts in research and clinical environments? Addressing this issue, the overall goal of this research is to improve the robustness of our software, such that it can automatically analyze scans from a wide range of CT scanners and using a wide variety of CT acquisition protocols, including new low-dose protocols that limit radiation exposure to the patient. Such a robust BCT diagnostic tool could then be offered as a supplementary ""add-on"" analysis to many types of CT exams taken for other purposes such as CT colonography, pelvic, abdominal, and spine exams, thus reducing hospital costs, incurring no addition radiation to the patient, requiring no change in the CT acquisition protocols, and therefore greatly increasing the number of patients that could be screened at low cost. Specifically, we propose in this Phase-I project to combine expertise in computer vision, CT scanning, and biomechanics in order to develop an automated method of ""phantomless"" cross-calibration of CT scans for robust vertebral strength assessment. Focusing on the spine, our major tasks are to perform a series of clinical studies in which patients are scanned twice using a variety of CT acquisition protocols; develop a custom external-calibration phantom and use that to determine the effects of various CT acquisition parameters on scanning standardization; and use machine learning techniques to develop a ""statistical atlas"" of the spine for automation of all image processing. We will combine these efforts to develop a phantomless BCT method that accounts for differences in image quality due to variations in CT scanners and acquisition protocols, including low-dose protocols, and that does so in a highly automated fashion requiring minimal user expertise and input. Should this project be successful, future work will further refine the techniques, extend them to the hip and quantitative analysis of muscle and other soft tissues, and address robustness of longitudinal changes for clinical monitoring.  PUBLIC HEALTH RELEVANCE: With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.           Statement of Relevance With a mortality rate up to 30% one year after hip fracture, and an economic burden exceeding $17 billion annually, osteoporotic fracture is a debilitating condition whose impact on our aging society is growing. Early identification of those at risk for fracture can guide prevention and treatment, and BCT will provide a means for such detection with a sensitivity and specificity lacking in DXA based bone densitometry. The greater radiation exposure from CT, however, limits the market for such a diagnostic. The proposed project will result in a robust diagnostic test that significantly lowers radiation dose to the patient, and in some implementations, completely eliminates additional radiation by using CT scans already ordered for other medical purposes. Successful development of this product will broaden the pool of individuals who will benefit from a more accurate and sensitive fracture risk prediction, expand the market for O. N. Diagnostics' business, and result in an important advance in the preventative care and treatment of osteoporosis.",Robust BCT for Clinical Use,7747873,R43AR057616,"['Abdomen', 'Accounting', 'Address', 'Adoption', 'Affect', 'Age', 'Aging', 'Algorithms', 'Angiography', 'Atlases', 'Automation', 'Biomechanics', 'Bone Density', 'Businesses', 'Cadaver', 'Calibration', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Densitometry', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Dose', 'Dual-Energy X-Ray Absorptiometry', 'Early identification', 'Economic Burden', 'Elderly', 'Elements', 'Environment', 'Exposure to', 'Fracture', 'Future', 'Goals', 'Growth', 'Guide prevention', 'Healthcare', 'Healthcare Systems', 'Hip Fractures', 'Hip region structure', 'Hospital Costs', 'Image', 'Individual', 'Intervertebral disc structure', 'Low Dose Radiation', 'Lung', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Medicare', 'Methods', 'Minerals', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Muscle', 'Osteoporosis', 'Outcome', 'Patients', 'Pelvis', 'Performance', 'Phase', 'Population', 'Postmenopause', 'Protocols documentation', 'Public Health', 'Radiation', 'Research', 'Research Personnel', 'Risk', 'Scanning', 'Screening procedure', 'Second lumbar vertebra', 'Sensitivity and Specificity', 'Series', 'Societies', 'Standardization', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Tube', 'Variant', 'Vertebral column', 'Woman', 'Work', 'X-Ray Computed Tomography', 'aging population', 'base', 'bone', 'bone strength', 'cohort', 'cost', 'cost effective', 'image processing', 'improved', 'meetings', 'mortality', 'novel', 'osteoporosis with pathological fracture', 'product development', 'public health relevance', 'reconstruction', 'research study', 'soft tissue', 'spine bone structure', 'tool', 'treatment effect', 'virtual', 'voltage']",NIAMS,"O. N. DIAGNOSTICS, LLC",R43,2009,350000,-0.02329080324127971
"Decision Support in the Care of Preterm Newborns-Tool Development    DESCRIPTION (provided by applicant): Even after many advances in ventilator management, prediction of extubation outcome for a mechanically ventilated premature infant with respiratory distress syndrome (RDS) remains a challenging task for clinicians. We recently developed a machine-learned model (an Artificial Neural Network, ANN) to assist in decision- making regarding extubation of premature newborns (Mueller et al., 2004, 2006). The ANN model was found to perform with accuracy comparable to that of experienced clinicians; however, this approach needs to be compared to equally powerful machine-learning approaches before it can be evaluated in clinical practice. An appropriately validated decision-support tool could help in reducing the number of days a premature infant spends on a mechanical ventilator, and hence the risk of developing short and long-term side effects of mechanical ventilation, resulting in a corresponding decrease in overall health care costs.    In this R21 proposal, we will use several machine-learning approaches combined as a committee formation to obtain the best prediction of extubation success for a given infant. Further, we will build on the previously developed ANN prototype to create an enhanced decision support tool by developing data representation, storage, management, and most important, causal inference, which will enable effective integration of the resulting web-based decision-support tool with clinical practice. This last feature is only possible due to the integrated nature of the proponents themselves, which range from data structure and mathematical modeling experts to experienced neonatologists with a well established working relationship. The proposed effort aims at using advanced modeling tools for translational research by developing a web-based decision-support tool to aid primarily inexperienced clinicians in their decision-making and by promoting interoperability and data exchange among researchers in this field. The critical feature of this infrastructure is its web-based nature, which enables clinicians to evaluate a predictor's accuracy and parametric sensitivity individually for each neonate without having to use any other software than a web-browser. Such a prediction model will be of critical value not only to increase overall clinical accuracy but also to identify effective measures of validity of the original predictions.    The overall aim of this study is to develop a high performing web-based prediction system to use as a decision-support tool in clinical practice and to promote interoperability, and thus, data sharing and interaction among researchers in the neonatal community.    PUBLIC HEALTH RELEVANCE: Predicting extubation outcome in premature infants on mechanical ventilators remains a challenging task even for experienced clinicians. In the proposed work, we aim to provide a sophisticated web-based tool that uses a machine-learning committee comprised of artificial neural networks (ANN), support vector machines (SVM), naive Bayesian classifiers (NBC), influence diagrams (ID), boosted decision trees (BDT) and multivariable logistic regression (MLR) to assist primarily inexperienced clinicians in the decision-making. For the implementation of this tool we propose to develop an XML schema and RDFS model that can promote interoperability, and thus, data sharing and interaction among researchers in the neonatal community.          n/a",Decision Support in the Care of Preterm Newborns-Tool Development,7665362,R21HL090598,"['Adverse effects', 'Arts', 'Biological Neural Networks', 'Caring', 'Characteristics', 'Clinical', 'Committee Members', 'Communities', 'Computer software', 'Data', 'Data Storage and Retrieval', 'Decision Making', 'Decision Trees', 'Development', 'Evaluation', 'Extensible Markup Language', 'Health Care Costs', 'Infant', 'Information Resources Management', 'Internet', 'Language', 'Logistic Regressions', 'Machine Learning', 'Measures', 'Mechanical Ventilators', 'Mechanical ventilation', 'Methods', 'Modeling', 'Nature', 'Neonatal', 'Neonatal Intensive Care Units', 'Neural Network Simulation', 'Newborn Infant', 'Online Systems', 'Outcome', 'Performance', 'Premature Infant', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'System', 'Translational Research', 'Ventilator', 'Work', 'caregiving', 'clinical practice', 'data exchange', 'data mining', 'data sharing', 'data structure', 'experience', 'interoperability', 'mathematical model', 'member', 'neonate', 'premature', 'prototype', 'public health relevance', 'respiratory distress syndrome', 'routine care', 'success', 'tool', 'tool development', 'web based interface']",NHLBI,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R21,2009,185389,-0.03674652760802746
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7577491,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2009,342223,-0.018900775503569247
"High-Throughput Computing for a Multi-Plan Framework in Radiotherapy    DESCRIPTION (provided by applicant):    Computerized planning for radiation delivery via either external beam radiation therapy (EBRT) or intensity- modulated radiation therapy (IMRT) from linear accelerators is a complex process involving a large amount of input data and vast numbers of decision variables. Such large-scale combinatorial optimization problems are typically intractable for conventional approaches such as the direct application of the best available commercial algorithms, and thus specialized methods that take advantage of problem structure are required. Radiation treatment planning (RTP) problems are further complicated by the fact that they are multi-objective, that is, the RTP optimization process must take into account a trade-off between the competing goals of delivering appropriate doses to the tumor and avoiding the delivery of harmful radiation to nearby healthy organs. The goal of this proposal is to harness distributive computing via the Condor system for High Throughput Computing (HTC) within an RTP environment. The specific aims for this proposal are: 1) To develop a Nested Partitions (NP) framework that guides a global search process for optimal IMRT delivery parameters using HTC. 2) To develop parallel HTC-based linear programming (LP) methods to efficiently solve the dose optimization problem in IMRT for each given set of beam angles or beam apertures. (3) To exploit a high-throughput computing (HTC) environment and the developed NP/LP/segmentation framework to efficiently generate multiple plans for each given patient case. (4) To couple this multi-plan framework with a decision support system (DSS) that includes planning surface models, a graphical-user-interface (GUI) and machine learning tools to prediction OAR complication in order to aid in the ranking and selection of the generated treatment plans. This proposal requires a multi-disciplinary approach that is best conducted within the framework of the Innovations in Biomedical Computational Science and Technology program announcement. It brings together an interdisciplinary team of investigators with expertise in medical physics, mathematical programming, industrial engineering and clinical radiation oncology that is crucial to the development of the proposed multi- plan framework using HTC in radiation therapy. PUBLIC HEALTH RELEVANCE: The goal of this proposal is to develop a multi-dimensional platform for sophisticated treatment planning of radiation delivery. It will develop novel algorithms that will enable generation of superior treatment plans with the added advantage of increasing the speed of treatment planning. Further, it will allow physicians to know beforehand the quality of the treatment plan relative to the multiple treatment objectives and be able to determine the treatment complication scenario beforehand.           PROJECT NARRATIVE The goal of this proposal is to develop a multi-dimensional platform for sophisticated treatment planning of radiation delivery. It will develop novel algorithms that will enable generation of superior treatment plans with the added advantage of increasing the speed of treatment planning. Further, it will allow physicians to know beforehand the quality of the treatment plan relative to the multiple treatment objectives and be able to determine the treatment complication scenario beforehand.",High-Throughput Computing for a Multi-Plan Framework in Radiotherapy,7736445,R01CA130814,"['Accounting', 'Algorithms', 'Behavior', 'Clinical Engineering', 'Collection', 'Complex', 'Complication', 'Computational Science', 'Data', 'Decision Support Systems', 'Dependence', 'Development', 'Dose', 'Engineering', 'Environment', 'External Beam Radiation Therapy', 'Generations', 'Genetic Programming', 'Goals', 'Intensity-Modulated Radiotherapy', 'Knowledge', 'Lead', 'Linear Accelerator Radiotherapy Systems', 'Linear Programming', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Modeling', 'Monte Carlo Method', 'NIH Program Announcements', 'Organ', 'Patients', 'Physicians', 'Physics', 'Process', 'Property', 'Radiation', 'Radiation Oncology', 'Radiation therapy', 'Relative (related person)', 'Research Personnel', 'Risk', 'Sampling', 'Shapes', 'Simulate', 'Solutions', 'Speed', 'Structure', 'Surface', 'System', 'Technology', 'Time', 'Toxic effect', 'base', 'cluster computing', 'combinatorial', 'computer science', 'computerized', 'computing resources', 'direct application', 'graphical user interface', 'heuristics', 'improved', 'innovation', 'insight', 'novel', 'novel strategies', 'predictive modeling', 'process optimization', 'programs', 'public health relevance', 'research clinical testing', 'tool', 'treatment planning', 'tumor']",NCI,UNIVERSITY OF MARYLAND BALTIMORE,R01,2009,317367,-0.034234854755252044
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7582301,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2009,2057843,-0.019472393955964073
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7652508,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'intelligence genetics', 'novel', 'programs', 'resistant strain', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2009,363929,-0.016881666087739864
"Novel Analytic Techniques to Assess Physical Activity    DESCRIPTION (provided by applicant): Progress has been made in developing and using accelerometer-based motion sensors for physical activity research. However, traditional methods of processing activity monitor data do not provide sufficient accuracy to satisfy current trends in the use of objective physical activity data in the research arena. The aims of this proposal address this weakness in accelerometer- based PA assessment methodologies: The specific aims are: 1) To develop and validate novel methods to process Actigraph accelerometer data to improve estimates of PA using powerful modern classification methods (classification trees, discriminant analyses, hidden Markov models, neural networks, regression splines, and support vector machines); 2) To compare these classification methods and traditional approaches for assessing PA in a controlled setting; 3) To compare the classification methods and traditional approaches for quantifying PA in free living PA conditions and to select a recommended method; and 4) To correct for measurement error in summary estimates of habitual PA from the novel classification methods and traditional approaches for quantifying PA. Our uniquely qualified multidisciplinary research group will address these aims by first developing innovative classification methods to identify specific activities in a laboratory setting, and then validating the models using data collected from known activities performed in both controlled laboratory environments and free- living situations. Based on the results of these studies, the classification methods will be refined, and estimates of PA behavior will be adjusted using statistical measurement error methods to derive more accurate estimates of PA. We have chosen the classification methods to include publicly available ""off-the shelf"" classification methods that others can easily use. The resulting data processing programs will be implemented in popular commercial software packages and made freely available. The results of the proposed investigations will move the field of PA assessment forward by providing innovative approaches to derive more accurate and detailed estimates of PA using a popular accelerometer-based PA monitor. This systematic approach will provide information leading to a clearer understanding of the dose-response relationship between PA and health and the physiological basis of this relationship.           n/a",Novel Analytic Techniques to Assess Physical Activity,7620994,R01CA121005,"['Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Chronic Disease', 'Classification', 'Computer software', 'Data', 'Diet', 'Discriminant Analysis', 'Dose', 'Environment', 'Health', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Laboratories', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Motion', 'NIH Program Announcements', 'Nature', 'Outcome', 'Output', 'Participant', 'Pattern', 'Performance', 'Physical activity', 'Physiological', 'Population', 'Principal Investigator', 'Process', 'Qualifying', 'Recommendation', 'Research', 'Scientist', 'Series', 'Techniques', 'Time', 'Time Study', 'Trees', 'Validation', 'Walking', 'Work', 'base', 'computerized data processing', 'improved', 'innovation', 'intervention effect', 'markov model', 'meetings', 'novel', 'novel strategies', 'nutritional epidemiology', 'programs', 'response', 'sensor', 'trend']",NCI,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,2009,263148,-0.003283028183983256
"Novel Analytic Techniques to Assess Physical Activity Progress has been made in developing and using accelerometer-based motion sensors for physical activity research. However, traditional methods of processing activity monitor data do not provide sufficient accuracy to satisfy current trends in the use of objective physical activity data in the research arena. The aims of this proposal address this weakness in accelerometer- based PA assessment methodologies: The specific aims are: 1) To develop and validate novel methods to process Actigraph accelerometer data to improve estimates of PA using powerful modern classification methods (classification trees, discriminant analyses, hidden Markov models, neural networks, regression splines, and support vector machines); 2) To compare these classification methods and traditional approaches for assessing PA in a controlled setting; 3) To compare the classification methods and traditional approaches for quantifying PA in free living PA conditions and to select a recommended method; and 4) To correct for measurement error in summary estimates of habitual PA from the novel classification methods and traditional approaches for quantifying PA. Our uniquely qualified multidisciplinary research group will address these aims by first developing innovative classification methods to identify specific activities in a laboratory setting, and then validating the models using data collected from known activities performed in both controlled laboratory environments and free- living situations. Based on the results of these studies, the classification methods will be refined, and estimates of PA behavior will be adjusted using statistical measurement error methods to derive more accurate estimates of PA. We have chosen the classification methods to include publicly available ""off-the shelf"" classification methods that others can easily use. The resulting data processing programs will be implemented in popular commercial software packages and made freely available. The results of the proposed investigations will move the field of PA assessment forward by providing innovative approaches to derive more accurate and detailed estimates of PA using a popular accelerometer-based PA monitor. This systematic approach will provide information leading to a clearer understanding of the dose-response relationship between PA and health and the physiological basis of this relationship. n/a",Novel Analytic Techniques to Assess Physical Activity,7809191,R01CA121005,"['Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Chronic Disease', 'Classification', 'Computer software', 'Data', 'Diet', 'Discriminant Analysis', 'Dose', 'Environment', 'Health', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Laboratories', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Motion', 'NIH Program Announcements', 'Nature', 'Outcome', 'Output', 'Participant', 'Pattern', 'Performance', 'Physical activity', 'Physiological', 'Population', 'Principal Investigator', 'Process', 'Qualifying', 'Recommendation', 'Research', 'Scientist', 'Series', 'Techniques', 'Time', 'Time Study', 'Trees', 'Validation', 'Walking', 'Work', 'base', 'computerized data processing', 'improved', 'innovation', 'intervention effect', 'markov model', 'meetings', 'novel', 'novel strategies', 'nutritional epidemiology', 'programs', 'response', 'sensor', 'trend']",NCI,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,2009,140804,-0.003524428419543029
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,7730229,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Arts', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'public health relevance', 'response']",NEI,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2009,391450,-0.019957456934419228
"Integrated Analysis of Genome-Wide Array Data    DESCRIPTION (provided by applicant): This project will develop an integrated desktop application to combine data from expression array, RNA transcript array, proteomics, SNP array (for polymorphism an analysis, as well as LOH and copy number determination), methylation array, histone modification array, promoter array, and microRNA array and metabolomics technologies. Current approaches to analysis of individual `omic' technologies suffer from problems of fragmentation, that present an incomplete view of the workings of the cell. However, effective integration into a single analytic platform is non-trivial. There is a need for a consistent approach, infrastructure, and interface between array types, to maximize ease of use, while recognizing and accommodating the specific computational and statistical requirements, and biological context, of each array. A central challenge is the need to create and work with lists of genomic regions of interest (GROIs) for each sample: we propose three novel approaches to aid in identification of GROIs. These lists must then be integrated with rectangular (sample by feature) data arrays to facilitate statistical analysis. Integration between array types occurs at the computational level, through a unified software package, statistically, through tools that seek statistical relationships between features from different arrays, biologically, through use of annotations (particularly gene ontology, protein- protein and protein-DNA interactions, and pathway membership) that document functional relationships between features, and through genomic interactions that suggest relationships between features that map to the same regions of the genome. The end product will support analysis of each platform separately, with a comprehensive suite of data management, statistical and heuristic analytic tools and the means to place findings of interest into a meaningful biological context through cross-reference to extensive biobases. Beyond that, a range of methods - statistical, biological and genomic - will be available to explore interactions and associations between platforms. PDF created with PDF Factory trial version www.pdffactory.com. PUBLIC HEALTH RELEVANCE: While the large-scale array technologies have provided an unprecedented capability to model cellular processes, both in normal functioning and disease states, this capability is utterly dependent on the availability of complex data management, computational, statistical and informatic software tools.  The utility of the next generation of arrays - which focus on critical regulation and control functions of the cell - will be stymied by an initial lack of suitable bioinformatic tools.  This proposal initiates an accelerated development of an integrated software package intended to empower biologists in the application and analysis of these powerful new technologies, with broadly reaching impact at all levels of biological and clinical research, and across every discipline.          n/a",Integrated Analysis of Genome-Wide Array Data,7788875,R43HG004677,"['Algorithms', 'Alternative Splicing', 'Binding', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Bite', 'Cell physiology', 'Cells', 'Classification', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'DNA copy number', 'DNA-Protein Interaction', 'Data', 'Data Linkages', 'Development', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Gene Expression', 'Genes', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Heating', 'Imagery', 'Individual', 'Informatics', 'Internet', 'Joints', 'Link', 'Loss of Heterozygosity', 'Machine Learning', 'Maps', 'Methylation', 'MicroRNAs', 'Modeling', 'Ontology', 'Pathway interactions', 'Phase', 'Polymorphism Analysis', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Regulation', 'Research Infrastructure', 'Resources', 'Sampling', 'Software Tools', 'Sorting - Cell Movement', 'Statistical Methods', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Transcript', 'Work', 'base', 'data management', 'empowered', 'genome wide association study', 'genome-wide analysis', 'heuristics', 'high throughput technology', 'histone modification', 'interest', 'metabolomics', 'new technology', 'next generation', 'novel', 'novel strategies', 'prognostic', 'promoter', 'public health relevance', 'tool', 'tool development']",NHGRI,EPICENTER SOFTWARE,R43,2009,142123,-0.03073609383094174
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7804332,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2009,363247,-0.013769378297851992
"DEVELOPMENT OF SOFTWARE SYSTEMS TO FACILITATE THE USE OF ELECTRONIC DATA RECORDS The objective of this project is to build a commercially-viable automated system to identify records required for population-based cancer surveillance and extract from them specific data elements and their values. The system is to express the elements and values in standard nomenclatures and transmit them to defined destinations. A prototype system using artificial intelligence techniques has been successfully developed to extract reports of CNS neoplasms from CT and MRI reports. During this project that prototype wi1J be extended to receive reports for a second cancer site and to incorporate MRI-F and PET reports. The revised prototype will be implemented in four production environments, transmitting to three central registries. The reports wilt be processed by the software and also manually reviewed by a team of expert CTR's. Results will be compared and the software will be improved to achieve sensitivity and specificity goals in the 98-99% range. The benefits to central cancer registries will be measured in terms of case ascertainment, level of effort and timeliness. A marketing effort will be launched to determine the commercial viability and identify customers for the software. Post Phase II, other lexicons will be added to process other cancer sites found through MRI/CT/PET/F-MRI techniques. n/a",DEVELOPMENT OF SOFTWARE SYSTEMS TO FACILITATE THE USE OF ELECTRONIC DATA RECORDS,7952603,61200900040C,[' '],NCI,QUANTUMMARK LLC,N44,2009,749996,-0.03965830850870928
"Validation of a Vascular Health Profile for Cardiovascular Disease    DESCRIPTION (provided by applicant):  This application address broad challenge area ""(03) Biomarker Discovery and Validation"" and specific challenge research topic ""03-HL-101* Identify and validate clinically relevant, quantifiable biomarkers of diagnostic and therapeutic responses for blood, vascular, cardiac, and respiratory tract dysfunction."" Treatment paradigms have evolved from studies of patients who, despite similar presentations, may have experienced disparate environmental exposures or clinical courses and may have varied underlying pathobiologies. A developing and exciting biomarker strategy is the measurement of microparticles (MPs) and assessment of circulating progenitor and mature endothelial cells. All eukaryotic cells shed MPs in response to activation or apoptosis and elevation of plasma MPs, particularly those of endothelial origin, reflects cellular injury and is a surrogate marker for vascular dysfunction. Microparticles have been enumerated in a number of conditions where vascular dysfunction and inflammation are important pathophysiological mechanisms, for example coronary artery disease or thrombotic microangiopathies. We recently completed a pilot study evaluating levels of MPs in patients with diabetes mellitus (DM) and compared flow cytometry results with those of a non cell specific Enzyme Linked ImmunoSorbent assay (ELISA). The ELISA assay results correlated with flow cytometry results but did not distinguish the cell of origin where the micoparticle originated. The overall goal of this study is to develop and validate a novel cell-based high throughput, high content, vascular health profile analysis that provides a signature for individuals at high risk for cardiovascular events. A unique biocomputational approach at Penn called cytometric fingerprinting will be used to identify populations of cells. The aims are: 1: To develop and validate a single platform high throughput, multiplexed flow cytometry assay for cell specific MPs, endothelial progenitor cells and hematopoietic progenitors. 2: To develop and validate a cell specific ELISA biomarker assay for MPs in healthy group of subjects and patients with DM and correlate with an independent flow cytometry test for EPCs and HSCs as a dual platform measure of vascular health. 3: To use high order informatics to derive a signature profile from the results of Aims 1 and 2. Such a high throughput high information content approach may prove to be clinically useful in discerning laboratory markers that would be useful for guiding therapy of patients with DM. Penn Medicine contributes substantially to the local economy. In 2008, Penn Medicine created 37,000 jobs and $5.4 billion in regional economic activity, with the area's highly trained workforce producing more than 24,600 applications for just 840 open Penn staff research positions. The current proposal will create or retain 3 jobs. If successfully validated, the biomarker technology proposed could be commercialized, create thousands of jobs in the health care industry and potentially prevent costly hospital admissions. Also, an ELISA for MPs could provide an early evaluation of impact of novel pharmaceutical compounds on vascular health. If successfully validated, the biomarker technology proposed could be commercialized, create thousands of jobs in the health care industry and potentially prevent costly hospital admissions. Also, an ELISA for MPs could provide an early evaluation of impact of novel pharmaceutical compounds on vascular health.       PUBLIC HEALTH RELEVANCE:  If successfully validated, the biomarker technology proposed could be commercialized, create thousands of jobs in the health care industry and potentially prevent costly hospital admissions. Also, an ELISA for MPs could provide an early evaluation of impact of novel pharmaceutical compounds on vascular health.           If successfully validated, the biomarker technology proposed could be commercialized, create thousands of jobs in the health care industry and potentially prevent costly hospital admissions. Also, an ELISA for MPs could provide an early evaluation of impact of novel pharmaceutical compounds on vascular health.",Validation of a Vascular Health Profile for Cardiovascular Disease,7814553,RC1HL099528,"['Address', 'Admission activity', 'Age', 'Apoptosis', 'Area', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Platelets', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cell Count', 'Cell Line', 'Cells', 'Cessation of life', 'Characteristics', 'Clinical', 'Complex', 'Computer Analysis', 'Consensus Development', 'Coronary Arteriosclerosis', 'Data', 'Databases', 'Diabetes Mellitus', 'Diabetic Angiopathies', 'Diagnostic', 'Economics', 'Endothelial Cells', 'Environmental Exposure', 'Enzyme-Linked Immunosorbent Assay', 'Eukaryotic Cell', 'Evaluation', 'Event', 'Fingerprint', 'Flow Cytometry', 'Functional disorder', 'Gender', 'Goals', 'Health', 'Healthcare Industry', 'Hematopoietic stem cells', 'Hospitals', 'Impact evaluation', 'Individual', 'Inflammation', 'Informatics', 'Knowledge', 'Laboratory Markers', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Monitor', 'Occupations', 'Pathogenesis', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pilot Projects', 'Plasma', 'Play', 'Population', 'Populations at Risk', 'Positioning Attribute', 'Process', 'Publishing', 'Reporting', 'Research', 'Respiratory System', 'Respiratory tract structure', 'Risk', 'Role', 'Stem cells', 'Surrogate Markers', 'Systems Analysis', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Validation', 'Venous blood sampling', 'Work', 'base', 'cardiovascular risk factor', 'cell injury', 'clinical practice', 'clinically relevant', 'disease classification', 'experience', 'flexibility', 'high risk', 'macrovascular disease', 'monocyte', 'novel', 'prevent', 'progenitor', 'public health relevance', 'response', 'success']",NHLBI,UNIVERSITY OF PENNSYLVANIA,RC1,2009,456475,-0.042607654390878644
"Measuring real time decision-making about UVR Protection    DESCRIPTION (provided by applicant): The development of interventions to maximize consistency in ultraviolet radiation (UVR) protection rests on improved understanding of decision-making factors that contribute to daily variation in UVR protection. In this study, we use Ethnographic Decision Tree Modeling to examine decision-making regarding sunscreen use, shade-seeking, and UVR protection behavior in melanoma first-degree relatives (FDRs). In Phase I, we will generate the models via qualitative ethnographic interviews with 25 melanoma FDRs, and then will construct a composite decision-making model for each of the three UVR protection outcomes. In Phase II we will establish the validity of the models using ecological momentary assessment of UVR protection (over 14 summer days, at 1 pm and 5 pm daily) in 60 FDRs. We will recruit equal numbers of women and men, and equal numbers of those who perceive high and low advantages of tanning, given the importance of these predictors for UVR protection. Specific Aim I is to generate and establish the validity of the models explaining decision-making about three UVR protection behaviors (sunscreen use, shade-seeking, use of protective clothing) in melanoma FDRs, and Specific Aim II is to examine theory-driven affective and cognitive predictors of sun protection maintenance (sunscreen use, shade-seeking, and use of sun protective clothing) assessed in real time. We adopt a theory-informed approach to decision-making, and so expect that the factors identified inductively in Phase I, as well as between- and within-subject variation in melanoma threat, efficacy beliefs, and satisfaction with UVR protection drawn from Witte's Extended Parallel Processing Model and Rothman's theory of health behavior maintenance will predict UVR protection behaviors. We will also examine gender and tanning attitudes as covariates of these effects. The study findings will increase our understanding of the decision- making context for behavioral maintenance of UVR protection, and dictate novel intervention strategies to reduce behavioral inconsistency - and increase behavioral maintenance - of UVR protection in those at high risk for melanoma. PUBLIC HEALTH RELEVANCE: This study will examine daily UVR protection and decision-making about protection in 60 first degree family members of melanoma patients who complete 14-day diaries via personal digital assistants and audio-taped narratives. We will employ qualitative and quantitative research strategies and determine between and within- person variability in UVR protection and decision-making that will inform the development of interventions to increase UVR protection maintenance among those who are at risk for melanoma.                    Narrative This study will examine daily UVR protection and decision-making about protection in 60 first degree family members of melanoma patients who complete 14-day diaries via personal digital assistants and audio-taped narratives. We will employ qualitative and quantitative research strategies and determine between and within- person variability in UVR protection and decision-making that will inform the development of interventions to increase UVR protection maintenance among those who are at risk for melanoma.",Measuring real time decision-making about UVR Protection,7739952,R21CA137532,"['Adopted', 'Affective', 'Anthropology', 'Area', 'Attitude', 'Behavior', 'Behavioral', 'Belief', 'Clothing', 'Cognitive', 'Decision Making', 'Decision Trees', 'Development', 'Ethnography', 'Family member', 'First Degree Relative', 'Gender', 'General Population', 'Guidelines', 'Health', 'Health behavior', 'Individual', 'Intervention', 'Interview', 'Maintenance', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Outcome Study', 'Patients', 'Performance', 'Personal Digital Assistant', 'Persons', 'Phase', 'Physical activity', 'Process', 'Protective Clothing', 'Psychology', 'Radiation Protection', 'Recruitment Activity', 'Reporting', 'Research', 'Rest', 'Risk', 'Risk Factors', 'Risk Reduction', 'Role', 'Skin Cancer', 'Skin tanning', 'Sunburn', 'Sunscreening Agents', 'Technology Assessment', 'The Sun', 'Time', 'Ultraviolet Rays', 'Variant', 'Woman', 'behavioral/social science', 'cancer risk', 'design', 'diaries', 'good diet', 'high risk', 'improved', 'innovation', 'melanoma', 'men', 'modifiable risk', 'novel', 'parallel processing', 'public health relevance', 'satisfaction', 'success', 'sun protection', 'theories', 'therapy development', 'uptake']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R21,2009,333696,-0.023601287443234135
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,7586102,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Arts', 'Blindness', 'Central Scotomas', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Contrast Sensitivity', 'Data', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'depressed', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2009,522802,0.0016032855615153504
"Recursive partitioning and ensemble methods for classifying an ordinal response    DESCRIPTION (provided by applicant):       Classification methods applied to microarray data have largely been those developed by the machine learning community, since the large p (number of covariates) problem is inherent in high-throughput genomic experiments. The random forest (RF) methodology has been demonstrated to be competitive with other machine learning approaches (e.g., neural networks and support vector machines). Apart from improved accuracy, a clear advantage of the RF method in comparison to most machine learning approaches is that variable importance measures are provided by the algorithm. Therefore, one can assess the relative importance each gene has on the predictive model. In a large number of applications, the class to be predicted may be inherently ordinal. Examples of ordinal responses include TNM stage (I,II,III, IV); drug toxicity (none, mild, moderate, severe); or response to treatment classified as complete response, partial response, stable disease, and progressive disease. These responses are ordinal; while there is an inherent ordering among the responses, there is no known underlying numerical relationship between them. While one can apply standard nominal response methods to ordinal response data, in so doing one loses the ordered information inherent in the data. Since ordinal classification methods have been largely neglected in the machine learning literature, the specific aims of this proposal are to (1) extend the recursive partitioning and RF methodologies for predicting an ordinal response by developing computational tools for the R programming environment; (2) evaluate the proposed ordinal classification methods against alternative methods using simulated, benchmark, and gene expression datasets; (3) develop and evaluate methods for assessing variable importance when interest is in predicting an ordinal response. Novel splitting criteria for classification tree growing and methods for estimating variable importance are proposed, which appropriately take the nature of the ordinal response into consideration. In addition, the Generalized Gini index and ordered twoing methods will be studied under the ensemble learning framework, which has not been previously conducted. This project is significant to the scientific community since the ordinal classification methods to be made available from this project will be broadly applicable to a variety of health, social, and behavioral research fields, which commonly collect responses on an ordinal scale.           n/a",Recursive partitioning and ensemble methods for classifying an ordinal response,7470967,R03LM009347,"['Algorithms', 'Behavioral Research', 'Benchmarking', 'Biological Neural Networks', 'Class', 'Classification', 'Communities', 'Data', 'Data Analyses', 'Data Set', 'Discriminant Analysis', 'Drug toxicity', 'Environment', 'Gene Expression', 'Genes', 'Genomics', 'Goals', 'Health', 'Health Surveys', 'Image Analysis', 'In complete remission', 'Individual', 'Learning', 'Literature', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Neoplasm Metastasis', 'Northern Blotting', 'Numbers', 'Outcome', 'Performance', 'Polymerase Chain Reaction', 'Process', 'Progressive Disease', 'Relative (related person)', 'Simulate', 'Stable Disease', 'Staging', 'Standards of Weights and Measures', 'Structure', 'Technology', 'Time', 'Trees', 'computerized tools', 'forest', 'improved', 'indexing', 'interest', 'neglect', 'novel', 'partial response', 'predictive modeling', 'programs', 'research study', 'response', 'social', 'tumor']",NLM,VIRGINIA COMMONWEALTH UNIVERSITY,R03,2008,74521,-0.020803573164579776
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7351765,R01NS051826,"['Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Anatomy', 'Area', 'Back', 'Class', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Diffuse Pattern', 'Disease', 'Disease Progression', 'Evaluation', 'Fetal Growth Retardation', 'Goals', 'Gold', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Intuition', 'Knowledge', 'Learning', 'Localized', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Research', 'Methods', 'Modeling', 'Morphology', 'Neonatal', 'Neuroanatomy', 'Normal Range', 'Operative Surgical Procedures', 'Pathology', 'Patients', 'Population', 'Population Study', 'Process', 'Range', 'Research', 'Schizophrenia', 'Shapes', 'Standards of Weights and Measures', 'Statistical Distributions', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'computer studies', 'desire', 'disease classification', 'feeding', 'imaging Segmentation', 'improved', 'neonate', 'nervous system disorder', 'neurosurgery', 'normal aging', 'novel', 'shape analysis', 'tool']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2008,281588,-0.01091487786835338
"Accessible Artificial Intelligence Tutoring Software (Phase II SBIR)    DESCRIPTION (provided by applicant): This Phase II proposal focuses on the development of accessible artificial intelligence (AI) software for individualized tutoring and formative assessment in chemistry education. If successful, an immediate outcome will be the very first AI tutoring systems for chemistry that are accessible to blind students, delivered through the Internet. An AI tutoring methodology formulated with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. Furthermore, classroom teachers can obtain individualized assessment reporting and diagnostic information for visually impaired students on demand, as if from a ""virtual teaching assistant"". Feasibility of Phase I was demonstrated by developing a prototype accessible AI tutoring program that received certification in the National Federation of the Blind's (NFB) Nonvisual Accessibility Web Application Certification Program. In previous SBIR projects, Quantum has successfully innovated new concepts in the field of AI and has developed, tested and brought to the classroom tutoring and assessment systems for science and mathematics education. Certain unique attributes of the Quantum AI Tutors make them potentially very well suited for full accessibility to the blind, as well as individuals with other print-related disabilities, using Internet- capable screen reader technology. The potential technological innovation is the development of the first advanced AI chemistry tutoring technology that has accessibility built into its framework design. Important Phase II objectives include:  Continued progress on chemistry-specific accessibility issues. Completion of full accessibility support in AI framework itself. Implementation of Braille support for chemical formulas and equations. Investigation of chemistry-specific pedagogical issues for blind students. Extension to accessible science assessment for blind/VI students, building on AI assessment technology currently under development by Quantum in other projects. Special education is a particular challenge for assessment within the No Child Left Behind legislation. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum has long-term partnerships with McGraw-Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as two additional commercial agreements with major science education supply companies, Science Kit & Boreal Laboratories and Sargent-Welch. Chemistry comprises the majority of the content standard for physical science in the National Science Education Standards, and yet is one of the most neglected areas in terms of quality educational software, in general, and is a particularly acute problem for the blind and visually impaired. Through recent federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom the very first artificial intelligence (AI) tutoring systems for chemistry. The goal of the present research is to bring the full power and benefit of this cutting-edge new educational technology to students who are blind and visually impaired using Internet-capable screen access technology.          n/a",Accessible Artificial Intelligence Tutoring Software (Phase II SBIR),7404392,R44EY016251,"['Achievement', 'Acute', 'Address', 'Agreement', 'American', 'Area', 'Artificial Intelligence', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Child', 'Computer software', 'Country', 'Development', 'Diagnostic', 'Drug Formulations', 'Education', 'Educational Technology', 'Educational process of instructing', 'Equation', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Investigation', 'Laboratories', 'Left', 'Mathematics', 'Methodology', 'Mission', 'Numbers', 'Outcome', 'Performance', 'Phase', 'Philosophy', 'Preparation', 'Printing', 'Purpose', 'Reader', 'Reporting', 'Research', 'Schools', 'Science', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Special Education', 'Standards of Weights and Measures', 'Statutes and Laws', 'Students', 'Support of Research', 'System', 'Technology', 'Technology Assessment', 'Testing', 'Visual impairment', 'Work', 'blind', 'braille', 'commercialization', 'concept', 'design', 'disability', 'falls', 'high school', 'improved', 'innovation', 'neglect', 'next generation', 'physical science', 'programs', 'prototype', 'quantum', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'virtual']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2008,383858,-0.02450623464504648
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7433144,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Class', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Computers', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Numbers', 'Performance', 'Personal Satisfaction', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Public Health', 'Randomized', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Today', 'Training', 'Voting', 'Work', 'base', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSIGHTFUL CORPORATION,R44,2008,25548,-0.022147034685075173
"Decision Support in the Care of Preterm Newborns-Tool Development    DESCRIPTION (provided by applicant): Even after many advances in ventilator management, prediction of extubation outcome for a mechanically ventilated premature infant with respiratory distress syndrome (RDS) remains a challenging task for clinicians. We recently developed a machine-learned model (an Artificial Neural Network, ANN) to assist in decision- making regarding extubation of premature newborns (Mueller et al., 2004, 2006). The ANN model was found to perform with accuracy comparable to that of experienced clinicians; however, this approach needs to be compared to equally powerful machine-learning approaches before it can be evaluated in clinical practice. An appropriately validated decision-support tool could help in reducing the number of days a premature infant spends on a mechanical ventilator, and hence the risk of developing short and long-term side effects of mechanical ventilation, resulting in a corresponding decrease in overall health care costs.    In this R21 proposal, we will use several machine-learning approaches combined as a committee formation to obtain the best prediction of extubation success for a given infant. Further, we will build on the previously developed ANN prototype to create an enhanced decision support tool by developing data representation, storage, management, and most important, causal inference, which will enable effective integration of the resulting web-based decision-support tool with clinical practice. This last feature is only possible due to the integrated nature of the proponents themselves, which range from data structure and mathematical modeling experts to experienced neonatologists with a well established working relationship. The proposed effort aims at using advanced modeling tools for translational research by developing a web-based decision-support tool to aid primarily inexperienced clinicians in their decision-making and by promoting interoperability and data exchange among researchers in this field. The critical feature of this infrastructure is its web-based nature, which enables clinicians to evaluate a predictor's accuracy and parametric sensitivity individually for each neonate without having to use any other software than a web-browser. Such a prediction model will be of critical value not only to increase overall clinical accuracy but also to identify effective measures of validity of the original predictions.    The overall aim of this study is to develop a high performing web-based prediction system to use as a decision-support tool in clinical practice and to promote interoperability, and thus, data sharing and interaction among researchers in the neonatal community.    PUBLIC HEALTH RELEVANCE: Predicting extubation outcome in premature infants on mechanical ventilators remains a challenging task even for experienced clinicians. In the proposed work, we aim to provide a sophisticated web-based tool that uses a machine-learning committee comprised of artificial neural networks (ANN), support vector machines (SVM), naive Bayesian classifiers (NBC), influence diagrams (ID), boosted decision trees (BDT) and multivariable logistic regression (MLR) to assist primarily inexperienced clinicians in the decision-making. For the implementation of this tool we propose to develop an XML schema and RDFS model that can promote interoperability, and thus, data sharing and interaction among researchers in the neonatal community.          n/a",Decision Support in the Care of Preterm Newborns-Tool Development,7530584,R21HL090598,"['Adverse effects', 'Arts', 'Biological Neural Networks', 'Caring', 'Characteristics', 'Clinical', 'Committee Members', 'Communities', 'Computer software', 'Data', 'Data Storage and Retrieval', 'Decision Making', 'Decision Trees', 'Development', 'Evaluation', 'Extensible Markup Language', 'Health Care Costs', 'Infant', 'Information Resources Management', 'Internet', 'Language', 'Logistic Regressions', 'Machine Learning', 'Measures', 'Mechanical Ventilators', 'Mechanical ventilation', 'Methods', 'Modeling', 'Nature', 'Neonatal', 'Neonatal Intensive Care Units', 'Neural Network Simulation', 'Newborn Infant', 'Newborn Respiratory Distress Syndrome', 'Numbers', 'Online Systems', 'Outcome', 'Performance', 'Premature Infant', 'Public Health', 'Purpose', 'Range', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'System', 'Translational Research', 'Ventilator', 'Work', 'caregiving', 'data mining', 'data structure', 'day', 'experience', 'interoperability', 'mathematical model', 'member', 'neonate', 'prototype', 'success', 'tool', 'tool development', 'web based interface']",NHLBI,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R21,2008,234220,-0.03674652760802746
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7431959,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Condition', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Numbers', 'Patients', 'Play', 'Population', 'Process', 'Public Health', 'Rate', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'particle', 'size', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2008,376423,-0.018900775503569247
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7367958,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'Work', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2008,2037396,-0.019472393955964073
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7495734,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease Resistance', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Numbers', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Range', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'novel', 'programs', 'size', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2008,353327,-0.016881666087739864
"Novel Analytic Techniques to Assess Physical Activity    DESCRIPTION (provided by applicant): Progress has been made in developing and using accelerometer-based motion sensors for physical activity research. However, traditional methods of processing activity monitor data do not provide sufficient accuracy to satisfy current trends in the use of objective physical activity data in the research arena. The aims of this proposal address this weakness in accelerometer- based PA assessment methodologies: The specific aims are: 1) To develop and validate novel methods to process Actigraph accelerometer data to improve estimates of PA using powerful modern classification methods (classification trees, discriminant analyses, hidden Markov models, neural networks, regression splines, and support vector machines); 2) To compare these classification methods and traditional approaches for assessing PA in a controlled setting; 3) To compare the classification methods and traditional approaches for quantifying PA in free living PA conditions and to select a recommended method; and 4) To correct for measurement error in summary estimates of habitual PA from the novel classification methods and traditional approaches for quantifying PA. Our uniquely qualified multidisciplinary research group will address these aims by first developing innovative classification methods to identify specific activities in a laboratory setting, and then validating the models using data collected from known activities performed in both controlled laboratory environments and free- living situations. Based on the results of these studies, the classification methods will be refined, and estimates of PA behavior will be adjusted using statistical measurement error methods to derive more accurate estimates of PA. We have chosen the classification methods to include publicly available ""off-the shelf"" classification methods that others can easily use. The resulting data processing programs will be implemented in popular commercial software packages and made freely available. The results of the proposed investigations will move the field of PA assessment forward by providing innovative approaches to derive more accurate and detailed estimates of PA using a popular accelerometer-based PA monitor. This systematic approach will provide information leading to a clearer understanding of the dose-response relationship between PA and health and the physiological basis of this relationship.           n/a",Novel Analytic Techniques to Assess Physical Activity,7417618,R01CA121005,"['Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Chronic Disease', 'Classification', 'Computer software', 'Condition', 'Daily', 'Data', 'Diet', 'Discriminant Analysis', 'Disease regression', 'Dose', 'Effectiveness of Interventions', 'Environment', 'Health', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Laboratories', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Motion', 'NIH Program Announcements', 'Nature', 'Outcome', 'Output', 'Participant', 'Pattern', 'Performance', 'Physical activity', 'Physiological', 'Population', 'Principal Investigator', 'Process', 'Qualifying', 'Recommendation', 'Research', 'Scientist', 'Series', 'Techniques', 'Time', 'Time Study', 'Trees', 'Validation', 'Walking', 'Work', 'base', 'computerized data processing', 'improved', 'innovation', 'markov model', 'novel', 'novel strategies', 'nutritional epidemiology', 'programs', 'response', 'sensor', 'trend']",NCI,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,2008,263507,-0.003283028183983256
"Novel Analytic Techniques to Assess Physical Activity Progress has been made in developing and using accelerometer-based motion sensors for physical activity research. However, traditional methods of processing activity monitor data do not provide sufficient accuracy to satisfy current trends in the use of objective physical activity data in the research arena. The aims of this proposal address this weakness in accelerometer- based PA assessment methodologies: The specific aims are: 1) To develop and validate novel methods to process Actigraph accelerometer data to improve estimates of PA using powerful modern classification methods (classification trees, discriminant analyses, hidden Markov models, neural networks, regression splines, and support vector machines); 2) To compare these classification methods and traditional approaches for assessing PA in a controlled setting; 3) To compare the classification methods and traditional approaches for quantifying PA in free living PA conditions and to select a recommended method; and 4) To correct for measurement error in summary estimates of habitual PA from the novel classification methods and traditional approaches for quantifying PA. Our uniquely qualified multidisciplinary research group will address these aims by first developing innovative classification methods to identify specific activities in a laboratory setting, and then validating the models using data collected from known activities performed in both controlled laboratory environments and free- living situations. Based on the results of these studies, the classification methods will be refined, and estimates of PA behavior will be adjusted using statistical measurement error methods to derive more accurate estimates of PA. We have chosen the classification methods to include publicly available ""off-the shelf"" classification methods that others can easily use. The resulting data processing programs will be implemented in popular commercial software packages and made freely available. The results of the proposed investigations will move the field of PA assessment forward by providing innovative approaches to derive more accurate and detailed estimates of PA using a popular accelerometer-based PA monitor. This systematic approach will provide information leading to a clearer understanding of the dose-response relationship between PA and health and the physiological basis of this relationship. n/a",Novel Analytic Techniques to Assess Physical Activity,7611584,R01CA121005,"['Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Chronic Disease', 'Classification', 'Computer software', 'Condition', 'Daily', 'Data', 'Diet', 'Discriminant Analysis', 'Disease regression', 'Dose', 'Effectiveness of Interventions', 'Environment', 'Health', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Laboratories', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Motion', 'NIH Program Announcements', 'Nature', 'Outcome', 'Output', 'Participant', 'Pattern', 'Performance', 'Physical activity', 'Physiological', 'Population', 'Principal Investigator', 'Process', 'Qualifying', 'Recommendation', 'Research', 'Scientist', 'Series', 'Techniques', 'Time', 'Time Study', 'Trees', 'Validation', 'Walking', 'Work', 'base', 'computerized data processing', 'improved', 'innovation', 'markov model', 'novel', 'novel strategies', 'nutritional epidemiology', 'programs', 'response', 'sensor', 'trend']",NCI,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,2008,142424,-0.003524428419543029
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7480255,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2008,89733,-0.030599994594693113
"Integrated Analysis of Genome-Wide Array Data    DESCRIPTION (provided by applicant): This project will develop an integrated desktop application to combine data from expression array, RNA transcript array, proteomics, SNP array (for polymorphism an analysis, as well as LOH and copy number determination), methylation array, histone modification array, promoter array, and microRNA array and metabolomics technologies. Current approaches to analysis of individual `omic' technologies suffer from problems of fragmentation, that present an incomplete view of the workings of the cell. However, effective integration into a single analytic platform is non-trivial. There is a need for a consistent approach, infrastructure, and interface between array types, to maximize ease of use, while recognizing and accommodating the specific computational and statistical requirements, and biological context, of each array. A central challenge is the need to create and work with lists of genomic regions of interest (GROIs) for each sample: we propose three novel approaches to aid in identification of GROIs. These lists must then be integrated with rectangular (sample by feature) data arrays to facilitate statistical analysis. Integration between array types occurs at the computational level, through a unified software package, statistically, through tools that seek statistical relationships between features from different arrays, biologically, through use of annotations (particularly gene ontology, protein- protein and protein-DNA interactions, and pathway membership) that document functional relationships between features, and through genomic interactions that suggest relationships between features that map to the same regions of the genome. The end product will support analysis of each platform separately, with a comprehensive suite of data management, statistical and heuristic analytic tools and the means to place findings of interest into a meaningful biological context through cross-reference to extensive biobases. Beyond that, a range of methods - statistical, biological and genomic - will be available to explore interactions and associations between platforms. PDF created with PDF Factory trial version www.pdffactory.com. PUBLIC HEALTH RELEVANCE: While the large-scale array technologies have provided an unprecedented capability to model cellular processes, both in normal functioning and disease states, this capability is utterly dependent on the availability of complex data management, computational, statistical and informatic software tools.  The utility of the next generation of arrays - which focus on critical regulation and control functions of the cell - will be stymied by an initial lack of suitable bioinformatic tools.  This proposal initiates an accelerated development of an integrated software package intended to empower biologists in the application and analysis of these powerful new technologies, with broadly reaching impact at all levels of biological and clinical research, and across every discipline.          n/a",Integrated Analysis of Genome-Wide Array Data,7538527,R43HG004677,"['Algorithms', 'Alternative Splicing', 'Binding', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Bite', 'Cell physiology', 'Cells', 'Classification', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'DNA copy number', 'DNA-Protein Interaction', 'Data', 'Data Linkages', 'Development', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'GDF15 gene', 'Gene Expression', 'Genes', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Heating', 'Histones', 'Imagery', 'Individual', 'Informatics', 'Internet', 'Joints', 'Link', 'Loss of Heterozygosity', 'Machine Learning', 'Maps', 'Methylation', 'MicroRNAs', 'Modeling', 'Modification', 'Numbers', 'Ontology', 'PLAB Protein', 'Pathway interactions', 'Phase', 'Polymorphism Analysis', 'Process', 'Proteins', 'Proteomics', 'Public Health', 'Purpose', 'RNA', 'Range', 'Regulation', 'Research Infrastructure', 'Resources', 'Sampling', 'Software Tools', 'Sorting - Cell Movement', 'Statistical Methods', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Transcript', 'Work', 'base', 'data management', 'genome-wide analysis', 'heuristics', 'high throughput technology', 'interest', 'metabolomics', 'new technology', 'next generation', 'novel', 'novel strategies', 'prognostic', 'promoter', 'tool', 'tool development']",NHGRI,EPICENTER SOFTWARE,R43,2008,157474,-0.03073609383094174
"Dysbiosis in Inflammatory Bowel Disease    DESCRIPTION (provided by applicant): Inflammatory Bowel Diseases (IBDs), namely ulcerative colitis (DC) and Crohn's disease (CD), are chronic, lifelong, relapsing illnesses, affecting close to 1 million Americans. Despite the many clues that a dysbiosis may exist in IBD, the specific changes in the microflora of IBD patients are largely unknown. Amplicon length heterogeneity (ALH) is a sophisticated and well established PCR based technology that can be used as a screening tool to identify changes in the Bacterial microflora of IBD patients. We therefore have hypothesized that the ileocolonic microflora in IBD has an altered microbial composition compared to normal microflora. We have gathered preliminary data that shows statistical differences between controls and IBD as well as within IBD patients. Therefore, to test the above hypothesis, we are proposing the following 2 inter-related scientific aims: AIM 1. Identify bacterial fingerprint patterns associated with IBD using ALH. ALH patterns will be determined in a total of 160 IBD patients and health controls and will be analyzed using diversity indeces, multivariate reduction analysis and cluster analysis. ALH patterns associated with IBD will be determined using histograms, ecological software in conjunction with custom PERL scripts as well as supervised and unsupervised automated pattern recognition systems. AIM 2.Determine the bacterial contents of putatively IBD associated ALH fingerprint patterns using molecular cloning and sequencing. Cloning and sequencing of targeted samples will be linked to bacterial identities by employing multiple bioinformatics tools. Significance. This proposal involves the first time use of a sophisticated and highly reproducible molecular biology tool, ALH, in the study of microflora in the Gl tract. There is a growing recognition of the importance of microflora in health and disease, including IBD. Studies that characterized microflora in human using powerful techniques from environmental microbiology such as ALH can bring about significant advances in the understanding of Gl tract illnesses. ALH may enable a real-time survey of microfloral changes for the first time in medicine and may provide the first evidence linking IBD with specific microbial patterns.           n/a",Dysbiosis in Inflammatory Bowel Disease,7434510,R21DK071838,"['Affect', 'Age', 'Algorithms', 'American', 'Attention', 'Back', 'Bacteria', 'Bioinformatics', 'Biopsy Specimen', 'Bispecific Antibody 2B1', 'Celiac Disease', 'Chronic', 'Clinical', 'Cloning', 'Cluster Analysis', 'Colon', 'Colonoscopy', 'Colorectal', 'Complex', 'Computer software', 'Crohn&apos', 's disease', 'Custom', 'DNA', 'Data', 'Databases', 'Disease', 'Distal part of ileum', 'Effectiveness', 'Environment', 'Environmental Microbiology', 'Feces', 'Fingerprint', 'Flare', 'Flexible fiberoptic sigmoidoscopy', 'Future', 'Gender', 'Genus Cola', 'Hand', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Human', 'Human body', 'Immunosuppressive Agents', 'Incidence', 'Individual', 'Infection', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Intestines', 'Irritable Bowel Syndrome', 'Knowledge', 'Length', 'Link', 'Machine Learning', 'Maps', 'Medicine', 'Methods', 'Molecular Biology', 'Molecular Cloning', 'Morbidity - disease rate', 'Mucous Membrane', 'Newly Diagnosed', 'Numbers', 'Operative Surgical Procedures', 'Organ', 'Organism', 'Patients', 'Pattern', 'Pattern Recognition', 'Pattern Recognition Systems', 'Pharmaceutical Preparations', 'Polymerase Chain Reaction', 'Population', 'Probiotics', 'Procedures', 'Race', 'Reaction', 'Recruitment Activity', 'Relapse', 'Relative (related person)', 'Research Personnel', 'Ribosomal RNA', 'Sampling', 'Schedule', 'Screening procedure', 'Soil', 'Surveys', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Toxic effect', 'Ulcerative Colitis', 'Visual', 'base', 'carcinogenesis', 'clinical application', 'computerized', 'cost', 'data mining', 'disabling disease', 'ileum', 'indexing', 'microbial', 'microbial community', 'neglect', 'novel', 'novel diagnostics', 'pathogen', 'prebiotics', 'programs', 'satisfaction', 'success', 'time use', 'tool', 'treatment effect']",NIDDK,RUSH UNIVERSITY MEDICAL CENTER,R21,2008,181300,-0.020850497967969006
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7748401,R44GM083965,"['Learning', 'Techniques', 'parallel computing']",NIGMS,INSILICOS,R44,2008,143361,-0.022147034685075173
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): The proposed Clinical Cytometry Analysis Software Project described in this grant application is designed to create a new, more efficient and effective way of analyzing cells for the presence of cancer, HIV/AIDS and other disease, using a fully automated software system. Using modern data mining techniques (pattern recognition, feature recognition, image analysis) we will design software which will analyze data (the cell samples from patients) at a much faster rate and with fewer false positives and negatives than the manual method now in use. Objectives: Assemble and validate algorithms in software that can automatically classify regions of interest in flow cytometry data. We will demonstrate that the particular populations required by our use cases can be validly, rigorously and repeatably identified automatically. Develop and validate graphical and statistical results that satisfy FDA requirements for medical device software, simplify regulatory compliance by the clinical user, and automatically deliver analysis results to diagnostic expert systems and/or LIMS systems. Satisfy the  translational medicine  goals outlined in the NIH Roadmap. This software will bring the clinician streamlined testing currently only available in research labs. Methods: Four use cases have been selected, one employing synthetic data and three clinical data; Leukemia/Lymphoma test, Analysis of longitudinal Graft vs. Host Disease (GvHD) in bone marrow transplant specimens for predictive markers and HIV/AIDS - Gag-specific T cell cytokine response profile assay. For each we have access to a substantial body of existing data, analyzed by experts. Beginning with the autogating routines in our own FlowJo software, we will test and expand the application of Magnetic gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural and Support Vector Machines (SVM). Using a sampling of human operators to establish a control range, we will test each of these five techniques against the four use cases in cooperation with our collaborators. Events in the manually classified samples are given a weighted score based on the frequency with which they are included by all the operators. A single operator's score or the gating algorithm's score is compared with the cumulative score of the expert group and a match rating is computed. Additional validation techniques include combinatory validation on internal measures with respect to Pareto optimality, and Predictive Power/Stability self consistency checks using resampled or perturbed data measured with external indices such as the adjusted Rand index and the Variation of Information index.  PUBLIC HEALTH RELEVANCE: By eliminating the operator's time, we estimate that the cost of clinical flow cytometry analysis can be reduced to half the current figure while delivering the results much faster. By eliminating the subjectivity and human error of manually created regions and reducing the range of variability of the so created, there would result fewer false positives and false negatives, improving the clinical outcome for those patients needing therapy but undetected by current methods. An order of magnitude increase in speed means faster therapeutic intervention.  A less expensive test improves outcome by making the test accessible to more patients.          n/a",Clinical Cytometry Analysis Software with Automated Gating,7482923,R43RR024094,"['AIDS/HIV problem', 'Algorithms', 'Applications Grants', 'B-Lymphocytes', 'Biological Assay', 'Biological Neural Networks', 'Bone Marrow Transplantation', 'Cells', 'Characteristics', 'Class', 'Classification', 'Clinical', 'Clinical Data', 'Cluster Analysis', 'Complex', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cytometry', 'Data', 'Data Analyses', 'Data Files', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Educational process of instructing', 'Environment', 'Evaluation', 'Event', 'Expert Systems', 'Facility Construction Funding Category', 'Flow Cytometry', 'Frequencies', 'Funding', 'Future', 'Gagging', 'Generations', 'Goals', 'Grant', 'Graph', 'Human', 'Image Analysis', 'Individual', 'Instruction', 'Knowledge', 'Legal patent', 'Life Cycle Stages', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Noise', 'Numbers', 'Outcome', 'Output', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Population', 'Probability', 'Process', 'Public Health', 'Publishing', 'Range', 'Rate', 'Regulation', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Scientist', 'Score', 'Software Design', 'Software Engineering', 'Software Tools', 'Solutions', 'Specific qualifier value', 'Specimen', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'T-Lymphocyte', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tube', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Voting', 'Weight', 'base', 'clinical Diagnosis', 'commercialization', 'cost', 'cytokine', 'data mining', 'design', 'improved', 'indexing', 'innovation', 'interest', 'leukemia/lymphoma', 'novel', 'predictive modeling', 'relating to nervous system', 'research study', 'response', 'software systems', 'statistics', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R43,2008,100854,-0.012958170485981487
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.       n/a",Bioconductor: an open computing resource for genomics,7495201,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Class', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Sources', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Numbers', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Range', 'Reader', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'size', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web-accessible']",NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2008,805222,-0.04510879245663584
"Webcam Interface for Audio/touch Graphics Access by Blind People    DESCRIPTION (provided by applicant):  The goal of this project is to develop a compact inexpensive alternative to the bulky expensive touchpads now required by blind people for audio/touch access to graphical information. Audio/touch is known to provide excellent access to computer-literate blind people as well as people with dyslexia or other severe print disabilities. Preparing Audio/touch materials was very expensive until ViewPlus introduced the IVEO Scalable Vector Graphic (SVG) Authoring/conversion software in 2005. IVEO permits virtually any graphical information to be created or converted/imported easily to a well- structured highly accessible SVG format. Tactile copy was also very expensive before 2000 when ViewPlus introduced the Tiger embossing Windows printers that ""print"" by embossing. The new ViewPlus Emprint printer/embossers emboss and also print color images, creating color tactile images particularly useful for people with dyslexia and a number of other print disabilities. An audio/touch user reads an IVEO SVG graphic using the free IVEO Viewer, a tactile copy of the image, and a touchpad. The user places the tactile graphic on the touchpad and presses a point of interest. The touchpad communicates the position of that point back to the computer, and the IVEO Viewer speaks the appropriate information. Tactile text made from mainstream graphics has a distinctive pattern. When a user presses, that text is spoken by the IVEO Viewer. When the user presses a graphic object having a SVG title within the file, that title will be spoken. Objects may also have arbitrarily long description fields that can be spoken and browsed. All spoken information can be displayed on an attached braille display if desired. Graphical information is ubiquitous today, but almost none is accessible to blind people. Government agencies, libraries, companies, and agencies serving people with disabilities could easily send highly accessible IVEO graphics files and tactile graphic copies to clients with disabilities, but there is a ""chicken and egg"" dilemma that must be overcome before they are likely to do so. Few blind people have a touchpad (which cost $500 or more), so few could use that information. The specific aim of this Phase I proposal is to develop an affordable webcam-based prototype as an alternative to touchpads. It is based on an inexpensive webcam that is focused on the graphic and follows a finger. A touchpad press is emulated in this prototype by pressing some computer key with the other hand. This project could be the key to bringing accessible graphics to all blind computer users and is clearly of interest to NEI whose mission statement includes mental health and quality of life of blind people. PUBLIC HEALTH RELEVANCE:  This proposal is relevant to the mission of the National Eye Institute, because it could be the key to making nearly all graphical information easily accessible to people who are blind or have other severe print disabilities. Graphical information is ubiquitous in the world today but is not presently accessible to blind people except through expensive and time-consuming conversion by trained transcribers. Making all graphical information accessible would have an obviously highly beneficial direct effect on education and professional opportunities, mental health, and quality of life of blind people. Mental health and quality of life issues for blind people are parts of the mission of the National Eye Institute.          n/a",Webcam Interface for Audio/touch Graphics Access by Blind People,7480812,R43EY018973,"['Back', 'Braille Display', 'Businesses', 'Chickens', 'Client', 'Color', 'Communities', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consultations', 'Development', 'Devices', 'Disabled Persons', 'Dyslexia', 'Event', 'Fingers', 'Goals', 'Government Agencies', 'Hand', 'Home environment', 'Image', 'Information Systems', 'Institution', 'Internet', 'Libraries', 'Link', 'Mainstreaming', 'Marketing', 'Mental Health', 'Methods', 'Mission', 'Modeling', 'Mus', 'National Eye Institute', 'Numbers', 'Oregon', 'Pattern', 'Phase', 'Positioning Attribute', 'Printing', 'Professional Education', 'Public Health', 'Publications', 'Quality of life', 'Range', 'Reading', 'Site', 'Structure', 'Structure of nail of finger', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Text', 'Tigers', 'Time', 'Title', 'Today', 'Touch sensation', 'Training', 'Universities', 'Visual', 'Visually Impaired Persons', 'base', 'blind', 'braille', 'cost', 'desire', 'digital', 'disability', 'egg', 'interest', 'literate', 'print disabilities', 'programs', 'prototype', 'research and development', 'tool', 'touchpad', 'vector']",NEI,"VIEWPLUS TECHNOLOGIES, INC.",R43,2008,100001,-0.01877469236823789
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,7351808,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Arts', 'Blindness', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Condition', 'Contrast Sensitivity', 'Data', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Range', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Models', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'concept', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2008,482736,0.0016032855615153504
"Machine Learning Applied to Automated Planar Patch Clamps    DESCRIPTION (provided by applicant): The introduction of automated planar patch clamp instruments over the past two years has increased the throughput of voltage clamp ion channel assays by a factor of at least ten. This is possible because the automated systems can perform assays in parallel using16 and 384-well plates. While the drug discovery industry has embraced this new technology, the enthusiasm has been tempered by the modest success rates of the assays and by the high cost of the consumable patch substrate. Currently, typical success rates for a standard ion channel assay, using, for example, the Q-Patch from Sophion Biosciences, the Port-a-Patch system from Nanion Biosciences, or the PatchXpress from Molecular Devices Corp., is around 50%. In other words, for every16 channel chip used in these systems, only eight will produce useable data. This effectively doubles the price of each data point over what is ideally possible. In order for a planar patch clamp experiment to succeed, several events need to occur (assuming that the cell expresses the appropriate ion channels in functional states): the cell of interest must form a high-resistance seal with the planar substrate, the whole-cell configuration must be achieved, and fluidic pathways must be intact so that compounds of interest maybe applied to the cell. A failure of anyone of these steps will result in no data collected from that well. We propose to optimize the first two steps in this process, namely, seal formation and entry into whole-cell recording configuration. We will use machine learning approaches to examine how a human patch clamp expert interacts with the patch clamp system in order to develop a model that will provide parameters that can be used to more efficiently and successfully provide useable whole-cell recording configuration. It is important to note that the model that we derive from our approach will not actually copy what the expert does, but will attempt to optimize the process based on cues that mayor may not be consciously monitored by the expert. The Specific Aims of the Phase I component will be to: (1) integrate recording capabilities into existing automated patch clamp software from Nanion, (2) evaluate the success rate of the procedure specified by our machine learning analysis, and (3) develop stand-alone software for use specifically with manual patch clamp setups and for exploration of the potential benefits of using machine learning via expert training in other applications. In Phase II we propose to develop the proof-of-concept software into a user-friendly commercial software module which we will offer to existing and potential automated patch clamp companies. We will also simplify and streamline the user interface of this software as a stand-alone component for manual patch clamp systems. Developing drugs that target ion channels has been hindered by the expense of the consumables used in automated patch clamp screening devices. We propose to develop a method, using machine learning techniques which may increase the success rate of these instruments and therefore lower the overall cost of ion channel drug discovery.          n/a",Machine Learning Applied to Automated Planar Patch Clamps,7220448,R43EB007148,"['Biological Assay', 'Cells', 'Chemistry', 'Computer software', 'Condition', 'Cues', 'Data', 'Devices', 'Drug Delivery Systems', 'Employee Strikes', 'Event', 'Failure', 'Goals', 'Housing', 'Human', 'Industry', 'Ion Channel', 'Learning', 'Licensing', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Monitor', 'Pathway interactions', 'Performance', 'Phase', 'Price', 'Procedures', 'Process', 'Programmed Learning', 'Protocols documentation', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Resistance', 'Running', 'Sales', 'Scientist', 'Screening procedure', 'Software Engineering', 'Solutions', 'Specific qualifier value', 'Spottings', 'Standards of Weights and Measures', 'Suction', 'Surface', 'System', 'Techniques', 'Testing', 'Training', 'Visual', 'Whole-Cell Recordings', 'Work', 'Writing', 'base', 'cell type', 'concept', 'cost', 'drug discovery', 'improved', 'instrument', 'interest', 'new technology', 'patch clamp', 'programs', 'research study', 'seal', 'success', 'tool', 'user-friendly', 'voltage', 'voltage clamp']",NIBIB,BLATZ SCIENTIFIC,R43,2007,199389,-0.03263437030191545
"Computer Vision Methods for the Real Time Assessment of Dietary Intake    DESCRIPTION (provided by applicant): Obesity is a leading cause of preventable death and disability in the U.S. Self- monitoring of all foods and beverages consumed is central to weight loss and maintenance efforts; however, this places a heavy burden on the user. These same burdens also impede nutritional research. The proposed research is for the testing of a semi-automated, objective, near real-time computer vision and pattern recognition approach to the measurement of dietary intake. In the proposed product, cell phone pictures of meals and snacks will be analyzed by software in an attempt to automatically recognize as many items as possible. A small number of intelligent yes/no questions will help provide additional information when necessary in order to meet the accuracy demands of the target application. Following identification of the items, the software will estimate the portion sizes of all identified items. The experiments comprising this Phase I SBIR are (a) extract the most informative sets of features using a large number of food and beverage items taken from an existing database of real world meal images, (b) compare the accuracy of candidate pattern recognition approaches to identify items based on the extracted features, (c) identify the most feasible algorithms for estimating portion size, and (d) test usability and user acceptance with a simulated version of the product. Phase II will (a) apply the approach to a greater variety of food and beverage items, (b) improve automated analysis, and (c) compare the approach to existing assessment instruments. This research will extend defense- and security-related technologies to the assessment and treatment of obesity.          n/a",Computer Vision Methods for the Real Time Assessment of Dietary Intake,7405586,R43CA124265,"['Address', 'Adherence', 'Algorithms', 'Area', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Biometry', 'Body Weight decreased', 'Calculi', 'Cellular Phone', 'Cessation of life', 'Class', 'Coin', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Decision Trees', 'Diabetic Diet', 'Diet Records', 'Dietary intake', 'Disease', 'Eating', 'Eating Behavior', 'Face', 'Feedback', 'Fingerprint', 'Food', 'Food and Beverages', 'Goals', 'Habits', 'Health', 'Image', 'Individual', 'Information Theory', 'Intake', 'Iris', 'Life', 'Life Style', 'Lighting', 'Machine Learning', 'Maintenance', 'Marketing', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Numbers', 'Nutritional', 'Nutritionist', 'Obesity', 'Obesity associated disease', 'Pattern Recognition', 'Phase', 'Placement', 'Principal Investigator', 'Public Health', 'Research', 'Research Personnel', 'Security', 'Shapes', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Three-Dimensional Image', 'Time', 'Training', 'Treatment Protocols', 'United States', 'Wing', 'base', 'design', 'digital imaging', 'disability', 'improved', 'innovation', 'instrument', 'interest', 'obesity treatment', 'research study', 'size', 'usability']",NCI,"MEDIABALANCE, INC.",R43,2007,191710,-0.016297121689411095
"Accessible Artificial Intelligence Tutoring Software (Phase II SBIR)    DESCRIPTION (provided by applicant): This Phase II proposal focuses on the development of accessible artificial intelligence (AI) software for individualized tutoring and formative assessment in chemistry education. If successful, an immediate outcome will be the very first AI tutoring systems for chemistry that are accessible to blind students, delivered through the Internet. An AI tutoring methodology formulated with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. Furthermore, classroom teachers can obtain individualized assessment reporting and diagnostic information for visually impaired students on demand, as if from a ""virtual teaching assistant"". Feasibility of Phase I was demonstrated by developing a prototype accessible AI tutoring program that received certification in the National Federation of the Blind's (NFB) Nonvisual Accessibility Web Application Certification Program. In previous SBIR projects, Quantum has successfully innovated new concepts in the field of AI and has developed, tested and brought to the classroom tutoring and assessment systems for science and mathematics education. Certain unique attributes of the Quantum AI Tutors make them potentially very well suited for full accessibility to the blind, as well as individuals with other print-related disabilities, using Internet- capable screen reader technology. The potential technological innovation is the development of the first advanced AI chemistry tutoring technology that has accessibility built into its framework design. Important Phase II objectives include:  Continued progress on chemistry-specific accessibility issues. Completion of full accessibility support in AI framework itself. Implementation of Braille support for chemical formulas and equations. Investigation of chemistry-specific pedagogical issues for blind students. Extension to accessible science assessment for blind/VI students, building on AI assessment technology currently under development by Quantum in other projects. Special education is a particular challenge for assessment within the No Child Left Behind legislation. Preparation for success in Phase III has already been undertaken by involving partners that are important commercially as well as technically, such as the National Federation of the Blind and the American Printing House for the Blind (APH). In addition, Quantum has long-term partnerships with McGraw-Hill and Holt, Rinehart and Winston, two of the country's leading educational publishers, as well as two additional commercial agreements with major science education supply companies, Science Kit & Boreal Laboratories and Sargent-Welch. Chemistry comprises the majority of the content standard for physical science in the National Science Education Standards, and yet is one of the most neglected areas in terms of quality educational software, in general, and is a particularly acute problem for the blind and visually impaired. Through recent federally-supported research, Quantum Simulations, Inc. has successfully developed, tested and brought to the classroom the very first artificial intelligence (AI) tutoring systems for chemistry. The goal of the present research is to bring the full power and benefit of this cutting-edge new educational technology to students who are blind and visually impaired using Internet-capable screen access technology.          n/a",Accessible Artificial Intelligence Tutoring Software (Phase II SBIR),7220194,R44EY016251,"['Achievement', 'Acute', 'Address', 'Agreement', 'American', 'Area', 'Artificial Intelligence', 'Categories', 'Certification', 'Chemicals', 'Chemistry', 'Child', 'Computer software', 'Country', 'Development', 'Diagnostic', 'Drug Formulations', 'Education', 'Educational Technology', 'Educational process of instructing', 'Equation', 'Evaluation', 'Feedback', 'Future', 'Goals', 'Hand', 'Home environment', 'Housing', 'Individual', 'Institution', 'Instruction', 'Internet', 'Intervention', 'Investigation', 'Laboratories', 'Left', 'Mathematics', 'Methodology', 'Mission', 'Numbers', 'Outcome', 'Performance', 'Phase', 'Philosophy', 'Preparation', 'Printing', 'Purpose', 'Reader', 'Reporting', 'Research', 'Schools', 'Science', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Special Education', 'Standards of Weights and Measures', 'Statutes and Laws', 'Students', 'Support of Research', 'System', 'Technology', 'Technology Assessment', 'Testing', 'Visual impairment', 'Work', 'blind', 'braille', 'commercialization', 'concept', 'design', 'disability', 'falls', 'high school', 'improved', 'innovation', 'neglect', 'next generation', 'physical science', 'programs', 'prototype', 'quantum', 'science education', 'simulation', 'success', 'teacher', 'technological innovation', 'virtual']",NEI,"QUANTUM SIMULATIONS, INC.",R44,2007,366168,-0.02450623464504648
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7186695,R01NS051826,"['Accounting', 'Adult', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Anatomic structures', 'Anatomy', 'Area', 'Atlases', 'Back', 'Biomechanics', 'Boston', 'Brain', 'Caring', 'Class', 'Classification', 'Clinical assessments', 'Clutterings', 'Collaborations', 'Competence', 'Computer Simulation', 'Computer Vision Systems', 'Computing Methodologies', 'Corpus Callosum', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diffuse Pattern', 'Discipline of obstetrics', 'Disease', 'Disease Progression', 'Effectiveness', 'Effectiveness of Interventions', 'Electroencephalography', 'Elements', 'Ensure', 'Evaluation', 'Evolution', 'Fetal Growth Retardation', 'General Hospitals', 'Genetic Markers', 'Goals', 'Gold', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Incidence', 'Individual', 'Infant', 'Intervention', 'Intuition', 'Invasive', 'Knowledge', 'Label', 'Learning', 'Learning Disabilities', 'Link', 'Localized', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Motivation', 'Neonatal', 'Neuroanatomy', 'Neurosciences', 'Neurosurgeon', 'Noise', 'Normal Range', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Pediatric Hospitals', 'Population', 'Population Characteristics', 'Population Study', 'Positioning Attribute', 'Premature Infant', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Property', 'Psyche structure', 'Range', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Resolution', 'Rest', 'Role', 'Scanning', 'Schizophrenia', 'Shapes', 'Site', 'Specificity', 'Staging', 'Standards of Weights and Measures', 'Statistical Distributions', 'Statistical Models', 'Statistical Study', 'Statistically Significant', 'Structure', 'Surface', 'Surgeon', 'Surgical Instruments', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Tweens', 'Universities', 'Validation', 'Variant', 'Washington', 'Woman', 'base', 'cohort', 'computer studies', 'computerized tools', 'desire', 'deviant', 'disease classification', 'expectation', 'feeding', 'healthy aging', 'imaging Segmentation', 'improved', 'instrument', 'interest', 'mortality', 'neonate', 'nervous system disorder', 'neuroimaging', 'neurosurgery', 'normal aging', 'novel', 'programs', 'radiologist', 'reconstruction', 'relating to nervous system', 'research clinical testing', 'response', 'shape analysis', 'statistics', 'tool', 'tumor']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2007,282619,-0.01091487786835338
"A RuleFit Product for Classification and Regression Prediction and data exploration are important aspects of modern commercial and scientific life. Regression methods predict dependent variables (e.g., tumor growth, severity of disease), while classification methods predict class membership (e.g., tumor or disease type). Both use a vector of independent variables to make the predictions. Because they are often superior predictors, can handle large numbers observations and large numbers of variables, can often yield insight into the data not provided by other methods, and because they can adapt to arbitrarily complex relationships, modern machine learning methods based on tree ensembles such as RANDOM FORESTS and MART have become leading modern analytical methods. Here we propose to commercially implement RULEFIT, a recent innovative method extending the RANDOM FORESTS and MART approaches, that shows strong evidence of being consistently more accurate than either ensemble. RULEFIT also includes groundbreaking new methods for variable selection in the face of huge numbers of predictors, and for identifying interactions, and ranking their importance. Optionally, RULEFIT extracts ""rules"" of special interest: succinct statements of conditions under which an outcome is especially likely or unlikely, or especially large or small. The primary output of RULEFIT is a numeric value reecting a prediction of the value of the dependent variable or the probability of a class membership. RULEFIT is likely to become a leading technique in the machine learning and statistics. It builds on RANDOM FORESTS and MART and includes all their useful benefits such as variable selection, data exploration, data reduction, outlier detection, and missing value imputation, while enhancing and extending these benefits.  COMMERCIAL POTENTIAL The market for advanced analytical tools has been growing strongly over the last decade and the growth shows no signs of diminishing. Modelers and data analysts in both university- based and commercial settings are increasingly aware of the power and value of new analytical tools derived from modern statistics and machine learning research. The increased accuracy of the new methods and the acceleration they provide to the analysis of complex data are fueling demand for this new technology. The advances embedded in the proposed product represent substantial improvements to existing technology and include methods to solve vexing problems in contemporary data analysis, and thus should find a welcoming market.  There are further reasons to forecast robust commercial potential for this product. The applicant organization has a strong track record in the industry and is widely recognized as a developer of high quality software. We have been working with consultant Friedman since 1990 and have gained exclusive rights to the proprietary sourcecode for a number of his innovations. These include CART, MARS, MART and PRIM. With the addition of RULEFIT and its associated sub-components, these products represent a unique collection of pedigreed tools. We have also forged a similar relationship with the (late) Leo Breiman and have the exclusive rights to commercialization of Breiman's Random Forests sourcecode. Our proposed package thus occupies a distinctive position in machine learning software which cannot be replicated by other vendors. Keywords: machine learning; classi?cation; prediction; supervised learning; variable importance; inter- action detection; Justi?cation Dr. Steinberg has extensive experience in software development for advanced statistical and machine learning methods, particularly in the area of classi?cation and regression trees, sur- vival analysis, adaptive modeling, RANDOM FORESTS and MART. He will oversee all aspects of the project. He will will work with Dr. Cardell, Professor Friedman, Mr. Colla, and with the Salford Systems software development engineer in creating and studying the software and methods used in this proposal. He will also be responsible for the architecture of the Phase I software. Professor Friedman and Dr. Cardell will provide technical support as follows: Dr. Fried- man is an expert on machine learning methods and is one of the developers of the RULEFIT technique. Regular consultation with him will be in this area. Dr. Cardell is an expert in asymptotic theory, and in the design of Monte Carlo and other tests for the evaluation of ma- chine learning algorithms. He also has extensive experience in machine learning, including adaptive modeling, neural networks, logistic regression, and classi?cation methods. He will review core algorithms of RULEFIT for possible improvement and extension and design the Monte Carlo tests. Mr. Colla has extensive experience in software development and with machine learning methods, including work on the commercial implementations of CART, MARS, RANDOM FORESTS, and MART. Working with Dr. Cardell, he will be responsible for much of the new software coding. 5 Project Description Page 7 Principal Investigator/Program Director (Last, first, middle): Steinberg, Dan Prediction models based upon classification and regression tree ensembles have become important in medical and other research. There are currently no commercial products available that implement the proposed RuleFit methodology. These methods have significant advantages over existing techniques, and will aid researchers in obtaining the best possible predictions.   n/a",A RuleFit Product for Classification and Regression,7268612,R43CA124294,"['Acceleration', 'Agreement', 'Algorithms', 'Architecture', 'Area', 'Beds', 'Build-it', 'Cations', 'Class', 'Classification', 'Code', 'Collection', 'Comparative Study', 'Complex', 'Computer software', 'Condition', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Decision Trees', 'Detection', 'Disease', 'Disease regression', 'Engineering', 'Evaluation', 'Face', 'Generations', 'Growth', 'Industry', 'Information Systems', 'Investigation', 'Learning', 'Left', 'Life', 'Linear Models', 'Literature', 'Logistic Regressions', 'Machine Learning', 'Marketing', 'Measures', 'Medical', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Neural Network Simulation', 'Numbers', 'Outcome', 'Output', 'Painless', 'Pattern', 'Performance', 'Phase', 'Plant Leaves', 'Play', 'Positioning Attribute', 'Principal Investigator', 'Probability', 'Rate', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Rights', 'Role', 'Sampling', 'Severity of illness', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Trees', 'Universities', 'Variant', 'Vendor', 'Work', 'analytical method', 'analytical tool', 'base', 'commercialization', 'data mining', 'data structure', 'design', 'evaluation/testing', 'experience', 'forest', 'forging', 'graphical user interface', 'innovation', 'insight', 'interest', 'loss of function', 'man', 'new technology', 'novel', 'professor', 'programs', 'prototype', 'relating to nervous system', 'research study', 'software development', 'statistics', 'theories', 'tool', 'tumor', 'tumor growth', 'vector']",NCI,SALFORD SYSTEMS,R43,2007,91700,-0.004848555336756669
"The Use of Mathematic Algorithms in the Prevention of Improper Medical Payments    DESCRIPTION (provided by applicant): The goal of this research is to create software that uses mathematical algorithms to detect medical billing coding errors prior to payment. The well-publicized failure of current healthcare cost containment technologies to prevent improper payments in both the commercial healthcare market and the federal Medicare program highlights the urgent need for a new approach to the growing problem of out of control medical costs. A recent federal study by the GAO estimated that improper payments by Medicare alone were in excess of 21 billion dollars, a truly staggering 48.1 percent of all improper payments by federal programs. Like SPAM, whose dynamic nature makes static or post hoc remedies ineffective, effective cost containment in one area often merely leads to the creation of new areas of abuse. Clearly, the ideal solution is a system that can evaluate the fairness of payments before they are made, and that can respond to dynamic patterns of abuse. The first step in creating such a system is the creation of robust method for sorting bills for appropriate rule-based analysis on the basis of the type of bill. Currently neither Medicare nor major insurers are capable of making this classification reliably except through the use of inefficient, static rules and the use of manual sorting--a costly and inefficient approach to assuring timely payment to hospitals and medical providers. We propose a novel method for using mathematical algorithms that utilize machine-learning (ML) methods to address the problem of medical bill categorization, the first step in coding error detection. Specifically, we propose the evaluation of a variety of genetic algorithms that are well adapted to the problems of large, dynamic datasets and can be ""trained"" using real world correctly coded datasets in healthcare claims. This work is particularly timely due to recent Medicare contracting reform. Using more than 50 contractors and carriers, bill classification is largely determined by the carrier's contract. Centralizing this process to only four payment centers will require the classification system we propose. [This research is directed toward the development of software applications that will detect billing errors and perform proper edits to payment of medical bills. Current anticipated changes and reforms in the Medicare system will require these systems, which do not currently exist in the public or private sector.]             n/a",The Use of Mathematic Algorithms in the Prevention of Improper Medical Payments,7316071,R43LM009190,"['Address', 'Age', 'Algorithms', 'Area', 'Arts', 'Classification', 'Code', 'Collaborations', 'Computer Simulation', 'Computer software', 'Contractor', 'Contracts', 'Cost Control', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Development', 'Elements', 'Environment', 'Evaluation', 'Failure', 'Genetic Programming', 'Goals', 'Health Care Costs', 'Health Care Fraud', 'Health Personnel', 'Healthcare', 'Healthcare Market', 'Healthcare Systems', 'Hospitals', 'Industry', 'Inpatients', 'Insurance Carriers', 'Learning', 'Machine Learning', 'Manuals', 'Mathematics', 'Medical', 'Medicare', 'Methods', 'Mining', 'Modeling', 'Nature', 'Numbers', 'Operative Surgical Procedures', 'Outcome', 'Outpatients', 'Pattern', 'Phase', 'Policies', 'Population', 'Prevention', 'Private Sector', 'Process', 'Provider', 'Rate', 'Reporting', 'Research', 'Running', 'Small Business Technology Transfer Research', 'Solutions', 'Sorting - Cell Movement', 'Standards of Weights and Measures', 'System', 'Technology', 'Testing', 'Training', 'Work', 'base', 'college', 'computerized', 'cost', 'design', 'experience', 'improved', 'mathematical algorithm', 'novel', 'novel strategies', 'payment', 'prevent', 'programs', 'size', 'software development', 'stem', 'success']",NLM,"QMEDTRIX SYSTEMS, INC.",R43,2007,92482,-0.020616135694110638
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7246847,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'Work', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2007,2183988,-0.019472393955964073
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7318595,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease Resistance', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Numbers', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Range', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'novel', 'programs', 'size', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA IRVINE,R01,2007,372000,-0.016881666087739864
"Novel Analytic Techniques to Assess Physical Activity    DESCRIPTION (provided by applicant): Progress has been made in developing and using accelerometer-based motion sensors for physical activity research. However, traditional methods of processing activity monitor data do not provide sufficient accuracy to satisfy current trends in the use of objective physical activity data in the research arena. The aims of this proposal address this weakness in accelerometer- based PA assessment methodologies: The specific aims are: 1) To develop and validate novel methods to process Actigraph accelerometer data to improve estimates of PA using powerful modern classification methods (classification trees, discriminant analyses, hidden Markov models, neural networks, regression splines, and support vector machines); 2) To compare these classification methods and traditional approaches for assessing PA in a controlled setting; 3) To compare the classification methods and traditional approaches for quantifying PA in free living PA conditions and to select a recommended method; and 4) To correct for measurement error in summary estimates of habitual PA from the novel classification methods and traditional approaches for quantifying PA. Our uniquely qualified multidisciplinary research group will address these aims by first developing innovative classification methods to identify specific activities in a laboratory setting, and then validating the models using data collected from known activities performed in both controlled laboratory environments and free- living situations. Based on the results of these studies, the classification methods will be refined, and estimates of PA behavior will be adjusted using statistical measurement error methods to derive more accurate estimates of PA. We have chosen the classification methods to include publicly available ""off-the shelf"" classification methods that others can easily use. The resulting data processing programs will be implemented in popular commercial software packages and made freely available. The results of the proposed investigations will move the field of PA assessment forward by providing innovative approaches to derive more accurate and detailed estimates of PA using a popular accelerometer-based PA monitor. This systematic approach will provide information leading to a clearer understanding of the dose-response relationship between PA and health and the physiological basis of this relationship.           n/a",Novel Analytic Techniques to Assess Physical Activity,7262592,R01CA121005,"['Address', 'Area', 'Behavior', 'Biological Neural Networks', 'Chronic Disease', 'Classification', 'Computer software', 'Condition', 'Daily', 'Data', 'Diet', 'Discriminant Analysis', 'Disease regression', 'Dose', 'Effectiveness of Interventions', 'Environment', 'Health', 'Interdisciplinary Study', 'Intervention', 'Investigation', 'Laboratories', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Motion', 'NIH Program Announcements', 'Nature', 'Outcome', 'Output', 'Participant', 'Pattern', 'Performance', 'Physical activity', 'Physiological', 'Population', 'Principal Investigator', 'Process', 'Qualifying', 'Recommendation', 'Research', 'Scientist', 'Series', 'Techniques', 'Time', 'Time Study', 'Trees', 'Validation', 'Walking', 'Work', 'base', 'computerized data processing', 'improved', 'innovation', 'markov model', 'novel', 'novel strategies', 'nutritional epidemiology', 'programs', 'response', 'sensor', 'trend']",NCI,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,2007,263847,-0.003283028183983256
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,7269383,R01RR014477,[' '],NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2007,307022,-0.025340311652476504
"Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment    DESCRIPTION (provided by applicant):      Conventional ROC analysis has been widely accepted as a standard in the assessment of diagnostic techniques for binary diagnoses. Many medical diagnoses, however, involve multiple diagnostic alternatives. Examples are breast cancer diagnosis using mammography, where the diagnostic classes are normal, benign, or malignant tumor, and cardiac disease diagnosis using myocardial perfusion SPECT (MRS), where the classes are normal, reversible or fixed defect. To assess multi-class diagnostic techniques, multi-class ROC is required, but has remained an unsolved problem ever since the introduction of binary ROC analysis in the 1950s. Sparked by a practical challenge raised by MPS optimization, the candidate proposed a three- class ROC analysis method that extends and unifies the decision theoretic, linear discriminant analysis and probabilistic foundations of binary ROC in a three-class paradigm. She has conducted five preliminary studies on three-class ROC analysis: (1) deriving its decision model [He, Metz, et.al IEEE Trans Med Imag (TMI) vol. 25(5), 2006]; (2) investigating its decision theoretic foundation [He and Frey, TMI, vol. 25(8), 2006]; (3) exploring its linear discriminant analysis (LDA) foundation [He and Frey, TMI, in press, 2006]; (4) establishing its probabilistic foundation; and (5) comparing it with conventional three-class LDA and revealing the limitations of conventional three-class LDA. The candidate obtained a PhD in Biomedical Engineering in December 2005 and had intensive training on medical imaging. She increased her interest in medical image quality assessment during the development of three-class ROC analysis; her knowledge of the statistics and decision theory principals used in this research is self-taught. Further exploring new areas opened by three- class ROC analysis requires systematic understanding of the statistical principles in decision theory, statistical learning, and Bayesian modeling, etc. Thus, she requests a two-year mentored phase focusing on formal biostatistics training. The training phase will substantially enhance the candidate's career development as an interdisciplinary investigator and contribute to her independent research to accomplish the following specific aims: 1) to establish the theoretical foundations of three-class ROC analysis; (2) to develop general statistical methods for three-class ROC analysis; (3) to apply the three-class methodologies to task-based medical image quality assessment. The significance of the proposed work is two-fold. First, it provides a rigorous solution to an open theoretical problem and will open new areas of theoretical research in ROC analysis and medical decision making. Second, it enables applications of task-based assessment techniques for multi-class diagnosis. These techniques have the potential to fundamentally improve current imaging techniques for disease detection and characterization, and thus to enhance doctors' performance in disease diagnosis, which will broadly benefit public health.          n/a",Three-Class ROC Analysis for Task-Based Medical Image Quality Assessment,7298516,K99EB007620,"['Area', 'Benign', 'Biomedical Engineering', 'Biometry', 'Class', 'Classification', 'Clinical', 'Communities', 'Data', 'Decision Making', 'Decision Modeling', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Discriminant Analysis', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Foundations', 'Goals', 'Grant', 'Heart Diseases', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Investigation', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical', 'Medical Imaging', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Myocardial perfusion', 'Patients', 'Performance', 'Phase', 'Physical assessment', 'Pilot Projects', 'Public Health', 'ROC Curve', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Statistical Methods', 'Surface', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Training', 'Work', 'base', 'breast cancer diagnosis', 'career', 'improved', 'interest', 'programs', 'response', 'single photon emission computed tomography', 'statistics']",NIBIB,JOHNS HOPKINS UNIVERSITY,K99,2007,88539,-0.030599994594693113
"Comparative Visualization and Analysis for GCxGC    DESCRIPTION (provided by applicant): Project Summary. This project will investigate and develop effective information technologies for comparative analysis and visualization of complex data generated by comprehensive two-dimensional gas chromatography (GCxGC). GCxGC is an emerging technology that provides an order-of-magnitude greater separation capacity, significantly better signal-to-noise ratio, and higher dimensional retention-structure relations than traditional GC. The principal challenge for utilization of GCxGC, in a wide range of public-health and other applications, is the difficulty of analyzing and interpreting the large, complex data it generates. The quantity and complexity of GCxGC data necessitates the investigation and development of new information technologies. This project will develop and demonstrate innovative methods and tools for comparative analysis of GCxGC datasets. The expected results of this research and development include a PCA-based method for chemical fingerprinting, decision trees with chemical constraints for sample classification, genetic programming for template and constraint-based matching and classification, and visualization methods for comparative GCxGC analyses. These methods will be implemented in commercial software that will support researchers and laboratory analysts in a wide range of commercial applications, including health care, environmental monitoring, and chemical processing. The power of GCxGC, supported by effective information technologies, will enable better understanding of chemical compositions and processes, a foundation for future scientific advances and discoveries. Relevance to Public Health. Today, a few advanced laboratories are pioneering GCxGC for a variety of applications such as environmental monitoring of exposure profiles in air, soil, food, and water; identification and quantification of toxic products in blood, urine, milk, and breath samples; and qualitative and quantitative metabolomics to provide a holistic view of the biochemical status or biochemical phenotype of an organism. Many analyses in these applications require detailed chemical comparisons of samples, e.g..monitoring changes, comparison to reference standards, chemical matching or ""fingerprinting"", and classification. GCxGC is a powerful new technology for such comparative analyses. This proposal will provide innovative information technologies to support users in these applications.           n/a",Comparative Visualization and Analysis for GCxGC,7270029,R44RR020256,"['Air', 'Archives', 'Biochemical', 'Blood', 'Chemicals', 'Classification', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Trees', 'Development', 'Emerging Technologies', 'Environmental Monitoring', 'Fingerprint', 'Food', 'Foundations', 'Future', 'Gas Chromatography', 'Genetic Programming', 'Goals', 'Healthcare', 'Image', 'Imagery', 'Information Technology', 'Investigation', 'Laboratories', 'Language', 'Machine Learning', 'Marketing', 'Methods', 'Milk', 'Monitor', 'Noise', 'Organism', 'Pattern', 'Phase', 'Phenotype', 'Principal Component Analysis', 'Process', 'Public Health', 'Range', 'Reference Standards', 'Reporting', 'Research Personnel', 'Sales', 'Sampling', 'Schedule', 'Scientific Advances and Accomplishments', 'Signal Transduction', 'Software Tools', 'Soil', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Today', 'Trademark', 'Urine', 'Water', 'base', 'chemical fingerprinting', 'commercial application', 'comparative', 'innovation', 'innovative technologies', 'instrument', 'metabolomics', 'new technology', 'research and development', 'tool', 'two-dimensional']",NCRR,"GC IMAGE, LLC",R44,2007,239373,-0.012148473654653756
"Developing computerized tools for cryosurgery planning    DESCRIPTION (provided by applicant):    Cryosurgery has been known as an invasive surgical technique since 1961, when Cooper and Lee invented the first cryoprobe. In the 1990s, new developments in Joule-Thomson cooling (the cooling effect associated with a sudden relief of a pressurized gas) led to a dramatic decrease in the size of cryoprobes and an increase in the number of cryoprobes that could be used simultaneously. A dozen or more cryoprobes operating simultaneously in a single prostate cryosurgery is already common practice. If localized effectively, one of the primary benefits of using a large number of miniaturized cryoprobes is superior control over the freezing process.   Currently, the process of selecting the correct placement of the cryoprobes for a specific procedure is an art held by the cryosurgeon, based on the surgeon's own experience and rules of thumb. Cryoprobes are typically operated in a trial-and-error fashion, until the entire target volume is thought to be frozen. Currently, there are no means to determine the optimal locations for the cryoprobes. Suboptimal cryoprobe localization may leave regions in the target volume unfrozen, may lead to cryoinjury of healthy surrounding tissues, may require an unnecessarily large number of cryoprobes, may increase the duration of the surgical procedure, and may increase the likelihood of post cryosurgery complications, all of which affect the quality and cost of the medical treatment. Computerized planning tools would help to alleviate these difficulties.   The ""cryoheater,"" a new device for cryosurgery control has recently been presented by the research team. The cryoheater is a temperature controlled electrical heater. In broad terms, cryoheaters can dramatically increase the ability to control the shape and size of the frozen region, however, to achieve the full benefits of cryoheaters, computerized planning tools for cryoheater localization are necessary.   Our goal is to develop computerized planning tools for cryosurgery that are suitable for all available cooling techniques. The proposed research includes: (1) Development of an efficient numerical scheme for bioheat transfer simulations of cyroprocedures, (2) Development of an efficient optimization technique based on a force-field analogy. (3) Development of knowledge-based optimization techniques. (4) Experimental verification of the planning tool.       Besides planning, another important application of the proposed tool is the training of cryosurgeons. The proposed tool will provide cryosurgeons with the ability to visualize the 3D volumetric nature of the freezing process.   Likewise, it will allow the surgeon to explore the performance of various configurations of cryoprobes and cryoheaters, and observe the defects that would result from each. Such visualization capabilities will provide surgeons with insights into the physics of cryosurgery that are difficult to obtain from physical experiments or surgical practice.         n/a",Developing computerized tools for cryosurgery planning,7210691,R01EB003563,"['Affect', 'Arts', 'Biological', 'Catheters', 'Computational Technique', 'Condition', 'Cool-X-A', 'Cryosurgery', 'Defect', 'Depth', 'Development', 'Devices', 'Europe', 'Feasibility Studies', 'Freezing', 'Frequencies', 'Furuncles', 'Gases', 'Goals', 'Heating', 'Imagery', 'Imaging Device', 'Invasive', 'Lasers', 'Lead', 'Learning', 'Left', 'Liquid substance', 'Localized', 'Location', 'Machine Learning', 'Medical', 'Methods', 'Modems', 'Nature', 'Nitrogen', 'Numbers', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Performance', 'Physics', 'Placement', 'Procedures', 'Process', 'Prostate', 'Publishing', 'Purpose', 'Radio', 'Reporting', 'Research', 'Research Proposals', 'Scheme', 'Shapes', 'Simulate', 'Solutions', 'Source', 'Surgeon', 'Techniques', 'Temperature', 'Thermal Ablation Therapy', 'Thinking', 'Thumb structure', 'Time', 'Tissues', 'Training', 'Ultrasonography', 'Urethra', 'base', 'clinical application', 'computerized', 'computerized tools', 'cost', 'experience', 'insight', 'knowledge base', 'miniaturize', 'research study', 'simulation', 'size', 'thermal seeds', 'three-dimensional modeling', 'tool']",NIBIB,CARNEGIE-MELLON UNIVERSITY,R01,2007,87443,-0.0034298560703572433
MACE - Michigan Alliance for Cheminformatic Exploration No abstract available n/a,MACE - Michigan Alliance for Cheminformatic Exploration,7472717,P20HG003890,"['Address', 'Algorithms', 'Applications Grants', 'Area', 'Belief', 'Bioinformatics', 'Biotechnology', 'Categories', 'Cell Nucleus', 'Chemicals', 'Chemistry', 'Class', 'Classification', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Descriptor', 'Development', 'Educational workshop', 'Effectiveness', 'Environment', 'Evaluation', 'Faculty', 'Funding', 'Generations', 'Generic Drugs', 'Grant', 'Hybrids', 'Industry', 'Institution', 'Interdisciplinary Study', 'Knowledge', 'Laboratories', 'Location', 'Machine Learning', 'Methodology', 'Methods', 'Michigan', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Medicine', 'Molecular Structure', 'Online Systems', 'Pattern Recognition', 'Pharmacotherapy', 'Pilot Projects', 'Preparation', 'Process', 'Property', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Screening procedure', 'Seeds', 'Site', 'Specialist', 'Structure', 'Students', 'Sum', 'TNFRSF5 gene', 'Techniques', 'Testing', 'Travel', 'Validation', 'Vision', 'Work', 'base', 'chemical property', 'cheminformatics', 'computer center', 'computer science', 'concept', 'data mining', 'design', 'in vitro Assay', 'interdisciplinary approach', 'knowledge base', 'model development', 'organizational structure', 'predictive modeling', 'symposium', 'tool', 'training project']",NHGRI,UNIVERSITY OF MICHIGAN,P20,2007,271370,-0.007693349885409842
"Optical surveillance of tumor margins in patients undergoing breast conserving su    DESCRIPTION (provided by applicant):  In 2005, 72,000 women that underwent breast surgery had to have a second re-excision surgery due to incomplete removal of the cancer during the first surgery. Needing a second surgery means increased cancer recurrence, patient anxiety, complications, and cost. Currently, surgeons have no readily available, cost efficient, intraoperative instruments that ensure that the cancer has been completely excised to prevent re-excision. To improve care, surgeons are seeking real time information on the tumor margins at the site of excision. Prior intraoperative solutions (frozen section and cytology) to prevent re-excision have not been adopted because they required a pathologist in the O.R., take too long during surgery, and only examine less than 1% of the tumor margin. Our long-term objective is to develop a chemically specific and quantitative multi-channel optical assay device for intraoperative assessment of tumor margins in patients undergoing breast conserving surgery (lumpectomy). The optical device will provide non-destructive evaluation of approximately 80% of the tumor margin in the excised specimen (as opposed to 1% provided by touch prep or frozen section); require no specialized personnel or sample processing (cutting and staining); and will require considerably less time than conventional techniques. The goal of the work is to design, fabricate and evaluate a single- channel alpha version of the optical assay device that will provide point measurements, and conduct a pilot clinical study on ex vivo breast tissues to demonstrate the feasibility and effectiveness of our novel technology. The specific aims are to: (1) design and optimize a single-channel optical device using Monte Carlo simulations; (2) build an alpha prototype device based on the simulations, and (3) validate the device's performance against a standard bench- top optical system on synthetic breast tissue phantoms, and determine the sensitivity and specificity on excised human breast tissue specimens in a pilot clinical study. Concurrent with this effort, we are recruiting expertise in management, regulatory and reimbursement strategies so that we will be well positioned to bring this device to market following completion of the R&D program. This device will have significant clinical benefits including: (1) reduced repeat surgeries and hence, reduced local recurrence, (2) reduced tissue removal, which translates to cosmetically-superior lumpectomies at the time of the first surgery, (3) reduced emotional distress, (4) reduced complications due to reduced number of surgeries and shorter recovery times for the patient and (5) reduced cost for the patient and the healthcare system. Successful completion of this project will set the foundation for the development of a fast, multi-pixel optical assay system for intraoperative assessment of tumor margins in patients undergoing breast cancer surgery. The optical assay system will have significant clinical benefits including: (1) reduced re-excision rates, (2) reduced tissue removal, which translates to cosmetically-superior lumpectomies at the time of the first surgery, (3) better margin assessment leading to reduced repeat surgeries and hence, reduced local recurrence, (4) reduced emotional distress, and (5) reduced complications due to reduced number of surgeries and shorter recovery times for the patient.          n/a",Optical surveillance of tumor margins in patients undergoing breast conserving su,7270954,R41CA128160,"['Adopted', 'Algorithms', 'Anxiety', 'Biological Assay', 'Breast', 'Breast-Conserving Surgery', 'Caliber', 'Cancerous', 'Caring', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collection', 'Cytology', 'Depth', 'Development', 'Devices', 'Diffuse', 'Effectiveness', 'Ensure', 'Evaluation', 'Excision', 'Foundations', 'Frequencies', 'Frozen Sections', 'Goals', 'Gold', 'Healthcare Systems', 'Histopathology', 'Human', 'Human Resources', 'Imaging Device', 'Lighting', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammary Gland Parenchyma', 'Marketing', 'Measurement', 'Measures', 'Medical Surveillance', 'Methods', 'Modeling', 'Noise', 'Non-Malignant', 'Numbers', 'Operative Surgical Procedures', 'Optics', 'Pathologic', 'Pathologist', 'Pathology', 'Patients', 'Performance', 'Personal Satisfaction', 'Phase', 'Positioning Attribute', 'Process', 'Property', 'Range', 'Rate', 'Recovery', 'Recruitment Activity', 'Recurrence', 'Repeat Surgery', 'Reproducibility', 'Research', 'Risk', 'Sampling', 'Sensitivity and Specificity', 'Series', 'Signal Transduction', 'Site', 'Small Business Technology Transfer Research', 'Solutions', 'Specimen', 'Spectrum Analysis', 'Staining method', 'Stains', 'Standards of Weights and Measures', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Touch sensation', 'Translating', 'Woman', 'Work', 'absorption', 'base', 'breast cancer diagnosis', 'breast lumpectomy', 'breast surgery', 'cancer cell', 'cancer recurrence', 'cancer surgery', 'cost', 'cost efficient', 'design', 'desire', 'detector', 'emotional distress', 'feeding', 'improved', 'in vivo', 'instrument', 'malignant breast neoplasm', 'new technology', 'prevent', 'programs', 'prototype', 'research and development', 'simulation', 'tissue phantom', 'tumor']",NCI,"ZENALUX BIOMEDICAL, INC.",R41,2007,195843,-0.0760999003761902
"Dysbiosis in Inflammatory Bowel Disease    DESCRIPTION (provided by applicant): Inflammatory Bowel Diseases (IBDs), namely ulcerative colitis (DC) and Crohn's disease (CD), are chronic, lifelong, relapsing illnesses, affecting close to 1 million Americans. Despite the many clues that a dysbiosis may exist in IBD, the specific changes in the microflora of IBD patients are largely unknown. Amplicon length heterogeneity (ALH) is a sophisticated and well established PCR based technology that can be used as a screening tool to identify changes in the Bacterial microflora of IBD patients. We therefore have hypothesized that the ileocolonic microflora in IBD has an altered microbial composition compared to normal microflora. We have gathered preliminary data that shows statistical differences between controls and IBD as well as within IBD patients. Therefore, to test the above hypothesis, we are proposing the following 2 inter-related scientific aims: AIM 1. Identify bacterial fingerprint patterns associated with IBD using ALH. ALH patterns will be determined in a total of 160 IBD patients and health controls and will be analyzed using diversity indeces, multivariate reduction analysis and cluster analysis. ALH patterns associated with IBD will be determined using histograms, ecological software in conjunction with custom PERL scripts as well as supervised and unsupervised automated pattern recognition systems. AIM 2.Determine the bacterial contents of putatively IBD associated ALH fingerprint patterns using molecular cloning and sequencing. Cloning and sequencing of targeted samples will be linked to bacterial identities by employing multiple bioinformatics tools. Significance. This proposal involves the first time use of a sophisticated and highly reproducible molecular biology tool, ALH, in the study of microflora in the Gl tract. There is a growing recognition of the importance of microflora in health and disease, including IBD. Studies that characterized microflora in human using powerful techniques from environmental microbiology such as ALH can bring about significant advances in the understanding of Gl tract illnesses. ALH may enable a real-time survey of microfloral changes for the first time in medicine and may provide the first evidence linking IBD with specific microbial patterns.           n/a",Dysbiosis in Inflammatory Bowel Disease,7197734,R21DK071838,"['Affect', 'Age', 'Algorithms', 'American', 'Attention', 'Back', 'Bacteria', 'Bioinformatics', 'Biopsy Specimen', 'Bispecific Antibody 2B1', 'Celiac Disease', 'Chronic', 'Clinical', 'Cloning', 'Cluster Analysis', 'Colon', 'Colonoscopy', 'Colorectal', 'Complex', 'Computer software', 'Crohn&apos', 's disease', 'Custom', 'DNA', 'Data', 'Databases', 'Disease', 'Distal part of ileum', 'Effectiveness', 'Environment', 'Environmental Microbiology', 'Feces', 'Fingerprint', 'Flare', 'Flexible fiberoptic sigmoidoscopy', 'Future', 'Gender', 'Genus Cola', 'Hand', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Human', 'Human body', 'Immunosuppressive Agents', 'Incidence', 'Individual', 'Infection', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Intestines', 'Irritable Bowel Syndrome', 'Knowledge', 'Length', 'Link', 'Machine Learning', 'Maps', 'Medicine', 'Methods', 'Molecular Biology', 'Molecular Cloning', 'Morbidity - disease rate', 'Mucous Membrane', 'Newly Diagnosed', 'Numbers', 'Operative Surgical Procedures', 'Organ', 'Organism', 'Patients', 'Pattern', 'Pattern Recognition', 'Pattern Recognition Systems', 'Pharmaceutical Preparations', 'Polymerase Chain Reaction', 'Population', 'Probiotics', 'Procedures', 'Race', 'Reaction', 'Recruitment Activity', 'Relapse', 'Relative (related person)', 'Research Personnel', 'Ribosomal RNA', 'Sampling', 'Schedule', 'Screening procedure', 'Soil', 'Surveys', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Toxic effect', 'Ulcerative Colitis', 'Visual', 'base', 'carcinogenesis', 'clinical application', 'computerized', 'cost', 'data mining', 'disabling disease', 'ileum', 'indexing', 'microbial', 'microbial community', 'neglect', 'novel', 'novel diagnostics', 'pathogen', 'prebiotics', 'programs', 'satisfaction', 'success', 'time use', 'tool', 'treatment effect']",NIDDK,RUSH UNIVERSITY MEDICAL CENTER,R21,2007,222000,-0.020850497967969006
"Automatic Detection of Critical Dermoscopy Features for Melanoma Diagnosis    DESCRIPTION (provided by applicant): Malignant melanoma, with an estimated growth in incidence of about 6% per year for decades, causes considerable loss of life. Yet melanoma can be easily cured if detected early. Digital dermoscopy has shown promise for more accurate detection, particularly at an early stage. Recent conferences have highlighted a general agreement on definition of dermoscopic features and moderate agreement on the most useful structural features. Automatic detection of these specific structures that are critical for early diagnosis and are used in various dermoscopic diagnostic algorithms would be desirable. Yet little work has been published on automatic detection of any specific dermoscopic structures. Although specific colors figure prominently in the definition of the most critical dermoscopic structures, little work has been done on finding the specific regions or region combinations in the color space where colors are located, particularly with reference to the surrounding skin. The work in Phase I and after Phase I successfully segmented the border within 5% of the range of the dermatologists' borders, found several highly accurate dermoscopy features, and brought mean diagnostic accuracy on difficult early lesions to a high level. This proposal seeks to develop a digital dermosocopy system by 1) comparing classifiers 2) testing border accuracy and modifying segmentation if needed 3) developing an algorithm that uses a three-dimensional representation of a probability density function to specify single and paired melanoma colors via cluster methods and fuzzy logic techniques 4) identifying critical structural features including brown globules, abrupt border cutoff, granularity, regression, and pigment asymmetry with high accuracy 5) developing a clinical interface for acquisition of images within the clinic 6) testing the new algorithms in six dermatology clinics including two pigmented lesion clinics with both EpiLight and DermLite II Pro dermoscopy images taken in the clinic. Key features of the research include dermatopathology confirmation of specific structures and the use of relative color analysis. If successful, software will be marketed to the growing number of dermatologists with digital dermoscopy capability. The commercial software package will be ready for marketing as a diagnostic adjunct for digital camera dermoscopy attachments. Malignant melanoma, with an estimated growth in incidence of about 6% per year for decades, causes considerable loss of life. Melanoma can be easily cured if detected early, and this project seeks to develop a digital dermoscopy device that can detect very early melanomas. The project goal is to develop inexpensive melanoma detection software and test it in multiple dermatology clinics.          n/a",Automatic Detection of Critical Dermoscopy Features for Melanoma Diagnosis,7284886,R44CA101639,"['Agreement', 'Algorithms', 'Am 80', 'Amelanotic Melanoma', 'American', 'Architecture', 'Area', 'Benign', 'Biological', 'Biological Neural Networks', 'Biopsy', 'Blood Vessels', 'Borderline Lesion', 'Boxing', 'Calibration', 'Characteristics', 'Cicatrix', 'Class', 'Classification', 'Clinic', 'Clinical', 'Code', 'Color', 'Computer software', 'Computer-Assisted Image Analysis', 'Count', 'Decision Trees', 'Dermatologist', 'Dermatology', 'Dermoscopy', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease regression', 'Dysplastic Nevus', 'Early Diagnosis', 'Effectiveness', 'Equipment', 'Evaluation', 'Excision', 'Fuzzy Logic', 'Goals', 'Government', 'Growth', 'Hair', 'Hair Removal', 'Head', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Incidence', 'Lentigo', 'Lesion', 'Life', 'Lighting', 'Location', 'Machine Learning', 'Manuals', 'Marketing', 'Measures', 'Methods', 'N(delta)-acetylornithine, -isomer', 'N-dodecanoylglutamic acid, -isomer, sodium salt', 'Noise', 'Numbers', 'Odds Ratio', 'Pattern', 'Peripheral', 'Persons', 'Phase', 'Phase I Clinical Trials', 'Physicians', 'Pigments', 'Precancerous melanosis', 'Probability', 'Process', 'Published Comment', 'Publishing', 'Purpose', 'ROC Curve', 'Radial', 'Range', 'Rate', 'Relative (related person)', 'Reporting', 'Research', 'Risk', 'Score', 'Series', 'Skin', 'Software Tools', 'Source', 'Specificity', 'Staging', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'To specify', 'Training', 'Work', 'alpha-difluoromethyl-DOPA, -isomer', 'alpha-methylornithine dihydrochloride, -isomer', 'base', 'density', 'diagnostic accuracy', 'digital', 'experience', 'improved', 'indexing', 'melanoma', 'reconstruction', 'software development', 'software systems', 'statistics', 'symposium', 'tool development', 'vector']",NCI,STOECKER & ASSOCIATES,R44,2007,494442,-0.028239535629350512
"Bayesian Methods and Experimental Design for Molecular Biology Experiments    DESCRIPTION (provided by applicant): The goal of this proposal is to provide a suite of software tools for bioinformatics and systems biology researchers who are using molecular biology (Omics) data to identify the best experimental design and to analyze the resulting experimental data using Bayesian tools. A common problem for most bioinformatics experiments is low power due to low replication. This problem can be alleviated economically when an increase in adoption and use of a specific platform leads to a decrease in associated costs, thereby enabling an increase in samples allocated per treatment. Yet, many bioinformatics experiments remain underpowered as researchers use the offsets of decreased costs to explore more complex questions. When designing an experiment, the allocation of samples to treatment regimens, and the choice of treatments to test, are traditionally the only variables to manipulate. Bayesian experimental design provides a framework to find the optimal design out of n possible designs subject to a utility function that can include such items as time and material costs.      Bayesian statistical methods have been gaining substantial favor in bioinformatics and systems biology as they provide a highly flexible framework for fitting and exploring complex models. Bayesian models also provides to domain experts such as biologists and physicians easily interpretable models through posterior probabilities which are more naturally understood than the traditional p-value. While a number of open source tools based on Bayesian models are available, most are applied best in the context of a specific research data analysis problem or model and are not integrated into a single, complete system for data analysis.      We propose to research and develop a statistical analysis software package S+OBAYES (for S-PLUS and R) with generalized tools for Bayesian design of experiments, empirical and fully Bayesian analysis, and modeling and simulation using modern commercial software development practices. These tools will provide functionality for finding the optimal choice and layout of experimental treatments for molecular biology experiments and for fitting Bayesian linear and non-linear models to a variety of data types including time series. We propose to validate the software in molecular biology research problems such as the detection of differential gene, protein, and metabolite abundance. The benefits of this work will be a commercial-quality software package with validated statistical methodology and interactive visualization tools that will appeal to molecular biologists and systems biology investigators. The results of the proposed work will expedite discoveries in basic science, early disease detection, and drug discovery and development.          n/a",Bayesian Methods and Experimental Design for Molecular Biology Experiments,7325828,R43GM083023,"['Address', 'Adoption', 'Algorithms', 'Animal Genetics', 'Arizona', 'Basic Science', 'Bayesian Analysis', 'Bayesian Method', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biological Sciences', 'Biometry', 'Biotechnology', 'Cations', 'Chromosome Mapping', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Department of Defense', 'Depth', 'Detection', 'Development', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Employment', 'Ensure', 'Experimental Designs', 'Exposure to', 'Factor Analysis', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Government', 'Government Agencies', 'Health', 'Imagery', 'Industry', 'Information Systems', 'Institution', 'Iowa', 'Libraries', 'Linear Models', 'Machine Learning', 'Manuals', 'Manuscripts', 'Maps', 'Marketing', 'Mass Spectrum Analysis', 'Measures', 'Medical Informatics', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Molecular', 'Molecular Biology', 'Non-linear Models', 'Numbers', 'Pathway interactions', 'Phase', 'Physicians', 'Population Study', 'Principal Investigator', 'Probability', 'Property', 'Proteome', 'Proteomics', 'Proxy', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Rice', 'Risk Factors', 'SNP genotyping', 'Sampling', 'Science', 'Scientist', 'Series', 'Services', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Tools', 'Software Validation', 'Solutions', 'Speed', 'Standards of Weights and Measures', 'Statistical Methods', 'Statistical Models', 'Systems Biology', 'Techniques', 'Telecommunications', 'Testing', 'Time', 'Time Series Analysis', 'Training', 'Treatment Protocols', 'Universities', 'Validation', 'Washington', 'Wisconsin', 'Work', 'animal breeding', 'base', 'cost', 'design', 'drug discovery', 'experience', 'human subject', 'improved', 'interest', 'lecturer', 'models and simulation', 'open source', 'professor', 'programs', 'protein metabolite', 'research and development', 'research study', 'skills', 'software development', 'statistics', 'success', 'theories', 'tool', 'treatment effect']",NIGMS,INSIGHTFUL CORPORATION,R43,2007,103995,-0.04185272722433231
"Smart Wheelchair Component System    DESCRIPTION (provided by applicant):  Independent mobility is critical to individuals of any age. While the needs of many individuals with disabilities can be satisfied with power wheelchairs, some members of the disabled community find it difficult or impossible to operate a standard power wheelchair. This population includes, but is not limited to, individuals with low vision, visual field neglect, spasticity, tremors, or cognitive deficits. The goal of this project is to develop a set of components that can be added to standard power wheelchairs to convert them into ""smart"" wheelchairs which can assist the user in navigation and obstacle avoidance. During Phase I, a prototype of the Smart Wheelchair Component System (SWCS) was developed from a laptop computer and a collection of sonar, infrared and bump sensors. The evaluation activities performed during Phase I demonstrated that the system is compatible with multiple brands of wheelchairs, can accept both continuous and switch-based input, and can support front-, mid-, and rear-wheel drive wheelchairs. During Phase II, we propose to refine the system hardware and software; replace the laptop computer with an embedded microprocessor; fabricate enclosures for the system components; and develop tools to support clinicians in installing and configuring the system. The system will be evaluated in tests involving potential users, clinicians, and wheelchair design standards. The final product will be a market-ready modular system which can be attached to a variety of standard power wheelchairs. This product has the potential to increase the independence and quality of life of many wheelchair users and potential wheelchair users whose disabilities limit their capacity for independent wheelchair navigation.       n/a",Smart Wheelchair Component System,7237214,R44HD040023,"['Adult', 'Age', 'Child', 'Client', 'Cognitive deficits', 'Collection', 'Communities', 'Compatible', 'Computer Vision Systems', 'Computer software', 'Computers', 'Condition', 'Destinations', 'Development', 'Disabled Persons', 'Disadvantaged', 'Documentation', 'Equipment', 'Evaluation', 'Future', 'Goals', 'Individual', 'Joystick', 'Laboratories', 'Learning', 'Location', 'Locomotion', 'Manufacturer Name', 'Marketing', 'Methods', 'Microprocessor', 'Numbers', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Powered wheelchair', 'Production', 'Quality of life', 'Range', 'Relative (related person)', 'Research Personnel', 'Robot', 'Self Perception', 'Standards of Weights and Measures', 'System', 'Technology', 'Testing', 'Touch sensation', 'Travel', 'Tremor', 'Visual Fields', 'Visual impairment', 'Wheelchairs', 'Work', 'base', 'data acquisition', 'design', 'disability', 'laptop', 'member', 'neglect', 'peer', 'prototype', 'sensor', 'sonar', 'tool']",NICHD,AT SCIENCES,R44,2007,387828,-0.00608192912268225
"Designing Visually Accessible Spaces    DESCRIPTION (provided by applicant): Reduced mobility is one of the most debilitating consequences of vision loss for more than three million Americans with low vision. We define visual accessibility as the use of vision to travel efficiently and safely through an environment, to perceive the spatial layout of key features in the environment, and to keep track of one's location in the environment. Our long-term goal is to create tools to enable the design of safe environments for the mobility of low-vision individuals and to enhance safety for the elderly and others who may need to operate under low lighting and other visually challenging conditions. We plan to develop a computer-based design tool in which environments (such as a hotel lobby, large classroom, or hospital reception area), could be simulated with sufficient accuracy to predict the visibility of key landmarks or obstacles, such as steps or benches, under differing lighting conditions. Our project addresses one of the National Eye Institute's program objectives: ""Develop a knowledge base of design requirements for architectural structures, open spaces, and parks and the devices necessary for optimizing the execution of navigation and other everyday tasks by people with visual impairments"". Our research plan has four specific goals: 1) Develop methods for predicting the physical levels of light reaching the eye in existing or planned architectural spaces. 2) Acquire performance data for normally sighted subjects with visual restrictions and people with low vision to investigate perceptual capabilities critical to visually-based mobility. 3) Develop models that can predict perceptual competence on tasks critical to visually-based mobility. 4) Demonstrate a proof-of-concept software tool that operates on design models from existing architectural design systems and is able to highlight potential obstacles to visual accessibility. The lead investigators in our partnership come from three institutions: University of Minnesota Gordon Legge, Daniel Kersten; University of Utah William Thompson, Peter Shirley, Sarah Creem-Regehr; and Indiana University Robert Shakespeare. This interdisciplinary team has expertise in the four areas required for programmatic research on visual accessibility empirical studies of normal and low vision (Legge, Kersten, Creem-Regehr, and Thompson), computational modeling of perception (Legge, Kersten, and Thompson), photometrically correct computer graphics (Shirley), and architectural design and lighting (Shakespeare).           n/a",Designing Visually Accessible Spaces,7172766,R01EY017835,"['Accounting', 'Address', 'American', 'Area', 'Arts', 'Blindness', 'Characteristics', 'Classification', 'Competence', 'Complex', 'Computer Graphics', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Condition', 'Contrast Sensitivity', 'Data', 'Depressed mood', 'Detection', 'Development', 'Devices', 'Elderly', 'Engineering', 'Environment', 'Evaluation', 'Eye', 'Goals', 'Hospitals', 'Indiana', 'Individual', 'Institution', 'Lead', 'Light', 'Lighting', 'Lobbying', 'Location', 'Measurement', 'Methods', 'Minnesota', 'Modeling', 'National Eye Institute', 'Pattern', 'Perception', 'Performance', 'Peripheral', 'Photometry', 'Published Comment', 'Range', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Priority', 'Safety', 'Simulate', 'Software Tools', 'Space Models', 'Space Perception', 'Specialist', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Testing', 'Travel', 'Universities', 'Utah', 'Vision', 'Visual', 'Visual impairment', 'base', 'concept', 'design', 'innovation', 'knowledge base', 'luminance', 'model design', 'model development', 'physical model', 'predictive modeling', 'programs', 'tool', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2007,487230,0.0016032855615153504
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,7111722,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2006,314029,-0.025340311652476504
"Support Vector Machine modeling software for improving RNAi efficacy prediction    DESCRIPTION (provided by applicant): Title Support vector machines predict sequence ~ activity relationships in RNA interference: Project Summary/Abstract: Support Vector Machines (SVMs) are a group of algorithms in supervised machine learning that are able to build classification or regression models on training data such that these models can be used to predict information not seen during model construction. RNA interference (RNAi) is the property of small (20 to 23 bases) RNA sequences that with the help of the RNA Induced Silencing Complex (RISC) enable the catalytic cleavage of target RNA sequences and the knockdown of the expression level of the target gene. The steps involved in loading and associating an RNAi sequences into an active RISC are several in addition to the multi-factorial variation in biochemical activities of RNAi sequences once in an active RISC. Finding the relevant biochemical features that associate with these quantifiable measures of RNAi can allow i) better predictive models of RNAi and RNAi-like (e.g. microRNAs) activities and ii) a better understanding of the relevant biochemical properties since presumably less relevant properties should not increase the predictive abilities of models containing those properties. We have developed a novel feature mapping method, referred to as Binary Base mapping, that improves the ability of a SVM to predict RNAi activities when compared to 2 previous methods, refered to as Unit Vector and N-gram mapping. Alone, the Binary Base SVM method has greater predictive accuracy than a recently published neural network machine learning method, on the same training and testing data. Several additional mapping methods can be envisioned, including methods that incorporate RNAi thermodynamics, secondary structure or measures of entropy, and whether alone or in combination these mappings of sequence to vector space for SVM model construction lead to better predictive models or understanding of RNAi biochemistry is unknown. We are requesting funding for the specific aims of: i) testing whether the Binary Base method can be used to further dissect and identify relevant biochemical feature associated with RNAi activity, ii) analyzing what additional vector mapping methods lead to predictive models with increased accuracy or greater understanding of relevant biochemical properties, and iii) investigating the distribution of sites within and among target mRNA genes where predictive SVM models identify high versus low activity. Title Support vector machines predict sequence ~ activity relationships in RNA interference: Project Narrative: Small non-coding RNAs (sncRNAs) have regulatory influence in human development and disease and better understanding how these molecules function involves the development of predictive models. Machine learning methods such as Support Vector Machines (SVMs) are 1 way to develop predictive models for these small RNA sequences and the incorporation of novel mapping methods in SVMs leads to model improvement. Finding and combining additional sequence mapping methods can lead to better predictive models for RNA interference activity as well as related processes such as microRNA activity, chemical modification of RNAi and RNAi stability or RNAi toxicity; further improving the understanding of how scnRNAs function and how they might be regulated.          n/a",Support Vector Machine modeling software for improving RNAi efficacy prediction,7157547,R43GM079132,"['RNA interference', 'biotechnology', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'gene targeting', 'genetic mapping', 'mathematical model', 'messenger RNA', 'method development', 'molecular genetics', 'nucleic acid sequence', 'nucleic acid structure', 'thermodynamics']",NIGMS,"INTEGRATED DNA TECHNOLOGIES, INC.",R43,2006,97773,-0.042655447073970856
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,7287568,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2006,38558,-0.00446733780521259
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,7286911,R01EY003311,"['artificial intelligence', 'atrial natriuretic peptide', 'biological transport', 'body water dehydration', 'clinical research', 'cornea edema', 'corneal endothelium', 'corneal epithelium', 'corneal stroma', 'electrophysiology', 'human subject', 'intraocular fluid', 'laboratory rabbit', 'mathematical model', 'membrane permeability', 'model design /development', 'morphology', 'nitric oxide', 'refractive keratoplasty', 'thermodynamics', 'vision tests', 'visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2006,76298,0.00701052218893366
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7015019,R01NS051826,"['Alzheimer&apos', 's disease', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain morphology', 'human data', 'image enhancement', 'image guided surgery /therapy', 'magnetic resonance imaging', 'mathematical model', 'prenatal growth disorder']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2006,289590,-0.01091487786835338
"Elective Surgery as a Teachable Moment for Smoking Cessation    DESCRIPTION (provided by applicant): The term ""teachable moment"" refers to an event that motivates individuals to spontaneously adopt risk- reducing health behaviors. Events such as the diagnosis of smoking-related illnesses (e.g. cancer) and the scheduling of surgery spontaneously (i.e., in the absence of interventions) increase the rate of quitting. However, as recently discussed in an important conceptual paper by McBride et al, little is known about factors that make certain cueing events ""teachable"". They proposed a heuristic in which an event is a ""teachable moment"" for smoking cessation to the extent that it impacts 3 key constructs. Although appealing in concept, its validity has not been evaluated. The scheduling of surgery provides a unique opportunity to test the McBride model. This study will evaluate the McBride heuristic as applied to smoking behavior following elective surgical procedures. Two specific aims will be pursued. In the first we will develop measures of the Me Bride model specific to the surgical setting, and perform an initial evaluation of their stability and internal consistency in a group of surgical patients. In the second, we will perform a pilot study to explore the hypothesis that in patients scheduled for elective surgery: 1) higher perceptions of risks or greater negative expectancies regarding health outcomes related to smoking, 2) higher levels of positive or negative affective responses, and 3) self-concept or role expectations related to smoking will correlate with measures of self-efficacy and intent, and predict postoperative abstinence from smoking. Measures of the McBride constructs will be administered to smokers scheduled for elective surgery, whose smoking behavior will be evaluated for up to 30 days postoperatively. Structural equation modeling will be utilized both to validate the measurement model established in Aim 1 and to test the fit of the structural model associated with the McBride heuristic to postoperative smoking behavior. Relevance to public health: Evaluation of the McBride heuristic is of interest not only from a theoretical standpoint, but may have practical implications regarding the design of behavioral interventions to exploit the ""teachable moment. For example, if the constructs predict behavior, interventions can attempt to specifically influence these constructs. Our overall goal is to develop effective tobacco use interventions for surgical patients; this project will be an important step in this process.           n/a",Elective Surgery as a Teachable Moment for Smoking Cessation,7226537,R03CA126371,"['artificial intelligence', 'behavior', 'clinical research', 'health', 'model', 'smoking', 'smoking cessation', 'surgery']",NCI,MAYO CLINIC,R03,2006,74000,-0.03422281104186178
"Simulation Algorithms for Spatial Pattern Recognition    DESCRIPTION (provided by applicant):    This SBIR project is developing methods and software for the specification, construction and simulation of neutral spatial models, and for applying these neutral models within the framework of probabilistic pattern recognition. Results will allow epidemiologists, environmental scientists and image analysts across a broad range of commercial disciplines to more accurately identify patterns in spatial data by removing the bias towards false positives that is caused by unrealistic null hypotheses such as ""complete spatial randomness"" (CSR). This project will accomplish 5 aims:      1. Conduct a requirements analysis to specify the neutral models and functionality to incorporate in the software.   2. Develop and test a software prototype to evaluate feasibility of the proposed models.   3. Propose a topology of neutral models and develop strategies to generate them and to conduct sensitivity analysis for investigating the impact of implicit assumptions (i.e. spatial autocorrelation or non-uniform risk) and number of realizations on test results.   4. Incorporate the neutral models in the first commercially established software package that allows for user-specified alternate hypothesis in spatial statistical tests.   5. Apply the software and methods to demonstrate the approach and its unique benefits for exposure and health risk assessment.      Feasibility of this project was demonstrated in the Phase I. This Phase II project will accomplish aims three through five. These technologic, scientific and commercial innovations will revolutionize our ability to identify, document and assess the probability of spatial patterns relative to neutral models that incorporate realistic local, spatial and multivariate dependencies. The neutral models and methods in this proposal make possible, for the first time ever, evaluation of the sensitivity of the results of cluster or boundary analyses to specification of the null hypothesis.         n/a",Simulation Algorithms for Spatial Pattern Recognition,7015648,R44CA092807,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'human data', 'image processing', 'imaging /visualization /scanning', 'statistics /biometry', 'visual cortex']",NCI,BIOMEDWARE,R44,2006,500182,-6.145770986004515e-05
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,7107923,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2006,509027,-0.02601916319833742
"Paperless Quality Donor System with Decision Making DESCRIPTION (provided by applicant):    The long-term objectives of this project are to improve the safety and availability of the US blood supply. The principal aim of this SBIR Competing Continuation Phase II Proposal for a Paperless Quality Donor System with Decision Making is to complete the development of its Quality Donor System(tm) (QDS) and to secure ongoing 510(k) clearances for it from the US Food & Drug Administration (FDA), Center for Biologies Evaluation and Research (CBER) for implementation and evaluation of the total system in blood centers and hospital blood banks.      The research is based on continuing development of the Quality Donor System and deploying it in regional blood centers and hospital blood banks. System use by donors and staff and user satisfaction will be measured and analyzed to assess success. Blood safety is enhanced by eliminating FDA-reportable errors and by increasing blood donor honesty in disclosing risky behaviors. Blood availability is enhanced by increasing donor satisfaction, resulting in higher return rates for new blood donors and increasing employer sponsorship of blood drives. n/a",Paperless Quality Donor System with Decision Making,7127266,R44HL072635,"['Internet', 'artificial intelligence', 'blood bank /supply contamination', 'blood donor', 'case history', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'decision making', 'human subject', 'interview', 'nonEnglish language', 'patient safety /medical error', 'phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2006,927498,-0.01357850228513089
"Mini Bone-Attached Robot for Joint Arthroplasty DESCRIPTION (provided by applicant):    Medical robotics has the potential to revolutionize how surgical procedures on bony anatomy are performed. It can assist surgeons by preparing bones much more accurately than mechanical guides or freehand cutting. It can help improve patient outcomes by decreasing surgical errors. In the orthopaedics community, though, medical robots have not been very successful due to a variety of issues ranging from robot size, to surgical time, and soft-tissue difficulties. We propose to overcome these difficulties by utilizing a miniature robotic milling device that attaches directly to the bone.      Realizing the potential of minimally invasive procedures, the implant industry is currently in the process of redesigning implants and, together with surgeons, reexamining surgical procedures. It can be expected that the next generation of implants will be smaller and more suitable for eventual development of less invasive procedures. One example of such procedures in knee arthroplasty is patellofemoral resurfacing of the knee. Without lose of generality we will examine the capability of the robot in improving the accuracy of the femoral-component preparation for patellofemoral arthroscopy. From engineering point of this procedure simulates the future generation of orthopaedic arthroplasty where there will be a need to machine bone surface into a more complex shape that is not planar or spherical but complex surfaces. Therefore, the technology demonstrated by this research, though, will not be specific to the patellofemoral procedure, and will be adaptable to many other areas.      We propose to develop a miniature robot that will be rigidly affixed directly to the bone. The robot itself will scan the shape of the femur directly, removing any need for preoperative imaging or intraoperative registration and tracking of the bone. With the additional input of the direction of patellar tracking, we will automatically optimize the planned position of the implant to ensure that it is properly aligned and congruent with the surrounding healthy cartilage. Congruency is a requirement for this procedure to make certain that the patellar component does not impinge on the edge of the femoral component and lead to early failure of the implant. The robot will then mill out the cavity to within 1mm of the planned location, guaranteeing complete coverage of the area with a defined surface uniformity.      By validating the results generated with the proposed robot, first on wax blocks and then plastic bone phantoms, porcine bones, and finally on cadaver knees, we will show that the robot can deliver the accuracy required to precisely place the implant. This precise placement of the femoral component should reduce the possibility of impingement, patellar maltracking, and component loosening, and improve patient outcomes. n/a",Mini Bone-Attached Robot for Joint Arthroplasty,7117290,R01AR052700,"['arthroplasty', 'artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'clinical biomedical equipment', 'computer assisted patient care', 'computer simulation', 'computer system design /evaluation', 'femur', 'hip prosthesis', 'image guided surgery /therapy', 'joint prosthesis', 'knee', 'medical implant science', 'miniature biomedical equipment', 'phantom model', 'postmortem', 'robotics']",NIAMS,WESTERN PENNSYLVANIA HOSPITAL,R01,2006,140714,-0.0009831292111589522
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,7068069,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2006,19532,-0.012189315095042216
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,7243612,R33RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R33,2006,350636,-0.00382920862357828
"Intelligent Tutor for WMD EMS Incident Management    DESCRIPTION (provided by applicant): We propose to develop EMS/IM ITS, a suite of simulation-based intelligent tutoring systems and scenarios that will enable practice-based learning of WMD emergency medical services incident management principles and skills, including situation assessment, decision-making, and real-time execution of EMS tasks within an incident command structure. To support practical and economical development of many EMS/IM ITS training scenarios, we will also develop software tools and development methods that enable efficient authoring of new scenarios and adaptation/enhancement of existing scenarios by instructors or subject matter experts, without programming. We will leverage our tutoring system development tools and our experience developing tutoring systems for medical training, command and control, and tactical decision-making. The National Incident Management System (NIMS) was mandated by HSPD-5 to provide a comprehensive, national approach to domestic incident management, so that all levels of government across the nation could work efficiently and effectively together to prepare for, respond to, and recover from domestic incidents. We believe that EMS/IM ITS can contribute to NIMS by providing scenario-based learning of incident management principles for medical first responders, consistent with NIMS, and tailorable via scenario authoring to the specific circumstances and incident management plans of each government organization. This proposed Phase I effort will lay the groundwork for the Phase II effort, by producing 1) requirements and design of the system to be developed during Phase II, 2) a software prototype that illustrates our concept, and 3) a formative evaluation of the prototype and design that provides a basis for estimating the feasibility and effectiveness of the operational system that would be developed during Phase II.             n/a",Intelligent Tutor for WMD EMS Incident Management,7115108,R43ES014801,"['artificial intelligence', 'computer assisted instruction', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'educational resource design /development', 'emergency service /first responder', 'health care personnel education', 'health care professional practice', 'health services research tag', 'medical education', 'method development', 'patient care management', 'training']",NIEHS,"STOTTLER HENKE ASSOCIATES, INC.",R43,2006,99999,-0.003869657336580306
"Generalization of the Client Matching Protocol    DESCRIPTION (provided by applicant):     This proposal tests the generalization of a standardized client-treatment matching interview and decision-tree algorithm (the Client Matching Protocol, or CMP) through an 18-month secondary analysis of the Drug Abuse Treatment Outcome Study (DATOS) database. The investigative team's previous study of Therapeutic Community (TC)-oriented agencies found that clients entering outpatient and residential treatment settings in which there was a concordance with the CMP algorithm (matched clients) showed significantly higher rates of treatment completion and long-term retention than clients entering settings that were discordant with the CMP algorithm (mismatched clients). The present study uses the DATOS variables to recreate the CMP algorithm. The study extends the previous research by 1) testing the generalization of the CMP to non-TC residential and outpatient programs, 2) determining the effect of matching on treatment process, and 3) testing the generalization of the matching effect to one- and five-year treatment outcomes. Additional research questions explore the extension of the CMP algorithm to short-term residential and methadone outpatient treatment, and to the interaction between the CMP match and organizational and client variables. Non-parametric statistics, ANOVA, logistic and multiple regression, and Structural Equation Modeling test the effects of matching and the interaction of matching and the program and client characteristics. The present study contains important research and clinical implications. This 18-month study contains significant implications for both treatment and research in that it will provide empirical clarification of whether and how matching contributes to treatment improvement. Specifically replicating a matching effect in the DATOS modalities will establish the empirical basis for a controlled study of matching and a refined version of the matching protocol for use in clinical practice.         n/a",Generalization of the Client Matching Protocol,7016275,R01DA015787,"['behavioral /social science research tag', 'clinical research', 'drug abuse therapy', 'health care model', 'health care service evaluation', 'health services research tag', 'human data', 'mathematical model', 'outcomes research', 'outpatient care', 'patient care', 'patient oriented research']",NIDA,NATIONAL DEVELOPMENT & RES INSTITUTES,R01,2006,103998,-0.025896446237652686
"Diagnostic aid software for the visual field test Visual field (VF) test is a widely used, noninvasive technique for evaluating pathology or dysfunction in the visual pathways. The VF test, in conjunction with other diagnostics, is used for detection of  laucoma and for following its progression. Early detection is critical as blindness from glaucoma is preventable in nearly all cases, provided treatment is administered early in the progression. There is a need for an automated decision aid tool that will facilitate and standardize the interpretation task. Following a successful Phase I feasibility demonstration, Phase II will apply novel machine learning approaches to the problem of glaucoma diagnosis via an automated analysis of visual field and ancillary data. IAC will develop an integrated, user friendly software program that will provide a reliable detailed classification of glaucomatous and non-glaucomatous defects with the main emphasis on glaucomatous defects and early detection. The aim is to achieve classification accuracy close to that of a highly skilled human expert. The diagnosis suggested by the software will be supported by a set of comprehensive rules extracted from the classification algorithm. Optionally, the program will provide measures of visual field and glaucoma progression. n/a",Diagnostic aid software for the visual field test,7120029,R44EY014077,"['computer human interaction', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease /disorder classification', 'early diagnosis', 'eye disorder diagnosis', 'glaucoma', 'human data', 'mathematics', 'model design /development', 'pathologic process', 'visual fields']",NEI,"BIOFORMATIX, INC.",R44,2006,325411,-0.01889174685322344
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,7072754,U01DE013331,"['biomarker', 'biopsy', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'enzyme linked immunosorbent assay', 'facial muscles', 'gas chromatography mass spectrometry', 'human subject', 'inflammation', 'interview', 'magnetic resonance imaging', 'mastication', 'musculoskeletal disorder diagnosis', 'oral facial pain', 'pain threshold', 'psychobiology', 'questionnaires', 'radioimmunoassay', 'sign /symptom', 'statistics /biometry', 'synovial fluid', 'temporomandibular joint syndrome', 'tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2006,371497,-0.004104888382968509
"Accessible Artificial Intelligence Tutoring Software DESCRIPTION (provided by applicant): Quantum has successfully developed, tested and brought to the classroom the first artificial intelligence (Al) tutoring systems in chemistry education. This work successfully addressed several longstanding, clearly articulated needs for improved interactive educational software. A leading distributor for the U.S. and Canada, Science Kit & Boreal Laboratories, as well as prominent textbook publisher, Holt, Rinehart and Winston, have entered into long-term contracts with Quantum, resulting in rapid dissemination to an established end user base. The aim of this Phase I SBIR proposal is to bring the full power and benefits of this cutting-edge new educational technology to students who are blind and visually impaired. There is a considerable need for improved educational software for science education in general, but the problem of quality educational software materials for the blind is known to be particularly acute. Certain unique attributes of the Quantum Al Tutors make them potentially very well suited for full accessibility to the blind using Internet-capable screen reader technology. The potential technological innovation here is the development of advanced Al tutoring technology that has accessibility built into its framework design. If successful, an immediate outcome will be the first Al tutoring systems that are accessible to blind students, delivered through the Internet. A formulation of an Al tutoring methodology with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. This project can only be accomplished by working intimately with experts in education for the blind, and Quantum has arranged a number of important partnerships in this respect, for research as well as commercialization of the resulting technology, including: the National Federation of the Blind, the American Printing House for the Blind, Pearson Learning Group, Bartimaeus Group and Henter Mathematics. n/a",Accessible Artificial Intelligence Tutoring Software,6880607,R43EY016251,"['Internet', 'artificial intelligence', 'blind aid', 'chemistry', 'computer assisted instruction', 'computer human interaction', 'computer program /software', 'educational resource design /development', 'science education', 'technology /technique development']",NEI,"QUANTUM SIMULATIONS, INC.",R43,2005,100721,-0.021244512011785878
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6916483,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2005,321788,-0.025340311652476504
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6910621,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2005,245768,-0.00446733780521259
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,6914441,R01EY003311,"['artificial intelligence', 'atrial natriuretic peptide', 'biological transport', 'body water dehydration', 'clinical research', 'cornea edema', 'corneal endothelium', 'corneal epithelium', 'corneal stroma', 'electrophysiology', 'human subject', 'intraocular fluid', 'laboratory rabbit', 'mathematical model', 'membrane permeability', 'model design /development', 'morphology', 'nitric oxide', 'refractive keratoplasty', 'thermodynamics', 'vision tests', 'visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2005,315720,0.00701052218893366
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,6916728,R01NS051826,"['Alzheimer&apos', 's disease', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain morphology', 'human data', 'image enhancement', 'image guided surgery /therapy', 'magnetic resonance imaging', 'mathematical model', 'prenatal growth disorder']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2005,292728,-0.01091487786835338
"BIOROBOTICS TOOLKIT FOR ENABLING RAPID EXPERIEMENTATION    DESCRIPTION (provided by applicant): We propose to create a biorobotic toolkit for rapid experimentation in the life sciences, medicine, and bioengineering. This toolkit will allow the rapid creation of biorobots derived from reference designs. These reference designs are contributed by the community of researchers. The anticipated outcome will be a vast improvement in methodology in this field. The specific aims of phase I are: (1) The design of 1 reference model (2) Demonstration of a modular plug and play sensor that will be part of a biorobot derived from the reference model (3)Demonstration of a modular plug and play Actuator that will be part of a biorobot derived from the reference model (4) Assemble a robot derived from the reference model, and using the plug and play sensors and actuators achieved in aims 2,3. (5) Quantify the closed loop performance of the sensor-actuator network. (6) Layout a preliminary specification of the architecture.         n/a",BIOROBOTICS TOOLKIT FOR ENABLING RAPID EXPERIEMENTATION,6975326,R43EB004827,"['artificial intelligence', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment', 'biomedical equipment development', 'computational biology', 'model design /development', 'neuropsychology', 'psychological models', 'robotics']",NIBIB,"IGUANA ROBOTICS, INC.",R43,2005,150419,-0.009991527894958567
"Perception and Inter-Observer Variability in Mammography DESCRIPTION (provided by applicant):    Inter-observer variability in mammogram reading has been well documented in the literature. Various factors have been used to explain this variability; among them, the most significant are related to the management of perceived findings.  However, the nature of this inter-observer variability has not been explored. Namely, were the lesions that were consistently reported by the radiologists any different from the ones that yield disagreement? Furthermore, could these differences be quantitatively assessed? Moreover, were these differences in any way related with the experience level of the observer? In addition, the interpretation of perceived findings is closely related with the visual search strategy used to scan the breast tissue, because observers compare perceived findings with the background, in order to determine their uniqueness. Hence, what is the effect of visual search strategy on inter-observer variability? Can this effect be modeled using Artificial Neural Networks (ANNs)? Can inferences be made regarding the observers' decision patterns by analyzing the results of simulations run on the ANNs?  The work described here aims at answering these questions. We will use spatial frequency analysis to characterize the areas on mammogram cases where mammographers, chest radiologists with experience reading mammograms and radiology residents at the end of their mammography rotation, indicate the presence of a finding, or fail to do so. We will assess inter-observer agreement, as well as intra- and inter-group agreement for the various groups of observers. In addition, we will train artificial neural networks to represent each observer, in such a way that by changing the nature of the features input to the ANNs we will be able to simulate how such changes would have affected the actual observer. We will assess the effects on inter-observer variability of changing the search strategy used by the observer to sample the breast tissue. In our setting, the inter-observer variability will be assessed by comparing the outputs of the ANNs that represent each observer. In addition, the changes in sampling strategy will correspond to actual possible strategies for the human observers themselves. n/a",Perception and Inter-Observer Variability in Mammography,6924688,R21CA100107,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasm /cancer diagnosis', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'human data', 'human therapy evaluation', 'mammography', 'visual perception']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2005,167063,-0.06912677044146923
"Neural network model of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using radial basis function neural network (RBFNN) that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The RBFNN model will be fed training data from our existing database (chinchilla) consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals. Once trained, the model will be able to predict the auditory consequences of exposure to any noise environment characterized by ten noise metrics and five biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/histological data are available (Year 2). The training period will be an iterative process in which the RBFNN will be modified as training proceeds. The prediction model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a RBFNN to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Neural network model of noise-induced hearing loss,6941215,R03OH008175,"['artificial intelligence', 'chinchilla', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'disease /disorder model', 'environmental exposure', 'model design /development', 'noise biological effect', 'noise induced deafness']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R03,2005,71735,-0.0057709167681880775
"Linking Information, Families and Technology (LIFT) DESCRIPTION (provided by applicant): KIT Solutions, a private firm specializing in developing intelligent, Knowledge-based Information Technology (KIT) solutions for the field of health and human services will partner with the University of Pittsburgh, Office of Child Development (OCD) to develop a Web-based, interactive software application of a Family Support Management Information System (FS MIS) for nationwide dissemination. This innovation is called Linking Information, Families and Technology (LIFT).  Family support centers, like other human service programs and agencies across the country, are being required to implement best practices and document the impact of their services to funders, policy makers, and the community. However, most family centers do not have a state-of-the-art web-based information system available to them that integrates best practice, expert knowledge, and daily management functions. The proposed LIFT system will address these critical needs and has great potential for nationwide commercial distribution. The combination of KIT'S proven record of developing knowledge based information technology and OCD's over 20 years of research and practice in family support services will greatly enhances the chance of success for this business venture. In Phase I of the project, we will produce prototype software demonstrating the benefit, usability, and feasibility of a web-based, interactive, intelligent system for use by family support centers across the nation. The extent of which LIFT enables family center staff to build skill, capacity, access information and expert knowledge, to enhance their work will be the focus of this phase. In Phase II, we will fully develop the prototype LIFT to a commercial grade web application for nationwide dissemination and further validate the commercial potential and impact of LIFT, using a quasiexperimental design, which will involve a large number of users across multiple sites. In Phase III, we will seek private funding for marketing the system to the national market. We intend to use the Microsoft.Net Platform and follow XML web service concepts to develop the proposed innovation. Collection of a subscription fee will be used to support the maintenance and future development of the system. n/a","Linking Information, Families and Technology (LIFT)",6990440,R43HD049229,"['Internet', 'artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'family', 'focus groups', 'human subject', 'information dissemination', 'social service']",NICHD,"KIT SOLUTIONS, INC.",R43,2005,104545,-0.013405573716472826
"Simulation Algorithms for Spatial Pattern Recognition    DESCRIPTION (provided by applicant):    This SBIR project is developing methods and software for the specification, construction and simulation of neutral spatial models, and for applying these neutral models within the framework of probabilistic pattern recognition. Results will allow epidemiologists, environmental scientists and image analysts across a broad range of commercial disciplines to more accurately identify patterns in spatial data by removing the bias towards false positives that is caused by unrealistic null hypotheses such as ""complete spatial randomness"" (CSR). This project will accomplish 5 aims:      1. Conduct a requirements analysis to specify the neutral models and functionality to incorporate in the software.   2. Develop and test a software prototype to evaluate feasibility of the proposed models.   3. Propose a topology of neutral models and develop strategies to generate them and to conduct sensitivity analysis for investigating the impact of implicit assumptions (i.e. spatial autocorrelation or non-uniform risk) and number of realizations on test results.   4. Incorporate the neutral models in the first commercially established software package that allows for user-specified alternate hypothesis in spatial statistical tests.   5. Apply the software and methods to demonstrate the approach and its unique benefits for exposure and health risk assessment.      Feasibility of this project was demonstrated in the Phase I. This Phase II project will accomplish aims three through five. These technologic, scientific and commercial innovations will revolutionize our ability to identify, document and assess the probability of spatial patterns relative to neutral models that incorporate realistic local, spatial and multivariate dependencies. The neutral models and methods in this proposal make possible, for the first time ever, evaluation of the sensitivity of the results of cluster or boundary analyses to specification of the null hypothesis.         n/a",Simulation Algorithms for Spatial Pattern Recognition,6863029,R44CA092807,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'human data', 'image processing', 'imaging /visualization /scanning', 'statistics /biometry', 'visual cortex']",NCI,BIOMEDWARE,R44,2005,498368,-6.145770986004515e-05
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6944266,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2005,523667,-0.02601916319833742
"Multi-microphone long probe for OAE acquisition DESCRIPTION (provided by applicant): The development of an innovative multi-microphone probe and acquisition system for recording otoacoustic emissions {OAEs} with advanced noise cancellation algorithms, increased frequency and intensity ranges and pressurization capabilities is proposed. Two advanced noise cancellation algorithm will be implemented: 1) a multi-reference adaptive noise cancellation (ANC) network and 2) two-dimensional filtering. These algorithms will utilize the independent measurements provided by the multiple microphones in order to reduce noise contaminants. Each microphone or microphone groupings will be connected to individual analog-to-digital (A/D) converters in order to allow for the implementation of the digital signal processing algorithms. The pressurization capabilities of the probe will allow implementation of tympanometry and the acquisition of OAEs while compensating for pressure imbalances between the outer and middle ear. Results from a prototype single microphone long probe are presented demonstrating that the design concept is valid and provides good quality OAE recordings while reducing the undesirable effects of the metal response. The proposed probe will also improve upon the limited dynamic and frequency range of current OAE probes. The probe is expected to be able to provide stimulus levels of up to 90 dB HL and a frequency response of up to 24 kHz. During Phase I, various probes will be constructed and tested under different noise conditions in adult and infant subjects. During Phase II, the pressurization capabilities of the new probe will be further developed and examined. The optimal probe designed will be implemented along with the optimal noise cancellation algorithm and tested in a comprehensive clinical study incorporating the pressurization capabilities of the probe. n/a",Multi-microphone long probe for OAE acquisition,6933674,R43DC007543,"['adult human (21+)', 'artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical biomedical equipment', 'clinical research', 'computer program /software', 'ear disorder diagnosis', 'infant human (0-1 year)', 'mathematics', 'noise', 'otoacoustic emission', 'sound frequency']",NIDCD,INTELLIGENT HEARING SYSTEMS,R43,2005,100000,-0.0027406472556849096
"Paperless Quality Donor System with Decision Making DESCRIPTION (provided by applicant):    The long-term objectives of this project are to improve the safety and availability of the US blood supply. The principal aim of this SBIR Competing Continuation Phase II Proposal for a Paperless Quality Donor System with Decision Making is to complete the development of its Quality Donor System(tm) (QDS) and to secure ongoing 510(k) clearances for it from the US Food & Drug Administration (FDA), Center for Biologies Evaluation and Research (CBER) for implementation and evaluation of the total system in blood centers and hospital blood banks.      The research is based on continuing development of the Quality Donor System and deploying it in regional blood centers and hospital blood banks. System use by donors and staff and user satisfaction will be measured and analyzed to assess success. Blood safety is enhanced by eliminating FDA-reportable errors and by increasing blood donor honesty in disclosing risky behaviors. Blood availability is enhanced by increasing donor satisfaction, resulting in higher return rates for new blood donors and increasing employer sponsorship of blood drives. n/a",Paperless Quality Donor System with Decision Making,6990079,R44HL072635,"['Internet', 'artificial intelligence', 'blood bank /supply contamination', 'blood donor', 'case history', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'decision making', 'human subject', 'interview', 'nonEnglish language', 'patient safety /medical error', 'phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2005,910764,-0.01357850228513089
"Mini Bone-Attached Robot for Joint Arthroplasty DESCRIPTION (provided by applicant):    Medical robotics has the potential to revolutionize how surgical procedures on bony anatomy are performed. It can assist surgeons by preparing bones much more accurately than mechanical guides or freehand cutting. It can help improve patient outcomes by decreasing surgical errors. In the orthopaedics community, though, medical robots have not been very successful due to a variety of issues ranging from robot size, to surgical time, and soft-tissue difficulties. We propose to overcome these difficulties by utilizing a miniature robotic milling device that attaches directly to the bone.      Realizing the potential of minimally invasive procedures, the implant industry is currently in the process of redesigning implants and, together with surgeons, reexamining surgical procedures. It can be expected that the next generation of implants will be smaller and more suitable for eventual development of less invasive procedures. One example of such procedures in knee arthroplasty is patellofemoral resurfacing of the knee. Without lose of generality we will examine the capability of the robot in improving the accuracy of the femoral-component preparation for patellofemoral arthroscopy. From engineering point of this procedure simulates the future generation of orthopaedic arthroplasty where there will be a need to machine bone surface into a more complex shape that is not planar or spherical but complex surfaces. Therefore, the technology demonstrated by this research, though, will not be specific to the patellofemoral procedure, and will be adaptable to many other areas.      We propose to develop a miniature robot that will be rigidly affixed directly to the bone. The robot itself will scan the shape of the femur directly, removing any need for preoperative imaging or intraoperative registration and tracking of the bone. With the additional input of the direction of patellar tracking, we will automatically optimize the planned position of the implant to ensure that it is properly aligned and congruent with the surrounding healthy cartilage. Congruency is a requirement for this procedure to make certain that the patellar component does not impinge on the edge of the femoral component and lead to early failure of the implant. The robot will then mill out the cavity to within 1mm of the planned location, guaranteeing complete coverage of the area with a defined surface uniformity.      By validating the results generated with the proposed robot, first on wax blocks and then plastic bone phantoms, porcine bones, and finally on cadaver knees, we will show that the robot can deliver the accuracy required to precisely place the implant. This precise placement of the femoral component should reduce the possibility of impingement, patellar maltracking, and component loosening, and improve patient outcomes. n/a",Mini Bone-Attached Robot for Joint Arthroplasty,6957258,R01AR052700,"['arthroplasty', 'artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'clinical biomedical equipment', 'computer assisted patient care', 'computer simulation', 'computer system design /evaluation', 'femur', 'hip prosthesis', 'image guided surgery /therapy', 'joint prosthesis', 'knee', 'medical implant science', 'miniature biomedical equipment', 'phantom model', 'postmortem', 'robotics']",NIAMS,WESTERN PENNSYLVANIA HOSPITAL,R01,2005,172920,-0.0009831292111589522
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,6937143,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2005,20000,-0.012189315095042216
"A Run-to-Run Algorithm for Glucose Regulation DESCRIPTION (provided by applicant):    The long term objective of this work is to develop new algorithmic approaches to optimize the delivery of insulin in an automated fashion to people with type 1 diabetes. Specifically, we aim to develop a strategy, inspired by run-to-run control theory established by the chemical process industries, that ""learns"" from the previous sequence of glucose responses to insulin dosing (over the course of days), and optimally predicts the appropriate strategy for the forthcoming day. The notion of a ""cycle"" in engineering will be extended to manage the 24 hour routine of repeated meals, activities, and sleep cycles and the corresponding dosing of insulin. The algorithm will be tested in both simulation and clinical trials for robustness to sensor noise, uncertainty in the patient characterization, variability in the timing of the postprandial glucose peak, and variability in the carbohydrate content in the meals. The Specific Aims of this project are to: i) construct predictive patient sensitivity models for calculation of optimal insulin dosing from elevated (or depressed) glucose levels, ii) develop run-to-run algorithm for insulin bolus dosing to provide corrections in subsequent days based on previous history of glucose levels and insulin dosage, and iii) evaluate the robustness of the algorithm through meal challenges of varying carbohydrate content. The aims will blend prototype algorithms that are drawn from systems engineering with validation in a series of clinical tests. The proposed collaboration between systems engineers and renowned diabetes researchers in an established clinical research setting will allow a novel fusion of methods that can be truly characterized as ""innovative"". The medical collaborators in the proposal are located at the prestigious Sansum Medical Research Institute, which is located less than 10 miles from the campus of the University of California, Santa Barbara. The exchange of personnel will be facilitated, allowing the student and post-doc supported on this project to work at both the institute and the university over the span of the project n/a",A Run-to-Run Algorithm for Glucose Regulation,6953163,R01DK068663,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical automation', 'blood glucose', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer simulation', 'dietary carbohydrates', 'drug administration rate /duration', 'drug delivery systems', 'glucose metabolism', 'human subject', 'insulin dependent diabetes mellitus', 'insulin sensitivity /resistance', 'mathematical model', 'model design /development', 'patient oriented research']",NIDDK,SANSUM DIABETES RESEARCH INSTITUTE,R01,2005,202350,-0.03276394305472152
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,6914863,R21RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R21,2005,167918,-0.00382920862357828
"Model for prediction of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using a statistical learning machine (SLM), which includes an artificial neural network (ANN), a support vector machine (SVM), and a hybrid of ANN and SVM, that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The SLM model will be fed training data from our existing database consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals.  Once trained, the SLM model will be able to predict the auditory consequences of exposure to any noise environment characterized by the noise metrics and biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/ histological data are available (Year 2). The training period will be an iterative process in which the SLM will be modified as training proceeds. The predictions of the SLM model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a statistical learning machine to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Model for prediction of noise-induced hearing loss,6878561,R01OH007801,"['chinchilla', 'computational neuroscience', 'computer program /software', 'computer system design /evaluation', 'mathematical model', 'model design /development', 'noise induced deafness', 'noise pollution']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R01,2005,139799,-0.0036361350419111954
"Generalization of the Client Matching Protocol    DESCRIPTION (provided by applicant):     This proposal tests the generalization of a standardized client-treatment matching interview and decision-tree algorithm (the Client Matching Protocol, or CMP) through an 18-month secondary analysis of the Drug Abuse Treatment Outcome Study (DATOS) database. The investigative team's previous study of Therapeutic Community (TC)-oriented agencies found that clients entering outpatient and residential treatment settings in which there was a concordance with the CMP algorithm (matched clients) showed significantly higher rates of treatment completion and long-term retention than clients entering settings that were discordant with the CMP algorithm (mismatched clients). The present study uses the DATOS variables to recreate the CMP algorithm. The study extends the previous research by 1) testing the generalization of the CMP to non-TC residential and outpatient programs, 2) determining the effect of matching on treatment process, and 3) testing the generalization of the matching effect to one- and five-year treatment outcomes. Additional research questions explore the extension of the CMP algorithm to short-term residential and methadone outpatient treatment, and to the interaction between the CMP match and organizational and client variables. Non-parametric statistics, ANOVA, logistic and multiple regression, and Structural Equation Modeling test the effects of matching and the interaction of matching and the program and client characteristics. The present study contains important research and clinical implications. This 18-month study contains significant implications for both treatment and research in that it will provide empirical clarification of whether and how matching contributes to treatment improvement. Specifically replicating a matching effect in the DATOS modalities will establish the empirical basis for a controlled study of matching and a refined version of the matching protocol for use in clinical practice.         n/a",Generalization of the Client Matching Protocol,6865332,R01DA015787,"['behavioral /social science research tag', 'clinical research', 'drug abuse therapy', 'health care model', 'health care service evaluation', 'health services research tag', 'human data', 'mathematical model', 'outcomes research', 'outpatient care', 'patient care', 'patient oriented research']",NIDA,NATIONAL DEVELOPMENT & RES INSTITUTES,R01,2005,248500,-0.025896446237652686
"Proteomics processing using networked instrument router* DESCRIPTION (provided by applicant):  Real-time, distributed decision-making and data-processing has become necessary as high-throughput proteomics across geographic boundaries becomes more mature. The most common instrument used to characterize and analyze proteins is the Mass Spectrometer. As more Mass Spectrometers are used in parallel to create a high-throughput proteomics system, the data processing needs grow exponentially. Using a cluster of low-cost instrument routers, developed at Userspace Corporation, the goal for this project is to divide the data processing tasks into a decision tree, which converts sequential tasking into parallel tasking or multi-threaded algorithms. These instruments can be controlled and the algorithms can independently process data in parallel or offline as they emerge in large data sets from one or many Mass Spectrometers. The First Phase of study will use an LC-MS (Liquid Chromatography - Mass Spectroscopy) system that uses the ICAT (Isotope Coded Affinity Tags) technology developed at the lab of Dr. Ruedi Aebersold at the University of Washington (who is also the co-founder of the Institute for Systems Biology: ISB). The data from the Mass Spectrometers is analyzed using the COMET algorithm, also developed at the ISB. Userspace Corporation and ISB are collaborating on using Userspace's routers and framework in its Proteomics lab.      The first phase of this project will evaluate technologies and configuration required to process Mass Spectrometry data at the instrument level using a distributed network of the Userspace wireless instrument routers. The data will be processed in real-time as it becomes available to the router cluster and a rule-based decision matrix. The duration of this phase will be six months. The next phases would involve improving the data formatting, so that publication and data mining become science-centric and in a standardized XML (eXtensible Markup Language) representation. Other instruments, algorithms and processes will be added to the router library. n/a",Proteomics processing using networked instrument router*,6955044,R43AA014558,"['automated data processing', 'biotechnology', 'computer network', 'computer system design /evaluation', 'high throughput technology', 'mass spectrometry', 'parallel processing', 'proteomics']",NIAAA,USERSPACE CORPORATION,R43,2005,226700,-0.015430653750110879
"Diagnostic aid software for the visual field test Visual field (VF) test is a widely used, noninvasive technique for evaluating pathology or dysfunction in the visual pathways. The VF test, in conjunction with other diagnostics, is used for detection of  laucoma and for following its progression. Early detection is critical as blindness from glaucoma is preventable in nearly all cases, provided treatment is administered early in the progression. There is a need for an automated decision aid tool that will facilitate and standardize the interpretation task. Following a successful Phase I feasibility demonstration, Phase II will apply novel machine learning approaches to the problem of glaucoma diagnosis via an automated analysis of visual field and ancillary data. IAC will develop an integrated, user friendly software program that will provide a reliable detailed classification of glaucomatous and non-glaucomatous defects with the main emphasis on glaucomatous defects and early detection. The aim is to achieve classification accuracy close to that of a highly skilled human expert. The diagnosis suggested by the software will be supported by a set of comprehensive rules extracted from the classification algorithm. Optionally, the program will provide measures of visual field and glaucoma progression. n/a",Diagnostic aid software for the visual field test,6882489,R44EY014077,"['computer human interaction', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease /disorder classification', 'early diagnosis', 'eye disorder diagnosis', 'glaucoma', 'human data', 'mathematics', 'model design /development', 'pathologic process', 'visual fields']",NEI,"BIOFORMATIX, INC.",R44,2005,324664,-0.01889174685322344
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6901098,U01DE013331,"['biomarker', 'biopsy', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'enzyme linked immunosorbent assay', 'facial muscles', 'gas chromatography mass spectrometry', 'human subject', 'inflammation', 'interview', 'magnetic resonance imaging', 'mastication', 'musculoskeletal disorder diagnosis', 'oral facial pain', 'pain threshold', 'psychobiology', 'questionnaires', 'radioimmunoassay', 'sign /symptom', 'statistics /biometry', 'synovial fluid', 'temporomandibular joint syndrome', 'tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2005,1520994,-0.004104888382968509
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6910762,P30EY006883,"['biomedical facility', 'health science research', 'vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2005,611743,-0.00960418978305694
"Development of Ultrasonic Appratus for Dental Diagnosis DESCRIPTION: An ultrasonic diagnostic apparatus has been proposed for Dental applications in determining tooth pathologies such as demineralization/caries, hidden fractures, and formation of abscesses. The equipment adopts a piezoelectric and laser optic hybrid transduction system for interrogation of teeth. Ultrasonic responses of the tooth structure will be analyzed by a pattern recognition expert system (artificial intelligence) to determine the diagnosis of the tooth inspected. The proposed research will eventually help to reduce the use of harmful X-ray radiation in Dental clinics and contribute to artificial intelligence based diagnosis. The proposed concept has been successfully demonstrated in the previous Phase I study. In this Phase II study, instrumentation for clinical data collection using a combination of conventional piezoelectric and new laser-based ultrasonic technologies will be developed and optimized; an artificial intelligence based diagnostic function will be developed using clinical data and implemented using embedded computing; numerical simulations will be used to enhance diagnostic function development; and finally, initial clinical trials will be conducted to demonstrate the performance of the prototype equipment. The ultrasonic apparatus for Dental diagnosis outlined in this application is a first application of AI-based NDE in Dentistry. The research concept may also extend to periodontal and craniofacial applications. n/a",Development of Ultrasonic Appratus for Dental Diagnosis,6777482,R44DE014270,"['artificial intelligence', 'biomedical equipment development', 'clinical research', 'clinical trials', 'dental disorder diagnosis', 'dental structure', 'dentistry', 'diagnosis design /evaluation', 'human subject', 'patient oriented research', 'tooth', 'tooth surface']",NIDCR,AAC INTERNATIONAL,R44,2004,367866,9.141095704614148e-05
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6799187,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2004,321983,-0.025340311652476504
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6774688,R01EY014162,"['artificial intelligence', 'bioimaging /biomedical imaging', 'computer assisted diagnosis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'eye refractometry', 'human data', 'image processing', 'ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2004,242058,-0.00446733780521259
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,6774685,R01EY003311,"['artificial intelligence', 'atrial natriuretic peptide', 'biological transport', 'body water dehydration', 'clinical research', 'cornea edema', 'corneal endothelium', 'corneal epithelium', 'corneal stroma', 'electrophysiology', 'human subject', 'intraocular fluid', 'laboratory rabbit', 'mathematical model', 'membrane permeability', 'model design /development', 'morphology', 'nitric oxide', 'refractive keratoplasty', 'thermodynamics', 'vision tests', 'visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2004,315720,0.00701052218893366
"LiFESim: Software for health science education (NCRR)    DESCRIPTION (provided by applicant): Stottler Henke Associates in collaboration with Teachers College, Columbia University, proposes to build a software system for teaching scientific inquiry in the context of nutrition science, The goal of the proposed research is to develop a computer based instructional system - called LiFESim - that teaches accurate and detailed information about food and the food system -- from production of food on the farm through food processing and transportation, to impacts of food on personal health and on the natural environment in terms of waste and pollution. The software will complement an existing health science curriculum, developed at Teachers College for 4th-6th graders, called ""Linking Food and the Environment"" or LIFE, developed from an NIH Science Education Partnership Award (SEPA) RR 12374 (1997-2004). Our system will be based on the paradigm of role-playing simulation used in such popular computer games as SimCity and The Sims: students using the software assume roles in a simulated environment and learn from the consequences of the decisions that they make in those roles. Using the simulation paradigm students will be able to explore the dynamics of large-scale systems, such as those the food transportation system in ways that are not possible with the existing curriculum. For example, the simulation would allow students to explore the impact of changes in transportation patterns on food delivery. Our system will provide explicit coaching in applying scientific methods for investigation. We will also explore learning strategies that will encourage students to critically examine - and hopefully improve - their dietary choices. We will complement simulation-based learning with two other artificial intelligence based methodologies - the use of lifelike pedagogical agents, and the use of case-based reasoning. During Phase I, we will develop a set of detailed instructional goals, use these to develop an initial system design, develop a limited prototype of the system, and then develop and perform an informal pilot study to evaluate the viability of our design. The pilot study will be conducted over a one-month period at schools in Hayward, California and New York City. Our Phase II effort will focus on developing an extensive design and performing detailed use testing of the system developed during Phase I.         n/a",LiFESim: Software for health science education (NCRR),6790401,R43RR019780,"['artificial intelligence', 'bioengineering /biomedical engineering', 'clinical research', 'computer assisted instruction', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'education evaluation /planning', 'educational resource design /development', 'environmental contamination', 'food', 'food processing /preparation', 'health education', 'human subject', 'interactive multimedia', 'nutrition', 'nutrition related tag', 'science education']",NCRR,"STOTTLER HENKE ASSOCIATES, INC.",R43,2004,100000,-0.02678908476863163
"Use of Microarray Test Data for Toxicogenomic Prediction    DESCRIPTION (provided by applicant):    This project bridges the understanding between physical and chemical principles and genomic/proteomic response by integrating three independent parallel toxicity prediction tools. Each uses computational neural networks (CNNs) and wavelets to rapidly and accurately make pharmaceutical/chemical toxicity predictions. A CNN-based Quantitative Structure-Activity Relationship (QSAR) module makes toxicological predictions based only on structure-activity analyses; a second CNN/wavelet module makes independent toxicogenomic predictions using microarray data; and a third CNN/wavelet module makes toxicogenomic predictions using Massively Parallel Signature Sequencing (MPSS) data. This multi-intelligent, three-module approach provides crosschecks to reduce false positives and false negatives while substantially increasing confidence in predictions relative to current computer-based toxicity prediction techniques. The resulting product could potentially become a primary tool used by (a) human health researchers, b) pharmaceutical companies for screening drugs early during development, c) companies designing/developing new chemicals and chemically treated materials, and (d) government organizations (e.g., military) for mission-related chemical deployments. Public benefits include reduced health and environmental risks (e.g., 4 out of 5 chemicals in use today have inadequate testing); reduced reliance on animal testing; and reduced time and cost required to bring new pharmaceuticals and chemicals into beneficial medical and commercial use.            n/a",Use of Microarray Test Data for Toxicogenomic Prediction,6743871,R41ES013321,"['computational neuroscience', 'computer data analysis', 'evaluation /testing', 'method development', 'microarray technology', 'polymerase chain reaction', 'toxicant screening', 'toxicology']",NIEHS,"YAHSGS, LLC",R41,2004,211770,-0.03094624676624335
"Markov Chain Monte Carlo and Exact Logistic Regression    DESCRIPTION (provided by applicant): Today, software for fitting logistic regression models to binary data belongs in the toolkit of every professional biostatistician, epidemiologist, and social scientist. A natural follow-up to this development is the adoption of exact logistic regression by mainstream biostatisticians and data analysts for any setting in which the accuracy of a statistical analysis based on large-sample maximum likelihood theory is in doubt. Cutting-edge researchers in biometry and numerous other fields have already recognized that it is necessary to supplement inference based on large-sample methods with exact inference for small, sparse and unbalanced data. The LogXact software package developed by Cytel Software Corporation fills this need. It has been used since its inception in 1993 to produce exact inferences for data generated from a wide range fields including clinical trials, epidemiology, disease surveillance, insurance, criminology, finance, accounting, sociology and ecology. In all these applications exact logistic regression was adopted because the limitations of the corresponding asymptotic procedures were clearly recognized in advance by the investigators and the exact inference was computationally feasible. But most of the time it will not be obvious whether asymptotic or exact methods are applicable. Ideally one would prefer to run both types of analyses if there is any doubt about the appropriateness of the asymptotic inference. However, because of the computational limits of the exact algorithms, investigators are currently inhibited from attempting the exact analysis. There is uncertainty about the how long the computations will take and even whether they will produce any results at all before the computer runs out of memory. The current project eliminates this uncertainty by introducing a new generation of numerical algorithms that utilize network based Monte Carlo rejection sampling. The Phase 1 progress report has demonstrated that these new algorithms can speed up the computations by factors of 50 to 1000 relative to what is currently available in LogXact. More importantly they can predict how long a job will take so that the user may decide whether to proceed at once or at a better time. The Phase 2 effort aims to incorporate this new generation of computing algorithms into future versions of LogXact.         n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6703756,R44CA093112,"['artificial intelligence', 'clinical research', 'computer data analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'mathematics', 'statistics /biometry']",NCI,"CYTEL, INC",R44,2004,411387,-0.0016169346867595167
"Perception and Inter-Observer Variability in Mammography DESCRIPTION (provided by applicant):    Inter-observer variability in mammogram reading has been well documented in the literature. Various factors have been used to explain this variability; among them, the most significant are related to the management of perceived findings.  However, the nature of this inter-observer variability has not been explored. Namely, were the lesions that were consistently reported by the radiologists any different from the ones that yield disagreement? Furthermore, could these differences be quantitatively assessed? Moreover, were these differences in any way related with the experience level of the observer? In addition, the interpretation of perceived findings is closely related with the visual search strategy used to scan the breast tissue, because observers compare perceived findings with the background, in order to determine their uniqueness. Hence, what is the effect of visual search strategy on inter-observer variability? Can this effect be modeled using Artificial Neural Networks (ANNs)? Can inferences be made regarding the observers' decision patterns by analyzing the results of simulations run on the ANNs?  The work described here aims at answering these questions. We will use spatial frequency analysis to characterize the areas on mammogram cases where mammographers, chest radiologists with experience reading mammograms and radiology residents at the end of their mammography rotation, indicate the presence of a finding, or fail to do so. We will assess inter-observer agreement, as well as intra- and inter-group agreement for the various groups of observers. In addition, we will train artificial neural networks to represent each observer, in such a way that by changing the nature of the features input to the ANNs we will be able to simulate how such changes would have affected the actual observer. We will assess the effects on inter-observer variability of changing the search strategy used by the observer to sample the breast tissue. In our setting, the inter-observer variability will be assessed by comparing the outputs of the ANNs that represent each observer. In addition, the changes in sampling strategy will correspond to actual possible strategies for the human observers themselves. n/a",Perception and Inter-Observer Variability in Mammography,6821032,R21CA100107,"['artificial intelligence', 'bioimaging /biomedical imaging', 'breast neoplasm /cancer diagnosis', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'human data', 'human therapy evaluation', 'mammography', 'visual perception']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2004,153968,-0.06912677044146923
"Multiparametric Computational Echocardiography DESCRIPTION (provided by applicant):    In the United States, myocardial ischemia is the underlying etiology in nearly 70% of the 5 million patients suffering from mechanical failure of the cardiac left ventricle (LV). Echocardiography (echo) is well suited for the analysis of LV function, however, the problem of conveying this clinically important information in a quantitative, objective, and reproducible manner persists.      To address this problem and respond to the NIH PA-00-117 solicitation for innovations in biomedical information science and technology, the long-term goal of the proposed R21/R33 project is to develop methods for 1) quantitative and objective measurement of LV function, 2) reproducible diagnostic interpretation based on these measurements, and 3) standardized topologic mapping and parametric display of the results. We defined 3 parameters of LV function: 1) rate of local deformation (strain rate), 2) amplitude of deformation (strain), and 3) time interval to the transition (crossover) point of cyclic deformation.      The practical implementation of the long-term objectives will be achieved through the development of a Multiparametric Computational Echo (MPCE) system. The main hypothesis of this R21/R33 project is that the MPCE system will a) precisely and accurately quantitate (R21 phase) and b) reproducibly clinically interpret (R33 phase) segmental LV function. This hypothesis will be tested on digital echo data from animal models and clinical cases of myocardial ischemia representing a wide range of segmental LV dysfunction.      Specific Aims (R21 phase):   Aim 1 - Develop algorithms for parametric analysis of local ventricular function (Year 1).   Aim 2 - Test precision and accuracy of local LV functional analysis using MPCE (Year 2).   Satisfaction of the predefined milestones will initiate the commencement of the R33 phase.      Specific Aims (R33 phase):   Aim 1 - Develop a neural network MPCE system and test it initially in animals (Year 3).   Aim 2 - Refine parametric mapping and test reproducibility of MPCE data in humans (Year 4).   Successful completion of this project will result in noninvasive, quantitative, objective, and reproducible interpretation of LV function, thus facilitating optimal diagnostic and therapeutic decisions in cardiology. n/a",Multiparametric Computational Echocardiography,6783325,R21HL070363,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'echocardiography', 'evaluation /testing', 'heart function', 'human subject', 'method development', 'swine']",NHLBI,MAYO CLINIC,R21,2004,144693,-0.0124425398433448
"Neural network model of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using radial basis function neural network (RBFNN) that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The RBFNN model will be fed training data from our existing database (chinchilla) consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals. Once trained, the model will be able to predict the auditory consequences of exposure to any noise environment characterized by ten noise metrics and five biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/histological data are available (Year 2). The training period will be an iterative process in which the RBFNN will be modified as training proceeds. The prediction model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a RBFNN to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Neural network model of noise-induced hearing loss,6820323,R03OH008175,"['artificial intelligence', 'chinchilla', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'disease /disorder model', 'environmental exposure', 'model design /development', 'noise biological effect', 'noise induced deafness']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R03,2004,71000,-0.0057709167681880775
"3D Telestration for Robotically Assisted Surgery DESCRIPTION (provided by applicant):    The speed with which an innovative and improved surgical procedure can be widely adopted is governed principally by the availability of competent surgeon mentors. With its difficult learning curve, minimally invasive surgery has an especially strong need for mentors. Several investigators have developed ""telestration,"" the ability for a remote surgeon mentor to draw on the operating surgeon's video display, to make surgical mentoring available over long distances to increase the availability of mentors. Robotically assisted minimally invasive surgery such as that practiced with the da Vinci surgical robot has the same basic need for mentors, with two special circumstances that amplify the need for mentors: robotically assisted minimally invasive surgery is in its earlier stages, with few qualified mentors, and due to the surgeon's immersion at a control console with a high-fidelity 3D display, a mentor is in a sense ""remote"" even if he or she is in the same room. Both of these special circumstances make telestration even more attractive for robotically assisted minimally invasive surgery than it is for conventional minimally invasive surgery.      The proposed project would meet this challenge by leveraging another aspect of the surgical robot system - the presence of computational power- to apply image correlation algorithms to render 3D telestration drawings from drawings produced in 2D by the mentor. The same image correlation algorithms used to generate the 3D telestration also offer a second major benefit - the ability to virtually ""paint"" the telestration drawings on the anatomy in the surgeon's 3D view, so that the markings made by the mentor move with the anatomy, appearing to have been made with a paint pen directly on the tissue. In addition to the two immediate benefits of generating 3D telestration and creating drawings that track anatomy, application of these algorithms has broad potential impact in the area of image-guided surgery. n/a",3D Telestration for Robotically Assisted Surgery,6831980,R41EB004177,"['artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'image guided surgery /therapy', 'robotics', 'swine', 'technology /technique development', 'three dimensional imaging /topography']",NIBIB,"INTUITIVE SURGICAL, INC.",R41,2004,105941,-0.008782404929664001
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6784554,R01GM056529,"['artificial intelligence', 'biochemistry', 'computer program /software', 'computer system design /evaluation', 'dementia', 'enzyme mechanism', 'functional /structural genomics', 'information system analysis', 'mathematical model', 'molecular biology information system', 'molecular dynamics', 'physiology', 'protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2004,522252,-0.02601916319833742
"Wireless EEG/PSG System with Novel Artifact Removal DESCRIPTION (provided by applicant): EEG is a valuable non-invasive clinical tool in numerous applications, from the diagnosis and treatment of brain diseases to the clinical monitoring of neurological injuries, sleep disorders and depth of anesthesia.  However, EEG signals are very susceptible to various artifacts which seriously impede the EEG interpretation and compromise its therapeutic capabilities. Methods currently employed for removing artifacts from EEG recordings are not clinically effective or feasible for real-time and long-term neuro-monitoring. Hence, the overall goal of this project is to develop a novel, high-fidelity artifact identification and removal technique that will be specifically useful for ambulatory EEG recording and intervention.      The proposed novel artifact removal technique is based on the Wavelet-Based Artifact Removal (WBAR) method, which exploits the excellent time-frequency localization of artifacts provided by the wavelet decomposition. The WBAR method is computationally very efficient and allows for simultaneous, real-time removal of a variety of EEG artifacts. It has been recently developed by the PI and tested for a single EEG channel in an extensive clinical study as part of a novel depth-of-anesthesia monitor.       The WBAR method will be improved by combining it with the Wavelet Neural Networks for the precise artifact classification, and recursive EEG Parameterization methods for the reliable estimation of the corrupted EEG components. The combination of these methods will result in fully automated, real-timeartifact removal technique that maximally preserves valid EEG information.       The development and implementation of this novel method will greatly enhance the functionality and  utilization of Cleveland Medical Devices' entire line of ambulatory wireless EEG/PSG systems. n/a",Wireless EEG/PSG System with Novel Artifact Removal,6792393,R43NS046978,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'brain electrical activity', 'clinical biomedical equipment', 'clinical research', 'computer program /software', 'electroencephalography', 'human subject', 'patient monitoring device', 'patient oriented research', 'polysomnography', 'portable biomedical equipment', 'sleep']",NINDS,"CLEVELAND MEDICAL DEVICES, INC.",R43,2004,204478,-0.035447608306501906
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6721300,R37GM030998,"['DNA', 'artificial intelligence', 'biochemical evolution', 'computational neuroscience', 'computer assisted sequence analysis', 'computer simulation', 'gene frequency', 'genetic models', 'mathematical model', 'method development', 'model design /development', 'natural selections', 'nucleic acid sequence', 'species difference', 'statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2004,161792,-0.03200257674086958
"Paperless Quality Donor System with Decision Making    DESCRIPTION (provided by applicant):    The principal aim of this proposal is for Talisman to develop, implement and evaluate a computerized, integrated system for processing blood donors that incorporates a series of decision aids and decision algorithms.  The system is expected to significantly reduce donor and staff errors and omissions, increase blood availability, improve staff efficiency and have substantial commercial appeal to blood centers and blood collecting hospitals.      The secondary aim of the proposal is for Talisman to continue assessment of the effectiveness of its computer-assisted, audio-video donor health history self interviewing system, QDS, in reducing donor lying on sexual and other sensitive questions, increasing the frequency of donor returns, reducing staff errors and omissions, and increasing staff efficiency.         n/a",Paperless Quality Donor System with Decision Making,6745080,R44HL072635,"['artificial intelligence', 'blood bank /supply contamination', 'blood donor', 'case history', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'decision making', 'human subject', 'interview', 'patient safety /medical error', 'phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2004,359477,-0.011065739723263277
"Paperless Quality Donor System with Decision Making    DESCRIPTION (provided by applicant):    The principal aim of this proposal is for Talisman to develop, implement and evaluate a computerized, integrated system for processing blood donors that incorporates a series of decision aids and decision algorithms.  The system is expected to significantly reduce donor and staff errors and omissions, increase blood availability, improve staff efficiency and have substantial commercial appeal to blood centers and blood collecting hospitals.      The secondary aim of the proposal is for Talisman to continue assessment of the effectiveness of its computer-assisted, audio-video donor health history self interviewing system, QDS, in reducing donor lying on sexual and other sensitive questions, increasing the frequency of donor returns, reducing staff errors and omissions, and increasing staff efficiency.         n/a",Paperless Quality Donor System with Decision Making,6930165,R44HL072635,"['artificial intelligence', 'blood bank /supply contamination', 'blood donor', 'case history', 'clinical research', 'computer assisted diagnosis', 'computer assisted medical decision making', 'computer program /software', 'computer system design /evaluation', 'decision making', 'human subject', 'interview', 'patient safety /medical error', 'phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2004,394563,-0.011065739723263277
"Accelerated x-ray therapy planning system PEREGRINE DESCRIPTION (provided by applicant): Computerized radiation therapy planning systems (RTP) are essential in Radiation Oncology for quantitative evaluation of radiation doses prior to patient treatment. Among currently available computational methods, the Monte Carlo method of calculating dose distributionsis most universal and accurate. It is believed that Monte Carlo software packages will become a central part of future RTP systems. The limiting problem with current Monte Carlo codes is the length of time (CPU time) required for calculations even when using state-of-the-art hardware. An increase in efficiency of Monte Carlo codes has been demonstrated using algorithms known as variance-reduction techniques (VR techniques), but the calculation times are still too long for routine  clinical use. While there is no single VR technique that would make Monte Carlo code clinically viable, a combination of such techniques usually results in improved performance. At present, the only commercial RTP system using Monte Carlo code for photon dose calculations is PEREGRINE from Lawrence Livermore National Laboratory and NOMOS Corporation. PEREGRINE uses several VR techniques. However, it is estimated that a further reduction in CPU time by a factor of 10 would be required to have a clinically efficient system.  Our theoretical study and subsequent Monte Carlo results support a new variance-reduction technique (NVR) for photon-beam dose calculations. It is shown that NVR yields up to a 5-fold reduction in CPU time. The long-term objective of the project is to reduce PEREGRIN's CPU time from currently several hours to several; minutes. This will require a combination of NVR with other VR techniques. Within this scope, the specific aims of Phase I are:  1. Development, implementation and validation of a PEREGRINE-specific NVR algorithm.  2. Benchmarking of NVR over the range of clinically useful energies in homogeneous and heterogeneous phantoms.  3. Validation of NVR in the case of patient-specific Monte Carlo calculations using CT based patient anatomy. n/a",Accelerated x-ray therapy planning system PEREGRINE,6787955,R41CA108088,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computed axial tomography', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'electromagnetic radiation', 'mathematics', 'patient care planning', 'radiation dosage', 'radiation therapy', 'technology /technique development']",NCI,NOMOS CORPORATION,R41,2004,100000,-0.014627308775349662
"Neuroinformatic Analysis of Olfactory Coding DESCRIPTION (provided by applicant): Our goal is to use neuroinformatics to help resolve the conflicting findings from which two models of olfactory coding have emerged. One model proposes that very many low-specificity neural responses represent each odorant and the other model suggests that fewer, more specific olfactory receptors bind to particular molecular features and that the combination of these specific responses characterizes each odorant. Since much of the data supporting the low-specificity model has been collected without regard for the exquisite spatial heterogeneity of the olfactory system, it is possible that the differences in conclusions could be resolved if the distinct types of data that are collected by various laboratories were placed into spatial register with one another. To that end, we have been building an archive of the spatial patterns of glomerular responses evoked by a wide range of odorants, and we have been able to test hypotheses regarding strategies of olfactory coding by calculating homologies across glomerular-layer response patterns. To facilitate our analytical task, and to make it feasible for others to place their data in register with this odorant response archive, we propose to continue to develop analytical and visualization software for olfactory bulb data. We also propose to extend this approach to both the olfactory epithelium and olfactory cortex to be able to understand both the initial coding and synthetic levels of the olfactory system.  These efforts will be freely available via the web site on which our olfactory activity archive is posted. We propose to improve the site by incorporating meta-data, as well as data from labs using other species and other types of data, such as lesions and neurophysiological data that can be located in space. Finally, the wide range of odorants that we must test to capture a sense of the system also will necessitate the use of an informatics approach to allow us to test hypotheses regarding the complex means by which chemical structure is represented in the system. The combination of these approaches should help resolve the differences between the conflicting models of olfactory coding. n/a",Neuroinformatic Analysis of Olfactory Coding,6803809,R01DC006516,"['artificial intelligence', 'automated data processing', 'bioinformatics', 'chemoreceptors', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'image processing', 'information retrieval', 'laboratory mouse', 'laboratory rat', 'mathematical model', 'meta analysis', 'neural information processing', 'nucleic acid sequence', 'olfactions', 'olfactory lobe', 'olfactory stimulus', 'respiratory epithelium', 'sensory mechanism', 'stimulus /response']",NIDCD,UNIVERSITY OF CALIFORNIA IRVINE,R01,2004,20000,-0.012189315095042216
"A Run-to-Run Algorithm for Glucose Regulation DESCRIPTION (provided by applicant):    The long term objective of this work is to develop new algorithmic approaches to optimize the delivery of insulin in an automated fashion to people with type 1 diabetes. Specifically, we aim to develop a strategy, inspired by run-to-run control theory established by the chemical process industries, that ""learns"" from the previous sequence of glucose responses to insulin dosing (over the course of days), and optimally predicts the appropriate strategy for the forthcoming day. The notion of a ""cycle"" in engineering will be extended to manage the 24 hour routine of repeated meals, activities, and sleep cycles and the corresponding dosing of insulin. The algorithm will be tested in both simulation and clinical trials for robustness to sensor noise, uncertainty in the patient characterization, variability in the timing of the postprandial glucose peak, and variability in the carbohydrate content in the meals. The Specific Aims of this project are to: i) construct predictive patient sensitivity models for calculation of optimal insulin dosing from elevated (or depressed) glucose levels, ii) develop run-to-run algorithm for insulin bolus dosing to provide corrections in subsequent days based on previous history of glucose levels and insulin dosage, and iii) evaluate the robustness of the algorithm through meal challenges of varying carbohydrate content. The aims will blend prototype algorithms that are drawn from systems engineering with validation in a series of clinical tests. The proposed collaboration between systems engineers and renowned diabetes researchers in an established clinical research setting will allow a novel fusion of methods that can be truly characterized as ""innovative"". The medical collaborators in the proposal are located at the prestigious Sansum Medical Research Institute, which is located less than 10 miles from the campus of the University of California, Santa Barbara. The exchange of personnel will be facilitated, allowing the student and post-doc supported on this project to work at both the institute and the university over the span of the project n/a",A Run-to-Run Algorithm for Glucose Regulation,6827448,R01DK068663,"['artificial intelligence', 'bioengineering /biomedical engineering', 'biomedical automation', 'blood glucose', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer simulation', 'dietary carbohydrates', 'drug administration rate /duration', 'drug delivery systems', 'glucose metabolism', 'human subject', 'insulin dependent diabetes mellitus', 'insulin sensitivity /resistance', 'mathematical model', 'model design /development', 'patient oriented research']",NIDDK,SANSUM DIABETES RESEARCH INSTITUTE,R01,2004,203050,-0.03276394305472152
"Vortex Tubed Thermocycler with Intelligent Software    DESCRIPTION (provided by applicant): A novel system is proposed for the rapid identification of DNA. The system comprises of a unique thermocycler platform built around the extraordinary vortex tube, detection optics, intelligent software to provide users with information on most ideal operating conditions, and virtual insight into the PCR process as it progresses. An intelligent user interface will allow DNA amplification/detection on an unprecedented timescale (less than 10 minutes). A multi-disciplinary team that consists of a chemical engineer, a mechanical engineer, and two biochemists has been assembled for this project. The efficiency of the vortex tube will be optimized by the use of computational fluid dynamics. Heat transfer between the gas phase and the cuvets will be improved through computational fluid dynamic calculations. The intelligent software consists of a detailed mathematical model that uses similar starting conditions as the initial cuvet composition to model the amplification progress and it performs a virtual PCR in parallel with the actual process. The virtual PCR will become a quantitative tool point-of-care diagnosis of a wide variety of heritable and infectious diseases. The virtues of the intelligent vortex tube PCRJet are: speed, versatility, reliability, portability and low cost.         n/a",Vortex Tubed Thermocycler with Intelligent Software,6810083,R21RR020219,"['DNA', 'artificial intelligence', 'bacterial DNA', 'bioengineering /biomedical engineering', 'bioinformatics', 'biomedical equipment development', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'diagnostic tests', 'mathematical model', 'neoplasm /cancer genetics', 'nucleic acid amplification techniques', 'nucleic acid purification', 'nucleic acid quantitation /detection', 'optics', 'polymerase chain reaction', 'portable biomedical equipment', 'virus DNA']",NCRR,UNIVERSITY OF NEBRASKA LINCOLN,R21,2004,178840,-0.00382920862357828
"Model for prediction of noise-induced hearing loss DESCRIPTION:  The objective of the proposed work is to develop a prediction model using a statistical learning machine (SLM), which includes an artificial neural network (ANN), a support vector machine (SVM), and a hybrid of ANN and SVM, that will predict the auditory consequences of excessive noise exposure in a chinchilla model. The SLM model will be fed training data from our existing database consisting of noise exposure metrics and audiometric/histological/otoacoustic emission data acquired from previously exposed animals.  Once trained, the SLM model will be able to predict the auditory consequences of exposure to any noise environment characterized by the noise metrics and biological variables of the animals that are input to the model. There are two phases to this research. The first phase is the design of the system structure and implementation software (Year 1). The second phase involves training the system using an extensive database consisting of more than 2500 subjects on which comprehensive exposure and audiometric/ histological data are available (Year 2). The training period will be an iterative process in which the SLM will be modified as training proceeds. The predictions of the SLM model can also be used to design experimental conditions from which the model can be experimentally tested. The successful demonstration of the application of a statistical learning machine to the prediction of noise-induced auditory effects has considerable potential for application to the assessment of industrial and military noise environments for the protection of hearing in humans, and can result in a considerable savings in the amount of work/resources that are needed to develop new and improved noise standards. Specifically, given the many similarities in the response to noise of the chinchilla and the human, the model can be used to identify combinations of parameters of an exposure that are important determinants of damage that would also be applicable to human exposure conditions. The chinchilla model can be used as a template or a guide for developing a human model possibly from some of the existing human data from which current standards were developed. n/a",Model for prediction of noise-induced hearing loss,6753927,R01OH007801,"['chinchilla', 'computational neuroscience', 'computer program /software', 'computer system design /evaluation', 'mathematical model', 'model design /development', 'noise induced deafness', 'noise pollution']",NIOSH,PLATTSBURGH STATE UNIVERSITY,R01,2004,138439,-0.0036361350419111954
"Proteomics processing using networked instrument router DESCRIPTION (provided by applicant):  Real-time, distributed decision-making and data-processing has become necessary as high-throughput proteomics across geographic boundaries becomes more mature. The most common instrument used to characterize and analyze proteins is the Mass Spectrometer. As more Mass Spectrometers are used in parallel to create a high-throughput proteomics system, the data processing needs grow exponentially. Using a cluster of low-cost instrument routers, developed at Userspace Corporation, the goal for this project is to divide the data processing tasks into a decision tree, which converts sequential tasking into parallel tasking or multi-threaded algorithms. These instruments can be controlled and the algorithms can independently process data in parallel or offline as they emerge in large data sets from one or many Mass Spectrometers. The First Phase of study will use an LC-MS (Liquid Chromatography - Mass Spectroscopy) system that uses the ICAT (Isotope Coded Affinity Tags) technology developed at the lab of Dr. Ruedi Aebersold at the University of Washington (who is also the co-founder of the Institute for Systems Biology: ISB). The data from the Mass Spectrometers is analyzed using the COMET algorithm, also developed at the ISB. Userspace Corporation and ISB are collaborating on using Userspace's routers and framework in its Proteomics lab.      The first phase of this project will evaluate technologies and configuration required to process Mass Spectrometry data at the instrument level using a distributed network of the Userspace wireless instrument routers. The data will be processed in real-time as it becomes available to the router cluster and a rule-based decision matrix. The duration of this phase will be six months. The next phases would involve improving the data formatting, so that publication and data mining become science-centric and in a standardized XML (eXtensible Markup Language) representation. Other instruments, algorithms and processes will be added to the router library. n/a",Proteomics processing using networked instrument router,6702436,R43AA014558,"['automated data processing', 'biotechnology', 'computer network', 'computer system design /evaluation', 'high throughput technology', 'mass spectrometry', 'parallel processing', 'proteomics']",NIAAA,USERSPACE CORPORATION,R43,2004,194000,-0.015430653750110879
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6773915,U01DE013331,"['biomarker', 'biopsy', 'clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'enzyme linked immunosorbent assay', 'facial muscles', 'gas chromatography mass spectrometry', 'human subject', 'inflammation', 'interview', 'magnetic resonance imaging', 'mastication', 'musculoskeletal disorder diagnosis', 'oral facial pain', 'pain threshold', 'psychobiology', 'questionnaires', 'radioimmunoassay', 'sign /symptom', 'statistics /biometry', 'synovial fluid', 'temporomandibular joint syndrome', 'tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2004,1637046,-0.004104888382968509
"Tree Ensemble Regression and Classification Methods    DESCRIPTION (provided by applicant):    This SBIR aims to produce next generation classification and regression software based upon ensembles of decision trees: bagging, random forests, and boosting. The prediction accuracy of these methods has caused much excitement in the machine learning community, and both challenges and complements the data modeling culture prevalent among biostatisticians. Recent research extends the methodology to likelihood based methods used in biostatistics, leading to models for survival data and generalized forest models. Generalized forest models extend regression forests in the same way that generalized linear models extend linear models.      This software would apply broadly, including to medical diagnosis, prognostic modeling, and detecting cancer; and for modeling patient characteristics like blood pressure, discrete responses in clinical trials, and count data.      Phase I work will prototype software for survival data, and investigate the performance of ensemble methods on simulated and real data. For survival applications, we will assess out-of-bag estimates of performance, and investigate measures of variable importance and graphics that help clinicians understand the results. Experience writing prototypes and using them on data will lead to a preliminary software design that serves as the foundation of Phase II work.      Phase II will expand upon this work to create commercial software. We will research and implement algorithms for a wider range of applications including generalized forest models, classification, and least squares regression. We will also implement robust loss criteria that enable good performance on noisy data, and make adaptations to handle large data sets.      This proposed software will enable medical researchers to obtain high prediction accuracy, and complement traditional tools like discriminant analysis, linear and logistic regression models, and the Cox model.         n/a",Tree Ensemble Regression and Classification Methods,6832086,R43CA105724,"['clinical research', 'computer assisted medical decision making', 'computer graphics /printing', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'method development', 'model design /development', 'neoplasm /cancer classification /staging', 'neoplasm /cancer diagnosis', 'neoplasm /cancer remission /regression', 'prognosis', 'statistics /biometry']",NCI,INSIGHTFUL CORPORATION,R43,2004,99937,0.008018164607958612
"Micro-environment Glasses as a Treatment for CVS DESCRIPTION (provided by applicant) Computer Vision Syndrome (CVS) refers to a collection of eye problems associated with computer use, and about three-quarters of computer users have it. Conservative estimates indicate that over $2 billion is currently spent on examinations and special eyewear for CVS treatment. The most common symptoms of CVS include: eyestrain or eye fatigue, dry eyes, burning eyes, sensitivity to light, and blurred vision. Non-ocular symptoms include headaches, pain in the shoulders, neck, or back. As diverse as the symptoms are, they may be related and can be subdivided into to three potential pathophysiological causes:   1) Ocular Surface Mechanisms   2) Accommodative Mechanisms   3) Extra-Ocular Mechanisms   There is a significant gap in the fund of knowledge regarding the diagnosis of this disease. In the near-term, we plan to focus on the ocular surface category of disorders as a cause of CVS, identify clinical conditions associated with this syndrome and develop a treatment that addresses this cause. In phase 1, we propose to:   Clinically define CVS by observing the incidence of ocular surface abnormalities in symptomatic subjects and compare them with an age and sex matched non-symptomatic control population   Develop specialized micro-environment glasses to combat CVS symptoms   Study the efficacy of micro-environment glasses in symptomatic and control populations   Critically evaluate viability of CVS micro-environment glasses as a commercial product      using both statistical methods and subjective questionnaires.            n/a",Micro-environment Glasses as a Treatment for CVS,6792878,R41EY015023,"['age difference', 'bioengineering /biomedical engineering', 'biomedical equipment development', 'clinical biomedical equipment', 'clinical research', 'computers', 'data collection methodology /evaluation', 'eye disorder diagnosis', 'gender difference', 'human subject', 'keratoconjunctivitis sicca', 'occupational health /safety', 'portable biomedical equipment', 'questionnaires', 'syndrome', 'vision aid', 'vision disorders', 'visual photosensitivity', 'work site']",NEI,"SEEFIT, INC.",R41,2004,100000,-0.0340845745795337
"Automatic Counting System for Items Used in Surgery    DESCRIPTION (provided by applicant): The specific aim of this work is to develop a technological means to improve the reliability of counting instruments and other items used in surgical operations. This work will directly result in improved clinical outcomes by reducing or eliminating the occurrence of retained foreign bodies following surgery. The inadvertent retention of a foreign body such as a surgical instrument in a patient's body cavity or incision following a surgical procedure continues to be a dangerous and costly accident. Counting is an error-prone process that can be affected by increasing stress and confusion levels that may occur in emergencies or unplanned changes in the surgical procedure. It is hypothesized that an Automatic Counting System would add a level of security beyond that provided by human counting alone. In Phase I, we will determine the feasibility of several candidate-counting technologies for reducing errors. The candidate technologies are computer-vision, radiofrequency-identification tagging and precision weighing of items used in the surgical operation. The Phase I work will be in two parts. The first part is the experimental measurement of the error rates of the individual candidate technologies in terms of identifying and counting surgical instruments and other items used in operations. The second part is a computer simulation using probabilistic methods applied to a mathematical model of the Automatic Counting System that incorporates the candidate technologies. The simulation will be used to determine how well these candidate technologies perform at reducing overall errors when integrated into the whole system. In Phase II, we will continue this work to arrive at a commercially available and clinically usable product.         n/a",Automatic Counting System for Items Used in Surgery,6832636,R43NR009129,"['biomedical automation', 'clinical research', 'computer simulation', 'health services research tag', 'injury prevention', 'mathematical model', 'patient safety /medical error', 'surgery material /equipment', 'technology /technique development']",NINR,"ROBOTIC SURGICAL TECH, INC.",R43,2004,100000,0.00683163799413326
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6766751,P30EY006883,"['biomedical facility', 'health science research', 'vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2004,593925,-0.00960418978305694
"A Novel Probabilistic Engine for Virtual Screening DESCRIPTION (provided by applicant): The goal of this work is to provide a novel probabilistic computational engine for docking-based virtual screening. The engine is based on probabilistic model of Markov Random Fieds (MRF). MRF's have proven successful in other fields such as Computer Vision, and can be seen as a 3D analog of the successful 1D application of Hidden Markov Models to bioinformatics. The docking of a rigid ligand or ligand fragment into a protein active site is modeled as a weighted graphical match of an abstracted description of the ligand to an abstracted description of the active site. These abstracted descriptions are graphs, whose nodes are chemical entities (hydrogen bond acceptors/donors, hydrophobic spheres and etc.) and whose edges are associated distance constraints. The weighted graph-matching problem is expressed as an MRF, whose solution minimizes its associated free energy function. A fast, convergent message-passing scheme called Belief Propagation is used to solve the MRF. The result is a probability distribution that describes all possible placements of the ligand into the active site. Individual low-energy placements of the molecule are obtained by marginalizing this probability distribution. The method provides a fast and mathematically complete examination of possible fits of the ligand into the protein active site, and our prototype MRF application demonstrates excellent timing and completeness properties. The method also provides an attractive data structure enabling a variety of applications. The data structure intrinsically admits an enriched description of the active site. This description can incorporate an extended set of chemical substructures for matching at its nodes. It also can incorporate sets of probabilistic beliefs, expressed as probabilistic prior distributions. These can be used to bias matches according to known actives. Our goals in Phase I are to further develop our prototype into a robust MRF-based docking engine to positioning rigid molecules and molecular fragments into protein active sites. Our goals in Phase II will be to implement applications based on the MRF docking engine: (i) inclusion flexible ligand docking, (ii) incorporation of flexible side chains into docking, (iii) de-novo ligand design, and (iv) docking into multiple aligned proteins. We will seek corporate partners interested in collaborating on applying the technologies to specific problems in drug discovery in Phase I1. The technology developed will be sold as commercial software in Phase III. n/a",A Novel Probabilistic Engine for Virtual Screening,6786885,R43GM071055,"['binding sites', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'ligands', 'statistics /biometry']",NIGMS,"BIOCOMPUTING GROUP, INC.",R43,2004,153420,-0.05289026989342652
"Development of Ultrasonic Appratus for Dental Diagnosis DESCRIPTION: An ultrasonic diagnostic apparatus has been proposed for Dental applications in determining tooth pathologies such as demineralization/caries, hidden fractures, and formation of abscesses. The equipment adopts a piezoelectric and laser optic hybrid transduction system for interrogation of teeth. Ultrasonic responses of the tooth structure will be analyzed by a pattern recognition expert system (artificial intelligence) to determine the diagnosis of the tooth inspected. The proposed research will eventually help to reduce the use of harmful X-ray radiation in Dental clinics and contribute to artificial intelligence based diagnosis. The proposed concept has been successfully demonstrated in the previous Phase I study. In this Phase II study, instrumentation for clinical data collection using a combination of conventional piezoelectric and new laser-based ultrasonic technologies will be developed and optimized; an artificial intelligence based diagnostic function will be developed using clinical data and implemented using embedded computing; numerical simulations will be used to enhance diagnostic function development; and finally, initial clinical trials will be conducted to demonstrate the performance of the prototype equipment. The ultrasonic apparatus for Dental diagnosis outlined in this application is a first application of AI-based NDE in Dentistry. The research concept may also extend to periodontal and craniofacial applications. n/a",Development of Ultrasonic Appratus for Dental Diagnosis,6691772,R44DE014270,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' clinical trials', ' dental disorder diagnosis', ' dental structure', ' dentistry', ' diagnosis design /evaluation', ' human subject', ' patient oriented research', ' tooth', ' tooth surface']",NIDCR,AAC INTERNATIONAL,R44,2003,382129,9.141095704614148e-05
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6682996,R01RR014477,"['X ray crystallography', ' artificial intelligence', ' automated data processing', ' chemical structure', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' crystallization', ' data collection methodology /evaluation', ' image processing', ' mathematics', ' method development', ' protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2003,298672,-0.025340311652476504
"Computer-Aided Interpretation of Oculometric Data    DESCRIPTION (provided by applicant): The primary goal of the proposed research program is to develop computer software tools with embedded artificial intelligence (AI) that can perform instantaneous, automated analysis and clinical interpretation of wavefront error measurements of the human eye and cornea. Secondary goals are to improve the overall design of oculometric data visualization tools, provide information that will help to establish clinical and scientific standards for ocular measurements and procedures, and improve our understanding of the fundamental relationship between optical performance and visual performance. We hypothesize that a) AI-based algorithms will detect complex patterns of wavefront errors; b) these patterns are specific to and significantly correlated with certain diseases and disorders; and c) AI-based interpretation of complex data will be superior to that performed by expert humans, who are the gold standard for interpreting clinical data. Specifically, we will (1) develop, train, and test AI-based algorithms (Bayesian and neural networks) to interpret the significance of complex wavefront error data obtained retrospectively from examination records of patients with various ocular diseases, disorders, or surgical interventions, as well as normal eyes; (2) simulate wavefront error data using computer models based on statistical distributions of actual ocular aberrations from patient population samples for the purpose of investigating the importance of individual higher order aberrations to retinal image formation and potential visual performance, as well as to generate new data that will enhance the overall AI training and testing process, and (3) establish standard methods to acquire and analyze wavefront error data. AI-based tools will assist vision scientists to efficiently develop study databases and analyze aberration data. Clinicians will diagnose patients faster, more accurately, and with a greater degree of confidence. For patients, refractive surgery outcomes will be more predictable, and they will benefit from earlier detection of diseases such as cataracts and corneal ectasias.         n/a",Computer-Aided Interpretation of Oculometric Data,6617187,R01EY014162,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' diagnosis design /evaluation', ' eye disorder diagnosis', ' eye refractometry', ' human data', ' image processing', ' ophthalmoscopy']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2003,241570,-0.00446733780521259
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,6608089,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' clinical research', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' vision tests', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2003,315720,0.00701052218893366
"Development of a Multi-State Decoding Framework DESCRIPTION (provided by applicant): This proposal aims to increase the capability and decrease the cost of decoding the Illumina bead array platform by adding decode states. DNA probes attached to microbeads are randomly loaded onto fiber optic bundles. A decoding process of sequential hybridization stages is necessary to determine the locus correspondence of each bead. Decoders (sequences complementary to the DNA probes on the beads) that are either unlabeled, or labeled with a dye are hybridized to the array. Images are taken after each hybridization, and the experiment is designed so that the hybridization signature of each bead through the decode process, uniquely determines the identity of the bead. The cost and time of decoding is proportional to the number of decode stages. The number of stages is determined by the number of loci represented on the array and the number of distinguishable labels, or decode states, used in the decode process (e.g. ON in dye 1). The current availability of 3 states allows the decoding of 1,500 probes in 8 stages. The successful execution of this project would extend the number of states to at least 8. With 8 states, the number of stages for the 1,500-probe product would become 4. The number of probes that could be decoded in 8 stages would increase by 3 orders of magnitude. The main components of the project are wet lab chemistry and algorithm development. Wet lab chemistry will be used to determine the optimal mixture of dye labeled and unlabeled oligonucleotides that will lead to distinguishable intensity states. Beads will have signal levels in FAM and CY3 dye. Variability in the process will need to be sufficiently low to reliably distinguish different concentrations of dye labeled oligonucleo tides. Three levels of FAM and CY3 signal would lead to 9 states. It is likely that 8 of these will be reliably distinguishable. Pattern matching algorithms will be developed to decode the beads. Decision tree methods based on expected signal will be applied. Arrays will be decoded twice -- first with the current 3-state decoding, and then with the multi-state decoding -- to enable training and machine learning algorithms. Achieving 8 state decoding will decrease the cost of the array and dramatically increase the number of loci explored and the number of probes per locus. n/a",Development of a Multi-State Decoding Framework,6737095,R43HG003096,"['chemistry', ' cost effectiveness', ' dyes', ' mathematics', ' microarray technology', ' nucleic acid probes', ' technology /technique development']",NHGRI,"ILLUMINA, INC.",R43,2003,141830,-0.007511575303295308
"Embedded Tools for Processing Neural Ensembles DESCRIPTION (provided by applicant): Multi-electrode recording from ensembles of neurons in awake, behaving animals is a central technique for understanding the neural basis of behavior and nervous systems disorders, and a prerequisite to the creation of neural-controlled prostheses. However, for these techniques to reach their full potential for processing neural data in real time, there are both computational and the hardware barriers to be overcome.  The overall goal of this project is to provide software and hardware tools for overcoming these barriers and to encourage significant advances in multi-electrode recordings. Phase I will design a fast spike-sorting algorithm for real-time use, embed critical portions in reprogrammable hardware (FPGAs), and construct an overall plug-and-play architecture that integrates FPGA capabilities and includes a high-level FPGA compiler.  Phase II will produce a beta version of Neural Arts' Chorus Recording System that incorporates software and hardware designed in Phase I. The software and hardware resulting from this project will give researchers the first real-time processing platform using reprogrammable FPGAs that is low-cost, lightweight, and can take full advantage of multi-wire electrodes and advanced spike sorting algorithms.  The principal scientific benefit of this research will be to make possible significantly more powerful real-time systems for use with awake, behaving animals. The principal health-related benefit will be to facilitate increased understanding of neural functioning and disorders, and to provide a development platform for accelerated progress toward neural-controlled prostheses. Multi-electrode recording from ensembles of neurons in awake, behaving animals is a central technique for understanding the neural basis of behavior and nervous systems disorders, and a prerequisite to the creation of neural-controlled prostheses. However, for these techniques to reach their full potential for processing neural data in real time, there are both computational and the hardware barriers to be overcome.  The overall goal of this project is to provide software and hardware tools for overcoming these barriers and to encourage significant advances in multi-electrode recordings. Phase I will design a fast spike-sorting algorithm for real-time use, embed critical portions in reprogrammable hardware (FPGAs), and construct an overall plug-and-play architecture that integrates FPGA capabilities and includes a high-level FPGA compiler.  Phase II will produce a beta version of Neural Arts' Chorus Recording System that incorporates software and hardware designed in Phase I. The software and hardware resulting from this project will give researchers the first real-time processing platform using reprogrammable FPGAs that is low-cost, lightweight, and can take full advantage of multi-wire electrodes and advanced spike sorting algorithms.  The principal scientific benefit of this research will be to make possible significantly more powerful real-time systems for use with awake, behaving animals. The principal health-related benefit will be to facilitate increased understanding of neural functioning and disorders, and to provide a development platform for accelerated progress toward neural-controlled prostheses. n/a",Embedded Tools for Processing Neural Ensembles,6742734,R43NS047889,"['artificial intelligence', ' bioengineering /biomedical engineering', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' electrodes', ' electroencephalography']",NINDS,NEURAL ARTS,R43,2003,90695,-0.022405860619962168
"Ab-Initio Geometry Optimization of Large Molecules    DESCRIPTION (provided by applicant):  While density-functional calculations of the energy are now feasible for biomolecules, the use of density-functional geometry optimizers is still confined to relatively small molecules containing no more than thirty atoms. The key limitation of conventional density-functional geometry optimizers is that the cost of the geometry optimization scales at least quadratically with the number of atoms in the molecule. In contrast the energy at a fixed geometry can be evaluated for a cost which scales linearly with molecule size, enabling very large molecules to be treated. This proposal is based on a radical change in the algorithm for density-functional geometry optimization, potentially reducing the total cost from quadratic to linear in molecule size and enabling a quantum leap in the size of molecules that can be optimized. The proposed algorithm resembles a conventional self-consistent calculation of the energy at a fixed geometry but at convergence the proposed algorithm yields not only the density but also the optimized geometry. This is achieved by simultaneous optimization of the wavefunction and the geometry via a modified self-consistent-field procedure. The proposed algorithm will be implemented in the QChem software package and, if successful, widely distributed through QChem Inc. and Spartan Inc.           n/a",Ab-Initio Geometry Optimization of Large Molecules,6583907,R43GM067335,"['artificial intelligence', ' chemical models', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' mathematics', ' molecular dynamics', ' molecular size', ' quantum chemistry']",NIGMS,"Q-CHEM, INC.",R43,2003,99639,-0.01330131988002064
"Inference in Regression Models with Missing Covariates DESCRIPTION:  (Adapted from investigator's abstract) This project will examine new methodology for making inference about the regression parameters in the presence of missing covariate data for two commonly used classes of regression models.  In particular, we examine the class of generalized linear models for general types of response data and the Cox model for survival data.  The methodology addresses problems occurring frequently in clinical investigations for chronic disease, including cancer and AIDS.  The specific objectives of the project are to:  1) develop and study classical and Bayesian methods of inference for the class of generalized linear models (GLM's) in the presence of missing covariate data.  In particular, we will  i) examine methods for estimating the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanism is ignorable.  Also, parametric models for the covariate distribution will be examined.  The methods of estimation will focus on the Monte Carlo version of the EM algorithm (Wei and Tanner, 1990) and other related iterative algorithms.  The Gibbs sampler (Gelfand and Smith, 1990) along with the adaptive rejection algorithm of Gilks and Wild (1992) will be used to sample from the conditional distribution of the missing covariates given the observed data.  ii) examine estimating the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanism is nonignorable.  Models for the missing data mechanism will be studied.  iii) develop and study Bayesian methods of inference in the presence of missing covariate data when the missing covariates are either categorical or continuous and the missing data mechanism is ignorable.  Parametric prior distributions for the regression coefficients are proposed.  Properties of the posterior distributions of the regression coefficients will be studied.  The methodology will be implemented using Markov Chain Monte Carlo methods similar to those of Tanner and Wong (1987). iv) investigate Bayesian methods when the covariates are either categorical or continuous and the missing data mechanism is nonignorable.  Multinomial models for the missing data mechanism will be studied.  Dirichlet prior distributions for the multinomial parameters will be investigated.  2) develop and study classical and Bayesian methods of inference for the Cox model for survival outcomes in the presence of missing covariates.  Specifically, we will  i) develop and study estimation methods for the Cox model for survival outcomes in the presence of missing covariates. Methods for estimating the regression parameters when the missing covariates are either categorical or continuous will be studied.  The methods of estimation will focus on an EM type algorithm similar to that of Wei and Tanner (1990).  ii) study estimation of the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanisms nonignorable.  Models for the missing data mechanism will be studied.  Bayesian methods similar to those of 1-iii) and -iv) will be investigated. Computational techniques using the Monte Carlo methods described in 1-iii) will be implemented.  n/a",Inference in Regression Models with Missing Covariates,6617906,R01CA074015,"['artificial intelligence', ' computer data analysis', ' data collection methodology /evaluation', ' human data', ' mathematical model', ' method development', ' model design /development', ' statistics /biometry']",NCI,UNIVERSITY OF NORTH CAROLINA CHAPEL HILL,R01,2003,170109,-0.003246908197921233
"Permutation Test Software for Randomized Clinical Trials The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of an RCT are almost always analyzed using some form of statistical hypothesis test. The most frequently used hypothesis tests assume a population model for statistical inference, even though a randomization model is more consistent with real-world characteristics of RCTs. Approximate p- values returned by population-model tests can, under certain circumstances, be misleading, resulting in effective drugs being declared ineffective, or ineffective drugs being declared effective. To support analysis of RCTs using the appropriate randomization model, sophisticated software for conducting randomization-based permutation tests is needed. Ongoing advances in computing technology have created a favorable climate for widespread use of such software. The goal of this research is to develop flexible and robust software for carrying out randomization-based permutation tests for single- or multi- clinic RCTs. A subset of this functionality has been successfully implemented in a Phase I pre-prototype (""RTAnalyzer""). Phase II seeks to build a full-scale prototype capable of handling a wide variety of trial designs, including designs using adaptive randomization. The Phase II project includes collaborations with two experts in the field of permutation testing: Dr. William Rosenberger and Dr. Bonnie LaFleur. PROPOSED COMMERCIAL APPLICATION: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid. n/a",Permutation Test Software for Randomized Clinical Trials,6622262,R44CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R44,2003,373280,-0.017459257313572476
"Vector Quantization for Image Pattern Recognition    DESCRIPTION (provided by applicant):    This Phase-I SBIR application addresses the increasingly significant challenges faced by pathologists and clinicians in manually inspecting microscope slides. Microscopic inspection suffers from being labor-intensive, subjective, expensive and limited by the need for physical access to the glass slide specimen of interest. The obstacle to automated microscopic inspection has been the inability to efficiently digitize entire microscope specimens at high resolutions. Aperio has developed the ScanScope (R), a novel microscope slide scanner that makes it practical - for the first time - to rapidly create virtual microscope slides at high resolutions. Virtual slides set the stage for automating microscopic inspection using automated pattern recognition. This research aims to adapt and optimize Aperio's existing and novel algorithms for vector quantization (VQ) to the problem of automatic pattern recognition in virtual slides. VQ is a general mathematical technique for encoding bitstreams using a vocabulary. The primary aim is to demonstrate the feasibility of using VQ for pattern recognition in a practical and well-characterized application: automatically finding virtually all micrometastasis clusters in cytology specimens. This proposed research represents a first attempt to automate pattern recognition in virtual slides using VQ.         n/a",Vector Quantization for Image Pattern Recognition,6695147,R43EB001617,"['artificial intelligence', ' automated data processing', ' bioimaging /biomedical imaging', ' cell line', ' computer system design /evaluation', ' cytology', ' digital imaging', ' high throughput technology', ' metastasis', ' microscopy', ' nomenclature']",NIBIB,"APERIO TECHNOLOGIES, INC.",R43,2003,97269,-0.013770733785437762
"Markov Chain Monte Carlo and Exact Logistic Regression    DESCRIPTION (provided by applicant): Today, software for fitting logistic regression models to binary data belongs in the toolkit of every professional biostatistician, epidemiologist, and social scientist. A natural follow-up to this development is the adoption of exact logistic regression by mainstream biostatisticians and data analysts for any setting in which the accuracy of a statistical analysis based on large-sample maximum likelihood theory is in doubt. Cutting-edge researchers in biometry and numerous other fields have already recognized that it is necessary to supplement inference based on large-sample methods with exact inference for small, sparse and unbalanced data. The LogXact software package developed by Cytel Software Corporation fills this need. It has been used since its inception in 1993 to produce exact inferences for data generated from a wide range fields including clinical trials, epidemiology, disease surveillance, insurance, criminology, finance, accounting, sociology and ecology. In all these applications exact logistic regression was adopted because the limitations of the corresponding asymptotic procedures were clearly recognized in advance by the investigators and the exact inference was computationally feasible. But most of the time it will not be obvious whether asymptotic or exact methods are applicable. Ideally one would prefer to run both types of analyses if there is any doubt about the appropriateness of the asymptotic inference. However, because of the computational limits of the exact algorithms, investigators are currently inhibited from attempting the exact analysis. There is uncertainty about the how long the computations will take and even whether they will produce any results at all before the computer runs out of memory. The current project eliminates this uncertainty by introducing a new generation of numerical algorithms that utilize network based Monte Carlo rejection sampling. The Phase 1 progress report has demonstrated that these new algorithms can speed up the computations by factors of 50 to 1000 relative to what is currently available in LogXact. More importantly they can predict how long a job will take so that the user may decide whether to proceed at once or at a better time. The Phase 2 effort aims to incorporate this new generation of computing algorithms into future versions of LogXact.         n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6587476,R44CA093112,"['artificial intelligence', ' clinical research', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' human data', ' mathematical model', ' mathematics', ' statistics /biometry']",NCI,CYTEL SOFTWARE CORPORATION,R44,2003,400084,-0.0016169346867595167
"Multiparametric Computational Echocardiography DESCRIPTION (provided by applicant):    In the United States, myocardial ischemia is the underlying etiology in nearly 70% of the 5 million patients suffering from mechanical failure of the cardiac left ventricle (LV). Echocardiography (echo) is well suited for the analysis of LV function, however, the problem of conveying this clinically important information in a quantitative, objective, and reproducible manner persists.      To address this problem and respond to the NIH PA-00-117 solicitation for innovations in biomedical information science and technology, the long-term goal of the proposed R21/R33 project is to develop methods for 1) quantitative and objective measurement of LV function, 2) reproducible diagnostic interpretation based on these measurements, and 3) standardized topologic mapping and parametric display of the results. We defined 3 parameters of LV function: 1) rate of local deformation (strain rate), 2) amplitude of deformation (strain), and 3) time interval to the transition (crossover) point of cyclic deformation.      The practical implementation of the long-term objectives will be achieved through the development of a Multiparametric Computational Echo (MPCE) system. The main hypothesis of this R21/R33 project is that the MPCE system will a) precisely and accurately quantitate (R21 phase) and b) reproducibly clinically interpret (R33 phase) segmental LV function. This hypothesis will be tested on digital echo data from animal models and clinical cases of myocardial ischemia representing a wide range of segmental LV dysfunction.      Specific Aims (R21 phase):   Aim 1 - Develop algorithms for parametric analysis of local ventricular function (Year 1).   Aim 2 - Test precision and accuracy of local LV functional analysis using MPCE (Year 2).   Satisfaction of the predefined milestones will initiate the commencement of the R33 phase.      Specific Aims (R33 phase):   Aim 1 - Develop a neural network MPCE system and test it initially in animals (Year 3).   Aim 2 - Refine parametric mapping and test reproducibility of MPCE data in humans (Year 4).   Successful completion of this project will result in noninvasive, quantitative, objective, and reproducible interpretation of LV function, thus facilitating optimal diagnostic and therapeutic decisions in cardiology. n/a",Multiparametric Computational Echocardiography,6688878,R21HL070363,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' echocardiography', ' evaluation /testing', ' heart function', ' human subject', ' method development', ' swine']",NHLBI,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R21,2003,136861,-0.0124425398433448
"System for Cost Effective Clinical Trial Design The long-term objective of this project is to develop software to facilitate the design of cost effective clinical trials. In 1999, the pharmaceutical industry and NIH spent more than $23 billion on clinical trials. Developments in clinical trial design theory, and in optimization algorithms have opened possibilities for more cost- effective designs that can be executed for lower total cost, over shorter periods of time and / or requiring fewer patients. The proposed System for Cost Effective Trials (SCET) will be a software package to guide the trial designer through comparisons of the power, sample size requirements, and cost of alternate trial designs. These methods are under-used throughout medical research, but are particularly applicable to trials with relatively short treatment regimens and rapid ascertainment of endpoints, such as many cancer treatment trials. The aims of SCET Phase II are to build the system, validate it in compliance with FDA regulations for software validation, perform Beta testing at a range of target client organizations, and use the Beta test findings to produce a marketable release. PROPOSED COMMERCIAL APPLICATION: The potential market for this software system includes virtually every pharmaceutical company in the world (multiple licenses to each), every biotech company involved in clinical trials, every contract research organization involved in the design or conduct of clinical trials, coordinating centers of NIH-sponsored multi-center clinical trials, individual university-based investigators who conduct clinical trials, individual biostatistical consultants who design clinical trials, and agricultural businesses and researchers that conduct animal research. n/a",System for Cost Effective Clinical Trial Design,6626050,R44CA088667,"['artificial intelligence', ' clinical trials', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' cost effectiveness', ' drug design /synthesis /production', ' experimental designs']",NCI,"RHO FEDERAL SYSTEMS DIVISION, INC.",R44,2003,386197,-0.013889650456670505
"Software to Handle Missing Values in Large Data DESCRIPTION (provided by applicant):    This SBIR aims to produce commercial software for handling missing data in large data sets, where the goal is data mining and knowledge discovery. There may be a large number of subjects, variables, or both. Examples include microarray data, surveys, genomic data, and high throughput screening data.      Handling missing data is one important step of careful data preparation, which is key to the success of an entire project. Missing values often arise in medical data. This is an obstacle because many data mining tools either require complete data or are not robust to missing data.      Principled methods of handling missing data are computationally intensive. Therefore computational feasibility is a challenge to handling missing values in large data sets.      Phase I work will explore strategies such as sampling, constraining parameters, and monotone data algorithms for model based techniques. Factor analysis and multivariate linear mixed effects models will be used to reduce the number of parameters. A variable-by-variable approach using a popular data mining technique, recursive partitioning, will also be used to impute missing values.      For each of the methods, we will write prototype software and test performance on missing data patterns simulated on real data. Several ad hoc techniques will serve as a baseline for comparison.   Experience writing prototypes and using them in simulations will lead to preliminary software design that will serve as the foundation of Phase II work.       This proposed software will enable medical researchers to gain more from their data mining efforts: maximally extracting information and achieving unbiased predictions, despite missing data. n/a",Software to Handle Missing Values in Large Data,6690119,R43RR017862,"['artificial intelligence', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' human data', ' mathematical model', ' statistics /biometry']",NCRR,INSIGHTFUL CORPORATION,R43,2003,99847,-0.003306419587474712
"Optical Detection of Intravenous Infiltration  DESCRIPTION (provided by applicant): About 80% of hospital patients in the United States require IV therapy and 50% of IV lines fail due to infiltration, a clot in the cannula, an inflammatory response of the vein, or separation of the cannula from the vein. IV infiltration is usually accompanied by pain, erythema, and swelling at the cannula tip or the insertion site. Severe infiltration may lead to necrosis requiring skin debridement, skin grafting, or amputation. Early detection of infiltration prevents the occurrence of serious incidents that may require surgical correction. The long-term objective of this project is to develop an infiltration sensor for monitoring IV failures. The Phase II research design includes the development of an advanced prototype, improvement of algorithms, evaluation of the prototype on animal models and human measurements, investigation of its accuracy and utility, and the examination of the commercial potential. The innovation of this project lies in the use of an optical method coupled with the advanced development in fiber optics and algorithms for tissue optics to provide a means for noninvasive monitoring of the IV sites. It will provide routine, automated, continuous, and real-time monitoring capabilities for patients undergoing IV therapy.   n/a",Optical Detection of Intravenous Infiltration,6666836,R44HL062008,"['artificial intelligence', ' blood coagulation', ' catheterization', ' clinical research', ' diagnosis design /evaluation', ' fiber optics', ' human subject', ' intravenous administration', ' medical complication', ' necrosis', ' optics', ' patient monitoring device', ' swine', ' technology /technique development']",NHLBI,"CW OPTICS, INC.",R44,2003,381881,-0.031000270351987966
"Diagnostic Aid Software for Visual Field Test    DESCRIPTION (provided by applicant): Visual Field (VF) test is a widely used, noninvasive technique for evaluating pathology or dysfunction in the visual pathways. The VF test, in conjunction with other diagnostics, is used for detection of early stages of glaucoma and for following its progression. Early detection is critical as blindness from glaucoma is preventable in nearly all cases, provided treatment is administered early in the progression. However, the inherent subjectivity of the VF test makes it often difficult to interpret even for a skilled practitioner. There is a need for automated decision aid tool that will facilitate and standardize the interpretation task.   In Phase 1 of this project, IAC will design and implement novel software algorithms to automate the interpretation of VF test data for detection of glaucoma. The software will classify VF test data into normal, borderline glaucomatous, glaucomatous and unknown (not normal or glaucomatous). The aim is to provide classification performance close to that of a highly skilled human expert. The emphasis will be on the detection of early stages of glaucoma. In addition to the classification output, the software will produce a set of comprehensive rules that will explain the decision path leading to the suggested diagnosis.         n/a",Diagnostic Aid Software for Visual Field Test,6582662,R43EY014077,"['artificial intelligence', ' computer assisted diagnosis', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' early diagnosis', ' glaucoma', ' glaucoma test', ' human data', ' noninvasive diagnosis', ' vision tests', ' visual fields']",NEI,INTELLIGENT AUTOMATION CORPORATION,R43,2003,99681,-0.02739539544884776
"Rapid Cancer-Treatment Efficacy Monitoring System DESCRIPTION (provided by applicant): Evaluating cancer therapy efficacy by studying symptomatic improvement in patient condition is a popular practice due to the lack of rapid, reliable and robust quantitative evaluation protocols for routine clinical measurement of cancer therapy efficacy. Reducing time required for arriving at decisions and reducing cost without compromising accuracy could provide potentially improved treatments especially for patients with advanced leukemia of various types. This proposal focuses on rapid quantitative assessment of cancer treatment efficacy for leukemia. The proposed approach is based on quantifying apoptosis (programmed cell death) and has been shown to be one of the most reliable and one of the earliest indicators for assessing anticancer efficacy of a drug. Several other techniques are available to detect apoptosis (Agarose gel electrophoresis, Caspase-3, TUNEL assay, Morphological estimation, Annexin V assays etc). However, these techniques are inaccurate, expensive or time consuming.      A recently developed a two stage DNA diffusion assay holds promise to be an accurate, relatively inexpensive and rapid methodology for quantitative apoptosis measurement via the apoptotic index. The two stages are:(1) slide preparation and microscopy imaging, which requires approximately 1.5 hrs and (2) image analysis, which is tedious, and takes approximately 2 hours of additional intensive manual labor leading to errors in categorization of the cells. We propose to fully automate the second stage with the goal to minimize manual effort and there by reduce the human errors. This would also make the procedure more reproducible. Phase I work will involve: (1) segmentation and classification algorithm development for automatic apoptotic index calculation, and (2) characterizing the algorithm performance by inducing apoptosis in leukemia cells in culture using known apoptosis inducing agents. n/a",Rapid Cancer-Treatment Efficacy Monitoring System,6643057,R43CA101292,"['apoptosis', ' artificial intelligence', ' automated health care system', ' bioimaging /biomedical imaging', ' biomedical automation', ' computer program /software', ' fluorescence microscopy', ' image processing', ' leukemia', ' patient care management', ' prognosis', ' technology /technique development', ' tissue /cell culture']",NCI,INSIGHTFUL CORPORATION,R43,2003,99644,-0.034270110314831424
"Community Deposit and Review of Biochemical Databases DESCRIPTION (provided by applicant):    Understanding how the phenotype of an organism is produced by its genotype and environment is fundamental to modern biomedicine. Cellular biochemistry forms the best-characterized complex biochemical system available, and provides a unique opportunity to better understand the structure-function relationships that produce phenotypes. Understood mathematically, cells are a biochemical network whose topology, function, and possible behaviors are only still only dimly understood.      Our previous work has resulted in the development of several databases (END, BND, Klotho) and software systems (The Agora, Glossa) to provide, accumulate, and use data on biochemical networks by users worldwide. In this application for competitive renewal, we propose to embark on a systematic study of structure-function relationships in biochemical networks, focusing on the discovery of patterns of biochemical function --- functional motives. We will identify these motives and their distribution over all enzymatic reactions by comparing changes in reactants' structures and enzymes' specificities, rather than just examine keywords. This systematic examination will allow us to determine, at much greater resolution than ever before, what functions each molecule and reaction have. To do this we must significantly extend the functionalities of our current systems in three major ways. First, we will add significant new data on the structure of small molecules of biochemical interest, enzymatic reactions, the mechanisms of gene expression, and dementia. Second, we will further develop and test methods that produce semantic interoperability among independent, disparate databases. Third, we will develop algorithms to detect and catalogue patterns of biochemical function among thousands of reactions and molecules; to more speedily enumerate paths among molecules and subnets in the biochemical network; to determine the extent of convergent evolution among enzymes; to trace atoms through a sequence of reactions such as a metabolic pathway; and to suggest novel biochemical reactions. We will use these capabilities to define and search for functional motives among enzymatic reactions, testing their correlation with network topology and dynamics, and to estimate the extent to which functional similarities arise from convergent evolution of enzymes. n/a",Community Deposit and Review of Biochemical Databases,6694513,R01GM056529,"['artificial intelligence', ' biochemistry', ' computer program /software', ' computer system design /evaluation', ' dementia', ' enzyme mechanism', ' functional /structural genomics', ' information system analysis', ' mathematical model', ' molecular biology information system', ' molecular dynamics', ' physiology', ' protein structure function']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2003,556670,-0.02601916319833742
"Smart Power Assistance Module for Manual Wheelchairs    DESCRIPTION (provided by applicant): We propose to use power assistance as the basis for a Smart Power Assistance Module (SPAM) that provides independent power assistance to the right and left rear wheels of a manual wheelchair. The SPAM will detect obstacles near the wheelchair, and modify the forces applied to each wheel to avoid obstacles.  For individuals with visual impairments that are unable to walk with a long cane or walker, the SPAM will provide safe travel by assisting the user to avoid obstacles. This research will build on the investigative team's previous experience with power assistance for manual wheelchairs and obstacle avoidance for power wheelchairs and rollators. Extensive outside evaluation of the SPAM will be provided throughout the course of the project by clinicians active in wheelchair seating and mobility.         n/a",Smart Power Assistance Module for Manual Wheelchairs,6667132,R43EY014490,"['artificial intelligence', ' assistive device /technology', ' biomedical device power system', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' field study', ' human subject', ' medical rehabilitation related tag', ' vision aid', ' vision disorders']",NEI,AT SCIENCES,R43,2003,209800,-0.003627129755739604
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6635877,R37GM030998,"['DNA', ' artificial intelligence', ' biochemical evolution', ' computational neuroscience', ' computer assisted sequence analysis', ' computer simulation', ' gene frequency', ' genetic models', ' mathematical model', ' method development', ' model design /development', ' natural selections', ' nucleic acid sequence', ' species difference', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2003,161792,-0.03200257674086958
"Automated Quantitation of 3D Echocardiograms In Phase I we developed a method for automated border detection (ABD) of echocardiographic scans that is feasible for clinical application. The accuracy of our processes provides exceeds Phase I goals and is comparable to interobserver variability in measuring volume and ejection fraction, and in border location. For a diverse set of patients, we have achieved an accuracy of 10 ml for endocardial volume, 4% for ejection fraction, and ,2.0 mm for border position. Our processes operates in 4 min. In Phase II we propose to continue research and development to move our ABD technology closer to clinical user. Our first specific aim is to reduce the amount of manual input required even further. Our second aim is to develop a prototype system suitable for clinical evaluation. Our third aim is to perform a pilot trial to evaluate the performance of our ABD process, as a preparation for a more formal, multi-center clinical trial planned for Phase III. The proposed research is important because quantitative 3D echo provides greater accuracy and reproducibility and more comprehensive information on cardiac status than currently available imaging techniques. The significant advantages of 3D echo are not currently available for clinical practice because it is impractical without automation. PROPOSED COMMERCIAL APPLICATIONS: Automation of echocardiogram border detection enables physicians to obtain accurate, reproducible and comprehensive measurements of the heart's size, shape and function. This technology can be included in ultrasound systems or provided in workstations. The core technology can be applied to other organs and other imaging modalities. n/a",Automated Quantitation of 3D Echocardiograms,6622226,R44HL059054,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' echocardiography', ' heart disorder diagnosis', ' heart ventricle', ' human subject', ' image processing', ' papillary muscles', ' pericardium']",NHLBI,"QUANTIGRAPHICS, INC.",R44,2003,244092,-0.02449168749835427
"AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION Quantification of Minimal Residual Disease (MRD) is a general concern in oncology since this parameter is likely to give valuable information to clinicians to customize chemotherapeutic treatments and to anticipate possible relapses. An automated system will be developed for the quantification of MRD by using real-time PCR to quantify cancer cells in a background of non pathologic DNA. The system will be derived from an existing high-throughput sample handling system (developed by Meldrum and team) named Acapella. Acapella has a pipelined serial architecture which makes it possible to develop an adaptive PCR control algorithm ensuring a level of sensitivity and accuracy for the quantification results specified by the clinician. In the R21 phase of the project, a critical component of the system is the real-time thermocycler. It will provide DNA quantification results of greater precision than what is currently possible with commercial instruments such as the ABI PRISM 7700 Sequence Detector by taking advantage of a high performance custom fluorescence analyzer and sophisticated data analysis methods. The fluorescence analyzer will have a signal to noise ratio and a dynamic range of at least one order of magnitude larger than the optics used on commercial systems. This unique feature will permit precise measurements of the amplification kinetics during at least five cycles in the exponential phase of the reaction. The amplification yield will he derived from these data using statistical estimators customized to meet the requirements of real-time PCR data analysis. The sample DNA content will be derived from the amplification yield and the calibrated fluorescence measurements of the reaction kinetics. This new approach will make it possible to run series of real-time PCRs with more flexibility than would be possible if the assay was based on standard reactions required to have the same amplification yield as the clinical samples. PCR conditions will be adapted online without concerns about possible differences of amplification rate. The assay control algorithm will adapt the reaction DNA content, the primer selection, and the number of PCRs to meet the clinician requirements for particular patient DNA. During the R21 phase of the project a prototype of the real-time thermocycler will be developed to demonstrate the optic performance and the possibility to estimate the PCR amplification rates with 5% accuracy. A conceptual design of the fully integrated process from patient blood sample to MRD quantification data will be completed to allow assessment of expected performance, cost, and risks associated with the development of the fully engineered system. The development of the various hardware and software components along with their integration into the automated system will take place during the R33 phase of the project. Performance of the system will he evaluated on real biological samples provided by the UW Department of Laboratory Medicine. Results returned by the system will he compared with results of t(14; 18) PCR performed in this department with an ABI PRISM 7700 for the diagnosis of patients suffering from follicular lymphomas.  n/a",AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION,6633609,R33CA084691,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosome translocation', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence', ' high throughput technology', ' human tissue', ' minimal residual disease', ' neoplasm /cancer diagnosis', "" nonHodgkin's lymphoma"", ' nucleic acid quantitation /detection', ' polymerase chain reaction']",NCI,UNIVERSITY OF WASHINGTON,R33,2003,618638,0.0011818646275180906
"Paperless Quality Donor System with Decision Making    DESCRIPTION (provided by applicant):    The principal aim of this proposal is for Talisman to develop, implement and evaluate a computerized, integrated system for processing blood donors that incorporates a series of decision aids and decision algorithms.  The system is expected to significantly reduce donor and staff errors and omissions, increase blood availability, improve staff efficiency and have substantial commercial appeal to blood centers and blood collecting hospitals.      The secondary aim of the proposal is for Talisman to continue assessment of the effectiveness of its computer-assisted, audio-video donor health history self interviewing system, QDS, in reducing donor lying on sexual and other sensitive questions, increasing the frequency of donor returns, reducing staff errors and omissions, and increasing staff efficiency.         n/a",Paperless Quality Donor System with Decision Making,6728674,R44HL072635,"['artificial intelligence', ' blood bank /supply contamination', ' blood donor', ' case history', ' clinical research', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer program /software', ' computer system design /evaluation', ' decision making', ' human subject', ' interview', ' patient safety /medical error', ' phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2003,514079,-0.011065739723263277
"Paperless Quality Donor System with Decision Making    DESCRIPTION (provided by applicant):    The principal aim of this proposal is for Talisman to develop, implement and evaluate a computerized, integrated system for processing blood donors that incorporates a series of decision aids and decision algorithms.  The system is expected to significantly reduce donor and staff errors and omissions, increase blood availability, improve staff efficiency and have substantial commercial appeal to blood centers and blood collecting hospitals.      The secondary aim of the proposal is for Talisman to continue assessment of the effectiveness of its computer-assisted, audio-video donor health history self interviewing system, QDS, in reducing donor lying on sexual and other sensitive questions, increasing the frequency of donor returns, reducing staff errors and omissions, and increasing staff efficiency.         n/a",Paperless Quality Donor System with Decision Making,6585908,R44HL072635,"['artificial intelligence', ' blood bank /supply contamination', ' blood donor', ' case history', ' clinical research', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer program /software', ' computer system design /evaluation', ' decision making', ' human subject', ' interview', ' patient safety /medical error', ' phlebotomy']",NHLBI,"TALISMAN, LTD",R44,2003,119826,-0.011065739723263277
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6640921,U01DE013331,"['biomarker', ' biopsy', ' clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' enzyme linked immunosorbent assay', ' facial muscles', ' gas chromatography mass spectrometry', ' human subject', ' inflammation', ' interview', ' magnetic resonance imaging', ' mastication', ' musculoskeletal disorder diagnosis', ' oral facial pain', ' pain threshold', ' psychobiology', ' questionnaires', ' radioimmunoassay', ' sign /symptom', ' statistics /biometry', ' synovial fluid', ' temporomandibular joint syndrome', ' tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2003,1388868,-0.004104888382968509
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6707987,U01DE013331,"['biomarker', ' biopsy', ' clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' enzyme linked immunosorbent assay', ' facial muscles', ' gas chromatography mass spectrometry', ' human subject', ' inflammation', ' interview', ' magnetic resonance imaging', ' mastication', ' musculoskeletal disorder diagnosis', ' oral facial pain', ' pain threshold', ' psychobiology', ' questionnaires', ' radioimmunoassay', ' sign /symptom', ' statistics /biometry', ' synovial fluid', ' temporomandibular joint syndrome', ' tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2003,376755,-0.004104888382968509
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6635595,P30EY006883,"['biomedical facility', ' health science research', ' vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2003,576626,-0.00960418978305694
"Using AL to Enhance VR Anxiety Disorder Treatment DESCRIPTION (provided by applicant) This project will develop an artificial intelligence to provide the core functionality for virtual reality and computer based treatments for anxiety disorders. The use of artificial intelligence offers a number of advantages over existing treatments: (1) artificial intelligence provides personalized treatment - using multiple real time physiologic and subjective anxiety feedback loops, it adjusts exposure stimuli ""on the fly"" to maximize outcome, (2) as an autonomous system, it has the potential to be used safely in a wide range of applications from therapist guided interventions to minimal therapist contact interventions to self guided treatment, (3) it is adaptive and flexible, continuously learning what works and doesn't work, applying those changes in real time, and storing them for later use, (4) it can monitor levels of presence and adjust patient/exposure variables to ensure the depth of presence necessary to benefit from virtual reality treatments, and (5) it has the potential to increase retention in treatment by monitoring factors that predict drop out and adjusting exposure to minimize their effect. During Phase I eighty phobic and non-phobic participants will be used to build, assess, and validate the artificial intelligence. This is the first application of artificial intelligence to virtual reality treatments for anxiety disorders. n/a",Using AL to Enhance VR Anxiety Disorder Treatment,6443585,R41DA016534,"['anxiety disorders', ' artificial intelligence', ' behavioral /social science research tag', ' clinical research', ' computer assisted patient care', ' computer human interaction', ' computer simulation', ' computer system design /evaluation', ' human subject', ' interactive multimedia', ' library', ' phobias', ' psychotherapy']",NIDA,"VRSIMULATIONS, INC.",R41,2002,101678,-0.025988912666112318
"Using AL to Enhance VR Anxiety Disorder Treatment DESCRIPTION (provided by applicant) This project will develop an artificial intelligence to provide the core functionality for virtual reality and computer based treatments for anxiety disorders. The use of artificial intelligence offers a number of advantages over existing treatments: (1) artificial intelligence provides personalized treatment - using multiple real time physiologic and subjective anxiety feedback loops, it adjusts exposure stimuli ""on the fly"" to maximize outcome, (2) as an autonomous system, it has the potential to be used safely in a wide range of applications from therapist guided interventions to minimal therapist contact interventions to self guided treatment, (3) it is adaptive and flexible, continuously learning what works and doesn't work, applying those changes in real time, and storing them for later use, (4) it can monitor levels of presence and adjust patient/exposure variables to ensure the depth of presence necessary to benefit from virtual reality treatments, and (5) it has the potential to increase retention in treatment by monitoring factors that predict drop out and adjusting exposure to minimize their effect. During Phase I eighty phobic and non-phobic participants will be used to build, assess, and validate the artificial intelligence. This is the first application of artificial intelligence to virtual reality treatments for anxiety disorders. n/a",Using AL to Enhance VR Anxiety Disorder Treatment,6745859,R41DA016534,"['anxiety disorders', ' artificial intelligence', ' behavioral /social science research tag', ' clinical research', ' computer assisted patient care', ' computer human interaction', ' computer simulation', ' computer system design /evaluation', ' human subject', ' interactive multimedia', ' library', ' phobias', ' psychotherapy']",NIDA,"VRSIMULATIONS, INC.",R41,2002,101678,-0.025988912666112318
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,6545242,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' clinical research', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' vision tests', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2002,315720,0.00701052218893366
FOUNDATION MODEL OF ANATOMY No abstract available n/a,FOUNDATION MODEL OF ANATOMY,6538208,R01LM006822,"['anatomy', ' artificial intelligence', ' biological models', ' computer simulation', ' human data', ' information systems', ' model design /development', ' physical model']",NLM,UNIVERSITY OF WASHINGTON,R01,2002,465957,-0.0015567561719376476
FOUNDATION MODEL OF ANATOMY No abstract available n/a,FOUNDATION MODEL OF ANATOMY,6555795,R01LM006822,"['anatomy', ' artificial intelligence', ' biological models', ' computer simulation', ' human data', ' information systems', ' model design /development', ' physical model']",NLM,UNIVERSITY OF WASHINGTON,R01,2002,20004,-0.0015567561719376476
FOUNDATION MODEL OF ANATOMY No abstract available n/a,FOUNDATION MODEL OF ANATOMY,6658862,R01LM006822,"['anatomy', ' artificial intelligence', ' biological models', ' computer simulation', ' human data', ' information systems', ' model design /development', ' physical model']",NLM,UNIVERSITY OF WASHINGTON,R01,2002,30000,-0.0015567561719376476
"Inference in Regression Models with Missing Covariates DESCRIPTION:  (Adapted from investigator's abstract) This project will examine new methodology for making inference about the regression parameters in the presence of missing covariate data for two commonly used classes of regression models.  In particular, we examine the class of generalized linear models for general types of response data and the Cox model for survival data.  The methodology addresses problems occurring frequently in clinical investigations for chronic disease, including cancer and AIDS.  The specific objectives of the project are to:  1) develop and study classical and Bayesian methods of inference for the class of generalized linear models (GLM's) in the presence of missing covariate data.  In particular, we will  i) examine methods for estimating the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanism is ignorable.  Also, parametric models for the covariate distribution will be examined.  The methods of estimation will focus on the Monte Carlo version of the EM algorithm (Wei and Tanner, 1990) and other related iterative algorithms.  The Gibbs sampler (Gelfand and Smith, 1990) along with the adaptive rejection algorithm of Gilks and Wild (1992) will be used to sample from the conditional distribution of the missing covariates given the observed data.  ii) examine estimating the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanism is nonignorable.  Models for the missing data mechanism will be studied.  iii) develop and study Bayesian methods of inference in the presence of missing covariate data when the missing covariates are either categorical or continuous and the missing data mechanism is ignorable.  Parametric prior distributions for the regression coefficients are proposed.  Properties of the posterior distributions of the regression coefficients will be studied.  The methodology will be implemented using Markov Chain Monte Carlo methods similar to those of Tanner and Wong (1987). iv) investigate Bayesian methods when the covariates are either categorical or continuous and the missing data mechanism is nonignorable.  Multinomial models for the missing data mechanism will be studied.  Dirichlet prior distributions for the multinomial parameters will be investigated.  2) develop and study classical and Bayesian methods of inference for the Cox model for survival outcomes in the presence of missing covariates.  Specifically, we will  i) develop and study estimation methods for the Cox model for survival outcomes in the presence of missing covariates. Methods for estimating the regression parameters when the missing covariates are either categorical or continuous will be studied.  The methods of estimation will focus on an EM type algorithm similar to that of Wei and Tanner (1990).  ii) study estimation of the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanisms nonignorable.  Models for the missing data mechanism will be studied.  Bayesian methods similar to those of 1-iii) and -iv) will be investigated. Computational techniques using the Monte Carlo methods described in 1-iii) will be implemented.  n/a",Inference in Regression Models with Missing Covariates,6605420,R01CA074015,"['artificial intelligence', ' computer data analysis', ' data collection methodology /evaluation', ' human data', ' mathematical model', ' method development', ' model design /development', ' statistics /biometry']",NCI,UNIVERSITY OF NORTH CAROLINA CHAPEL HILL,R01,2002,174567,-0.003246908197921233
"Inference in Regression Models with Missing Covariates DESCRIPTION:  (Adapted from investigator's abstract) This project will examine new methodology for making inference about the regression parameters in the presence of missing covariate data for two commonly used classes of regression models.  In particular, we examine the class of generalized linear models for general types of response data and the Cox model for survival data.  The methodology addresses problems occurring frequently in clinical investigations for chronic disease, including cancer and AIDS.  The specific objectives of the project are to:  1) develop and study classical and Bayesian methods of inference for the class of generalized linear models (GLM's) in the presence of missing covariate data.  In particular, we will  i) examine methods for estimating the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanism is ignorable.  Also, parametric models for the covariate distribution will be examined.  The methods of estimation will focus on the Monte Carlo version of the EM algorithm (Wei and Tanner, 1990) and other related iterative algorithms.  The Gibbs sampler (Gelfand and Smith, 1990) along with the adaptive rejection algorithm of Gilks and Wild (1992) will be used to sample from the conditional distribution of the missing covariates given the observed data.  ii) examine estimating the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanism is nonignorable.  Models for the missing data mechanism will be studied.  iii) develop and study Bayesian methods of inference in the presence of missing covariate data when the missing covariates are either categorical or continuous and the missing data mechanism is ignorable.  Parametric prior distributions for the regression coefficients are proposed.  Properties of the posterior distributions of the regression coefficients will be studied.  The methodology will be implemented using Markov Chain Monte Carlo methods similar to those of Tanner and Wong (1987). iv) investigate Bayesian methods when the covariates are either categorical or continuous and the missing data mechanism is nonignorable.  Multinomial models for the missing data mechanism will be studied.  Dirichlet prior distributions for the multinomial parameters will be investigated.  2) develop and study classical and Bayesian methods of inference for the Cox model for survival outcomes in the presence of missing covariates.  Specifically, we will  i) develop and study estimation methods for the Cox model for survival outcomes in the presence of missing covariates. Methods for estimating the regression parameters when the missing covariates are either categorical or continuous will be studied.  The methods of estimation will focus on an EM type algorithm similar to that of Wei and Tanner (1990).  ii) study estimation of the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanisms nonignorable.  Models for the missing data mechanism will be studied.  Bayesian methods similar to those of 1-iii) and -iv) will be investigated. Computational techniques using the Monte Carlo methods described in 1-iii) will be implemented.  n/a",Inference in Regression Models with Missing Covariates,6513068,R01CA074015,"['artificial intelligence', ' computer data analysis', ' data collection methodology /evaluation', ' human data', ' mathematical model', ' method development', ' model design /development', ' statistics /biometry']",NCI,DANA-FARBER CANCER INSTITUTE,R01,2002,21871,-0.003246908197921233
VOICE RESPONSE/INTERNET REGISTRATION & RANDOMIZATION No abstract available n/a,VOICE RESPONSE/INTERNET REGISTRATION & RANDOMIZATION,6540631,R44RR014168,"['Internet', ' artificial intelligence', ' clinical trials', ' computer program /software', ' computer system design /evaluation', ' interactive multimedia', ' patient /disease registry', ' statistics /biometry', ' telecommunications']",NCRR,"RHO FEDERAL SYSTEMS DIVISION, INC.",R44,2002,366772,-0.007693349885409842
"Improving Quantum Chemistry Calculations DESCRIPTION (provided by applicant): We propose to extend the functionality of our commercial quantum chemistry program, Q-Chem, to effectively treat molecules containing transition metals. This enhanced capability will provide Q-Chem's end-users with the ability to accurately model complex molecules such as proteins, enzymes, and catalysts of industrial importance. While remarkable progress has been made over the last several years in the accurate modeling of systems containing transition metals, current numerical methods for achieving SCF convergence in these systems are problematic at best, resulting in long execution times or, in some cases, complete failure to find a solution. However, a novel computational technique developed at Q-Chem has been shown to dramatically improve convergence for organic molecules with known SCF convergence problems. We propose to adapt this method for use with transition metals. Our goal is to achieve the same robust SCF convergence that is realized for most organic molecules, thereby greatly increasing productivity and extending the capability of scientists to study molecules such as enzymes and industrial catalysts. During Phase (I, our efforts will be to further extend Q-Chem's capability in the molecular biology arena. This proposal seeks to improve the quantum chemical treatment of molecular systems containing transition metals. Transition metal elements are essential to natural biological processes. The technology developed in this research will enable the computer modeling of those systems that are difficult to handle with the current methodologies and therefore increase of the applications of computational modeling. PROPOSED COMMERCIAL APPLICATION: Transition-metal elements play a vital role in biological systems.  The success of this project will improve the performance of modeling of transition-metal complexes and making the modelings possible for the systems that current algorithms fail.  The resulting work will be made available to researchers in health industry and universities through our commercial software Q-Chem. n/a",Improving Quantum Chemistry Calculations,6484828,R43GM065617,"['artificial intelligence', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' heavy metals', ' mathematical model', ' mathematics', ' model design /development', ' quantum chemistry']",NIGMS,"Q-CHEM, INC.",R43,2002,109642,-0.02210644989189472
"Permutation Test Software for Randomized Clinical Trials The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of an RCT are almost always analyzed using some form of statistical hypothesis test. The most frequently used hypothesis tests assume a population model for statistical inference, even though a randomization model is more consistent with real-world characteristics of RCTs. Approximate p- values returned by population-model tests can, under certain circumstances, be misleading, resulting in effective drugs being declared ineffective, or ineffective drugs being declared effective. To support analysis of RCTs using the appropriate randomization model, sophisticated software for conducting randomization-based permutation tests is needed. Ongoing advances in computing technology have created a favorable climate for widespread use of such software. The goal of this research is to develop flexible and robust software for carrying out randomization-based permutation tests for single- or multi- clinic RCTs. A subset of this functionality has been successfully implemented in a Phase I pre-prototype (""RTAnalyzer""). Phase II seeks to build a full-scale prototype capable of handling a wide variety of trial designs, including designs using adaptive randomization. The Phase II project includes collaborations with two experts in the field of permutation testing: Dr. William Rosenberger and Dr. Bonnie LaFleur. PROPOSED COMMERCIAL APPLICATION: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid. n/a",Permutation Test Software for Randomized Clinical Trials,6444337,R44CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R44,2002,362409,-0.017459257313572476
"Narrow-Band Active Noise Reduction for DPOAE Measurement DESCRIPTION (provided by applicant): The aim of this project is to enable accurate acquisition of distortion product otoacoustic emission (DPOAE) measurements in relatively high noise environments for use in hearing evaluations and screening. DPOAE measurements have been shown to be an effective and efficient method for screening infant, children, and adult hearing. Environmental noise, however, has been shown to adversely affect the ability to successfully obtain DPOAE measurements, especially at frequencies below 1500 Hz.  We will achieve our aim by developing a narrow-band, adaptive active noise reduction system that will seamlessly augment existing DPOAE measurement protocols. Our innovation will supplement existing DPOAE measurement systems with both low-cost acoustic hardware and advanced signal processing techniques. By reducing background noise levels in a narrow frequency band near the DPOAE test frequencies, we will enable higher signal-to-noise ratio DPOAE measurement sequences. The increased SNR will result in the ability to obtain DPOAE measurements in relatively high noise environments such as the newborn intensive care unit and nursery, offices of pediatricians, schools without special audiology facilities, field hospitals, and remote or mobile clinics. n/a",Narrow-Band Active Noise Reduction for DPOAE Measurement,6485483,R43DC005112,"['artificial intelligence', ' bioengineering /biomedical engineering', ' biomedical equipment development', ' clinical research', ' computer program /software', ' hearing tests', ' human subject', ' measurement', ' noise', ' otoacoustic emission', ' sound frequency']",NIDCD,"CREARE, INC.",R43,2002,103954,-0.010216675881286334
"Cluster Comparison Methods & the NCI Expression Dataset There is a significant commercial and academic need for new tools that provide quantitative cluster comparison metrics. It is important for pharmaceutical and biotechnology companies to be able to critically evaluate the utility of using different clustering techniques on large high dimensional datasets, in order to make the most informed decisions based upon the clustering results. We propose to evaluate and build bluster comparison metrics, integrating them with high dimensional visualization techniques, so that not only an overall scope, but the cluster distributions can be compared in an intuitive visual fashion. In carrying out our analysis, we will focus on the NCI (approximately 1,400) compound, subset, 118 known mechanism of action compound gene expression dataset analyzed by Scherf, et.al (2000). IN A FOLLOW ON Phase II SBIR Proposal, we will create a robust software package for commercial release where cluster comparison metrics are integrated with the most valuable visualization tools we identify in the Phase I research. PROPOSED COMMERCIAL APPLICATIONS: The Specific Aims of this Phase I proposal will allow us to create new tools where cluster comparison metrics are integrated with high dimensional visualization techniques, so that not only an overall score, but the cluster distributions can be compared in an intuitive visual fashion. We will use the publicly available NCI DIS compound subset, gene expression dataset of Scherf, e.g. al. (2000) to carry out these aims, as ell as data mine this dataset for new discoveries. n/a",Cluster Comparison Methods & the NCI Expression Dataset,6484325,R43CA096179,"['artificial intelligence', ' cancer information system', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' informatics', ' information retrieval', ' mathematics']",NCI,"ANVIL INFORMATICS, INC.",R43,2002,98438,-0.030484367108072112
"Actuarial Generation of Diagnostic Possibilities in Ment  DESCRIPTION (provided by applicant):  The primary goal of this Phase I project is to test the feasibility of a computerized diagnostic tool for collaborative assessment of psychiatric disorders in children and adolescents.  Such a system is sorely needed in both clinical and research settings because (a) structured clinical interviews, although the gold standard in diagnosis, are time consuming and underutilized, and (b) the clinical judgment that is often substituted is of Limited accuracy and subject to several significant biases.  Using the diagnostic rules from the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV), the proposed product will provide clinicians with automated actuarial symptom and diagnostic data thereby circumventing these limitations while assisting the collaborative diagnostic process.  These goals will be accomplished by integrating a reliable and valid symptom checklist filled out by patient informants with an advanced rule-based documentation system that employs an established logic-processing engine and which utilizes the complete DSM-IV rule set.  Based on the presence and severity of discrete symptoms, clinicians will be provided with actuarially derived probability values that indicate the likelihood of specific DSM-IV criteria or disorders.  Additionally, it will facilitate rapid and complete documentation DSM-IV criterion necessary to formally validate or refute diagnoses.  The improved integration of client and clinician information will provide increased diagnostic precision and facilitate collaboration between providers and clients.  In Phase II, the system will be extended to support repeated assessment, direct access via the World Wide Web, and larger sampling to collect further psychometric information.  Phase I objectives include: 1. To produce a highly usable collaborative diagnostic assessment tool that will be used by individual practitioners, small group practices and their clients.  2. To automate the determination of the positive and negative predictive power of informant symptom data for corresponding DSM-IV criterion and diagnoses, and to collect an initial data set to evaluate usability and psychometric properties of the system.  Phase II objectives include: (1) creation of a user interfaces and program logic to support repeated assessment (2) scaling to provide direct access via the World Wide Web and (3) larger sampling to extend the known psychometric properties of the system.  PROPOSED COMMERCIAL APPLICATION: Commercial potential is present in several areas related to psychiatric diagnosis and clinical decision-making: clinical practice, enterprise decision support, training, education, research, medical records, and managed care.   n/a",Actuarial Generation of Diagnostic Possibilities in Ment,6549219,R43MH062266,"['Internet', ' artificial intelligence', ' clinical research', ' computer assisted diagnosis', ' computer human interaction', ' computer system design /evaluation', ' diagnosis design /evaluation', ' human subject', ' mental disorder diagnosis', ' psychometrics']",NIMH,"MEDICINE RULES, INC.",R43,2002,99996,-0.015587850826130373
"System for Cost Effective Clinical Trial Design The long-term objective of this project is to develop software to facilitate the design of cost effective clinical trials. In 1999, the pharmaceutical industry and NIH spent more than $23 billion on clinical trials. Developments in clinical trial design theory, and in optimization algorithms have opened possibilities for more cost- effective designs that can be executed for lower total cost, over shorter periods of time and / or requiring fewer patients. The proposed System for Cost Effective Trials (SCET) will be a software package to guide the trial designer through comparisons of the power, sample size requirements, and cost of alternate trial designs. These methods are under-used throughout medical research, but are particularly applicable to trials with relatively short treatment regimens and rapid ascertainment of endpoints, such as many cancer treatment trials. The aims of SCET Phase II are to build the system, validate it in compliance with FDA regulations for software validation, perform Beta testing at a range of target client organizations, and use the Beta test findings to produce a marketable release. PROPOSED COMMERCIAL APPLICATION: The potential market for this software system includes virtually every pharmaceutical company in the world (multiple licenses to each), every biotech company involved in clinical trials, every contract research organization involved in the design or conduct of clinical trials, coordinating centers of NIH-sponsored multi-center clinical trials, individual university-based investigators who conduct clinical trials, individual biostatistical consultants who design clinical trials, and agricultural businesses and researchers that conduct animal research. n/a",System for Cost Effective Clinical Trial Design,6485420,R44CA088667,"['artificial intelligence', ' clinical trials', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' cost effectiveness', ' drug design /synthesis /production', ' experimental designs']",NCI,"RHO FEDERAL SYSTEMS DIVISION, INC.",R44,2002,380192,-0.013889650456670505
"Optical Detection of Intravenous Infiltration  DESCRIPTION (provided by applicant): About 80% of hospital patients in the United States require IV therapy and 50% of IV lines fail due to infiltration, a clot in the cannula, an inflammatory response of the vein, or separation of the cannula from the vein. IV infiltration is usually accompanied by pain, erythema, and swelling at the cannula tip or the insertion site. Severe infiltration may lead to necrosis requiring skin debridement, skin grafting, or amputation. Early detection of infiltration prevents the occurrence of serious incidents that may require surgical correction. The long-term objective of this project is to develop an infiltration sensor for monitoring IV failures. The Phase II research design includes the development of an advanced prototype, improvement of algorithms, evaluation of the prototype on animal models and human measurements, investigation of its accuracy and utility, and the examination of the commercial potential. The innovation of this project lies in the use of an optical method coupled with the advanced development in fiber optics and algorithms for tissue optics to provide a means for noninvasive monitoring of the IV sites. It will provide routine, automated, continuous, and real-time monitoring capabilities for patients undergoing IV therapy.   n/a",Optical Detection of Intravenous Infiltration,6550261,R44HL062008,"['artificial intelligence', ' blood coagulation', ' clinical research', ' diagnosis design /evaluation', ' fiber optics', ' human subject', ' intravenous administration', ' medical complication', ' necrosis', ' optics', ' patient monitoring device', ' swine', ' technology /technique development']",NHLBI,"CW OPTICS, INC.",R44,2002,250708,-0.031000270351987966
"Foot Pressure and Shear Data Visualization System DESCRIPTION (provided by applicant): Foot ulceration is a diabetic complication that results in over $1 billion worth of medical expenses per year in the United States alone. To better quantify the external forces involved in ulceration, researchers are developing new hardware systems that can measure both shear stress and vertical pressure. As these systems are commercialized, visualization software will be required for display and analysis of the 3-D stresses acting on the plantar surface. The proposed research will develop an advanced foot pressure and shear data visualization system, based on the innovative use of a deformed 2-D wire mesh to indicate stress, combined with more traditional vertical elevations and color-coding to indicate pressure. This new software will be adaptable to a variety of measurement systems, and will allow a clinician to see an accurate, 3-D representation of the maximum pressure and shear locations on the plantar surface. Also, novel analysis algorithms will be developed to identify areas where skin pressure and stress patterns (e.g., bunching, shearing, or stretching) are most likely to cause pathological consequences. Availability of this advanced software, in combination with new pressure/shear hardware measurement systems, will greatly improve the diagnosis, prevention, and treatment of foot ulcers in diabetic patients.  PROPOSED COMMERCIAL APPLICATION: According to the American Diabetes Association, there are approximately 16 million patients in the United States with diabetes, with 800,000 new diagnoses each year.  For these patients, foot complications account for more hospitalizations than any other clinical problem, and plantar ulcerations are a major reason for subsequent foot amputation.   The proposed research will lead to a new commercial software product aimed primarily at the prevention and treatment of diabetic foot ulcers.   In addition, product applications can be extended to the estimated 1 million patients per year who develop pressure ulcer bedsores, as well as to prosthetic limb patients who are at risk of skin breakdown due to peripheral vascular disease. n/a",Foot Pressure and Shear Data Visualization System,6443499,R43DK061164,"['artificial intelligence', ' biomechanics', ' biomedical equipment development', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' decubitus ulcer', ' foot', ' mechanical pressure', ' mechanical stress', ' monitoring device']",NIDDK,"FOSTER-MILLER, INC.",R43,2002,119415,-0.018290191593527155
"Applying Usability to A Knowledge Based System A cancer genetics-tracking database will be redesigned using usability engineering techniques to improve the functionality and usability of the current system. This is important because it will lead to a system that is easier to use and learn, will decrease the chance of errors, and will increase productivity, and user satisfaction. The current state of informatics offers the potential for the creation of tools to assist in the reduction of medical errors. The redesign of this tracking database will be completed through a three-phase process. The first phase will use the results of a usability analysis to redesign and prototype the cancer genetics-tracking database. In the second phase, usability studies will then be conducted to ensure that the system is functional, easy to use, easy to learn, and meets the goals of the users. The usability studies will include heuristic evaluations, keystroke level models, talk-aloud methods, and cognitive walkthrough techniques. The system will be modified based upon the results of these studies. Research will be compiled on the advantages and disadvantages of ICD coding Vs. SNOMED followed by the selection of the most useful system for coding medical information. In the third phase the final redesign will be compared to the old system using a within-subject design to determine if the redesign decreases the error rate, increases productivity, and user satisfaction. This will be followed-up with a survey to determine the perceived usability of the redesigned application. Throughout the redesign process, specific usability guidelines will be developed for designing healthcare software that is computational and knowledge- based in nature.  n/a",Applying Usability to A Knowledge Based System,6538226,F38LM007188,"['artificial intelligence', ' cancer information system', ' cancer registry /resource', ' computer assisted medical decision making', ' computer human interaction', ' computer system design /evaluation', ' family genetics', ' human data', ' neoplasm /cancer genetics']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2002,66954,-0.01474890113792668
"Automated PCR Pathogen Detection and Quantification  DESCRIPTION (provided by applicant):  We will develop software for automated pathogen detection and quantification using data from PCR experiments. Automated pathogen detection using data from a PCR experiment requires software to determine whether DNA from the pathogen is present or absent in a sample. We will develop a pattern-matching algorithm to mathematically analyze PCR amplification data. We will optimize the algorithm against a data set of at least 5000 PCR reactions (including a significant set of data gathered during the anthrax attack) to determine its efficacy and limitations. We expect the pathogen detection algorithms to distinguish positives samples from negative samples in more than 98% of the samples, to find inconclusive results in less than 1% of the samples, and to incorrectly classify less than 1% of the samples. We will also develop software to perform automated melting curve analysis of samples that our detection algorithm has determined to be positive or inconclusive. The melting profile of the probes is a property of the assay, and it can be used for secondary confirmation of a pathogen by comparing the profile of the unknown samples to the profile of the assay's positive controls. We will develop algorithms to automatically determine whether the melting profile of the sample and controls match. With melting analysis confirmation, the failure rate of the final detection algorithm should be less than 0.5%.   Automated pathogen quantification requires software to determine the number of copies of a pathogen's DNA in a sample. We will develop discrete dynamical models of PCR for quantification. We will optimize these methods against a large data set of PCR reactions with dilution series. We will systematically determine the features of the models that provide information and the features that can be ignored. We will measure efficacy by comparing computed DNA copy numbers against the known concentrations (as specified by experimenters), and against each other. We will use the most effective model (or models) in the software we produce.   n/a",Automated PCR Pathogen Detection and Quantification,6555484,R43AI052944,"['artificial intelligence', ' bioterrorism /chemical warfare', ' communicable disease diagnosis', ' computer program /software', ' computer system design /evaluation', ' microorganism', ' nucleic acid denaturation', ' nucleic acid quantitation /detection', ' phase change', ' polymerase chain reaction']",NIAID,IDAHO TECHNOLOGY,R43,2002,100000,-0.019850672653787805
"Diagnostic Logic and Adaptive Assessment for Psychiatry  DESCRIPTION (provided by applicant):  This SBIR Phase I application proposes to extend an existing multi-tier Internet client-server system (""CliniMetricar"") by integrating active diagnostic logic.  CliniMetrica currently provides systematic psychiatric assessment using the World Health Organization (WHO) Schedules for Clinical Assessment in Neuropsychiatry (SCAN, version 2.1). CliniMetrica automatically indexes digital audio recording of assessment interviews, and was developed with SBIR support from NIMH Digital video functions are currently being implemented and tested with additional NIMH support, as are functions to support remote psychometrics for the training and monitoring of interviewers.  The CliniMetrica system is increasing in sophistication and functionality, and has applications for clinical research (e.g., clinical trials) as well as for more routine clinical practice.  The current lack of fully developed and tested diagnostic functionality is a major gap.  A number of potential customers have requested integrated DSM-IV and/or lCD-10 diagnostic results to be automatically linked to assessments.  In order to meet this market need, we propose to implement the DSM-IV and ICD-10 nosologic systems as two classification knowledge bases that a logic engine will process to generate diagnostic results.  These logical functions are difficult to implement and manipulate with procedural languages (e. g. C + +). so the use of a logic engine provides significant technical benefits.  This diagnostic logic version of CliniMetrica is referred to as ""CliniMetrica-Dx.""  To assist raters in thorough examination and to support adaptive assessment, a user interface coupled to logic processing modules will allow tracking the diagnostic status of a subject (the sets of true, false, partially true, or partially false DSM-IV and lCD-10 diagnoses during assessment.  The logic engine will dynamically generate assessment item subsets (currently from the SCAN) needed to rule-in or rule-out DSM-IV and lCD-10 diagnoses. During the assessment, presentation of these symptom sets to the assessor can further guide the interview. By narrowing the ""search space,"" the efficiency of assessments will be increased. By formalizing the search, reliability and validity can be enhanced In addition, to provide support for nosologic research and development, in Phase II the system will include mappings between DSM-IV and lCD-10, and between current and future versions of the DSM and lCD.  The CliniMetrica-Dx system as an application framework will generalize to other clinical psychiatric assessment instruments such as the SCID, to adaptive self-report systems, and to other medical specialties.  It also will have applications for education and training.   n/a",Diagnostic Logic and Adaptive Assessment for Psychiatry,6549963,R43MH066434,"['Internet', ' artificial intelligence', ' clinical research', ' computer assisted diagnosis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' disease /disorder classification', ' human subject', ' indexing', ' mental disorder diagnosis', ' psychometrics']",NIMH,"MEDICAL DECISION LOGIC, INC.",R43,2002,94169,-0.005573410937410924
"Genomic application of suspension array technology DESCRIPTION (provided by applicant): The principle of the proposed project is the application of fluorescent microsphere based suspension array technology (SAT) to the cytometry based simultaneous detection of multi analytes. The proposal consists of four overlapping subprojects: (a) Technological development of biological microbead procedures using cells or microorganisms as substitutes for polymeric microspheres to lower the cost of SAT compared to the cost of methods using microbeads manufactured by polymer chemistry. (b) Development of a test to detect gene translocations and rearragements frequently responsible for malignant transformations. A method based on measuring bead-based hybridization of specific 5' and 3' nucleotide sequences in the vicinity of chromosomal translocation breakpoints would allow large scale screening of leukemias and various types of cancers by the measurement of 5'/3' sequence ratio. (c) Development of a DNA binding protein profiling assay providing easy, reproducible and high throughput technology to determine the expression pattern of transcription factors (TFs) binding to single stranded hexamere oligonucleotide sequences anchored to the solid phase surface of microspheres. This subproject is at the R&D level and needs to be thoroughly tested. (d) Development of artificial neural network software applications to analyze and classify the ""fingerprint patterns"" produced by the SAT measurements in subprojects (b) and (c). One of the most important goals of the work in Phase I will be to select the approach worth focusing on in Phase II. n/a",Genomic application of suspension array technology,6483937,R43CA096379,"['DNA binding protein', ' artificial intelligence', ' bacteria', ' chromosome translocation', ' flow cytometry', ' functional /structural genomics', ' gene rearrangement', ' genetic recombination', ' genome', ' high throughput technology', ' microarray technology', ' oligonucleotides', ' polymers', ' technology /technique development', ' tissue /cell culture', ' transcription factor']",NCI,"SOFT FLOW, INC.",R43,2002,100000,-0.033639765704488477
"Advaced Cross-Correlator Development of a general purpose ultrasound cross-correlator module that is proposed for a) blood flow estimation in one, two and three dimensions b) blood flow estimation in an overlapped mode for use in high frequency small vessels c) coded excitation deconvolution d) A-Mode tissue characteristic correlation quantification The module would be capable of accepting Digitized RF data at rates up to 4o million 12 bit samples per second from a beamformer and returning the Sum of the Products (SOP) of multiple selectable ranges of up to 48 samples with a theoretical accuracy of 1/128th of a sample in the range dimension and a dynamic range of 36 bits in the intensity dimension at the rate of the input data. Multiple results based upon the SOP would also be output. The chosen algorithms would be loaded through a Firewire interface to a personal computer (PC) in a sub second rates. The correlator modules would output its results again through the Firewire interface into the PC for further image optimization and viewing. Initially the module would be tested with the company's Beamformer but efforts would be made to offer a universal interface so researchers could utilize the computing power of the correlator on other instruments. It is also intended to make available the parameters of the algorithms for researchers to use this tool for further developments. PROPOSED COMMERCIAL APPLICATIONS: This proposed tool would be applicable in the research then clinical evaluation of true three-dimensional real time blood flow in the major vessels of the body down to the capillary vessels and in tissue flow as in angiogenesis. The correlator potentially will be used in improving he dynamic range, and quality of ultrasonic imaging. A possible application to be investigated is the correlators potential for recognizing tissue characteristics in real time. n/a",Advaced Cross-Correlator,6479214,R43CA096018,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer human interaction', ' computer network', ' computer program /software', ' computer system design /evaluation', ' computer system hardware', ' digital imaging', ' phantom model', ' radiowave radiation', ' ultrasound blood flow measurement']",NCI,WINPROBE CORPORATION,R43,2002,127797,-0.011880329892400742
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6519073,R37GM030998,"['DNA', ' artificial intelligence', ' biochemical evolution', ' computational neuroscience', ' computer assisted sequence analysis', ' computer simulation', ' gene frequency', ' genetic models', ' mathematical model', ' method development', ' model design /development', ' natural selections', ' nucleic acid sequence', ' species difference', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2002,161792,-0.03200257674086958
"Smart Power Assistance Module for Manual Wheelchairs    DESCRIPTION (provided by applicant): We propose to use power assistance as the basis for a Smart Power Assistance Module (SPAM) that provides independent power assistance to the right and left rear wheels of a manual wheelchair. The SPAM will detect obstacles near the wheelchair, and modify the forces applied to each wheel to avoid obstacles.  For individuals with visual impairments that are unable to walk with a long cane or walker, the SPAM will provide safe travel by assisting the user to avoid obstacles. This research will build on the investigative team's previous experience with power assistance for manual wheelchairs and obstacle avoidance for power wheelchairs and rollators. Extensive outside evaluation of the SPAM will be provided throughout the course of the project by clinicians active in wheelchair seating and mobility.         n/a",Smart Power Assistance Module for Manual Wheelchairs,6581049,R43EY014490,"['artificial intelligence', ' assistive device /technology', ' biomedical device power system', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' field study', ' human subject', ' medical rehabilitation related tag', ' vision aid', ' vision disorders']",NEI,AT SCIENCES,R43,2002,249727,-0.003627129755739604
"Automated Quantitation of 3D Echocardiograms In Phase I we developed a method for automated border detection (ABD) of echocardiographic scans that is feasible for clinical application. The accuracy of our processes provides exceeds Phase I goals and is comparable to interobserver variability in measuring volume and ejection fraction, and in border location. For a diverse set of patients, we have achieved an accuracy of 10 ml for endocardial volume, 4% for ejection fraction, and ,2.0 mm for border position. Our processes operates in 4 min. In Phase II we propose to continue research and development to move our ABD technology closer to clinical user. Our first specific aim is to reduce the amount of manual input required even further. Our second aim is to develop a prototype system suitable for clinical evaluation. Our third aim is to perform a pilot trial to evaluate the performance of our ABD process, as a preparation for a more formal, multi-center clinical trial planned for Phase III. The proposed research is important because quantitative 3D echo provides greater accuracy and reproducibility and more comprehensive information on cardiac status than currently available imaging techniques. The significant advantages of 3D echo are not currently available for clinical practice because it is impractical without automation. PROPOSED COMMERCIAL APPLICATIONS: Automation of echocardiogram border detection enables physicians to obtain accurate, reproducible and comprehensive measurements of the heart's size, shape and function. This technology can be included in ultrasound systems or provided in workstations. The core technology can be applied to other organs and other imaging modalities. n/a",Automated Quantitation of 3D Echocardiograms,6443269,R44HL059054,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' echocardiography', ' heart disorder diagnosis', ' heart ventricle', ' human subject', ' image processing', ' papillary muscles', ' pericardium']",NHLBI,"QUANTIGRAPHICS, INC.",R44,2002,255191,-0.02449168749835427
"Digital Elevation Models for Population Estimates Research exploring the feasibility of deriving population estimates from remotely sensed data demonstrates that objects in the urban landscape can be identified and incorporated into a population estimates system based on the housing unit method. Nonetheless, this research also reveals shortcomings in the technology producing the input files used in the automatic detection of objects. The problem involves the assumption and techniques used when converting high resolution images into digital elevation models (DEM). DEM files serve as input to the programs used in the detection of housing units. Efforts to correctly identify housing units are time-consuming and error-prone without clear and distinct DEMs. The objectives of this Phase I SBIR application are to further refine strengthen and test the software employed in transforming satellite and aerial imagery into digital elevation model (DEMs). DEM files serve as input to the programs used in the detection of housing units. Efforts to correctly identify housing units are time-consuming and error-prone without clear and distinct DEMs. The objectives of this Phase I SBIR application are to further refine, strengthen and test the software employed in transforming satellite and aerial imagery into digital elevation models. Specific goals of this Phase I proposal include: 1) modifying and coding new assumptions into the DEM software, 2) testing the accuracy and reliability of the digital elevation code on new sub1, aerial imagery, and 3) designing a new GUI for use in the pre- processing phase of DEM building. PROPOSED COMMERCIAL APPLICATIONS: The commercial value of this specific research is best understood when viewed as part of a larger effort to produce an automated system for deriving population estimates of user defined areas based on current, remotely sensed data. Such a system will serve a wide range of commercial interests seeking ""up-to-the-minute"" counts and measures of population and housing change. n/a",Digital Elevation Models for Population Estimates,6443114,R43HD041774,"['altitude', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' environment', ' geographic site', ' human population distribution', ' mathematical model', ' population survey', ' urban area']",NICHD,"SENECIO SOFTWARE, INC.",R43,2002,99979,-0.009085976754841242
"AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION Quantification of Minimal Residual Disease (MRD) is a general concern in oncology since this parameter is likely to give valuable information to clinicians to customize chemotherapeutic treatments and to anticipate possible relapses. An automated system will be developed for the quantification of MRD by using real-time PCR to quantify cancer cells in a background of non pathologic DNA. The system will be derived from an existing high-throughput sample handling system (developed by Meldrum and team) named Acapella. Acapella has a pipelined serial architecture which makes it possible to develop an adaptive PCR control algorithm ensuring a level of sensitivity and accuracy for the quantification results specified by the clinician. In the R21 phase of the project, a critical component of the system is the real-time thermocycler. It will provide DNA quantification results of greater precision than what is currently possible with commercial instruments such as the ABI PRISM 7700 Sequence Detector by taking advantage of a high performance custom fluorescence analyzer and sophisticated data analysis methods. The fluorescence analyzer will have a signal to noise ratio and a dynamic range of at least one order of magnitude larger than the optics used on commercial systems. This unique feature will permit precise measurements of the amplification kinetics during at least five cycles in the exponential phase of the reaction. The amplification yield will he derived from these data using statistical estimators customized to meet the requirements of real-time PCR data analysis. The sample DNA content will be derived from the amplification yield and the calibrated fluorescence measurements of the reaction kinetics. This new approach will make it possible to run series of real-time PCRs with more flexibility than would be possible if the assay was based on standard reactions required to have the same amplification yield as the clinical samples. PCR conditions will be adapted online without concerns about possible differences of amplification rate. The assay control algorithm will adapt the reaction DNA content, the primer selection, and the number of PCRs to meet the clinician requirements for particular patient DNA. During the R21 phase of the project a prototype of the real-time thermocycler will be developed to demonstrate the optic performance and the possibility to estimate the PCR amplification rates with 5% accuracy. A conceptual design of the fully integrated process from patient blood sample to MRD quantification data will be completed to allow assessment of expected performance, cost, and risks associated with the development of the fully engineered system. The development of the various hardware and software components along with their integration into the automated system will take place during the R33 phase of the project. Performance of the system will he evaluated on real biological samples provided by the UW Department of Laboratory Medicine. Results returned by the system will he compared with results of t(14; 18) PCR performed in this department with an ABI PRISM 7700 for the diagnosis of patients suffering from follicular lymphomas.  n/a",AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION,6514339,R33CA084691,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosome translocation', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence', ' high throughput technology', ' human tissue', ' minimal residual disease', ' neoplasm /cancer diagnosis', "" nonHodgkin's lymphoma"", ' nucleic acid quantitation /detection', ' polymerase chain reaction']",NCI,UNIVERSITY OF WASHINGTON,R33,2002,582434,0.0011818646275180906
"STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES   DESCRIPTION (Adapted from the Applicant's Abstract): This proposed project has       three primary objectives. Objective 1 is to develop improved strategies for          fitting more accurate classification and regression tree (i.e., CART) models.        Objective 2 is to develop a formal framework to allow statistical inference on       tree models. Objective 3 is to develop and distribute public-domain software         that will allow applied data analysts to implement the methods we develop in         the first two objectives. To meet these objectives we will integrate                 statistical and computational machine learning approaches. We believe our work       can have a significant impact in biomedical data analysis by combining the           strengths of statistics for developing objective criteria for model selection        and for providing a framework for assessing and quantifying uncertainty              associated with a model, with the strengths of machine learning for fitting          models to large and complex datasets.                                                                                                                                     n/a",STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES,6520234,R01GM061218,"['classification', ' computer assisted medical decision making', ' computer program /software', ' computer simulation', ' experimental designs', ' human data', ' information system analysis', ' mathematical model', ' model design /development', ' statistics /biometry']",NIGMS,BARNES-JEWISH HOSPITAL,R01,2002,163400,-0.0024663670156867263
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6516567,U01DE013331,"['biomarker', ' biopsy', ' clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' enzyme linked immunosorbent assay', ' facial muscles', ' gas chromatography mass spectrometry', ' human subject', ' inflammation', ' interview', ' magnetic resonance imaging', ' mastication', ' musculoskeletal disorder diagnosis', ' oral facial pain', ' pain threshold', ' psychobiology', ' questionnaires', ' radioimmunoassay', ' sign /symptom', ' statistics /biometry', ' synovial fluid', ' temporomandibular joint syndrome', ' tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2002,1325497,-0.004104888382968509
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6518379,P30EY006883,"['biomedical facility', ' health science research', ' vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2002,559831,-0.00960418978305694
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6525584,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2002,128860,-0.011693569141545516
ARTIFICIAL INTELLIGENCE METHODS FOR CRYSTALIZATION No abstract available n/a,ARTIFICIAL INTELLIGENCE METHODS FOR CRYSTALIZATION,6394754,R01RR014477,"['X ray crystallography', ' artificial intelligence', ' chemical structure', ' computer system design /evaluation', ' crystallization', ' method development']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2001,232402,0.004654196315320112
"Development of Ultrasonic Apparatus for Dental Diagnosis   DESCRIPTION: Ultrasonic diagnostic apparatus has been proposed (Phases 1 and 2)      for Dental applications in determining tooth pathologies such as                     demineralization, caries, fractures, abscesses, and tooth wear. The equipment        adopts piezoelectric and optic hybrid transduction system for interrogation on       teeth. Ultrasonic responses of the tooth structure will then be analyzed by a        pattern recognition expert system (artificial intelligence) to determine the         diagnosis of the tooth inspected. The proposed research will eventually help to      reduce the use of harmful X-ray radiation in Dental clinic and also contribute       to artificial intelligence based diagnosis. In the Phase 1 research, tooth           specimens will be collected from local Dental clinics; demonstration                 instrumentation will be constructed; ultrasonic testing will be conducted on         the tooth specimens in vitro; and finally, the test data will be analyzed to         show the potential for Dental pathology identification. The feasibility of the       proposed research concept will be demonstrated, if: 1) meaningful ultrasonic         tests can be conducted using the simple piezo-/opto-ultrasonic system on the         tooth specimens collected; 2) various Dental pathologies in the tooth specimens      may be characterized by using wave pattern of the ultrasonic responses; and 3)       by identifying particular features of an ultrasonic wave pattern, the actual         tooth pathology may be recognized.                                                   PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                          n/a",Development of Ultrasonic Apparatus for Dental Diagnosis,6402448,R43DE014270,"['artificial intelligence', ' biomedical equipment development', ' dental disorder diagnosis', ' dental structure', ' dentistry', ' diagnosis design /evaluation', ' tooth', ' tooth surface']",NIDCR,AAC INTERNATIONAL,R43,2001,100000,-0.0006924200290771655
FOUNDATION MODEL OF ANATOMY No abstract available n/a,FOUNDATION MODEL OF ANATOMY,6391279,R01LM006822,"['anatomy', ' artificial intelligence', ' biological models', ' computer simulation', ' human data', ' information systems', ' model design /development', ' physical model']",NLM,UNIVERSITY OF WASHINGTON,R01,2001,430609,-0.0015567561719376476
"Markov Chain Monte Carlo and Exact Logistic Regression   DESCRIPTION (provided by applicant): Logistic regression is a very popular           model for the analysis of binary data with widespread applicability in the           physical, behavioral and biomedical sciences. Parameter inference for this           model is usually based on maximizing the unconditional likelihood function.          However unconditional maximum likelihood inference can produce inconsistent          point estimates, inaccurate p-values and inaccurate confidence intervals for         small or unbalanced data sets and for data sets with a large number of               parameters relative to the number of observations. Sometimes the method fails        entirely as no estimates can be found that maximize the unconditional                likelihood function. A methodologically sound alternative approach that has          none of the aforementioned drawbacks is the exact conditional approach in which      one generates the permutation distributions of the sufficient statistics for         the parameters of interest conditional on fixing the sufficient statistics of        the remaining nuisance parameters at their observed values. The major stumbling      block to this approach is the heavy computational burden it imposes. Monte           Carlo methods attempt to overcome this problem by sampling from the reference        set of possible permutations instead of enumerating them all. Two competing          Monte Carlo methods are network based sampling and Markov Chain Monte Carlo          (MCMC) sampling. Network sampling suffers from memory limitations while MCMC         sampling can produce incorrect results if the Markov chain is not ergodic or if      the process is not in the steady state. We propose a novel approach which            combines the network and MCMC sampling, draws upon the strengths of each of          them and overcomes their individual limitations. We propose to implement this        hybrid network-MCMC method in our LogXact software and as an external procedure      in the SAS system.                                                                   PROPOSED COMMERCIAL APPLICATION:  There is great demand for logistic regression software that can handle small, sparse or  unbalanced data sets by exact methods.  Our LogXact package is the only software that  can provide exact inference for data sets which are not ""toy problems"".  Yet even  LogXact quickly breaks down on moderate sized problems.  The new generation of hybrid  network-MCMC algorithms will handle substantially larger problems that nevertheless need  exact inference.  The commercial potential is considerable since such data sets are common  in scientific studies.                                                                                      n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6404971,R43CA093112,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' mathematics', ' statistics /biometry']",NCI,CYTEL SOFTWARE CORPORATION,R43,2001,113111,-0.01010396549466888
VOICE RESPONSE/INTERNET REGISTRATION & RANDOMIZATION No abstract available n/a,VOICE RESPONSE/INTERNET REGISTRATION & RANDOMIZATION,6310317,R44RR014168,"['Internet', ' artificial intelligence', ' clinical trials', ' computer program /software', ' computer system design /evaluation', ' interactive multimedia', ' patient /disease registry', ' statistics /biometry', ' telecommunications']",NCRR,"RHO FEDERAL SYSTEMS DIVISION, INC.",R44,2001,382311,-0.007693349885409842
"Simulation Algorithms for Spatial Pattern Recognition   DESCRIPTION (provided by applicant): A new generation of satellites is imaging       the earth's surface with unprecedented spatial and spectral resolution. With         the ability to identify local features related to environmental exposures, this      high-resolution imagery is gong to revolutionize health risk assessment. The         realization of this potential depends critically on our ability to recognize         spatial patterns on these large images. This project will develop fast spatial       null models for use in statistical pattern recognition, and will accomplish 4        aims.                                                                                                                                                                     (1) Implement fast simulation algorithms conditioned on properties of the data,      and on spatial functions;                                                            (2) Assess project feasibility by evaluating the performance of these                algorithms on existing high-resolution, hyperspectral imagery;                       (3) Implement the simulation algorithms in 2 commercial spatial analysis             software packages;                                                                   (4) Apply the software and methods to demonstrate the approach and unique            benefits for risk assessment.                                                                                                                                             The phase 1 research will address the first two aims; aims three and four will       be accomplished in phase 2 once feasibility is demonstrated. The technologic         and scientific innovations from this project are expected to greatly enhance         our ability to extract knowledge from high resolution imagery.                       PROPOSED COMMERCIAL APPLICATION:  The imminent launch of over a dozen satellites capable of high-resolution imagery is giving  health researchers powerful new data for relating environmental features to health   outcomes, but existing software packages cannot undertake spatial analysis of these  extraordinarly large data sets.   The fast simulation algorithms from this research will  be incorporated into 2 commercial software packages, providing advanced spatial  analysis for large imagery.                                                                                     n/a",Simulation Algorithms for Spatial Pattern Recognition,6401389,R43CA092807,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data management', ' image processing', ' imaging /visualization /scanning', ' statistics /biometry']",NCI,BIOMEDWARE,R43,2001,170490,-0.0058988700325194425
"Advanced Vision Intervention Algorithm(AVIA)   Description (from the investigator's abstract): The objective of this                application is to implement an iterative, nine-step advanced vision                  intervention algorithm (AVIA) in software to optimize the predictability of          virtually any current or anticipated customized human vision intervention            method. The software program will use the investigator's Visual Optics class         library, as well as new software for the ray transfer element, database              analysis routines, and the ray tracing surface optimization algorithm. The           program will allow, but not require, exam data from commercially available           ophthalmic instruments such as corneal topography and wavefront aberration for       input in the optical modeling of an individual's eye. This algorithm is, to the      investigator's knowledge, the only formal framework designed specifically to         optimize the predictability of surgical and non-surgical correction methods. It      is not only a technological innovation in its own right, it also makes the most      of the current and future vision correction methods to which it is applied.          PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",Advanced Vision Intervention Algorithm(AVIA),6403968,R43EY013666,"['artificial intelligence', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' eye surgery', ' laser therapy', ' ophthalmoscopy', ' statistics /biometry', ' vision disorders']",NEI,"SARVER AND ASSOCIATES, INC.",R43,2001,99785,6.589681431510362e-05
"Applying Usability to A Knowledge Based System A cancer genetics-tracking database will be redesigned using usability engineering techniques to improve the functionality and usability of the current system. This is important because it will lead to a system that is easier to use and learn, will decrease the chance of errors, and will increase productivity, and user satisfaction. The current state of informatics offers the potential for the creation of tools to assist in the reduction of medical errors. The redesign of this tracking database will be completed through a three-phase process. The first phase will use the results of a usability analysis to redesign and prototype the cancer genetics-tracking database. In the second phase, usability studies will then be conducted to ensure that the system is functional, easy to use, easy to learn, and meets the goals of the users. The usability studies will include heuristic evaluations, keystroke level models, talk-aloud methods, and cognitive walkthrough techniques. The system will be modified based upon the results of these studies. Research will be compiled on the advantages and disadvantages of ICD coding Vs. SNOMED followed by the selection of the most useful system for coding medical information. In the third phase the final redesign will be compared to the old system using a within-subject design to determine if the redesign decreases the error rate, increases productivity, and user satisfaction. This will be followed-up with a survey to determine the perceived usability of the redesigned application. Throughout the redesign process, specific usability guidelines will be developed for designing healthcare software that is computational and knowledge- based in nature.  n/a",Applying Usability to A Knowledge Based System,6340157,F38LM007188,"['artificial intelligence', ' cancer information system', ' cancer registry /resource', ' computer assisted medical decision making', ' computer human interaction', ' computer system design /evaluation', ' family genetics', ' human data', ' neoplasm /cancer genetics']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2001,68753,-0.01474890113792668
"Neural Network System for Detection of EEG Microsleeps   DESCRIPTION (Verbatim from the Applicant's Abstract): A software system based        on Artificial Neuro-fuzzy hybrid technology will be developed for automatic          detection of microsleep events from EEG data. The software system will be            designed for used as a model-free and rule-free classification tool that             achieves generalization power through learning from examples.   The development of the software system will require a Graphical User Interface       for data example selection, frequency-analytic preprocessing of EEG raw data,        feature extraction for microsleep characterization, design and training of           neural networks for single EEG channels, and a fuzzy system for contextual           combination of network response for multiple EEG channels to a single system         response.                                                                                                                       The training and testing of the neural networks will be based on a database of       visually scored examples of microsleep and non-microsleep events from                electrophysiological data, which will be randomly divided into training,             validation and test sets.                                                                                 The performnance of the software system will be evaluated based on the               false-positive and false-negative rate for the microsleep detection using data       examples unknown to the system. The agreement rate between the combined network      response and results from visual and conventional automatic scoring will be          used as additional evaluation parameter.        PROPOSED COMMERCIAL APPLICATION: The software system will be an attractive tool for researchers, medical and technical  personal, industrial engineers. It enables the user to quantify alertness/sleepiness  in studies on sleep disorders, shiftwork, drug effects and fatigue countermeasures.  It will help reduce time-consuming visual scoring by human experts. In addition, it  will widen our knowledge about the rapid transition events (microsleeps) between  wake and sleep and can contribute to the development of alertness monitor systems.                                                                                                                                                                                                                                                                                                      n/a",Neural Network System for Detection of EEG Microsleeps,6338195,R43NS039711,"['artificial intelligence', ' biomedical automation', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' electroencephalography', ' electrophysiology', ' human data', ' neural information processing', ' sleep']",NINDS,"CIRCADIAN TECHNOLOGIES, INC.",R43,2001,93457,-0.059261513535334064
"Inference in Regression Models with Missing Covariates DESCRIPTION:  (Adapted from investigator's abstract) This project will examine new methodology for making inference about the regression parameters in the presence of missing covariate data for two commonly used classes of regression models.  In particular, we examine the class of generalized linear models for general types of response data and the Cox model for survival data.  The methodology addresses problems occurring frequently in clinical investigations for chronic disease, including cancer and AIDS.  The specific objectives of the project are to:  1) develop and study classical and Bayesian methods of inference for the class of generalized linear models (GLM's) in the presence of missing covariate data.  In particular, we will  i) examine methods for estimating the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanism is ignorable.  Also, parametric models for the covariate distribution will be examined.  The methods of estimation will focus on the Monte Carlo version of the EM algorithm (Wei and Tanner, 1990) and other related iterative algorithms.  The Gibbs sampler (Gelfand and Smith, 1990) along with the adaptive rejection algorithm of Gilks and Wild (1992) will be used to sample from the conditional distribution of the missing covariates given the observed data.  ii) examine estimating the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanism is nonignorable.  Models for the missing data mechanism will be studied.  iii) develop and study Bayesian methods of inference in the presence of missing covariate data when the missing covariates are either categorical or continuous and the missing data mechanism is ignorable.  Parametric prior distributions for the regression coefficients are proposed.  Properties of the posterior distributions of the regression coefficients will be studied.  The methodology will be implemented using Markov Chain Monte Carlo methods similar to those of Tanner and Wong (1987). iv) investigate Bayesian methods when the covariates are either categorical or continuous and the missing data mechanism is nonignorable.  Multinomial models for the missing data mechanism will be studied.  Dirichlet prior distributions for the multinomial parameters will be investigated.  2) develop and study classical and Bayesian methods of inference for the Cox model for survival outcomes in the presence of missing covariates.  Specifically, we will  i) develop and study estimation methods for the Cox model for survival outcomes in the presence of missing covariates. Methods for estimating the regression parameters when the missing covariates are either categorical or continuous will be studied.  The methods of estimation will focus on an EM type algorithm similar to that of Wei and Tanner (1990).  ii) study estimation of the regression parameters when the missing covariates are either categorical or continuous and the missing data mechanisms nonignorable.  Models for the missing data mechanism will be studied.  Bayesian methods similar to those of 1-iii) and -iv) will be investigated. Computational techniques using the Monte Carlo methods described in 1-iii) will be implemented.  n/a",Inference in Regression Models with Missing Covariates,6326240,R01CA074015,"['artificial intelligence', ' computer data analysis', ' data collection methodology /evaluation', ' human data', ' mathematical model', ' method development', ' model design /development', ' statistics /biometry']",NCI,DANA-FARBER CANCER INSTITUTE,R01,2001,183883,-0.003246908197921233
"A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER   Skin cancer is the fastest growing cancer. Approximately 34,100         Americans developed cutaneous melanoma in 1995; of the survivors, many must          contend with the ongoing trauma of disfigurement and fear. Skin biopsies are         now the most frequently performed medical procedure. It is axiomatic among           dermatologists that early detection and diagnosis are critical. Great strides        have been made in early detection of suspect skin lesions; however failure to        biopsy the right lesion has severe consequences. The dilemma is exacerbated          since 50- 80 percent of biopsies prove unnecessary, contributing to an enormous      waste of health care dollars, patient trauma and negative patient behavior           feedback. The Phase I work in dermatological spectroscopy and artificial neural      net technology suggest that an automated clinical diagnostic aid which produces      a quantitative rather than qualitative diagnostic assessment of skin lesions is      possible. This project proposes development and testing of such a product.           During Phase II a large number of spectroscopic samples of melanoma and nevi         will be used to complete development of an artificial neural net classifier.         Such a classifier system will lead to a commercial product to discriminate           ""normal,"" pre-cancerous and cancerous skin lesions.                                   PROPOSED COMMERCIAL APPLICATION:  The proposed project will lead to a non-invasive, in-office, real-time test to provide an  automated, repeatable diagnostic probability of the nature of skin lesions prior to biopsy.  Skin biopsies are now the most frequently performed reimbursed Medicare procedure,   and as many as 50-80% are found not to be necessary after the fact.  The low cost of   this test, and rapid amortization of the system, coupled with the enormous health care   cost savings possible in conjunction with a significant and widely recognized health   problem, suggest that this product could have great commercial potential.  n/a",A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER,6376769,R44CA078006,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence spectrometry', ' histology', ' human subject', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' reflection spectrometry', ' skin neoplasms', ' spectrometry']",NCI,"WESTERN RESEARCH COMPANY, INC.",R44,2001,359255,-0.027077912517951733
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6385455,R37GM030998,"['DNA', ' artificial intelligence', ' biochemical evolution', ' computational neuroscience', ' computer assisted sequence analysis', ' computer simulation', ' gene frequency', ' genetic models', ' mathematical model', ' method development', ' model design /development', ' natural selections', ' nucleic acid sequence', ' species difference', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2001,161792,-0.03200257674086958
"AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION Quantification of Minimal Residual Disease (MRD) is a general concern in oncology since this parameter is likely to give valuable information to clinicians to customize chemotherapeutic treatments and to anticipate possible relapses. An automated system will be developed for the quantification of MRD by using real-time PCR to quantify cancer cells in a background of non pathologic DNA. The system will be derived from an existing high-throughput sample handling system (developed by Meldrum and team) named Acapella. Acapella has a pipelined serial architecture which makes it possible to develop an adaptive PCR control algorithm ensuring a level of sensitivity and accuracy for the quantification results specified by the clinician. In the R21 phase of the project, a critical component of the system is the real-time thermocycler. It will provide DNA quantification results of greater precision than what is currently possible with commercial instruments such as the ABI PRISM 7700 Sequence Detector by taking advantage of a high performance custom fluorescence analyzer and sophisticated data analysis methods. The fluorescence analyzer will have a signal to noise ratio and a dynamic range of at least one order of magnitude larger than the optics used on commercial systems. This unique feature will permit precise measurements of the amplification kinetics during at least five cycles in the exponential phase of the reaction. The amplification yield will he derived from these data using statistical estimators customized to meet the requirements of real-time PCR data analysis. The sample DNA content will be derived from the amplification yield and the calibrated fluorescence measurements of the reaction kinetics. This new approach will make it possible to run series of real-time PCRs with more flexibility than would be possible if the assay was based on standard reactions required to have the same amplification yield as the clinical samples. PCR conditions will be adapted online without concerns about possible differences of amplification rate. The assay control algorithm will adapt the reaction DNA content, the primer selection, and the number of PCRs to meet the clinician requirements for particular patient DNA. During the R21 phase of the project a prototype of the real-time thermocycler will be developed to demonstrate the optic performance and the possibility to estimate the PCR amplification rates with 5% accuracy. A conceptual design of the fully integrated process from patient blood sample to MRD quantification data will be completed to allow assessment of expected performance, cost, and risks associated with the development of the fully engineered system. The development of the various hardware and software components along with their integration into the automated system will take place during the R33 phase of the project. Performance of the system will he evaluated on real biological samples provided by the UW Department of Laboratory Medicine. Results returned by the system will he compared with results of t(14; 18) PCR performed in this department with an ABI PRISM 7700 for the diagnosis of patients suffering from follicular lymphomas.  n/a",AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION,6467733,R33CA084691,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosome translocation', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence', ' high throughput technology', ' human tissue', ' minimal residual disease', ' neoplasm /cancer diagnosis', "" nonHodgkin's lymphoma"", ' nucleic acid quantitation /detection', ' polymerase chain reaction']",NCI,UNIVERSITY OF WASHINGTON,R33,2001,607570,0.0011818646275180906
"MULTICHANNEL EEG DATA COMPRESSION Recently, recording high-resolution Electroencephalograms (EEGs) from            a large number of electrodes has become a clear trend in both brain              research and clinical diagnosis.  However, the current EEG data                  acquisition systems store the collected data in a form that has never            changed since digital EEG emerged about 30 years ago.  As a result, the          size of the output data file increases enormously as the number of               recording channels increases, causing various problems including high            costs in data analysis, database management, archiving, and transmission         through the internet.                                                                                                                                             This proposal seeks to solve this problem through fundamental research           on data compression specifically for EEG data, but applicable to other           physiological data as well.  Our key approach is based on the                    application of advanced mathematical and signal processing technologies          to this critical problem.  We will develop and optimize a variable               sampling technique which eliminates redundant data samples using spline          interpolation and wavelet transformation.  We will also investigate              lossless data compression algorithms that possess two important                  features: 1) any part of the data within the compressed file can be read         without having to decompress the entire file, and 2) the compressed data         can be transmitted and presented in coarse or fine resolutions as                needed.  We expect that, using both variable sampling and lossless               compression, the EEG file size can be reduced by approximately 70                percent.                                                                          n/a",MULTICHANNEL EEG DATA COMPRESSION,6363936,R01NS038494,"['Internet', ' artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' clinical biomedical equipment', ' clinical research', ' computer data analysis', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' digital imaging', ' electroencephalography', ' human data', ' human subject', ' informatics', ' technology /technique development']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2001,177776,-0.013828735236806711
BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN       n/a,BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN,6351629,R29LM006233,"['artificial intelligence', ' automated medical record system', ' behavioral /social science research tag', ' belief', ' computer assisted medical decision making', ' computer assisted patient care', ' computer system design /evaluation', ' health care facility information system', ' health services research tag', ' human data', ' patient care management']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R29,2001,106893,-0.015519063695995141
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,6384434,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2001,259731,0.00020809561227725482
"PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS DESCRIPTION (Taken from application abstract):  Over the last decade             computational modeling has become central to neurobiology.  While much of        this work has focused on cellular and sub-cellular processes, the last few       years have seen increasing interest in systems level models and in               integrative accounts that span data from the subcellular to behavioral           levels.  Our proposal, in summary, is to extend existing work in parallel        discrete event simulation (PDES) and integrate it with existing work on          compartmental modeling environments, to produce a software environment which     has comprehensive support for modeling large scale, highly structured            networks of biophysically realistic cells; and which can efficiently exploit     the full range of parallel platforms, including the largest parallel             supercomputers, for simulation of these network models, which integrate          information about the nervous system from sub-cellular to the whole-brain        level.  Because of the scale of the models needed at this level of               integration, advanced parallel computing is required.  The critical              technical insight upon which this work rests is that neuronal modeling at        the systems level can often be reduced to a form of discrete event               simulation in which single cells are node functions and voltage spikes are       events.                                                                                                                                                           Three neuroscience modeling projects, will mold, test, and utilize these new     capabilities in investigations of system-level models of the nervous system      which integrate behavioral, anatomical and physiological data on a scale         that exceeds current simulation capabilities.  In collaboration with             computer scientists at Pittsburgh Supercomputing Center and UCLA,                neuroscientists at University of Virginia, the Born-Bunge Foundation,            Antwerp, and the Salk Institute, and developers of the NEURON and GENESIS        packages, these tools will be developed and made available to the                neuroscience community.  The software development aims include 1)                investigation of a portable, PDES system capable of running efficiently on       diverse parallel platforms, 2) development of interfaces to the PDES for         NEURON and GENESIS allowing models developed in those packages to be scaled      up, 3) investigation of a network specification language for neuronal            models, and associated a visualization interface, to facilitate                  investigation of systems-level models, 4) sufficiently robust and                well-documented software for download and installation at other sites.  The      three neuroscience projects will guide development of the software tools and     use the tools for investigation of large-scale models of cerebellum,             hippocampus and thalamocortical circuits.                                         n/a",PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS,6392266,R01MH057358,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biotechnology', ' cerebellar cortex', ' computational neuroscience', ' computer network', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' hippocampus', ' mathematical model', ' neural information processing', ' neurotransmitters', ' parallel processing', ' supercomputer', ' thalamocortical tract', ' vocabulary development for information system']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2001,232139,-0.014738261009797323
"RULE DISCOVERY IN BODY CAVITY EFFUSIONS  DESCRIPTION (adapted from the Abstract):                                             Machine learning methods are innovative tools used to find patterns in medical       data.  Laboratory data is suited to computerized Interpretation because of its       objective, quantitative nature.  Body fluid analysis is a good model for             evaluating machine learning in the laboratory.  Pathologists spend a                 substantial amount of time analyzing and classifying body fluids, or                 effusions, which are abnormal accumulations of fluid within body cavities of         human beings and animals, caused by diseases such as congestive heart failure.       Fluid classification provides clinicians with important diagnostic information       about the underlying disease process.  Automation of body fluid analysis by a        machine learning system would substantially increase the efficiency and              profitability of a medical laboratory.  In a pilot study, RIPPER (Repeated           Incremental Pruning to Produce Error Reduction), a rule discovery tool,              accurately classified effusions from animals into five standard categories,          based on the physical, chemical, and cellular characteristics of the fluid.          The purposes of this study are: 1) to determine the accuracy of RIPPER on a          larger data set, to expand and strengthen the results of the pilot; 2) to test       the accuracy of RIPPER's fluid classifications prospectively in a large              veterinary teaching hospital laboratory, 3) to determine the acceptance rate         or reason for rejection of RIPPER's classification by clinical pathologists;         and (4) to use RIPPER to discover novel rules for classifying effusions by           underlying disease process.                                                                                                                                               The results of this study will validate and test the acceptance of a machine         learning system applicable to fluid analysis in both human and veterinary            clinical laboratories.  By discovering new patterns in quantitative data that        identify the specific underlying disease, RIPPER can greatly enhance the             diagnostic value of laboratory analysis.                                                                                                                                  n/a",RULE DISCOVERY IN BODY CAVITY EFFUSIONS,6467346,F32LM000095,"['body fluids', ' classification', ' computer assisted instruction', ' programmed instruction', ' veterinary science']",NLM,UNIVERSITY OF CALIFORNIA DAVIS,F32,2001,52501,-0.020018323929159573
"ACTUARIAL STRATEGIES IN CHILD DIAGNOSTIC ASSESSMENT  The proposed project involves a preliminary investigation of                                                                                   potentially significant methodological advance in diagnostic assessment. The         current state-of-the-art in diagnostic assessment involves the use of a              structured interview. Typically, structured interviews involve a static skip         structure, i.e., some portions of the interview are administered conditional on                                 particular responses to prior questions. For example, if there is a negative         response to a question about depression and anhedonia, most structured               interviews require the clinical to skip the remaining questions about                associated symptoms (e.g., sleep disturbance, impaired concentration, etc.).         Although structured interviews represent an enormous advantage over earlier          diagnostic procedures, their inflexible structure is often incompatible with         the heterogeneity of most child and adolescent populations, and can result in        superfluous questioning about uncommon disorders and insufficient follow-up          about more common ones. Many interviews do not make exceptions for individual        characteristics. For example, 1) a 17 year old boy might need to answer ""no"" to      5 or 6 questions about separation anxiety before the interviewer may move on to      another set of questions; or 2) an underweight 16 year old girl might not be         asked important follow-up questions when replying ""no"" to the initial question       about eating disorders. One might conclude that introducing more clinician           flexibility would be the solution; however, the literature on clinical judgment      suggests that increasing clinician involvement in determination of interview         structure would likely degrade classification accuracy and introduce unwanted        sources of error and bias. To address this issue in another manner, the              principal investigator has developed a data-driven, actuarial expert system to       guide a flexible interview structure. Thus, interview structure is dynamically       responsive to individual characteristics, without introducing error associated       with qualitative clinical judgments. Pilot modeling revealed that his system         offers advantages in classification accuracy over state-of-the-art diagnostic        approaches, with the additional benefit of reducing administration time for          particular disorders. The current project is planned to generate requisite data      to develop a formal expert system and to forecast its relative accuracy and          efficiency in a child and adolescent population. It is predicted that this           system will demonstrate improvements in classification accuracy over a static        structured interview approach, with reduced administration time. If the data         are supportive, these developments have the potential to significantly advance       the manner in which future diagnostic interviews are conducted with mental           health populations.                                                                                                                                                       n/a",ACTUARIAL STRATEGIES IN CHILD DIAGNOSTIC ASSESSMENT,6392530,R03MH060134,"['adolescence (12-20)', ' anxiety', ' artificial intelligence', ' behavior test', ' behavioral /social science research tag', ' child (0-11)', ' child behavior disorders', ' child psychology', ' clinical research', ' computer assisted diagnosis', ' data collection methodology /evaluation', ' depression', ' diagnosis design /evaluation', ' human subject', ' interview', ' mathematical model', ' mental disorder diagnosis', ' model design /development', ' mood disorders', ' psychometrics', ' questionnaires']",NIMH,UNIVERSITY OF HAWAII AT MANOA,R03,2001,60756,-0.02247830673202181
"STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES   DESCRIPTION (Adapted from the Applicant's Abstract): This proposed project has       three primary objectives. Objective 1 is to develop improved strategies for          fitting more accurate classification and regression tree (i.e., CART) models.        Objective 2 is to develop a formal framework to allow statistical inference on       tree models. Objective 3 is to develop and distribute public-domain software         that will allow applied data analysts to implement the methods we develop in         the first two objectives. To meet these objectives we will integrate                 statistical and computational machine learning approaches. We believe our work       can have a significant impact in biomedical data analysis by combining the           strengths of statistics for developing objective criteria for model selection        and for providing a framework for assessing and quantifying uncertainty              associated with a model, with the strengths of machine learning for fitting          models to large and complex datasets.                                                                                                                                     n/a",STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES,6387141,R01GM061218,"['classification', ' computer assisted medical decision making', ' computer program /software', ' computer simulation', ' experimental designs', ' human data', ' information system analysis', ' mathematical model', ' model design /development', ' statistics /biometry']",NIGMS,BARNES-JEWISH HOSPITAL,R01,2001,163400,-0.0024663670156867263
"RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY DESCRIPTION: (adapted from the applicant?s abstract): Temporomandibular disorders (TMD) are common problems in the general population. The Research Diagnostic Criteria (RDC) for TMD were developed to establish specific operationalized examination procedures and diagnostic criteria for 8 Axis I biomedical diagnoses of TMD, as well as Axis II biobehavioral assessment procedures. Procedural reliability testing has been established for the RDC Axis I examination items, but full acceptance of the RDC requires confirmation of the temporal stability, validity, generalizability and clinical utility of the examination items, biomedical diagnoses, biobehavioral assessments, and general protocol. In order to accomplish these overall goals, a multi-center project is proposed that will first reassess at the University of Minnesota the reliability of 6 examiners (2 examiners each from 3 participating universities) to collect clinical Axis I examination data using the RDC operational definitions. In a second step, reliable blinded examiners will collect clinical examination data and formulate RDC diagnoses, which will be compared to criterion diagnoses made by an expert imaging. New clinical exam items will also be assessed. Subject to expert consensus, they will be added to yield a final exam protocol that will include all current RDC examination items as well as the new items. With this new protocol, the 6 examiners will continue examining normal and TMD subjects at their respective centers in order to test the temporal stability and diagnostic validity of the new and existing examination items, patient history items, and TMJ imaging by plain film and MRI. Discriminant analyses and decision tree analyses will be used to determine the best diagnostic algorithms for rendering RDC diagnoses. Masticatory muscle biopsies and TMJ synovial fluid will be collected from subjects at the University of Minnesota to evaluate biological markers for their role as potential mediators underlying the biomedical diagnoses. Simultaneously, Axis II biobehavioral assessment procedures will be tested for temporal reliability, compared with other accepted self-report instruments for concurrent validity, and, at two centers, evaluated for criterion validity against highly structured psychiatric interviews. The clinical and health services utility of adding Axis II biobehavioral assessments, imaging and biopsy results to Axis I clinical examination findings will be appraised. Advancement in our understanding of the prevalence, etiologies, natural progression, and treatment of TMD is dependent on having reliable and valid diagnostic criteria for these disorders. n/a",RESEARCH DIAGNOSTIC CRITERIA-- RELIABILITY AND VALIDITY,6286594,U01DE013331,"['biomarker', ' biopsy', ' clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' enzyme linked immunosorbent assay', ' facial muscles', ' gas chromatography mass spectrometry', ' human subject', ' inflammation', ' interview', ' magnetic resonance imaging', ' mastication', ' musculoskeletal disorder diagnosis', ' oral facial pain', ' pain threshold', ' psychobiology', ' questionnaires', ' radioimmunoassay', ' sign /symptom', ' statistics /biometry', ' synovial fluid', ' temporomandibular joint syndrome', ' tissue /cell culture']",NIDCR,UNIVERSITY OF MINNESOTA TWIN CITIES,U01,2001,1222618,-0.004104888382968509
"Core Grant for Vision Research The Smith-Kettlewell Eye Research Institute is a private non-profit organization, founded to encourage a productive collaboration between the clinical and basic research communities. To further this objective, the Institutes incorporates visual scientists from diverse medical and scientific backgrounds: ophthalmology visual scientific backgrounds. In the past, research at this Institute was focused on topics related to strabismus and amblyopia (oculomoter processing, binocular vision, cortical development of t he visual pathways). While these research areas are still growing, other distinct specialties have emerged in recent years Vision in the aging eye, motion and long-range processing, analysis of retinal functioning, retinal development, object recognition and computer vision are among the new research interests. Given the small scale of Smith-Kettlewell, the proximity of the scientists, and their common research interests, collaboration among scientist is an important aspect of the research milieu. Principal Investigators share resources with little difficulty. For more than twenty years, the Core Grant has formed the central component of the most important shared research services, chiefly electronic hardware design and maintenance, and computer communication and support. The technical expertise of our electronic and computer services group greatly benefits the rapid development of new research agendas-a tremendous advantage for new principal investigators and postdoctoral fellows, and a major factor in our high productivity. The Computer Services Module has evolved from providing predominantly software services in the past to establishing central computer services, including Internet, email, data transfer, central back-up and Intranet capabilities. We therefore are requesting renewal of these valuable Core Facilities.  n/a",Core Grant for Vision Research,6346620,P30EY006883,"['biomedical facility', ' health science research', ' vision']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,P30,2001,527694,-0.00960418978305694
"3-D SPATIAL MAPPING AND RECKONING FOR SURGICAL DEVICES   DESCRIPTION (Adapted from the applicant's abstract):  Innovative 3-D computer                                                                              vision algorithms that can enable a new generation of ""spatially aware""              instruments by providing real-time absolute positioning capability non-                                                             invasively, similar to the Global Positioning Satellite System for terrestrial       applications, are proposed.  They rely on a spatial reference map that is            constructed during the diagnostic exploration.  The position information can         be used for numerous purposes, including surgical navigation, guidance,              planning, on-line treatment monitoring, error detection, alarms and safety           shutoffs is when the tool strays from the target, change analysis, and even          surgical simulation.  This is a much better paradigm for instrument design           than (the largely unsuccessful) tracking algorithms that measure relative            displacements, and are thus prone to drift and tracking loss.  The proposed          algorithms will operate robustly and accurately at frame rates for extended          periods in poor and variable imaging conditions.  They could be incorporated         into existing clinical instruments without the need for precise calibration,         which is often not possible anyway, because the patient's anatomy (e.g., the         eye) is part of the imaging system.                                                                                                                                       The algorithms will be validated in the context of laser retinal surgery -           compelling as the only long-term proven treatment for the leading blindness-         causing conditions affecting over 20 million people in the US.  Yet, the             current success rate of this procedure is less than 50%, largely due to the          lack of spatial mapping and navigation aids in current clinical instruments.                                                                                              Beyond laser retinal surgery, the algorithms may be applied whenever:  (1)           precise locations on the retina are important (e.g., perimetry); (2) the             retinal periphery is of interest (AIDS/CMV, diabetes); (3) motion compensation       is needed; (4) a tool such as a laser or endoscope is to be monitored or             guided precisely at a chosen location; or 5) even when stable measurements of        the vasculature (retinopathy of prematurity) and retinal changes are of              interest (e.g., angiogenesis research).  Overall, the core methods are               expected to be broadly useful in a number of minimally-invasive surgical             techniques, including emerging alternatives to laser.                                                                                                                     n/a",3-D SPATIAL MAPPING AND RECKONING FOR SURGICAL DEVICES,6394720,R21RR014038,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' clinical research', ' computer assisted diagnosis', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' eye fundus photography', ' eye laser surgery', ' human subject', ' retina disorder', ' surgery material /equipment']",NCRR,RENSSELAER POLYTECHNIC INSTITUTE,R21,2001,97900,-0.004259929917211268
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6385653,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2001,127154,-0.011693569141545516
ARTIFICIAL INTELLIGENCE METHODS FOR CRYSTALIZATION No abstract available n/a,ARTIFICIAL INTELLIGENCE METHODS FOR CRYSTALIZATION,6188557,R01RR014477,"['X ray crystallography', ' artificial intelligence', ' chemical structure', ' computer system design /evaluation', ' crystallization', ' method development']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2000,228436,0.004654196315320112
"ADVANCED DIAGNOSTIC LOGIC FOR PSYCHIATRY   DESCRIPTION: (Verbatim from the Applicant's Abstract): This Phase I project          proposes to assess the feasibility of an advanced diagnostic logic system            (Diagnostica) to support the clinical assessment process for diagnosis in            psychiatry. A working prototype of the diagnostic rules in the American              Psychiatric Association Diagnostic and Statistical Manual (DSM-IV) uses and          artificial intelligence engine (""XSB"") to implement the logic of DSM-IV along        with and an interactive graphical user interface to allow a user to add              information and understand conclusions reached by the system. The Phase I            programming objectives are to make Diagnostica ready for commercial use by           improving its graphical user interface, and finalizing implementation of its         logical rules. The resulting system will be a practical tool in clinical             settings, and relies on computer science innovations that have preciously            neither been explored nor applied in the domain of medical reasoning. With the       emergence of decision support systems, the need for better quality diagnostic        information is becoming increasingly apparent. This has been due, in part, to        the complexity of diagnostic processes and the emphasis on support of financial      processes. Within mental health, the DSM-IV provides both a model and a              standard for making diagnoses. A software component that provides flexible,          complete, and efficient application of this standard is of great value. The          innovation of Diagnostica relies on the sophistication of its modeling of            DSM-IV rules, and it's flexibility in applying those rules. Diagnostica will         automatically track the status of the information entered and allow users to         tie up 'loose ends' in documenting the proof of diagnoses formally. AS example,      the user may indicate that a set of diagnoses in 'believed true' without             specifying the symptoms needed to make the diagnoses formally ( a procedure          used routinely in clinical practice). the application will track whatever            'residual' data this is necessary in order to complete formal diagnoses, while       leaving the option of when, or if, to complete the process up to the user.                                                                                                Phase II objectives include: (1) extending Diagnostica to provide other              software applications needing diagnostic decision support services, and              specifically to link Diagnostica to the World Health Organization Schedules for      Clinical Assessment in Neuropsychiatry (SCAN); (2) addressing logical modeling       of time and creating an effective user interface for repeated assessment; (3)        incorporating probabilistic information about sets of symptoms based on              empirical information initially obtained in Phase I; and (4) developing and          testing ""belief revision"" functions to changes in knowledge stemming from            repeated clinical assessment.                                                        PROPOSED COMMERCIAL APPLICATION:                                                                                     Computerization of diagnostic logic for clinical use can improve the quality of      mental health services by efficient standardization of assessment and through        motivating and making more practical the creation of data bases which can be         used for clinical quality improvement and knowledge discovery.                                                                                                            n/a",ADVANCED DIAGNOSTIC LOGIC FOR PSYCHIATRY,6210194,R43MH059420,"['artificial intelligence', ' computer assisted diagnosis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' interactive multimedia', ' mental disorder diagnosis', ' psychiatry']",NIMH,"MEDICINE RULES, INC.",R43,2000,98441,-0.009098877127574177
"SELECTING AMONG MATHEMATICAL MODELS OF COGNITION DESCRIPTION (Adapted from Applicant's Abstract):  In mathematical modeling       of cognition, it is important to have well-justified criteria for choosing       among differing explanations (i.e., models) of observed data.  This project      investigates those criteria as well as their instantiation in five model         selection methods.                                                                                                                                                Two lines of research will be undertaken.  In the first, a thorough              investigation of model complexity will be conducted.  Comprehensive              simulations re intended to determine complexity's contribution to model fit      and to model selection.  An analytical solution will also be sought with the     hope of quantifying model complexity.                                                                                                                             The second line of work examines the utility of each of the five selection       methods in choosing among models in three topic areas in cognitive               psychology (information integration, categorization, connectionist               modeling), the end goal being to identify their merits and shortcomings.                                                                                          Findings should provide a better understanding of model selection than           currently available and serve as a useful guide for researchers comparing        the suitability of quantitative models of cognition.                                                                                                               n/a",SELECTING AMONG MATHEMATICAL MODELS OF COGNITION,6185788,R01MH057472,"['artificial intelligence', ' choice', ' cognition', ' computer simulation', ' information dissemination', ' mathematical model', ' psychometrics']",NIMH,OHIO STATE UNIVERSITY,R01,2000,77332,-0.005813813764027089
"NEW ROC METHODOLOGY TO ASSESS DIAGNOSTIC ACCURACY DESCRIPTION (Adapted from Applicant's Abstract):  Receiver Operating             Characteristic (ROC) analysis is recognized widely as the best way of            measuring and specifying the accuracies of diagnostic procedures, because it     is able to distinguish between actual differences in discrimination              capacity, on one hand, and apparent differences that are due only to             decision-threshold effects, on the other.  Key methodological needs remain       to be satisfied before ROC analysis can address all of the practically           important situations that arise in diagnostic applications, however.  This       project employs signal detection theory and computer simulation to address       several of those needs, by:  (1) refining and continuing distribution of         software developed previously by the applicants for fitting ROC curves and       for testing the statistical significance of differences between ROC curve        estimates; (2) developing and evaluating new algorithms for ROC                  curve-Fitting and statistical testing, based on their recently-developed         ""proper"" binormal model, that should provide more meaningful results in          experimental situations that involve small samples of cases; (3)                 investigating the usefulness of a form of ROC methodology that is based on       mixture distributions in order to rduce the need for diagnostic truth in ROC     experiments; (4) investigating the effect of case-saple difficulty on the        statistical power tests for differences between ROC curves, in order to          determine the optimal difficulty of cases that shouldbe studied on rank          diagnostic systems; and (5) developing methods for training artificial           neural networks (ANNs) to maximize diagnostic accuracy in terms of ROC           analysis and signal detection theory.                                             n/a",NEW ROC METHODOLOGY TO ASSESS DIAGNOSTIC ACCURACY,6181168,R01GM057622,"['artificial intelligence', ' computer assisted diagnosis', ' computer system design /evaluation', ' method development', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R01,2000,218176,-0.011434048415255362
FOUNDATION MODEL OF ANATOMY No abstract available n/a,FOUNDATION MODEL OF ANATOMY,6185236,R01LM006822,"['anatomy', ' artificial intelligence', ' biological models', ' computer simulation', ' human data', ' information systems', ' model design /development', ' physical model']",NLM,UNIVERSITY OF WASHINGTON,R01,2000,415930,-0.0015567561719376476
"IMPROVED COLLIMATION FOR PIXELATED RADIATION DETECTORS   DESCRIPTION: The investigators propose to test the feasibility of developing         improved collimators for use with higher performance pixelated detectors under       development for use in gamma cameras now under development, as further               described by their abstract:                                                                                                                                              ""In nuclear medicine, the collimator plays a critical role in the formation of       a projection image of the radiopharmaceutical distribution within a patient.         The current state-of-the-art of collimator design for Nuclear Medicine has           matured, under the assumption that gamma-ray detectors have an intrinsic             position dependant Gaussian response function. A fundamental rethinking of           collimator design is necessary to optimize collimation for solid state               detectors that have a fixed intrinsic rect function response. We will construct      design tools by first developing a mathematical model of collimation for             detectors with intrinsic pixels and then implement it by computer algorithms.        We will conduct experiments to measure performance and validate the simulation       tools. Using the validated simulator we will then explore novel collimator           designs and hole patterns. We will examine all proposed designs for                  sensitivity, resolution, cost and manufacture. To advance clinical                   applications, collimator design will need to keep pace with the anticipated          improvements in detector technology. Phase II brings a production prototype of       the new collimator design to laboratory and clinical testing.""  PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                                          n/a",IMPROVED COLLIMATION FOR PIXELATED RADIATION DETECTORS,6071510,R41RR013519,"['artificial intelligence', ' biomedical equipment development', ' mathematical model', ' model design /development', ' nuclear medicine', ' radiation detector', ' scintillation cameras']",NCRR,MOSAIC IMAGING TECHNOLOGY,R41,2000,137074,-0.0006308613217401868
"KNOWLEDGE BASES FOR STRUCTURED CARDIOVASCULAR REPORTING Healthcare has lagged behind other industries in automating the storage and retrieval of information. While billing, blood testing, and other services are widely computerized, the bulk of patient clinical information is not. The central barrier to coding clinically useful data - patient historical, test, and procedural results - is the absence of effective knowledge frameworks for entry and review of clinical data. For this reason, sofiware for storage and retrieval of patient data remains suboptimal. This project focuses on methods for recording a specific subset of patient data: results of cardiovascular tests, Although only a subset of clinical knowledge, cardiovascular procedure reporting is typical of the larger problem of how knowledge is handled. Moreover, there is an unmet market demand for cardiology reportrng tools. In Phase I we will develop a methodology for creating and maintaining the knowledge bases needed for structured entry of cardiovascular data. We will apply and hone this methodology by creating two important knowledge bases: echocardiography and cardiac catheterization. Together with the methodology we use, these two developments will dovetail into a larger Phase II  project of systematically addressing knowledge-representation and structured data entry for cardiology. Beyond Phase II  we will apply our methodology to other branches of medicine. PROPOSED COMMERCIAL APPLICATION: This research will provide a means to optimize structured recording of patient test results in a computer-searchable format improving the process of procedural reporting, and facilitating implementation of an electronic medical record.  n/a",KNOWLEDGE BASES FOR STRUCTURED CARDIOVASCULAR REPORTING,6141030,R43HL062806,"['artificial intelligence', ' cardiovascular disorder diagnosis', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' echocardiography', ' heart catheterization', ' human data', ' informatics']",NHLBI,"CYBERPULSE, LLC",R43,2000,107000,-0.029192532825438405
"DEVELOPMENT OF SPATIAL SOFTWARER This SBIR project will develop software for identifying and correcting spatial patterns in data for a wide range of alcohol-related phenomenon including alcohol consumption, problematic outcomes, and treatment modalities. Identifying and correcting statistical relationships in spatially configured data sets would be invaluable to alcohol-related research, the overall health community, and even to most social scientists (and biomedical researchers). Ecological models or models with locational components that provide unbiased estimates and increased predictive performance enhance the researcher' ability to identify new patterns within alcohol-related phenomenon. While spatial analysis has been widely researched and is a proven statistical technique, commercially available software with reasonable diagnostics and commonly used regression techniques does not yet exist. This phase I project addresses this need and will pursue three objectives: (1) Research and increase the capabilities of the current software package, (2) Design interfaces easily useable (friendly) for alcohol researchers, and (3) Improve the speed and efficiency of the core code. The proposed software development will provide powerful diagnostic and corrective tool in the analysis of mapped data describing relationships between space and alcohol- related phenomenon. PROPOSED COMMERCIAL APPLICATIONS: The need for identifying and adjusting for spatial autocorrelation in alcohol- related data sets is huge (see page 21) and so there is a large market for the proposed statistical software. The proposed package is expected to provide an easy to use, speedy, and comprehensive tool relative to current packages.  n/a",DEVELOPMENT OF SPATIAL SOFTWARER,6073824,R43AA012373,"['alcoholism /alcohol abuse', ' artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' mathematics', ' statistics /biometry']",NIAAA,S-THREE DEVELOPMENT,R43,2000,129935,-0.04041913048081174
"CLUSTERING AND HYPER-LINKING OF LONG-TERM EEGS The proposed work offers enhancements to the MagicMarker software developed in Phase I.  This software offers a new methodology for the display and analysis of long-term EEG records.  Epochs of similar activity are grouped into segments and then states via two-pass hierarchial clustering.  This results in clearly differentiated background, paroxysmal activity and patient state transitions.  The underlying EEG  is always available via hyper- links so that artifacts can be distinguished from ""real EEG."" The Phase II work adds classification abilities (intelligence) to the Phase I software.  Proposed are an expert-level seizure detector, an ICU abnormality detector and a user-defined activity detector.  The effort includes the development of a large library of carefully analyzed and annotated prolonged EEG studies. Newborns, older children and adults will be included ensuring robust algorithms for all age groups. The proposed software greatly reduces staff requirements for long-term monitoring through intelligent notification (visual, audible and dial-up pager) of interesting events.  This, in addition to the ability to monitor patients ""away from the lab,"" provides more frequent patient checks and improved clinical outcomes. PROPOSED COMMERCIAL APPLICATION The proposed software would be a valuable addition to any digital EEG because of the great timesavings it provides for both neurologists and EEG technicians.  The software will be marketed along with current Persyst products (Insight, SpikeDetector and Prism), which support and are sold by virtually every major DEEG manufacturer.  n/a",CLUSTERING AND HYPER-LINKING OF LONG-TERM EEGS,6186323,R44MH055895,"['Internet', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' electroencephalography', ' generalized seizures', ' human data', ' image processing', ' intensive care']",NIMH,PERSYST DEVELOPMENT CORPORATION,R44,2000,352280,-0.009644344813878016
"WAVELET-BASED AUTOMATED CHROMOSOME IDENTIFICATION Commercial automated karyotyping instruments have improved to the point where the major factor limiting throughput is the time required for operator correction of chromosome classification errors. An improvement in chromosome classification accuracy would significantly increase the value of these instruments in cytogenetics labs. The goal of this project is to develop and commercialize significantly improved chromosome measurement and classification techniques for automated karyotyping. Currently the best-performing chromosome classification approach uses Weighted Density Distribution (WDD) features [11] to quantify the banding pattern of the chromosomes. These are computed as inner products between the banding profile and a set of WDD basis functions. The particular set of 1unctions originally proposed by Granum [11,38] has come into widespread use. In Phase I we showed that better function sets exist and that our new approach can find better WDD features than the best currently used. We have an innovative wavelet-based method for generating WDD functions and a chromosome classification testbed which supports large scale classification experiments. We propose to conduct a thorough, methodical search for better performing basis functions in Phase II. Phase III will incorporate the technology into PSI's PowerGene automated karyotyping instruments. PROPOSED COMMERCIAL APPLICATIONS: When the new chromosome classification technology is qualified for routine application, it will be incorporated into PSI's Powergene products, both in new systems sold and as an upgrade to existing systems.  n/a",WAVELET-BASED AUTOMATED CHROMOSOME IDENTIFICATION,6173267,R44CA076896,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosomes', ' computer program /software', ' cytogenetics', ' density', ' genetic mapping', ' genetic techniques', ' human genetic material tag', ' human tissue', ' image processing']",NCI,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2000,366807,0.007515190247140994
"PERMUTATION TEST SOFTWARE FOR RANDOMIZED CLINICAL TRIALS The randomized clinical trial (RCT) is arguably the linchpin of the drug development process, and the results of a randomized clinical trial are almost always analyzed using some form of statistical hypothesis test. Most hypothesis tests used for analyzing clinical trials assume a population model for statistical inference, when in fact a randomization model is more consistent with the way randomized clinical trials are actually conducted. Failure to consider the randomization model when analyzing clinical trials can lead to effective drugs being declared ineffective, and ineffective drugs being declared effective. In order to analyze clinical trials in accordance with the randomization model, sophisticated software for conducting permutation tests is needed. The overall goal of this research is to develop flexible and robust software, usable by statisticians or other medical data analysts, for conducting permutation tests for single- or multi-clinic randomized clinical trials. The ongoing advances in computing technology have created a favorable climate for development of software for conducting permutation tests. This project includes a collaboration with Dr. Rosenberger of the University of Maryland, Baltimore County who is a recognized expert on randomization based inference and adaptive designs. PROPOSED COMMERCIAL APPLICATIONS: Software that can use general permutation tests to analyze clinical trial data would have clear commercial value to clinical research organizations in academia, Government, and the pharmaceutical, biotechnology, and medical device industries. Key applications are the analysis of clinical trials with unusual randomization schemes, trials with unusual patterns of treatment response, and trials where standard distributional assumptions are invalid.  n/a",PERMUTATION TEST SOFTWARE FOR RANDOMIZED CLINICAL TRIALS,6141347,R43CA086556,"['artificial intelligence', ' clinical trials', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' experimental designs', ' human data', ' mathematics', ' statistics /biometry']",NCI,"LINCOLN TECHNOLOGIES, INC.",R43,2000,98172,-0.01736183821412368
COMPUTER AIDED CARDIAC MEASUREMENT The objective of the proposed research is to develop a method for providing fast and accurate measurements of volume and ejection fraction from 3D echo images. Our Computer Aided Measurement System will reconstruct the LV endocardium using a few user selected points on oriented echocardiographic images together with prior shape and size knowledge. The Specific Aims for Phase I are: 1. To improve the accuracy of quantitative echo while minimizing manual labor. 2. To improve the ease of use of the prototype system for application in a clinical setting. 3. To expand the catalog representing our knowledge base by acquiring additional large volume and abnormally shaped LV's in order to enhance fitting accuracy for atypical shapes. Previously described methods of analyzing echocardiograms in 3D require so much manual labor that this modality has been limited to research applications. The advantages of our proposed approach are that it makes the superior accuracy and reproducibility of 3D echo available for clinical practice. Furthermore this process will be applicable to other imaging modalities. PROPOSED COMMERCIAL APPLICATIONS: This research will lead to products which can be sold to echocardiography system manufacturers and end users. The products will provide accurate and convenient value measurements.  n/a,COMPUTER AIDED CARDIAC MEASUREMENT,6211201,R43HL065827,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' echocardiography', ' heart dimension /size', ' heart disorder diagnosis', ' human data', ' image processing', ' measurement']",NHLBI,"QUANTIGRAPHICS, INC.",R43,2000,100000,-0.024407548435328042
"ASSESSING NEW MATHEMATICAL MODELS FOR MEDICAL EVENTS Predictive models that generate estimate probabilities for medical outcomes have become widely used in health services research, in health policy, and increasingly, for the assessment of health care and for real-time decision support.  Logistic regression models for medical events are central to most probabilistic predictive clinical decision aids and are fundamental to comparative analyses of medical care based on risk-adjusted events.  In such applications, inaccurate assessment of patient risk can have significant health care and health policy implications. New computer-based modeling techniques including generalized additive models, classification trees, and neural networks may potentially capture information that regression methods may miss or misrepresent.  However, these methods use very local information in model construction and may be overfit to the sample data and thus not transport well to new settings.  In years 1-3, we investigated the relative accuracy of predictions made by these modeling methods under a variety of data structures, including the presence of outliers and missing data. For many of these data structures we found that the more ""local"" procedures frequently did not generalize to new test data as well as traditional regression methods.  However, our results suggest that as sample size and data complexity increases the performance of these procedures may substantially improved. Thus, to test these findings under more general conditions, we now propose two additional years of research to 1) rigorously assess the relative predictive performance and transportability of other new innovative modeling methods and of original hybrid model construction methods; 2) systematically investigate the relative predictive performance and model transportability of modeling methods applied to large and complex data structures; and 3) explore and assess procedures for handling outliers and missing data for classification trees and neural networks. The completion of the proposed work will result in the first systematic exploration of the factors affecting the predictive performance of the major modeling methods used to predict medical outcomes, and the comparative performance of models constructed by these methods on the extremely large data sets of the type that are becoming increasing available to researchers.  n/a",ASSESSING NEW MATHEMATICAL MODELS FOR MEDICAL EVENTS,6185210,R01LM005607,"['artificial intelligence', ' computational neuroscience', ' computer assisted medical decision making', ' computer simulation', ' health care facility information system', ' human data', ' information system analysis', ' mathematical model', ' model design /development', ' outcomes research', ' prognosis', ' statistics /biometry']",NLM,TUFTS MEDICAL CENTER,R01,2000,270618,-0.018454447434873907
"DECISION SUPPORT SOFTWARE TO TRIAGE FOR SKIN CANCER Many primary care physicians are unable to proficiently triage skin lesions suspicious for cancer, compromising patients' health. Decision support software could help in the early detection of skin cancer, decreasing morbidity and mortality related to skin cancer misdiagnoses. It also could reduce unnecessary referrals to specialists, lowering health care costs. In Phase I, we demonstrated that decision support software can significantly improve physicians' ability to arrive at appropriate triage decisions for a variety skin lesions, including cancerous lesions. In Phase II, we propose to l) expand the decision support software to triage for pigmented lesions and a wider range of nonpigmented skin lesions; 2) incorporate case-based reasoning methods into the software to enable users to conduct a confidence check on their final triage decision and to help them make the correct decision at each branch point in the decision tree; 3) develop a teaching application based on the decision tree; 4) enable the software to produce for patients individualized information on skin cancer prevention and treatment; 5) interface the decision support software with the computerized patient medical record; and 6) test the effectiveness, utility, and feasibility of the decision support software with a sample of primary care physicians and patients. PROPOSED COMMERCIAL APPLICATIONS: This research is designed to produce comprehensive decision support software that will be a commercially viable product. Two large potential markets for this product are medical schools, which may use the software as a teaching aid, and medical settings, which may use the software as a clinical tool for practicing primary care physicians.  n/a",DECISION SUPPORT SOFTWARE TO TRIAGE FOR SKIN CANCER,6172710,R44CA075906,"['cancer information system', ' cancer prevention', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer program /software', ' computer system design /evaluation', ' medical records', ' melanoma', ' neoplasm /cancer diagnosis', ' neoplasm /cancer therapy', ' pigments', ' skin neoplasms']",NCI,WEST PORTAL SOFTWARE CORPORATION,R44,2000,329958,-0.0587421046837116
"STATISTICAL STUDIES OF DNA EVOLUTION Our goals are to develop methods for statistical analyses of DNA sequence data and to understand the mechanisms of DNA evolution. The specific aims are: l. To examine current methods and develop new methods for estimating evolutionary dates, which is now a central issue in molecular evolution. We shall use the new methods to study divergence dates in mammals, which have recently become very controversial. 2. To develop methods for estimating selection intensities in different regions of a gene and to carry out statistical analyses of DNA sequence data from mammals. 3. To develop fast algorithms for finding optimal trees for the following methods: maximum likelihood, maximum parsimony, and minimum evolution. Such algorithms are much needed because these methods require a tremendous amount of computer time-and are not feasible for large trees. 4. An expert system for choosing the best tree reconstruction method for a data set according to the attributes of the data. 5. To introduce the neural network approach into phylogenetic study; this approach has proved extremely powerful in many branches of science and engineering.  n/a",STATISTICAL STUDIES OF DNA EVOLUTION,6131906,R37GM030998,"['DNA', ' artificial intelligence', ' biochemical evolution', ' computational neuroscience', ' computer assisted sequence analysis', ' computer simulation', ' gene frequency', ' genetic models', ' mathematical model', ' method development', ' model design /development', ' natural selections', ' nucleic acid sequence', ' species difference', ' statistics /biometry']",NIGMS,UNIVERSITY OF CHICAGO,R37,2000,152928,-0.03200257674086958
"A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER   Skin cancer is the fastest growing cancer. Approximately 34,100         Americans developed cutaneous melanoma in 1995; of the survivors, many must          contend with the ongoing trauma of disfigurement and fear. Skin biopsies are         now the most frequently performed medical procedure. It is axiomatic among           dermatologists that early detection and diagnosis are critical. Great strides        have been made in early detection of suspect skin lesions; however failure to        biopsy the right lesion has severe consequences. The dilemma is exacerbated          since 50- 80 percent of biopsies prove unnecessary, contributing to an enormous      waste of health care dollars, patient trauma and negative patient behavior           feedback. The Phase I work in dermatological spectroscopy and artificial neural      net technology suggest that an automated clinical diagnostic aid which produces      a quantitative rather than qualitative diagnostic assessment of skin lesions is      possible. This project proposes development and testing of such a product.           During Phase II a large number of spectroscopic samples of melanoma and nevi         will be used to complete development of an artificial neural net classifier.         Such a classifier system will lead to a commercial product to discriminate           ""normal,"" pre-cancerous and cancerous skin lesions.                                   PROPOSED COMMERCIAL APPLICATION:  The proposed project will lead to a non-invasive, in-office, real-time test to provide an  automated, repeatable diagnostic probability of the nature of skin lesions prior to biopsy.  Skin biopsies are now the most frequently performed reimbursed Medicare procedure,   and as many as 50-80% are found not to be necessary after the fact.  The low cost of   this test, and rapid amortization of the system, coupled with the enormous health care   cost savings possible in conjunction with a significant and widely recognized health   problem, suggest that this product could have great commercial potential.  n/a",A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER,6143548,R44CA078006,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence spectrometry', ' histology', ' human subject', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' reflection spectrometry', ' skin neoplasms', ' spectrometry']",NCI,"WESTERN RESEARCH COMPANY, INC.",R44,2000,363073,-0.027077912517951733
INTELLIGENT CRITIQUING OF CLINICAL-GUIDELINE APPLICATION No abstract available n/a,INTELLIGENT CRITIQUING OF CLINICAL-GUIDELINE APPLICATION,6045000,R01LM006806,"['artificial intelligence', ' behavioral /social science research tag', ' clinical research', ' computer assisted medical decision making', ' computer system design /evaluation', ' experimental designs', ' health care quality', ' health services research tag', ' human data', ' medical records', ' vocabulary development for information system']",NLM,STANFORD UNIVERSITY,R01,2000,294258,-0.004525347484289408
"AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION Quantification of Minimal Residual Disease (MRD) is a general concern in oncology since this parameter is likely to give valuable information to clinicians to customize chemotherapeutic treatments and to anticipate possible relapses. An automated system will be developed for the quantification of MRD by using real-time PCR to quantify cancer cells in a background of non pathologic DNA. The system will be derived from an existing high-throughput sample handling system (developed by Meldrum and team) named Acapella. Acapella has a pipelined serial architecture which makes it possible to develop an adaptive PCR control algorithm ensuring a level of sensitivity and accuracy for the quantification results specified by the clinician. In the R21 phase of the project, a critical component of the system is the real-time thermocycler. It will provide DNA quantification results of greater precision than what is currently possible with commercial instruments such as the ABI PRISM 7700 Sequence Detector by taking advantage of a high performance custom fluorescence analyzer and sophisticated data analysis methods. The fluorescence analyzer will have a signal to noise ratio and a dynamic range of at least one order of magnitude larger than the optics used on commercial systems. This unique feature will permit precise measurements of the amplification kinetics during at least five cycles in the exponential phase of the reaction. The amplification yield will he derived from these data using statistical estimators customized to meet the requirements of real-time PCR data analysis. The sample DNA content will be derived from the amplification yield and the calibrated fluorescence measurements of the reaction kinetics. This new approach will make it possible to run series of real-time PCRs with more flexibility than would be possible if the assay was based on standard reactions required to have the same amplification yield as the clinical samples. PCR conditions will be adapted online without concerns about possible differences of amplification rate. The assay control algorithm will adapt the reaction DNA content, the primer selection, and the number of PCRs to meet the clinician requirements for particular patient DNA. During the R21 phase of the project a prototype of the real-time thermocycler will be developed to demonstrate the optic performance and the possibility to estimate the PCR amplification rates with 5% accuracy. A conceptual design of the fully integrated process from patient blood sample to MRD quantification data will be completed to allow assessment of expected performance, cost, and risks associated with the development of the fully engineered system. The development of the various hardware and software components along with their integration into the automated system will take place during the R33 phase of the project. Performance of the system will he evaluated on real biological samples provided by the UW Department of Laboratory Medicine. Results returned by the system will he compared with results of t(14; 18) PCR performed in this department with an ABI PRISM 7700 for the diagnosis of patients suffering from follicular lymphomas.  n/a",AUTOMATED MINIMAL RESIDUAL DISEASE QUANTIFICATION,6062376,R21CA084691,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' chromosome translocation', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence', ' high throughput technology', ' human tissue', ' minimal residual disease', ' neoplasm /cancer diagnosis', "" nonHodgkin's lymphoma"", ' nucleic acid quantitation /detection', ' polymerase chain reaction']",NCI,UNIVERSITY OF WASHINGTON,R21,2000,154460,0.0011818646275180906
"KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY DESCRIPTION (Adapted from Applicant's Abstract):  Knowledge-guided, fully        automated image analytic procedures will be applied, and further developed       for the extraction of diagnostic and prognostic information from                 histopathologic sections.  It is proposed to develop knowledge files for the     grading of solar lesions, for the analysis of prostatic intraepithelial          neoplastic lesions (PIN), for benign proliferative epithelial lesions of the     breast, and for kidney tumors.  Quantitative progression indices will be         derived from histometric measurements.  These may serve to identify patients     at high risk to develop infiltrating disease, to measure rate of lesion          progression, and to allow a numeric assessment of the efficacy of                chemopreventive intervention.                                                                                                                                     Knowledge files are under development for a quantitative measurement of the      vascularization around PIN lesions.                                                                                                                               For nuclei, lesions and patients, novel methodology is proposed to               characterize these entities by identification, rather than by mere               classification.  This will allow a significantly more precise                    characterization of the nuceli in a lesion and of the state of lesion            progression.  The identification methods will be integrated into the current     diagnostic decision support system, and be given capabilities to handle          missing data, contradictory evidence, atypical diagnostic clue expression.       This capability relies on automated reasoning will be developed, and the         methodology will be adapted for used in histopathologic diagnosis.                n/a",KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6137486,R01CA053877,"['artificial intelligence', ' bioimaging /biomedical imaging', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' image processing', ' information system analysis', ' kidney neoplasms', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2000,442719,-0.05144004340011852
BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN DESCRIPTION (Taken from application abstract):  Reminder systems are expert       n/a,BELIEF NETWORK BASED REMINDER SYSTEMS THAT LEARN,6151393,R29LM006233,"['artificial intelligence', ' automated medical record system', ' behavioral /social science research tag', ' belief', ' computer assisted medical decision making', ' computer assisted patient care', ' computer system design /evaluation', ' health care facility information system', ' health services research tag', ' human data', ' patient care management']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R29,2000,103781,-0.004529223968653316
"PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS DESCRIPTION (Taken from application abstract):  Over the last decade             computational modeling has become central to neurobiology.  While much of        this work has focused on cellular and sub-cellular processes, the last few       years have seen increasing interest in systems level models and in               integrative accounts that span data from the subcellular to behavioral           levels.  Our proposal, in summary, is to extend existing work in parallel        discrete event simulation (PDES) and integrate it with existing work on          compartmental modeling environments, to produce a software environment which     has comprehensive support for modeling large scale, highly structured            networks of biophysically realistic cells; and which can efficiently exploit     the full range of parallel platforms, including the largest parallel             supercomputers, for simulation of these network models, which integrate          information about the nervous system from sub-cellular to the whole-brain        level.  Because of the scale of the models needed at this level of               integration, advanced parallel computing is required.  The critical              technical insight upon which this work rests is that neuronal modeling at        the systems level can often be reduced to a form of discrete event               simulation in which single cells are node functions and voltage spikes are       events.                                                                                                                                                           Three neuroscience modeling projects, will mold, test, and utilize these new     capabilities in investigations of system-level models of the nervous system      which integrate behavioral, anatomical and physiological data on a scale         that exceeds current simulation capabilities.  In collaboration with             computer scientists at Pittsburgh Supercomputing Center and UCLA,                neuroscientists at University of Virginia, the Born-Bunge Foundation,            Antwerp, and the Salk Institute, and developers of the NEURON and GENESIS        packages, these tools will be developed and made available to the                neuroscience community.  The software development aims include 1)                investigation of a portable, PDES system capable of running efficiently on       diverse parallel platforms, 2) development of interfaces to the PDES for         NEURON and GENESIS allowing models developed in those packages to be scaled      up, 3) investigation of a network specification language for neuronal            models, and associated a visualization interface, to facilitate                  investigation of systems-level models, 4) sufficiently robust and                well-documented software for download and installation at other sites.  The      three neuroscience projects will guide development of the software tools and     use the tools for investigation of large-scale models of cerebellum,             hippocampus and thalamocortical circuits.                                         n/a",PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS,6186179,R01MH057358,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biotechnology', ' cerebellar cortex', ' computational neuroscience', ' computer network', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' hippocampus', ' mathematical model', ' neural information processing', ' neurotransmitters', ' parallel processing', ' supercomputer', ' thalamocortical tract', ' vocabulary development for information system']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2000,234591,-0.014738261009797323
"RULE DISCOVERY IN BODY CAVITY EFFUSIONS  DESCRIPTION (adapted from the Abstract):                                             Machine learning methods are innovative tools used to find patterns in medical       data.  Laboratory data is suited to computerized Interpretation because of its       objective, quantitative nature.  Body fluid analysis is a good model for             evaluating machine learning in the laboratory.  Pathologists spend a                 substantial amount of time analyzing and classifying body fluids, or                 effusions, which are abnormal accumulations of fluid within body cavities of         human beings and animals, caused by diseases such as congestive heart failure.       Fluid classification provides clinicians with important diagnostic information       about the underlying disease process.  Automation of body fluid analysis by a        machine learning system would substantially increase the efficiency and              profitability of a medical laboratory.  In a pilot study, RIPPER (Repeated           Incremental Pruning to Produce Error Reduction), a rule discovery tool,              accurately classified effusions from animals into five standard categories,          based on the physical, chemical, and cellular characteristics of the fluid.          The purposes of this study are: 1) to determine the accuracy of RIPPER on a          larger data set, to expand and strengthen the results of the pilot; 2) to test       the accuracy of RIPPER's fluid classifications prospectively in a large              veterinary teaching hospital laboratory, 3) to determine the acceptance rate         or reason for rejection of RIPPER's classification by clinical pathologists;         and (4) to use RIPPER to discover novel rules for classifying effusions by           underlying disease process.                                                                                                                                               The results of this study will validate and test the acceptance of a machine         learning system applicable to fluid analysis in both human and veterinary            clinical laboratories.  By discovering new patterns in quantitative data that        identify the specific underlying disease, RIPPER can greatly enhance the             diagnostic value of laboratory analysis.                                                                                                                                  n/a",RULE DISCOVERY IN BODY CAVITY EFFUSIONS,6144004,F32LM000095,"['body fluids', ' classification', ' computer assisted instruction', ' programmed instruction', ' veterinary science']",NLM,UNIVERSITY OF CALIFORNIA DAVIS,F32,2000,52420,-0.020018323929159573
"MULTICHANNEL EEG DATA COMPRESSION Recently, recording high-resolution Electroencephalograms (EEGs) from            a large number of electrodes has become a clear trend in both brain              research and clinical diagnosis.  However, the current EEG data                  acquisition systems store the collected data in a form that has never            changed since digital EEG emerged about 30 years ago.  As a result, the          size of the output data file increases enormously as the number of               recording channels increases, causing various problems including high            costs in data analysis, database management, archiving, and transmission         through the internet.                                                                                                                                             This proposal seeks to solve this problem through fundamental research           on data compression specifically for EEG data, but applicable to other           physiological data as well.  Our key approach is based on the                    application of advanced mathematical and signal processing technologies          to this critical problem.  We will develop and optimize a variable               sampling technique which eliminates redundant data samples using spline          interpolation and wavelet transformation.  We will also investigate              lossless data compression algorithms that possess two important                  features: 1) any part of the data within the compressed file can be read         without having to decompress the entire file, and 2) the compressed data         can be transmitted and presented in coarse or fine resolutions as                needed.  We expect that, using both variable sampling and lossless               compression, the EEG file size can be reduced by approximately 70                percent.                                                                          n/a",MULTICHANNEL EEG DATA COMPRESSION,6165278,R01NS038494,"['Internet', ' artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' clinical biomedical equipment', ' clinical research', ' computer data analysis', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' digital imaging', ' electroencephalography', ' human data', ' human subject', ' informatics', ' technology /technique development']",NINDS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2000,172553,-0.013828735236806711
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,6178669,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2000,254318,0.00020809561227725482
"ACTUARIAL STRATEGIES IN CHILD DIAGNOSTIC ASSESSMENT  The proposed project involves a preliminary investigation of                                                                                   potentially significant methodological advance in diagnostic assessment. The         current state-of-the-art in diagnostic assessment involves the use of a              structured interview. Typically, structured interviews involve a static skip         structure, i.e., some portions of the interview are administered conditional on                                 particular responses to prior questions. For example, if there is a negative         response to a question about depression and anhedonia, most structured               interviews require the clinical to skip the remaining questions about                associated symptoms (e.g., sleep disturbance, impaired concentration, etc.).         Although structured interviews represent an enormous advantage over earlier          diagnostic procedures, their inflexible structure is often incompatible with         the heterogeneity of most child and adolescent populations, and can result in        superfluous questioning about uncommon disorders and insufficient follow-up          about more common ones. Many interviews do not make exceptions for individual        characteristics. For example, 1) a 17 year old boy might need to answer ""no"" to      5 or 6 questions about separation anxiety before the interviewer may move on to      another set of questions; or 2) an underweight 16 year old girl might not be         asked important follow-up questions when replying ""no"" to the initial question       about eating disorders. One might conclude that introducing more clinician           flexibility would be the solution; however, the literature on clinical judgment      suggests that increasing clinician involvement in determination of interview         structure would likely degrade classification accuracy and introduce unwanted        sources of error and bias. To address this issue in another manner, the              principal investigator has developed a data-driven, actuarial expert system to       guide a flexible interview structure. Thus, interview structure is dynamically       responsive to individual characteristics, without introducing error associated       with qualitative clinical judgments. Pilot modeling revealed that his system         offers advantages in classification accuracy over state-of-the-art diagnostic        approaches, with the additional benefit of reducing administration time for          particular disorders. The current project is planned to generate requisite data      to develop a formal expert system and to forecast its relative accuracy and          efficiency in a child and adolescent population. It is predicted that this           system will demonstrate improvements in classification accuracy over a static        structured interview approach, with reduced administration time. If the data         are supportive, these developments have the potential to significantly advance       the manner in which future diagnostic interviews are conducted with mental           health populations.                                                                                                                                                       n/a",ACTUARIAL STRATEGIES IN CHILD DIAGNOSTIC ASSESSMENT,6096946,R03MH060134,"['adolescence (12-20)', ' anxiety', ' artificial intelligence', ' behavior test', ' behavioral /social science research tag', ' child (0-11)', ' child behavior disorders', ' child psychology', ' clinical research', ' computer assisted diagnosis', ' data collection methodology /evaluation', ' depression', ' diagnosis design /evaluation', ' human subject', ' interview', ' mathematical model', ' mental disorder diagnosis', ' model design /development', ' mood disorders', ' psychometrics', ' questionnaires']",NIMH,UNIVERSITY OF HAWAII AT MANOA,R03,2000,63589,-0.02247830673202181
"STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES   DESCRIPTION (Adapted from the Applicant's Abstract): This proposed project has       three primary objectives. Objective 1 is to develop improved strategies for          fitting more accurate classification and regression tree (i.e., CART) models.        Objective 2 is to develop a formal framework to allow statistical inference on       tree models. Objective 3 is to develop and distribute public-domain software         that will allow applied data analysts to implement the methods we develop in         the first two objectives. To meet these objectives we will integrate                 statistical and computational machine learning approaches. We believe our work       can have a significant impact in biomedical data analysis by combining the           strengths of statistics for developing objective criteria for model selection        and for providing a framework for assessing and quantifying uncertainty              associated with a model, with the strengths of machine learning for fitting          models to large and complex datasets.                                                                                                                                     n/a",STATISTICAL METHODS FOR RECURSIVELY PARTITIONED TREES,6090912,R01GM061218,"['classification', ' computer assisted medical decision making', ' computer program /software', ' computer simulation', ' experimental designs', ' human data', ' information system analysis', ' mathematical model', ' model design /development', ' statistics /biometry']",NIGMS,BARNES-JEWISH HOSPITAL,R01,2000,214602,-0.0024663670156867263
"INTERACTIVE MEDIA FOR WOMEN CONSIDERING HORMONE THERAPY The long-term goal of Phase I and Phase II is to create a series of bilingual (Spanish/English), bicultural, interactive CD-ROMs dealing with issues related to menopause and aging, with specific emphasis on Hispanic women. This proposal will result in a CD-ROM about Hormone Replacement Therapy (HRT) that takes 15-3O minutes to use and will test its value in a controlled study. Through an interactive decision-tree that specifies individual risk factors and lifestyle preferences, the CD-ROM will help users identify their options, including HRT, lifestyle changes such as exercise and diet, and other alternatives. Besides providing information, the CD-ROM will be designed to improve decision-making and increase women's confidence in their ability to make informed choices. Although it may increase the risk of cancer, HRT relieves short-term menopausal symptoms, and appears to offer long-term benefits of reduced risk for heart disease, stroke and osteoporosis. Over 40 million women will pass through menopause in the next two decades. Studies have shown that Hispanic women are less familiar with HRT and less likely to use it than non-Hispanic white women. In addition, Hispanas approach medical care with their own set of cultural values. Interactive media offer personalization, enhanced learning through multiple sensory input, and a cost-effective method of providing information in a managed care environment or busy individual practice. This is an innovative application of existing technology to provide patient education. Possible topics for Phase II include osteoporosis, heart disease, depression, and stroke. PROPOSED COMMERCIAL APPLICATIONS: Educational media is a $3B market. Print and video materials on HRT and menopause are available, but little exists as interactive media, in Spanish, and/or is culturally-relevant to Hispanics. This CD-ROM and related topics in Phase II can be sold to HMOs, clinics, and doctors' offices through direct sales; posted on the Internet; or distributed through medical media and pharmaceutical companies, medical associations, and Hispanic and/or women's groups.  n/a",INTERACTIVE MEDIA FOR WOMEN CONSIDERING HORMONE THERAPY,6229044,R43AG017016,"['DVD /CD ROM', ' Hispanic Americans', ' aging', ' computer assisted medical decision making', ' computer program /software', ' computer system design /evaluation', ' disease /disorder proneness /risk', ' education evaluation /planning', ' estrogens', ' female', ' health education', ' hormone therapy', ' interactive multimedia', ' menopause', ' progestins', "" women's health""]",NIA,SANDIA CONSULTING GROUP,R43,2000,9813,-0.06919710850415783
"3-D SPATIAL MAPPING AND RECKONING FOR SURGICAL DEVICES   DESCRIPTION (Adapted from the applicant's abstract):  Innovative 3-D computer                                                                              vision algorithms that can enable a new generation of ""spatially aware""              instruments by providing real-time absolute positioning capability non-                                                             invasively, similar to the Global Positioning Satellite System for terrestrial       applications, are proposed.  They rely on a spatial reference map that is            constructed during the diagnostic exploration.  The position information can         be used for numerous purposes, including surgical navigation, guidance,              planning, on-line treatment monitoring, error detection, alarms and safety           shutoffs is when the tool strays from the target, change analysis, and even          surgical simulation.  This is a much better paradigm for instrument design           than (the largely unsuccessful) tracking algorithms that measure relative            displacements, and are thus prone to drift and tracking loss.  The proposed          algorithms will operate robustly and accurately at frame rates for extended          periods in poor and variable imaging conditions.  They could be incorporated         into existing clinical instruments without the need for precise calibration,         which is often not possible anyway, because the patient's anatomy (e.g., the         eye) is part of the imaging system.                                                                                                                                       The algorithms will be validated in the context of laser retinal surgery -           compelling as the only long-term proven treatment for the leading blindness-         causing conditions affecting over 20 million people in the US.  Yet, the             current success rate of this procedure is less than 50%, largely due to the          lack of spatial mapping and navigation aids in current clinical instruments.                                                                                              Beyond laser retinal surgery, the algorithms may be applied whenever:  (1)           precise locations on the retina are important (e.g., perimetry); (2) the             retinal periphery is of interest (AIDS/CMV, diabetes); (3) motion compensation       is needed; (4) a tool such as a laser or endoscope is to be monitored or             guided precisely at a chosen location; or 5) even when stable measurements of        the vasculature (retinopathy of prematurity) and retinal changes are of              interest (e.g., angiogenesis research).  Overall, the core methods are               expected to be broadly useful in a number of minimally-invasive surgical             techniques, including emerging alternatives to laser.                                                                                                                     n/a",3-D SPATIAL MAPPING AND RECKONING FOR SURGICAL DEVICES,6085479,R21RR014038,"['bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' clinical research', ' computer assisted diagnosis', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' eye fundus photography', ' eye laser surgery', ' human subject', ' retina disorder', ' surgery material /equipment']",NCRR,RENSSELAER POLYTECHNIC INSTITUTE,R21,2000,98763,-0.004259929917211268
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6180399,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2000,150497,-0.011693569141545516
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10224492,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,233900,-0.02332961214690937
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10017950,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,513041,-0.02332961214690937
"Stakeholder Guidance to Anticipate and Address Ethical Challenges in Applications of Machine Learning and Artificial Intelligence in Algorithmic Medicine: a Novel Empirical Approach PROJECT ABSTRACT The potential for artificial intelligence applications, specifically machine learning, to prevent, predict, and help manage disease sparks immense hope not only for the individuals affected, but also for the overall health of populations. Particularly exciting examples of these novel computing strategies are increasingly found in the development of deep learning algorithms for medical use. Already embedded in our daily lives, algorithms have begun to impact human-decision making, from recruitment and hiring of employees to criminal sentencing. Outside of medicine, recognition of the ways algorithms may reflect, reproduce, and perpetuate bias has led to an explosion of theoretical and empirical research on the subject. There is an increasing awareness of potential algorithmic weaknesses, including some that raise concerns about fundamental issues of fairness, justice, and bias. The need to anticipate and address emerging ethical issues in algorithmic medicine is time- sensitive. As health care systems increasingly utilize algorithms for patient identification, diagnosis, and treatment direction, the consequences of algorithmic bias yield real and significant costs. Numerous stakeholders are responsible for the development, application and interpretation of algorithms in medicine, and yet there has been very little engagement of stakeholders most affected by these learning systems and tools. The overarching goal of this empirical and hypothesis driven project is to articulate the landscape of ethical concerns and the issues emerging in the context of the development, refinement, and application of machine learning in algorithmic medicine. First, we determine the distinct ethical issues and problems encountered in the development, refinement, and application of machine learning, by querying the perspectives of a diverse array of stakeholders involved—machine learning researchers, clinicians, ethicists, and patients. Using the new insights generated from the first half, we will conduct an evidence-based, information-sharing vignette survey to understand the impact of the contexts of algorithms on the ethically salient perspectives of physicians—those poised to implement such innovation in their own decision-making for the care of patients. Maximizing our established record of expertise in empirical ethics investigations, this sequence of projects leverages access to the exceptional machine learning research conducted at Stanford University, including work by NIH-funded investigators, and provides extensive, systematically collected data on ethical issues encountered and anticipated throughout the development and implementation of algorithms. Finally, the project develops and refines an evidence-informed information-sharing survey for use in better understanding how physicians react to intelligent systems. PROJECT NARRATIVE  Machine learning-driven algorithmic medicine now faces an urgent need to anticipate and address emerging ethical issues. For machine learning applications in algorithmic medicine, the failure to examine ethical issues from the perspective of stakeholders will inevitably limit the ecological validity and utility of the algorithms and threaten society's future embrace of these innovations. A hypothesis-driven, empirical study is needed to anticipate and address ethical concerns, and provide clinicians, machine learning researchers, policymakers, and the public with evidence to better enable ethical application and translation of algorithms in medicine.",Stakeholder Guidance to Anticipate and Address Ethical Challenges in Applications of Machine Learning and Artificial Intelligence in Algorithmic Medicine: a Novel Empirical Approach,10099785,R01TR003505,"['Address', 'Adoption', 'Affect', 'Agreement', 'Algorithm Design', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Attitude', 'Awareness', 'Clinical', 'Clinical Investigator', 'Complex', 'Data', 'Decision Making', 'Development', 'Diagnosis', 'Dimensions', 'Disclosure', 'Disease Management', 'Effectiveness', 'Empirical Research', 'Employee', 'Ensure', 'Ethical Issues', 'Ethicists', 'Ethics', 'Evaluation', 'Expert Systems', 'Explosion', 'Face', 'Failure', 'Familiarity', 'Funding', 'Future', 'Goals', 'Health', 'Healthcare Systems', 'Human', 'Human Resources', 'Individual', 'Interview', 'Investigation', 'Judgment', 'Justice', 'Knowledge', 'Learning', 'Machine Learning', 'Medical', 'Medicine', 'Methodology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Perception', 'Persons', 'Physicians', 'Play', 'Randomized', 'Research', 'Research Personnel', 'Role', 'Science', 'Shapes', 'Societies', 'Structure', 'Surveys', 'System', 'Time', 'Training', 'Translations', 'Trust', 'United States National Institutes of Health', 'Universities', 'Work', 'clinical decision-making', 'clinical risk', 'cost', 'court', 'deep learning algorithm', 'evidence base', 'experience', 'improved', 'innovation', 'insight', 'meetings', 'multidisciplinary', 'novel', 'patient population', 'population health', 'precision medicine', 'prevent', 'recruit', 'response', 'tool']",NCATS,STANFORD UNIVERSITY,R01,2020,429327,-0.01656725432411334
"Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures PROJECT SUMMARY/ABSTRACT: Arterial hemorrhage after pelvic fractures is a leading reversible cause of death after blunt trauma. Prediction of arterial bleeding risk is difficult, and currently determined using subjective criteria, often based on qualitative results of admission computed tomography (CT). Segmented hematoma and contrast extravasation (CE) volumes predict need for angioembolization, major transfusion, and mortality but cannot be applied in real-time. The ill-defined multi-focal nature of pelvic hematomas and CE prevents reliable estimation using diameter-based measurements. Dr. Dreizin is a trauma radiologist at the University of Maryland School of Medicine. His early work has focused on improving the speed and reliability of volumetric analysis of pelvic hematomas using semi-automated techniques, and derivation of a logistic regression-based prediction tool for major arterial injury after pelvic fractures. Dr. Dreizin’s goal for this four- year K08 mentored career development award proposal is to gain the skills needed to 1) implement deep learning architectures for automated hematoma volume segmentation and 2) develop computational models for outcome prediction after pelvic trauma. These tools could greatly improve the speed and accuracy of clinical decision making in the setting of life-threatening traumatic pelvic bleeding. Fully convolutional neural networks (FCNs) have emerged as the most robust and scalable method for automated medical image segmentation. Intuitive software platforms for training FCN implementations and generating multivariable machine learning models have been developed in the Python programming environment. The training objectives and research activities of this proposal are necessary to provide Dr. Dreizin with new skills and practical experience in Python programming, deep learning software, and computational modeling software. By understanding the principles and computational infrastructure behind modern machine learning, Dr. Dreizin will be able to train and validate state-of-the-art algorithms independently and effectively lead a team of researchers in this area. To achieve his goals, Dr. Dreizin has assembled a multidisciplinary team of mentors, advisors, and collaborators with world-leading expertise in computer vision in medical imaging, probability theory, data science, and comparative effectiveness research. Dr. Dreizin will focus on two specific aims. In Aim 1, he will train and validate deep learning architectures for segmentation of traumatic pelvic hematomas and CE by computing the Dice metric, time effort, and correlation with clinical outcomes. In Aim 2, he will generate and test quantitative models for predicting major arterial bleeding after pelvic trauma based on a rich multi-label dataset of segmented features. The training and pilot data will be necessary for Dr. Dreizin’s long- term goal of research independence and R01 support to develop automated segmentation algorithms for the spectrum of clinically important imaging features after pelvic trauma, as well as fully automated multivariable clinical prediction tools with potential for translation to industry and as an FDA-cleared product. PROJECT NARRATIVE: Hemorrhage after pelvic fractures is common after motor vehicle collisions, falls, and crush injuries, with mortality rates that range from 5-54%. The volume of hemorrhage, as measured on computed tomography (CT) scans, predicts the need for rapid intervention or transfusion, and is a strong predictor of mortality, but no automated image-processing methods exist for real-time hemorrhage volume measurement. We propose to develop automated software for hemorrhage-detection, and real-time risk prediction software for major arterial hemorrhage after pelvic fractures.",Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures,9955253,K08EB027141,"['Admission activity', 'Adoption', 'Algorithms', 'Angiography', 'Architecture', 'Area', 'Arterial Injury', 'Award', 'Blunt Trauma', 'Caliber', 'Catheters', 'Cause of Death', 'Clinical', 'Communities', 'Comparative Effectiveness Research', 'Computer Models', 'Computer Vision Systems', 'Computer software', 'Crush Injury', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Detection', 'Development', 'Diagnosis', 'Early Intervention', 'Engineering', 'Environment', 'Extravasation', 'Funding', 'Goals', 'Hematoma', 'Hemorrhage', 'Hospitalization', 'Human', 'Image', 'Industry', 'Intervention', 'Intuition', 'K-Series Research Career Programs', 'Knowledge', 'Label', 'Lead', 'Learning', 'Life', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Maryland', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Obesity', 'Outcome', 'Patients', 'Pelvis', 'Predictive Value', 'Probability Theory', 'Process', 'Programming Languages', 'Pythons', 'Radiology Specialty', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Shorthand', 'Speed', 'Supervision', 'Techniques', 'Terminology', 'Testing', 'Therapeutic Embolization', 'Thinness', 'Time', 'Training', 'Transfusion', 'Translations', 'Trauma', 'Treatment outcome', 'Triage', 'Universities', 'Vehicle crash', 'Work', 'X-Ray Computed Tomography', 'adverse outcome', 'algorithm development', 'artificial neural network', 'automated segmentation', 'base', 'clinical decision-making', 'computer infrastructure', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'fall injury', 'hemodynamics', 'heuristics', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'learning strategy', 'medical schools', 'mortality', 'multidisciplinary', 'muscle form', 'neural network architecture', 'outcome prediction', 'pelvis fracture', 'personalized predictions', 'predictive modeling', 'prevent', 'primary outcome', 'radiologist', 'random forest', 'real time model', 'secondary outcome', 'segmentation algorithm', 'skills', 'standard of care', 'support vector machine', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF MARYLAND BALTIMORE,K08,2020,186183,-0.012230453580440155
"Transfer learning to improve the re-usability of computable biomedical knowledge Candidate: With my multidisciplinary background in Artificial Intelligence (PhD), Public Health Informatics (MS), Epidemiology and Health Statistics (MS), and Preventive Medicine (Bachelor of Medicine), my career goal is to become an independent investigator working at the intersection of Artificial Intelligence and Biomedicine, with a particular emphasis initially in machine learning and public health. Training plan: My K99/R00 training plan emphasizes machine learning, deep learning and scientific communication skills (presentation, writing articles, and grant applications), which will complement my current strengths in artificial intelligence, statistics, medicine and public health. I have a very strong mentoring team. My mentors, Drs. Michael Becich (primary), Gregory Cooper, Heng Huang, and Michael Wagner, all of whom are experienced with research and professional career development. Research plan: The research goal of my proposed K99/R00 grant is to increase the re-use of computable biomedical knowledge, which is knowledge represented in computer-interpretable formalisms such as Bayesian networks and neural networks. I refer to such representations as models. Although models can be re-used in toto in another setting, there may be loss of performance or, even more problematically, fundamental mismatches between the data required by the model and the data available in the new setting making their re-use impossible. The field of transfer learning develops algorithms for transferring knowledge from one setting to another. Transfer learning, a sub-area of machine learning, explicitly distinguishes between a source setting, which has the model that we would like to re-use, and a target setting, which has data insufficient for deriving a model from data and therefore needs to re-use a model from a source setting. I propose to develop and evaluate several Bayesian Network Transfer Learning (BN- TL) algorithms and a Convolutional Neural Network Transfer Learning algorithm. My specific research aims are to: (1) further develop and evaluate BN-TL for sharing computable knowledge across healthcare settings; (2) develop and evaluate BN-TL for updating computable knowledge over time; and (3) develop and evaluate a deep transfer learning algorithm that combines knowledge in heterogeneous scenarios. I will do this research on models that are used to automatically detect cases of infectious disease such as influenza. Impact: The proposed research takes advantage of large datasets that I previously developed; therefore I expect to quickly have results with immediate implications for how case detection models are shared from a region that is initially experiencing an epidemic to another location that wishes to have optimal case-detection capability as early as possible. More generally, it will bring insight into machine learning enhanced biomedical knowledge sharing and updating. This training grant will prepare me to work independently and lead efforts to develop computational solutions to meet biomedical needs in future R01 projects. Transfer learning to improve the re-usability of computable biomedical knowledge Narrative Re-using computable biomedical knowledge in the form of a mathematical model in a new setting is challenging because the new setting may not have data needed as inputs to the model. This project will develop and evaluate transfer learning algorithms, which are computer programs that adapt a model to a new setting by removing and adding local variables to it. The developed methods for re-using models are expected to benefit the public’s health by: (1) improving case detection during epidemics by enabling re-use of automatic case detectors developed in the earliest affected regions with other regions, and, more generally, (2) increasing the impact of NIH’s investment in machine learning by enabling machine-learned models to be used in more institutions and locations.",Transfer learning to improve the re-usability of computable biomedical knowledge,9952803,K99LM013383,"['Affect', 'Algorithms', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Bayesian Method', 'Bayesian Modeling', 'Bayesian Network', 'Big Data', 'Clinical', 'Communicable Diseases', 'Communication', 'Complement', 'Computerized Medical Record', 'Computers', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Epidemic', 'Epidemiology', 'Future', 'Goals', 'Grant', 'Health', 'Healthcare Systems', 'Heterogeneity', 'Influenza', 'Institution', 'Investigation', 'Investments', 'Knowledge', 'Lead', 'Location', 'Lung diseases', 'Machine Learning', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Parainfluenza', 'Patients', 'Performance', 'Play', 'Preventive Medicine', 'Process', 'Psychological Transfer', 'Public Health', 'Public Health Informatics', 'Research', 'Research Personnel', 'Role', 'Semantics', 'Societies', 'Source', 'Testing', 'Time', 'Training', 'Twin Multiple Birth', 'Unified Medical Language System', 'United States National Institutes of Health', 'Universities', 'Update', 'Utah', 'Work', 'Writing', 'base', 'career', 'career development', 'computer program', 'convolutional neural network', 'deep learning', 'deep neural network', 'detector', 'experience', 'health care settings', 'improved', 'insight', 'large datasets', 'learning algorithm', 'mathematical model', 'multidisciplinary', 'neural network', 'skills', 'statistics', 'usability']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2020,92359,-0.04060154487899533
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9979659,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'MeSH Thesaurus', 'Measures', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'large scale data', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'public repository', 'specific biomarkers']",NLM,UNIVERSITY OF CENTRAL FLORIDA,U01,2020,467177,-0.01865859727934722
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,9972588,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,318155,-0.02956923735322826
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,9941090,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Catalogs', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2020,605875,-0.008592928994367106
"Machine learning approaches for improved accuracy and speed in sequence annotation Summary/Abstract Alignment of biological sequences is a key step in understanding their evolution, function, and patterns of activity. Here, we describe Machine Learning approaches to improve both accuracy and speed of highly- sensitive sequence alignment. To improve accuracy, we develop methods to reduce erroneous annotation caused by (1) the existence of low complexity and repetitive sequence and (2) the overextension of alignments of true homologs into unrelated sequence. We describe approaches based on both hidden Markov models and Artificial Neural Networks to dramatically reduce these sorts of sequence annotation error. We also address the issue of annotation speed, with development of a custom Deep Learning architecture designed to very quickly filter away large portions of candidate sequence comparisons prior to the relatively-slow sequence-alignment step. The results of these efforts will be incorporated into forks of the open source sequence alignment tools HMMER, MMSeqs, and (where appropriate) BLAST; we will also work with community developers of annotation pipelines, such as RepeatMasker and IMG/M, to incorporate these approaches. The development and incorporation into these widely used bioinformatics tools will lead to widespread impact on sequence annotation efforts. Narrative Modern molecular biology depends on effective methods for creating sequence alignments quickly and accurately. This proposal describes a plan to develop novel Machine Learning approaches that will dramatically increase the speed of highly-sensitive sequence alignment, and will also address two significant sources of erroneous sequence annotation, (i) the presence of repetitive sequence in biological sequences, and (ii) the tendency for sequence alignment algorithms to extend alignments beyond the boundaries of true homology. The proposed methods represent a mix of applications of hidden Markov models and Artificial Neural Networks, and build on prior success in applying such methods to the problem of sensitive sequence annotation.",Machine learning approaches for improved accuracy and speed in sequence annotation,10020995,R01GM132600,"['Address', 'Algorithms', 'Architecture', 'Bioinformatics', 'Biological', 'Classification', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Custom', 'DNA Transposable Elements', 'Data Set', 'Deletion Mutation', 'Descriptor', 'Development', 'Error Sources', 'Evolution', 'Foundations', 'Genome', 'Genomics', 'Hour', 'Human', 'Human Genome', 'Industry Standard', 'Insertion Mutation', 'Institutes', 'Intervention', 'Joints', 'Label', 'Letters', 'Licensing', 'Machine Learning', 'Manuals', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Molecular Biology', 'Network-based', 'Nucleotides', 'Pattern', 'Pilot Projects', 'Proteins', 'Repetitive Sequence', 'Sequence Alignment', 'Sequence Analysis', 'Source', 'Speed', 'Statistical Models', 'Takifugu', 'Work', 'annotation  system', 'artificial neural network', 'base', 'bioinformatics tool', 'computing resources', 'convolutional neural network', 'deep learning', 'density', 'design', 'genomic data', 'improved', 'markov model', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'software development', 'statistics', 'success', 'tool']",NIGMS,UNIVERSITY OF MONTANA,R01,2020,287504,-0.03589934916451005
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10133362,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk stratification', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data ', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2020,358890,-0.018073284224928106
"Synergistic integration of topology and machine learning for the predictions of protein-ligand binding affinities and mutation impacts Project Summary Fundamental challenges that hinder the current understanding of biomolecular systems are their tremendous complexity, high dimensionality and excessively large data sets associated with their geometric modeling and simulations. These challenges call for innovative strategies for handling massive biomolecular datasets. Topology, in contrast to geometry, provides a unique tool for dimensionality reduction and data simplification. However, traditional topology typically incurs with excessive reduction in geometric information. Persistent homology is a new branch of topology that is able to bridge traditional topology and geometry, but suffers from neglecting biological information. Built upon PI’s recent work in the topological data analysis of biomolecules, this project will explore how to integrate topological data analysis and machine learning to significantly improve the current state-of-the-art predictions of protein-ligand binding and mutation impact established in the PI’s preliminary studies. These improvements will be achieved through developing physics-embedded topological methodologies and advanced deep learning architectures for tackling heterogeneous biomolecular data sets arising from a variety of physical and biological considerations. Finally, the PI will establish robust databases and online servers for the proposed predictions. Project Narrative The project concerns the integration of topological data analysis and machine learning architectures for the predictions of protein-ligand binding affinities and mutation induced protein stability changes from massive data sets. This new data approach has considerable impact for future generation methods in computational biophysics and drug design.",Synergistic integration of topology and machine learning for the predictions of protein-ligand binding affinities and mutation impacts,9989158,R01GM126189,"['3-Dimensional', 'Address', 'Affinity', 'Architecture', 'Big Data', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biophysics', 'Characteristics', 'Chemicals', 'Classification', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Dimensions', 'Drug Design', 'Electrostatics', 'Elements', 'Free Energy', 'Freedom', 'Future Generations', 'Geometry', 'Handwriting', 'Image Analysis', 'Induced Mutation', 'Ions', 'Learning', 'Ligand Binding', 'Ligands', 'Lipids', 'Machine Learning', 'Medical', 'Membrane', 'Membrane Proteins', 'Metals', 'Methodology', 'Methods', 'Mutation', 'Physics', 'Plant Roots', 'Proteins', 'Psychological Transfer', 'Site', 'Speech', 'System', 'Techniques', 'Thermodynamics', 'Work', 'algebraic topology', 'base', 'cofactor', 'data warehouse', 'deep learning', 'deep learning algorithm', 'direct application', 'diverse data', 'high dimensionality', 'improved', 'innovation', 'language processing', 'large datasets', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'metallicity', 'models and simulation', 'multi-task learning', 'multitask', 'mutant', 'neglect', 'next generation', 'search engine', 'tool', 'trend', 'user-friendly']",NIGMS,MICHIGAN STATE UNIVERSITY,R01,2020,318777,-0.03634541068929208
"AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition ABSTRACT Dietary intake is a complex human behavior that drives disease risk and corresponding economic and healthcare burdens worldwide. Poor diet is the leading cause of death in the US and a known driver of obesity – a global epidemic. A major contributor to poor diet is food eaten away from home, such as restaurant foods. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods. Accurate approaches and tools to evaluate food and nutrient intake are essential in monitoring the nutritional status of individuals. There is a critical need for real-time data capture that minimizes burden and reduces error. While progress has been made, there is no tool available that accurately and automatically estimates foods left unconsumed in a meal. Two major limitations of existing systems is the reliance of a fiducial marker for food detection and volume estimation, and reliance on humans – either the respondent or a trained researcher – to estimate the portion of food leftover. This application leverages novel technology to remove those limitations. The long-term research goal is to utilize digital imaging (DI), artificial intelligence (AI) and computer vision (CV) techniques to develop a novel hybrid methodology for rapid, accurate measurement of dietary intake. To attain this goal, our objective in this R21 application is to refine and test a system architecture that (a) uses digital images to record dietary intake in real-time and (b) uses AI and CV techniques to identify food/beverage items and determine amounts leftover. We plan to build on our current prototype in which digital food images are captured before and after the meal, analyzed to detect the food items, a three-dimensional (3-D) virtual model constructed, and volume remaining after the meal estimated, which will be used to calculate the amount leftover based on the initial volume. Volume consumed will be converted to weight and linked to public-use nutrition information. These calorie estimates will be compared against calories those from (a) DIs coded by trained research staff and (b) weighed plate waste methodology. Our expectation is to develop a valid system architecture for rapidly estimating dietary intake. The outcome of this proposal is expected to have a significant positive impact, enabling nutrition and health researchers to collect high-quality food consumption data in real world settings, increasing knowledge of dietary patterns and improving capacity to assess dietary interventions. This work will lead to an R01 application that will expand food types and meal settings and test the utility of our system among consumers. Project Narrative Solutions to address the global obesity epidemic are urgently needed. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods, a known driver of obesity. This study integrates nutrition science, computer science, and engineering to develop and test a new method for assessing dietary intake, and if successful would yield a rapid, reliable, accurate and cost- effective tool.",AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition,9978495,R21CA250024,"['3-Dimensional', 'Address', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Behavior', 'Beverages', 'Body Weight decreased', 'Calories', 'Cause of Death', 'Cellular Phone', 'Code', 'Complex', 'Computer Vision Systems', 'Consumption', 'Data', 'Databases', 'Detection', 'Development', 'Diet', 'Diet Records', 'Dietary Assessment', 'Dietary Intervention', 'Dietary Practices', 'Dietary intake', 'Economics', 'Engineering', 'Epidemic', 'Food', 'Goals', 'Gold', 'Health', 'Healthcare', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Intake', 'Intervention', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Nutrient', 'Nutritional Science', 'Nutritional status', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Output', 'Participant', 'Research', 'Research Personnel', 'Research Training', 'Respondent', 'Restaurants', 'Side', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Validation', 'Weight', 'Work', 'base', 'computer science', 'cost', 'cost effective', 'design', 'digital', 'digital imaging', 'disorder risk', 'expectation', 'food consumption', 'food quality', 'handheld mobile device', 'improved', 'knowledge base', 'new technology', 'novel', 'nutrition', 'prototype', 'success', 'system architecture', 'tool', 'virtual model', 'wasting', 'weight maintenance']",NCI,TUFTS UNIVERSITY BOSTON,R21,2020,222002,-0.018718183580865626
"Neuroethical analysis of data sharing in the OpenNeuro project: Administrative supplement PROJECT SUMMARY/ABSTRACT Data sharing is essential to maximize the contributions of research subjects and the public’s investment in scientific research, but human subjects research also requires strong protection of the privacy and confidentiality of research subjects. This supplement will support an expert in neuroethics to undertake a rigorous ethical and regulatory analysis of data sharing policies, focusing in particular on the threats by artificial intelligence and machine learning techniques to reidentify neuroimaging datasets that have been thought to be deidentified. This research will lay the foundation for a sound data sharing policy for the OpenNeuro project and a regulatory framework to provide for the adequate protection of neuroimaging data while maximizing the benefits of data sharing. Project Narrative Data sharing is essential to maximize the contributions of research subjects and the public’s investment in scientific research, but human subjects research also requires strong protection of the privacy and confidentiality of research subjects. This supplement will support an expert in neuroethics to undertake a rigorous ethical and regulatory analysis of data sharing policies, focusing in particular on the threats by artificial intelligence and machine learning techniques to reidentify neuroimaging datasets that have been thought to be deidentified. This research will lay the foundation for a sound data sharing policy for the OpenNeuro project and a regulatory framework to provide for the adequate protection of neuroimaging data while maximizing the benefits of data sharing",Neuroethical analysis of data sharing in the OpenNeuro project: Administrative supplement,10149058,R24MH117179,"['Address', 'Administrative Supplement', 'Archives', 'Artificial Intelligence', 'Award', 'BRAIN initiative', 'Benefits and Risks', 'Consent Forms', 'Country', 'Data', 'Data Analyses', 'Data Security', 'Data Set', 'Ensure', 'Ethics', 'Foundations', 'Funding', 'Future', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Subject Research', 'International', 'Investments', 'Laws', 'Legal', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Neurosciences', 'Parents', 'Policies', 'Privacy', 'Process', 'Regulation', 'Research', 'Research Subjects', 'Risk', 'Security Measures', 'Series', 'Software Tools', 'Solid', 'Surveys', 'Techniques', 'United States', 'United States National Institutes of Health', 'data archive', 'data privacy', 'data sharing', 'design', 'human subject', 'human subject protection', 'machine learning algorithm', 'neuroethics', 'neuroimaging', 'novel', 'prevent', 'privacy protection', 'research study', 'sharing platform', 'sound', 'stem']",NIMH,STANFORD UNIVERSITY,R24,2020,126592,-0.017227273127879073
"A Machine Learning-Based Mobile Application and Cloud Platform to Enable Accurate and Streamlined Surveillance of Soil-Transmitted Helminth Infection and Schistosomiasis PROJECT SUMMARY/ABSTRACT Soil-transmitted helminth (STH) infections and schistosomiasis affect 2 billion people and have significant detrimental effects on health. Strategies to implement STH and schistosomiasis interventions currently rely on testing for these parasites by microscopic analysis of stool samples to detect parasite eggs and identify egg species. Accurate surveillance testing and timely and accurate reporting of results are required for effective decision-making at the programmatic level to implement infection control strategies. Approaches that increase the speed and standardize the accuracy of microscopy-based testing and streamline reporting could help eliminate STH infections and schistosomiasis. We propose to develop a mobile phone-based STH-schistosome egg identification and counting tool that employs machine learning (deep learning) and works in the absence of an internet connection. With this app, users will collect surveillance data for integration into a cloud platform. Surveillance data can then be visualized in dashboards to inform interventions to control disease. Our approach is fundamentally different from other published work that develop machine learning algorithms for STH and schistosomiasis because it will very accurately identify egg types during surveillance activities, and it will be available to users in an app and integrate with cloud storage and reporting. Our interdisciplinary team combines the expertise of global health researchers, product usability testing experts, microscopists, and data scientists. In the R21 phase, we will collect the largest ever microscopy image set of STH and schistosome eggs (> 15 000). We will train an algorithm based on convolutional neural networks that make highly accurate parasite egg classification (species identification) and embed this algorithm into a mobile app that works without internet connectivity. To promote app utility, we will evaluate its accuracy and usability in a surveillance setting. We established the feasibility of our approach in preliminary data by building a web app that serves the results of a deep learning model that identifies STH and schistosome eggs with > 98% accuracy. The R33 phase will be only undertaken if well-defined milestones are achieved. We will further develop the mobile app as a data capture system that will integrate with cloud storage and a dynamic data visualization system to enable increased accuracy in STH and schistosomiasis surveillance over time and across geographic location. ​Validation studies will assess the​ benefits of the system to time and cost savings and quality of data collected during surveillance activities. The overall goal of this work is to increase the accuracy and streamline STH and schistosomiasis surveillance to enable effective decision-making in disease control. PROJECT NARRATIVE Accurate surveillance testing in the field and timely and accurate reporting of results are required for effective decision-making by soil-transmitted helminth (STH) infection and schistosomiasis control and prevention programs. This project will develop and test a mobile phone-based STH-schistosomiasis diagnostic system that employs machine learning to very accurately identify and count parasite eggs from microscopy images of stool samples. This mobile app will work in the absence of any internet connection and will streamline collection of surveillance data for integration into a cloud-based surveillance platform that increases data visibility.",A Machine Learning-Based Mobile Application and Cloud Platform to Enable Accurate and Streamlined Surveillance of Soil-Transmitted Helminth Infection and Schistosomiasis,10058110,R21TW011753,"['Affect', 'Algorithms', 'Architecture', 'Car Phone', 'Classification', 'Collection', 'Cost Savings', 'Data', 'Data Aggregation', 'Data Collection', 'Data Scientist', 'Databases', 'Decision Making', 'Diagnostic', 'Feedback', 'Future', 'Geographic Locations', 'Goals', 'Health', 'Helminths', 'Image', 'Infection Control', 'Internet', 'Intervention', 'Location', 'Machine Learning', 'Microscope', 'Microscopic', 'Microscopy', 'Modeling', 'Pain', 'Parasites', 'Parasitic infection', 'Phase', 'Prevention', 'Prevention program', 'Process', 'Publishing', 'Reporting', 'Research Personnel', 'Schistosoma', 'Schistosomiasis', 'Soil', 'Speed', 'Standardization', 'Surface', 'System', 'Testing', 'Time', 'Validation', 'Work', 'algorithm training', 'base', 'cloud based', 'cloud platform', 'cloud storage', 'convolutional neural network', 'cost', 'dashboard', 'data access', 'data integration', 'data visualization', 'deep learning', 'design', 'digital', 'disorder control', 'egg', 'global health', 'helminth infection', 'improved', 'machine learning algorithm', 'microscopic imaging', 'mobile application', 'prevent', 'product development', 'stool sample', 'surveillance data', 'tool', 'transmission process', 'usability', 'validation studies', 'web app']",FIC,"PARASITE ID, CORP.",R21,2020,186698,-0.0217737288081583
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy Project Summary/Abstract Artificial intelligence on genomic/healthcare data that is performed jointly between multiple collaborating institutions relies on a trust model but can accelerate genomic medicine research and facilitate quality improvement. To conduct such machine learning while protecting patient privacy and reducing security risks, we are developing blockchain-based privacy-preserving learning methods in a K99/R00 study supported by the National Human Genome Research Institute (NHGRI). However, our previous design of privacy-preserving learning on private blockchain assumed “semi-honesty” as the underlying adversary assumption. That is, we assume that each participating site is curious yet very careful and honest, such that it would only submit correct predictive models. Nevertheless, in real world this assumption may be too optimistic; the models submitted could be an old one due to network latency or malicious users may try to create fake models, which can in turn lead to bioethical concerns and reduce the incentives for genomic/clinical institutions to participate in the collaborative predictive modeling. Therefore, the capability to detect, assess and prevent “model misconducts” is critical to increase the integrity/reliability of machine learning. To address this issue, we consider the following 3 types of model misconducts: (1) model plagiarism, of which a site becomes a free-rider and just submits a copy of a model from the other sites, trying to hide their own information and inspect models from other sites; (2) model fabrication, of which a site mocks up a model, trying to hide information and disturb the machine learning process; and (3) model falsification, of which a site tweaks its model a bit, trying to just disturb the learning process. For each type of the model misconducts, we are interest in how to detect these misconducts of another site, how to assess the losses of machine learning results due to misconducts, and how to prevent these model misconducts. Our aims include (a) detecting model misconducts using model properties, (b) assessing model misconducts losses via model simulation, and (c) preventing model misconducts based on whole model history. The innovative components to our proposed project include (i) summarizing various types of model misconduct, (ii) developing a complete strategy to handle the model misconduct, and (iii) providing a generalizable approach to mitigate bioethical concerns for collaborative machine learning. Project Narrative Artificial intelligence performed jointly between multiple collaborating institutions can accelerate genomic medicine research and facilitate quality improvement, but relies on a trust model which may be too optimistic in real-world setting. In this project, we plan to develop a comprehensive detection, assessment and prevention mechanism to address the potential bioethical risks brought by misconducts of model plagiarism, fabrication, and falsification. The proposed study can supplement the considerations of model misconducts for our original project of privacy-preserving learning on blockchain.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,10130868,R00HG009680,"['Address', 'Artificial Intelligence', 'Bioethics', 'Budgets', 'Calibration', 'Clinical', 'Data', 'Data Set', 'Detection', 'Digit structure', 'Discrimination', 'Event', 'Genomic medicine', 'Genomics', 'Healthcare', 'Incentives', 'Institution', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'National Human Genome Research Institute', 'Pattern', 'Plagiarism', 'Prevention', 'Privacy', 'Privatization', 'Process', 'Property', 'Randomized', 'Recording of previous events', 'Research', 'Risk', 'Security', 'Site', 'Sum', 'Testing', 'Time', 'Trust', 'base', 'blockchain', 'design', 'distributed ledger', 'innovation', 'interest', 'learning strategy', 'models and simulation', 'patient privacy', 'predictive modeling', 'prevent', 'privacy preservation', 'statistics']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R00,2020,102049,-0.017629112188843256
"Real-time Non-Rigid 3D Reconstruction and Registration for Laparoscopic-guided Minimally Invasive Liver Surgery Project Summary/Abstract Liver deformation leads to difficulties in tumor localization during minimally invasive liver surgery (MILS). The goal of this proposal is to develop an efficient surgical navigation tool for MILS by compensating for liver deformation and mapping preoperative data to the patient’s anatomy. Specifically, we will develop a non-rigid simultaneously localization and mapping (SLAM) approach to estimate the deformation of liver surface from stereo laparoscopy videos. We will develop machine-learning methods to detect landmarks and perform non- rigid registration. The algorithms will be implemented on a GPU to achieve real-time. Preliminary data has demonstrated the feasibility. During the R00 phase, we will mainly address the clinical needs and develop novel ways to provide intraoperative guidance. This project will greatly improve the tumor resection accuracy in MILS. The candidate for this award Dr. Haoyin Zhou is a postdoc at Surgical Planning Laboratory (SPL), Brigham and Women’s Hospital (BWH) and Harvard Medical School (HMS). Dr. Zhou has extensive experience and expertise in computer vision, machine learning and their applications in medicine. BWH is an international leader in basic, clinical and translational research on human diseases, and has established multiple research programs to promote the work and professional career development of young investigators. National Center for Image Guided Therapy, and Advanced Multi-modality Image Guided Operating (AMIGO) suite will greatly support this research. Dr. Zhou’s long-term research goal is to develop and apply advanced computer vision and machine learning technologies to improve understanding, diagnosis, treatment, and prevention of diseases for better health care. His long-term career goal is to become an independent investigator working at the frontier of medical image processing and image-guided therapy. To achieve these goals, Dr. Zhou plans to receive more education and training in the following four areas: (1) Critical training in conducting translational research in the hospital environment with surgeons and radiologists, (2) knowledge in the development of technologies for surgical guidance, (3) training in machine learning and its applications in medicine, and (4) training on writing grant applications independently and seeking funding. Dr. Zhou will participate in formal courses selected from Harvard, Harvard Catalyst, MIT CSAIL and Stanford Courses. He will attend weekly seminars at BWH, HMS and MIT. He will also attend one or two academic conferences per year to discuss his work and meet with experts in the field. A strong mentoring team, including one primary mentor, three co-mentors, and two collaborators, has been organized for the K99 phase of this award, which will provide solid support on both research and career development to Dr. Zhou based on their well-established expertise in diverse research fields. Prof. William M. Wells III (primary mentor) is a professor in medical image processing. Prof. Jayender Jagadeesan (co-mentor) is an assistant professor in surgical robotics and surgical navigation. Drs. Ali Tavakkoli and Jiping Wang (co- mentors) are experienced surgeons. All mentors and collaborators are from BWH, HMS. Project Narrative  Minimally invasive liver surgery (MILS) has many potential advantages but liver deformation leads to significant difficulties in localizing tumors and avoiding main vessels accurately. This project aims to develop a novel surgical navigation approach as a tool to guide MILS intraoperatively. Novel computer vision and machine learning algorithms, including GPU-based non-rigid simultaneously localization and mapping (SLAM), learning- based landmarks recognition and non-rigid registration will be developed to compensate for live deformation and map preoperative data to the patient’s anatomy in real-time during MILS.",Real-time Non-Rigid 3D Reconstruction and Registration for Laparoscopic-guided Minimally Invasive Liver Surgery,10017968,K99EB027177,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Applications Grants', 'Area', 'Award', 'Basic Science', 'Binocular Vision', 'Blood', 'Carbon Dioxide', 'Clinical', 'Clinical Research', 'Color', 'Computer Vision Systems', 'Computer software', 'Data', 'Dependence', 'Detection', 'Devices', 'Diagnosis', 'Diagnostic', 'Environment', 'Excision', 'Family suidae', 'Feedback', 'Funding', 'Goals', 'Healthcare', 'Hemorrhage', 'Hepatic', 'Hospitals', 'Image', 'International', 'Knowledge', 'Laboratories', 'Laparoscopes', 'Laparoscopy', 'Learning', 'Liver', 'Liver neoplasms', 'Location', 'Machine Learning', 'Malignant neoplasm of liver', 'Maps', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Motion', 'Multimodal Imaging', 'Navigation System', 'Operating Rooms', 'Operative Surgical Procedures', 'Patients', 'Phase', 'Pneumoperitoneum', 'Postdoctoral Fellow', 'Procedures', 'Psyche structure', 'Recovery', 'Research', 'Research Personnel', 'Research Support', 'Respiration', 'Robotics', 'Solid', 'Stress', 'Structure', 'Supervision', 'Surface', 'Surgeon', 'Surgical Instruments', 'System', 'Technology', 'Texture', 'Time', 'Tissues', 'Titan', 'Training', 'Training and Education', 'Translational Research', 'Trauma patient', 'Ultrasonography', 'Uncertainty', 'United States National Institutes of Health', 'Woman', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'cancer diagnosis', 'career', 'career development', 'catalyst', 'deep learning', 'design', 'disorder prevention', 'experience', 'frontier', 'haptic feedback', 'human disease', 'image guided', 'image guided therapy', 'image processing', 'image registration', 'improved', 'in vivo', 'machine learning algorithm', 'machine learning method', 'medical schools', 'minimally invasive', 'novel', 'postoperative recovery', 'professor', 'programs', 'prototype', 'radiologist', 'reconstruction', 'research and development', 'research clinical testing', 'symposium', 'technology development', 'three-dimensional visualization', 'tissue reconstruction', 'tool', 'tumor', 'uptake', 'virtual']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,K99,2020,93240,-0.03501927974422041
"Automatic Organ Segmentation Tool for Radiation Treatment Planning of Cancers ABSTRACT As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention, which is critical in reducing long term toxicity of cancers. To avoid excessively high radiation doses to organs-at-risk (OARs), OARs need to be correctly segmented from simulation computed tomography (CT) scans during radiation treatment planning to get an accurate dose distribution. Despite tremendous effort in developing semi- or fully-automatic segmentation solutions, current automated segmentation software, mostly using the atlas-based methods, has not yet reached the level of accuracy and robustness required for clinical usage. Therefore, in current practice, significant manual efforts are still required in the OAR segmentation process. Manual contouring suffers from inter- and intra-observer variability, as well as institutional variability where different sites adopt distinct contouring atlases and labeling criteria, thus leading to inaccuracy and variability in OAR segmentation. When OARs are very close to the treatment target, segmentation errors as small as a few millimeters can have a statistically significant impact on dosimetry distribution and outcome. In addition, it is also costly and time consuming as it can take 1-2 hours of a clinicians’ time to segment major thoracic organs due to the large number of axial slices required. In summary, an accurate and fast process for segmenting OARs in treatment planning using CT scans is needed for improving patient outcomes and reducing the cost of radiation therapy of cancers. In recent years, the rapid development of deep learning methods has revolutionized many computer-vision areas and the adoption of deep learning in medical applications has shown great success. Based on a deep-learning-based algorithm we developed that achieved better-than-human performance and ranked 1st in 2017 American Association of Physicist in Medicine Thoracic Auto-segmentation Challenge, an automatic OAR segmentation product will be developed in this project with the three aims: 1) further improve the performance and robustness of OAR segmentation algorithms, focusing on addressing the heterogeneity issue of different clinical environments; 2) further enrich the functionalities and enhance usability of the cloud- based software product; and 3) perform clinical validation study on the algorithm performance and software usability at collaborating sites. With this product, the segmentation accuracy can be improved, leading to more robust treatment plans in protecting normal organs and improved long term patient outcome. The time and cost of radiation treatment planning can be greatly reduced, contributing to a more affordable cancer treatment and reduced healthcare burden. NARRATIVE As early detection and better treatment have increased cancer patient survival rates, the importance of protecting normal organs during radiation treatment is drawing more attention. To avoid excessively high radiation doses to such organs-at-risk (OARs), they are required to be correctly segmented from simulation computed tomography (CT) scans. A deep-learning-based automatic OAR segmentation product developed in this project can improve the segmentation accuracy and reduce the time and cost of radiation treatment planning as compared with the current manual process, leading to improved long term patient outcome and reduced cancer treatment cost.",Automatic Organ Segmentation Tool for Radiation Treatment Planning of Cancers,10081752,R44CA254844,"['3-Dimensional', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'American', 'Area', 'Artificial Intelligence', 'Atlases', 'Attention', 'Body Regions', 'Body part', 'Cancer Patient', 'Chest', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Data', 'Development', 'Digital Imaging and Communications in Medicine', 'Dose', 'Early Diagnosis', 'Environment', 'Healthcare', 'Heterogeneity', 'Hour', 'Human', 'Image', 'Intraobserver Variability', 'Label', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Medical', 'Medicine', 'Methods', 'Modality', 'Modeling', 'Online Systems', 'Organ', 'Outcome', 'Patient-Focused Outcomes', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Radiation Dose Unit', 'Radiation therapy', 'Risk', 'Scanning', 'Site', 'Slice', 'Survival Rate', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Treatment Cost', 'Update', 'X-Ray Computed Tomography', 'algorithm development', 'automated segmentation', 'base', 'cancer radiation therapy', 'cancer therapy', 'clinical heterogeneity', 'cloud based', 'commercialization', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'dosimetry', 'healthcare community', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'life-long learning', 'millimeter', 'novel', 'phase 1 study', 'prototype', 'satisfaction', 'segmentation algorithm', 'simulation', 'software development', 'success', 'tool', 'treatment planning', 'usability', 'user-friendly', 'validation studies']",NCI,"CARINA MEDICAL, LLC",R44,2020,1000000,-0.03622102988076689
"Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models Project Summary Amyotrophic lateral sclerosis (ALS) and Frontotemporal Dementia FTD are devastating neurodegenerative disorders that lie on a genetic and mechanistic continuum. ALS is a disease of motor neurons that that is almost uniformly lethal within only 3-5 years of diagnosis. FTD is a heterogeneous, rapidly progressing syndrome that is among the top three causes of presenile dementia. About 10% of ALS cases are caused by dominantly transmitted gene defects. SOD1 and FUS mutations cause aggressive motor neuron pathology while TDP43 mutations cause ALS-FTD. Further, wild type FUS and TDP43 are components of abnormal inclusions in many FTD cases, suggesting a mechanistic link between these disorders. Early phenotypes are of particular interest because these could lead to targeted interventions aimed at the root cause of the disorder that could stem the currently inexorable disease progression. Elucidating such early, potentially shared characteristics of these disorders should be greatly aided by: 1) knock-in animal models expressing familial ALS-FTD genes; 2) sensitive, rigorous and objective behavioral phenotyping methods to analyze and compare models generated in different laboratories. In published work the co-PIs applied their first-generation, machine vision-based automated phenotyping method, ACBM ‘1.0’ (automated continuous behavioral monitoring) to detect and quantify the earliest-observed phenotypes in Tdp43Q331K knock-in mice. This method entails continuous video recording for 5 days to generate >14 million frames/mouse. These videos are then scored by a trained computer vision system. In addition to its sensitivity, objectivity and reproducibility, a major advantage of this method is the ability to acquire and archive video recordings and to analyze the data at sites, including the Cloud, remote from those of acquisition. We will use Google Cloud TPUs supercomputers that have been designed from the ground up to accelerate cutting-edge machine learning workloads, with a special focus on deep learning. We will analyze this data using Bayesian hierarchical spline models that describe the different mouse behaviors along the circadian rhythm. The current proposal has two main goals: 1) Use deep learning to refine and apply a Next Generation ACBM - ‘2.0’ - that will allow for more sensitive, expansive and robust automated behavioral phenotyping of four novel knock-in models along with the well characterized SOD1G93A transgenic mouse. 2) To establish and validate procedures to enable remote acquisition of video recording data with cloud-based analysis. Our vision is to establish sensitive, robust, objective, and open-source machine vision-based behavioral analysis tools that will be widely available to researchers in the field. Since all the computer-annotated video data is standardized in ACBM 2.0 and will be archived, we envision a searchable ‘behavioral database’, that can be freely mined and analyzed. Such tools are critical to accelerate the development of novel and effective therapeutics for ALS-FTD. Narrative ALS and Frontotemporal Dementia (FTD) are devastating, rapidly progressing diseases and current treatments are of limited value. In this proposal a neuroscientist and a computer scientist have teamed up to develop a new machine vision-based method for behavioral analysis novel mouse models of ALS-FTD. The ultimate goal is to reveal early phenotypes in ALS-FTD models that can be used in understanding disease pathology and in the development of new therapeutic targets.",Next generation machine vision for automated behavioral phenotyping of knock-in ALS-FTD mouse models,9979408,R21NS112743,"['Amyotrophic Lateral Sclerosis', 'Animal Model', 'Archives', 'Behavior', 'Behavior monitoring', 'Behavioral', 'Characteristics', 'Circadian Rhythms', 'Computer Vision Systems', 'Computers', 'Data', 'Data Set', 'Databases', 'Defect', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Expression Profiling', 'Familial Amyotrophic Lateral Sclerosis', 'Frontotemporal Dementia', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Hour', 'Human', 'Intervention', 'Knock-in', 'Knock-in Mouse', 'Laboratories', 'Lead', 'Link', 'Machine Learning', 'Methods', 'Modeling', 'Motor Neuron Disease', 'Motor Neurons', 'Mus', 'Mutation', 'Neurodegenerative Disorders', 'Paralysed', 'Pathology', 'Phenotype', 'Plant Roots', 'Presenile Dementia', 'Procedures', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Respiratory Paralysis', 'Scientist', 'Site', 'Standardization', 'Syndrome', 'TensorFlow', 'Time', 'Training', 'Transgenic Mice', 'Transgenic Organisms', 'Treatment Efficacy', 'Video Recording', 'Vision', 'Work', 'Workload', 'base', 'behavioral phenotyping', 'cloud based', 'data archive', 'deep learning', 'design', 'frontotemporal lobar dementia-amyotrophic lateral sclerosis', 'interest', 'knockin animal', 'machine vision', 'mouse model', 'new therapeutic target', 'next generation', 'novel', 'open source', 'programs', 'protein TDP-43', 'stem', 'supercomputer', 'superoxide dismutase 1', 'tool']",NINDS,BROWN UNIVERSITY,R21,2020,446875,-0.018776961926169355
"Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity PROJECT SUMMARY The long-term goal of this project is to determine whether optical coherence tomography (OCT) and OCT angiography (OCTA) might lead more accurate and objective diagnosis, earlier intervention, and improved outcomes in retinopathy of prematurity (ROP). International consensus and National Institute of Health (NIH) funded clinical trials over the last 30 years have defined the phenotypic classifications, natural history, prognosis, and management of ROP. However, it is well established that due to the subjectivity of the ophthalmoscopic examination, and systematic bias between examiners, there is significant variation in treatment of the most severe forms of ROP in the real world. This leads to both under-treatment (and poor outcomes due to retinal detachment) and over-treatment (exposing neonates to the ocular and systemic risks of treatment). Roughly 20,000 babies per year develop retinal detachments (RD) due to ROP and there is strong evidence that most of these are preventable. In adult retinal vascular diseases, most notably diabetic retinopathy (DR), OCT and OCTA can detect and quantify disease features such as diabetic macular edema (DME) and retinal neovascularization (NV) before they are noted clinically, enabling earlier treatment and reducing the risk of blindness from RD. However, evaluating the use of this technology in neonates requires high speed and portable technology, and the commercially available handheld OCTs are too slow for ultra-widefield (UWF) OCT and OCTA imaging. Several groups (including our own) have published preliminary results using prototype 100 to 200 kHz swept- source (SS) OCT systems, however consistent data acquisition remains challenging due to the lack of fixation and subsequent motion in an awake neonate, which has limited the evaluation of the potential benefits of the technology in this population. Recently, there has been much interest in using artificial intelligence (AI) (specifically deep learning), which relies on high speed graphics processing units (GPUs) to provide real time OCT image processing, segmentation, and tracking. This application addresses 2 fundamental gaps in knowledge: (1) Can we overcome the technical challenges through the development of a faster ultrawide-field view SS-OCT system coupled with a GPU-enabled DL software system to enable consistent data acquisition in neonates? (2) Would quantitative objective metrics of ROP improve objectivity of ROP diagnosis and detect subclinical signs of disease progression which may enable earlier intervention and improved outcomes in the future. By leveraging our institution’s OCT, AI, and ROP expertise, we will address these questions in three specific aims: (1) Develop an ultra-high speed, handheld, panoramic ultra-widefield OCT/OCTA system. (2) Develop real time GPU accelerated intelligent image acquisition software. (3) Evaluate the clinical significance OCT derived biomarkers. Successful translation of this technology to the ROP population could improve the accuracy and objectivity of ROP diagnosis, and lead to earlier intervention and improved outcomes in patients with severe ROP. PROJECT NARRATIVE Optical Coherence Tomography (OCT) and OCT angiography (OCTA) have proven the ability to detect subclinical disease, provide quantitative evaluation of disease progression, and improve outcomes in the leading causes of blindness in adults, age-related macular degeneration and diabetic retinopathy. Technological and practical limitations have limited the application of this technology in routine use for non-sedated children undergoing routine screening for retinopathy of prematurity (ROP), the leading cause of blindness in children. The proposed project will develop an ultra-high speed, handheld OCT system with graphics processing unit (GPU) enabled real-time processing to improve the feasibility of panoramic ultra-widefield OCT/OCTA imaging in non-sedated neonates and evaluate the clinical utility of OCT-derived biomarkers in ROP.",Artificial intelligence assisted panoramic Optical Coherence Tomography Angiography for Retinopathy of Prematurity,9943875,R01EY031331,"['Address', 'Adult', 'Aftercare', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Artificial Intelligence', 'Biological Markers', 'Blindness', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Trials', 'Computer software', 'Consensus', 'Coupled', 'Cross-Sectional Studies', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Disease Progression', 'Dyes', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Evaluation', 'Eye', 'Fluorescein Angiography', 'Funding', 'Fundus', 'Future', 'Goals', 'Image', 'Image Analysis', 'Injections', 'Institution', 'Intelligence', 'International', 'Knowledge', 'Lasers', 'Lead', 'Length', 'Longitudinal Studies', 'Measurement', 'Medical Imaging', 'Methods', 'Monitor', 'Morphologic artifacts', 'Motion', 'Natural History', 'Neonatal', 'Ophthalmic examination and evaluation', 'Ophthalmoscopes', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Patients', 'Performance', 'Peripheral', 'Phenotype', 'Pilot Projects', 'Population', 'Primary Health Care', 'Publishing', 'Quantitative Evaluations', 'Retina', 'Retinal Detachment', 'Retinal Neovascularization', 'Retinopathy of Prematurity', 'Risk', 'Scanning', 'Severities', 'Severity of illness', 'Source', 'Speed', 'Structure', 'System', 'Systematic Bias', 'Technology', 'Testing', 'Time', 'Translations', 'United States National Institutes of Health', 'Variant', 'Vascular Diseases', 'Visualization', 'accurate diagnosis', 'arm', 'awake', 'base', 'blind', 'clinical Diagnosis', 'clinically significant', 'data acquisition', 'deep learning', 'design', 'diabetic', 'disease classification', 'disorder of macula of retina', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'instrument', 'interest', 'lens', 'macular edema', 'neonate', 'neovascularization', 'novel', 'outcome forecast', 'overtreatment', 'parallel computer', 'portability', 'prototype', 'real-time images', 'research clinical testing', 'routine screening', 'sample fixation', 'software systems', 'standard of care', 'treatment response', 'treatment risk']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,341800,-0.025075167340775653
"Lupus Nephritis Neural Network, LuNN Up to 60% of adults and 80% of children with systemic lupus erythematosus (SLE) develop nephritis (LN), with 10–30% progressing to end-stage renal disease (ESRD). The gold standard for diagnosis of LN is a renal biopsy. Histological parameters remain the best predictors of ESRD. Despite being the gold standard, histological diagnosis of LN has several shortcomings. In multiple inter-observer renal pathology assessment studies reported thus far, the inter- pathologist correlation coefficients, or concordance, in assessing most histological parameters have been sub-optimal. This has provided the impetus for the current proposal. We propose to leverage the power of computer vision and deep learning to build a classifier that rivals the best-trained renal pathologists in making a histological diagnosis of LN using current diagnostic criteria. We propose to train a deep convolutional neural network to distinguish the different LN classes, and to identify a full spectrum of histological attributes useful for diagnosis. We will compare the performance of the newly generated neural network in scoring glomerular/tubulo-interstitial features and LN classes, against a panel of human renal pathologists. Finally, we propose to build a neural network that can predict clinical outcome based on baseline renal pathology. Reliable and reproducible classification of LN could dramatically improve patient management and long-term renal and patient survival. Despite being the gold standard, histological diagnosis of lupus nephritis is imprecise, and marked by significant inter-pathologist discordance in readings. We propose to leverage the power of computer vision and deep learning to build a classifier that rivals the best-trained renal pathologists in making a histological diagnosis of lupus nephritis. Reliable and reproducible classification of LN could dramatically improve patient management and long-term renal and patient survival.","Lupus Nephritis Neural Network, LuNN",10246669,R56DK122036,"['Adult', 'Algorithms', 'Automobile Driving', 'Cellular Structures', 'Child', 'Chronic', 'Classification', 'Computer Vision Systems', 'Diagnosis', 'Diagnostic', 'End stage renal failure', 'Feedback', 'Gold', 'Histologic', 'Human', 'Image', 'Kidney', 'Lupus', 'Lupus Nephritis', 'Machine Learning', 'Mus', 'Nephritis', 'Outcome', 'Outcome Study', 'Pathologist', 'Pathology', 'Patients', 'Performance', 'Phenotype', 'Prediction of Response to Therapy', 'Reading', 'Reporting', 'Reproducibility', 'Retrieval', 'Supervision', 'Systemic Lupus Erythematosus', 'Testing', 'Tissues', 'Training', 'Uncertainty', 'accurate diagnosis', 'base', 'convolutional neural network', 'deep learning', 'diagnosis standard', 'falls', 'improved', 'indexing', 'innovation', 'kidney biopsy', 'neural network', 'novel', 'predict clinical outcome', 'time interval', 'tool', 'treatment response', 'user-friendly', 'web portal']",NIDDK,UNIVERSITY OF HOUSTON,R56,2020,100750,-0.021860361848563218
"Development of Machine Learning Algorithms to Assess and Train Vesico-Urethral Anastomosis during Robot Assisted Radical Prostatectomy PROJECT SUMMARY/ABSTRACT CANDIDATE (Andrew J. Hung, MD): My long-term goal is to establish a career in innovating training methods for robotic surgery which will lead to curtailing surgeon learning curve, and maximize patient safety. My first step towards that goal focuses on understanding objective metrics that measure surgeon performance, and how machine learning algorithms can process that data to guide training. I have developed a career development program that builds on my clinical training in robotic urologic surgery and prior research in surgical training. Through mentorship, a fellowship, and formal coursework, this K23 award will provide me the necessary support to develop expertise in 3 areas where I do not have formal training, yet are critical to my success: (1) Machine learning; (2) Surgical education; (3) Advanced statistical skills and study design. MENTORING TEAM: My career development and research plans leverage existing institutional resources, including the USC Machine Learning Center, led by co-primary mentor Dr. Yan Liu; and Keck Hospital of USC, the second busiest robotic center by volume in the United States and the USC Institute of Urology (led by co- primary mentor and chairman Dr. Inderbir Gill), home to pioneers of several urologic surgical techniques with a robust research apparatus supporting several NIH-funded clinical scientists. My mentoring team is complemented by co-mentor Dr. Robert Sweet, a DOD-funded expert on surgical education; career mentor Dr. Larissa Rodriguez, a federally funded clinician/scientist experienced in mentoring K awardees; educational psychology collaborator Dr. Kenneth Yates, an authority on cognitive task analysis; and consultant Dr. Anthony Jarc, at Intuitive Surgical who has supported much of the pilot data on objective performance metrics. The proposed K23 work truly requires the robust collaboration of experts in robotic surgery, education, and machine learning. RESEARCH: The learning curve for surgeons performing robot assisted radical prostatectomy (RARP) is steep: over 100 cases. Current ‘gold standard’ methods of surgical assessment rely on subjective expert review, but such evaluations are time consuming and inconsistent. Nonetheless, credentialing a surgeon to perform robotic surgery has enormous implications - patient outcomes are at risk, and a surgeon’s career is on the line. Informed by my clinical expertise in robotic urological surgery and preliminary data, I will develop a novel method of utilizing machine learning (ML) algorithms to objectively assess robotic surgeon performance and to guide training for the vesico-urethral anastomosis (VUA), the most critical reconstructive part of the robot-assisted radical prostatectomy (RARP). I will develop and validate objective metrics directly captured from the da Vinci robot during the VUA (Aim 1), train machine learning algorithms to assess a surgeon’s performance of VUA (Aim 2), and utilize ML algorithms to guide surgeons learning the VUA (Aim 3). Armed with these data and skills from this award, I will be uniquely suited to utilize machine learning to generalize objective surgeon assessment for robot-assisted surgical procedures within and beyond urology. Finally, the results from this study will provide preliminary data for independent funding through mechanisms such as an NIH R01 grant. PROJECT NARRATIVE The learning curve for surgeons performing robot assisted radical prostatectomy (RARP) for prostate cancer is steep, and current methods of evaluating surgeons require subjective and time-consuming expert review. Streamlined training and assessment utilizing objective performance metrics and machine learning algorithms can significantly curtail learning curve with patients, and decrease the overall morbidity of prostate cancer treatment.",Development of Machine Learning Algorithms to Assess and Train Vesico-Urethral Anastomosis during Robot Assisted Radical Prostatectomy,9982955,K23EB026493,"['Address', 'Adopted', 'Affect', 'Anastomosis - action', 'Area', 'Artificial Intelligence', 'Award', 'Chairperson', 'Characteristics', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Consumption', 'Credentialing', 'Data', 'Data Analyses', 'Development', 'Education', 'Educational Intervention', 'Educational Psychology', 'Evaluation', 'Event', 'Fellowship', 'Foundations', 'Funding', 'Future', 'Gills', 'Goals', 'Gold', 'Grant', 'Hand', 'Home environment', 'Hospitals', 'Individual', 'Institutes', 'Intervention', 'Intuition', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Medical Research', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Meta-Analysis', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Motion', 'Movement', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Positioning Attribute', 'Procedures', 'Process', 'Program Development', 'Prostate Cancer therapy', 'Radical Prostatectomy', 'Research', 'Research Design', 'Resources', 'Risk', 'Robot', 'Robotics', 'Scientist', 'Specialist', 'Surgeon', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Urethra', 'Urologic Surgical Procedures', 'Urology', 'Work', 'authority', 'base', 'burden of illness', 'career', 'career development', 'clinically significant', 'cognitive task', 'common treatment', 'complex data ', 'computer program', 'data reduction', 'experience', 'functional outcomes', 'improved', 'innovation', 'kinematics', 'machine learning algorithm', 'male', 'novel', 'patient safety', 'peer', 'reconstruction', 'research and development', 'robot assistance', 'skills', 'success', 'task analysis', 'urologic', 'virtual reality', 'virtual reality simulation']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,K23,2020,192304,-0.013137163459120709
"Developing a virtual placenta biobank Project Summary / Abstract The placenta is the first organ to develop and functions as the fetal lung, kidney, gut, skin, immune and endocrine systems. It is the cause of, and reflects changes from, most diseases in pregnancy, yet remains understudied. This career development proposal will train me in the tools and practice of digital pathology, while I apply them to the placenta with the hypothesis that there are reproducible, quantitative changes in the placenta that can be modeled and used to identify abnormalities via artificial intelligence (AI). I will create a publicly available atlas of microscopically normal placentas from throughout the 2nd and 3rd trimesters. Whole slide imaging will be performed on microscopic slides of placentas from the beginning of the 2nd trimester (13 weeks) through post-term (42 weeks). I will lead a team to annotate tissue type, structures, and cells. Algorithms will be trained to replicate the manual annotations. To study the changes in the placenta over time, automated measurements will be performed to identify changes in shape, size, and cellularity of placental structures that correlate with gestational age. This research can be used to develop a model of placental development and study prematurity. I will demonstrate detection of diseases of pregnancy, using preeclampsia (PreE) as an example. Placentas with microscopic changes classically seen in PreE will be scanned and annotated and algorithms trained and tested to identify them. Like many diseases of pregnancy, placental changes in PreE are variable and sometimes absent. Slides from PreE cases with no microscopic abnormalities will be scanned and examined using the quantitative parameters developed for normal placentas, testing the hypothesis that one or more of them will significantly differ between PreE cases and gestational age- matched controls. I am an Assistant Professor of Pathology at Northwestern University with an emerging focus in informatics and machine learning for diseases of pregnancy. The mentor for this project is Lee D.A. Cooper, PhD, an expert in digital pathology and machine learning. The co-mentor is David M. Aronoff, MD, an expert in maternal-child health. Mentor and co-mentor both have a history of NIH funding and graduating mentees to independence. The advisory committee consists of a digital pathology expert (Gutman), a pediatrician (Mestan) and a pathologist physician scientist (Yang). They have proposed an aggressive schedule of one-on-one meetings, coursework, seminars, and scientific meetings to supplement learning by doing the science. Completion of these studies will build my expertise in the application of machine learning to placental pathology while creating a new, publicly- accessible tool for the rapid assessment and understanding of organ structure and function with great potential to improve maternal-child health. Project Narrative The placenta grows over the course of gestation from a single layer of cells to a complex organ that acts as the fetal skin, lung, gut, kidney, immune system, and endocrine system. This project will develop an online repository of placenta microscopic images over the course of gestation from normal placentas and one disease of pregnancy, preeclampsia. Using artificial intelligence to quantitatively describe the changes over time in normal placentas and those with disease could help understand preterm birth and diseases of pregnancy.",Developing a virtual placenta biobank,10040733,K08EB030120,"['Advisory Committees', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Biological', 'Cells', 'Cellularity', 'Child', 'Chorion', 'Complex', 'Data', 'Decidual Cell', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Elements', 'Endocrine system', 'Endothelium', 'Event', 'Feeds', 'Fetal Lung', 'Fibrinoid necrosis', 'Funding', 'Gestational Age', 'Glass', 'Goals', 'Hematoma', 'Hemosiderosis', 'Histology', 'Histopathology', 'Human', 'Immune system', 'Infarction', 'Informatics', 'Kidney', 'Lead', 'Learning', 'Length', 'Liver', 'Lung', 'Machine Learning', 'Manuals', 'Maternal and Child Health', 'Measurement', 'Membrane', 'Mentors', 'Microscopic', 'Modeling', 'Morphology', 'Organ', 'Pathogenicity', 'Pathologic', 'Pathologist', 'Pathology', 'Physicians', 'Physiological', 'Physiology', 'Placenta', 'Placentation', 'Pre-Eclampsia', 'Pregnancy', 'Premature Birth', 'Radar', 'Recording of previous events', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Scanning', 'Schedule', 'Science', 'Scientist', 'Second Pregnancy Trimester', 'Shapes', 'Skin', 'Slide', 'Specimen', 'Spiral Artery of the Endometrium', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Third Pregnancy Trimester', 'Time', 'Tissues', 'Training', 'Umbilical cord structure', 'United States National Institutes of Health', 'Universities', 'Variant', 'Villous', 'Villus', 'Yang', 'algorithm training', 'biobank', 'career development', 'cell type', 'chorionic plate', 'digital', 'digital pathology', 'fetal', 'health of the mother', 'improved', 'interest', 'intrahepatic cholestasis of pregnancy', 'machine learning algorithm', 'macrophage', 'meetings', 'microscopic imaging', 'novel', 'online repository', 'pediatrician', 'premature', 'professor', 'supplemental instruction', 'tool', 'trophoblast', 'virtual', 'whole slide imaging']",NIBIB,NORTHWESTERN UNIVERSITY AT CHICAGO,K08,2020,185630,-0.019753245849890095
"SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN) PROJECT SUMMARY/ABSTRACT In recent years, human cognitive auditory neuroscience has made rapid strides due to advances in human neuroimaging, the advent of innovative machine learning/big data analytic approaches, and a greater mechanistic understanding of cognitive-sensory interactions in animal models. The dynamic landscape of this emergent field necessitates a highly interdisciplinary, human and translation-centric symposium that brings together expertise across academia and industry. This application requests partial funding for the Symposium on Cognitive Auditory Neuroscience (SCAN) to be hosted in Pittsburgh, PA in July 2020 and 2022, as a joint venture between Carnegie Mellon University (CMU) and University of Pittsburgh (Pitt). As a biennial meeting, SCAN aims to become the premiere intellectual and professional venue for current research in the emerging field of human cognitive auditory neuroscience. SCAN will incorporate elements typical to academic conferences (research talks, posters) as well as novel ideas that promote ‘blue sky’ thinking in this rapidly evolving field. SCAN will assiduously and innovatively work towards inclusivity and creating an atmosphere that encourages intellectual and professional engagement from women, underrepresented minorities, and individuals with disabilities. Another critical aim of the SCAN is to foster industry-academic partnerships with an eye towards translation of basic research and fostering career opportunities for trainees. Pittsburgh is uniquely situated to launch SCAN. With an enviable concentration of co-located auditory neuroscience expertise, Pittsburgh is also an intellectual hub for industries/start-ups engaged in in machine learning, natural language processing, and speech recognition. SCAN will leverage these advantages to foster growth and innovation tied to core missions of the National Institutes of Deafness and Communication Disorders. PROJECT NARRATIVE The Symposium on Cognitive Auditory Neuroscience (SCAN) has a strong connection to deafness and communication disorders through its focus on the basic science of human cognitive auditory neuroscience, and its translation. SCAN will establish an intellectual home for dissemination of cutting-edge research in human cognitive auditory neuroscience, support the development of the next generation of scientists, build a vibrant and inclusive community that engages with the grand challenges in the field, and forge new academia-industry partnerships.",SYMPOSIUM ON COGNITIVE AUDITORY NEUROSCIENCE (SCAN),9914387,R13DC018243,"['Academia', 'Acoustics', 'Address', 'Affect', 'Americas', 'Animal Model', 'Atmosphere', 'Attention', 'Auditory', 'Auditory Perception', 'BRAIN initiative', 'Base of the Brain', 'Basic Science', 'Behavioral', 'Big Data Methods', 'Brain', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communities', 'Complex', 'Development', 'Disabled Persons', 'Disease', 'Ear', 'Educational workshop', 'Elements', 'Environment', 'Eye', 'Fertilization', 'Fostering', 'Funding', 'Geographic Locations', 'Goals', 'Growth', 'Hearing', 'Home environment', 'Human', 'Industry', 'Influentials', 'Institutes', 'Joint Ventures', 'Learning', 'Life', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Mission', 'Natural Language Processing', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Otolaryngology', 'Participant', 'Perception', 'Peripheral', 'Problem Solving', 'Process', 'Request for Applications', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Seeds', 'Sensory', 'Societies', 'Speech', 'Thinking', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'analytical tool', 'base', 'career', 'cognitive neuroscience', 'deafness', 'industry partner', 'innovation', 'interest', 'meetings', 'millisecond', 'neuroimaging', 'new technology', 'next generation', 'novel', 'open data', 'posters', 'pressure', 'relating to nervous system', 'sensory input', 'sound', 'speech recognition', 'symposium', 'virtual reality']",NIDCD,CARNEGIE-MELLON UNIVERSITY,R13,2020,36183,-0.02754366590889071
"Novel machine learning approaches for improving structural discrimination in cryo-electron tomography Project Summary Cellular cryo-electron tomography (Cryo-ET) has made possible the observation of cellular organelles and macromolecular complexes at nanometer resolution with native conformations. The rapid increasing amount of Cryo-ET data available however brings along some major challenges for analysis which we will timely ad- dress in this proposal. We will design novel data-driven machine learning algorithms for improving structural discrimination and resolution. In particular, we have the following speciﬁc aims: (1) We will develop a novel Autoencoder and Iterative region Matching (AIM) algorithm for marker-free alignment of image tilt-series to re- construct tomograms with improved resolution; (2) We will develop a saliency-based auto-picking algorithm for better detecting macromolecular complexes, and combine it with an innovative 2D-to-3D framework to further improve structure detection accuracy; (3) We will design an end-to-end convolutional model for pose-invariant clustering of subtomograms. This model will produce an initial clustering which will be reﬁned by a new subto- mogram averaging algorithm that automatically down-weights subtomograms of noise and little contribution; (4) We will perform experimental evaluations by using previously reported bacterial secretion systems and mito- chondrial ultrastructures datasets to improve the ﬁnal resolution. Implementing algorithms in Aims 1-3, we will develop a user-friendly open-source graphical user interface -tom to directly beneﬁt the scientiﬁc community.  -tom will be systematically compared with existing software including IMOD, EMAN2, and Relion on simulated and benchmark datasets. To facilitate distribution, -tom will be integrated into existing software platforms Sci- pion and TomoMiner. Our data-driven algorithms and software not only will facilitate and accelerate the future use of Cryo-ET, but also can be readily used on analyzing the existing large amounts of Cryo-ET data to im- prove our understanding of the structure, function, and spatial organization of macromolecular complexes in situ. Project Narrative This project will create a system of machine learning algorithms to accelerate and facilitate the use and re-use of the rapidly accumulating Cryo-ET datasets. For easy use, we will develop an open-source GUI -Tom (to be disseminated into the Scipion and TomoMiner software platforms) that streamlines the new approaches from the initial tomogram reconstruction step to the ﬁnal subtomogram averaging step. We will validate the performance of our system by applying it on published Cryo-ET datasets and monitor the improvement of the ﬁnal results.",Novel machine learning approaches for improving structural discrimination in cryo-electron tomography,9973462,R01GM134020,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Back', 'Benchmarking', 'Biological Process', 'Cells', 'Communities', 'Computer Analysis', 'Computer software', 'Cryo-electron tomography', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Discrimination', 'Evaluation', 'Future', 'Gaussian model', 'Group Structure', 'Hour', 'Image', 'In Situ', 'Knowledge', 'Laplacian', 'Literature', 'Machine Learning', 'Macromolecular Complexes', 'Manuals', 'Methods', 'Mitochondria', 'Modeling', 'Molecular Conformation', 'Monitor', 'Neurophysiology - biologic function', 'Noise', 'Organelles', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Series', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tomogram', 'Weight', 'Work', 'autoencoder', 'automated algorithm', 'base', 'deep learning', 'design', 'falls', 'feature detection', 'graphical user interface', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'nano', 'nanometer resolution', 'novel', 'novel strategies', 'open source', 'particle', 'pi-Mesons', 'programs', 'reconstruction', 'success', 'user-friendly']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2020,342970,-0.028176737777149744
"Development and Deployment of Artificial Intelligence (AI) Driven Methods to Enable Chest X-ray Radiography as an Alternative Diagnostic Method for COVID-19 Pneumonia ABSTRACT In this competitive revision, within the same scope of developing and deploying algorithms to make a quantum leap in clinical diagnosis as that in our current U01EB021183, we would like to revise the original aims to add a new Aim to leverage our expertise in the areas of algorithm development and clinical translation to make immediate contributions to combat the COVID-19 pandemic. Specifically, we propose to develop and deploy artificial intelligence (AI) methods to enable chest x-ray radiography (CXR) as an alternative diagnostic tool to diagnose COVID-19 pneumonia, to rapidly triage patients for appropriate treatment, to monitor the treatment response in a contained environment, and to optimize the distribution of the limited medical resources during the current COVID-19 crisis. PROJECT NARRATIVE In this project, our overarching objective is to develop automated artificial intelligence (AI)-based algorithms to help radiologists to differentiate COVID-19 related pneumonia from other non-COVID-19 related pneumonia using CXR images. The advantages of the proposed AI equipped CXR technique include: i) widely available, ii) inexpensive, iii) excellent coronavirus exposure profile for patient, technologist, and equipment, and iv) rapid and automated DL interpretation, which is effectively instantaneous.",Development and Deployment of Artificial Intelligence (AI) Driven Methods to Enable Chest X-ray Radiography as an Alternative Diagnostic Method for COVID-19 Pneumonia,10156179,U01EB021183,"['Accident and Emergency department', 'Air', 'Algorithms', 'American College of Radiology', 'Anosmia', 'Appearance', 'Area', 'Artificial Intelligence', 'Bilateral', 'COVID-19', 'COVID-19 pandemic', 'Case Study', 'Cessation of life', 'China', 'Clinic', 'Clinical', 'Communities', 'Containment', 'Coronavirus', 'Coughing', 'Country', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic Sensitivity', 'Diagnostic radiologic examination', 'Diarrhea', 'Disease', 'Disease Outbreaks', 'Dyspnea', 'Environment', 'Equipment', 'European', 'Exposure to', 'Fatigue', 'Fever', 'Glass', 'Gold', 'Health Personnel', 'Health care facility', 'Hospitals', 'Human', 'Image', 'Individual', 'Investigation', 'Lung', 'Lung diseases', 'Medical', 'Medical Imaging', 'Methods', 'Monitor', 'North America', 'Parents', 'Pathway interactions', 'Patient Triage', 'Patients', 'Performance', 'Persons', 'Pleural effusion disorder', 'Pneumonia', 'Process', 'Radiology Specialty', 'Reading', 'Reporting', 'Resources', 'Reverse Transcriptase Polymerase Chain Reaction', 'Rural', 'Sensitivity and Specificity', 'Societies', 'Symptoms', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Triage', 'United States', 'Viral Pneumonia', 'War', 'World Health Organization', 'X-Ray Computed Tomography', 'accurate diagnosis', 'algorithm development', 'base', 'chest computed tomography', 'clinical Diagnosis', 'clinical translation', 'combat', 'deep learning', 'high risk', 'high risk population', 'imaging facilities', 'imaging modality', 'improved', 'intelligent algorithm', 'neural network architecture', 'pandemic disease', 'prevent', 'profiles in patients', 'quantum', 'radiologist', 'screening', 'success', 'tool', 'treatment response', 'urgent care']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,U01,2020,605070,-0.006497778779519578
"Prevalence effects in visual research: Theoretical and practical implications Low prevalence searches form an important and problematic class of visual search tasks. These are tasks where the search target is rare. Many socially important tasks like airport security or cancer screening are low prevalence tasks. Previous work, much of it from our lab, has shown that low prevalence can have undesirable effects. Most notably, miss (false negative) errors are markedly elevated at low prevalence. This is a clear problem if the purpose of the search is to detect something rare but important like cancer or a terrorist threat. Our previous work has documented this pattern of increased miss errors in a number of expert domains including cytology (cervical cancer screening), airport baggage screening, and breast cancer screening. False alarm (false positive) error rates typically decline at low prevalence, moving in the opposite direction from miss errors. This indicates a shift in the observer’s decision criterion. At low prevalence, observers become more reluctant to call something a target. Several studies – ours and others - have shown that this “conservative” criterion shift is not adequate to explain the entire prevalence effect. Wolfe and VanWert (2010) developed a “Dual- Threshold” model that better captures the important aspects of the prevalence effect data by proposing two effects of low prevalence: (1) the conservative shift in the criterion for deciding if an attended item is a target, and (2) a lowering of the “quitting threshold.” The quitting threshold determines when observers end a search. Quitting too soon also increases the chance that the observer will miss a target. Prevalence effects have been studied in experimental isolation from other aspects of search. However, in tasks like breast cancer screening, other factors interact with prevalence. The four projects in the present proposal each investigate one of these interactions. Project 1 examines the relationship of prevalence to the “vigilance decrements” that are seen as time elapses in a task. In search, observers must maintain an internal, mental representation of the search target (or targets). Project 2 is concerned with the impact of prevalence on these “target templates”. Advances in artificial intelligence (notably deep learning) are producing tools to assist expert searchers. However, once deployed, these AI tools have been less effective than theory predicts. Project 3 tests the hypothesis that part of the problem is another side-effect of low prevalence and the project tests a potential intervention. Finally, clinicians, searching for one type of target (e.g. pneumonia) are supposed to report signs of other possible problems (e.g. lung cancer). Project 4 probes the role of prevalence in the failure to report such “incidental findings”. Again, we test several interventions. This is “use-inspired, basic research” whose results will provide guidance for experts performing socially important low prevalence tasks. Important tasks like breast cancer screening involve visual search for rare (“low prevalence”)  targets but, unfortunately, low prevalence is known to increase the percentage of targets that are  missed even by well-trained experts. In a task like breast cancer screening, prevalence interacts  with other factors like observer vigilance or the effectiveness of an artificial intelligence tool.  This proposal studies four of these interactions with the goal of counteracting the malign effects  of prevalence; thus making it possible for experts to perform their critical search tasks more  effectively.",Prevalence effects in visual research: Theoretical and practical implications,9885223,R01EY017001,"['Artificial Intelligence', 'Basic Science', 'Breast Cancer Detection', 'Cervical Cancer Screening', 'Collaborations', 'Cytology', 'Data', 'Detection', 'Effectiveness', 'Failure', 'Flecks', 'Goals', 'Human', 'Hybrids', 'Incidental Findings', 'Intervention', 'Joints', 'Low Prevalence', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methods', 'Modeling', 'Paper', 'Pattern', 'Performance', 'Pneumonia', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Screening for cancer', 'Security', 'Talents', 'Testing', 'Time', 'Training', 'Trust', 'Visual', 'Work', 'analog', 'base', 'clinically significant', 'deep learning', 'design', 'improved', 'mental representation', 'programs', 'side effect', 'social', 'theories', 'tool', 'vigilance', 'visual search']",NEI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2020,447500,-0.06537564180826828
"Differential artery-vein analysis in OCT angiography for objective classification of diabetic retinopathy Abstract: This project aims to establish differential artery-vein analysis in optical coherence tomography angiography (OCTA), and to validate comprehensive OCTA features for automated classification of diabetic retinopathy (DR). Early detection, prompt intervention, and reliable assessment of treatment outcomes are essential to prevent irreversible visual loss from DR. It is known that DR can target arteries and veins differently. Therefore, differential artery-vein analysis can provide better performance of DR detection and classification. However, clinical OCTA instruments lack the capability of artery-vein differentiation. During this project, we propose to use quantitative feature analysis of OCT, which is concurrently captured with OCTA, to guide artery- vein differentiation in OCTA. The first aim is to establish automated artery-vein differentiation in OCTA. In coordination with our recently demonstrated blood vessel tracking technique, OCT intensity/geometry features will be used to guide artery-vein differentiation in OCTA automatically. Differential artery-vein analysis of blood vessel tortuosity (BVT), blood vessel caliber (BVC), blood vessel density (BVD), vessel perimeter index (VPI), vessel branching coefficient (VBC), vessel branching angle (VBA), branching width ratio (BWR), fovea avascular zone area (FAZ-A) and FAZ contour irregularity (FAZ-CI) will be implemented. Key success criterion of the aim 1 study is to demonstrate robust artery-vein differentiation in OCTA, and to establish OCTA features for objective detection and classification of DR. The second aim is to validate automated OCTA classification of DR. We propose to employ ensemble machine learning to integrate multiple classifiers to achieve robust OCTA classification of DR. Key success criterion of the aim 2 study is to identify OCTA features and optimal-feature- combination to detect early DR, and to establish the correlations between the OCTA features and clinical biomarkers. The third aim is to verify OCTA prediction and evaluation of DR treatment. Our preliminary OCTA study of diabetic macular edema (DME) with anti-vascular endothelial growth factor (anti-VEGF) treatment has shown that BVD can serve as a biomarker predictive of visual improvement. During this project, we plan to test differential artery-vein analysis for DME treatment evaluation. Key success criterion of the aim 3 study is to identify artery-vein features to provide robust prediction and evaluation of DME treatment outcomes. As an alternative approach, we propose a fully convolutional neural network (FCNN) for deep machine leaning based artery-vein and DR classification. Early layers in the FCNN will produce simple features, which will be convolved and filtered into deeper layers to produce complex features for artery-vein and DR classification. Further investigation of the relationship between the new features learned through the machine learning process and clinical biomarkers will allow us to optimize the design for better DR classification. Success of this project will pave the way towards using quantitative OCTA features for early DR detection, objective prediction and assessment of treatment outcomes. Project Narrative This project is to establish quantitative optical coherence tomography angiography (OCTA) analysis for objective classification of diabetic retinopathy (DR). By translating subjective findings into objective assessments, this study will standardize clinical OCTA for eye disease detection and treatment assessment. In addition, objective OCTA analysis based automated DR classification can foster telemedicine in rural and underserved areas where the access to experienced ophthalmologists is limited.",Differential artery-vein analysis in OCT angiography for objective classification of diabetic retinopathy,9857745,R01EY030842,"['Adult', 'Affect', 'Angiography', 'Area', 'Arteries', 'Biological Markers', 'Blindness', 'Blood Vessels', 'Blood capillaries', 'Caliber', 'Classification', 'Clinical', 'Color', 'Complex', 'Derivation procedure', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exudate', 'Eye diseases', 'Fostering', 'Fundus photography', 'Geometry', 'Health Expenditures', 'Individual', 'Intervention', 'Investigation', 'Machine Learning', 'Maps', 'Methods', 'Microaneurysm', 'Modernization', 'Ophthalmologist', 'Optical Coherence Tomography', 'Optics', 'Performance', 'Process', 'Reflex action', 'Retina', 'Retinal Edemas', 'Retinal Hemorrhage', 'Sensitivity and Specificity', 'Source', 'Staging', 'Standardization', 'Symptoms', 'Techniques', 'Telemedicine', 'Testing', 'Thinness', 'Translating', 'Treatment outcome', 'Vascular Endothelial Growth Factors', 'Veins', 'Venous', 'Visual', 'Width', 'base', 'bevacizumab', 'clinical biomarkers', 'convolutional neural network', 'deep neural network', 'density', 'design', 'diabetic', 'diabetic patient', 'experience', 'fovea centralis', 'fundus imaging', 'global health', 'image registration', 'imaging capabilities', 'improved', 'indexing', 'instrument', 'macular edema', 'predictive marker', 'prevent', 'rural underserved', 'success', 'support vector machine', 'vascular abnormality']",NEI,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,2020,362544,-0.010030822735934605
"Large-scale annotation-free disease correlation analysis of the iHMP Project Summary We will work with the iHMP data resource to apply novel tools and data analysis methodologies to the challenge of disease association between large microbiome data sets, Inflammatory Bowel Disease, and the onset of diabetes. We will start with an annotation-free approach using k-mers to preprocess IBD and diabetes cohorts. We then will apply a novel scaling technology implemented in the sourmash software to reduce the data set size by a factor of 2000, rendering it tractable to machine learning approaches. We next will use random forests to determine a subset of predictive k-mers, and will measure their accuracy on validation data sets not used in the initial training. Finally, we will annotate the predictive k-mers using all available genome databases as well as a novel method to infer the metagenomic presence of accessory genomes of known genomes. Our outcomes will include a catalog of microbial genomes that correlate with IBD subtype and the onset of diabetes, as well as automated workflows to apply similar approaches to other data sets. Project Narrative We propose to work with the iHMP data, a large central microbiome resource, to study disease correlations with inflammatory bowel disease and diabetes. We will work to associate specific microbial species with the disease conditions. We will also produce resources that will help other researchers perform similar studies.",Large-scale annotation-free disease correlation analysis of the iHMP,10112077,R03OD030596,"['Catalogs', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diabetes Mellitus', 'Disease', 'Ecology', 'Genbank', 'Genome', 'Human', 'Immunoglobulin Variable Region', 'Inflammatory Bowel Diseases', 'Machine Learning', 'Measures', 'Metadata', 'Metagenomics', 'Methodology', 'Methods', 'Onset of illness', 'Organism', 'Outcome', 'Reporting', 'Research Personnel', 'Resources', 'Technology', 'Training', 'Update', 'Validation', 'Variant', 'Viral', 'Work', 'cohort', 'data resource', 'genome database', 'member', 'metagenome', 'metatranscriptome', 'metatranscriptomics', 'microbial', 'microbial genome', 'microbiome', 'novel', 'random forest', 'tool']",OD,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2020,304918,-0.03757440138790456
"Quantifying the Metrics of Surgical Mastery: An Exploration in Data Science PROJECT SUMMARY In surgery, it is accepted that there may be a ten to twenty-year learning curve to reach mastery for certain procedures. We believe this timeline can and should be shortened to improve patient care. Our short-term goal is to make a major contribution to the emerging field of Surgical Data Science by building a database of mastery level surgical performance and generating a roadmap for multimodal data collection and analysis procedures. Sharing our process, procedures and results broadly, will help to change measurement culture in healthcare. Through our newly developed partnership (October 2019) with the American College of Surgeons, we have already experienced early success in starting the conversation through the “Surgical Metrics Project” (https://www.facs.org/education/surgical-metrics). Using a standardized data collection platform (a mastery-level hernia simulation), we will deploy and synchronize multiple data capture approaches (motion tracking, video, audio and validated surgical performance checklists) to build our database. Data analysis will quantify surgical mastery and consist of new applications and discoveries in machine learning. Hypothesis: Using multiple, synchronized data capture approaches and machine learning, it is possible to create a database of mastery level surgical strategies that can be translated into a value-added, surgical navigation tool for surgeons. To test this hypothesis, we will empirically investigate the following paraphrased aims: SPECIFIC AIM 1: Quantify surgical mastery (cognitive and technical) during a simulated laparoscopic ventral hernia (LVH) repair by using a post-procedure analysis of multi-modal performance metrics captured from hospital credentialed surgeons (N~125). SPECIFIC AIM 2: Establish validity evidence for surgical mastery metrics by comparing simulation-based LVH performance with operating room LVH performance from the same surgeons (N~60). SPECIFIC AIM 3: Empirically investigate the best implementation strategy for utilization of a surgical navigation tool designed to deliver value-added information regarding mastery-level surgical performance strategies to a new group of hospital credentialed surgeons (N~125). PROJECT NARRATIVE The significance of this study is the opportunity to make a major contribution to the emerging field of Surgical Data Science by: 1) Generating a large multimodal dataset that can be de-identified and shared and 2) Providing a roadmap for predicting and supporting operative mastery with an artificial intelligence powered decision tool.",Quantifying the Metrics of Surgical Mastery: An Exploration in Data Science,10053113,R01DK123445,"['Address', 'American College of Surgeons', 'Area', 'Artificial Intelligence', 'Benchmarking', 'Caring', 'Clinical', 'Cognitive', 'Computer Vision Systems', 'Credentialing', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Databases', 'Decision Making', 'Development', 'Education', 'Evaluation', 'Feedback', 'Feeds', 'Goals', 'Healthcare', 'Hernia', 'Hospitals', 'Learning', 'Machine Learning', 'Magnetism', 'Measurement', 'Medical', 'Motion', 'Operating Rooms', 'Operative Surgical Procedures', 'Patient Care', 'Performance', 'Physicians', 'Procedures', 'Process', 'Protocols documentation', 'Quality of Care', 'Research', 'Structure', 'Students', 'Surgeon', 'Surgical Specialties', 'Technical Expertise', 'Technology', 'Testing', 'Time', 'TimeLine', 'Translating', 'United States National Institutes of Health', 'Validation', 'Ventral Hernia', 'Video Recording', 'Work', 'base', 'clinical practice', 'cognitive skill', 'data framework', 'data modeling', 'data sharing', 'data standards', 'design', 'early experience', 'force sensor', 'implementation strategy', 'improved', 'motion sensor', 'multimodal data', 'multimodality', 'new technology', 'repaired', 'simulation', 'skill acquisition', 'skills', 'success', 'symposium', 'tool']",NIDDK,STANFORD UNIVERSITY,R01,2020,671082,0.0005828253372300784
"ClientBot: A conversational agent that supports skills practice and feedback for Motivational Interviewing for AUD PROJECT SUMMARY/ABSTRACT  Millions of Americans are in need of evidence-based counseling, such as motivational interviewing (MI), for alcohol use disorders (AUDs) each year. To develop competence in an evidence-based practice like MI, trainees require ample opportunities for practice and immediate, performance-based feedback on the skills that they are learning. However, this is challenging if not impossible to offer at scale -- to the large number of providers in need of training. Opportunities for practice typically rely on roleplays with other trainees with limited experience, and feedback requires either direct supervision from an expert trainer or behavioral coding from a trained coding team; these are costly, limited, and time consuming. AI-based technology can meet this need, generating many opportunities for practice, and providing regular, actionable feedback. Many practice opportunities coupled with rapid, performance-based feedback can enhance and expand training in evidence-based counseling for AUDs in a scalable and cost-efficient manner.  Lyssn.io​, Inc., (“Lyssn”) is a start-up developing AI-based technologies to support training, supervision, and quality assurance of evidence-based counseling. Our goal is to develop innovative health technology solutions that are objective, scalable, and cost efficient. ​Lyssn’s​ team includes expertise in natural language processing, machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling. Previous research demonstrated the basic utility of a prototype conversational agent (ClientBot) for training counselors. Currently, ClientBot simulates a general mental health client who can engage in open-ended interaction with trainees and provides immediate, performance-based feedback to trainees using machine learning.  The current Fast-Track SBIR proposal partners ​Lyssn​ with Prevention Research Institute (PRI), who has a long track-record of training counselors in evidence-based approaches for AUD and currently trains approximately 1,250 counselors per year. Phase I will adapt ClientBot to an AUD training context, including understanding PRI training workflows, assessing usability, and accuracy of machine learning based MI feedback. Phase II will conduct a field-based usability trial and a randomized training trial (N = 200 PRI trainees) to evaluate the effectiveness of ClientBot on learning of MI skills compared to a wait-list and PRI training-as-usual. Analyses will also examine the hypothesized mechanisms of behavior change underlying ClientBot’s MI skills training. The successful execution of this project will break the reliance on role plays with peers and human judgment for training and performance-based feedback and support commercialization of a ClientBot product for training of AUD counselors in evidence-based practices. PROJECT NARRATIVE Training counselors in evidence-based treatments for alcohol use disorders (AUDs) requires repeated opportunities for skills practice with performance-based feedback, which is challenging to provide at scale. Building on an existing prototype, ​Lyssn.io​ – a technology start-up focused on scalable and cost-efficient human-centered technologies – will enhance and evaluate an AI-based, conversational agent (ClientBot) that simulates a realistic client with alcohol concerns and provides performance-based feedback to support counselor training.",ClientBot: A conversational agent that supports skills practice and feedback for Motivational Interviewing for AUD,10009084,R44AA028463,"['Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'American', 'Assessment tool', 'Behavioral', 'Behavioral Mechanisms', 'Client', 'Clinical', 'Code', 'Competence', 'Consumption', 'Control Groups', 'Counseling', 'Coupled', 'Development', 'Effectiveness', 'Environment', 'Evaluation', 'Evidence based practice', 'Evidence based treatment', 'Feedback', 'Goals', 'Health Personnel', 'Health Technology', 'Human', 'Individual', 'Interview', 'Judgment', 'Learning', 'Learning Skill', 'Machine Learning', 'Mental Health', 'Modeling', 'Music', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Nonprofit Organizations', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phase', 'Play', 'Prevention Research', 'Professional counselor', 'Provider', 'Randomized', 'Recovery', 'Research', 'Research Institute', 'Role', 'Small Business Innovation Research Grant', 'Software Engineering', 'Sports', 'Strategic Planning', 'Structure', 'Substance abuse problem', 'Supervision', 'System', 'Technology', 'Testing', 'Text', 'Thinking', 'Time', 'Training', 'Training Activity', 'Training Support', 'Vision', 'Waiting Lists', 'Work', 'alcohol testing', 'alcohol use disorder', 'base', 'behavior change', 'behavioral health', 'commercialization', 'cost', 'cost efficient', 'design', 'effectiveness evaluation', 'evidence base', 'experience', 'experimental study', 'improved', 'innovation', 'member', 'motivational enhancement therapy', 'peer', 'prototype', 'quality assurance', 'scale up', 'skill acquisition', 'skills', 'skills training', 'tool', 'treatment choice', 'usability', 'user centered design']",NIAAA,"LYSSN.IO, INC.",R44,2020,397456,-0.04231456586213656
"Machine Learning for Integrative Modeling of the Immune System in Clinical Settings Machine Learning for Integrative Modeling of the Immune System in Clinical Settings In response to an immunological challenge, immune cells act in concert forming complex and dense networks. A deep understanding of these immune responses is often the first step in developing immune therapies and diagnostic tests. Multivariate modeling algorithms can simultaneously consider all measured aspects of the immune system but requires prohibitively larger cohort sizes as technological advancements increase the number of measurements (a.k.a., “Curse of Dimensionality”). To address this, we propose a series of studies to develop machine learning algorithms for comprehensive profiling of the immune system in clinical settings. Particularly, for analysis of the immune system at a single-cell-level, we will leverage the stochastic nature of clustering algorithms to produce a robust pipeline for prediction of clinical outcomes. Next, we introduce the immunological Elastic-Net (iEN) algorithm, which addresses both the curse of dimensionality and reproducibility by integrating prior immunological knowledge into the models.  The cellular systems that govern immunity act through symbiotic interactions with multiple interconnected biological systems. The simultaneous interrogation of these systems with suitable technologies can reveal otherwise unrecognized crosstalk. In collaboration with several leading laboratories, we have produced multiomics datasets (including analysis the genome, proteome, microbiome, and metabolome) in synchronized groups of patients. Using these coordinated datasets, we will evaluate several algorithms for combining multiple biological modalities while accounting for the intrinsic characteristics of each assay, to reveal biological cross- talk across various systems and increase combined predictive power. Importantly, numerous population- level factors (including medical history, environmental, and socioeconomic factors) significantly impact the immune system and studies focused on homogenous patient populations often lack generalizability to other populations. To address this, we will develop machine learning strategies to integrate population-level factors directly into our immunological data. These models will objectively define subpopulations of patients and enable flexibility in the coefficients of the models (and hence, the importance of the various biological measurements) in each group.  This research program will be executed using data from several biorepositories focused on various diseases. This approach will ensure generalizability of our work to previously unseen datasets and increase the long-term impact of our findings. Throughout the proposal, a major area of focus is the development of visualization and model-reduction strategies that lay the foundation for interpretation of complex models. The machine learning algorithms developed will be readily applicable to a broad range of multiomics and multicohort studies and will be available as open-source software. PROJECT NARRATIVE Recent technological advances have enabled the production of large immune monitoring datasets, providing an opportunity for systems-level efforts to harness the power of the immune system in developing immune therapies and diagnostic tests. In this project, we will develop machine learning algorithms for analysis of the immune system at a single-cell level, in a multiomics setting integrated with various other biological measurements, and subject to adjustments based on population-level factors. This work will provide a strong quantitative bridge between large-scale epidemiologic trends and deep biological profiling to investigate the complex mechanisms that govern the immune system in clinical settings.",Machine Learning for Integrative Modeling of the Immune System in Clinical Settings,10028766,R35GM138353,"['Accounting', 'Address', 'Algorithmic Analysis', 'Algorithms', 'Area', 'Biological', 'Biological Assay', 'Cells', 'Characteristics', 'Clinical', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnostic tests', 'Dimensions', 'Disease', 'Ensure', 'Environmental Risk Factor', 'Epidemiological trend', 'Foundations', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Immunologic Monitoring', 'Immunological Models', 'Immunologics', 'Immunotherapy', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurement', 'Measures', 'Medical History', 'Modality', 'Modeling', 'Nature', 'Patients', 'Population', 'Production', 'Proteome', 'Reproducibility', 'Research', 'Series', 'Socioeconomic Factors', 'System', 'Technology', 'Visualization', 'Work', 'base', 'biobank', 'biological systems', 'cohort', 'flexibility', 'genome analysis', 'learning strategy', 'machine learning algorithm', 'metabolome', 'microbiome', 'multiple omics', 'open source', 'patient population', 'patient subsets', 'predict clinical outcome', 'programs', 'response']",NIGMS,STANFORD UNIVERSITY,R35,2020,382710,-0.021374499183903276
"Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches Project Summary The form (or shape) and function relationship of anatomical structures is a central theme in biology where abnor- mal shape changes are closely tied to pathological functions. Morphometrics has been an indispensable quan- titative tool in medical and biological sciences to study anatomical forms for more than 100 years. Recently, the increased availability of high-resolution in-vivo images of anatomy has led to the development of a new generation of morphometric approaches, called statistical shape modeling (SSM), that take advantage of modern computa- tional techniques to model anatomical shapes and their variability within populations with unprecedented detail. SSM stands to revolutionize morphometric analysis, but its widespread adoption is hindered by a number of sig- niﬁcant challenges, including the complexity of the approaches and their increased computational requirements, relative to traditional morphometrics. Arguably, however, the most important roadblock to more widespread adop- tion is the lack of user-friendly and scalable software tools for a variety of anatomical surfaces that can be readily incorporated into biomedical research labs. The goal of this proposal is thus to address these challenges in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM), which automat- ically constructs optimal statistical landmark-based shape models of ensembles of anatomical shapes without relying on any speciﬁc surface parameterization. The proposed research will provide an automated, general- purpose, and scalable computational solution for constructing shape models of general anatomy. In Aim 1, we will build computational and machine learning algorithms to model anatomies with complex surface topologies (e.g., surface openings and shared boundaries) and highly variable anatomical populations. In Aim 2, we will introduce an end-to-end machine learning approach to extract statistical shape representation directly from im- ages, requiring no parameter tuning, image pre-processing, or user assistance. In Aim 3, we will provide intuitive graphical user interfaces and visualization tools to incorporate user-deﬁned modeling preferences and promote the visual interpretation of shape models. We will also make use of recent advances in cloud computing to enable researchers with limited computational resources and/or large cohorts to build and execute custom SSM work- ﬂows using remote scalable computational resources. Algorithmic developments will be thoroughly evaluated and validated using existing, fully funded, large-scale, and constantly growing databases of CT and MRI images lo- cated on-site. Furthermore, we will develop and disseminate standard workﬂows and domain-speciﬁc use cases for complex anatomies to promote reproducibility. Efforts to develop the proposed technology are aligned with the mission of the National Institute of General Medical Sciences (NIGMS), and its third strategic goal: to bridge biology and quantitative science for better global health through supporting the development of and access to computational research tools for biomedical research. Our long-term goal is to increase the clinical utility and widespread adoption of SSM, and the proposed research will establish the groundwork for achieving this goal. Project Narrative This project will develop general-purpose, scalable, and open-source statistical shape modeling (SSM) tools, which will present unique capabilities for automated anatomy modeling with less user input. The proposed tech- nology will introduce a number of signiﬁcant improvements to current SSM approaches and tools, including the support for challenging modeling problems, inferring shapes directly from images (and hence bypassing the seg- mentation step), parallel optimizations for speed, and new user interfaces that will be much easier and scalable than the current tools. The proposed technology will constitute an indispensable resource for the biomedical and clinical communities that will enable new avenues for biomedical research and clinical investigations, provide new ways to answer biologically related questions, allow new types of questions to be asked, and open the door for the integration of SSM with clinical care.","Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches",9969467,R01AR076120,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomic Surface', 'Anatomy', 'Area', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Brain', 'Bypass', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Collection', 'Communities', 'Complex', 'Complex Analysis', 'Computational Technique', 'Computer Models', 'Computer software', 'Computers', 'Custom', 'Data', 'Databases', 'Development', 'Disease', 'Felis catus', 'Funding', 'Generations', 'Geometry', 'Goals', 'Human', 'Ice', 'Image', 'Imagery', 'Injury', 'Intuition', 'Laboratory Research', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematical Computing', 'Measures', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Modernization', 'Modification', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Occupations', 'Online Systems', 'Organism', 'Orthopedics', 'Pathologic', 'Population', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Shapes', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Speed', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Variant', 'Visual', 'Visualization software', 'Work', 'algorithm development', 'base', 'biomedical resource', 'clinical care', 'clinical investigation', 'clinically relevant', 'cohort', 'computerized tools', 'computing resources', 'deep learning', 'experience', 'flexibility', 'global health', 'graphical user interface', 'image archival system', 'image processing', 'imaging Segmentation', 'in vivo imaging', 'innovation', 'large datasets', 'machine learning algorithm', 'model development', 'multidisciplinary', 'open source', 'particle', 'preference', 'software development', 'tool', 'usability', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2020,614363,-0.02580105990898986
"Adapt2Quit – A Machine-Learning, Adaptive Motivational System: RCT for Socio-Economically Disadvantaged smokers” 7. Project Summary We will test Adapt2Quit, an innovative Machine-Learning, Adaptive Motivational Messaging System. Adapt2Quit uses complex, machine-learning algorithms to adaptively select the best messages for a smoker, based upon multiple attributes, including: 1) the smoker’s profile; 2) the smoker’s explicit feedback over time to the system; and 3) data from thousands of prior smokers’ profiles and their feedback patterns. Adapt2Quit’s type of machine- learning is called a recommender system. Outside healthcare, companies (like Amazon) use recommender systems to continuously learn from user feedback (e.g.: liked product, products purchased) to improve, thus enhancing personal relevance and customer engagement. Engagement is a huge challenge for digital health. In the field of computer-tailored health messaging, Adapt2Quit is the first to use machine-learning to continuously adapt to feedback and select new personalized messages to send to smokers. To evaluate the impact of the recommender system, Adapt2Quit will be compared with a robust, active control, a simple but effective messaging system. In our pilot experiment, Adapt2Quit outperformed the control, especially among socio- economically disadvantaged (SED) smokers. SED smokers are harder to engage in interventions. Thus, Adapt2Quit’s increased engagement will be of particular importance for targeting SED smokers. In addition to the potential impact of the Adapt2Quit messages in inducing and engaging smokers in cessation, our goal is to increase use of the state Quitline. We will recruit 700 SED smokers at two sites. All smokers will complete a baseline interview and receive a paper brochure with information about the state’s Quitline. Smokers will then be randomized to: Adapt2Quit or the standard messaging. As the system is designed to enhance engagement, and through engagement lead to positive actions, Aim 1 will focus on engagement [Hypothesis (H1a) Among Adapt2Quit smokers, those with higher engagement levels (completed more ratings) will have greater scores on the perceived competence scale (PCS)]. Aim 2 compares (Adapt2Quit and control) behavior change processes including perceived competence for smoking cessation and cessation supporting actions (calling a Quitline) [H2a: Adapt2Quit smokers will have greater scores on the PCS than control smokers; H2b: Adapt2Quit smokers will adopt more cessation supporting actions (Quitline, NRT) than control smokers]. Aim 3 will assess effectiveness of the system [H3a: (primary outcome) Adapt2Quit smokers will have greater smoking cessation rates (6-month point prevalence biochemically verified) than control smokers; H3b: (secondary outcome) Adapt2Quit smokers will have lower time to first quit attempt than control smokers; H3c: (mediation analysis) Measured internal and external processes will mediate the effect of Adapt2Quit on smoking cessation]. To accomplish the above aims, we have brought together a multidisciplinary team with relevant expertise, and a strong track record of collaboration. 8. Narrative We propose testing Adapt2Quit — an innovative motivational texting “recommender system.” Adapt2Quit enhances tailored motivational messaging systems using machine-learning algorithms to learn from, and adapt to, user feedback (prior and daily message ratings), thereby increasing message personal relevance. Our study will test Adapt2Quit motivational messaging texting with socioeconomically disadvantaged (SED) smokers.","Adapt2Quit – A Machine-Learning, Adaptive Motivational System: RCT for Socio-Economically Disadvantaged smokers”",9954825,R01CA240551,"['Address', 'Adopted', 'Award', 'Behavior Therapy', 'Behavioral', 'Belief', 'Biochemical', 'Collaborations', 'Competence', 'Complex', 'Computers', 'Data', 'Disease', 'Effectiveness', 'Engineering', 'Evaluation', 'Feedback', 'Frequencies', 'Funding', 'Goals', 'Health', 'Healthcare', 'Heterogeneity', 'Individual', 'Intervention', 'Interview', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Motivation', 'Odds Ratio', 'Pamphlets', 'Paper', 'Pattern', 'Prevalence', 'Process', 'Randomized', 'Readiness', 'Self Determination', 'Self Efficacy', 'Site', 'Smoke', 'Smoker', 'Smoking', 'Smoking and Health Research', 'System', 'Target Populations', 'Testing', 'Text Messaging', 'Time', 'active control', 'base', 'behavior change', 'design', 'digital', 'disadvantaged population', 'evidence base', 'experimental study', 'health care settings', 'health disparity', 'high risk population', 'improved', 'innovation', 'learning progression', 'machine learning algorithm', 'multidisciplinary', 'nicotine replacement', 'primary outcome', 'quitline', 'recruit', 'rural healthcare', 'secondary outcome', 'smoking cessation', 'socioeconomic disadvantage', 'theories']",NCI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2020,712077,-0.015446990212780719
"Improving Population Representativeness of the Inference from Non-Probability Sample Analysis SUMMARY The critical role of population-representativeness for estimating disease incidence and prevalence has been widely accepted in epidemiologic studies. Improving population representativeness of nonprobability samples, such as samples of volunteers in epidemiologic studies or electronic health records, however, has received little attention by biostatisticians or epidemiologists. In this project, we propose two innovative “pseudoweight” construction methods: 1) two-step matching, and 2) calibration, under an adapted exchangeability assumption, for unbiased estimation of disease incidence and prevalence in the target population. The proposed methods, combined with machine learning methods for propensity score estimation, will achieve significant bias reduction, especially when selection into nonprobability samples is driven by complex relationships between the covariates. We will quantify the bias reduced by the proposed “pseudoweights”, numerically and empirically, on the estimation of disease incidence and prevalence in the target population. Monte Carlo simulation studies are designed under varying degrees of departure from the adapted exchangeability assumption to evaluate the bias of the proposed estimates. The robustness of the proposed estimators against varying sample sizes, number of clusters in survey, and complexities of the true propensity score modeling will be investigated in scenarios that differ by levels of non-linearity, non-additivity and correlations between covariates in the true propensity model. Using data from National Institutes of Health and the American Association of Retired Persons (NIH-AARP, a nonprobability cohort sample) data and the US National Health Interview Survey (NHIS, a probability survey sample), the proposed methods will be applied to estimate the prevalence of self-reported diseases and all-cause or all-cancer mortality rates for people aged 50-71 in the US. To test our methods, we will purposely select outcome variables that are available in both the NIH-AARP and the NHIS. Thus, the amount of bias in NIH-AARP estimates corrected by the proposed pseudoweights can be quantified in practice, assuming the weighted NHIS estimate is true. The proposed methods, although motivated by the volunteer-based epidemiological studies, have wide applications outside of epidemiology, such as electronic health records or web surveys. The results from this project can be used by epidemiologists and health policy makers to improve the understanding of the health-related characteristics in the general population. Computer software that implements the proposed methods will be made available for public use. PROJECT NARRATIVE The project proposes innovative “pseudoweights” construction methods for nonprobability samples, such as samples of volunteers in epidemiologic studies or electronic health records, to improve their population representativeness. The project will quantify the amount of bias reduced by the proposed “pseudoweights,” numerically and empirically, on the estimation of population parameters such as disease incidence and prevalence. The result can be used by epidemiologists and health policy makers to improve the understanding of the health related characteristics in the general population.",Improving Population Representativeness of the Inference from Non-Probability Sample Analysis,10046869,R03CA252782,"['American', 'Attention', 'Calibration', 'Characteristics', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Equilibrium', 'General Population', 'Health', 'Health Policy', 'Incidence', 'Internet', 'Lead', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monte Carlo Method', 'National Health Interview Survey', 'Outcome', 'Patient Self-Report', 'Policy Maker', 'Population', 'Prevalence', 'Probability', 'Probability Samples', 'Research', 'Role', 'Sample Size', 'Sampling', 'Source', 'Surveys', 'Target Populations', 'Testing', 'Trees', 'United States National Institutes of Health', 'Weight', 'aged', 'base', 'cohort', 'complex data ', 'design', 'epidemiology study', 'flexibility', 'improved', 'innovation', 'machine learning method', 'mortality', 'random forest', 'retiree', 'software development', 'volunteer']",NCI,"UNIV OF MARYLAND, COLLEGE PARK",R03,2020,154500,-0.030475707495731308
"Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study PROJECT SUMMARY The built environment is an important modifiable determinant of human health, yet our ability to understand its effects on human health have been limited by the lack of scalable data on specific components (and exposures) of the built environment. The emergence of ubiquitous geo-referenced imagery in the United States (e.g. Google Street View Imagery), combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring street-level built environment features at scales needed for population-based research. To develop and demonstrate the potential of deep learning algorithms for environmental health research we will: develop methods to assess green space features using street view imagery and deep learning algorithms; create new deep learning algorithms to predict urban green space quality, stress reduction and restorative potential; and apply new street view measures to 9,070 adult Twin Pairs in the Washington Twin Registry to determine associations between green space and mental health. Our proposed study will dramatically move the field of environmental health forward by provided a completely new, transferable and scalable exposure assessment method for assessing built environment exposures relevant to human health and provide robust information on how urban green space influences mental health. Overall, our new approach will provide rich new data sources for environmental epidemiologists, city planners, policy makers and neighborhoods and communities at large. PROJECT NARRATIVE The built environment is an important determinant of human health, yet our ability to measure specific components of the built environment relevant to health is limited. The availability of street view imagery, combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring detailed built environment features at scales needed for population-based research. Here we develop such approaches for green space and evaluate associations with mental health using a unique Twin analysis.",Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study,9998736,R21ES029722,"['Adult', 'Anxiety', 'Attention', 'Baseline Surveys', 'Biological', 'Buffers', 'Case Study', 'Cities', 'Communities', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Databases', 'Dizygotic Twins', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Epidemiologist', 'Esthetics', 'Flowers', 'Genetic', 'Green space', 'Health', 'Human', 'Image', 'Imagery', 'Link', 'Measures', 'Mechanics', 'Mental Depression', 'Mental Health', 'Mental Health Associations', 'Methods', 'Monozygotic twins', 'Nature', 'Neighborhoods', 'Neurocognitive', 'Outcome Measure', 'Pathway interactions', 'Perception', 'Plants', 'Poaceae', 'Policy Maker', 'Population Research', 'Psychological Transfer', 'Registries', 'Research', 'Rest', 'Sampling', 'Stress', 'Surveys', 'Training', 'Trees', 'Twin Multiple Birth', 'Twin Studies', 'United States', 'Washington', 'base', 'biological adaptation to stress', 'built environment', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'directed attention', 'distraction', 'early life exposure', 'experimental study', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'learning strategy', 'longitudinal analysis', 'novel', 'novel strategies', 'response', 'restoration', 'segmentation algorithm', 'stress reduction', 'theories']",NIEHS,OREGON STATE UNIVERSITY,R21,2020,185625,-0.01791087370686608
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10022332,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2020,243885,-0.021915205537083312
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10228145,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2020,59206,-0.021915205537083312
"Using machine learning to predict odor characteristics from molecular structure PROJECT SUMMARY/ABSTRACT We cannot yet look at a chemical structure and predict if the molecule will have an odor, much less what character it will have. The goal of the proposed research is to apply machine learning to predict perceptual characteristics from chemical features of molecules. The specific aims of the proposal will determine (1) which molecules are odorous , and (2) what data are needed to model odor character. Building a highly predictive model requires two key ingredients: high-quality data and a sound modeling approach. High-quality data must be accurate (ratings are consistent and describe true odor properties) and detailed (ratings describe even small differences in odor properties). We have collected human psychophysical data on a diverse set of molecules and have trained a model to predict if a molecule has an odor, but pilot data identified odorous contaminants that limit model training and measurement of model accuracy. In Aim 1, I will apply my background in analytical chemistry to evaluate the accuracy of the data, using gas chromatography to identify and correct errors caused by chemical contaminants. In Aim 2, I will apply my experience in human sensory evaluation to measure and compare the consistency and the degree of detail in ratings that can be achieved with different sensory methods and subject training procedures. By executing my training plan, I will develop the skills in statistical programming and machine learning needed to employ a sound modeling approach to these problems. The model constructed in Aim 1 will enable prediction of odor classification (odor/odorless) for any molecule and thus define which molecules are perceptually relevant. Predicting odor character is a far more complex challenge – while a molecule can have only one of two odor classifications (odor or odorless) it may elicit any number of diverse odor character attributes (fruity, floral, musky, sweet, etc.). Descriptive Analysis (DA) is the gold standard method for generating accurate and detailed sensory profiles, but this method is time-consuming. We estimate that an odor character dataset will be large enough (“model-ready”) to predict odor character with approximately 10,000 molecules and that it would require more than 30,000 hours of human subject evaluation, or approximately 6 years for the typical trained panel, to produce this dataset using DA. Before we invest the time and resources, it is responsible to evaluate the relative data quality of more rapid sensory methods. The results of Aim 2 are expected to determine the best approach for generating a model-ready dataset by quantifying trade-offs in degree of detail (data resolution), rating consistency, and method speed of five candidate sensory methods. Together, these aims represent a significant step forward in linking chemical recipe to human odor perception, an advancement that supports the NIDCD goal of understanding normal olfactory function (how stimulus relates to percept) and has many potential applications in foods (what composition of molecules should be present to produce a target aroma percept). PROJECT NARRATIVE Currently, scientists cannot predict whether a molecule will have an odor and, if so, what odor characteristics it will have based on its chemical structure. The goal of this project is to develop predictive models linking chemical composition to odor characteristics. These models will advance our understanding of the human olfactory system and help design strategies for improving the aroma and palatability of healthy foods.",Using machine learning to predict odor characteristics from molecular structure,10142097,F32DC019030,"['Address', 'Analytical Chemistry', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Classification', 'Collection', 'Complex', 'Consumption', 'Data', 'Data Set', 'Descriptor', 'Development', 'Evaluation', 'Food', 'Fruit', 'Gas Chromatography', 'Goals', 'Gold', 'Health Food', 'Hour', 'Human', 'Human Resources', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Structure', 'National Institute on Deafness and Other Communication Disorders', 'Odors', 'Olfactory Pathways', 'Palate', 'Perception', 'Positioning Attribute', 'Procedures', 'Programmed Learning', 'Property', 'Protocols documentation', 'Psychophysics', 'Quality Control', 'Recipe', 'Research', 'Research Technics', 'Resolution', 'Resources', 'Sampling', 'Science', 'Scientist', 'Sensory', 'Smell Perception', 'Speed', 'Stimulus', 'Structure', 'Testing', 'Time', 'Training', 'Work', 'base', 'data quality', 'design', 'experience', 'food science', 'human subject', 'improved', 'machine learning algorithm', 'model building', 'predictive modeling', 'prevent', 'rapid technique', 'skills', 'sound']",NIDCD,MONELL CHEMICAL SENSES CENTER,F32,2020,67446,-0.026889612011221004
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Summary The goal of this project is to develop a smartphone-based wayfinding app designed to help people with visual impairments navigate indoor environments more easily and independently. It harnesses computer vision and smartphone sensors to estimate and track the user’s location in real time relative to a map of the indoor environment, providing audio-based turn-by-turn directions to guide the user to a desired destination. An additional option is to provide audio or tactile alerts to the presence of nearby points of interest in the environment, such as exits, elevators, restrooms and meeting rooms. The app estimates the user’s location by recognizing standard informational signs present in the environment, tracking the user’s trajectory and relating it to a digital map that has been annotated with information about signs and landmarks. Compared with other indoor wayfinding approaches, our computer vision and sensor-based approach has the advantage of requiring neither physical infrastructure to be installed and maintained (such as iBeacons) nor precise prior calibration (such as the spatially referenced radiofrequency signature acquisition process required for Wi-Fi-based systems), which are costly measures that are likely to impede widespread adoption. Our proposed system has the potential to greatly expand opportunities for safe, independent navigation of indoor spaces for people with visual impairments. Towards the end of the grant period, the wayfinding software (including documentation) will be released as free and open source software (FOSS). Health Relevance For people who are blind or visually impaired, a serious barrier to employment, economic self- sufficiency and independence is the ability to navigate independently, efficiently and safely in a variety of environments, including large public spaces such as medical centers, schools and office buildings. The proposed research would result in a new smartphone-based wayfinding app that could greatly increase travel independence for the approximately 10 million Americans with significant vision impairments or blindness.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,9899994,R01EY029033,"['Adoption', 'Algorithms', 'American', 'Blindness', 'Calibration', 'Cellular Phone', 'Computer Vision Systems', 'Computer software', 'Cost Measures', 'Destinations', 'Development', 'Documentation', 'Economics', 'Elevator', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Floor', 'Focus Groups', 'Goals', 'Grant', 'Health', 'Indoor environment', 'Infrastructure', 'Location', 'Maps', 'Measures', 'Medical center', 'Needs Assessment', 'Performance', 'Process', 'Research', 'Schools', 'System', 'Systems Integration', 'Tactile', 'Testing', 'Time', 'Travel', 'Visual', 'Visual impairment', 'base', 'blind', 'design', 'digital', 'improved', 'interest', 'lens', 'meetings', 'open source', 'radio frequency', 'sensor', 'way finding', 'wireless fidelity']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2020,416374,-0.0062000952965249895
"Physically Realistic Virtual Surgery Physically Realistic Virtual Surgery Abstract While virtual reality (VR)-based surgical simulation technology is being developed to improve laparoscopic surgical training outside the operating room (OR), existing simulators focus mostly on technical skills (TS) of hand-eye coordination for isolated tasks and seldom on non-technical skills (NTS) associated with both cognitive skills of decision making, as well as interpersonal skills of communication, team-work and conflict resolution. To enable VR-based surgical simulators to also train for cognitive skills, in the previous grant period we successfully developed the next generation (Gen2) of laparoscopic surgical simulators that immerse the trainee in a virtual OR using a head-mounted display (HMD) system, and introduce distractions, interruptions and other stressors to capture the high-stress environment of the real OR. However, to the best of our knowledge, there exists no VR-based simulator for training interpersonal skills needed for the multidisciplinary integration of OR teams, which consist of surgeons, anesthesiologists, and perioperative nurses. Following the significant reduction of adverse events in other disciplines, such as aviation, by the introduction of mandatory simulation-based team training (e.g., crew resource management), the National Surgical Skills Curriculum developed by the American College of Surgeons (ACS) and Association of Program Directors in Surgery (APDS) has prescribed ten team-based training modules to be performed in a simulation facility (e.g., an OR endosuite) with scenario-based training on high- fidelity manikin simulators. However, such facility-based team training is extremely expensive and cumbersome, requires dedicated facility and faculty time, and entails significant planning and schedule coordination between trainees, technicians, and faculty. To overcome the challenges of facility-based OR team training, the goal of this project is to extend the immersive VR technology (Gen2) developed as part of our prior grant for a single user to the entire OR team, and harness recent advances in cloud computing, mobile device-based VR and artificial intelligence and machine learning to design, develop and evaluate a Virtual Operating Room Team Experience (VORTeX) simulation system. The VORTeX will allow the OR team to train together in a distributed fashion (i.e., not co-located in the same room or simulation facility) wearing mobile device-based HMD systems to develop further their NTS based on computer-generated simulation scenarios replacing the physical ones. Evaluation of the simulation scenarios will be performed asynchronously by a team of experts based on post-action replays. We will implement the VORTeX for a laparoscopic cholecystectomy crisis scenario, developed and validated by our Co-I Dr. Dan Jones at BIDMC and adopted as one of the team training modules of the ACS/APDS national surgical skills curriculum. We hypothesize that the VORTeX will be at least as good as or better than traditional facility-based simulation in providing non-technical skills training to OR teams. Project Narrative: The goal of this research is to develop and validate a comprehensive computer-based technology that will allow surgical trainees to practice their surgical skills on computer-based models. Surgical procedures and techniques, learnt and perfected in this risk-free manner before application to patients, will translate to fewer operating room errors, reduced patient morbidity and improved patient outcomes resulting in faster healing, shorter hospital stay and reduced post surgical complications and treatment costs.",Physically Realistic Virtual Surgery,9969824,R01EB005807,"['Adopted', 'Adoption', 'Adverse event', 'American College of Surgeons', 'Artificial Intelligence', 'Aviation', 'Awareness', 'Behavior', 'Board Certification', 'Boston', 'Client', 'Cloud Computing', 'Communication', 'Computer Models', 'Computers', 'Consensus', 'Decision Making', 'Discipline', 'Educational Curriculum', 'Educational process of instructing', 'Effectiveness', 'Enrollment', 'Environment', 'Evaluation', 'Event', 'Exposure to', 'Face', 'Faculty', 'Feedback', 'Floor', 'Goals', 'Grant', 'Internet', 'Interruption', 'Israel', 'Laparoscopic Cholecystectomy', 'Length of Stay', 'Machine Learning', 'Manikins', 'Medical center', 'Minimally Invasive Surgical Procedures', 'Modeling', 'Morbidity - disease rate', 'Operating Rooms', 'Operative Surgical Procedures', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perioperative Nursing', 'Phase', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Resources', 'Risk', 'Running', 'Schedule', 'Software Framework', 'Standardization', 'Stress', 'Surgeon', 'Surgical complication', 'System', 'Technical Expertise', 'Techniques', 'Technology', 'Testing', 'Thinking', 'Time', 'Training', 'Training Activity', 'Translating', 'Treatment Cost', 'Variant', 'Work', 'base', 'cloud platform', 'cognitive skill', 'cognitive training', 'computer generated', 'conflict resolution', 'design', 'distraction', 'experience', 'experimental study', 'eye hand coordination', 'handheld mobile device', 'head mounted display', 'healing', 'improved', 'instructor', 'interactive computing', 'member', 'multidisciplinary', 'next generation', 'novel', 'programs', 'simulation', 'simulation environment', 'skills', 'skills training', 'stressor', 'success', 'virtual', 'virtual environment', 'virtual reality', 'virtual reality environment', 'virtual surgery']",NIBIB,RENSSELAER POLYTECHNIC INSTITUTE,R01,2020,646125,-0.005070345027259843
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9929633,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2020,1011405,-0.046335303285177806
"Patient specific 3D printed tissue engineered vascular graft for aortic reconstruction designed by artificial intelligence algorithm. 1 The goal of this study is to create patient-specific, hemodynamically optimized, tissue engineered  2 vascular grafts (TEVG) for use in aortic arch repair surgery. These TEVGs are optimized for high pressure  3 circulation using 3D printing technology and artificial intelligence, and will grow with the patient, in hopes of  4 obviating need for future surgeries to replace grafts, which can occur with contemporary arch reconstruction  5 materials. Congenital heart disease (CHD) is the leading cause of death due to congenital anomalies. Despite  6 significant advances in surgical management for CHD, one significant source of morbidity and mortality arises  7 from the complexity of surgery for diverse anatomies in the aortic arch. Previous studies have demonstrated  8 that the resultant arch geometry after surgical reconstruction of stenotic or hypoplastic aortas is important to  9 minimize reduce energy loss and undesirable flow inside the arch, which can lead to hypertension, abnormal 10 vascular response and ventricular dysfunction. Ensuring a patient-specific graft design for ideal reconstructed 11 route before surgery with minimum energy loss and wall shear stress may yield long-term benefits for patient 12 health and quality of life. 13 We have demonstrated native vessel like neotissue formation of TEVG in small and large animal 14 studies. Based on these experiences, we have developed a novel 3D printing technology combining 3D printed 15 metal mandrels with nanofiber electro-spun technology. With this 3D printing technology, we showed that 16 TEVG developed native like neovessel formation in venous circulation in a sheep model. For this next step, we 17 aim to develop grafts in arterial circulation that can be applied to aortic reconstruction. We will also develop 18 automatic design algorithms to design optimal graft shape in order to reduce time and cost of patient specific 19 design. We hypothesize that patient-specific TEVG using our 3D printing technology can be designed, 20 aided by pre-operative imaging and flow data, computer assisted design (CAD), automatic design 21 algorithms based on computation fluid dynamics (CFD) results, and will demonstrate proper neotissue 22 formation and growth while maintaining optimally designed hemodynamics. 23 This project will be an important step towards clinical application of patient-specific vascular grafts that 24 recapitulate the native anatomy and mechanical properties. The results of this work will have a broader impact 25 on the design and fabrication of other more complex cardiovascular structures for implantation. This paradigm 26 shift in vascular graft technology will improve the quality and safety of pediatric patient care. The goal of this study is to create patient-specific, hemodynamically optimized, tissue engineered vascular grafts using 3D printing technology and artificial intelligence for use in aortic arch repair surgery which demands a structured surgical approach in order to optimize hemodynamics postoperatively. We will optimize the design of an aortic graft automatically using computational flow dynamics, refine 3D printing manufacturing, evaluate grafts with in-vitro testing, and finally will test the performance of the grafts in vivo over time. This paradigm shift in vascular graft technology will improve the quality, safety and longevity of pediatric cardiovascular care.",Patient specific 3D printed tissue engineered vascular graft for aortic reconstruction designed by artificial intelligence algorithm.,10024070,R01HL143468,"['3-Dimensional', '3D Print', '4D MRI', 'Acute', 'Adult', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Animals', 'Aorta', 'Artificial Intelligence', 'Blood Circulation', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Cause of Death', 'Childhood', 'Clinic', 'Complex', 'Computer-Aided Design', 'Computers', 'Consumption', 'Custom', 'Data', 'Descending aorta', 'Ensure', 'Experimental Animal Model', 'FDA approved', 'Future', 'Geometry', 'Goals', 'Growth', 'Health', 'Histologic', 'Hypertension', 'Image', 'Implant', 'In Vitro', 'Inferior vena cava structure', 'Lead', 'Liquid substance', 'Longevity', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Operative Surgical Procedures', 'Organ', 'Patient Care', 'Patients', 'Performance', 'Physiological', 'Postoperative Period', 'Process', 'Quality of life', 'Route', 'Safety', 'Shapes', 'Sheep', 'Source', 'Structure', 'Surgical Management', 'Technology', 'Time', 'Tissue Engineering', 'Tissues', 'Translating', 'Vascular Graft', 'Venous', 'Ventricular Dysfunction', 'Work', 'aortic arch', 'base', 'clinical application', 'congenital anomaly', 'congenital heart disorder', 'cost', 'design', 'experience', 'hemodynamics', 'implantation', 'improved', 'in vitro testing', 'in vivo', 'intelligent algorithm', 'mechanical properties', 'model design', 'mortality', 'nanofiber', 'novel', 'pediatric patients', 'performance tests', 'preservation', 'pressure', 'reconstruction', 'repaired', 'response', 'scaffold', 'shear stress', 'surgery outcome', 'vascular tissue engineering']",NHLBI,UNIVERSITY OF CHICAGO,R01,2020,568300,-0.011166571752904458
"Computer Vision-Based Navigation System for High-Precision Orthopedic Trauma Surgery PROJECT SUMMARY / ABSTRACT Closed or open fracture reduction and internal fixation is the standard surgical approach in treating pelvic fractures, with current clinical practice using fluoroscopic guidance, guidewire insertion, and cannulated screw placement. The challenge in reckoning complex 3D morphology in 2D fluoroscopy presents a major source of uncertainty, trial-and- error, and poor outcomes, with 20-30% rate of suboptimal screw placement and long fluoroscopic runtime (mean fluoro time > 123 s) exposing operating personnel to high levels of radiation exposure. Despite these challenges, mainstream surgical approach has remained largely unchanged for 35 years, and surgical navigation systems (though increasingly common in neurosurgery) present cost and workflow barriers that limit their broad applicability in trauma surgery. We propose a computer vision-based navigation approach that is compatible with routine trauma surgery workflow, offers real-time guidance with accuracy comparable to stereotactic navigation, gives ten-fold reduction in radiation exposure, and works with tools already common in the trauma surgery arsenal. The proposed system uses a miniature stereoscopic camera mounted onboard the surgical drill in combination with 3D-2D registration of fluoroscopic views for direct, real-time registration of the instrument trajectory relative to patient anatomy. Real-time overlay of instrument trajectory in fluoroscopic views and/or CT permits accurate identification of guidewire entry point, orientation, and conformance within bone corridors and will reduce reliance on “fluoro hunting” and trial-and-error guidewire placement. The following aims develop and evaluate the system for application in pelvic trauma surgery, including quantitative assessment of accuracy, workflow, and radiation dose in pre-clinical studies. Aim 1. System for computer vision-based guidance in trauma surgery. The hardware and software components required for vision-based tracking onboard a standard surgical drill will be developed, providing real-time trajectory overlay in fluoroscopy and/or preoperative CT. A fast calibration method will be developed for automatic drill axis calibration. Automatic feature-based registration of the video and fluoroscopic frames enables real-time overlay of instrument trajectory in fluoroscopic views (Fluoro Navigation), and 3D-2D registration between CT and fluoroscopy will enable real-time overlay of the instrument trajectory in CT (CT Navigation). Aim 2: Evaluation in preclinical studies. The vision-based navigation system will be implemented in pre-clinical (cadaver) experiments to evaluate accuracy and workflow. These studies will evaluate the geometric accuracy and workflow factors relating to the number of repeated insertion attempts, procedure time, and radiation dose, evaluating vision-based Fluoro Navigation and CT Navigation in comparison to conventional freehand fluoroscopy guidance. Successful completion of the aims will establish a system suitable for computer vision-based navigation to be translated to clinical studies in future work. Such a system offers a potentially major advance in routine trauma surgery, bringing capabilities comparable to state-of-the-art stereotactic navigation without the cost, complexity, and additional workflow of conventional navigation. PROJECT NARRATIVE Even experienced trauma surgeons are challenged in resolving the complex 3D morphology of the pelvis in 2D x-ray fluoroscopy, presenting a major source of uncertainty, a high rate of malpositioned screws, and high levels of radiation exposure to the patient and operating staff. To facilitate high-precision pelvic trauma surgery and reduce intraoperative radiation dose, we propose a computer vision-based navigation approach providing real-time overlay of surgical instrument trajectories in fluoroscopic views and CT, facilitating accurate identification of guidewire entry point, orientation, and conformance within safe bone corridors. The approach offers a major advance compared to conventional navigation by not requiring intraoperative 3D imaging, avoiding time-consuming calibration, and eliminating externally-positioned hardware in the operating room, and the proposed research translates the system from basic development and quantitative testing to preclinical studies evaluating geometric accuracy, workflow, and radiation dose.",Computer Vision-Based Navigation System for High-Precision Orthopedic Trauma Surgery,10005337,R21EB028330,"['3-Dimensional', '3D Print', 'Affect', 'Anatomy', 'Biopsy', 'Cadaver', 'Calibration', 'Clinical Research', 'Closed Fractures', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Consumption', 'Detection', 'Development', 'Diagnostic radiologic examination', 'Ensure', 'Evaluation', 'Exposure to', 'Fluoroscopy', 'Fracture', 'Future', 'Healthcare', 'High Prevalence', 'Hour', 'Human Resources', 'Image', 'Incidence', 'Mainstreaming', 'Methods', 'Morphology', 'Navigation System', 'Needles', 'Open Fractures', 'Operating Rooms', 'Operative Surgical Procedures', 'Optics', 'Orthopedics', 'Outcome', 'Patients', 'Pelvis', 'Persons', 'Positioning Attribute', 'Procedures', 'Radiation Dose Unit', 'Radiation exposure', 'Research', 'Roentgen Rays', 'Source', 'Structure', 'Surgeon', 'Surgical Instruments', 'System', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Training', 'Translating', 'Translations', 'Trauma', 'Uncertainty', 'Visceral', 'Vision', 'Work', 'base', 'bone', 'clinical practice', 'comorbidity', 'cortical bone', 'cost', 'disability', 'experience', 'experimental study', 'improved', 'instrument', 'instrumentation', 'mortality', 'neurosurgery', 'neurovascular', 'pelvis fracture', 'pre-clinical', 'preclinical study', 'sample fixation', 'socioeconomics', 'stereoscopic', 'tool', 'virtual']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,204688,-0.009514732917924273
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10027477,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2020,360287,-0.031275613162240416
"Therapeutic potential of vagal neurostimulation to reduce food intake Obesity affects almost 40% percent of US adults and is associated with high levels of comorbidities, including cancer, cardiovascular disease, and diabetes. Although effective treatments with minimal side effects are lacking, vagus nerve stimulation (VNS) can reduce body weight and suppress feeding behavior. There is little insight, however, into its mechanism and it is unclear whether VNS effects on feeding and body weight result from non-specific side effects, such as nausea. The current application directly addresses these issues by assessing gastrointestinal (GI) myoelectric changes as a potential mechanism for effects of VNS on feeding behavior, while comparing these responses to emetic activation. We plan to accomplish this by using a ferret model, which is a gold-standard for studying emesis, vagus nerve, and GI physiology. We will test the hypothesis that electrical stimulation of the vagus nerve can reduce food intake without triggering indicators of nausea, such as disrupted GI myoelectric responses, retching, and vomiting. We will complete three Aims. Aim 1: Define the individualized GI myoelectric patterns during feeding behavior using machine learning classification. Animals will be implanted with planar electrodes attached to the GI serosal surface from proximal gastric fundus to distal duodenum. We will use machine learning to classify GI myoelectric patterns of meal consumption compared to emetic-related states, including those elicited by intragastric emetine and high amplitude and frequency VNS known to trigger emesis. Aim 2: Test the efficacy of abdominal VNS on reducing meal size without triggering disruptions of GI myoelectric responses, retching, and emesis. Animals will be assessed for effects of abdominal VNS using a variety of stimulus parameters on feeding behavior and multi-site GI myoelectric recordings. Aim 3: Determine the efficacy of cervical VNS in controlling meal size without producing off-target effects (disruptions of GI myoelectric responses, retching, emesis, changes in heart rate, or blood pressure). We will test the impact of cervical VNS parameters on feeding behavior, GI myoelectric responses, retching, emesis, hear rate variability, and blood pressure. Our approach is innovative because we will use machine learning classification to detect individualized GI myoelectric response patterns in an awake free-moving animal for comparing therapeutic and off-target effects of VNS on feeding, GI activity, emesis, and cardiovascular function. This planned research is significant because VNS therapy can potentially provide a frontline treatment option for patients with high levels of obesity refractory to behavioral or pharmacological therapy, which unlike other surgical interventions for weight loss, such as gastric bypass, is potentially tunable and reversible by changing stimulation parameters, switching the device off, or complete removal. Obesity affects almost 40% percent of US adults, is associated with type 2 diabetes, cardiovascular disease, and cancer, and has a health-care cost that could total nearly one trillion US dollars by 2030. The current project is designed to test vagus nerve stimulation to reduce food intake, while limiting adverse effects, such as nausea, vomiting, and disrupted gastrointestinal function. Our proposed research is relevant to the NIH’s plan to support the design and testing of new interventions for achieving and maintaining a healthy weight (Strategic Plan for NIH Obesity Research).",Therapeutic potential of vagal neurostimulation to reduce food intake,9963258,R01DK121703,"['Abdomen', 'Address', 'Adult', 'Adverse effects', 'Affect', 'Anatomy', 'Animals', 'Behavioral', 'Blood Pressure', 'Body Weight', 'Body Weight decreased', 'Cardiovascular Diseases', 'Cardiovascular Physiology', 'Cardiovascular system', 'Cervical', 'Chemicals', 'Chronic', 'Classification', 'Consumption', 'Data', 'Devices', 'Diabetes Mellitus', 'Distal', 'Duodenum', 'Eating', 'Effectiveness', 'Electric Stimulation', 'Electrodes', 'Emetics', 'Emetine', 'Event', 'Excision', 'FDA approved', 'Feeding behaviors', 'Ferrets', 'Fiber', 'Frequencies', 'Gastric Bypass', 'Gastrointestinal Motility', 'Gastrointestinal Physiology', 'Gastrointestinal tract structure', 'Goals', 'Gold', 'Health Care Costs', 'Hearing', 'Heart Rate', 'Implant', 'Individual', 'Intervention', 'Laboratory Rat', 'Laboratory mice', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Modeling', 'Nausea', 'Nausea and Vomiting', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pharmacology', 'Phenotype', 'Physiological', 'Rattus', 'Refractory', 'Reporting', 'Research', 'Rodent Model', 'Satiation', 'Sensory', 'Signal Transduction', 'Site', 'Sleep', 'Stimulus', 'Stomach', 'Strategic Planning', 'Surface', 'Testing', 'Therapeutic', 'Training', 'United States National Institutes of Health', 'Upper digestive tract structure', 'Vagus nerve structure', 'Vomiting', 'awake', 'behavioral pharmacology', 'comorbidity', 'design', 'effective therapy', 'efficacy testing', 'experimental study', 'feeding', 'gastric fundus', 'gastrointestinal', 'gastrointestinal function', 'healthy weight', 'heart rate variability', 'indexing', 'innovation', 'insight', 'learning classifier', 'machine learning algorithm', 'obesity treatment', 'personalized medicine', 'pre-clinical', 'predicting response', 'recruit', 'reduced food intake', 'response', 'side effect', 'support vector machine', 'therapeutic target', 'vagus nerve stimulation', 'weight loss intervention']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,508751,-0.028520419242678067
"Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers Abstract COVID-19 has made traveling as a blind or visually impaired person much riskier and more difficult than before the pandemic. As a result, people with visual impairments may limit their essential travel such as trips to the doctor’s office, the pharmacy and grocery shopping and walks for exercise or leisure. Accordingly, the goal of this COVID Supplement, which builds on and expands the work being conducted by the parent grant, is to develop a COVID map tool that provides fully accessible, non-visual access to maps. This tool will allow visually impaired persons to explore maps and preview routes from the comfort of their home, allowing them to plan their travel along safer, less congested routes using crowdedness data. In addition, the tool will present county-by-county COVID incidence data in a fully accessible form, which will inform their travel plans over greater distances. Thus, this project will give visually impaired persons the tools and confidence to undertake safer, more independent travel. Health Relevance The COVID-19 pandemic has an especially severe impact on people with significant vision impairments or blindness. The need for social distancing and reduced touching of one’s surroundings has made traveling as a blind or visually impaired person much riskier and more difficult than before the pandemic. As a result, people with visual impairments may limit their essential travel such as trips to the doctor’s office, the pharmacy and grocery shopping and walks for exercise or leisure. These travel limitations may have adverse impacts on their physical and mental health. The proposed research would result in a new software tool that could greatly increase the confidence of the approximately 10 million Americans with significant vision impairments or blindness to undertake safe, independent travel.",Leveraging Maps and Computer Vision to Support Indoor Navigation for Blind Travelers,10220178,R01EY029033,"['American', 'Blindness', 'COVID-19', 'COVID-19 pandemic', 'Cellular Phone', 'Color', 'Communities', 'Computer Vision Systems', 'Computers', 'County', 'Crowding', 'Data', 'Destinations', 'Development', 'Ensure', 'Evaluation', 'Exercise', 'Goals', 'Health', 'Home environment', 'Incidence', 'Internet', 'Knowledge', 'Leisures', 'Maps', 'Mental Health', 'Pharmacy facility', 'Process', 'Publications', 'Research', 'Route', 'Running', 'Social Distance', 'Software Tools', 'System', 'Tablets', 'Tactile', 'Target Populations', 'Touch sensation', 'Travel', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Walking', 'Work', 'blind', 'braille', 'coronavirus disease', 'design', 'outreach', 'pandemic disease', 'parent grant', 'physical conditioning', 'software development', 'symposium', 'tool', 'way finding']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,2020,406525,-0.0071623554612725866
"Development of a prototype software for automated PET/CT interpretation and reporting in thoracic cancer Abstract. In cancer, body-wide FDG-PET/CT is a prime modality for diagnosis, staging, and treatment assessment. Despite its paramount importance to enable precision medicine in cancer, no method is currently available for automated disease burden estimation and standardized reporting on PET/CT images regionally and globally in anatomic organs and lymph node zones within a body region or body-wide. Automated production- mode body-wide/ body-region-wide disease measurement with standardized reporting will foster cancer research discovery and will be of great interest to oncologists, radiologists/ nuclear medicine physicians, Medicare and private health insurers, and pharmaceutical companies that conduct clinical trials of new cancer therapeutics and currently rely on manual methods of response assessment. The overarching goal of this Phase I project is, therefore, to develop, validate, and demonstrate a prototype software for disease measurement and reporting via FDG-PET/CT in the above manner in one body region, namely thorax, based on innovative algorithms that are generalizable body-wide. The project has two aims: Aim 1: Develop, implement, and validate algorithms for disease burden estimation in thoracic cancer via FDG-PET/CT. Aim 2: Develop and demonstrate a prototype software implementing the above algorithms for disease measurement and reporting. Aim 1 will be accomplished in 3 stages: Tasks 1, 2: PET/CT image data sets which are radiologically near normal for the thoracic body region will be gathered from existing whole-body scans of 100 patients. In these data sets, 7 key anatomic organs and 5 key lymph node zones in the thorax will be delineated under expert guidance. These data will be used to build population fuzzy anatomy models following our established Automatic Anatomy Recognition (AAR) methodology. An additional 100 whole-body PET/CT scans of patients with different types of cancer will be gathered to test our methods. Using available commercial clinical software, the PET uptake properties of lesions in organs and diseased lymph nodes in lymph node zones will be measured manually and used as reference ground truth of disease burden. Task 3: Deep learning (DL) algorithms anatomically guided by AAR will be developed to very accurately localize (but not delineate) organs and lymph node zones in PET/CT images using the models. Task 4: Novel methods based on fuzzy principles will be developed to automatically tag and quantify pathological regions (without explicitly delineating them) within located organs and nodal zones, and the accuracy of disease measurement will be evaluated (Task 5). Aim 2 will be accomplished by incorporating the disease measurement methodology into a prototype software named AAR-DQ (Tasks 6, 7) based on our earlier software platform CAVASS. AAR-DQ will report disease burden in a hierarchical manner – (i) at the body-region level; (ii) at each organ/ lymph node zone level; (ii) at each lesion/ lymph node level. Expected milestones. Aim 1: AAR-DQ disease measurement not to deviate more than 10% from clinical ground truth measurement. Aim 2: Disease measurement/ reporting in under 5 minutes per patient PET/CT study. Automated production-mode body-wide/ body-region-wide disease measurement has numerous potential applications in cancer and other diseases and has considerable commercial potential. The overarching goal of this Phase I STTR project is to develop, validate, and demonstrate a prototype software for disease measurement and reporting via FDG-PET/CT in the above manner in one body region, namely thorax, based on innovative algorithms that are generalizable body-wide.",Development of a prototype software for automated PET/CT interpretation and reporting in thoracic cancer,10076938,R41CA236492,"['Abbreviations', 'Abdomen', 'Algorithms', 'Anatomy', 'Artificial Intelligence', 'Body Burden', 'Body Regions', 'Cancer Patient', 'Chest', 'Clinical', 'Communication', 'Computer software', 'Conduct Clinical Trials', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Discipline of Nuclear Medicine', 'Disease', 'Distant', 'Fostering', 'Geography', 'Glycolysis', 'Goals', 'Head and neck structure', 'Health', 'Image', 'Image Analysis', 'Insurance Carriers', 'Knowledge', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Medicare', 'Methodology', 'Methods', 'Mining', 'Modality', 'Modeling', 'Monitor', 'Names', 'Nodal', 'Normalcy', 'Oncologist', 'Organ', 'PET/CT scan', 'Pathologic', 'Patient-Focused Outcomes', 'Patients', 'Pelvis', 'Pharmacologic Substance', 'Phase', 'Physicians', 'Population', 'Positron-Emission Tomography', 'Privatization', 'Production', 'Property', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research Personnel', 'Sampling Biases', 'Scanning', 'Small Business Technology Transfer Research', 'Staging', 'Standardization', 'Technology', 'Testing', 'Therapeutic', 'Training', 'X-Ray Computed Tomography', 'algorithm training', 'anticancer research', 'base', 'burden of illness', 'cancer diagnosis', 'cancer type', 'deep learning', 'deep learning algorithm', 'evidence based guidelines', 'fluorodeoxyglucose positron emission tomography', 'imaging modality', 'improved', 'innovation', 'interest', 'learning strategy', 'lymph nodes', 'lymphoid organ', 'model building', 'novel', 'object recognition', 'outcome forecast', 'payment', 'precision medicine', 'prototype', 'radiologist', 'response', 'software development', 'treatment response', 'uptake', 'whole body imaging']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R41,2020,252131,-0.034698126585322966
"Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings Project Summary: Darwin Babino, PhD, a trained pharmacologist/electrophysiologist, has spent the last ten years working on several disciplines in the vision sciences. His proposal entitled “Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings” presents his overarching goal to improve vision restoration approaches by developing methods to test the potential of these techniques thereby accelerating the development of effective interventions. Dr. Babino and his primary mentor, Dr. Russell Van Gelder, have assembled a strong team of co-mentors at the University of Washington SOM and collaborators to guide him through the proposed training and research. His previous training will be supplemented with goals to help his development as an independent investigator: 1) Study design and practical learning in performing panretinal (MEA) biological experiments; 2) Fundamental and advanced techniques of the proposed optogenetic and stem-cell restoration techniques; 3) Application of advanced machine learning techniques; 4) Develop leadership and professional skills to establish an independent group. The ability to assess the function of panretinal circuitry will foster our understanding of the advantages and weaknesses of different restoration techniques (Aim 1). The work proposed here will improve an existing retinal acuity assessment tool which combines machine learning techniques on novel, high-density multielectrode array recordings of ganglion cell responses in several mouse models. The utility of this system will be demonstrated in assessing visual potential of the mouse retina in three different approaches to vision restoration that are challenging for in vivo assessment (Aim 2). In collaboration with Dr. Deepak A. Lamba at UCSF, we will apply our system to animals which have undergone stem-cell replacement of retinal cells including photoreceptor cells. An optogenetics approach will also be evaluated in collaboration with Dr. John Flannery at UC Berkeley whose group has developed vectors for expressing rhodopsin and cone opsins in ganglion and bipolar cells. Finally, differences between native and restored vison with small molecule photoswitches, light-activated inhibitors of voltage-gated potassium channels, which confer light-dependent firing on treated cells, will be assessed. The resulting advanced electrophysiology application will help elucidate fundamental questions about the functional retina, mechanisms that lead to retinal degeneration and the potential of several therapeutics for the treatment of retinal diseases. Furthermore, this career development award will facilitate Dr. Babino’s development into an independent investigator by priming an R01 grant application. Project Narrative: Project Narrative: The prevalence of vision loss from retinal degeneration numbers in the millions world-wide and is expected to double by the year 2050, and despite the development of several promising approaches to restore vision in the blind, progress in developing these therapies has been hampered by challenges in analysis of these methods in animal models. We describe a novel system that analyzes, by machine learning, retinal ganglion cell output in native, degenerated and therapeutically treated blind retinas which can characterize the visual information content of the ‘reanimated’ blind retina and thereby facilitate the development of these technologies. The system developed through this grant, as well as the career development pursued by the investigator, will be readily applicable to the assessment of potential retinal acuity restoration by current and novel therapeutic approaches.",Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings,9943144,K99EY031333,"['Aftercare', 'Amacrine Cells', 'Animal Model', 'Animals', 'Applications Grants', 'Assessment tool', 'Behavioral Assay', 'Biological', 'Blindness', 'Cells', 'Collaborations', 'Cone', 'Contrast Sensitivity', 'Data', 'Development', 'Discipline', 'Dissection', 'Doctor of Philosophy', 'Ectopic Expression', 'Electrophysiology (science)', 'Electroretinography', 'Evolution', 'Feedback', 'Fostering', 'Ganglia', 'Genetic', 'Goals', 'Grant', 'Human', 'Image', 'In Vitro', 'Individual', 'Intervention', 'K-Series Research Career Programs', 'Knockout Mice', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Light', 'MW opsin', 'Machine Learning', 'Measurable', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Methods', 'Movement', 'Mus', 'Opsin', 'Output', 'Photoreceptors', 'Prevalence', 'Protocols documentation', 'Psychophysics', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Retina', 'Retinal Cone', 'Retinal Degeneration', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Retinal gene therapy', 'Rhodopsin', 'Rod', 'Rodent', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Specificity', 'Stimulus', 'Synapsins', 'System', 'Systems Analysis', 'Systems Development', 'Techniques', 'Testing', 'Therapeutic', 'Training', 'Transgenic Organisms', 'Universities', 'Vertebrate Photoreceptors', 'Viral', 'Vision', 'Visual', 'Visual Acuity', 'Visual system structure', 'Voltage-Gated Potassium Channel', 'Washington', 'Wild Type Mouse', 'Work', 'base', 'behavior test', 'blind', 'career development', 'cell type', 'cost effective', 'density', 'effective intervention', 'experimental study', 'ganglion cell', 'improved', 'in vivo', 'induced pluripotent stem cell', 'inhibitor/antagonist', 'interest', 'light intensity', 'mimicry', 'mouse model', 'multi-electrode arrays', 'mutant', 'nonhuman primate', 'novel', 'novel therapeutic intervention', 'optogenetics', 'promoter', 'rapid eye movement', 'response', 'restoration', 'scale up', 'skills', 'small molecule', 'stem cells', 'technology development', 'therapy development', 'tool', 'vector', 'vision science', 'visual information']",NEI,UNIVERSITY OF WASHINGTON,K99,2020,113080,-0.035125808049769496
"Machine learning accelerated on-line adaptive replanning Abstract. The overall goal of this proposal is to develop and test a novel machine learning (ML) accelerated On-Line Adaptive Replanning (MOLAR) solution for magnetic resonance imaging (MRI) guided radiation therapy (RT) (MRgRT). During the multi-fraction RT process, the location, shape and size of tumors and normal organs vary significantly between the fractions. These interfraction variations are among the major factors that can limit the accuracy of RT targeting. The current standard practice of image-guided RT (IGRT), developed to address the interfraction variations based on cone-beam CT (CBCT), can only correct for translational errors, and thus does not fully account for interfraction changes. To address this issue, researchers recently introduced online adaptive replanning (OLAR) that generates a new plan based on the anatomy of the day and delivers the plan for the fraction. Currently, two main obstacles affect the success of OLAR: (1) the anatomy of the day cannot be delineated accurately based on CBCT, and (2) the time required to perform OLAR is long enough to render it impractical. One way to improve the delineation accuracy is to use MRI versus CT. MRI-guided OLAR is currently being introduced into the clinics to substantially improve RT targeting. However, the bottleneck is still the impractical length of time required to segment the anatomy of the day, which can exceed 30 minutes. Furthermore, available synthetic CT (sCT) generation methods are slow or inaccurate for MRI-guided OLAR. There is no method available to quickly and objective determine when OLAR is necessary. To address these issues, we plan to develop novel techniques in the MOLAR solution. We hypothesize that the MRI-based MOLAR solution will fully account for interfraction changes, thereby substantially improving tumor targeting during RT delivery and the effectiveness of RT. Specifically, we aim to (1) develop practical ML-based solutions to quickly determine the necessity of OLAR and to rapidly generate accurate synthetic CTs; (2) develop ML-based techniques to substantially accelerate segmentation for OLAR using a progressive three-step process; and (3) verify clinical practicality and effectiveness of MOLAR by retrospectively and prospectively applying the MOLAR on MRI sets to test its speed and effectiveness in accounting for interfraction variations. We will develop this novel MOLAR solution by forging unique collaborations between clinical physicists, radiation oncologists and industry developers via an established academic-industry partnership. The successful completion of this project will enable clinicians to routinely practice “image-plan-treat”, which is the optimal solution for MRgRT. This new paradigm will fully account for interfraction variations, improve tumor targeting, reduce normal tissue toxicity, and ultimately encourage clinicians to revise the current doses and/or dose fractionations to increase therapeutic gain, enhance patient quality of life, and/or substantially save on healthcare costs. Our proposed strategy represents a drastic departure from current practice. We firmly believe that this strategy is the future of RT delivery. Project Narrative: This R01 application proposes to develop and test a novel machine learning accelerated online adaptive replanning (MOLAR) solution for magnetic resonance imaging (MRI) guided adaptive radiation therapy through a unique academic and industry partnership. The MOLAR solution aims to fully account for interfraction variations, thereby substantially improving the accuracy and effectiveness of radiation therapy (RT) for cancer. This solution will enable clinicians to routinely practice “image-plan-treat”, a drastic departure from current practice and representing the future of RT delivery.",Machine learning accelerated on-line adaptive replanning,9941621,R01CA247960,"['3-Dimensional', 'Accounting', 'Address', 'Adoption', 'Affect', 'Air', 'Anatomy', 'Clinic', 'Clinical', 'Collaborations', 'Dose Fractionation', 'Effectiveness', 'Electron Transport', 'Future', 'Generations', 'Goals', 'Health Care Costs', 'Image', 'Industry', 'Learning', 'Length', 'Location', 'Lung', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of pancreas', 'Maps', 'Methodology', 'Methods', 'Modality', 'Normal tissue morphology', 'Organ', 'Patients', 'Physiology', 'Process', 'Quality of life', 'Radiation Oncologist', 'Radiation therapy', 'Research Personnel', 'Shapes', 'Site', 'Speed', 'Surface', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Toxic effect', 'Variant', 'automated segmentation', 'base', 'bone', 'cancer radiation therapy', 'cone-beam computed tomography', 'convolutional neural network', 'electron density', 'forging', 'image guided', 'image guided radiation therapy', 'imaging modality', 'improved', 'industry partner', 'innovation', 'large datasets', 'neural network algorithm', 'novel', 'pancreatic cancer patients', 'prospective', 'prospective test', 'quantitative imaging', 'routine practice', 'soft tissue', 'success', 'targeted treatment', 'tool', 'treatment response', 'tumor']",NCI,MEDICAL COLLEGE OF WISCONSIN,R01,2020,517299,-0.047677209032649846
"Improving Diagnosis of Multiple Sclerosis Through the Integration of Novel Imaging and Laboratory Biomarkers Project Summary/Abstract:  The diagnosis of multiple sclerosis (MS) remains challenging due to its clinical heterogeneity and lengthy differential diagnosis. The incorrect assignment of a diagnosis of MS occurs in approximately 9% of newly evaluated patients and is associated with considerable clinically important, and avoidable, medical risk, morbidity, and healthcare costs. At the same time studies have demonstrated that many patients encounter a significant diagnostic delay prior to confirmation of a correct diagnosis of MS. In such patients early and accurate diagnosis of MS can result in prompt initiation of disease modifying therapy and consequent preventable disability. MS remains a clinical diagnosis and diagnostic criteria for MS are revised periodically, including most recently in 2017. Since implementation of the 2017 criteria, like all prior revisions, will continue to rely on subjective clinical and radiological assessments for its fulfillment, misdiagnosis will remain a risk.  New objective, automated, and clinically applicable approaches to MS diagnosis are needed. Recent preliminary data from cross-sectional pilot studies in patients with established diagnoses have shown promise for three new radiographic and three new laboratory methods to differentiate MS from other disorders. The present study will evaluate these six methods for the first time in a prospective cohort of 125 patients undergoing an initial evaluation for MS at an academic MS subspecialty center. The specificity and sensitivity of each method will be compared to fulfillment of 2017 MS diagnostic criteria at the time of initial clinical evaluation. Using diagnostic thresholds developed from this analysis, a two year post-enrollment analysis will also be performed in participants who did not meet 2017 criteria initially but did so during the subsequent two year interval to determine if the study methods could have predicted a diagnosis of MS earlier in such patients. The use of a multimodal and machine-learning approach to evaluate the integration of each of these six new methods which represent different aspects of MS neuroinflammatory and neurodegenerative processes will also be performed during each analysis, and such a combination of radiographic and laboratory methodology may provide superior diagnostic accuracy compared to any given method alone.  Planned collaborative career development, mentoring, and advising activities will facilitate acquisition of specific advanced quantitative and qualitative research skills necessary to develop and coordinate collection of data for this large prospective cohort study to rigorously evaluate new diagnostic methods for MS and incorporate machine learning analyses. Successful completion of this study will provide experience and skills necessary to move the field of MS diagnosis forward through a planned prospective multicenter NIH R01 funded study. Project Narrative: A highly specific, sensitive, objective and automated novel diagnostic approach to multiple sclerosis (MS) is needed maximize early benefits of disease modifying therapy in patients with MS and to prevent the frequent problem of MS misdiagnosis. This project assesses three novel MRI techniques and three novel blood tests for the diagnosis of MS in a large prospective cohort undergoing a new clinical evaluation for suspect MS. While each method may show promise alone, utilization of machine learning methodology combining these approaches that represent different aspects of MS pathophysiology may demonstrate a highly accurate and clinically applicable methodology for MS diagnosis.",Improving Diagnosis of Multiple Sclerosis Through the Integration of Novel Imaging and Laboratory Biomarkers,9843746,K02NS109340,"['Algorithms', 'Appearance', 'Atrophic', 'Binding', 'Biological Assay', 'Biological Markers', 'Blood Tests', 'C-Peptide', 'Central Vein', 'Clinical', 'Clinical/Radiologic', 'Computer Models', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic radiologic examination', 'Differential Diagnosis', 'Disease', 'Early Diagnosis', 'Enrollment', 'Erythrocytes', 'Evaluation', 'Evolution', 'Functional disorder', 'Funding', 'Gene Expression', 'Goals', 'Gold', 'Health Care Costs', 'Image', 'Inflammatory', 'Laboratories', 'Lesion', 'Light', 'Liquid substance', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Multiple Sclerosis', 'Myelin', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuronal Injury', 'Participant', 'Pathogenesis', 'Patients', 'Peptides', 'Pilot Projects', 'Process', 'Prospective cohort', 'Prospective cohort study', 'Qualitative Research', 'RNA', 'Rare Diseases', 'Risk', 'Sensitivity and Specificity', 'Serum', 'Specificity', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Thalamic structure', 'Time', 'Training', 'United States National Institutes of Health', 'Untranslated RNA', 'Whole Blood', 'accurate diagnosis', 'career development', 'clinical Diagnosis', 'clinical application', 'clinical diagnostics', 'clinical heterogeneity', 'clinical phenotype', 'clinical practice', 'cohort', 'diagnostic accuracy', 'disability', 'disease heterogeneity', 'experience', 'gray matter', 'improved', 'machine learning method', 'multimodality', 'multiple sclerosis patient', 'neurofilament', 'neuroinflammation', 'novel', 'novel diagnostics', 'novel imaging technique', 'prevent', 'prospective', 'recruit', 'research clinical testing', 'skills', 'specific biomarkers', 'support vector machine', 'white matter']",NINDS,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,K02,2020,193783,-0.011706356191380314
"Optical Coherence Elastography of the Cornea PROJECT SUMMARY The fundamental physical properties of the outer tunic of the eye determine the structural characteristics of the ocular globe and may be altered in several devastating disease states including axial elongation in myopia, pathological deformation in keratoconus, and iatrogenic keratoectasia following corneal refractive surgery. These biomechanical tissue characteristics not only influence our clinical interpretation of diagnostic tests, e.g. measurement of intraocular pressure, but have been implicated as important factors in the development of glaucoma. Currently, there is no available reliable method to perform quantitative measurement of corneal elasticity in vivo. Here we will develop novel method for the assessment of corneal elastic properties that could potentially be used for routine clinical diagnostic and treatment. This method will take advantages of highly localized air pressure stimulation and ultra-sensitive detection and analysis of the pressure waves propagation on corneal posterior and anterior surfaces with a line-field Optical Coherence Tomography to reconstruct volumetric biomechanical properties of the cornea. Our previous work has made fundamental advances in the understanding of corneal biomechanics through a novel approach with potentially impactful applications in other disciplines (e.g. cataract surgery, LAISK, corneal cross-linking, and tissue transplants with personalize treatments). The proposed studies will accelerate transition of this technology into clinics, influence our selection and application of corneal surgical treatments and will help us to understand the structural consequences of corneal disease and wound healing: Aim 1. Develop a line-field OCE (LF-OCE) system for ultrafast 3D clinical imaging. Aim 2. In vivo studies with rabbits. Aim 3. Preliminary clinical studies in humans. Aim 4. Refine numerical (FEM) and Artificial Intelligence (AI) models of the depth-dependent nonlinear viscoelastic properties of the cornea. PROJECT NARRATIVE This proposal will focus on the development of novel technology and methods for noninvasive assessment of biomechanical properties of the cornea. Development of such a technique would significantly advance our understanding of the corneal disorders, allow developing novel clinical therapies and interventions, and improve outcome of current surgical ant therapeutic interventions.",Optical Coherence Elastography of the Cornea,10063805,R01EY022362,"['3-Dimensional', 'Achievement', 'Agreement', 'Air Pressure', 'Animals', 'Anisotropy', 'Anterior', 'Ants', 'Artificial Intelligence', 'Beds', 'Biological', 'Biomechanics', 'Cataract Extraction', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Connective Tissue', 'Cornea', 'Corneal Diseases', 'Custom', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Diagnostic tests', 'Discipline', 'Disease', 'Elasticity', 'Eye', 'Glaucoma', 'Goals', 'Heterogeneity', 'Human', 'Iatrogenesis', 'Image', 'Individual', 'Intervention', 'Keratoconus', 'Knowledge', 'Laser In Situ Keratomileusis', 'Link', 'Location', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Myopia', 'Nature', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Oryctolagus cuniculus', 'Outcome', 'Pathologic', 'Patients', 'Physiologic Intraocular Pressure', 'Physiological', 'Property', 'Protocols documentation', 'Reaction', 'Reporting', 'Research', 'Routine Diagnostic Tests', 'Shapes', 'Signal Transduction', 'Speed', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Therapeutic Intervention', 'Time', 'Tissue Transplantation', 'Tissues', 'Training', 'Tunic', 'Validation', 'Variant', 'Work', 'base', 'biomechanical model', 'clinical diagnostics', 'clinical imaging', 'clinical translation', 'clinically significant', 'convolutional neural network', 'corneal epithelial wound healing', 'crosslink', 'deep learning', 'denoising', 'design', 'elastography', 'improved', 'improved outcome', 'in vivo', 'insight', 'mechanical properties', 'models and simulation', 'new technology', 'novel', 'novel strategies', 'personalized medicine', 'physical property', 'pressure', 'response', 'success', 'viscoelasticity', 'visual tracking']",NEI,UNIVERSITY OF HOUSTON,R01,2020,410000,-0.020333647907309613
"Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1 PROJECT SUMMARY Previous studies showed discrepancies of health and behavior prevalence between American Indians (AI) population and other racial or ethnic groups. Most health surveys have certain limitations when studying AI population due to the small sample sizes for AI population. Data collected by AI Tribal Epidemiology Centers (TECs) provides an excellent opportunity to conduct research for AI population due to sufficient sample size and extensive information. However, most surveys conducted by TECs used non-probability sampling design (e.g. convenient sample) due to its lower cost and increased time efficiency. Non-probability sample may suffer from sampling, coverage and nonresponse errors without further proper adjustments. Such difficulties greatly hampers the analysis of AI population in health and behavior research. Our general hypothesis is that data integration by combining information from non-probability and probability samples can reduce sampling, coverage and nonresponse errors in original non-probability sample. The Goal of this project is to develop an accurate and robust data integration methodology for AI population analysis specifically tailored to health and behavior research. During the past years, we have 1) studied data integration using calibration and parametric modeling approaches; 2) investigated machine learning and propensity score modeling methods in survey sampling and other fields; and 3) assembled an experienced team of multi-disciplinary team of experts. In this project, we propose to capitalize on our expertise and fulfill the following Specific Aims: Aim 1. Develop a data integration approach using machine learning and propensity score modeling We will develop machine learning and propensity score based data integration approaches to combine information from non-probability and probability samples. Compared to existing methods (i.e., Calibration, Parametric approach), our proposed approaches are more robust against the failure of underlying model assumptions. The inference is more general and multi-purpose (e.g. one can estimate most parameters such as means, totals and percentiles). Simulation studies will be performed to compare our proposed methods with other existing methods. A computing package will be built to implement the method in other settings. Aim 2. Evaluate the accuracy and robustness of the proposed method in AI health and behavior research We will use real data to validate the proposed methods in terms of accuracy and robustness to the various data types. The performance will also be assessed by comparing with results from existing data integration methods such as calibration and parametric modeling approaches. The planned study takes advantage of a unique data source and expands the impact of the Indian Health Service (IHS)-funded research. We expect this novel integration method will vertically advance the field by facilitating the analysis based on non-probability sample, which can provide in-depth understanding regarding the AI population health and behavior studies. Project Narrative The overall goal of this R21 project is to develop an accurate, robust and multi-purpose data integration methodology for AI population (non-probability sample) analysis specifically tailored to health and behavior research such as diabetes and smoking. The code implementing the proposed method will be released and is general enough to be applied to AI population studies of other fileds. The success of this study will vertically advance the field by facilitating the AI population analysis, which can provide a better guidance and new insights on the future precision personalized prevention and treatment of certain diseases.",Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1,10063407,R21MD014658,"['Adult', 'Age', 'American', 'American Indians', 'Behavioral', 'Behavioral Risk Factor Surveillance System', 'Calibration', 'Censuses', 'Code', 'Communities', 'Community Surveys', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Sources', 'Diabetes Mellitus', 'Disease', 'Epidemiology', 'Ethnic group', 'Event', 'Failure', 'Funding', 'Future', 'General Population', 'Geographic state', 'Goals', 'Health', 'Health Fairs', 'Health Surveys', 'Health behavior', 'High Prevalence', 'Kansas', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Not Hispanic or Latino', 'Oklahoma', 'Performance', 'Population', 'Population Analysis', 'Population Study', 'Prevalence', 'Probability', 'Probability Samples', 'Publishing', 'Race', 'Research', 'Research Personnel', 'Respondent', 'Risk Factors', 'Sample Size', 'Sampling', 'Smoking', 'Surveys', 'Target Populations', 'Testing', 'Texas', 'Time', 'Tobacco', 'Training', 'United States Indian Health Service', 'Weight', 'Work', 'Youth', 'base', 'behavioral study', 'cigarette smoking', 'cluster computing', 'cost', 'data integration', 'data quality', 'design', 'experience', 'improved', 'individualized prevention', 'innovation', 'insight', 'multidisciplinary', 'novel', 'personalized medicine', 'population health', 'simulation', 'smoking prevalence', 'success', 'therapy development', 'tribal health']",NIMHD,UNIVERSITY OF OKLAHOMA HLTH SCIENCES CTR,R21,2020,115176,-0.023363617425568473
"Systems Immunology in Aging and Chronic Diseases of Aging PROJECT SUMMARY / ABSTRACT The funds requested in this R13 application are for partial support of “Systems Immunology in Aging and Chronic Diseases of Aging” annual meetings to be offered each September from 2020 through 2022 at The Jackson Laboratory for Genomic Medicine (JAX-GM) in Farmington, Connecticut. This meeting builds on its very successful first instance in 2019 and will bring together up to 150 interdisciplinary scientists including molecular biologists, immunologists, computational biologists, and geriatricians, who share a common interest in understanding aging and aging-associated disease at the systems level. Many aging-associated diseases, such as cancer and cardiovascular disease, are influenced by dysfunctions in the immune system. Recent advances in genomic profiling techniques (e.g., single cell transcriptomics) provide an opportunity to uncover aging-related changes in human cells/tissues and to link these changes to health and lifespan. The wealth and complexity of data produced using these technologies is ever increasing, as is the need to develop advanced computational methods to mine and integrate these data. Despite this need, there are currently no formal venues at which scientists, specifically those in the aging field, can be trained in the basics and application of data mining techniques (i.e., machine learning algorithms). Furthermore, current conferences on aging are not aimed at specifically bringing together computational biologists, immunologists and basic and clinical aging researchers. Therefore, the objectives of this meeting are: (1) to recognize and emphasize the highly interdisciplinary nature of the aging field and to promote and accelerate collaborations and cross-pollination of ideas across the three disciplines: aging, immunology, and computational biology; (2) to provide trainees (students and postdoctoral fellows) an opportunity to closely interact with, and gain feedback from, more senior investigators to advance their projects and establish connections to help build their careers; and (3) to provide an opportunity for researchers in the field of aging to learn the basics of machine learning techniques, which they will be able to immediately apply to their own research upon return to their home institutions. We will reach these objectives through carrying out the following Aims. In Aim 1, we will organize an interdisciplinary meeting and hands-on workshop focused on aging and aging-related diseases. The meeting will include a 2-day seminar session featuring talks by leading scientists, followed by a 1-day hands-on workshop on the basics of machine learning. In Aim 2, we will promote interactions to foster collaborative research and career advancement, including through a poster session. In Aim 3, we will recruit diverse attendees. Our proposed speaker list features several female scientists, and we will use our partnership networks to specifically recruit attendees from nationally underrepresented racial and ethnic groups. The ultimate goal of the meeting is to advance the aging research field through expediting collaborations and the understanding of aging-related genomic data via application of advanced data mining approaches. PROJECT NARRATIVE / RELEVANCE TO PUBLIC HEALTH Aging and aging-associated diseases, such as Alzheimer's, cancer and cardiovascular disease, represent a significant and growing health and economic burden, with the elderly population of the US projected to double by 2030. Herein, we propose to organize an interdisciplinary conference with a hands-on computational training component that will bring together scientists from the fields of aging, immunology, and computational biology, which will enable creative collaborations and train early career scientists in the aging research field on the basics of advanced computational techniques to mine aging-related genomic data. This is ultimately expected to lead to a better molecular understanding of the aging process and to novel approaches for the improvement of human healthspan and/or lifespan.",Systems Immunology in Aging and Chronic Diseases of Aging,10070754,R13AG069519,"['Academia', 'Address', 'Affect', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Cardiovascular Diseases', 'Career Mobility', 'Cell physiology', 'Cells', 'Chronic Disease', 'Cities', 'Clinical', 'Collaborations', 'Complex', 'Computational Biology', 'Computational Technique', 'Computing Methodologies', 'Connecticut', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Discipline', 'Disease', 'Economic Burden', 'Educational workshop', 'Elderly', 'Ethnic group', 'Etiology', 'Feedback', 'Female', 'Fostering', 'Functional disorder', 'Funding', 'Genomic medicine', 'Genomics', 'Geroscience', 'Goals', 'Health', 'Home environment', 'Human', 'Immune', 'Immune system', 'Immunologist', 'Immunology', 'Industry', 'Inflammation', 'Institution', 'Lead', 'Learning', 'Link', 'Location', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'Mus', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Organism', 'Outcome', 'Participant', 'Phenotype', 'Play', 'Population', 'Postdoctoral Fellow', 'Process', 'Public Health', 'Pythons', 'Race', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scholarship', 'Science', 'Scientist', 'Series', 'Shock', 'Societies', 'Students', 'Support System', 'System', 'Techniques', 'Technology', 'The Jackson Laboratory', 'Time', 'Tissues', 'Training', 'Underrepresented Minority', 'Universities', 'Work', 'aging population', 'cancer type', 'career', 'clinical biomarkers', 'clinically significant', 'data mining', 'deep learning algorithm', 'epigenomics', 'frailty', 'genomic biomarker', 'genomic data', 'genomic profiles', 'graduate student', 'health economics', 'healthspan', 'innovation', 'interdisciplinary approach', 'interest', 'machine learning algorithm', 'meetings', 'next generation', 'novel strategies', 'posters', 'programs', 'recruit', 'response', 'senescence', 'single cell technology', 'skills', 'symposium', 'technology development', 'transcriptomics', 'translational approach']",NIA,JACKSON LABORATORY,R13,2020,34380,-0.031158030959905658
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Abstract Selective internal radiation therapy (SIRT) with preferential delivery of 90Y microspheres to target lesions has shown promising response rates with limited toxicity in the treatment of hepatocellular (HCC), the second leading cause of cancer death in the world. However, to achieve more durable responses, there is much room to improve/adapt the treatment to ensure that all lesions and lesion sub-regions receive adequate radiation delivery. While externally delivered stereotactic body radiation therapy (SBRT) is well suited for smaller solitary HCC, its application for larger or multifocal disease is challenged by the radiation tolerance of the normal liver parenchyma. A dosimetry guided combined approach that exploits complementary advantages of internal and external radiation delivery can be expected to improve treatment of HCC. To make this transition, however, prospective clinical trials establishing safety are needed. Furthermore, for routine clinic use, accurate and fast voxel-level dose estimation in internal radionuclide therapy, that lags behind external beam therapy dosimetry, is still needed. Our long-term goal is to improve the efficacy of radiation therapy with personalized dosimetry guided treatment. Our objective in this application is to demonstrate that it is possible to use 90Y imaging based absorbed dose estimates after SIRT to safely deliver external radiation to target regions (voxels) that are predicted to be underdosed and to develop deep learning based tools to make voxel-level internal dose estimation practical for routine clinic use. Specifically, in Aim 1, we will perform a Phase 1 clinical trial in HCC patients where we will take the novel approach of using the 90Y PET/CT derived absorbed dose map after SIRT to deliver SBRT to tumor regions predicted to be underdosed based on previously established dose-response models. The primary objective of the trial is to obtain estimates of safety of combined SIRT+SBRT for future Phase II trial design. In parallel, in Aim 2, building on promising initial results we will develop novel deep learning based tools for 90Y PET/CT and SPECT/CT reconstruction, joint reconstruction-segmentation and scatter estimation under the low count-rate setting, typical for 90Y. These methods have a physics/mathematics foundation, where convolutional neural networks (CNNs) are included within the iterative reconstruction process, instead of post-reconstruction denoising. In Aim 3, we will develop a CNN for fast voxel-level dosimetry and combine with the CNNs of Aim 2 to develop an innovative end-to-end framework with unified dosimetry-task based training. At the end of this study, we will be ready to use the new deep learning tools in a Phase II trial to demonstrate enhanced efficacy with SIRT+SBRT compared with SIRT alone and advance towards our long- term goal. This will accelerate adoption of these next-generation tools in clinical practice and will have a significant positive impact because treatment based on patient specific dosimetry will substantially improve efficacy, compared with current standard practice in SIRT. Although we focus on 90Y SIRT, our tools will be applicable in radionuclide therapy in general, a rapidly advancing treatment option. Narrative We will perform a Phase I clinical trial where standard-of-care Y-90 microsphere radioembolization in hepatocellular carcinoma will be followed by external radiation to target regions that are predicted to be underdosed by Y-90, based on patient specific dosimetry. In parallel, we will develop and test voxel-level internal dosimetry tools using convolution neural networks to make such dosimetry-based planning accurate and fast for routine clinic use. This study is relevant to public health because a dosimetry-guided combination radiation treatment approach is likely to substantially improve patient outcome compared to current standard practice of internal or external radiation only.",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,10052989,R01EB022075,"['90Y', 'Address', 'Adoption', 'Cancer Etiology', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Disease', 'Dose', 'Ensure', 'Evaluable Disease', 'External Beam Radiation Therapy', 'Failure', 'Foundations', 'Funding', 'Future', 'Goals', 'Hepatotoxicity', 'Image', 'Joint repair', 'Joints', 'Lesion', 'Liver', 'Liver parenchyma', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motivation', 'Noise', 'PET/CT scan', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Photons', 'Physics', 'Pilot Projects', 'Positron-Emission Tomography', 'Primary carcinoma of the liver cells', 'Process', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation therapy', 'Radioembolization', 'Radionuclide therapy', 'Reporting', 'Safety', 'Scanning', 'Testing', 'Time', 'Toxic effect', 'Training', 'base', 'clinical practice', 'clinically relevant', 'convolutional neural network', 'deep learning', 'denoising', 'dosimetry', 'image reconstruction', 'imaging Segmentation', 'improved', 'innovation', 'internal radiation', 'learning strategy', 'multimodal data', 'multimodality', 'next generation', 'novel', 'novel strategies', 'personalized cancer therapy', 'phase II trial', 'prospective', 'radiation delivery', 'reconstruction', 'response', 'single photon emission computed tomography', 'standard of care', 'tool', 'trial design', 'tumor']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,670584,-0.046984098890808054
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9989196,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'automated algorithm', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2020,222618,-0.022110119221933927
"Sensory Cue Integration in Melanoma Screening Imaging biomarkers are features in images that have biological implications. For example, in a picture of a person with red hair, the red hair is a feature and the implication is that there is a mutation in the MC1R gene that provides instructions for making a protein called the melanocortin 1 receptor. This feature, an imaging biomarker, can be used as a medical cue to indicate increased risk for melanoma. When used in this context, this imaging biomarker becomes an imaging biomarker cue (IBC), in the sense that it may cue the medical professional observer to alter treatment accordingly, such as recommending sunscreen use. IBCs do not individually bear the full weight of medical decision-making and instead are integrated. IBC analysis may be a process of sensory cue integration or may be a process of observation and integration by technology such as a digital camera and computer. An advantage of the latter is that computational scalability enables machine vision to compute vast permutations of IBCs that would be overwhelming to a human observer. Thus computers can try many potential diagnostic methods rapidly before picking the best one to teach back to humans. The purpose of this project is to develop a human/machine interface for bi-directional teaching so expert dermatologists can teach computers what IBCs they use to achieve accurate diagnosis and computers can teach dermatologists the best way to use current IBCs and suggest integration of new IBCs that machine learning guides them to. As an outcome, we will measure the diagnostic performance of dermatologists who undergo IBC training in detecting melanoma. It is known that early detection saves lives, but the potential of technology to improve early detection, a great need since 10,000 Americans still die each year from melanoma, is unknown. This project will help answer that unknown and if we are successful in translating IBCs with commuter vision and machine learning, more melanomas will be detected early and lives will be saved. Our long-term goal is to reduce melanoma related deaths and unnecessary biopsies by helping clinicians increase the predictive value of dermoscopy-based melanoma screening. We believe sensitivity and specificity of dermoscopy- based melanoma screening for non-expert screeners can be improved by assistive technology, which is highly desirable given the cost of false positives (patient stress and unnecessary biopsies) and the extremely high cost of false negatives (delayed melanoma treatment). This project creates a technology to help medical personnel see and integrate features of abnormal skin spots that help them determine if the spot they are looking at is a melanoma. Since melanoma is deadly if left untreated, this technology helps them guide biopsy and surgical removal of skin to potentially cut more melanomas out (saving lives) and not cut so many benign lesions out unnecessarily (leaving less scars). Our augmentation of vision and cognition uses machine learning in a way that is visually intuitive so physicians may be able to show their patients the rationale behind the choice to surgically excise abnormal skin spots or not to.",Sensory Cue Integration in Melanoma Screening,10025420,R21CA240254,"['Address', 'Algorithms', 'American', 'Area Under Curve', 'Back', 'Bayesian Modeling', 'Benign', 'Biological', 'Biopsy', 'Cessation of life', 'Cicatrix', 'Classification', 'Clinical', 'Code', 'Cognition', 'Complement Factor D', 'Computers', 'Control Groups', 'Cues', 'Decision Making', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Early Diagnosis', 'Educational process of instructing', 'Effectiveness', 'Excision', 'Exposure to', 'Feedback', 'Genes', 'Goals', 'Hair', 'Health Personnel', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Instruction', 'Intuition', 'Language', 'Left', 'Lesion', 'Logic', 'Machine Learning', 'Malignant - descriptor', 'Maps', 'Measures', 'Medical', 'Melanocortin 1 Receptor', 'Methodology', 'Modeling', 'Mole the mammal', 'Mutation', 'Nevus', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Persons', 'Physicians', 'Predictive Value', 'Procedures', 'Process', 'Proteins', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Reporting', 'Risk', 'Risk Factors', 'Savings', 'Screening Result', 'Self-Help Devices', 'Sensitivity and Specificity', 'Sensory', 'Sensory Process', 'Skin', 'Skin Abnormalities', 'Specific qualifier value', 'Spottings', 'Statistical Data Interpretation', 'Stress', 'Sunscreening Agents', 'Surface', 'Technology', 'Testing', 'Training', 'Translating', 'Uncertainty', 'Ursidae Family', 'User-Computer Interface', 'Vision', 'Visual', 'Weight', 'accurate diagnosis', 'base', 'clinical diagnostics', 'cost', 'deep learning', 'diagnostic accuracy', 'digital', 'graphical user interface', 'imaging biomarker', 'improved', 'machine learning algorithm', 'machine vision', 'melanoma', 'predictive modeling', 'prevent', 'rapid technique', 'screening', 'success', 'vector']",NCI,ROCKEFELLER UNIVERSITY,R21,2020,412585,-0.01844802367280432
"Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks PROJECT SUMMARY The long-term goal of this project is to improve the care of patients with laryngeal disorders through development of automated diagnostic support for in-office flexible laryngoscopy. To accomplish this goal, we propose developing neural network-based algorithms to detect and classify structural laryngeal lesions in laryngoscopy images. An automated diagnostic tool for in-office laryngoscopy such as we propose will have several benefits: (1) It will improve access to care for patients with symptoms of laryngeal dysfunction living in communities with limited otolaryngology resources, (2) It will improve early detection of laryngeal cancers potentially reducing the morbidity of treatment, and (3) It will prove a valuable teaching tool for students and residents first learning to interpret laryngoscopic exams. Flexible laryngoscopy is a common in-office procedure performed by otolaryngologists to evaluate the upper aerodigestive tract in patients with symptoms of laryngeal dysfunction. Subtle differences in the appearance of laryngeal lesions enable otolaryngologists to differentiate benign lesions from suspected malignant ones. The expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training and therefore laryngoscopy is largely only performed in subspecialty otolaryngology clinics. The primary objective of this project is to develop neural network-based algorithms to detect and classify structural laryngeal lesions. Our hypothesis is that these algorithms can be trained using a large dataset of laryngeal images to accurately detect and classify structural laryngeal lesions on flexible laryngoscopic exam. To test this hypothesis, we propose the following aims: (1) Generate a dataset of high-quality, labeled endoscopic laryngeal images corresponding to normal and structural lesions of the larynx, (2) Develop a location-aware anchor-based reasoning neural network for accurate detection of laryngeal lesions, and (3) Develop an adaptive network model for classification of structural laryngeal pathologies including papilloma, polyp, leukoplakia and suspected malignancy. With expertise in the diagnosis and treatment of laryngeal disorders and computer vision, including object detection and classification, our multidisciplinary team is uniquely qualified to complete this project. PROJECT NARRATIVE We propose to revolutionize in-office laryngoscopy through development of a deep neural network-based automated detection and classification system for diagnosis of structural diseases of the larynx. Currently, flexible laryngoscopy is only performed by expert subspecialists with years of experience because developing the expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training. Through development of deep neural network-based algorithms to detect and classify laryngeal lesions on in- office laryngoscopy, we will improve access to care for patients living in communities without subspecialty otolaryngology care and will develop an important teaching tool for clinicians learning to interpret laryngoscopic exams.",Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks,10043172,R03CA253212,"['Aerodigestive Tract', 'Algorithms', 'Anesthesia procedures', 'Appearance', 'Architecture', 'Awareness', 'Benign', 'Caring', 'Categories', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Collaborations', 'Colonic Polyps', 'Colonoscopy', 'Communities', 'Computer Vision Systems', 'Custom', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Distal', 'Drops', 'Early Diagnosis', 'Educational process of instructing', 'Ensure', 'Fellowship', 'Functional disorder', 'Gastroesophageal reflux disease', 'Goals', 'Health Services Accessibility', 'Hoarseness', 'Image', 'Improve Access', 'Infection', 'Label', 'Laryngeal Diseases', 'Laryngoscopes', 'Laryngoscopy', 'Larynx', 'Learning', 'Lesion', 'Leukoplakia', 'Location', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of larynx', 'Manuals', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Network-based', 'Normal Range', 'Otolaryngologist', 'Otolaryngology', 'Papilloma', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Pilot Projects', 'Plug-in', 'Polyps', 'Positioning Attribute', 'Procedures', 'Recurrence', 'Resources', 'Sampling', 'Semantics', 'Structure', 'Students', 'Symptoms', 'System', 'Technical Expertise', 'Testing', 'Training', 'Vision research', 'Work', 'base', 'classification algorithm', 'cost', 'deep neural network', 'detector', 'digital', 'experience', 'feature extraction', 'flexibility', 'improved', 'large datasets', 'learning algorithm', 'multidisciplinary', 'network models', 'neural network', 'tool']",NCI,UNIVERSITY OF KANSAS MEDICAL CENTER,R03,2020,154375,-0.05523354541669157
"Prospective Health Outcomes and Inflammatory Biomarkers Associated with e-Cigarette Use Project Summary. This project is designed to identify validated biomarkers for use in the assessment of electronic nicotine delivery systems (ENDS) by the FDA. Since the introduction of ENDS, commonly referred to as e-cigarettes, there has been a large increase in ENDS use among young adults and older traditional cigarette smokers who also use ENDS (dual users). Since 2016, the Food and Drug Administration (FDA) has had regulatory authority over ENDS, and there is an acute need for ENDS-related biomarkers that can be used as validated surrogate endpoints for evaluation of new ENDS products. With the goal of validated biomarker discovery in two independent cohorts, the COPDGene and UCSD ENDS studies, we propose to identify ENDS-related inflammatory biomarkers in ENDS only and dual users and relate these biomarkers to five-year lung health outcomes. COPDGene is an ongoing, longitudinal study of >6,000 current and former traditional cigarette (t-cig) smokers enriched for chronic obstructive pulmonary disease (COPD) with detailed longitudinal lung phenotyping data (including chest CT), genome-wide blood RNA-seq, and proteomic data. The UCSD ENDS Study is a controlled study of young ENDS only users and controls with detailed assessment of inflammatory biomarkers in the oropharynx, airways and blood.  Biomarkers used as validated surrogate measures must be 1) associated with ENDS use, 2) predictive of health outcomes, and 3) have a strong biological rationale. We hypothesize that inflammatory biomarkers of ENDS use will be predictive of five-year lung health effects. In Aim 1 of this proposal, discovery of inflammatory transcriptomic and proteomic biomarkers of ENDS exposure will be performed in subjects from the COPDGene five-year study visit, and biomarkers will be validated in two independent sets of subjects from the COPDGene ten-year visit and the UCSD ENDS Study. In Aim 2 we will identify antibody-specific adaptive immune response biomarkers of ENDS exposure using adaptive immune receptor repertoire sequencing (AIRR-seq). Auto-antibodies are biomarkers that are associated with the degree of lung damage in COPD. AIRR-seq is a powerful tool for inflammatory biomarker discovery that characterizes an individual’s decades-long history of antibody responses. In Aim 3 we will use machine learning predictive models to relate ENDS-associated biomarker panels to five-year lung health outcomes from COPDGene. The investigative team for this grant is well-positioned to identify novel inflammatory biomarkers of ENDS use. The COPDGene and UCSD cohorts have the detailed lung phenotyping and molecular characterization necessary to discover and clinically validate biomarkers in two important populations of ENDS users, i.e. ENDS only and dual users. Public Health Relevance: Since the introduction of electronic nicotine delivery systems (ENDS), commonly referred to as e-cigarettes, there has been a large increase in ENDS use among young adults and older traditional cigarette smokers who also use ENDS (dual users). Since 2016, the Food and Drug Administration (FDA) has had regulatory authority over ENDS, and there is an acute need for ENDS-related biomarkers that can be used as validated surrogate endpoints for evaluation of new ENDS products. Using two studies of ENDS users and controls, this project is designed to identify validated biomarkers for use in the health assessment of ENDS products.",Prospective Health Outcomes and Inflammatory Biomarkers Associated with e-Cigarette Use,10018099,R01HL147326,"['Acute', 'Adaptive Immune System', 'Address', 'Antibodies', 'Antibody Response', 'Autoantibodies', 'B-Lymphocytes', 'Biological', 'Biological Markers', 'Blood', 'Cells', 'Chronic Obstructive Airway Disease', 'Cigarette', 'Cigarette Smoker', 'Clinical', 'Control Groups', 'Controlled Study', 'Data', 'Disease', 'Electronic Nicotine Delivery Systems', 'Electronic cigarette', 'Elements', 'Evaluation', 'Genomics', 'Goals', 'Grant', 'Health', 'Human', 'Immunologic Receptors', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Response', 'Link', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Measures', 'Methods', 'Molecular', 'Mouse Strains', 'Oropharyngeal', 'Outcome', 'Pattern', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Proteomics', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Questionnaires', 'Recording of previous events', 'Respiratory Signs and Symptoms', 'Smoker', 'Spirometry', 'Surrogate Endpoint', 'T cell response', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Testing', 'United States Food and Drug Administration', 'Visit', 'X-Ray Computed Tomography', 'adaptive immune response', 'authority', 'biomarker discovery', 'biomarker panel', 'candidate marker', 'chest computed tomography', 'cohort', 'design', 'electronic cigarette use', 'genome-wide', 'health assessment', 'lung injury', 'novel', 'novel strategies', 'patient population', 'phenotypic data', 'predictive modeling', 'prospective', 'public health relevance', 'random forest', 'response biomarker', 'study population', 'targeted sequencing', 'tool', 'transcriptome sequencing', 'transcriptomics', 'young adult']",NHLBI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2020,509303,-0.04147142432142091
"DUET: Rapid dual-mode microscopy for quantitative slide-based renal fibrosis evaluation Contact PD/PI: Fereidouni, Farzad Abstract Kidneys, like other organs, have an inherent capacity to recover from acute injury; however, severe or recurrent injury can result in chronic kidney disease (CKD), the sequelae of which result in 82,000 deaths annually in the US alone. Regardless of the etiology of the initial injury, the common final pathway leading to- end stage renal disease is closely connected to fibrosis(excess or aberrant collagen distribution), one of the most important determinants of renal disease severity and prognosis. Histology is the gold standard for evaluation, typically through the use of histochemical stains such as trichrome and PAS that highlight the presence of collagens and basement membrane, respectively. Nevertheless, these stains are not completely specific, can be technically challenging to perform well and reproducibly, and thus contribute to interobserver variability and a concomitant decrease in diagnostic precision. Moreover, they also require the preparation of extra slides and additional staining procedures, and thus increase cost and can prolong the diagnostic process. We propose to optimize, deploy and test a new kind of microscope, DUET (DUal mode Emission and Transmission microscopy), developed at UC Davis, that will be a low-cost and very rapid solution for detection and digital characterization of the presence and distribution of collagen and other macromolecules, directly from standard formalin-fixed, paraffin-embedded hematoxylin and eosin-stained slides. Specifically, we will finalize the design of the hardware and software components of the instrument itself, validate imaging performance against standard histology and immunohistochemical stains for collagen and other components, and with the assistance of scientists at our partnering institutions (John Hopkins University and University of Buffalo) develop robust tools for analysis and quantitation of fibrosis. DUET instrument hardware will be shared with JHU to ensure that the methods are technically reproducible across multiple sites. The application leverages the expertise across three institutions in optics, biomedical engineering, renal pathology and novel artificial intelligence approaches. The goal of the project is development and validation of DUET, which promises to be a robust, inexpensive and practical approach for the rapid and accurate evaluation of fibrosis, extensible to other renal pathologies, and indeed across other organs systems, with significant positive impact on disease research, clinical practice, and patient outcomes. Page 6 Project Summary/Abstract Project Narrative Evaluation of fibrosis and tubular atrophy from chemically stained kidney biopsies are essential for diagnosis and disease-severity assessment, but current techniques are time-consuming, somewhat non-specific and contribute to interobserver variability and imprecision, affecting care. We propose to optimize and test a new kind of microscope (“DUET”) that can visualize fibrosis (scarring) and other tissue abnormalities directly from standard slides to enable high-quality reproducible fibrosis scoring and evaluation. This multi-site project will also provide a unique opportunity to perform a retrospective study from hundreds of existing H&E slides with associated months to years of clinical follow-up data, and to create a method with demonstrated utility in more than one institution.",DUET: Rapid dual-mode microscopy for quantitative slide-based renal fibrosis evaluation,10261643,R56DK124873,"['Acute', 'Affect', 'Agreement', 'Algorithms', 'Allografting', 'Archives', 'Artificial Intelligence', 'Atrophic', 'Basement membrane', 'Biomedical Engineering', 'Biopsy', 'Buffaloes', 'Caring', 'Cessation of life', 'Chemicals', 'Chronic Kidney Failure', 'Cicatrix', 'Clinical', 'Collagen', 'Computer software', 'Computers', 'Consumption', 'Data', 'Data Science', 'Data Sources', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'End stage renal failure', 'Ensure', 'Etiology', 'Evaluation', 'Fibrillar Collagen', 'Fibrosis', 'Fluorescence', 'Formalin', 'Goals', 'Gold', 'Hematoxylin and Eosin Staining Method', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Injury', 'Institution', 'Interobserver Variability', 'Kidney', 'Kidney Diseases', 'Kidney Failure', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Natural History', 'Optics', 'Organ', 'Paraffin Embedding', 'Pathologist', 'Pathology', 'Pathway interactions', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Preparation', 'Procedures', 'Process', 'Property', 'Quantitative Microscopy', 'Recurrence', 'Renal Replacement Therapy', 'Renal function', 'Reproducibility', 'Research', 'Retrospective Studies', 'Running', 'Scientist', 'Severity of illness', 'Signal Transduction', 'Sirius Red F3B', 'Site', 'Slide', 'Staging', 'Stains', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissue Embedding', 'Tissues', 'Trichrome stain method', 'Tubular formation', 'Universities', 'Validation', 'base', 'body system', 'clinical care', 'clinical practice', 'clinically significant', 'cohort', 'cost', 'cost effective', 'design', 'digital', 'digital pathology', 'follow-up', 'histological stains', 'instrument', 'instrumentation', 'kidney biopsy', 'kidney fibrosis', 'macromolecule', 'novel', 'outcome forecast', 'personalized diagnostics', 'predict clinical outcome', 'predictive modeling', 'prognostic', 'prognostic value', 'software development', 'stem', 'tool', 'transmission process']",NIDDK,UNIVERSITY OF CALIFORNIA AT DAVIS,R56,2020,91725,-0.014014585368010436
"VR-Based Evaluation and Training System for Emergency Responders and Managers Virtual and Augmented Reality (VR/AR) systems are increasingly being utilized as training platforms for complex, extremely demanding or rarely executed tasks. Often, VR systems focus primarily on delivering increasingly realistic scenarios for training purposes without any capability to assess or refine trainee performance in situ. Our novel VR training platform to deliver HAZMAT training not only delivers realistic scenarios, but also measures and evaluates performance using scientifically validated measures of variables associated with both individual and team performance. The advantage of our approach is to immerse first responders in HAZMAT emergency scenarios that are realistic and also designed to focus on measurement and refinement of specific areas of performance. Key contributors to performance among emergency responders and managers were identified by an extensive review of the literature and subsequent tested for association by psychometric assessment of over three hundred emergency responders. A subset of 18 highly associated contributors were then identified through statistical analysis of survey results. These contributors can be measurably represented in VR Training scenario elements. Performance related to each can then be measured and assessed for individual or team trainees. These refined key contributors can then be validated on larger, more diverse samples of emergency responders using the beta version of our proposed VR-based system. Our VR system is also a configurable platform that enables the evaluation and training of a wide range of skills needed by distinct roles (police, firefighters, EMTs, etc.) in diverse scenarios such as biosafety spills, HAZMAT disasters and bioterrorism threats. Also, HAZMAT disasters that are rare or very difficult/costly to create real world training events can be more easily and cost effectively mastered. Scenarios also can be dynamically modulated by trainer input in real-time, or by computerized Artificial Intelligence analysis of performance and trainee real-time physiological measures to rapidly optimize specific key contributor performance of individuals and teams. Rapid, efficient and effective training of emergency responders serves the ultimate goal of minimizing potential catastrophic consequences of these events. Our novel VR training platform to deliver HAZMAT training not only delivers realistic scenarios, but also measures and evaluates performance using scientifically validated measures of variables associated with both individual and team performance",VR-Based Evaluation and Training System for Emergency Responders and Managers,9987201,R44ES029348,"['Area', 'Artificial Intelligence', 'Bioterrorism', 'Competence', 'Complex', 'Elements', 'Evaluation', 'Event', 'Goals', 'Gold', 'Hazardous Substances', 'In Situ', 'Individual', 'Measurable', 'Measurement', 'Measures', 'Performance', 'Phase', 'Physiological', 'Police', 'Psychometrics', 'Resources', 'Review Literature', 'Role', 'Sampling', 'Statistical Data Interpretation', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Virtual and Augmented reality', 'base', 'computerized', 'cost', 'design', 'effectiveness measure', 'emergency service responder', 'first responder', 'hazardous materials disaster', 'improved', 'novel', 'skills']",NIEHS,"TIETRONIX SOFTWARE, INC.",R44,2020,199977,-0.006564265983767288
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10016840,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2020,330502,-0.005491284838194706
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,9979523,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2020,77243,-0.03754204908831629
"SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring This project aims to develop an interpretable, physician-in-the-loop AI-aided software that accurately delineates glioma boundaries in MRIs, computes volumetric curves, and statistically quantifies the tumor growth in longitudinal studies. The current clinical practice of visually analyzing and manually contouring tumors is subjective, time-consuming, and often inconsistent. The novelty of MRIMath's explainable, trustworthy, and physician-in-the-loop AI system is multi-fold. First, we introduce a multi-scale feature extraction framework using the inception modules in contracting and expanding paths of the U-Net image segmentation neural network architecture. Second, we propose a new loss function based on the modified Dice similarity coefficient. Third, we train and test the AI system using two learning regimes: learning to segment intra-tumoral structures and learning to segment glioma sub-regions. Finally, we produce heat maps to visualize the features extracted by the AI, thus offering physicians a view of AI's attention patterns and activation maps that were triggered during AI's decision-making. An intuitive and interactive User Interface will allow the physician to review contouring results, make adjustments and approve contours, visualize AI's explanations and volumetric measurements, and finally review the results of the statistical analysis. Any modifications made by the physician will be used later to re-train AI. n/a","SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269837,5N91020C00049,"['Artificial Intelligence', 'Attention', 'Computer software', 'Consumption', 'Contracts', 'Data', 'Data Sources', 'Decision Making', 'Diagnosis', 'Glioma', 'Human', 'Intuition', 'Learning', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measurement', 'Modality', 'Modification', 'Monitor', 'Pattern', 'Phase', 'Physicians', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'System', 'Testing', 'Time', 'TimeLine', 'Training', 'base', 'cancer imaging', 'cancer prevention', 'clinical practice', 'design', 'feature extraction', 'imaging Segmentation', 'imaging software', 'imaging system', 'loss of function', 'neural network architecture', 'prototype', 'tumor', 'tumor growth', 'usability']",NCI,"MRIMATH, LLC",N43,2020,400000,-0.033144272859277825
"A Novel Cryopreservation Technology for Large Skin Grafts to Facilitate Tissue Banking and Allograft Transplantations SUMMARY As a result of recent and rapid advances of immunogenetical, artificial intelligence (AI) and big data technologies, the accuracy and efficiency of donor-recipient immunogenetical matching are expected to be significantly improved. As such, traditional tissue banking practices are being severely challenged due to low cryopreservation throughput. Skin allograft transplantations are currently utilized for numerous clinical applications. In such applications, donor tissues are now typically utilized as “expensive bandages”, i.e. for temporary coverage, thereby requiring painful and damaging follow-on autotransplantation procedures. With tremendously improved skin graft cryopreservation methods coupled with use of HLA matching based on AI network, future tissue banking platforms can potentially provide grafts to be used as permanent and definitive treatment for patients, thereby bringing high impact to clinical applications and the healthcare industry. Based on CryoCrate’s novel ultra-fast (106 K/min on a sample surface) cooling technology platform (PCT/US2019/26162), this project aims to develop a highly efficient (approaching 100% post-thaw viability) tissue graft cryopreservation prototype system that requires no cryoprotectant. The post-thaw viability and functionality will be assessed by standard in vitro assays using porcine and human skin (research exempt) grafts and in vivo assays using a mouse model. After achieving these aims, in future phase II and III stages, CryoCrate and its academic collaborator will collaborate with a local Organ Procurement Organization (Mid-America Transplant) and a wound healing clinic (University of Missouri Hospital) for porcine and human skin transplantation studies and clinical trials. Narrative A novel skin graft cryopreservation technology that requires no cryoprotectant will be developed to significantly improve efficiencies for tissue banking and allograft transplantation practices. This project initiates collaboration between CryoCrate LLC and local stakeholders, and thereby paves a path to commercialization of a new generation of ultra‐fast tissue cryopreservation devices.",A Novel Cryopreservation Technology for Large Skin Grafts to Facilitate Tissue Banking and Allograft Transplantations,10011745,R43AI155070,"['Allografting', 'Americas', 'Animal Model', 'Area', 'Artificial Intelligence', 'Autologous Transplantation', 'Bandage', 'Big Data', 'Biological Assay', 'Clinic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Communities', 'Coupled', 'Cryopreservation', 'Cryopreserved Tissue', 'Devices', 'Engineering', 'Excision', 'Family suidae', 'Freeze Drying', 'Freezing', 'Fresh Tissue', 'Future', 'Gases', 'Generations', 'Goals', 'Healthcare Industry', 'Hospitals', 'Human', 'Immunogenetics', 'Impairment', 'In Situ Nick-End Labeling', 'In Vitro', 'Liquid substance', 'Mechanics', 'Methods', 'Missouri', 'Modeling', 'Mus', 'Nitrogen', 'Organ Procurements', 'Outcome', 'Pain', 'Patients', 'Performance', 'Phase', 'Procedures', 'Process', 'Research', 'Research Project Grants', 'Sampling', 'Skin', 'Skin Tissue', 'Skin Transplantation', 'Skin graft', 'Stains', 'Surface', 'System', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissue Donors', 'Tissue Grafts', 'Tissue Transplantation', 'Tissues', 'Toxic effect', 'Transplantation', 'Universities', 'Variant', 'base', 'biobank', 'clinical application', 'commercialization', 'design', 'experimental study', 'improved', 'in vitro Assay', 'in vivo', 'invention', 'medical schools', 'mouse model', 'novel', 'prototype', 'scale up', 'skin allograft', 'success', 'transplant model', 'two-dimensional', 'wound healing']",NIAID,"CRYOCRATE, LLC",R43,2020,160371,-0.005096660533835145
"SCH: INT: Conversations for Vision: Human-Computer Synergies in Prosthetic Interactions  The project will investigate prosthetic support for people with visual impairment (PVI) that integrates computer vision-based prosthetics with video-mediated human-in-the-loop prosthetics. Computer vision- based (CV) prosthetics construe the fundamental technical challenge for visual prosthetics as one of parsing and identifying objects across scales, distances, and orientations. Visual prosthetic applications have been central drivers in the development of computer vision technology through the past 50 years. Video-mediated remote sighted assistance (RSA) prosthetics are more recent, enabled by different technologies, and construe the orienting technical challenge for visual prosthetics as one of effective helping interactions. RSA services are commercially available now, and have evoked much excitement in the PVI community. The two approaches, CV and RSA, will be successively integrated through a series of increasingly refined Wizard of Oz simulations, and investigate possible synergies between the two approaches. We will employ a human-centered design approach, identifying a set of key assistive interaction scenarios that represent authentic needs and concerns of PVIs, by leveraging our 6-year relationship working directly with our local chapter of the National Federation of the Blind. RELEVANCE (See Instructions): 23.7 million American adults have vision loss; 1.3 million people in US are legally blind. This project addresses a transformational opportunity to enhance human performance and experience, to diversify workplace participation, and to enhance economic and social well-being. n/a",SCH: INT: Conversations for Vision: Human-Computer Synergies in Prosthetic Interactions ,10020434,R01LM013330,"['Address', 'Adult', 'American', 'Articulation', 'Back', 'Blindness', 'Communities', 'Computer Vision Systems', 'Computers', 'Data Set', 'Development', 'Economics', 'Emotional', 'Female', 'Goals', 'Human', 'Information Sciences', 'Instruction', 'Mediating', 'Modeling', 'Ocular Prosthesis', 'Performance', 'Prosthesis', 'Route', 'Self-Help Devices', 'Series', 'Services', 'Social Well-Being', 'Technology', 'Time', 'Underrepresented Students', 'Vision', 'Visual', 'Visual impairment', 'Work', 'Workplace', 'base', 'blind', 'design', 'experience', 'graduate student', 'human-in-the-loop', 'learning materials', 'legally blind', 'outreach', 'prototype', 'simulation', 'synergism', 'undergraduate student']",NLM,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2020,229482,-0.02095939501022066
"Multi-Study Integer Programming Methods for Human Voltammery Project Summary/Abstract  The development of treatments for addiction requires the characterization of neural mechanisms underlying reward. Studying reward in humans requires assays that can detect changes in neurotransmitter levels with high chemical specificity. Recently, fast-scan cyclic voltammetry (FSCV) has been implemented in humans to measure dopamine with high temporal and spatial resolution. This technological achievement was enabled in large part through the novel application of machine learning methods. FSCV relies on statistical tools since FSCV records an electrochemical response which must be converted into concentration estimates via a statistical model. The validity of the scientific conclusions from human FSCV studies therefore depends heavily on the reliability of these statistical models to generate accurate dopamine concentration estimates.  In human FSCV, models are fit on in vitro training sets as making in vivo training sets in humans is infeasible. Producing accurate estimates thus requires that models trained on in vitro training sets generalize to in vivo brain recordings. Combining data from multiple training sets is the standard approach human FSCV researchers have employed to improve model generalizability. This proposal extends work that shows that multi-study machine learning methods improve dopamine concentration estimates by combining training sets from different electrodes such that the resulting average signal (“cyclic voltammogram” or CV) is similar to the average CV of the electrode used in the brain. However, this approach relies on random resampling. This is problematic because the randomness limits the extent to which estimate accuracy can be improved and the slow speed of the resampling approach precludes the generation of estimates during data collection, which is critical to experiment success.  This proposal details the development of methods that leverage mixed integer programming to optimally generate training sets that combine data from multiple electrodes. By generating training sets that are specifically tailored to the electrode used for brain measurements, one can vastly improve dopamine concentration estimate accuracy. The speed of the integer programming methods will enable the use of this approach during data collection. This work will include validation of the methods on in vitro data as well as on data from published in vivo and slice experiments in rodents. By applying methods to published optogenetic experiments, one can compare estimates from the proposed methods and from standard methods. The asymptotic properties of the proposed methods will be characterized analytically assuming a linear mixed effects model and empirically through application of the methods to data simulated under this model.  This work will be conducted at the highly collaborative and innovative Harvard School of Public Health. The fellowship will support growth in statistical, computing and collaborative skills, and prepare the trainee for a productive career as a biostatistics professor who develops methods for neuroscience and addiction research. Project Narrative  Fast-scan cyclic voltammetry in humans offers an invaluable tool to study the neural mechanisms underlying reward by allowing for sub-second detection of dopamine during cognitive-behavioral tasks. However, conducting voltammetry in humans presents distinct statistical challenges that must be overcome to ensure optimal dopamine concentration estimates. We propose novel statistical methods that use mixed integer optimization and extend preliminary work that shows multi-study machine learning methods substantially improve dopamine concentration estimate accuracy.",Multi-Study Integer Programming Methods for Human Voltammery,10067624,F31DA052153,"['Achievement', 'Address', 'Algorithms', 'Behavioral', 'Biological Assay', 'Biometry', 'Brain', 'Cells', 'Chemicals', 'Cognitive', 'Complex Mixtures', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Dopamine', 'Electrodes', 'Ensure', 'Fellowship', 'Generations', 'Goals', 'Grant', 'Growth', 'Human', 'In Vitro', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Meta-Analysis', 'Methods', 'Modeling', 'Neurosciences', 'Neurotransmitters', 'Nucleus Accumbens', 'Performance', 'Periodicity', 'Property', 'Public Health Schools', 'Publications', 'Publishing', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Rewards', 'Rodent', 'Scanning', 'Scheme', 'Signal Transduction', 'Slice', 'Specificity', 'Speed', 'Statistical Computing', 'Statistical Methods', 'Statistical Models', 'Techniques', 'Training', 'Validation', 'Work', 'addiction', 'algorithm training', 'career', 'effective therapy', 'experimental study', 'improved', 'in vivo', 'innovation', 'insight', 'machine learning method', 'method development', 'multiple data sources', 'neuromechanism', 'novel', 'optogenetics', 'predictive modeling', 'professor', 'relating to nervous system', 'response', 'skills', 'success', 'therapy development', 'tool']",NIDA,HARVARD SCHOOL OF PUBLIC HEALTH,F31,2020,37235,-0.015978095147127083
"Development of a scalable, portable device platform to help objectively monitor the treatment of substance abuse. Abstract Assessing the effectiveness of substance abuse rehabilitation, where high relapse rates create financial and social tolls, is a pressing clinical problem in need of better measurement tools. The ability to identify cognitive changes should improve outcomes but current intake into rehabilitation programs doesn’t typically include cognitive tests. Simple, quick, cost-effective, and objective measures are needed. This is the problem this proposal seeks to address. This proposal utilizes the experience of Evolve Behavioral Health which serve 150 patients weekly, and WAVi, a commercialized brain-assessment platform that combines EEG evoked responses (ERP) with 5 other tests also sensitive to addiction (heart rate variability, physical reaction times, MoCA, Trail Making, and Flanker). This user-friendly platform focuses on minimizing testing times and cost while maximizing information. Our first premise is that adding these tests will help us identify those addicts whose cognitive state requires modified treatment approaches, and this will decrease relapse rates and recidivism rates. Our second premise is that we can create a dataset that can be trained to identify appropriate treatment regimens on an individual basis from the initial baseline test. To date, WAVi data have shown ERP to be highly sensitive to concussion (another cognitive issue) and that artificial intelligence on raw EEG can classify both PTSD and musculoskeletal pain with high sensitivities and specificities. The aims of this project are to develop a scalable EEG-based test for rehabilitation facilities that is readily accessible to clinicians and to create a dynamic data asset to help longitudinally predict outcomes. Accomplishing these aims will assist clinicians on the front lines of substance abuse assessment and treatment. Narrative This project will help create an objective and clinically accessible test to be used in substance-abuse rehabilitation programs to assist clinicians in making intervention choices as well as determining the timing of release from rehabilitation.","Development of a scalable, portable device platform to help objectively monitor the treatment of substance abuse.",10145897,R43DA053012,"['Address', 'Artificial Intelligence', 'Auditory', 'Autonomic nervous system', 'Brain', 'Brain Concussion', 'Budgets', 'Caring', 'Clinic', 'Clinical', 'Cognition', 'Cognitive', 'Cognitive Therapy', 'Consent', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Electroencephalography', 'Event-Related Potentials', 'Frequencies', 'Future', 'Goals', 'Grant', 'Individual', 'Inpatients', 'Intake', 'Intervention', 'Longitudinal Studies', 'Measurement', 'Measures', 'Medical History', 'Modality', 'Monitor', 'Musculoskeletal Pain', 'Opiate Addiction', 'Patients', 'Phase', 'Photoplethysmography', 'Population', 'Post-Traumatic Stress Disorders', 'Protocols documentation', 'Public Domains', 'Publishing', 'Reaction Time', 'Rehabilitation Centers', 'Rehabilitation Outcome', 'Rehabilitation therapy', 'Relapse', 'Research', 'Research Personnel', 'Rest', 'Sensitivity and Specificity', 'Structure', 'Substance abuse problem', 'Technology', 'Testing', 'Time', 'Training', 'Treatment Protocols', 'addiction', 'base', 'behavioral health', 'biopsychosocial', 'cognitive change', 'cognitive testing', 'cost', 'cost effective', 'expectation', 'experience', 'heart rate variability', 'improved outcome', 'individualized medicine', 'multimodality', 'novel marker', 'open data', 'outcome prediction', 'outpatient facility', 'phase 2 study', 'point of care', 'portability', 'programs', 'recidivism', 'response', 'social', 'standard measure', 'substance abuse rehabilitation', 'substance abuse treatment', 'tool', 'treatment planning', 'user-friendly']",NIDA,WAVI COMPANY,R43,2020,221675,-0.052151245019297326
"Georgia Clinical & Translational Science Alliance (GaCTSA) EFFECTIVE ALLOCATION OF TEST CENTERS FOR COVID-19 USING MACHINE LEARNING AND  ADAPTIVE SAMPLING ABSTRACT A critical task in managing and dealing with COVID-19 in communities is to perform diagnostic and/or antibody tests to identify diseased individuals. This information is critical to public health officials to estimate prevalence and transmission, and to effectively plan for required resources such as ICU beds, ventilators, personal protective equipment, and medical staff. Additionally, information on the number of infected people can be used to develop probabilistic and statistical models to estimate the reproduction number of the disease, and to predict the likely spatial and temporal trajectories of the outbreak. This provides vital information for planning actions and preparing policies and guidelines for social-distancing, school closures, remote work, community lockdown, etc. Despite the importance of diagnostic testing and identification of the positive cases, broad-scale testing is a challenging task particularly due to the limited number of test kits and resources. Our proposed research focuses on the development machine learning-based allocation strategies for determining the optimal location of COVID-19 test centers, including mobile and satellite centers, to minimize the local and global prediction uncertainties, maximize geographic coverage, associated with projections of spatio-temporal outbreak trajectories, and to improve efficient identification of diseased cases. EFFECTIVE ALLOCATION OF TEST CENTERS FOR COVID-19 USING MACHINE LEARNING AND  ADAPTIVE SAMPLING NARRATIVE Diagnostic and antibody tests for COVID-19 can provide invaluable information on prevalence and transmission of the disease. However, due to limited test capacity, broad-scale testing is currently not feasible. Consequently, there is a pressing need for a systematic and data-driven approach to defining testing strategies, in particular, determining the number and location of satellite and mobile testing centers (e.g., drive-through test locations). Our research program develops machine learning approaches to effectively allocate test centers for COVID-19 at the city, county, and state levels to accurately and reliably estimate the disease prevalence and its trajectory for resource planning and policy making, and to efficiently identify cases for treatment.",Georgia Clinical & Translational Science Alliance (GaCTSA),10158891,UL1TR002378,"['Active Learning', 'Antibodies', 'Area', 'Beds', 'Biology', 'COVID-19', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Cities', 'Clinical Sciences', 'Communities', 'Contracts', 'County', 'Data', 'Development', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Disease Surveillance', 'Ecology', 'Ensure', 'Epidemic', 'Epidemiology', 'Equipment', 'Federal Government', 'Future', 'Geography', 'Goals', 'Guidelines', 'Hybrids', 'Individual', 'Local Government', 'Location', 'Machine Learning', 'Medical Staff', 'Methods', 'Modeling', 'Monitor', 'Neighborhood Health Center', 'Neurology', 'Pattern', 'Performance', 'Policies', 'Policy Making', 'Population', 'Prevalence', 'Process', 'Public Health', 'Readiness', 'Reproduction', 'Research', 'Research Project Grants', 'Resistance', 'Resources', 'Sampling', 'Scheme', 'Schools', 'Series', 'Social Distance', 'Statistical Models', 'Testing', 'Time', 'Translational Research', 'Uncertainty', 'Update', 'Ventilator', 'Virus', 'Work', 'base', 'case finding', 'disease transmission', 'environmental justice', 'evidence base', 'experience', 'flexibility', 'improved', 'metropolitan', 'multidisciplinary', 'novel', 'pandemic disease', 'programs', 'racial and ethnic', 'racial diversity', 'sociodemographics', 'socioeconomics', 'spatiotemporal', 'transmission process']",NCATS,EMORY UNIVERSITY,UL1,2020,225579,-0.013121961831435727
"Development of a Wheelchair Maintenance Alert Application for Elderly Wheelchair Users Project Summary Elderly wheelchair users experience wheelchair breakdowns every 2-3 months in low- and middle-income countries (LMICs) and rural areas of high-income countries. One in three breakdowns leads to adverse physical, social, psychosocial and economic consequences to wheelchair users which increases the public health and personal burden. Preventative wheelchair maintenance has been found to reduce the frequency of wheelchair breakdowns by ten-fold, but compliance with maintenance recommendations is extremely low because they are generic and not reflective of how and where the wheelchair is being used. To address this issue, we are developing a low-cost, scalable maintenance application that leverages artificial intelligence tools to provide maintenance recommendations tailored to how a wheelchair is used. The availability of low-cost technology and widespread use of smartphones by the elderly and people with disabilities in LMICs has led us to develop a smartphone application called WheelTrak that measures wheelchair wear as a function of usage in community. Based on the wear factors, the application produces a Wheelchair Wear Index (WWI) that is representative of wear of critical wheelchair parts that are prone to breakdown. Once a WWI threshold is reached, maintenance is required, and the application notifies the user and/or caregiver who can conduct maintenance to avoid breakdowns and related health consequences. We will conduct a data collection study in collaboration with our wheelchair industry partner – UCP Wheels in El Salvador – and characterize the WWI for the elderly by tracking wear factors which include user’s travel distance, ground shocks and surface vibrations using WheelTrak and a wheel sensor. Based on the trained WWI algorithm, a preventative maintenance schedule will be developed for older adults that can be employed through WheelTrak for maintenance reminders. Semi-structured interviews will be conducted to evaluate the usability of the application and gather barriers to maintenance. User feedback will assist us in improving WheelTrak for greater user satisfaction and compliance with maintenance, and addressing any personal or logistical challenges that elderly users and their caregivers or family members may face with conducting maintenance activities in LMICs. Findings from the proposed studies in this application will assist us in planning future studies to investigate the WWI-enabled WheelTrak tool as an intervention to prevent or reduce breakdowns and health consequences with the elderly in LMICs. Preventative maintenance of wheelchairs is necessary to reduce frequent wheelchair breakdowns and corresponding health consequences experienced by the elderly in adverse environments which are commonly present in low- and middle-income countries (LMICs). WheelTrak is a smartphone application that measures real-time wheelchair wear in the community during use and triggers preventative maintenance reminders. In this study, we are modelling the application algorithm and collecting user and caregiver feedback to transform WheelTrak into a maintenance intervention tool for elderly wheelchair users in LMICs.",Development of a Wheelchair Maintenance Alert Application for Elderly Wheelchair Users,10095020,R03AG069836,"['Activities of Daily Living', 'Address', 'Adult', 'Algorithms', 'Artificial Intelligence', 'Beds', 'Caregivers', 'Cause of Death', 'Cellular Phone', 'Clinic', 'Collaborations', 'Communities', 'Country', 'Data', 'Data Collection', 'Development', 'Devices', 'Disabled Persons', 'Economics', 'El Salvador', 'Elderly', 'Environment', 'Face', 'Failure', 'Family member', 'Feedback', 'Frequencies', 'Future', 'Goals', 'Health', 'Hospitalization', 'Income', 'Injury', 'Intervention', 'Intervention Studies', 'Interview', 'Life Style', 'Logistics', 'Long-Term Care', 'Maintenance', 'Manual wheelchair', 'Measures', 'Mental Depression', 'Modeling', 'Monitor', 'Names', 'Notification', 'Pattern', 'Personal Satisfaction', 'Population', 'Preventive', 'Provider', 'Public Health', 'Recommendation', 'Risk', 'Schedule', 'Services', 'Shock', 'Societies', 'Structure', 'Study models', 'Surface', 'Technology', 'Time', 'Training', 'Travel', 'User Compliance', 'Wheelchairs', 'aged', 'base', 'cohort', 'cost', 'decubitus ulcer', 'disability', 'evidence base', 'experience', 'improved', 'indexing', 'industry partner', 'low and middle-income countries', 'prevent', 'prospective', 'psychosocial', 'rural area', 'satisfaction', 'sensor', 'sensor technology', 'smartphone Application', 'social', 'tool', 'usability', 'vibration']",NIA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R03,2020,75877,-0.02920671392721777
"DIGITAL HEALTH SOLUTIONS FOR COVID-19:  COVID COMMUNITY ACTION AND RESEARCH ENGAGEMENT (COVID-CARE) The goal of this project is to develop mobile applications, data integrations, and validated machine learning algorithms to identify COVID-19 and differentiate it from the flu, and to perform contact tracing using Wi-Fi technologies.  Vibrent Health will accomplish this goal by enhancing their Vibrent Digital Health Solutions Platform (DHSP) implementation to large-scale pilot populations among diverse user groups.  The project will focus on validating the technology’s performance, usability, and reliability in refinement of analytics to generate predictive algorithms for infection.  The platform is intended to support individual, organizational, community, and societal-level decision-making in the COVID-19 pandemic response.  The first objective involves innovation to develop a technology that can differentiate between COVID-19 and flu (or other respiratory illness).  The second objective involves the development and testing of a Wi-Fi-based contact tracing tool using George Mason University’s enterprise Wi-Fi system.  The third objective involves the development of a full technical integration approach and strategy to support data exchange.  Data collected under this project will be deidentified and securely transmitted to an NIH data hub. n/a",DIGITAL HEALTH SOLUTIONS FOR COVID-19:  COVID COMMUNITY ACTION AND RESEARCH ENGAGEMENT (COVID-CARE),10274145,5N91020C00038,"['Action Research', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Communities', 'Community Actions', 'Contact Tracing', 'Data', 'Decision Making', 'Development', 'Goals', 'Health', 'Individual', 'Infection', 'Performance', 'Population', 'Secure', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Universities', 'base', 'coronavirus disease', 'data exchange', 'data hub', 'data integration', 'digital', 'flu', 'innovation', 'machine learning algorithm', 'mobile application', 'prediction algorithm', 'respiratory', 'response', 'tool', 'usability', 'wireless fidelity']",NCI,"VIGNET, INC.",N01,2020,1098256,-0.009008853790192173
THE PRIMARY OBJECTIVE OF THE PROPOSED PHASE I WORK IS TO FURTHER DEVELOP A PROOF-OF-CONCEPT(POC) MACHINE LEARNING APPROACH TO DETECT ILLEGAL OPIOID SE N/A n/a,THE PRIMARY OBJECTIVE OF THE PROPOSED PHASE I WORK IS TO FURTHER DEVELOP A PROOF-OF-CONCEPT(POC) MACHINE LEARNING APPROACH TO DETECT ILLEGAL OPIOID SE,10286221,5N95019C00069,"['Data Collection', 'Facebook', 'Machine Learning', 'Opioid', 'Phase', 'Sales', 'Twitter', 'Work', 'data mining', 'phrases', 'social media']",NIDA,"S-3 RESEARCH, LLC",N43,2020,55000,-0.011674144878867494
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9872178,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'data analysis pipeline', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'programmed cell death protein 1', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2020,314000,-0.022071014994134063
"Real-time non-intrusive workload monitoring-Integration of human factors in surgery training and assessment Project Summary/Abstract (30 lines)  High physiological and cognitive workload required in de-coupled surgical work demands may have significant impact on patient outcome, surgical efficacy, and surgical performance. As novel surgical techniques, e.g., telesurgery, are developed, surgical operations will become more complex and the mental and physical demand on surgeons will likely increase, making it critical to develop remote and connected workload monitoring methods for the safe and effective surgical procedure design, testing, and training. This work will implement novel technology and machine learning analytics to quantify real-time and remote workload and test how workload feedback can impact care delivery in both in telesurgery and surgical simulation environments. Our overall hypothesis is that connected sensing technology in telesurgical procedures and simulation can improve surgical training and understanding of the impact of their workload on performance; ultimately improving patient health, surgery efficacy, and patient access (e.g., tele-mentoring) to surgical care. Two specific aims are proposed to investigate this hypothesis.  The objective of Specific Aim 1 is to develop a connected sensor system to objectively quantify workload real-time in simulated telerobotic procedures. This involves: 1) integrating non-intrusive sensors into a single system within the simulation trainer or environment, 2) training machine learning techniques to objectively distinguish workload using a simulated surgical skills tasks, and 3) validating metrics across varying levels of cognitive loads under various task difficulty with medical trainees and expert participants.  The objective of Specific Aim 2 is to determine the impact of the real-time workload feedback intervention on trainee performance times, errors, and intraoperative workload. Two tasks are proposed: 1) Explore modalities preferred by surgeons for providing real-time feedback on workload and 2) Assess impact of workload feedback on task performance and learning. Our primary hypothesis is that performance times and errors will improve when participants are provided realtime feedback on workload compared to performance with no feedback.  The expected deliverables include 1) workload monitoring technology, algorithms, and software for complementing current simulation-based training, 2) objective and automated workload metrics, 3) real-time assistive intervention tool, and 4) preliminary evidence on impact of workload monitoring on training. The technology in this proposed work will improve public health by reducing adverse events due to human factors in surgery and improve access to surgical care with intervention technology that can adaptively train surgeons and remotely assess proficiency. Project Narrative High physiological and cognitive workload required in de-coupled surgical work demands may have significant impact on patient outcome, surgical efficacy, and surgical team performance. Our overall hypothesis is that connected sensing technology, machine learning analytics, and real-time user-centered feedback on cognitive and physiological workload in telesurgical procedures and simulation can improve surgical training and understanding of the impact of their workload on performance; ultimately improving patient health, surgery efficacy, and patient access to surgical care. The technology in this proposed work will improve public health by reducing adverse events due to human factors in surgery and improve access to surgical care with intervention technology that can adaptively train surgeons and remotely assess proficiency.",Real-time non-intrusive workload monitoring-Integration of human factors in surgery training and assessment,9983030,R21EB026177,"['Accreditation', 'Adverse event', 'Algorithmic Software', 'Algorithms', 'Assessment tool', 'Attention', 'Awareness', 'Caring', 'Cognitive', 'Complement', 'Complex', 'Computer software', 'Coupled', 'Environment', 'Equipment', 'Event', 'Feedback', 'Future', 'Health', 'Human', 'Impairment', 'Improve Access', 'Intervention', 'Joints', 'Knowledge', 'Learning', 'Literature', 'Machine Learning', 'Measures', 'Medical', 'Mentors', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Plant Roots', 'Postoperative Period', 'Procedures', 'Psyche structure', 'Public Health', 'Robotics', 'Sentinel', 'Supervision', 'Surgeon', 'Surveys', 'System', 'Task Performances', 'Techniques', 'Technology', 'Technology Assessment', 'Telerobotics', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'Workload', 'base', 'care delivery', 'cognitive load', 'design', 'distraction', 'experience', 'improved', 'individualized feedback', 'innovation', 'motion sensor', 'new technology', 'novel', 'operation', 'patient safety', 'programs', 'recruit', 'robotic training', 'sensor', 'sensor technology', 'simulation', 'simulation environment', 'skills', 'skills training', 'tool', 'vigilance', 'virtual surgery']",NIBIB,PURDUE UNIVERSITY,R21,2020,183111,-0.01139530096375967
"Multimodality imaging-driven multifidelity modeling of aortic dissection PROJECT SUMMARY. Aortic dissections are responsible for significant morbidity and mortality in young and old individuals alike. Whereas type A (ascending aorta) dissections are treated aggressively via surgery, type B (descending thoracic aorta) dissections are often monitored for long periods to determine the best treatment. These lesions can cease to propagate (i.e., stabilize or heal) or they can propagate further and either turn inward and connect again with the true lumen to form a re-entry tear or turn outward and result in rupture in the case of an compromised adventitia. Notwithstanding the importance of these later events, there is a pressing need to understand better the early processes that initiate the dissection and drive its initial propagation as well as to determine whether the presence of intramural thrombus is protective or not against early or continued propagation. Over the past 5 years our collaborative team has developed numerous new multimodality imaging techniques, biomechanical testing methods, and computational modeling approaches across multiple scales that uniquely positions us to understand better the process of early aortic dissection and the possible roles played by early intramural thrombus development. In this project, we propose to use nine complementary mouse models to gain broad understanding of the bio-chemo-mechanical processes that lead to aortic dissection and to introduce a new machine learning based multifidelity modeling approach to develop predictive probabilistic multiscale models of dissection. These models will be informed, trained, and validated via data obtained from a combination of unique in vitro biomechanical phenotyping experiments (wherein we can, for the first time, quantify the initial delamination process under well-controlled conditions and regional material properties thereafter) and novel multimodality imaging of delamination / dissection both in vitro and in vivo. We will consider, for example, the roles of different elastic lamellar geometries; we will assess separate roles of focal proteolytic activation and pooling of highly negatively charged mucoid material, which can degrade or swell the wall respectively; and we will model and assess the effects of early thrombus deposition within a false lumen. We submit that our new probabilistic paradigm, based on statistical autoregressive schemes and enabled by machine learning tools, could be transformative and lead to a paradigm shift in disease prediction where historical data, animal experiments, and limited clinical input (e.g., multiomics) can be used synergistically for robust prognosis and thus interventional planning. Our work is also expected to lead naturally to an eventual better understanding of the chronic processes associated with dissection via predictive models that are aided by the expected “revolution of resolution” in diagnostic imaging. PUBLIC HEALTH RELEVANCE Mounting evidence reveals that thoracic aortic dissections – which afflict young and old individuals alike – are responsible for even greater disability and death than long thought. We will use a unique combination of multiple mouse models, advanced medical imaging, and novel computational models to elucidate the mechanisms responsible for the initiation of a dissection and reasons for the extreme biological variability that characterizes these lethal lesions.",Multimodality imaging-driven multifidelity modeling of aortic dissection,9981804,U01HL142518,"['Acute', 'Address', 'Animal Experiments', 'Animal Model', 'Aorta', 'Aortic Rupture', 'Arteries', 'Attention', 'Biological', 'Biomechanics', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Blunt Trauma', 'Carotid Arteries', 'Categories', 'Cervical', 'Cessation of life', 'Charge', 'Chest', 'Child', 'Chronic', 'Clinical', 'Coagulation Process', 'Collaborations', 'Communities', 'Computer Models', 'Coupling', 'Data', 'Defect', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dilatation - action', 'Disease', 'Dissection', 'Elderly', 'Event', 'Foundations', 'Geometry', 'Glycosaminoglycans', 'Goals', 'Heritability', 'Human', 'Hypertension', 'Image', 'Imaging Techniques', 'In Vitro', 'Individual', 'Infusion procedures', 'Intervention', 'Knowledge', 'Lead', 'Lesion', 'Long-Term Effects', 'Machine Learning', 'Mechanics', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Motivation', 'Multimodal Imaging', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Outcome', 'Phase', 'Phenotype', 'Platelet aggregation', 'Play', 'Positioning Attribute', 'Prevention', 'Process', 'Property', 'Research', 'Resolution', 'Risk Factors', 'Role', 'Rupture', 'Scheme', 'Site', 'Solid', 'Statistical Models', 'Testing', 'Thoracic aorta', 'Thrombus', 'Time', 'Training', 'Tunica Adventitia', 'Ultrasonography', 'Uncertainty', 'Video Microscopy', 'Work', 'ascending aorta', 'base', 'digital imaging', 'disability', 'experimental study', 'healing', 'hemodynamics', 'improved', 'in silico', 'in vivo', 'insight', 'intracranial artery', 'microSPECT', 'mortality', 'mouse model', 'mucoid', 'multi-scale modeling', 'multiple omics', 'normotensive', 'novel', 'novel strategies', 'outcome forecast', 'particle', 'predictive modeling', 'public health relevance', 'spatiotemporal', 'supervised learning', 'tool', 'virtual', 'young adult']",NHLBI,YALE UNIVERSITY,U01,2020,601275,-0.016190259495739958
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,10241562,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Visualization', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2020,2500,-0.006100154503884509
"Advancing personalized medicine in PD using harmonized multi-site clinical data Project Summary Among neurological disorders, the fastest growing is now Parkinson's disease (PD), surpassing Alzheimer's dis- ease. PD manifests as a heterogeneous clinical syndrome and this variability in the clinical phenotype highlights the need to tailor the type and/or the dosage of treatment to the speciﬁc and changing needs of individuals living with PD. The main goal of individualized, or precision, medicine is to use patient characteristics to determine an individualized treatment strategy (ITS) to promote wellness. Due to the complex nature of PD coupled with phenotypic heterogeneity, formulating successful individualized approaches to medical care is a complex prob- lem that may beneﬁt from a more data-driven approach. One of the challenges in developing reliable ITSs is that the analyses require studies with fairly large sample sizes and longitudinal assessment of subjects over a relatively long period of time. The data set must also include various prescribing patterns to allow the analytic method to learn the effects of different treatment sequences (strategies). These important requirements preclude investigators from using data from a single clinical study to construct data-driven ITSs. Existing guidelines for symptomatic drug therapy for PD can best be described as ""permissive"". The relative lack of comparative evidence for different classes of drugs has created challenges in devising recommendations to follow any speciﬁc therapeutic strategy. We ﬁll this important gap by proposing a two phase study. The ﬁrst phase (R61) focuses on creating a harmonized and curated dataset by integrating data from six clinical trials and the PPMI observational study that, in aggregate, involved 4,705 patients followed from 23.5 to 96 months. To the best of our knowledge, such comprehensive data harmonization has not been done before in PD and it can provide an excellent source of information for future studies as well. In the second phase (R33), we will leverage the harmonized data set to develop high quality ITSs for PD with respect to several clinical outcomes including UPDRS score, quality of life, and Schwab and England (SE) ADL measured at 24 and 48 months of follow-up. Speciﬁcally, the goals of the R33 phase are to (Aim 1) compare commonly used sequences of drug classes for PD; (Aim 2) identify the best individualized treatment strategies to inform optimal sequences of drug classes for PD. In pursuit of these aims, we will propose robust, rigorous and computationally efﬁcient statistical machine learning methods for constructing data-driven optimal ITSs for PD. The proposal expands the scope of existing methods in developing ITSs by relaxing certain unrealistic assumptions and through the use of ﬂexible modeling techniques (e.g., machine learning methods) while maintaining valid statistical inference. These new methods will be integrated into easy-to-use, publicly available software in the R language (Aim 3). This will maximize the adoption of the proposed methodology by other investigators and allow researchers to analyze other PD datasets with a goal of constructing an ITS for PD. Furthermore, because the methods are not disease-speciﬁc, our methods and software will enable similar exploration for other diseases. Project Narrative Constructing reliable individualized treatment strategies requires studies with fairly large sample sizes with longi- tudinal assessment of subjects over a relatively long period of time. To this end, we will create a harmonized and curated dataset by integrating data from seven long-term observational and randomized studies in Parkinson's disease. Using this harmonized data, we will develop and apply robust, rigorous and computationally efﬁcient methods for estimating an optimal individualized treatment strategy for Parkinson's disease with respect to var- ious outcomes (e.g., Uniﬁed Parkinson's Disease Rating Scale, quality of life, and Schwab and England ADL score). We will also leverage statistical machine learning approaches to improve the quality of the constructed optimal individualized treatment strategy while providing valid statistical inference.",Advancing personalized medicine in PD using harmonized multi-site clinical data,10129639,R61NS120240,"['Adoption', 'Alzheimer&apos', 's Disease', 'Behavior', 'Benefits and Risks', 'Caring', 'Characteristics', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Decision Making', 'Decision Trees', 'Disease', 'England', 'Future', 'Goals', 'Guidelines', 'Health', 'Heterogeneity', 'Individual', 'Journals', 'Language', 'Lead', 'Learning', 'Longterm Follow-up', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Observational Study', 'Outcome', 'Output', 'Parkinson Disease', 'Participant', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Population', 'Procedures', 'Process', 'Protocols documentation', 'Publications', 'Quality of life', 'Randomized', 'Recommendation', 'Recording of previous events', 'Research', 'Research Personnel', 'Sample Size', 'Sampling', 'Software Tools', 'Source', 'Syndrome', 'Target Populations', 'Techniques', 'Therapeutic', 'Time', 'analytical method', 'base', 'care providers', 'clinical care', 'clinical decision-making', 'clinical phenotype', 'clinical research site', 'comparative', 'comparative effectiveness study', 'data harmonization', 'data management', 'demographics', 'dosage', 'flexibility', 'follow-up', 'improved', 'individualized medicine', 'longitudinal dataset', 'machine learning method', 'nervous system disorder', 'open source', 'overtreatment', 'patient response', 'personalized approach', 'personalized medicine', 'precision medicine', 'progression marker', 'repository', 'response', 'software development', 'statistical and machine learning', 'tool', 'treatment planning', 'treatment response', 'treatment strategy']",NINDS,UNIVERSITY OF ROCHESTER,R61,2020,514654,-0.015701928668140894
"Pre-cancer atlases of cutaneous and hematologic origin (PATCH Center) SUMMARY-ABSTRACT  The overall goal of this proposal is to construct two pre-cancer atlases (PCAs) from highly accessible pre- malignant diseases that impose high burdens on human health (i) one focused on progression of pre- melanoma lesions to invasive cancer and (ii) a second on progression from clonal hematopoiesis (CHIP) to myeloid neoplasms. Both of these involve expansion of specific clones in normal and diseased niches as shaped by complex interactions among immune and pre-cancer cells. The resulting Atlases developed by the Center for Pre-cancer Atlases of Cutaneous and Hematologic Origin (PATCH Center) present complementary technical challenges, avenues to scientific discovery, and opportunities for the development of precision prevention strategies and therapies. The key goal in both cases is to precisely delineate and understand the molecular mechanisms driving progression from pre-malignant to malignant disease, to identify high risk individuals, prioritize particular therapies and serve as the foundation for precision prevention clinical trials. This will be achieved by integrated characterization of single cell genotype and cell states using high-plex tissue imaging and omic characterization of cross-sectional and well-controlled longitudinal patient cohorts.  Aim 1 will establish an administrative core responsible for scientific management of the Center, coordination with HTAN members and dissemination of Atlases under the direction of an internal Executive Committee with three subcommittees. Aim 2 will establish a Biospecimen Unit under the leadership of pathologists, oncologists and a surgeon. The DFCI Pasquarello Tissue Repository will provide highly annotated hematological specimens for image-based and omic characterization of CHIP; the BWH dermatopathologic tissue repository will provide annotated FFPE samples for melanoma precursors. These services will also play a key role in prospective sample acquisition and analysis. Aim 3 will establish a Characterization Unit directed by an oncologist and pathologist to perform and integrate single-cell genomics, multiplex flow cytometry and high- plex imaging using two methods reduced to practice within the Center: tissue-based cyclic immunofluorescence (t-CyCIF) and DNA exchange imaging (DEI). The Characterization Unit will also validate reagents and associate all primary results with appropriate metadata, protocols and reagent specifications. Aim 4 will establish a Data Analysis Unit enlisting systems and computational biologists and data scientists to manage all aspects of data acquisition, interpretation and visualization. This is expected to be the most technically challenging aspect of the Atlas projects. The Data Analysis Unit will release Phase I/II atlases each in preliminary and final stages to facilitate collaborative and crowd-sourced approaches to algorithm development. The resulting human browsable and machine-readable atlases are expected to yield new scientific discoveries, demonstrate the feasibility and utility of new technologies and help to reduce the incidence of life-threatening cancers of the skin and blood. NARRATIVE Construction of Pre-Cancer Atlases comprising detailed spatial and molecular data on cell state and omic data in melanoma and clonal hematopoiesis will join together the two primary means of diagnosing human cancer: histology and genetics. The atlases we construct will help to identify patients with pre-cancer skin lesions and blood conditions at risk of progressing to malignancy at a sufficiently early stage that aggressive disease can be prevented.",Pre-cancer atlases of cutaneous and hematologic origin (PATCH Center),10252281,U2CCA233262,"['Antibodies', 'Area', 'Atlases', 'Automobile Driving', 'Back', 'Benchmarking', 'Biological Assay', 'Biological Specimen Banks', 'Biopsy', 'Blood', 'Bone Marrow', 'Cancer Histology', 'Cell Line', 'Cells', 'Cellular Morphology', 'Clinical', 'Clinical Data', 'Code', 'Collaborations', 'Collection', 'Communication', 'Complex', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Cutaneous', 'DNA', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Scientist', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Engineering', 'Enrollment', 'Ensure', 'FAIR principles', 'Fee-for-Service Plans', 'Flow Cytometry', 'Formalin', 'Foundations', 'Freezing', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Head', 'Health', 'Hematology', 'Hematopoiesis', 'Hematopoietic Neoplasms', 'Histologic', 'Human', 'Image', 'Immune', 'Immunofluorescence Immunologic', 'Incidence', 'Individual', 'Industrialization', 'Laboratories', 'Lead', 'Leadership', 'Lesion', 'Life', 'Link', 'Liquid substance', 'Malignant - descriptor', 'Malignant Neoplasms', 'Maps', 'Metadata', 'Methods', 'Molecular', 'Monitor', 'Myeloproliferative disease', 'Oncologist', 'Paraffin Embedding', 'Pathologist', 'Patients', 'Performance', 'Periodicity', 'Pharmacology', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Prevention strategy', 'Prevention therapy', 'Prevention trial', 'Prospective cohort', 'Protocols documentation', 'Readability', 'Reagent', 'Research Personnel', 'Risk', 'Running', 'Sampling', 'Scientist', 'Services', 'Skin Cancer', 'Software Engineering', 'Solid', 'Specimen', 'Standardization', 'Stromal Cells', 'Surgeon', 'System', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'Tissue Banks', 'Tissue imaging', 'Tissues', 'Tumor Tissue', 'Validation', 'Visualization', 'Visualization software', 'Work', 'algorithm development', 'base', 'cancer invasiveness', 'cell type', 'cohort', 'computing resources', 'crowdsourcing', 'data acquisition', 'data standards', 'data submission', 'data visualization', 'deep neural network', 'dimensional analysis', 'feature extraction', 'genetic analysis', 'high dimensionality', 'high risk', 'image visualization', 'individual patient', 'individualized prevention', 'insight', 'knowledge base', 'laser capture microdissection', 'machine learning method', 'melanoma', 'member', 'multiplexed imaging', 'neoplastic', 'new technology', 'premalignant', 'prevent', 'prevention clinical trial', 'prospective', 'skin lesion', 'tumor microenvironment']",NCI,HARVARD MEDICAL SCHOOL,U2C,2020,974841,-0.040020915795808784
"Leveraging Heterogeneity in Preclinical Traumatic Brain Injury to Drive Discovery and Reproducibility Traumatic brain injury (TBI) is a leading cause of neurological disorders and affects over 2.5 million people each year, yet no treatment has successfully translated from bench to clinic. TBI is a broad term and encompasses an extremely heterogeneous set of injuries differing by cause, severity, biomechanics, and the varied, complex secondary injury responses that collectively result in chronic disabilities. Current preclinical research circumvents the issue of TBI heterogeneity by relying on specific preclinical animal models that mimic subpopulations of patients and particular secondary injury mechanisms with each study focusing on limited, individual pathways. This proposal instead aims to tackle TBI heterogeneity by approaching TBI as a “big data” problem and aggregating and analyzing the multidimensional data collectively. A framework for data harmonization and curation will be developed, and datasets from a consortium of preclinical labs employing a variety of preclinical TBI models will be collected and curated into an open data commons (ODC-TBI). Utilizing machine learning and multidimensional analytics, the proposed research will directly leverage TBI heterogeneity in the merged dataset to identify persistent features of TBI to empower translational research. By creating a preclinical TBI ODC and applying machine learning to integrate the heterogeneity of preclinical TBI models, the project will reveal multidimensional features of TBI across heterogeneous injuries and characterize how diverse secondary injury mechanisms interact and ultimately affect injury outcome. Throughout the project's timeline, new datasets will continue to be harmonized into the ODC-TBI according to the established framework. The ODC-TBI will be the first open multicenter, multi-model repository of preclinical TBI data and will enable the application of data science to the field of TBI. Furthermore, the ODC-TBI and the methods implemented throughout the project will be openly shared to improve reproducibility of TBI research. Together with the multidimensional analysis that will provide quantitative and qualitative understanding of TBI heterogeneity, the project aims to ultimately accelerate data- driven discovery and precision medicine for TBI. Reflecting the complexities of clinical traumatic brain injury (TBI), preclinical TBI research is confounded by the extreme heterogeneity prevalent across possible injury models and resulting biological responses. The proposed research will aggregate and curate an extensive open data commons (ODC) of preclinical TBI research with multiple TBI models and utilize machine learning to tackle TBI heterogeneity directly. The project will create an ODC for preclinical TBI research to improve data sharing and scientific reproducibility, and will empower translational TBI research by identifying multidimensional features of TBI that best predict functional outcome.",Leveraging Heterogeneity in Preclinical Traumatic Brain Injury to Drive Discovery and Reproducibility,10042756,F32NS117728,"['Address', 'Affect', 'Animal Model', 'Big Data', 'Biological', 'Biological Markers', 'Biomechanics', 'Brain region', 'Chronic', 'Clinic', 'Clinical', 'Closed head injuries', 'Common Data Element', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Commons', 'Data Element', 'Data Science', 'Data Set', 'Development', 'Foundations', 'Goals', 'Heterogeneity', 'Incidence', 'Individual', 'Inflammation', 'Informatics', 'Injury', 'Institutes', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Multivariate Analysis', 'National Institute of Neurological Disorders and Stroke', 'Outcome', 'Pathway interactions', 'Pattern', 'Pharmacologic Substance', 'Population', 'Positioning Attribute', 'Pre-Clinical Model', 'Principal Component Analysis', 'Publishing', 'Reproducibility', 'Research', 'Severities', 'Standardization', 'Synaptic plasticity', 'Therapeutic', 'TimeLine', 'Translating', 'Translational Research', 'Translations', 'Traumatic Brain Injury', 'behavioral outcome', 'bench to bedside', 'biomarker discovery', 'controlled cortical impact', 'data curation', 'data framework', 'data harmonization', 'data sharing', 'disability', 'experimental study', 'functional outcomes', 'genetic manipulation', 'improved', 'insight', 'multidimensional data', 'multiple datasets', 'nerve injury', 'nervous system disorder', 'neuroinflammation', 'open data', 'patient subsets', 'pre-clinical', 'pre-clinical research', 'precision medicine', 'repository', 'response', 'response to injury']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",F32,2020,69810,-0.018788910417308236
"BlueBox: A Complete Code Blue Data Recorder, Phase II “Code blue” is the signal used in hospitals to call for an immediate cardiopulmonary resuscitation (CPR) following a cardiac or respiratory arrest. Reviewing the performance of the “code blue team” is a cornerstone for improving outcomes. The current standard of using handwritten records on a paper “code sheet” does not allow measurement of key quality indicators and is subject to human error. In the Phase I STTR project, we developed an electronic device for complete recording of code blue events, called BlueBox. The BlueBox is a small electronic recorder on an adhesive patch to be placed on the left chest next to the mid-sternum. The prototype we developed in Phase I was successfully tested on high fidelity mannequins and on pigs. In Phase II, our goal is to complete the product development and testing and prepare the BlueBox for regulatory clearance and market launch. To achieve this goal, we propose 3 Specific Aims. Aim 1 is to complete the product development of the BlueBox device and the software user interface (UI) for the “electronic code sheet.” We will turn the engineering prototype we developed in Phase I into a product ready for commercialization through rigorous product development processes. We will develop a mobile app for iPads with a software UI for the “electronic code sheet.” Aim 2 is to conduct human factors and usability engineering (HF/UE) testing and prepare for regulatory submission. The alpha prototype will undergo HF/UE testing in the Simulation Center. We will establish and maintain quality management records and conduct a pilot production run of 200 units of BlueBox. Aim 3 is to validate the BlueBox system in clinical studies. The objectives of the clinical study are: 1) to establish equivalence of the electronic code sheet to the current standard of paper code sheet; 2) to demonstrate the effectiveness of the electronic code sheet in identifying key CPR quality indicators. We will conduct a code blue simulation study of 50 sessions on high fidelity mannequins with hospital code blue teams to compare BlueBox recording with paper code sheets. We will conduct a study of 30 healthy volunteers for BlueBox sensor validation. The criteria for successful development of the product will be that it passes all required regulatory testing and is validated in the clinical study for its equivalence and effectiveness in code blue recording. There will be two major milestones in this project: (1) finalizing product development with successful test production of 200 units; and (2) completing the clinical study and preparing for a 510(k) submission. Achieving the aims will result in a validated BlueBox system ready for submission to the FDA and commercialization. We intend to first introduce the BlueBox system to hospitals as a tool for staff training and quality improvement. We will continue the technology development with machine learning to provide instant feedback in the second generation BlueBox. Our ultimate goal is to minimize human error and improve patient outcomes through the BlueBox system’s better documentation and continuous feedback mechanism. Modified Specific Aims  “Code blue” is the alert used in hospitals to initiate immediate cardiopulmonary resuscitation (CPR) following a cardiac or respiratory arrest.1 These situations are dire emergencies. Medical errors are likely to occur, and lives can be lost. Reviewing the performance quality of the “code blue team” is a cornerstone for improving outcomes of in-hospital arrests.2-4 Thorough and accurate recording of code blue events facilitates the detailed analyses needed for quality improvement.5-7 However, the current standard of using handwritten records on a paper “code sheet” does not allow measurement of key quality indicators and is subject to human errors. In our Phase I STTR project, we developed an electronic device for complete recording of code blue events, called BlueBox. The BlueBox is a small electronic recorder on an adhesive patch to be placed on the left chest next to the mid-sternum. It captures and records all code blue events -- vital signs, cardiac rhythm, verbal orders and their execution, chest compressions, cardioversion/defibrillation, procedures, medications, and labs. The prototype we developed in Phase I was successfully tested on high fidelity mannequins in the Simulation Center, and on pigs in the Animal Lab. The purpose of the BlueBox is to support medical training and quality improvement in code blue situations, and to enhance safety for patients undergoing CPR. In Phase II, our goal is to complete the product development and testing to prepare the BlueBox for regulatory clearance and market launch. To achieve this goal, we propose 3 Specific Aims: Specific Aim 1. Completing the product development of the BlueBox recorder and the software user interface (UI) for the “electronic code sheet” In Phase I, after developing the BlueBox technology and completing its proof-of-concept, the engineering prototype was tested successfully. The firmware drives all sensors and enables simultaneous recordings of all parameters with time stamps. The circuit can withstand 5kV, which is what is used in cardioversion and defibrillation. In Phase II, we will turn the prototype into a product ready for commercialization through rigorous product development processes. The product development processes include: miniaturization, mechanical design, industrial design, and usability engineering, as well as development of a mobile app for an iPad with an “electronic code sheet” user interface (UI) displaying the code blue events. To provide instant feedback during CPR, we will develop model-based and machine learning data analytics during and beyond the Phase II project. Specific Aim 2. Conducting human factors and usability testing, quality management and regulatory support and preparation We will conduct human factors and usability engineering (HF/UE) testing on the alpha prototype in the Simulation Center. The first HF/UE study aims to test the use of the BlueBox recorder by members and captains of the hospital code team in a code blue scenario. The second HF/UE study aims to test the software and UI of the electronic code sheet on iPads, as used by members of the hospital code blue team, hospital administrators, and EMR and IT specialists. We will establish and maintain quality management records and conduct a pilot production run of 200 units of BlueBox. The pilot run units will be tested for reliability and validity in the Simulation Center. We will request a pre-submission meeting (Qsub) with the FDA. In the Qsub meeting, we will discuss specific regulatory submission requirements and obtain feedback on the clinical validation study. Specific Aim 3. Validating the BlueBox system in clinical studies We will first conduct a prospective study of 50 sessions of simulated code blue resuscitations. Each session will be attended by a team of 4 clinicians-- a captain (physician), a nurse, an ancillary staff, and a code sheet recording staff (typically a nurse). We will also conduct a study of BlueBox sensor validation in 30 healthy volunteers. We will conduct a code blue simulation study on high fidelity mannequins with a hospital code blue team to compare BlueBox recording with paper code sheets. The objectives of the clinical studies are: 1) to establish equivalence of the electronic code sheet to the current standard of paper code sheet; 2) to demonstrate the effectiveness of the electronic code sheet in identifying key CPR quality indicators specified in the American Heart Association (AHA) guidelines. Feasibility Criteria: The criteria for successful development of the BlueBox are:1) it passes all required regulatory testing; 2) it is validated in the clinical study for its equivalence and effectiveness in code blue recording and quality review and improvement. Expected Outcomes and Impact: Two major milestones are (1) finalizing product development in Year 1, and (2) completing the clinical study in Year 2. Achieving the aims will result in a validated BlueBox system ready for regulatory submission to the FDA and commercialization. We intend to first market the BlueBox system to hospitals as a tool for staff training and quality improvement. We will continue the development of BlueBox technology with machine learning algorithms to provide instant feedback. Our ultimate goal is to minimize human error and improve patient outcomes through the BlueBox system’s continuous feedback mechanism. Debriefings and detailed reviews of the performance of the “code blue team” in cardiopulmonary resuscitation (CPR) can improve quality of care and patient outcomes. In Phase I, we developed and successfully tested an electronic device, the BlueBox, for recording all CPR events and enabling full displays of code blue resuscitations in an “electronic code sheet.” We will turn the engineering prototype into a product ready for regulatory submission and commercialization in the proposed Phase II project.","BlueBox: A Complete Code Blue Data Recorder, Phase II",9857035,R42GM113463,"['Accident and Emergency department', 'Adhesives', 'American Heart Association', 'Animals', 'Cardiac', 'Cardiopulmonary Resuscitation', 'Chest', 'Clinical', 'Clinical Research', 'Code', 'Code Blue', 'Data', 'Data Analytics', 'Development', 'Devices', 'Documentation', 'Effectiveness', 'Electric Countershock', 'Electronics', 'Emergency Situation', 'Engineering', 'Event', 'Family suidae', 'Feedback', 'Generations', 'Goals', 'Guidelines', 'Hospital Administrators', 'Hospitals', 'Human', 'Industrialization', 'Left', 'Machine Learning', 'Manikins', 'Measurement', 'Mechanics', 'Medical', 'Medical Errors', 'Miniaturization', 'Modeling', 'Outcome', 'Paper', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Pilot Projects', 'Preparation', 'Procedures', 'Process', 'Production', 'Quality Indicator', 'Quality of Care', 'Records', 'Resuscitation', 'Running', 'Signal Transduction', 'Small Business Technology Transfer Research', 'Specialist', 'Specific qualifier value', 'Sternum', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Validity and Reliability', 'base', 'care outcomes', 'commercialization', 'design', 'graphical user interface', 'heart rhythm', 'human error', 'improved', 'improved outcome', 'machine learning algorithm', 'meetings', 'member', 'mobile application', 'patient safety', 'product development', 'prototype', 'respiratory', 'sensor', 'simulation', 'technology development', 'tool', 'usability', 'validation studies']",NIGMS,"NEOVATIVE, INC.",R42,2020,821493,-0.011286012415645903
"Maternal Antecedents and Electronic Fetal Monitoring in Term Asphyxia (MAESTRA) Neonatal hypoxic-ischemic encephalopathy (HIE) is a neurologic syndrome that results from reduced flow of oxygenated blood to the fetal or newborn brain. HIE occurs in 1-3 per 1,000 term births and may cause death or neurologic disabilities such as cerebral palsy. Electronic fetal monitoring (EFM) was developed in the 1970's to assess the adequacy of fetal oxygenation as a strategy to prevent HIE, and is now standard of care. Yet clinical trials report that EFM usage has not reduced the rate of CP, perinatal death or HIE, but is associated with a dramatic increase in cesarean deliveries. The currently used 3 Category fetal heart rate (FHR) classification system, based on simple rules designed to be easy to apply at the bedside, has some utility in predicting HIE. However, Category II FHR patterns that make up the vast majority of tracings are poorly predictive of HIE and confer “indeterminate” risk. Category III patterns are also of limited use in predicting HIE due to low sensitivity. There is an urgent need to develop better objective methods to assess EFM that would identify more fetuses at risk of HIE in time for corrective actions. Uterine tachysystole, or excessive frequency of uterine contractions, has been implicated as a preventable cause of HIE; yet studies report conflicting results. EFM research has been limited by an inability to access and manually analyze the large datasets needed to study HIE. We now have the ability to analyze digital EFM signals using automated methods to measure standard FHR patterns as well as to discover novel aspects of the tracing that may not be readily detectable by a clinician at the bedside. We hypothesize that modern signal processing and machine learning techniques can create highly predictive models of HIE by analyzing established and novel features of EFM tracings, in combination with demographic and pertinent clinical information from the mother and fetus. We propose a population-based retrospective cohort study of 350,000 infants born at ≥ 36 weeks gestation at Kaiser Permanente Northern California in 2010-19. Our specific aims are: 1) To create the MAESTRA Cohort dataset that links EFM recordings to HIE and neonatal acidosis among 350,000 infants born at ≥ 36 weeks gestation in 2010-19 at Kaiser Permanente Northern CA; 2) Using modern signal processing and machine learning techniques, to extract established and novel FHR and uterine contractility features from the EFM recordings, and to determine which of these features are most predictive of HIE and acidosis when combined with maternal and fetal clinical data; and 3) To perform external validation by applying the final predictive models to a historical dataset. We anticipate that machine learning techniques incorporating novel FHR and uterine contractility patterns over time, as well as pre- and perinatal clinical characteristics, will improve the predictive value of the EFM data that are already being collected as part of routine care. Our results will inform future clinical trials. Such an unprecedented large-scale multidisciplinary study will lead to improvements in our ability to use EFM data to prevent neonatal brain injury while minimizing unnecessary cesarean sections. MAESTRA Project Narrative Hypoxic-ischemic encephalopathy (HIE) occurs when a baby gets reduced oxygen and blood flow to the brain, and can lead to death or long-term disabilities such as cerebral palsy. During labor and delivery, doctors are able to continuously record the heart rate of the fetus. This study will determine how best to use the heart rate information so that we can reduce the number of infants who develop this severe brain condition.",Maternal Antecedents and Electronic Fetal Monitoring in Term Asphyxia (MAESTRA),9972526,R01HD099216,"['Acidosis', 'Address', 'Apgar Score', 'Asphyxia', 'Blood', 'Blood flow', 'Brain', 'California', 'Categories', 'Cause of Death', 'Cerebral Palsy', 'Cesarean section', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Computerized Medical Record', 'Conflict (Psychology)', 'Data', 'Data Set', 'Discipline of obstetrics', 'Educational workshop', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Frequencies', 'Future', 'Heart Rate', 'Infant', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Metabolic Brain Diseases', 'Metabolic acidosis', 'Methods', 'Modeling', 'Modernization', 'Mothers', 'National Institute of Child Health and Human Development', 'Neonatal', 'Neonatal Brain Injury', 'Neurologic', 'Newborn Infant', 'Observational Study', 'Outcome', 'Oxygen', 'Pattern', 'Perinatal', 'Perinatal anoxic ischemic brain injury', 'Perinatal mortality demographics', 'Population', 'Positioning Attribute', 'Predictive Value', 'Pregnancy', 'Preventive Intervention', 'Records', 'Reporting', 'Research', 'Retrospective cohort study', 'Risk', 'Seizures', 'Sensitivity and Specificity', 'Signal Transduction', 'Syndrome', 'System', 'Techniques', 'Term Birth', 'Testing', 'Time', 'Uterine Contraction', 'Uterus', 'Validation', 'base', 'cohort', 'computerized', 'design', 'digital', 'disability', 'effectiveness evaluation', 'falls', 'fetal', 'fetus at risk', 'high risk', 'hypoxia neonatorum', 'improved', 'large datasets', 'multidisciplinary', 'neonatal hypoxic-ischemic brain injury', 'novel', 'population based', 'predictive modeling', 'prevent', 'routine care', 'signal processing', 'standard measure', 'standard of care', 'uterine contractility']",NICHD,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,667049,-0.02702877211190066
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9838229,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Models', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'random forest', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2020,474671,-0.020162373117959223
"Virtual growing child 5-dimensional functional models for treating respiratory anomalies Thoracic Insufficiency Syndrome (TIS) is a group of serious disorders of the pediatric thorax resulting in an inability of the thorax to support respiration or lung growth. TIS is associated with at least 28 pediatric syndromes, with an estimated health care cost per patient that can easily exceed a million dollars. In TIS, three-dimensional deformity of the thoracic components anatomically and functionally reduces the volume available for ventilation. Pediatric specialists dealing with TIS currently face several serious challenges: (a) The complex interplay among dynamic and growing thoracic structures and its influence on thoracic function and growth are not understood at present. (b) The prime outcome measure for the corrective procedures has remained the radiographic Cobb angle of the spine, a 60-year old metric with poor correlation with lung dynamic function and limited true health assessment value. (c) A normative imaging database with functional metrics describing dynamics and growth of the thoracic structures of the normal pediatric population does not exist. Due to these hurdles, innovations in growth-modulating surgical techniques are difficult to achieve. Supported by extensive preliminary results based on dynamic MRI (dMRI) of patients and normal subjects, the overarching goal of this proposal is to develop novel dynamic functional metrics for TIS by establishing a normative database of dMRI images and anatomic and functional models and metrics, and to translate these to develop markers of TIS and of its corrective-surgery outcomes. The project has three aims. Aim 1: To develop a new methodology called The Virtual Growing Child (VGC) consisting of 4 key components: a) To build a normative database of dMRI images prospectively gathered from 200 normal children divided into 10 groups. b) To build population anatomic models involving key thoraco-abdominal objects following an established automatic anatomy recognition (AAR) technology and deep learning (DL) techniques. c) To develop and validate joint AAR-DL algorithms to segment these objects in dMRI images of TIS patients. d) To build a normative database of measurements derived from dMRI images describing normal thoracic architecture, dynamic function, and growth. The database will also include a full battery of Pulmonary Function Testing data and anthropometric measurements. Aim 2: To test retrospectively the utility of the VGC ensemble in deriving markers of TIS and its surgical treatment effects on a cohort of 100 TIS patients. Aim 3: To retrospectively test the utility of the VGC approach for planning surgery in 30 TIS patients by comparing VGC-guided surgical planning to the current planning method. The post-operative key dMRI parameters of patients whose surgical plan would have changed due to VGC data will be compared to those of patients whose plan did not change. Expected outcomes: (i) A unique registry of thoracic dMRI of 200 normal pediatric subjects, segmented objects, and the associated anatomic, dynamic, and developmental parameters. (ii) A validated VGC approach for studying TIS which can also be utilized for studying other pediatric and adult thoracic disorders. Thoracic Insufficiency Syndrome (TIS) is a group of serious disorders of the pediatric thorax. Currently there are no reliable and scientific functional metrics to describe these disorders and their treatment effects. This grant application proposes to build an innovative methodology called the Virtual Growing Child (VGC) based on dynamic MRI of the thorax, construct a comprehensive normative database of MRI images and associated measurements, and utilize the VGC methodology to scientifically characterize TIS and arrive at innovative surgical planning methods.",Virtual growing child 5-dimensional functional models for treating respiratory anomalies,9861454,R01HL150147,"['3-Dimensional', 'Abdomen', 'Address', 'Adult', 'Aftercare', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Applications Grants', 'Architecture', 'Birth', 'Chest', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Databases', 'Deformity', 'Development', 'Diagnostic radiologic examination', 'Dimensions', 'Disease', 'Face', 'Gender', 'Goals', 'Growth', 'Health Care Costs', 'Image', 'Incidence', 'Joints', 'Life', 'Lung', 'MRI Scans', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Names', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedic Procedures', 'Outcome', 'Outcome Measure', 'Patients', 'Population', 'Population Group', 'Postoperative Period', 'Procedures', 'Pulmonary function tests', 'Registries', 'Respiration', 'Respiratory physiology', 'Rod', 'Scanning', 'Sensitivity and Specificity', 'Specialist', 'Spinal', 'Spinal Fusion', 'Spirometry', 'Structure', 'Syndrome', 'Techniques', 'Technology', 'Testing', 'Thoracic Diseases', 'Tidal Volume', 'Time', 'Translating', 'Vertebral column', 'Vital capacity', 'age group', 'base', 'cohort', 'deep learning', 'deep learning algorithm', 'health assessment', 'innovation', 'novel', 'prospective', 'pulmonary function', 'respiratory', 'surgery outcome', 'treatment effect', 'ventilation', 'virtual']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2020,799509,-0.019498795254684644
"Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space Project Summary  The natural environment is intrinsically spatiotemporally heterogenous at both macroscopic and microscopic levels. What shapes such a heterogeneity includes the concentration gradients of biologically relevant chemical species in the extracellular medium including dioxygen (O2), reactive oxygen species (ROS), as well as essential redox-active transition metals. While a significant amount of effort has been devoted to spectroscopically image these chemical moieties, our capability to spatiotemporally control their concentration distributions in the extracellular medium remains limited. This is especially the case for biofilms and microbiota, in which the microorganisms’ small length scales pose significant challenges for concentration modulation. The inadequate control of concentration heterogeneity limits our capability of mimicking the natural environments in vitro and investigating how local concentration gradients affect microbial functionality. Therefore, there is a need for an advanced method of controlling chemical concentrations at microscopic level.  Our proposed research aims to use electrochemical nano-/micro-electrodes to spatiotemporally control the concentration gradients in the extracellular medium. When an electrochemical reaction occurs on an electrode’s surface, a concentration gradient is established near the electrode. Taking advantages of this phenomena with the assistance of numerical simulation, we will employ an array of nano-/micro-electrodes with individually addressable electrochemical potentials to program any arbitrary spatiotemporal concentration profiles. We will fine-tune the surface chemistry and the electrochemical properties of these electrodes to ensure biocompatibility and reaction specificity. The developed system will be applied to biofilms and we aim to investigate how the microbial social behavior will be affected by a perturbation of local O2 concentration. Moreover, we will use this device to mimic the heterogenous environment in the gut and culture gut microbiota in vitro. An algorithm based on machine learning will be employed to actively adjust electrode potentials, maintaining a stable concentration profile despite the accumulation of gut microorganisms.  Ultimately, our work will expand our capability of controlling the concentration heterogeneity in nature. The developed electrochemical system will serve an in vitro platform to culture microorganisms in their native environment, or as a tool to perturb the concentration profiles. Combining electrochemistry, inorganic chemistry, and nanomaterials the research will enable a deeper understanding of the spatial distribution and temporal response of microbial systems. Project Narrative The natural environment is intrinsically heterogenous yet our control of concentrations for chemical species is limited at microscopic level. The proposed research is relevant to the mission of the NIH because it describes the development of technology that will expand our capability of controlling chemical concentration profiles in a variety of microbial systems relevant to the public health. The research described here will enable a deeper understanding of disease-related microbial systems and help to formulate strategies to combat diseases.",Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space,10029526,R35GM138241,"['Affect', 'Algorithms', 'Biological', 'Chemicals', 'Chemistry', 'Devices', 'Dioxygen', 'Disease', 'Electrochemistry', 'Electrodes', 'Ensure', 'Environment', 'Heterogeneity', 'In Vitro', 'Individual', 'Inorganic Chemistry', 'Length', 'Machine Learning', 'Methods', 'Microbial Biofilms', 'Microscopic', 'Mission', 'Nanoarray Analytical Device', 'Nature', 'Oxidation-Reduction', 'Property', 'Public Health', 'Reaction', 'Reactive Oxygen Species', 'Research', 'Shapes', 'Social Behavior', 'Spatial Distribution', 'Specificity', 'Surface', 'System', 'Transition Elements', 'United States National Institutes of Health', 'Work', 'base', 'biomaterial compatibility', 'combat', 'extracellular', 'gut microbiota', 'microbial', 'microbiota', 'microorganism', 'microorganism culture', 'nano', 'nanomaterials', 'programs', 'response', 'simulation', 'spatiotemporal', 'spectroscopic imaging', 'technology development', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2020,371084,-0.044566815900433474
"Development of a biomarker panel for minimally-invasive screening and diagnosis of gynecological disease PROJECT SUMMARY One-third of all women of reproductive age will experience nonmenstrual pelvic pain at some point in their lives and one-third of outpatient visits to gynecologists in the U.S. are for evaluation of abnormal uterine bleeding. For many women, these symptoms accompany infertility which is reported in ~10% of all US women and even higher percentages worldwide. For almost all of these women, these conditions result in a diagnostic odyssey wherein women struggle through multiple physicians over many years for a definitive diagnosis, frequently culminating in invasive laparoscopy or hysteroscopy with dilation and curettage (D&C) for definitive diagnosis. To reduce the burden of diagnosis and enable early treatment, MDDx, Inc. is developing the first biomarker- based diagnostic test to enable minimally invasive simultaneous diagnosis of four of the most common causes which together result in chronic pain, uterine bleeding and infertility: adenomyosis, endometrial polyps, leiomyoma, and endometriosis. MDDx, Inc. has been leveraging access to >12 years of longitudinally collected and deeply annotated biobanked uterine lavage samples from the Gynecologic Cancer Translational Research Program (Icahn School of Medicine at Mount Sinai; New York, NY and Nuvance Health; Danbury, CT) to identify diagnostic autoantibodies (AAb) that could serve as diagnostic biomarkers for these benign gynecological diseases. By performing AAb profiling against the entire human proteome and applying our novel machine-learning based method for classification of molecular profiles we have determined that there is a common set of ~200 biomarkers that could be used to diagnose women with adenomyosis, endometrial polyps, leiomyoma, or endometriosis. The goal of Phase I is to finalize and validate the optimized set of ~200 diagnostic AAbs, while Phase II will focus on validation of the commercial diagnostic assay. In Aim 1 we will expand our proprietary database of uterine lavage autoantibody profiles to ensure that we have a sample size (~935) that will enable us to confidently apply our machine learning approaches to identifying the minimal panel of AAbs for the diagnostic. We will use this enhanced database to identify a prototype panel of ~200 AAbs for construction of classification scoring functions to distinguish between adenomyosis, endometrial polyps, leiomyoma, and endometriosis. In Aim 2 we will perform a blinded validation and performance study using an independent set of 300 uterine lavage samples to provide proof-of- concept for clinically useful sensitivity and specificity prior to large scale prospective validation in Phase II. Successful completion of this Phase I program will identify the optimized panel of AAbs for an affordable, laboratory-based diagnostic test that will significantly reduce the number of women who will need to undergo laparoscopy or hysteroscopy with D&C for definitive diagnosis, enabling early treatment of disease and reducing the significant psychological and financial burden of diagnoses that otherwise can take years. PROJECTIVE NARRATIVE Nearly half of all women of reproductive age will experience some combination of nonmenstrual pelvic pain, abnormal uterine bleeding, and infertility in their lifetimes, yet there are no non-invasive methods to definitively diagnose the primary causes of these symptoms. MDDx, Inc. is developing the first laboratory diagnostic test to enable minimally invasive simultaneous diagnosis of four common causes of these often debilitating symptoms and infertility: adenomyosis, endometrial polyps, leiomyoma, and endometriosis. This test will enable early detection, early treatment, and reduce the physical, emotional, and financial burden of obtaining a diagnosis for women suffering from these common yet disruptive symptoms.",Development of a biomarker panel for minimally-invasive screening and diagnosis of gynecological disease,10146682,R41HD104402,"['Address', 'Age', 'Algorithms', 'Anesthesia procedures', 'Antigens', 'Area', 'Atypical Endometrial Hyperplasias', 'Autoantibodies', 'Benign', 'Biological Markers', 'Blinded', 'Categories', 'Classification', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Diagnostic tests', 'Dilatation and Curettage', 'Disease', 'Early Diagnosis', 'Early treatment', 'Emotional', 'Endometrial Carcinoma', 'Ensure', 'Entropy', 'Evaluation', 'Female Genital Diseases', 'Financial Hardship', 'General Anesthesia', 'Goals', 'Gynecologist', 'Health', 'Healthcare Systems', 'Hemorrhage', 'Human', 'Hysteroscopy', 'Image', 'Infertility', 'Irrigation', 'Laboratories', 'Laparoscopy', 'Leiomyoma', 'Liquid substance', 'Machine Learning', 'Malignant Female Reproductive System Neoplasm', 'Malignant neoplasm of ovary', 'Methods', 'Molecular', 'Molecular Profiling', 'New York', 'Operating Rooms', 'Outpatients', 'Pain', 'Patients', 'Pelvic Pain', 'Performance', 'Phase', 'Physicians', 'Polyps', 'Population Control', 'Positioning Attribute', 'Preneoplastic Conditions', 'Probability', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Recording of previous events', 'Reporting', 'Risk', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Specificity', 'Structure', 'Surgeon', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Triage', 'United States', 'Uterine Polyp', 'Uterine hemorrhage', 'Uterus', 'Validation', 'Visit', 'Woman', 'Work', 'base', 'biobank', 'biomarker panel', 'chronic pain', 'clinically relevant', 'cost', 'diagnostic assay', 'diagnostic biomarker', 'diagnostic panel', 'disabling symptom', 'disease diagnosis', 'endometriosis', 'experience', 'improved', 'large datasets', 'medical schools', 'minimally invasive', 'novel', 'phase 1 study', 'programs', 'prospective', 'prototype', 'psychologic', 'reproductive', 'screening', 'translational research program', 'uterus endometriosis']",NICHD,"MDDX, INC.",R41,2020,299998,-0.0524934722638006
"Elucidating Sensorial and Functional Characteristics of Topical Formulations Abstract In addition to the defined therapeutic effect caused by an active drug in a product, there is also a placebo and, potentially, a nocebo effect associated with that product. In topical products, these latter effects may account for 30% to 50% of the overall response for some products. They may also explain why some topical products with apparently identical bioavailability are associated with different patient outcomes. This application seeks to address the question of when do subtle excipient and manufacturing changes in a topical product cause a sensorial perception by subjects such that the “feel” of a product has changed either before and/or after it is applied to human skin. A second question is whether the “feel” of a product both before and after application can be quantified by instrumental rheology, tribology and texture analysis methods and whether these, in turn, can be related to the reported sensorial behaviour. We will manufacture topical formulations that systematically vary in Q1, Q2, and/or Q3 attributes and have large and borderline perceptive differences. We will then characterize these products using a range of rheology, tribology and texture analysis methods along with characterization of rate of drying, particle and globule size. In parallel, these products will be evaluated by perceptive testing focus groups, with controls, for their sensory properties or the ‘feel’ of the products. We will then relate these sensorial findings with the variations in formulation nature, composition and manufacture, and their resulting instrumental test results. Our goals are, firstly, to understand the relationships between product nature, instrumental findings and sensorial analyses and, secondly, to derive criteria for instrument tests that indicate what product composition subjects suggest do not differ, uncertain if they differ and do differ in their sensorial behaviour. It is anticipated that we can define the simplest, robust test that accurately and robustly aligns with sensory perceptions. A range of statistical methods, including (potentially) sophisticated, machine learning and deep learning tools will then be used to model the most appropriate instrumental analysis that can, with reasonable confidence predict perceptive attributes. A key outcome is a potential regulatory guideline advocating that generic products should exhibit similar sensorial behaviour as a reference listed drug product, giving boundaries in rheology, tribology and texture analysis as defined by Q1, Q2 and Q3 differences when sensorial behaviour between topical products is likely to be different. Narrative Generic and reference-listed topical products have the potential to have differing placebo and nocebo effects, i.e. effects beyond those of the active drug. This project aims to understand what subtle changes in Q1,Q2 or Q3 between different product formulations lead to a subject reporting sensorial perceptions suggesting that the “feel” of two product is either different or they can no longer perceive a meaningful difference. Compositions (reference and generic) will be manufactured with variations in Q1, Q2 and Q3, characterised by instrumental measures and the results related to sensorial analysis findings.",Elucidating Sensorial and Functional Characteristics of Topical Formulations,9999507,U01FD006700,[' '],FDA,UNIVERSITY OF QUEENSLAND,U01,2020,499990,-0.022596793836138662
"Associating retinal nerve fiber layer thickness with glucose metabolism and diabetic retinopathy Project Summary/Abstract Type 2 diabetes mellitus (T2DM), a metabolic disease that affects over 300 million people worldwide and that can be accompanied by serious health complications such as heart disease, kidney failure, stroke, and damage to the eyes, in particular diabetic retinopathy (DR), which is diagnosed in a third of people with diabetes and which is the leading cause of blindness within the age group between 20 and 64 years. T2DM is clinically diagnosed by parameters related to glucose metabolism obtained by blood tests. Due to its long pre- symptomatic phase, an estimate of 25% of diabetics in the US are undiagnosed. In this project, the relationship between spatial patterns of retinal nerve fiber layer (RNFL) thickness (RNFLT), measured by spectral-domain optical coherence tomography (OCT), and blood test levels as well as levels of DR severity is investigated in 9,261 participants of a population based study.  In a first step, OCT RNFLT measurements of the macular and the circumpapillary area around optic nerve head are segmented into spatial sectors, and representative spatial patterns of RNFLT are calculated by an unsupervised machine learning method. Afterwards, a multivariate linear model comparison is performed with the coefficients of the spatial RNFLT patterns as regressors and diagnostic blood test results as dependent variable. The optimal combination of the RNFLT patterns, determined by an established model selection criterion (Bayes Factor), is expected to reveal insight into the association between the specific retinal locations of RNFL thinning accompanying the change in parameters related glucose metabolism during the development and progression of T2DM. Furthermore, fundus images are graded by DR severity following a nine-step scale derived from the Early Treatment Diabetic Retinopathy Study from no DR to severe proliferative DR. The spatial RNFLT patterns and metabolic blood test scores are then compared with respect to modeling DR severity by linear regression. An optimal model of DR severity combining glucose metabolism parameters and RNFLT patterns is developed. Finally, in an analogous procedure, DR severity of the follow-up measurement, five years after baseline, is statistically predicted from RNFLT and metabolic blood parameters and from their change over time.  To summarize, the proposed research identifies spatial patterns of RNFLT associated with parameters of glucose metabolism and their development over DR severity. Once accomplished, the proposed project would provide the details to establish RNFLT as an alternative manifestation of T2DM that complements diagnostic blood tests and thereby, for instance, lay the foundations for the development of novel and more accurate T2DM progression monitoring or the prediction of the onset of DR. Project Narrative Parameters related to glucose metabolism obtained by blood tests are clinically used to diagnose diabetes, a metabolic disease that affects over 300 million people worldwide and that can be accompanied by serious health complications, such as diabetic retinopathy (DR), the leading cause of blindness within the age group between 20 and 64 years. Decreased levels of blood glucose tolerance have been associated with retinal nerve fiber layer (RNFL) thinning, but these results were based on comparisons between small populations of diagnosed diabetics and healthy controls, and RNFL was typically represented by coarse summary parameters which neglect retinal anatomy. This project contributes directly and immediately to public health by exploring the relationship between spatial patterns of RNFL thickness, present and future DR severity, and diagnostic blood test results in 9,261 participants of a population based study, with the final goal to establish and quantify RNFL thickness as an alternative manifestation of diabetes that complements diagnostic blood tests and lays the foundations for the development of novel and more accurate disease progression monitoring or the prediction of DR onset.",Associating retinal nerve fiber layer thickness with glucose metabolism and diabetic retinopathy,10002287,R21EY030631,"['Affect', 'Anatomy', 'Area', 'Bayesian Modeling', 'Blindness', 'Blood', 'Blood Glucose', 'Blood Tests', 'Clinical', 'Complement', 'Data', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Disease Progression', 'Early treatment', 'Eye', 'Foundations', 'Future', 'Glycosylated hemoglobin A', 'Goals', 'Health', 'Heart Diseases', 'Kidney Failure', 'Linear Models', 'Linear Regressions', 'Location', 'Maps', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Diseases', 'Modeling', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'OGTT', 'Optic Disk', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Pattern', 'Phase', 'Population', 'Population Study', 'Procedures', 'Public Health', 'Research', 'Retina', 'Scanning', 'Selection Criteria', 'Severities', 'Severity of illness', 'Stroke', 'Sum', 'Techniques', 'Test Result', 'Testing', 'Thick', 'Thinness', 'Time', 'Validation', 'age group', 'archetypal analysis', 'base', 'clinical Diagnosis', 'diabetic', 'fasting plasma glucose', 'follow-up', 'fundus imaging', 'glucose metabolism', 'glucose tolerance', 'insight', 'machine learning method', 'macula', 'neglect', 'novel', 'predictive modeling', 'proliferative diabetic retinopathy', 'public health relevance', 'retinal nerve fiber layer', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,R21,2020,240285,-0.012313945732666335
"An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis Project Summary  Improved methods for the bedside diagnosis and evaluation of neuromuscular disorders are needed. One technology that is finding increasing use for this purpose is electrical impedance myography (EIM). In EIM, a very weak, high frequency electrical current is passed through a muscle of interest and the resulting surface voltages are measured. Disease associated alterations in the composition and microstructural features of the muscle produce characteristic changes that can be used to help classify specific conditions and grade disease severity. To date, most studies using EIM analysis have utilized a fairly limited data set for disease assessment. While effective, this approach ignores a great deal of information locked within the impedance data, including those values that can assist in predicting specific muscle features (such as myofiber diameter) and the presence of pathological change (e.g., fat or connective tissue deposition). In addition, as it stands, the data set is challenging for the clinician to understand without a detailed knowledge of impedance theory. Myolex, Inc is a small business concern located in Boston, MA has as its main focus the development of EIM technologies for clinical use. Myolex recently completed a Phase 1 SBIR that demonstrated the potential capability of machine learning based classification algorithms to effectively discriminate healthy muscle from diseased and to discriminate one disease from another. In this proposed work, we will greatly advance this concept by embodying classification algorithms into a powerful new software suite for Myolex’s current EIM system, the mView. Our underlying hypothesis is that EIM data analysis can be automated to the point that classification systems can provide data on disease diagnosis as well as disease severity for improved ease-of-use. We propose to study this hypothesis via 2 specific aims. In Specific Aim 1, we will design a software suite capable of assisting with artifact-free data collection to be incorporated into our current EIM system, the mViewTM. Then using classification paradigms based on a prodigious amount of previous collected data, we will develop an automated data analysis tool to help provide data on disease category as well as microscopic features, muscle based on the impedance data alone using Microsoft’s Azure Cloud platform. In Specific Aim 2, we will test this developed software suite in a total of180 adult and pediatric neuromuscular disease patients and healthy participants evaluated at Ohio State University Wexner Medical Center (adults) and Boston Children’s Hospital (children). During this data collection period, the Ohio State and Boston Children’s researchers will have real- time access to Myolex staff to provide feedback and have questions/problems answered and addressed. The user interface will continue to be refined and classification algorithms improved. At the conclusion of this work, a new diagnostic tool will be developed for potential 510(k) FDA approval. It will serve as the basis for a continuously self-refining system as additional data sets are collected by end-users employing them in regular clinical use. Project Narrative  Electrical impedance myography (EIM) is a valuable technique to assist with the evaluation of a variety of conditions affecting nerve and muscle. However, to date, only simplistic EIM outcomes have been utilized to assess muscle condition. In this proposed work, we will develop a software platform using machine learning to be incorporated into current EIM technology to allow for automated diseased classification and characterization using the entire large EIM data set collected with each muscle measurement. This will serve as the basis for a new, powerful and convenient tool for neuromuscular diagnosis that will continue to advance over time.",An integrated electrical impedance myography platform for neuromuscular disease classification and diagnosis,10002324,R44NS113756,"['Address', 'Adult', 'Affect', 'Algorithmic Software', 'Amyotrophic Lateral Sclerosis', 'Area', 'Back Pain', 'Boston', 'Businesses', 'Caliber', 'Categories', 'Characteristics', 'Child', 'Childhood', 'Classification', 'Clinical', 'Complex', 'Computer software', 'Connective Tissue', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Set', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Duchenne muscular dystrophy', 'Effectiveness', 'Electrodes', 'Ensure', 'Evaluation', 'Fatty acid glycerol esters', 'Feedback', 'Fiber', 'Frequencies', 'Functional disorder', 'Health', 'Inclusion Body Myositis', 'Individual', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Medical Technology', 'Medical center', 'Methods', 'Microscopic', 'Morphologic artifacts', 'Muscle', 'Muscular Dystrophies', 'Myography', 'Myopathy', 'Myositis', 'Nerve', 'Neuromuscular Diseases', 'Neuromuscular conditions', 'Ohio', 'Outcome', 'Participant', 'Pathologic', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phase', 'Physicians', 'Play', 'Positioning Attribute', 'Provider', 'Radiculopathy', 'Research Personnel', 'Role', 'Severities', 'Severity of illness', 'Small Business Innovation Research Grant', 'Specific qualifier value', 'Spinal Muscular Atrophy', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Universities', 'Work', 'advanced analytics', 'base', 'classification algorithm', 'cloud based', 'cloud platform', 'commercialization', 'complex data ', 'data acquisition', 'design', 'diagnosis evaluation', 'disease classification', 'disease diagnosis', 'electric impedance', 'feature extraction', 'improved', 'indexing', 'interest', 'machine learning algorithm', 'method development', 'nerve injury', 'neuromuscular', 'novel diagnostics', 'pediatric patients', 'physical therapist', 'prototype', 'sarcopenia', 'software development', 'success', 'theories', 'tool', 'usability', 'user friendly software', 'user-friendly', 'voltage']",NINDS,"MYOLEX, INC.",R44,2020,869698,-0.002226455895009987
"A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth This project provides a data science framework and a toolbox of best practices for systematic and reproducible data-driven methods for validating and deriving RDoC constructs with relevance to psychopathology. Despite recent advances in methods for data-driven constructs, results are often hard to reproduce using samples from other studies. There is a lack of systematic statistical methods and analytical design for enhancing reproducibility. To fill this gap, we will develop a data science framework, including novel scalable algorithms and software, to derive and validate RDoC constructs. Although the proposed methods will generally apply to all RDoC domains and constructs, we focus specifically on furthering understanding of the RDoC domains of cognitive control (CC) and attention (ATT) constructs implicated in attention deficit disorder (ADHD) and obsessive-compulsive disorder (OCD). Our application will use multi-modal neuroimaging, behavioral, and clinical/self-report data from large, nationally representative samples from the on Adolescent Brain Cognitive Development (ABCD) study and multiple local clinical samples with ADHD and OCD. Specifically, using the baseline ABCD samples, in aim 1, we will apply and develop methods to assess and validate the current configuration of RDoC for CC and ATT using confirmatory latent variable modeling. We will implement and develop new unsupervised learning methods to construct new computational-driven, brain-based domains from multi-modal image data. In Aim 2, We will introduce network analysis (via Gaussian graphical models) to characterize heterogeneity in the interrelationship of RDoC measurements due to observed characteristics (i.e., age and sex). We will further model the heterogeneity of the population due to unobserved characteristics by introducing the data-driven precision phenotypes, which are the subgroup of participants with similar RDoC dimensions. We propose a Hierarchical Bayesian Generative Model and scalable algorithm for simultaneous dimension reduction and identify precision phenotypes. The model also serves as a tool to transfer information from the community sample ABCD to local clinical enriched studies. In aim 3, we will utilize the follow-up samples from ABCD and local clinical enriched data sets to validate the results from Aims 1 and 2 and assess the clinical utility of the precision phenotypes in predicting psychological development in follow-up time. Our project will provide a suite of analytical tools to validate existing RDoC constructs and derive new, reproducible constructs by accounting for various sources of heterogeneity. To advance the understanding of psychopathology using dimensional constructs of measurements from multiple units of analysis, we propose reproducible statistical framework for validating and deriving RDoC constructs with relevance to psychopathology. We will use multi-modal neuroimaging, behavioral and clinical/self-report data from multiple samples to develop this framework. The design of our study consists of analyzing large, nationally representative samples, validating the results in local clinically enriched samples, and transfer information from the large community samples to local clinical samples.",A Data Science Framework for Empirically Evaluating and Deriving Reproducible and Transferrable RDoC Constructs in Youth,10058921,R01MH124106,"['11 year old', 'Accounting', 'Adolescent', 'Age', 'Algorithmic Software', 'Algorithms', 'Attention', 'Attention Deficit Disorder', 'Base of the Brain', 'Behavioral', 'Brain', 'Characteristics', 'Child', 'Chronology', 'Clinical', 'Clinical Data', 'Communities', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Dimensions', 'Ensure', 'Functional Magnetic Resonance Imaging', 'Gaussian model', 'Goals', 'Heterogeneity', 'Image', 'Knowledge', 'Learning', 'Link', 'Measurement', 'Measures', 'Mental Health', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Obsessive-Compulsive Disorder', 'Participant', 'Pathway Analysis', 'Patient Self-Report', 'Phenotype', 'Population Heterogeneity', 'Prediction of Response to Therapy', 'Psychological Transfer', 'Psychopathology', 'Reproducibility', 'Reproducibility of Results', 'Research Domain Criteria', 'Sampling', 'Source', 'Statistical Methods', 'Structure', 'Subgroup', 'Symptoms', 'Time', 'Variant', 'Youth', 'age effect', 'analytical tool', 'autoencoder', 'base', 'biological sex', 'cognitive control', 'cognitive development', 'deep learning', 'design', 'follow up assessment', 'follow-up', 'high dimensionality', 'independent component analysis', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'multimodality', 'network models', 'neuroimaging', 'novel', 'psychologic', 'response', 'sex', 'tool', 'unsupervised learning']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R01,2020,710101,-0.01602037732008424
"Predicting complicated grief from grief processing PROJECT SUMMARY Most people grieving the loss of a loved one will experience a period of intense pain and focusing on the loss lasting around 6 months, which is known as acute grief. Complicated grief (CG) occurs when the experiences of acute grief extend well past 6-months post-loss. Thoughts and feelings about the loss (i.e. grief processing) occurring during acute grief may play a role in healthy grieving and protect against CG development. Identification of the cognitive and emotional mechanisms of grief processing that contribute to healthy grief resolution would advance knowledge of the goals of grieving and assist the development of interventions for complicated grief. Two core components of grief processing are top-down regulation and balanced loss confrontation. Top-down pursue related emotional representations and recruit proportion regulation is the ability to suppress processing of intrusive emotional information to a stated goal. Top-down regulation may facilitate healthy grieving by allowing reprieve from intense loss thinking. Balanced loss confrontation refers to the processing of the loss in a way that protects against overload. Confrontation with the l oss may assist in the process of reforming one's mental of the deceased. This tudy will test extrinsic and intrinsic measures of top-down regulation balanced loss confrontation during acute grieving as predictors of CG development a year later We will a sample at high-risk for CG, the suicide-bereaved, in order to maximize the likeliness that a significant of the sample develops CG. The s . findings produced by this study may advance the knowledge of how CG develops, assist in the identification of people at high-risk for developing CG and potentially form the basis for targeted interventions.  The following K23 presents a research and training program that will support the applicant on the path of becoming an independent investigator of the role of grief processing in the development of complicated grief. The research mentorship, coursework, hands-on experience, seminars and classes ingrained in this training and plan will propel the applicant to independence in the domains of1) Clinical Research, 2) Psychometric Assessment of Grief Processing, 3) Machine Learning analysis of fMRI, 4) Biostatistics, 5) Scientific Independence. team independent and The combination of the environment, t raining plan, research strategy and mentorship will not only provide the candidate with a spectrum of new methods and skills that will establish him as an research scientist, but will also produce a body of knowledge that will clarify the specific cognitive emotional grief processes that contribute to the development of CG. PROJECT NARRATIVE Complicated grief describes an inability to adjust to the loss of a loved one over the course of the first year following the death. This study will identify cognitive, emotional and neural processes occurring in the early grieving period (3 to 5-months post-loss) that predict or protect against the development of complicated grief a year later in suicide bereaved subjects, a sample at high-risk for developing complicated grief. These findings may advance understanding of the process of grief, facilitate early identification of high-risk grievers and potentially form the basis for targeted treatment of complicated grief.",Predicting complicated grief from grief processing,9888433,K23MH114021,"['Acute', 'Age', 'Attention', 'Biometry', 'Cessation of life', 'Clinical', 'Clinical Research', 'Cognitive', 'Data', 'Depressed mood', 'Development', 'Down-Regulation', 'Early identification', 'Emotional', 'Emotions', 'Environment', 'Failure', 'Family member', 'Feeling', 'Functional Magnetic Resonance Imaging', 'Gender', 'Goals', 'Grief reaction', 'Guilt', 'High Prevalence', 'Individual', 'Instruction', 'Intervention', 'Interview', 'Knowledge', 'Machine Learning', 'Measures', 'Mental Depression', 'Mentorship', 'Methods', 'Modeling', 'Pain', 'Pathogenesis', 'Pattern', 'Play', 'Process', 'Psyche structure', 'Psychometrics', 'Questionnaires', 'Rain', 'Reaction Time', 'Recording of previous events', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Resolution', 'Role', 'Sampling', 'Scientist', 'Severities', 'Shame', 'Stimulus', 'Suicide', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Training Programs', 'Trauma', 'Unconscious State', 'Validation', 'attentional bias', 'base', 'experience', 'high risk', 'indexing', 'intense pain', 'loved ones', 'neural patterning', 'recruit', 'relating to nervous system', 'response', 'sex', 'skills', 'sustained attention', 'targeted treatment', 'therapy development']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,K23,2020,199800,-0.03710232796114265
New Approaches to Dementia Heterogeneity  ,New Approaches to Dementia Heterogeneity,10053649,P30AG062422,"['Aging', 'Area', 'Artificial Intelligence', 'Astrocytes', 'Behavior', 'Big Data', 'Biological Markers', 'Blood', 'Blood Vessels', 'Brain', 'Brain imaging', 'Cells', 'Cognition', 'Cognitive', 'Data', 'Data Analytics', 'Data Collection', 'Degenerative Disorder', 'Dementia', 'Disease', 'Disease Progression', 'Dissection', 'Early Diagnosis', 'Emotional', 'Endothelium', 'Etiology', 'Failure', 'Fibrosis', 'Functional disorder', 'Funding', 'Goals', 'Heterogeneity', 'Homeostasis', 'Image', 'Impaired cognition', 'Impairment', 'Inflammation', 'Injury', 'Intervention', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mediating', 'Mediation', 'Mentors', 'Mentorship', 'Modeling', 'Molecular', 'National Institute of Neurological Disorders and Stroke', 'Natural regeneration', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neuroglia', 'Neurons', 'Outcome', 'Pathologic Neovascularization', 'Pathway interactions', 'Patients', 'Pattern', 'Perfusion', 'Phase', 'Phenotype', 'Play', 'Population', 'Proteomics', 'Research Personnel', 'Risk', 'Role', 'Scientist', 'Site', 'Synapses', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Training', 'Vascular Dementia', 'Vascular Diseases', 'Veterans', 'angiogenesis', 'base', 'biomedical informatics', 'cerebrovascular biology', 'clinical phenotype', 'cognitive testing', 'cohort', 'disorder subtype', 'drug development', 'endophenotype', 'exosome', 'hypoperfusion', 'molecular marker', 'multidimensional data', 'neuroinflammation', 'neurovascular', 'novel', 'novel strategies', 'phenotypic biomarker', 'precision medicine', 'predictive signature', 'prospective', 'proteostasis', 'resilience', 'retinal imaging', 'tau Proteins', 'tool', 'unsupervised learning', 'vascular cognitive impairment and dementia']",NIA,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",P30,2020,298759,-0.02580212017430601
"Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease. ABSTRACT More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease (LD). While the CDC conventional standard two-tier (CSTT) approach for serodiagnosis of LD has worked relatively well when used as recommended, there is plenty of room for improvement. Of a number of weaknesses associated with the supplemental immunoblot of the CSTT the most significant is low reproducibility due to the subjective visual interpretation of results. To overcome these weaknesses the CDC recently updated its recommendations based on a modified STT (MSTT) in that a second EIA can replace the immunoblot. The major goal of this project is to develop an objective, quantitative, multiplex EIA that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens to build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity. The novelty of this study relies on: 1) evaluation of B. burgdorferi antigen-specific antibody isotypes and IgG subclasses that can be correlated with Lyme disease stage; and 2) development of new diagnostic tools using machine learning techniques to train and integrate all data and produce an objective result to discriminate early Lyme from early disseminated/late Lyme disease. We expect this Phase I SBIR to allow us to develop a new EIA for serodiagnosis of Lyme disease (isoEIAplex-Ld) and to further an ongoing collaboration with DCN diagnostics for the adaptation of our biomarkers to a new rapid Lateral Flow Assay (see Letter of Support) for a follow up Phase II SBIR . NARRATIVE More than 3 million tests are performed each year to support the laboratory diagnosis of human Lyme disease. While the CDC conventional standard two-tier approach for serodiagnosis of Lyme disease has worked relatively well when used as recommended, there is plenty of room for improvement. We propose to develop an objective multiplex enzyme immunoassay that can detect four antibody isotypes (IgM/D/G/A) and all four IgG subclasses (IgG1/2/3/4) to leverage acquisition of simultaneous antibody profile information on multiple B. burgdorferi antigens and build an assay that can discriminate Lyme disease stage with increased overall sensitivity without incurring in loss of specificity.",Antibody isotyping for discrimination of disease stage and diagnosis of early Lyme disease.,10080461,R43AI155211,"['Acute', 'Acute Disease', 'Affinity', 'Antibodies', 'Antibody Response', 'Antigens', 'Arthritis', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Borrelia burgdorferi', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Collaborations', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Specificity', 'Discrimination', 'Disease', 'Early Diagnosis', 'Enzyme Immunoassay', 'Evaluation', 'GTP-Binding Protein alpha Subunits, Gs', 'Genetic Recombination', 'Goals', 'Grant', 'High Prevalence', 'Human', 'IgA1', 'IgA2', 'IgE', 'IgG1', 'IgG2', 'IgG3', 'IgG4', 'Immune response', 'Immunodominant Antigens', 'Immunoglobulin A', 'Immunoglobulin D', 'Immunoglobulin G', 'Immunoglobulin Isotypes', 'Immunoglobulin M', 'Immunoglobulins', 'Infection', 'Iowa', 'Laboratories', 'Laboratory Diagnosis', 'Lateral', 'Lesion', 'Letters', 'Licensing', 'Lyme Arthritis', 'Lyme Disease', 'Machine Learning', 'OspC protein', 'Patients', 'Peptidoglycan', 'Performance', 'Phase', 'Proteins', 'ROC Curve', 'Recommendation', 'Reproducibility', 'Research', 'Serum', 'Small Business Innovation Research Grant', 'Specificity', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Update', 'V(D)J Recombination', 'Visual', 'Work', 'antigen binding', 'base', 'commercialization', 'disease diagnosis', 'erythema migrans', 'follow-up', 'improved', 'novel diagnostics', 'pathogen', 'tool']",NIAID,"IMMUNO TECHNOLOGIES, INC.",R43,2020,298123,-0.023159151295908162
"Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident Summary Following a large scale radiological or nuclear event, hundreds of thousands of people may be exposed to ionizing radiation/s and require subsequent dose-dependent medical management. It will be crucial to collect and analyze human biofluids (such as blood, urine, saliva) as soon as possible within the first week for accurate dose prediction and early triage decision. There is a need for FDA-approved in vitro diagnostic high-throughput biodosimetry devices with the ability to determine past radiation exposure with precision and accuracy. At the Center for High Throughput Radiation Biodosimetry, the Columbia University Center for Medical Countermeasures against Radiation (CMCR), we have developed FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system, to measure radiation-responsive proteins in human peripheral blood samples for retrospective estimation of radiation dose. The protein panel also includes biomarkers for blood leukocyte subtypes to reflect hematological sensitivity and injury. The FAST- DOSE assay system is intended as an in vitro diagnostic device (IVD) as defined by 21 CFR 809.3. The platform uses a commercial imaging flow cytometry system (ImageStream®X) and associated Image Data Exploration and Analysis Software (IDEAS®) to rapidly quantify changes in biomarker expression levels within specific cellular structures using fluorescent imagery and algorithms for estimation of absorbed dose. The studies planned here are designed to develop and optimize our FAST-DOSE assay system to accurately estimate absorbed dose and assess hematopoietic injury in human lymphocytes after ionizing irradiation. The first objective is to build on our current biomarker validation data for early engagement with the FDA via the pre-submission process. We have used the human ex vivo model and humanized mouse (Hu-NSG) and non- human primate (NHP) models to validate biomarker expression and radiosensitivity in blood leukocytes after acute ionizing radiation exposure. The Specific Aims proposed here are designed to: optimize the assay protocol and identify biomarker dose/time kinetics for accurate dose predictions in vitro and test 1) inter-donor variation, 2) intra-donor variation and 3) inter-laboratory variability (Aim 1); test the effect of specific confounders: age and sex, inheritance with germline BRCA1/2 pathogenic variant, and inflammation and trauma on the biomarker response, before and after irradiation (Aim 2); measure biomarker levels and time kinetics in vivo and correlate with hematopoietic injury, based on peripheral blood leukocyte counts, and stem and progenitor cell levels in the bone marrow of Hu-NSG mice (Aim 3) and, develop mathematical models (using machine learning and regression techniques) to select the best FAST-DOSE biomarkers and their combinations for generating dose predictions based on the ex vivo and in vivo dose response of these biomarkers (Aim 4). Our vision for future development is to develop a more simplified, faster rapid FAST-DOSE assay system whereby the biomarkers could be developed and transitioned for use in a point-of-care (POC) device. NARRATIVE We have developed a high-throughput biodosimetry device, the FAST-DOSE (Fluorescent Automated Screening Tool for Dosimetry) assay system to measure radiation-responsive proteins in human blood leukocytes for retrospective estimation of radiation dose. Studies are designed to validate and test the performance of the blood protein biomarker panel to accurately predict absorbed dose after ionizing radiation exposure. We will correlate biomarker expression levels and time kinetics with hematopoietic injury, based on peripheral blood leukocyte counts and bone marrow toxicity in humanized mice.","Development of FAST-DOSE assay system for the rapid assessment of acute radiation exposure, individual radiosensitivity and injury in victims for a large-scale radiological incident",9870417,U01AI148309,"['Academic Medical Centers', 'Acute', 'Age', 'Algorithms', 'BRCA1 gene', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Blood', 'Blood Proteins', 'Blood specimen', 'Bone Marrow', 'Burn injury', 'Cell Culture Techniques', 'Cellular Structures', 'Computer software', 'Confidence Intervals', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Dose', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Fluorescence', 'Future', 'Gold', 'Hematology', 'Hematopoietic', 'Human', 'Image', 'Imagery', 'Immune', 'Immunoassay', 'In Vitro', 'Individual', 'Industrial Accidents', 'Inflammation', 'Inherited', 'Injury', 'Ionizing radiation', 'Ions', 'Kinetics', 'Laboratories', 'Leukocytes', 'Linear Regressions', 'Lymphocyte', 'Machine Learning', 'Mass Screening', 'Measures', 'Medical', 'Medical center', 'Modeling', 'Mus', 'Noise', 'Nuclear Accidents', 'Pathogenicity', 'Patients', 'Performance', 'Physiological', 'Population', 'Process', 'Proteins', 'Protocols documentation', 'Radiation', 'Radiation Accidents', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation exposure', 'Reaction Time', 'Reproducibility', 'Research Design', 'Roentgen Rays', 'Saliva', 'Screening procedure', 'Seeds', 'Surface Antigens', 'System', 'Techniques', 'Testing', 'Time', 'Toxic effect', 'Trauma', 'Triage', 'Uncertainty', 'Urine', 'Variant', 'Vision', 'White Blood Cell Count procedure', 'base', 'biodosimetry', 'biomarker panel', 'biomarker performance', 'biomarker validation', 'blood damage', 'data exploration', 'design', 'dirty bomb', 'dosimetry', 'humanized mouse', 'in vitro testing', 'in vivo', 'irradiation', 'machine learning algorithm', 'mathematical model', 'medical countermeasure', 'micronucleus', 'nonhuman primate', 'nonlinear regression', 'performance tests', 'peripheral blood', 'point of care', 'predicting response', 'predictive modeling', 'protein biomarkers', 'response', 'response biomarker', 'sex', 'stem', 'stem cells']",NIAID,COLUMBIA UNIVERSITY HEALTH SCIENCES,U01,2020,485237,-0.015242954707268596
"Open Data-driven Infrastructure for Building Biomolecular Force Field for Predictive Biophysics and Drug Design PROJECT SUMMARY/ABSTRACT Molecular simulation is a powerful tool to predict the properties of biomolecules, interpret biophysical experiments, and design small molecules or biomolecules with therapeutic utility. However, a number of obstacles have impeded the development of quantitative, cloud-scale research workﬂows involving biomolecular simulation. Two main ob- stacles are the insufﬁcient accuracy of current atomistic models for biomolecules and small molecule therapeutics and the lack of interoperability in simulation toolchains used in both academic and industrial biomolecular research. Our original R01, “Open Data-driven Infrastructure for Building Biomolecular Force Fields for Predictive Bio- physics and Drug Design,” seeks to solve the ﬁrst problem. It helps fund our effort, the Open Force Field Initiative (https://openforceﬁeld.org) to develop open, extensible, and shared software and data infrastructure, implementing statistically robust methods of parameterizing force ﬁelds and choosing new force ﬁelds in a statistically sound manner. This work is designed to create not just a new generation of force ﬁelds, but an open technology to continue advancing force ﬁeld science. However, even with improved molecular models, putting together complete workﬂows of biomolecular simulations involves interfacing substantial numbers of different tools. However the majority of the existing molecular simulation workﬂows are mutually incompatible, with differing representations of the molecular models. The Open Force Field Initiative effort already includes the development of molecular data structures that we can ex- port into existing molecular simulation tools. We propose to extend the existing scope of our R01 to create an extensible common molecular simulation representation and translators to and from this representation. Such a set of tools will immediately make it signiﬁcantly easier to combine the disparate workﬂows developed for different sets of molecular simulation tools. Researchers will be able to set up and build the biophysical simulations using their usual tools, but run and analyze them with currently incompatible tools, enabling better matching of computational resources and methods to problems. It will help avoid trapping in a single software framework, and enable combinations of functionalities previously impossible without substantial developer time and effort. We will (Aim 1) work with partners to generalize our modular, extensible object model for representing parameterized biomolecular systems in a manner that accommodates the force ﬁeld terms currently supported by most popular biomolecular simulation packages. We will engineer it to be extensible to advanced interaction forms, such as polarizability and other multibody terms, and machine learning models for intermolecular forces. We will (Aim 2): enable easy conversion between components of molecular simulation workﬂows by allowing other molecular simulation packages to easily store their representations in this data model, developing converters that can import/export this object model to multiple popular ﬁle formats, focusing initially on OpenMM, AMBER, CHARMM, and GROMACS. We will demonstrate the utility of this interface in cloud-ready workﬂows. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life carry out their functions and to design new medications. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms. This supplement will make it much easier for molecular simulation workﬂows to interoperate with each other in large-scale workﬂows.",Open Data-driven Infrastructure for Building Biomolecular Force Field for Predictive Biophysics and Drug Design,10166314,R01GM132386,"['Affinity', 'Binding', 'Biophysics', 'COVID-19', 'Collaborations', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'DNA', 'Development', 'Drug Design', 'Ecosystem', 'Engineering', 'Funding', 'Generations', 'Human', 'Individual', 'Industrialization', 'Infrastructure', 'Language', 'Learning', 'Libraries', 'Life', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Motion', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Problem Solving', 'Property', 'Proteins', 'Pythons', 'RNA', 'Readability', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Scientist', 'Software Framework', 'System', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Work', 'Writing', 'biomaterial interface', 'computing resources', 'data infrastructure', 'data modeling', 'design', 'experimental study', 'file format', 'improved', 'interoperability', 'molecular modeling', 'open data', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'sound', 'structured data', 'tool']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,225000,-0.030455530508069907
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10052188,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'combat', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2020,347094,-0.01454874836931124
"Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment PROJECT SUMMARY/ABSTRACT With the introduction of many novel techniques to minimize radiation dose in CT, there is still a large variation in terms of radiation dose levels prescribed in CT exams and therefore a large variation of diagnostic performance. Some patients may receive higher dose than necessary. Some may be under-dosed and mis- diagnosed as a result of insufficient image quality. In order to determine the appropriate amount of radiation dose reduction in each exam, accurate quantification of diagnostic performance is needed so that the dose reduction can be achieved without sacrificing important diagnostic information. However, currently there is a lack of efficient and quantitative tools for objective assessment of diagnostic performance, particularly for many of the novel dose reduction methods involving non-linear processing of the data such as iterative reconstruction and deep-learning-based noise reduction methods. The specific goal of this application is to disseminate a highly automated solution, CT Protocol optimization (CTPro) software, to a wide CT community. This quantitative tool provides an efficient implementation of diagnostic performance assessment and CT radiation dose optimization. This tool is based on channelized Hotelling observer (CHO), which itself was developed decades ago to mimic human observer visual responses in signal detection tasks. However, the use of CHO in clinical CT is quite limited because of a lack of rigorous validation and efficient and robust implementation in practice. We were the first to demonstrate its correlation with human observer performance in low-contrast detection, classification and localization tasks in clinical CT. The main objective of the current proposal is to optimize this tool for simplicity and robustness, and disseminate it to CT researchers and clinical users, which will be accomplished through 3 specific aims: Aim 1: Optimize CTPro for simplicity, robustness, and generalizability. Aim 2: Develop an open-source web-based platform for software dissemination. Aim 3: Build use cases and disseminate CTPro. The proposed work is significant because the software tool will allow any CT users and researchers to perform CT radiation dose optimization and diagnostic performance evaluation in an efficient, quantitative, and objective manner. This work is innovative in that the automated tool will use quantitative measures of diagnostic performance to systematically guide the complex task of CT dose optimization, moving beyond traditional metrics that are inappropriate for many novel dose reduction techniques. The software tool, once widely employed, will facilitate a paradigm shift in how dose optimization and the evaluation of dose reduction techniques are performed, and will allow a more rapid and consistent adoption of dose reduction technology into clinical practice, which will benefit millions of CT patients. PROJECT NARRATIVE There has been a lack of quantitative tools for efficient and objective assessment of diagnostic performance in CT, which is the reason why inappropriate radiation dose is frequently used in CT exams, resulting in unnecessarily high radiation exposure to patients or lose of important diagnostic information. The purpose of this project is to disseminate a highly automated solution to a wide CT community for efficient CT radiation dose optimization. If successful, appropriate amount of radiation can be prescribed for millions of CT patients at any facility, while maintaining the level of diagnostic information required for high quality patient care.",Dissemination of a Software Platform for Efficient CT Radiation Dose Optimization and Diagnostic Performance Assessment,10019348,U24EB028936,"['Address', 'Adoption', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Dose', 'Educational workshop', 'Electronic Mail', 'Encapsulated', 'Ensure', 'Evaluation', 'Exposure to', 'Funding', 'Goals', 'Human', 'Image', 'Imaging Phantoms', 'Knowledge', 'Laboratories', 'Lesion', 'Libraries', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Newsletter', 'Noise', 'Online Systems', 'Patient Care', 'Patients', 'Performance', 'Play', 'Privatization', 'Protocols documentation', 'Publications', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Software Tools', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical practice', 'clinical research site', 'computerized data processing', 'deep learning', 'improved', 'innovation', 'interest', 'novel', 'novel diagnostics', 'open source', 'reconstruction', 'response', 'symposium', 'tool', 'validation studies', 'web site']",NIBIB,MAYO CLINIC ROCHESTER,U24,2020,314388,-0.026444684081169328
"Detection and characterization of critical under-immunized hotspots Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots,9887876,R01GM109718,"['Affect', 'Bayesian Method', 'Behavioral Model', 'California', 'Characteristics', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Disease model', 'Economic Burden', 'Economics', 'Epidemic', 'Epidemiology', 'Exhibits', 'Funding', 'Geography', 'Growth', 'Health', 'Health Personnel', 'Herd Immunity', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Individual', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Measles-Mumps-Rubella Vaccine', 'Medical', 'Methodology', 'Methods', 'Minnesota', 'Modeling', 'New Jersey', 'New York', 'Oregon', 'Outcome', 'Pathway interactions', 'Policies', 'Policy Maker', 'Population', 'Population Analysis', 'Privatization', 'Public Health', 'Records', 'Registries', 'Resolution', 'Resource Allocation', 'Resources', 'Risk', 'Scanning', 'Schools', 'Science', 'Source', 'System', 'Systems Analysis', 'Techniques', 'Time', 'Uncertainty', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Washington', 'Work', 'base', 'data mining', 'demographics', 'diverse data', 'economic cost', 'economic outcome', 'health care delivery', 'health disparity', 'health organization', 'improved', 'interest', 'novel', 'novel strategies', 'population based', 'provider networks', 'public health intervention', 'social', 'social media', 'spatiotemporal', 'statistics', 'tool', 'transmission process']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2020,324178,-0.01837044335897864
"Multiscale models of fibrous interface mechanics PROJECT SUMMARY Interfaces between tissues either transfer load (requiring toughness) or provide a smooth surface (requiring low friction). Fibrous interfaces are very effective at transferring load between tissues, e.g., at connective tissue-bone interfaces (“entheses”), peritoneal-mesentery interfaces, interfaces between layers of the vasculature, and the pia mater. These interfaces require toughness to resist high stresses associated with material mismatches. Surgical repair can lead to smooth interfaces becoming fibrous, (e.g., following hernia surgery) or to tough interfaces becoming weak (e.g., following tendon- and ligament-to-bone repair). In older patients with large rotator cuff repairs, for example, where the desired attachment is not reformed, up to 94% of surgical repairs fail. These challenges arise in part because the features that endow fibrous interfaces with toughness are not known. We therefore propose to develop a comprehensive modeling and experimental approach for studying the factors underlying the transition from tough to weak in a fibrous interface. Our previous work motivates the hypothesis that disorder is a key toughening feature of fibrous attachments. We will focus initially on the example of tendon attaching to bone, in which microscale disorder underlies the ordered macroscale, graded transition between the two tissues, as a foundation for studying the general problem of adhesion throughout the body. We predict that disorder enhances energy absorption by distributing failure processes and energy absorption over larger volumes of tissue. We propose this as a fundamental mechanism by which fibrous interfaces in the body transfer load effectively. We will test these ideas through two aims: (1) Identify and model the mechanisms of fibrous attachment toughening ex vivo. We will model and experimentally validate how disorder across length scales toughens the tendon-to-bone attachment. Hierarchical molecular dynamics-to- continuum models, enriched by machine learning, will be validated in vitro, in systems with nanoscale control of mineral distributions, and ex vivo, in tissue samples of fibrous attachments. (2) Identify and model the loss of fibrous attachment toughness due to pathologic settings in vivo using murine rotator cuff tendinopathy models. In both aims, nano- through milli-scale characterization will be performed to define the mechanisms driving mechanical behavior. We will test the hypothesis that pathology- induced changes at multiple length scales will predict changes in failure mode. These models and experiments will test the global hypothesis that energy absorption across hierarchies is a fundamental toughening mechanism by which fibrous interfaces resist injury level loads. Taken together, we believe that these new models of fibrous attachment will enable an understanding of how the order and complexity of fibrous attachments leads to effective attachment of tissues. PROJECT NARRATIVE Tough fibrous interfaces between tissues are a common location of injury and source of pathology, pain and disability. Surgical repairs of interfaces that are desirable proceed in the absence of knowledge of the mechanisms that endow fibrous interfaces with toughness, and unsurprisingly have very high failure rates of up to a nearly unbelievable 94%. By developing and testing the first mathematical models for the toughness of this class of interfaces, we hope to identify the mechanisms of toughening definitively, and more broadly to provide technology that enables design of improved surgical procedures.",Multiscale models of fibrous interface mechanics,10037326,R01AR077793,"['Adhesions', 'Adhesives', 'Animal Model', 'Automobile Driving', 'Behavior', 'Biological Models', 'Bone Regeneration', 'Bone Tissue', 'Botulinum Toxin Type A', 'Brain', 'Characteristics', 'Collagen', 'Collagen Diseases', 'Collagen Fiber', 'Connective Tissue', 'Disease', 'Environment', 'Failure', 'Fiber', 'Foundations', 'Friction', 'Hernia', 'In Vitro', 'Injury', 'Intra-abdominal', 'Knowledge', 'Laparotomy', 'Lead', 'Length', 'Ligaments', 'Location', 'Machine Learning', 'Mechanics', 'Meniscus structure of joint', 'Mesentery', 'Minerals', 'Modeling', 'Modification', 'Mus', 'Musculoskeletal', 'Nature', 'Nervous system structure', 'Operative Surgical Procedures', 'Pain', 'Paralysed', 'Pathologic', 'Pathology', 'Patients', 'Peritoneal', 'Physiological', 'Pia Mater', 'Process', 'Rotator Cuff', 'Running', 'Skin', 'Slide', 'Source', 'Specimen', 'Stress', 'Structure', 'Surface', 'System', 'Technology', 'Tendinopathy', 'Tendon structure', 'Testing', 'Tissue Sample', 'Tissues', 'Work', 'absorption', 'bone', 'cranium', 'crosslink', 'design', 'disability', 'experimental study', 'improved', 'in vivo', 'mathematical model', 'mechanical behavior', 'millimeter', 'molecular dynamics', 'multi-scale modeling', 'nano', 'nanocrystal', 'nanoscale', 'older patient', 'repaired', 'treadmill']",NIAMS,WASHINGTON UNIVERSITY,R01,2020,545403,-0.009748918383507965
"Development of assistive self-care robot technologies for people with disabilities Towards Autonomy in Daily Living: A Formalism for Intelligent Assistive Feeding Systems  Applicant PI, Tapomayukh Bhattacharjee Overview We propose to develop a design space framework and co-design methodology for the development of assistive self-care robot technologies that are informed by the social model of disability. Our model of assistive robots in the domain of self-care considers an individual's social and environmental context, coping processes and other factors that can affect independent functioning. Our design methods utilize embedded sensing to intelligently respond to these con- siderations. We speciﬁcally focus on assistive feeding tasks, proposing a formalism that enables a robotic system to feed a person with upper-extremity disability. Our guiding principle is that human-level interaction is feasible only if the robot itself relies on human-level semantics. We im- plement this principle by relying on data to learn and develop object-dependent control policies and timing models for acquiring and transferring a bite to a user at a proper time. The system's ob- server detects world states and arbitrator invokes different control policies based on these states. The tangible result will be an intelligent assistive feeding robot whose performance can generalize to different activities, adapt to user preferences, and recover from failures. Objectives and Relevance to NIH A design framework for assistive robots would provide for- malisms that let us address the fundamental challenge of designing robots that are responsive to context of use and support assisted self-care in a variety of social settings. We combine method- ologies from human-robot interaction, cognitive science, machine learning, robotics and haptics with user studies and our formalism to address the following research questions: (Q1) Mechanics of Feeding-Control Policies: How can control policies be designed for dexterous non-prehensile manipu- lation of deformable objects such as food? (Q2) Social Aspects of Feeding-Bite Timing: How should an assistive feeding robot decide the right timing for feeding a user? (Q3) Human-in-the-Loop: How can human-directed feedback be added into the loop for an autonomous assistive feeding system?  The proposed work will allow users with upper-arm disabilities to use this system for intelli- gent assistance with daily feeding tasks. This can in turn help them increase their independence and autonomy making eating easier and more enjoyable. While we presently focus on this spe- ciﬁc application, the tools and insights we gain can generalize to the ﬁelds of robotic assistance and human-robot interaction across other activities of daily living and instrumental activities of daily living. Thus, our work is clearly motivated by the intent to improve the quality of health and life of the aging population and is very relevant to the theme of NIH. 1 Towards Autonomy in Daily Living: A Formalism for Intelligent Assistive Feeding Systems  Applicant PI, Tapomayukh Bhattacharjee  The proposed work will allow users with upper-arm disabilities to use this system for intelli- gent assistance with daily feeding tasks, potentially increasing their independence and autonomy making eating easier and more enjoyable. The long-term promise of this research is to have robots in society that are able to seamlessly and ﬂuently perform complex manipulation tasks in dynamic human environments in real homes which could impact individuals with other disabilities as well as able-bodied individuals. Through improved access to independent living and customizing to the unique needs and preferences of users, the results of this project can positively impact mil- lions of people worldwide, especially given the vast variability in our target population by being transformational in the scalability of assistive robotics for self-care. 1",Development of assistive self-care robot technologies for people with disabilities,9907705,F32HD101192,"['Activities of Daily Living', 'Address', 'Affect', 'Aging', 'Bathing', 'Bite', 'Caregiver Burden', 'Caring', 'Child', 'Cognitive Science', 'Communities', 'Complex', 'Cues', 'Custom', 'Data', 'Development', 'Disabled Persons', 'Eating', 'Emotional', 'Environment', 'Expert Systems', 'Failure', 'Family', 'Feedback', 'Food', 'Generations', 'Health', 'Home environment', 'Human', 'Improve Access', 'Independent Living', 'Individual', 'Intelligence', 'Learning', 'Life', 'Machine Learning', 'Mechanics', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Panthera leo', 'Parents', 'Performance', 'Persons', 'Play', 'Policies', 'Population', 'Process', 'Quality of life', 'Research', 'Robot', 'Robotics', 'Role', 'Self Care', 'Semantics', 'Societies', 'Sterile coverings', 'System', 'Target Populations', 'Taxonomy', 'Technology', 'Time', 'Tweens', 'United States National Institutes of Health', 'Upper Extremity', 'Upper arm', 'Work', 'aging population', 'assistive robot', 'base', 'care recipients', 'coping', 'design', 'disability', 'experience', 'experimental study', 'feeding', 'haptics', 'human subject', 'human-in-the-loop', 'human-robot interaction', 'improved', 'insight', 'instrumental activity of daily living', 'intergenerational', 'kinematics', 'patient oriented', 'peer', 'preference', 'robot assistance', 'robotic system', 'social', 'social model', 'tool']",NICHD,UNIVERSITY OF WASHINGTON,F32,2020,65310,-0.03226067242546214
"TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS ABSTRACT There is a growing interest in dietary patterns that capture the overall quality of diet as well as its constituent foods and nutrients. Commonly used dietary patterns are a priori diet score/index based on a set of dietary recommendations for a healthy diet (e.g., Mediterranean diet, Healthy Eating Index) or data-driven dietary patterns (e.g., prudent diet, western diet). Numerous studies have shown that those dietary patterns were related to the risk of chronic diseases such as heart disease, diabetes, and cancer. However, none of these dietary patterns incorporates eating behavior such as when we eat (i.e., eating time) and how often we eat (i.e. eating frequency) during a day. Since the amount of foods and nutrients consumed at one eating occasion influences the food consumption at the subsequent eating occasion and overall intake of the day, eating time and frequency are integral parts of dietary patterns. Furthermore, several lines of evidence consistently suggest that eating time and frequency as well as a meal composition play roles in body weight regulation and metabolic health and also regulate circadian rhythms, all of which may lead to metabolic dysfunctions and ultimately chronic diseases. Given a clear need to expand the dietary patterns framework and close a gap in dietary patterns methodological work, we propose to 1) develop a “temporal” dietary patterns based on temporal distribution of eating time and frequency during a day; and 2) evaluate if the identified temporal dietary patterns are associated with i) overall diet quality and nutrient intakes, ii) adiposity (e.g., BMI, waist circumference), and iii) metabolic biomarkers (e.g., insulin, HOMA-IR, LDL-cholesterol, c-reactive protein). To overcome a limitation that a conventional statistical method cannot capture multidimensional aspects of temporal dietary patterns (e.g., 24-dimensional feature vectors, multivariate dietary intake time-series data), we will use a novel approach combining nutrition and systems science—machine learning method. The Interactive Diet and Activity Tracking in AARP (IDATA) study that repeatedly collected diet, anthropometry, and blood samples from 1,021 men and women, 50-74 years old will be used. During one year, the IDATA study collected 24-hour recalls with clock time for each eating occasion, every other month (total six 24-hour recalls); measured anthropometry three times (baseline and at month 6 and 12); and collected blood twice, 6-month apart. Successful completion of our proposed study will identify temporal dietary patterns that are related to diet quality and metabolic health and validate the utility of temporal dietary patterns as a new tool for future research on diet-health relations and prevention of chronic diseases. NARRATIVE Eating behaviors and its impact on health are complex and multidimensional. The proposed study provides an excellent opportunity to develop new dietary patterns that capture eating behaviors such as when we eat and how often we eat during a day. The findings of the study about healthy eating patterns will also improve dietary recommendations by adding messages on when and how often to eat during a day.",TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS,9830609,R01CA226937,"['Advisory Committees', 'Affect', 'Algorithms', 'Animals', 'Anthropometry', 'Biological Markers', 'Blood', 'Blood specimen', 'Body Weight', 'C-reactive protein', 'Calories', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Circadian Rhythms', 'Complex', 'Consumption', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Diet Habits', 'Dietary Practices', 'Dietary intake', 'Dimensions', 'Eating', 'Eating Behavior', 'Energy Intake', 'Evaluation', 'Fasting', 'Fatty acid glycerol esters', 'Food', 'Frequencies', 'Health', 'Healthy Eating', 'Heart Diseases', 'Hour', 'Human', 'Individual', 'Insulin', 'Intake', 'LDL Cholesterol Lipoproteins', 'Lead', 'Macronutrients Nutrition', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediterranean Diet', 'Metabolic', 'Metabolic dysfunction', 'Metabolic syndrome', 'Methodology', 'Modeling', 'Nutrient', 'Obesity', 'Outcome', 'Pattern', 'Persons', 'Physical activity', 'Play', 'Population', 'Positioning Attribute', 'Prevention', 'Recommendation', 'Regulation', 'Risk', 'Role', 'Science', 'Series', 'Statistical Methods', 'System', 'Techniques', 'Time', 'Waist-Hip Ratio', 'Weight maintenance regimen', 'Woman', 'Work', 'base', 'cardiovascular disorder risk', 'dietary guidelines', 'doubly-labeled water', 'epidemiology study', 'food consumption', 'good diet', 'improved', 'indexing', 'interest', 'machine learning method', 'men', 'novel', 'novel strategies', 'nutrient metabolism', 'nutrition', 'obesity risk', 'prudent diet', 'tool', 'vector', 'waist circumference', 'western diet']",NCI,WASHINGTON UNIVERSITY,R01,2020,396585,-0.013024199089438464
"ShapeWorks in the Cloud Project Summary This application is submitted in response to NOT-OD-20-073 as an administrative supplement to the parent award R01AR076120 titled: ""Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches."" The form (or shape) of anatomies is the clinical language that describes abnormal mor- phologies tied to pathologic functions. Quantifying such subtle morphological shape changes requires parsing the anatomy into a quantitative description that is consistent across the population in question. For more than 100 years, morphometrics has been an indispensable quantitative tool in medical and biological sciences to study anatomical forms. But its representation capacity is limited to linear distances, angles, and areas. Sta- tistical shape modeling (SSM) is the computational extension of classical morphometric techniques to analyze more detailed representations of complex anatomy and their variability within populations The parent award ad- dresses existing roadblocks for the widespread adoption of SSM computational tools in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM) and its associated suite of open-source software tools, ShapeWorks. ShapeWorks enables learning population-level shape representation via automatic dense placement of homologous landmarks on image segmentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread applicability and impact to medicine and biology are hindered by computational barriers that most existing shape modeling packages face. The goal of this supplement award is to provide supplemental support for Aim 3 of the parent award to leverage best practices in software development and advances in cloud computing to enable researchers with limited computational resources and/or large-scale cohorts to build and execute custom SSM workﬂows us- ing remote scalable computational resources. To achieve this goal, we have developed a plan to enhance the design, implementation, and cloud-readiness of ShapeWorks and augmented our scientiﬁc team to add senior, experienced software engineers/developers who have extensive experience in professional programming, code refactoring, and scientiﬁc computing. This award will provide our team with the support necessary to (Aim 1) de- sign ShapeWorks as a collection of modular and reusable services, (Aim 2) decouple ShapeWorks services from explicitly encoded data sources, and (Aim 3) refactor ShapeWorks to scale efﬁciently on the cloud. All software development will be performed in adherence to software engineering practices and design principles, including coding style, documentation, and version control. The proposed efforts will be released as open-source software in a manner consistent with the principles of reproducible research and the practices of open science. Our long- term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein in addition to the parent award will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. The impact and scientiﬁc value of ShapeWorks have been recognized in a range of applications, including psychology, biological phenotyping, car- diology, and orthopedics. If funded, this supplement will provide support to revise, refactor, and redeploy Shape- Works to take advantage of new cloud computing paradigms, to be robust, sustainable, scalable, and accessible to a broader community, and to address the growing need for shape modeling tools to handle large collections of clinical data and to obtain sufﬁcient statistical power for large shape studies.",ShapeWorks in the Cloud,10166337,R01AR076120,"['Address', 'Adherence', 'Administrative Supplement', 'Adoption', 'Anatomy', 'Applied Research', 'Architecture', 'Area', 'Award', 'Biological', 'Biological Sciences', 'Biology', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cloud Computing', 'Cloud Service', 'Code', 'Collection', 'Communication', 'Communities', 'Complex', 'Complex Analysis', 'Computer Models', 'Computer software', 'Computers', 'Coupled', 'Custom', 'Data', 'Data Sources', 'Databases', 'Disabled Persons', 'Documentation', 'Environment', 'Face', 'Funding', 'Goals', 'Image', 'Imagery', 'Language', 'Learning', 'Machine Learning', 'Mathematics', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Morphology', 'Occupations', 'Online Systems', 'Orthopedics', 'Parents', 'Pathologic', 'Phenotype', 'Population', 'Privatization', 'Psychology', 'Readiness', 'Reproducibility', 'Research', 'Research Personnel', 'Running', 'Scientist', 'Services', 'Shapes', 'Software Design', 'Software Engineering', 'Software Tools', 'Source Code', 'Speed', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Work', 'base', 'cohort', 'computational platform', 'computerized tools', 'computing resources', 'data management', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'large datasets', 'model development', 'open data', 'open source', 'particle', 'response', 'scientific computing', 'shape analysis', 'software development', 'statistics', 'tool', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2020,210000,-0.008869722154973107
"A Virtual Coach to Enhance Surgical Training using Human-Centric Modeling and Adaptive Haptic Guidance PROJECT SUMMARY We aim to reduce surgical robotic errors by developing novel technology to coach experienced practitioners by using real-time data-driven predictive models of operator behavior, task difﬁculty, and expertise levels during complex surgical training tasks. This technology could increase the effectiveness of simulation-based training, particularly for practicing clinicians, as the predictive models will inform the design of adaptive and personalized feedback for the surgeon.  Surgical training typically involves didactic learning, skills labs, and practice on live patients. Safety concerns asso- ciated with training on patients has led to signiﬁcant developments in simulation-based technology; however, existing simulators may lack the ability promote mastery of skills for practicing providers. Improved training is important for both the provider and the patient. An estimated 100,000 death per year occur due to preventable medical errors. In robotic surgeries, the majority of patient injuries can be attributed to inexperience and lack of technical competence of the attending surgeon. These errors could potentially be avoided through personalized and adaptive coaching.  In general, robotic systems can sense and adapt to their environment, even act autonomously to complete a task. However, the majority of surgical robots used today are “teleoperated systems"". These systems only perform tasks directly commanded by the human operator, possibly with some scaling or tremor cancellation. There is a missed opportunity to leverage the intelligence of robotic systems to sense and interpret the movements of the surgeon and to enable some form of adaptive feedback for personalized coaching. Our prior work in human-centric modeling could hold the key to the technical challenge of integrating intelligent methods into existing surgical robotic training platforms by better understanding the technical strengths and weaknesses of the practicing surgeon in a data-driven manner.  The long-term goal of this project is to improve surgical training outcomes by developing a personalized and adaptive surgical robotic coach capable of providing meaningful feedback to the practicing provider to optimize learning and skill transfer. The speciﬁc aims of the proposal include: (1) evaluate the ability of human- centric models to characterize surgeon performance using motion and video data, (2) design adaptive haptic or visual guidance cues to provide learners with real-time feedback and to optimize learning, and (3) evaluate the effectiveness of the adaptive technology coach through end-user validation using procedural-speciﬁc training models for general surgery, urology, and gynecologic oncology. This project could signiﬁcantly improve provider training in robotic surgery. The project could also improve provider training for laparoscopic and open surgery as the models used to develop the virtual coach are inherently human-centric and not tied to any speciﬁc surgical tasks or surgical platforms.  Our team is uniquely positioned to achieve success in this project, bringing together experts in surgical robotics, human-centric modeling, machine learning, and advanced surgical training. We have conducted extensive preliminary studies in areas related to this proposal, supporting feasibility of this project. Our integration with the Simulation Center at UTSW will enable translation of successful outcomes of this project into the surgical training and retraining pipeline. PUBLIC HEALTH RELEVANCE Human-generated, preventable errors, particularly those made intra-operatively, can lead to morbidity and mortality for the patient and high costs for the hospital. While simple inanimate trainers have been successfully developed for surgical resident education, there is a lack of simulation-based technology for practicing surgeons. This research leverages novel data-driven methods to quantify how, and how well, a surgeon is performing a task for the long-term goal of developing personalized, adaptive virtual coaches for surgical robotic systems, resulting in better patient outcomes.",A Virtual Coach to Enhance Surgical Training using Human-Centric Modeling and Adaptive Haptic Guidance,10037429,R01EB030125,"['Algorithms', 'Area', 'Behavior', 'Bilateral', 'Cause of Death', 'Cessation of life', 'Clinical', 'Clinical Trials', 'Cognitive', 'Competence', 'Complex', 'Coupled', 'Credentialing', 'Cues', 'Data', 'Development', 'Devices', 'Discipline of obstetrics', 'Education', 'Educational Curriculum', 'Effectiveness', 'Environment', 'Evaluation', 'Feedback', 'Freedom', 'Funding Mechanisms', 'Future', 'Goals', 'Gynecologic Oncology', 'Gynecology', 'Hand', 'Hospital Costs', 'Human', 'Individual', 'Injury', 'Intelligence', 'Intuition', 'Lead', 'Learning', 'Learning Skill', 'Machine Learning', 'Measures', 'Medical Errors', 'Medical center', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Motion', 'Movement', 'Nature', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physiological', 'Positioning Attribute', 'Procedures', 'Provider', 'Research', 'Resources', 'Robot', 'Robotics', 'Rotation', 'Safety', 'Shapes', 'Standardization', 'Surgeon', 'Surgical Error', 'Surgical Models', 'Surveys', 'System', 'Tactile', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Model', 'Training', 'Transferable Skills', 'Translations', 'Tremor', 'United States', 'Urinary Diversion', 'Urology', 'Validation', 'Visual', 'Work', 'Wrist', 'base', 'design', 'effectiveness evaluation', 'emotional factor', 'experience', 'experimental study', 'haptic feedback', 'haptics', 'human model', 'improved', 'kinematics', 'medical specialties', 'mortality', 'new technology', 'novel', 'predictive modeling', 'preference', 'prevent', 'public health relevance', 'recruit', 'robotic system', 'robotic training', 'simulation', 'skills', 'success', 'virtual coach', 'virtual reality', 'visual feedback']",NIBIB,"UNIVERSITY OF TEXAS, AUSTIN",R01,2020,327275,-0.009471434701975
"Automatic Quantification and Labeling of Cerebral Microbleeds, Oxygen Saturation and Sources of Abnormal Susceptibility ABSTRACT The detection, localization and quantification of cerebral microbleeds (CMBs) plays an important role in diagnosing and establishing appropriate treatment plans in neurodegenerative diseases specifically in vascular dementia (VaD). To date, evaluating CMBs is time consuming, inaccurate and sometimes not possible. We propose to mitigate these problems by developing our software, “qSPIN”, that will provide fast and easy-to-use methods for: 1) automatic identification of CMBs and veins, 2) automatic quantification of CMBs, 3) automatic quantification of oxygen saturation in veins, and 4) creation of a user-friendly software for the practicing radiologist. Recent developments in MRI have provided a new means by which to study the role of CMBs and venous abnormalities in neurological diseases such as Alzheimer’s Disease (AD), VaD, stroke and traumatic brain injury (TBI). Susceptibility weighted imaging (SWI) has proven to be a powerful tool by which to detect CMBs and quantitative susceptibility mapping (QSM) can be used to measure changes in oxygen saturation. Knowing how many CMBs there are can predict the onset of VaD, determine whether anti-platelet therapy in stroke should be used, and correlate with neuropsychological outcome for patients with TBI. Our recent version of multi-echo SWI makes it possible to obtain both an arteriogram and a venogram simultaneously. Oxygen saturation can also be used to monitor perfusion changes and extend the window of treatment in stroke.  Currently, most radiologists and technologists do not have time to perform such detailed quantitative processing and thus it is not being done clinically. Our qSPIN software will provide this quantitative data. With the number, size, and location of CMBs or venous abnormalities, a better diagnosis would be possible. Our group is uniquely positioned to address this problem having developed many of these techniques. The novelty of our approach is the marriage of SWI, QSM, STAGE and deep learning techniques to detect these vascular and functional abnormalities. To accomplish the goals of this proposal, we will develop user friendly software that incorporates all imaging information from SWI and QSM to label CMBs. We will also provide the location of the CMBs in Talairach coordinates using a template dataset. In the end, we will have a complete picture of the prevalence of CMBs, abnormal oxygen saturation and their locations in patients with neurodegenerative disease that will improve diagnosis and potentially change their treatment. PROJECT NARRATIVE There is a huge demand today for a comprehensive analysis of diseases with cerebral microbleeds, abnormal oxygen saturation and thrombosis such as vascular dementia. The quantification of these features will have major ramifications for the diagnosis and treatment of dementia as well hypertension, stroke and traumatic brain injury all of which can lead to dementia. Therefore, our major objective in this application is to design and develop advanced image processing software that can rapidly and accurately identify and quantify the presence of cerebral microbleeds and changes in oxygen saturation in dementia and related diseases.","Automatic Quantification and Labeling of Cerebral Microbleeds, Oxygen Saturation and Sources of Abnormal Susceptibility",10026456,R44HL145826,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Arteriogram', 'Arteriosclerosis', 'Basal Ganglia', 'Blood Vessels', 'Brain', 'Brain hemorrhage', 'Businesses', 'Cerebral Amyloid Angiopathy', 'Cerebral hemisphere hemorrhage', 'Clinical', 'Computer software', 'Consumption', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Diagnosis', 'Diffuse Axonal Injury', 'Disease', 'Feedback', 'Goals', 'Hemorrhage', 'Hypertension', 'Image', 'Image Analysis', 'Impaired cognition', 'Infarction', 'Iron', 'Label', 'Lead', 'Link', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Magnetism', 'Maps', 'Marriage', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Multiple Sclerosis', 'Neurodegenerative Disorders', 'Neuropsychology', 'Outcome', 'Oxygen', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Perfusion', 'Phase', 'Play', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Protocols documentation', 'Protons', 'Published Comment', 'Reporting', 'Role', 'Sampling', 'Site', 'Source', 'Spatial Distribution', 'Stroke', 'TBI Patients', 'Techniques', 'Testing', 'Thalamic structure', 'Thrombosis', 'Time', 'Training', 'Traumatic Brain Injury', 'Vascular Dementia', 'Veins', 'Venous', 'base', 'cerebral microbleeds', 'cerebral vein', 'computerized data processing', 'contrast imaging', 'deep learning', 'density', 'design', 'image processing', 'improved', 'innovation', 'mild traumatic brain injury', 'nervous system disorder', 'neurovascular', 'prototype', 'quantitative imaging', 'radiologist', 'stroke risk', 'tool', 'treatment planning', 'user friendly software']",NHLBI,"MAGNETIC RESONANCE INNOVATIONS, INC.",R44,2020,667050,-0.07922438522210506
"Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Efforts to include behavioral measures in large-scale studies as envisioned by precision medicine are hampered by the time and expertise required. Paper-and-pencil tests currently dominating clinical assessment and neuropsychological testing are plainly unfeasible. The NIH Toolbox contains many computerized tests and clinical assessment tools varying in feasibility. Unique in the Toolbox is the Penn Computerized Neurocognitive Battery (CNB), which contains 14 tests that take one hour to administer. CNB has been validated with functional neuroimaging and in multiple normative and clinical populations across the lifespan worldwide, and is freely available for research. Clinical assessment tools are usually devoted to specific disorders, and scales vary in their concentration on symptoms that are disorder specific. We have developed a broad assessment tool (GOASSESS), which currently takes about one hour to administer. These instruments were constructed, optimized and validated with classical psychometric test theory (CTT), and are efficient as CTT allows. However, genomic studies require even more time-efficient tools that can be applied massively.  Novel approaches, based on item response theory (IRT) can vastly enhance efficiency of testing and clinical assessment. IRT shifts the emphasis from the test to the items composing it by estimating item parameters such as “difficulty” and “discrimination” within ranges of general trait levels. IRT helps shorten the length of administration without compromising data quality, and for many domains leads to computer adaptive testing (CAT) that further optimizes tests to individual abilities. We propose to develop and validate adaptive versions of the CNB and GOASSESS, resulting in a neurocognitive and clinical screener that, using machine learning tools, will be continually optimized, becoming shorter and more precise as it is deployed. The tool will be in the Toolbox available in the public domain. We have item-level information to perform IRT analyses on existing data and use this information to develop CAT implementations and generate item pools for adaptive testing. Our Specific Aims are: 1. Use available itemwise data on the Penn CNB and the GOASSESS and add new tests and items to generate item pools for extending scope while abbreviating tests using IRT-CAT and other methods. The current item pool will be augmented to allow large selection of items during CAT administration and add clinical items to GOASSESS. New items will be calibrated through crowdsourcing. 2. Produce a modular CAT version of a neurocognitive and clinical assessment battery that covers major RDoC domains and a full range of psychiatric symptoms. We have implemented this procedure on some CNB tests and clinical scales and will apply similar procedures to remaining and new tests as appropriate. 3. Validate the CAT version in 100 individuals with psychosis spectrum disorders (PS), 100 with depression/anxiety disorders (DA), and 100 healthy controls (HC). We will use this dataset to implement and test data mining algorithms that optimize prediction of specific outcomes. All tests, algorithms and normative data will be in the toolbox. Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan Narrative Large scale genomic studies are done in the context of precision medicine, and for this effort to benefit neuropsychiatric disorders such studies should include behavioral measures of clinical symptoms and neurocognitive performance. Current tools are based on classical psychometric theory, and we propose to apply novel approaches of item response theory to develop a time-efficient adaptive tool for assessing broad neurocognitive functioning and psychopathology. The tool will be available in the public domain (NIH Toolbox) and will facilitate incorporation of psychiatric disorders into the precision medicine initiative.",Creating an adaptive screening tool for detecting neurocognitive deficits and psychopathology across the lifespan,9920211,R01MH117014,"['Algorithms', 'Anxiety', 'Anxiety Disorders', 'Assessment tool', 'Behavior', 'Biological Markers', 'Calibration', 'Characteristics', 'Classification', 'Clinical', 'Clinical Assessment Tool', 'Clinical assessments', 'Cognitive', 'Collection', 'Complex', 'Computers', 'Data', 'Data Compromising', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Discrimination', 'Disease', 'Environmental Risk Factor', 'Feedback', 'Female', 'Genomics', 'Hour', 'Individual', 'Internet', 'Internet of Things', 'Intervention Studies', 'Length', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Medicine', 'Mental Depression', 'Mental disorders', 'Methods', 'Molecular Genetics', 'Moods', 'Neurocognitive', 'Neurocognitive Deficit', 'Neuropsychological Tests', 'Neurosciences', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Phenotype', 'Population', 'Precision Medicine Initiative', 'Preparation', 'Preventive Intervention', 'Procedures', 'Psychiatry', 'Psychometrics', 'Psychopathology', 'Psychotic Disorders', 'Public Domains', 'Research', 'Research Domain Criteria', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Severities', 'Speed', 'Structure', 'Symptoms', 'Tablets', 'Testing', 'Time', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'base', 'behavior measurement', 'cognitive performance', 'computerized', 'crowdsourcing', 'data mining', 'data quality', 'digital', 'genomic variation', 'improved', 'individualized prevention', 'instrument', 'male', 'mobile computing', 'neuroimaging', 'neuropsychiatric disorder', 'novel', 'novel strategies', 'open source', 'precision medicine', 'protective factors', 'psychiatric symptom', 'response', 'symptom cluster', 'theories', 'tool', 'trait', 'validation studies']",NIMH,UNIVERSITY OF PENNSYLVANIA,R01,2020,709525,-0.017054325036819876
"Evaluation of multiple medication exposures concurrently using a novel algorithm PROJECT SUMMARY The development of large observational health databases (OHD) has expanded the data available for analysis by pharmacoepidemiology research. The efficiency of these studies may be improved by simultaneously studying the association of multiple medications with a disease of interest. Unfortunately, prior research has demonstrated that it is difficult to distinguish true-positive from false-positive results when studying multiple exposures simultaneously, thus limiting the conclusions drawn from these types of studies and representing a major gap in the field. The objective of this proposal, which is the first step in achieving the applicant's long- term goal of improving the diagnosis and treatment of gastrointestinal diseases using insights derived from OHD, is to evaluate and validate medication class enrichment analysis (MCEA), a novel set-based signal-to- noise enrichment algorithm developed by the applicant to analyze multiple exposures from OHD with high sensitivity and specificity. The central hypothesis of this proposal is that MCEA has equal sensitivity and greater specificity compared to logistic regression, the most widely used analytic method for OHD, for identifying true associations between medications and clinical outcomes. The applicant will complete the following two interrelated specific aims to test the hypothesis: Aim 1 – to calculate the sensitivity and specificity of medication class enrichment analysis (MCEA) and logistic regression (LR) for identifying medication associations with Clostridium difficile infection (CDI) and Aim 2 – to calculate the sensitivity and specificity of MCEA and LR for identifying medication associations with gastrointestinal hemorrhage (GIH). The rationale for these aims is that by reproducing known medication-disease associations without false positives, MCEA can be used to identify novel pharmacologic associations with gastrointestinal diseases in future studies. The expected outcome for the proposed research is that it will demonstrate MCEA as a valid method for pharmacoepidemiology research, opening new research opportunities for the study of multi-exposure OHD. These new research opportunities may lead to more rapid identification of potential pharmacologic causes of emerging diseases and discovery of unanticipated beneficial medication effects, allowing such medications to be repurposed for new indications. To attain the expected outcome, the applicant will complete additional coursework that builds on his Master of Science in Clinical Epidemiology to learn computational biology, machine learning, and econometrics techniques. With the support of this grant and his institution, he will also directly apply these techniques to pharmacoepidemiology applications under the close mentorship of a carefully selected team of faculty with extensive experience in gastroenterology, pharmacoepidemiology, medical informatics, and mentoring prior K-award grant recipients. Through these activities, the applicant will develop the skills necessary to obtain NIH R01-level funding and become a leader in developing novel techniques for application to the epidemiologic study of gastrointestinal diseases. PROJECT NARRATIVE Traditionally, research studying medications associated with diseases are limited to analyzing one medication at a time. This novel proposal will validate medication class enrichment analysis, a recently developed algorithm to study multiple medications simultaneously for association with a disease of interest. Validation of this method will allow researchers to use existing medical databases to more rapidly identify potential medication causes of emerging diseases and identify medications with unanticipated beneficial effects, allowing such medications to be repurposed for new indications.",Evaluation of multiple medication exposures concurrently using a novel algorithm,9853783,K08DK119475,"['Address', 'Algorithms', 'Aminoglycosides', 'Antibiotics', 'Anticoagulants', 'Antiplatelet Drugs', 'Big Data to Knowledge', 'Biological', 'Carbapenems', 'Case-Control Studies', 'Cephalosporins', 'Characteristics', 'Charge', 'Clinical', 'Clinical Research', 'Clostridium difficile', 'Computational Biology', 'Computer software', 'Data', 'Databases', 'Development', 'Development Plans', 'Diagnosis', 'Digestive System Disorders', 'Disease', 'Electronic Health Record', 'Epidemiologic Methods', 'Evaluation', 'Faculty', 'Fluoroquinolones', 'Funding', 'Future', 'Gastroenterology', 'Gastrointestinal Diseases', 'Gastrointestinal Hemorrhage', 'Generations', 'Genomics', 'Goals', 'Grant', 'Health', 'Infection', 'Informatics', 'Inpatients', 'Institution', 'K-Series Research Career Programs', 'Lead', 'Learning', 'Logistic Regressions', 'Machine Learning', 'Master of Science', 'Medical', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Noise', 'Non-Steroidal Anti-Inflammatory Agents', 'Outcome', 'Penicillins', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacology', 'Research', 'Research Design', 'Research Personnel', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Techniques', 'Testing', 'Time', 'United Kingdom', 'United States National Institutes of Health', 'Validation', 'Veterans', 'analytical method', 'base', 'beta-Lactams', 'career development', 'clinical epidemiology', 'econometrics', 'epidemiology study', 'experience', 'improved', 'inhibitor/antagonist', 'insight', 'interest', 'novel', 'research study', 'simulation', 'skills', 'usability']",NIDDK,UNIVERSITY OF PENNSYLVANIA,K08,2020,167900,-0.026908611274504782
"A knowledge graph framework for automated gating analysis of cytometry data Project Summary / Abstract Flow and mass cytometry provide multiparametric single-cell data critical for understanding the cellular heterogeneity in various biological systems. Modern polychromatic flow cytometers simultaneously measure about 16 parameters routinely. The next-generation mass cytometry (CyTOF) technology allows for the simultaneous measurement of 50 or more parameters. Even as the cytometry technology is rapidly advancing, approaches for analyzing such complex data remain inadequate. The widely-used manual gating analysis is knowledge-driven and easy-to- interpret, but it is subjective, labor-intensive, and not scalable to handle the increasing complexity of the data. Recent developments of automated data-driven algorithms are able to address the issues of manual gating, but the results from data-driven algorithms are often not intuitive for biology experts to interpret. These limitations create a critical bottleneck for flow and mass cytometry analysis. The overall objective of this application is to develop a novel framework that combines both knowledge-driven and data-driven approaches to achieve automated gating analysis of flow cytometry and CyTOF data. The specific aims are: (1) build knowledge graphs to capture existing knowledge of manual gating analysis, (2) develop algorithms for automated gating analysis, and (3) validate the knowledge graph framework using large-scale studies in ImmPort. The proposed research is significant because it will enable efficient and reproducible gating analysis and provide visualizations that are easy-to-interpret, both of which are critically important to the research community. Such contributions will fundamentally impact single-cell analysis of cellular heterogeneity in diverse fields including immunology, infectious diseases, cancer, AIDS, among others. Project Narrative The proposed research is relevant to public health because it is expected to develop novel computational methods for automated analysis and interpretation of single-cell analysis by flow and mass cytometry. Such contributions will impact single-cell analysis of cellular heterogeneity in diverse fields such as immunology, infectious diseases, cancer, AIDS, among others.",A knowledge graph framework for automated gating analysis of cytometry data,10026829,UH2AI153028,"['Acquired Immunodeficiency Syndrome', 'Address', 'Adopted', 'Adoption', 'Algorithm Design', 'Algorithmic Analysis', 'Algorithms', 'Biological', 'Biological Sciences', 'Biology', 'Cells', 'Clinical', 'Clinical Research', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Set', 'Database and Analysis Portal', 'Development', 'Dimensions', 'Flow Cytometry', 'Graph', 'Heterogeneity', 'Human', 'Immune system', 'Immunology', 'Individual', 'Intuition', 'Knowledge', 'Literature', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Modeling', 'Modernization', 'Mus', 'Online Systems', 'Outcome', 'Public Health', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Technology', 'Thinking', 'Visualization', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'cell type', 'complex data ', 'data and analysis portal', 'data resource', 'deep learning', 'design', 'diverse data', 'graphical user interface', 'high dimensionality', 'informatics tool', 'knowledge graph', 'multidimensional data', 'next generation', 'novel', 'protein biomarkers', 'single cell analysis', 'stem', 'user-friendly', 'web based interface']",NIAID,GEORGIA INSTITUTE OF TECHNOLOGY,UH2,2020,211738,-0.018374776043998675
"CHABMAP (Cyanobacterial Harmful Algal Bloom Mapping and Analyses Platform) technology automates the quantification of toxic CyanoHABs exposure epochs for any waterbody. Specific Aim #1: Operationalize spatio-temporal CyanoHAB exposure epoch metrics  • Fuse multi-scale and disparate satellite remote sensing platforms and automate retrievals over  space and time to derive CyanoHAB exposure metrics. We will build enterprise software to fully  automate the harmonization and fusion of NASA’s Landsat-8 OLI and ESA’s Sentinel-2 and  Sentinel-3 satellite platforms to provide long-term (1984-present) moderate spatial resolution  (30meter pixels) and high temporal frequency CyanoHAB exposure metrics (Cyanobacteria  Intensity, Color Dissolved Organic Matter, Total Suspended Solids, Floating Algae Index,  Chlorophyll-a Concentration, & toxins). The decision support tool automates epoch synthesis to  understand incubation periods and exposure triggers for neurodegenerative diseases. Specific Aim #2: Scale on-demand CHABMAP commercial product services  • Scale and implement CHABMAP data services for infinite scalability using BigData cloud  technologies. This Aim involves three main development efforts: adapting our proprietary  Geospatial Image and Processing System (GIPS) capabilities to an AWS-deployable auto-scaling  cluster, creation of user interfaces and application programming interfaces (APIs) to interact with  these services, and enhancements to the base GIPS framework to facilitate intercommunication  between remote GIPS-enabled archives and the cloud processing streams. This includes the  creation of deployable compute instances, optimization of computation and parallelization  specific to AWS deployment, optimization of temporary and long-term storage of intermediate  products, and optimization of communication and data transfer with end users. Ultimately, this  Aim will allow for the assessment and monitoring of CyanoHAB conditions for any waterbody or  region (i.e., North America) on the planet. Specific Aim #3: Execute risk assessment frameworks with public health partners  • We will work in partnership with Cleveland Clinic, Dartmouth Hitchcock Medical Center,  University of Miami, Macquarie University, NIH’s Neuromuscular Diseases Research Section and  CDC’s Agency for Toxic Substances and Disease Registry (National ALS Registry) to assess the role  of CyanoHABs exposure as a risk factor for Amyotrophic lateral sclerosis (ALS) using patients,  clinic-, and population-based controls across diverse settings and geographies. Each application  end user has ongoing risk assessment frameworks (i.e., Gene-Environment, Residential History  Machine Learning, eco-epidemiological, molecular biology) which our CHABMAP technology will  integrate exposure epoch metrics to understand the etiology or ALS and support drug discovery. Proposed Innovation CHABMAP technology automates the quantification of toxic Cyanobacterial Harmful Algal Bloom (CHAB) exposure epochs for any waterbody or catchment in the world for the past four decades using multi-scale harmonized satellites. We use custom and proprietary techniques combined with BigData software to generate historical exposure (“exposome”) profiles as well provide Decision Support Tools services for CHAB monitoring in near-real time. During Phase 2 and beyond we work with world experts to integrate our commercial products and services into neurodegenerative disease Gene-Environment (GxE) risk assessment frameworks. Proposed Products, Services, Outcomes  • Develop historical CHAB exposure measurements working with environmental agency partners  • Assessment of CyanoHABs as a risk factor for ALS across multiple, independent study regions  • CHABMAP on-demand Analytics-as-a-Service platform operating at end of Phase 2  • Support discovery of etiology and drug development for neurological disorders and diseases Project Narrative Design, build, and operate a cloud-based Cyanobacterial Harmful Algal Bloom Mapping and Analysis Platform (CHAB-MAP) for developing public health applications’ in partnership with NASA, EPA, and medical centers. Assess as risk factor for ALS. Help address cyanobacteria and toxicity public help threats.",CHABMAP (Cyanobacterial Harmful Algal Bloom Mapping and Analyses Platform) technology automates the quantification of toxic CyanoHABs exposure epochs for any waterbody.,9906581,R44ES025513,"['Address', 'Algae', 'Amyotrophic Lateral Sclerosis', 'Archives', 'Big Data', 'Centers for Disease Control and Prevention (U.S.)', 'Chlorophyll', 'Clinic', 'Color', 'Communication', 'Computer software', 'Custom', 'Cyanobacterium', 'Data', 'Development', 'Environment', 'Epidemiology', 'Etiology', 'Frequencies', 'Genes', 'Geography', 'Machine Learning', 'Measurement', 'Medical center', 'Molecular Biology', 'Monitor', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuromuscular Diseases', 'North America', 'Outcome', 'Patients', 'Phase', 'Planets', 'Poison', 'Public Health', 'Public Health Applications Research', 'Recording of previous events', 'Registries', 'Research', 'Resolution', 'Retrieval', 'Risk Assessment', 'Risk Factors', 'Role', 'Sentinel', 'Services', 'Solid', 'Stream', 'System', 'Techniques', 'Technology', 'Time', 'Toxic effect', 'Toxin', 'United States National Aeronautics and Space Administration', 'United States National Institutes of Health', 'Universities', 'Work', 'application programming interface', 'base', 'cloud based', 'data exchange', 'design', 'disease registry', 'drug development', 'drug discovery', 'harmful algal blooms', 'image processing', 'indexing', 'innovation', 'nervous system disorder', 'parallelization', 'population based', 'remote sensing', 'spatiotemporal', 'support tools']",NIEHS,"APPLIED GEOSOLUTIONS, LLC",R44,2020,504200,-0.016533499141491
"Combinatorial matrix-mimetic recombinant proteins as engineered nerve guidance conduits ABSTRACT Over 500,000 Americans suffer from peripheral nerve injury (PNI), and despite surgical interventions, most suffer permanent loss of motor function and sensation. Current clinical options for long nerve gap PNI include naturally- derived grafts, which provide native matrix cues to regenerate neurons but suffer from very limited supply and batch-to-batch variability, or synthetic nerve guidance conduits (NGCs), which are easy to manufacture but often fail due to lack of regenerative cues. The main challenge with using any NGC for treatment of PNI is the immense trade-off between providing the complex matrix cues necessary for optimal nerve regeneration while providing a conduit that is readily available, reproducible, and easily fabricated. To overcome this challenge, we propose an entirely new type of biomaterial: a computationally optimized, protein-engineered recombinant NGC (rNGC). This rNGC combines the reliability of synthetic NGCs with the presentation of multiple regenerative matrix cues of natural NGCs. Because current understanding of cell-matrix interactions is insufficient to enable to direct design of a fully functional rNGC, we hypothesize that the use of machine learning, computational optimization methods will allow identification of an rNGC that promotes nerve regeneration similar to the current gold standard autograft. We utilize a family of protein-engineered, elastin-like proteins (ELPs) that are reproducible, with predictable, consistent material properties, and fully chemically defined for streamlined FDA approval. Due to ELPs’ modular design, they have biomechanical (i.e. matrix stiffness) and biochemical (i.e. cell-adhesive ligand) properties that are independently tunable over a broad range. While numerous studies detail the effects of individual biomechanical or biochemical matrix cues on neurite outgrowth using single-variable approaches, their combinatorial effects have been largely unexplored as insufficient knowledge exists to make accurate predictions of their interactions a priori. This fundamentally prohibits the direct design of combinatorial matrix cues. We hypothesize that optimized presentation of biomechanical and biochemical cues will create a microenvironment that better mimics the native ECM milieu, resulting in synergistic ligand cross-talk to improve nerve regeneration. In Aim 1, we use computational optimization methods to identify the combination of ligand identities, ligand concentrations, and matrix stiffness that best enhances neurite outgrowth. We will develop and characterize a library of ELP variants with distinct cell-adhesive ligands derived from native ECM, and assess their ability to support neurite outgrowth from rat dorsal root ganglia (DRG). In Aim 2, we will validate our in vitro optimization results in a preclinical, rat sciatic nerve injury model. A core-shell, ELP-based rNGC with an inner core matrix of the optimized ELP formulation from Aim 1 will be fabricated and evaluated for its ability to enhance therapeutic outcome. Controls include reversed nerve autograft, hollow silicone conduit, and non-optimized ELP- based rNGC. This study would represent the first use of computational optimization methods to design a reproducible, reliable, recombinant biomaterial with multiple regenerative matrix cues. PROJECT NARRATIVE The main challenge with using nerve guidance conduits (NGCs) to bridge long peripheral nerve gap injuries is the immense trade-off between providing the complex matrix cues necessary for optimal nerve regeneration while providing a conduit that is readily available, reproducible, and easily fabricated. To address this challenge, here we utilize (1) computational optimization methods to identify the optimal biochemical and biomechanical matrix cues for nerve regeneration, and (2) advanced protein-engineering strategies to incorporate these cues into a recombinant NGC (rNGC). Our rNGC combines the reliability of synthetic NGCs with the matrix cues of naturally-derived NGCs to make an affordable, off-the-shelf rNGC that promotes nerve regeneration.",Combinatorial matrix-mimetic recombinant proteins as engineered nerve guidance conduits,9872885,R21NS114549,"['Address', 'Adhesives', 'Allografting', 'American', 'Amino Acids', 'Autologous Transplantation', 'Axon', 'Behavioral', 'Biochemical', 'Biocompatible Materials', 'Biomechanics', 'Blood Vessels', 'Cell Surface Receptors', 'Cells', 'Chemicals', 'Cholinergic Receptors', 'Chronic', 'Clinical', 'Collagen', 'Complex', 'Cues', 'Data', 'Elastin', 'Electron Microscopy', 'Encapsulated', 'Engineering', 'Esthesia', 'Extracellular Matrix', 'Fibronectins', 'Formulation', 'Gold', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'In Vitro', 'Individual', 'Injury', 'Knowledge', 'Label', 'Laminin', 'Libraries', 'Ligands', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Modulus', 'Motor', 'Motor Neurons', 'Muscle', 'Natural regeneration', 'Nerve', 'Nerve Regeneration', 'Neurites', 'Neuroglia', 'Neurons', 'Operative Surgical Procedures', 'Patients', 'Peripheral Nerves', 'Peripheral nerve injury', 'Process', 'Property', 'Protein Engineering', 'Protein Family', 'Proteins', 'Rattus', 'Recombinant Proteins', 'Recombinants', 'Recovery of Function', 'Reporting', 'Reproducibility', 'Signal Pathway', 'Signal Transduction', 'Silicones', 'Spinal', 'Spinal Ganglia', 'Stains', 'Synaptophysin', 'Tenascin', 'Tissues', 'Tolonium chloride', 'Variant', 'Walking', 'alpha Bungarotoxin', 'base', 'combinatorial', 'comparative', 'design', 'exhaustion', 'experimental study', 'gel electrophoresis', 'improved', 'in vivo evaluation', 'mimetics', 'motor control', 'myelination', 'nerve autograft', 'nerve gap', 'nerve injury', 'nerve supply', 'postsynaptic', 'pre-clinical', 'regenerative', 'sciatic nerve', 'therapy outcome', 'tomato lectin', 'transcriptional coactivator p75']",NINDS,STANFORD UNIVERSITY,R21,2020,436238,-0.020054639523479058
"Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS) Project Abstract  Per- and polyfluoroalkyl substances (PFAS) are a family of over 5000 man-made chemicals that are ubiquitous in the environment, due to their chemical stability and bioaccumulative properties. Many of these “forever chemicals” have been linked with health concerns, including strong evidence of developmental health and harm to hormone-sensitive tissues. Manufacturers continue to substitute new PFAS for which exposure- based health risks are unknown. There is an urgent public health need to determine the effects of PFAS in use on both mammary gland development and increased breast cancer incidence. Current exposure studies use rodent models that require cumbersome end-point analyses as well as large monetary and time investments.  Our proposal is aimed at developing an in vitro to in vivo extrapolation (IVIVE) pipeline of mammary gland development and maintenance to identify and prioritize potentially toxic PFAS, to ultimately mitigate number of animals needed for environmental exposure studies. Our approach is to develop in vitro models of the mammary gland of increasing complexity but decreasing throughput, identifying links between high-throughput and high- complexity model endpoint readouts to best prioritize large chemical libraries. A key technology to establish links across multiple in vitro culture platforms is optical coherence tomography-based structural-functional imaging (OCT-SFI), developed by MPI Oldenburg, which non-invasively visualizes label-free cells, their intracellular motility, and morphology of formed spheroids, within optically turbid tissue models.  Our first specific aim advances a high-throughput paper-based culture system, developed by MPI Lockett, to study mammary epithelial cell invasion in physiologically relevant tissue microenvironments. The platform will evaluate 96 different exposure conditions in parallel. Our second specific aim employs 3D co-culture models that include fibroblasts to model stromal signaling known to affect mammary gland development. OCT-SFI will provide cellular motility and morphology of the organotypic spheroids that form in these cultures. Finally, our third aim will screen a library of 40 PFAS, with a particular focus on the perfluoroethercarboxylic acids (PFECAs) currently used in industrial coatings. In addition, 12 PFAS will be screened for which there is existing in vivo rodent model data available, and comparisons between in vitro assay outputs and in vivo gland remodeling will be used to refine the assay models and establish initial thresholds for screening.  The models developed as part of this proposal will thus be predictive of biology, enabling the high-throughput capability needed for future screening of all PFAS as well as other emerging endocrine disruptors. The project’s risk is balanced by the known imaging capabilities of OCT-SFI to probe responses in 3D spheroid and paper- based co-cultures. The high-throughput nature of this IVIVE pipeline makes it ideal for screening libraries of potential toxicants, providing information-rich datasets of spatially and temporally resolved morphological and molecular changes across the tissue-like structures. Project Narrative This proposal aims to develop a pipeline to screen and prioritize libraries of potentially toxic man-made chemicals found in the environment for further analyses, with particular emphasis on per- and poly-fluoroalkyl substances (PFAS) of which there are over 5000 currently known. Current environmental exposure testing methods evaluate mammary gland development in live mice because the mammary gland is highly susceptible to chemical exposure; yet, such methods are slow and expensive. Our proposal uses mammary cell culture models in increasingly complex, tissue-like environments, in combination with high-speed 3D optical imaging techniques, and ultimately compare the platform with a few candidate PFAS against existing data in live mice, setting the stage for future high-throughput screening of potential environmental toxicants.",Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS),10152786,R01ES032730,"['3-Dimensional', 'Acids', 'Affect', 'Animals', 'Architecture', 'Biological Assay', 'Biology', 'Biometry', 'Breast Cancer Epidemiology', 'Breast Epithelial Cells', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Cellular Morphology', 'Characteristics', 'Chemical Exposure', 'Chemicals', 'Clinical Trials', 'Coculture Techniques', 'Complex', 'Data', 'Data Set', 'Development', 'Endocrine Disruptors', 'Environment', 'Environmental Exposure', 'Epithelial', 'Epithelium', 'Estrogen receptor positive', 'Exposure to', 'Family', 'Fiber', 'Fibroblasts', 'Functional Imaging', 'Future', 'Gene Proteins', 'Gland', 'Growth', 'Health', 'Hormones', 'Imaging Techniques', 'In Vitro', 'Incidence', 'Industrialization', 'Investments', 'Label', 'Libraries', 'Link', 'Maintenance', 'Malignant Neoplasms', 'Mammary gland', 'Manufacturer Name', 'Mesenchymal', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'Mus', 'National Institute of Environmental Health Sciences', 'Nature', 'North Carolina', 'Odds Ratio', 'Optical Coherence Tomography', 'Optics', 'Output', 'Paper', 'Pathology', 'Physiological', 'Poly-fluoroalkyl substances', 'Property', 'Public Health', 'Rattus', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Rodent', 'Rodent Model', 'S-Phase Fraction', 'Scanning', 'Scoring Method', 'Signal Transduction', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'Toxic Environmental Substances', 'Up-Regulation', 'Work', 'assay development', 'base', 'carcinogenesis', 'carcinogenicity', 'cell motility', 'chemical stability', 'data modeling', 'deep learning', 'deep learning algorithm', 'high throughput screening', 'imaging capabilities', 'in vitro Assay', 'in vitro Model', 'in vivo', 'intercellular communication', 'machine learning algorithm', 'malignant breast neoplasm', 'malignant phenotype', 'mammary epithelium', 'mammary gland development', 'man', 'model design', 'non-invasive imaging', 'novel', 'optical imaging', 'premalignant', 'protein biomarkers', 'response', 'screening', 'small molecule libraries', 'three dimensional cell culture', 'three-dimensional modeling', 'tool', 'toxicant']",NIEHS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,559511,-0.03040549196928615
"ADAR-editing landscape dysregulation in neuropsychiatric disorders Project Abstract:  Adenosine deaminase acting on RNA (ADAR) editing plays a major role in shaping transcriptome diversity by creating variant isoforms that enable fine-tuning of calcium-mediated excitatory and other signaling needed for brain development, neural plasticity and mood regulation. The spatio-temporal ADAR editing landscapes are tightly regulated by controlling ADAR expression levels to preserve preferential binding and editing. Previous studies have shown that activation of the interferon pathways of the innate immune system – such as those seen in viral infections - leads to increased expression of ADAR1p150, which ultimately results in changes to ADAR editing patterns. Furthermore, common side effects to innate immune activation by interferon alpha therapies include increased risk of depression and suicide. The changes in spatio-temporal regulation of editing patterns can lead to a wide spectrum of neurological symptoms, including neuropsychiatric disorders (e.g., decreased ADAR editing in the serotonin receptor subunit2C in the prefrontal cortex observed in individuals who commit suicide). Yet, our understanding of ADAR editing landscapes remain cursory. Advances in high throughput RNA-seq enable more accurate variant calling from the sequencing reads, providing a way to map ADAR editing patterns in the transcriptome. However, there are no computational pipelines focused on ADAR editing that are easy to use, are reproducible and can handle large scale analysis. I have recently built a pipeline to handle meta-analysis of RNA-seq data that incorporates variant calling steps, but further work is needed to validate this tool to assure accuracy and reproducibility of results. It can then be used to map the spatio-temporal variation of ADAR editing landscapes. The proposed project will study ADAR editing landscapes in the following ways: (i) new computational pipelines will be benchmarked to use variant calling with RNA-seq datasets using simulated reads, (ii) ADAR editing landscape diversity in the publicly available human samples will be mapped; the computational predictions and hypotheses generated from the pipeline will be validated using (iii) measuring calcium flux in cells with known differential ADAR editing landscapes caused by PolyI:C (viral infection mimic) treatment. The proposed work will yield a validated pipeline capable of mapping ADAR editing landscapes with machine learning algorithms. Defining ADAR editing landscapes is paramount to biomarker discovery and can influence precision medicine applications in diagnosis and treatment of neuropsychiatric disorders. This project will allow for me to gain the knowledge base necessary to become an independent researcher with a unique skill set of both computational and benchwork methods to advance the field of neuroscience. Project Narrative Inferring ADAR editing landscapes and their link with ion homeostasis and excitatory signaling in the brain is important for understanding, diagnosing or staging neurological and neuropsychiatric disorders, including major depressive disorder and suicide. This proposed project will develop and validate computational tools to use RNA-seq from publicly available datasets for ADAR editing inferences and to delineate patterns of editing changes in cells experiencing viral infections. Overall, this project will give me the training to build my unique skill set of both computational and experimental methods that will enable me as an independent researcher to bridge the gap between bioinformatics and experimental researchers and translate my findings into precision medicine.",ADAR-editing landscape dysregulation in neuropsychiatric disorders,9992699,F31MH123131,"['Accounting', 'Anxiety', 'Benchmarking', 'Binding', 'Bioinformatics', 'Brain', 'Calcium', 'Cardiovascular Diseases', 'Cause of Death', 'Cell Culture Techniques', 'Cells', 'Complex', 'Computer Analysis', 'Custom', 'Data', 'Data Set', 'Databases', 'Depression and Suicide', 'Development', 'Diagnosis', 'Economic Burden', 'Etiology', 'Frequencies', 'Fura-2', 'Genes', 'Genetic Transcription', 'Genotype-Tissue Expression Project', 'Glutamate Receptor', 'High-Throughput RNA Sequencing', 'Homeostasis', 'Human', 'Image', 'Immune response', 'Immune system', 'Immunohistochemistry', 'Individual', 'Innate Immune System', 'Interferon Activation', 'Interferon-alpha', 'Ions', 'Lead', 'Link', 'Major Depressive Disorder', 'Maps', 'Measures', 'Mediating', 'Meta-Analysis', 'Methods', 'Molecular', 'Nervous system structure', 'Neurologic Symptoms', 'Neuronal Plasticity', 'Neurosciences', 'PF4 Gene', 'Pathway interactions', 'Pattern', 'Permeability', 'Play', 'Population', 'Prefrontal Cortex', 'Protein Isoforms', 'Proteins', 'RNA', 'RNA Editing', 'Regulation', 'Reproducibility', 'Reproducibility of Results', 'Research Personnel', 'Risk', 'Role', 'Sampling', 'Shapes', 'Signal Transduction', 'Site', 'Staging', 'Suicide', 'Testing', 'Training', 'Translating', 'United States', 'Validation', 'Variant', 'Viral', 'Virus Diseases', 'Western Blotting', 'Work', 'accomplished suicide', 'adenosine deaminase', 'biomarker discovery', 'computational pipelines', 'computerized tools', 'data visualization', 'detector', 'differential expression', 'disability-adjusted life years', 'dopaminergic differentiation', 'excitotoxicity', 'experience', 'immune activation', 'in silico', 'innate immune pathways', 'insight', 'knowledge base', 'machine learning algorithm', 'mood regulation', 'nerve stem cell', 'nervous system disorder', 'neuropsychiatric disorder', 'neurotransmission', 'novel marker', 'precision medicine', 'preservation', 'relating to nervous system', 'release of sequestered calcium ion into cytoplasm', 'serotonin receptor', 'side effect', 'skills', 'social', 'spatiotemporal', 'suicidal risk', 'tool', 'transcriptome', 'transcriptome sequencing', 'virtual machine']",NIMH,KENT STATE UNIVERSITY,F31,2020,29830,-0.08379681264314894
"Optimizing delivery of ethyl cellulose ethanol for ablation of cervical precancer ABSTRACT Cervical cancer affects the lives of half a million women worldwide each year. Over half of these women die, even though cervical cancer is highly preventable through vaccination or early screening, diagnosis, and treatment of cervical pre-cancer. Cervical cancer prevention consists of three visits in the U.S.: 1) screening using the Papanicolaou smear; 2) colposcopy followed by biopsy of cervical abnormalities for women with positive screening results; 3) treatment by excising the lesion using a Loop Electrosurgical Excision Procedure (LEEP) for women with cervical pre-cancer. This three-visit model is not practical for use in medically underserved regions due to the technologies and expertise needed and patient attrition between clinic visits. Our team has already developed a novel Pocket colposcope and machine learning algorithms that when combined provide high-quality, magnified visualization and automated diagnosis with comparable performance to standard-of-care colposcopy. However, screening and diagnosis alone will not lead to decreases in cervical cancer mortality if access to point-of-care treatment is limited. Recently, the thermocoagulator has gained acceptance for ablation of cervical pre-cancer lesions as it does not require consumables (continuous supply of pressurized liquid nitrogen for cryotherapy) or a stable power supply (for LEEP). However, low-cost thermocoagulators have frequent failures based on reports of field-testing and the more reliable versions cost more than $10k. To address these well-documented shortcomings, our group is working to establish a low-cost ablative therapy using a ubiquitous agent, ethanol to treat cervical pre-cancer. While ethanol ablation has a long history of clinical use, its direct injection into tissue leads to non-uniform distribution and hence low efficacy in the region of interest. We propose a new formulation of ethanol using a polymer called ethyl cellulose (generally regarded as safe by the FDA), which will act as a slow release gel without off target toxicity, and an automated injector to control delivery of ethanol-ethyl cellulose (EEC) into the region of interest. The goal of this Phase I SBIR grant is to establish controlled delivery of EEC for cervical pre-cancer treatment using a combination of tissue surrogates and ex vivo and in vivo models of the swine cervix to induce a zone of necrosis that is consistent with thermocoagulation, a commonly used ablation method. In Aim 1, an automated needle injector will be designed for reproducible EEC delivery in tissue surrogates by maximizing the ratio of distributed to injected volume and minimizing back flow and crack formation. In Aim 2, the automated needle injector will be tested in ex vivo swine cervices to establish the distribution of the agent within the defined region of interest and also to determine the number of injections needed to achieve optimal coverage. In Aim 3, the injector safety and efficacy will be tested in in vivo swine cervices to establish the distribution volume and zone of necrosis caused by EEC. The results from the Phase I SBIR will set the foundation for development of alpha and beta versions of the automated needle injector, quality control assessment and packaging of the EEC injectate, and submission of an IND for EEC to the FDA. The goal of this SBIR is for PIs from academic and small business institutions to work in partnership to develop a technological strategy that will transform treatment of cervical pre-cancer in low-resource communities. The proposed research is significantly relevant to public health, as the developed technologies will contribute to the improvement of cervical cancer prevention, and thus a reduction in the mortality rate of this imminently preventable disease.",Optimizing delivery of ethyl cellulose ethanol for ablation of cervical precancer,10140866,R43CA257303,"['Ablation', 'Acute', 'Address', 'Adverse event', 'Affect', 'Alcohol consumption', 'Anatomy', 'Back', 'Benchmarking', 'Businesses', 'Caliber', 'Cellulose', 'Cervical', 'Cervix Uteri', 'Characteristics', 'Clinic Visits', 'Clinical', 'Cold Therapy', 'Colposcopes', 'Colposcopy', 'Communities', 'Country', 'Defect', 'Development', 'Diagnosis', 'Disease', 'Dose', 'Early Diagnosis', 'Electrocoagulation', 'Ethanol', 'Excision', 'Extravasation', 'Failure', 'Family suidae', 'Field Reports', 'Fluorescein', 'Formulation', 'Foundations', 'Freezing', 'Gel', 'Goals', 'Grant', 'Hour', 'Human', 'Human Papillomavirus', 'Image', 'Improve Access', 'Income', 'Infusion procedures', 'Injections', 'Institution', 'Lesion', 'Light', 'Liquid substance', 'Malignant Neoplasms', 'Malignant neoplasm of cervix uteri', 'Measurable', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Necrosis', 'Needles', 'Nitrogen', 'Outcome', 'Pap smear', 'Pathway interactions', 'Patients', 'Performance', 'Phase', 'Polymers', 'Power Sources', 'Protocols documentation', 'Public Health', 'Quality Control', 'Recording of previous events', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Safety', 'Screening Result', 'Site', 'Small Business Innovation Research Grant', 'Source', 'Squamous cell carcinoma', 'Stains', 'System', 'Technology', 'Testing', 'Tissues', 'Toxic effect', 'Vaccination', 'Vision', 'Visit', 'Visualization', 'Woman', 'Work', 'X-Ray Computed Tomography', 'arm', 'base', 'cervical biopsy', 'cervical cancer prevention', 'cost', 'design', 'early screening', 'experience', 'field study', 'in vivo', 'in vivo Model', 'interest', 'intervention cost', 'loop electrosurgical excision procedure', 'low and middle-income countries', 'machine learning algorithm', 'medically underserved', 'mortality', 'novel', 'point of care', 'portability', 'preclinical study', 'pressure', 'prevent', 'prototype', 'screening', 'standard of care']",NCI,CALLA HEALTH FOUNDATION,R43,2020,300000,-0.044174483174982494
"FluMod - Center for the Multiscale Modeling of Pandemic and seasonal Flu Prevention and Control PROJECT SUMMARY In this proposal we plan to contribute addressing the above foundational and operational challenges by advancing the science of influenza modeling and contributing novel methods and data sources that will increase the accuracy and availability of seasonal and pandemic influenza models. To address these challenges, we plan to build on the unique mechanistic spatially structured modeling approaches developed by our consortium, that includes stochastic metapopulation models and fully developed agent-based models nested together in our global epidemic and mobility modeling (GLEAM) approach. The objective of this project is to generate novel and actionable scientific insights from dynamic transmission models of influenza transmission that effectively integrate key socio-demographic indicators of the focus population, as well as a wide spectrum of pharmaceutical and non-pharmaceutical interventions. Our proposed work in specific aim 1 (A1) will leverage our global modeling (from the global to local scale) framework that can be used to explore the multi-year impact of influenza vaccination, antiviral prophylaxis/treatment, and community mitigation during influenza seasons and pandemics. Our specific aim 2 (A2) will focus on using high quality data to model heterogeneous transmission drivers and novel contact pattern stratifications that will allow us to guide mitigation strategies and prioritization for interventions. In our Aim 3 (A3) we will use artificial intelligence approaches to identify interventions that are particularly synergistic and well-suited to particular epidemic scenarios, for seasonal and pandemic influenza. Our overarching goal is to provide a modeling portfolio with flexible and innovative mathematical and computational approaches. We aim to address several questions commonly asked about seasonal and pandemic influenza and match these with analytical methods and outbreak projections. The modeling and data developed in this project can help facilitate and justify transparent public health decisions, while contributing to the definition of standard methods for model selection and validation. Finally, our influenza modeling platform can also benefit the broader network of modeling teams and can be used to improve result sharing and harmonization of modeling approaches. The objective of this proposal is to advance the science of modeling and contribute novel methods and data analytics tools that will increase the understanding of seasonal and pandemic influenza in the context of the network of modeling teams coordinated by the CDC. To address these challenges, we plan to develop a novel global modeling framework, contribute new data and methods for improve the accuracy and validation of flu modeling approaches, and evolve successful methodologies to advance the analysis of layered intervention with artificial Intelligence.",FluMod - Center for the Multiscale Modeling of Pandemic and seasonal Flu Prevention and Control,10071782,U01IP001137,[' '],NCIRD,NORTHEASTERN UNIVERSITY,U01,2020,371721,-0.012184329903452171
"A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities DESCRIPTION (provided by applicant): Our ultimate goal is to improve our ability to create and measure 3D models derived from cone-beam computed tomography (CBCT). Our main motivation is to improve quality and reduce costs in care of patients with craniomaxillofacial (CMF) deformities. The resulted innovations will also impact other fields. CMF deformities involve congenital and acquired deformities of the jaws and face. A large number of patients in the US and around the world suffered from CMF deformities. The evaluation of these patients includes an assessment of CMF form on 3D models that are traditionally generated from segmented spiral multi-slice CTs (MSCTs). These models are also used to plan their treatment. The purpose of segmentation is to separate different anatomical structures and to remove the artifacts on the CTs. Once 3D models are generated from the segmented CTs, anatomical and teeth landmarks are manually digitized for measurements. Finally, diagnosis and treatment planning are performed based on measurements. Although MSCT provides high- quality images and thus allows relatively fast and easy post processing, many concerns have been raised on excessive radiation exposure to patients. Therefore, more doctors are now using CBCT scanners in their offices. CBCT has less radiation and is inexpensive compared to the MSCT, but their use in generating 3D models is greatly limited by the poor image quality, i.e., low contrast / signal-to-noise ratio and artifacts. Thus, the existing automated segmentation algorithms developed for MSCT are incapable of practically segmenting CBCTs. The current solution to CBCT segmentation entails an arduous and lengthy process that involves labor-intensive manual editing of hundreds of slices. Besides, another arduous and inaccurate task in the assessment of CMF deformities is the digitization of anatomical landmarks on 3D models - the first step to quantify the deformities. Currently a typical 3D cephalometric and teeth analysis requires the manual digitization of more than 200 landmarks, which is time consuming and has limited accuracy. We hypothesize that the creation and measurement of high-quality 3D models can be significantly improved by developing innovative CBCT-friendly post processing tools. Therefore, in this renewal project, we propose to develop and validate a novel CBCT analysis platform to automate the process of CBCT segmentation and landmark digitization. The feasibility of our approaches has already been proven by our preliminary studies. Our innovative CBCT analysis platform will significantly improve the quality and reduce the cost of care to the individuals with CMF conditions. It will change our dental/CMF fields in effectively utilizing CBCT as a guide for on-the-fly diagnosis and treatment planning. With minimal user intervention, the computer will accurately and effectively do the work, which is currently artistically done by the labor-intensive human operators. The resulted innovations may also impact other fields in the future, e.g., orthopedic surgery and cardiovascular surgery where intraoperative whole-body CBCT is acquired for image-guided surgery and intervention. PUBLIC HEALTH RELEVANCE: Cone-beam computed tomography (CBCT) is widely used in physician's offices for orthodontics, craniomaxillofacial (CMF) surgery, facial plastic surgery and dentistry, but its segmentation and landmark digitization have to be completed artistically by human operators, which is labor-intensive and with limited accuracy.  We propose to develop and validate an innovative CBCT post processing system to automate the processes of CBCT segmentation and landmark digitization with minimal user intervention.  The proposed system will significantly improve the quality and reduce the cost of care to the individuals  with CMF conditions, and also change 1) the fields of orthodontics, CMF surgery and general dentistry in  effectively utilizing CBCT as a guide for diagnosis and treatment planning, and 2) the fields of orthopedic  surgery, general surgery, and cardiovascular surgery where the quality and the speed of intraoperative imaging is critical.",A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities,9840832,R01DE022676,"['3-Dimensional', 'American', 'Anatomy', 'Atlases', 'Back', 'Cardiovascular Surgical Procedures', 'Cephalometry', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computed Tomography Scanners', 'Computer Assisted', 'Computer software', 'Computers', 'Consultations', 'Consumption', 'Deformity', 'Dental Care', 'Dentistry', 'Detection', 'Diagnosis', 'Diagnostic', 'Ensure', 'Evaluation', 'Exposure to', 'Face', 'Future', 'Goals', 'Head', 'Hour', 'Human', 'Image', 'Image-Guided Surgery', 'Individual', 'Intervention', 'Jaw', 'Label', 'Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motivation', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Oral', 'Orthodontics', 'Orthopedic Surgery procedures', 'Patient Care', 'Patients', 'Phase', 'Physicians&apos', ' Offices', 'Plastic Surgical Procedures', 'Process', 'Quality of Care', 'Quantitative Evaluations', 'Radiation', 'Radiation Dose Unit', 'Radiation exposure', 'Running', 'Scanning', 'Services', 'Shapes', 'Signal Transduction', 'Slice', 'Speed', 'Syncope', 'System', 'Technology', 'Three-Dimensional Image', 'Time', 'Tooth structure', 'Training', 'Validation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'accurate diagnosis', 'automated segmentation', 'base', 'care costs', 'cone-beam computed tomography', 'cost', 'craniofacial', 'craniomaxillofacial', 'design', 'detector', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'psychologic', 'public health relevance', 'random forest', 'segmentation algorithm', 'three-dimensional modeling', 'tool', 'treatment planning', 'usability', 'user-friendly', 'virtual surgery']",NIDCR,METHODIST HOSPITAL RESEARCH INSTITUTE,R01,2020,495143,-0.025925338588439765
"Synchronized brain dynamics and eye movement trajectory for objective evaluation of robot-assisted surgical skills Complicated and costly robot assisted surgery (RAS) training results in less frequent use of this technology in several complex areas of surgery, and consequently ends up in harm. RAS requires a unique blend of skills in addition to manual competence with human-machine interaction skills, while operating remotely from patient with no tactile feedback. To address this challenge, numerous studies have focused on simulation-based robotic training curricula, like Fundamental Skills of Robotic Surgery (FSRS), to develop and assess the performance level of the surgeon operator. However, such training tools were developed based on metrics measured by performance on a simulator and other subjectively evaluated metrics. The goal of this research proposal is to develop a tool for objective RAS skill assessment and a model for performance monitoring. We hypothesize that brain dynamics - Electroencephalogram (EEG) - and eye movement behavior are able to detect change of skill level and the level of surgeon’s performance. To validate this hypothesis, we will record EEG signals and eye movement time series from subjects with different RAS expertise levels. Ten novices, 5 beginners, 5 advanced beginners, and 5 expert surgeons will be included in the study and continuously perform four levels of designed RAS training tasks on surgical robot simulator, dry lab, and animal lab during one year; (1) performing six basic tasks on surgical simulator. All subjects will practice these tasks during two weekly sessions and each practice session takes 2 hours. (2) Subjects will practice 3 tasks of peg transfer, pattern cutting, and suturing on dry lab. (3) Subjects will practice 2 tasks (anastomosis and dissection) on animal tissue and also on plastic models. (4) Subjects will practice two operations of nephrectomy and hysterectomy on animal lab, 2 operations in each session, and each session takes 3 hours and occurs every other week. Two master surgeons will subjectively evaluate performance of subjects (all 25 subjects; Score scale: 1-20) and expertise level (four categories) in performing the designed tasks, every practice session. Master surgeons evaluate surgeon’s skill and performance throughout task and notify change of skill level and performance through time. We will then develop a ‘deep convolutional neural network’ algorithm trained by EEG and eye movement time series through running windows with equal size, to classify subject skill level into four categories of a novice, beginner, advanced beginner, and expert. We will also use network neuroscience techniques to extract engineered features from EEG and eye movement data and use them for training a regression algorithm to develop a model for performance level prediction. Ultimately, the developed objective skill evaluation tool and performance monitoring model will make RAS training more efficient by providing feedback to the trainee regarding his/her skills and directing him/her to focus on skills needed improvement. These improvements will result in more frequent use of RAS in complex surgical areas and ultimately lead to patient safety. Project Narrative The use of robot-assisted surgery (RAS) has offered advantages for surgeons and patients, yet there is no clinically practical tool for objective evaluation of subject’s expertise level and performance. The overall objective of this research is to develop a tool for objective RAS skill assessment and a model for performance monitoring, leading to optimized RAS training process, improved patient safety and surgical outcomes.",Synchronized brain dynamics and eye movement trajectory for objective evaluation of robot-assisted surgical skills,9939074,R01EB029398,"['Active Learning', 'Address', 'Algorithms', 'Anastomosis - action', 'Animals', 'Applied Skills', 'Area', 'Automobile Driving', 'Behavior', 'Brain', 'Categories', 'Classification', 'Clinical', 'Cognitive', 'Competence', 'Complex', 'Data', 'Development', 'Dissection', 'Educational Curriculum', 'Electroencephalogram', 'Engineering', 'Evaluation', 'Eye', 'Eye Movements', 'Feedback', 'Goals', 'Hour', 'Human', 'Hysterectomy', 'Individual', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Length', 'Literature', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Needles', 'Nephrectomy', 'Neurosciences', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patients', 'Pattern', 'Performance', 'Process', 'Publishing', 'Research', 'Research Proposals', 'Robot', 'Robotics', 'Role', 'Running', 'Series', 'Signal Transduction', 'Structure', 'Surgeon', 'Surgical sutures', 'System', 'Tactile', 'Techniques', 'Technology', 'Time', 'Training', 'Wrist', 'adaptive learning', 'algorithm development', 'algorithm training', 'animal tissue', 'arm', 'base', 'cognitive process', 'convolutional neural network', 'cost', 'deep neural network', 'density', 'design', 'gaze', 'human disease', 'improved', 'learning strategy', 'motor learning', 'neural network algorithm', 'operation', 'patient safety', 'regression algorithm', 'robot assistance', 'robotic device', 'robotic training', 'safety outcomes', 'sensor', 'signal processing', 'simulation', 'skill acquisition', 'skills', 'surgery outcome', 'tool']",NIBIB,ROSWELL PARK CANCER INSTITUTE CORP,R01,2020,393075,-0.01238100747663753
"Phase II - HazPrep Worker Training - Community Risk Profile - COVID-19 Rapid Response PROJECT SUMMARY/ABSTRACT COVID-19 Supplement to HazPrep Phase II. Original Summary: A worker's personal hazard profile (PHP) is a function of hazards present and his/her exposure level to those hazards. Workers with an elevated level of risk are those who can be engaged in activities related to - or working around - hazardous materials, waste generation, removal, containment, transportation, and emergency response. inXsol’s Phase I feasibility study verified the appeal and effectiveness of a new form of crowdsourced social learning platform. Our approach using cloud technology creates a dynamically growing library of incidents/scenarios, highly personalized (occupation/task/geo) risk profile and generates learning activities to train on risk awareness and mitigation techniques. The Phase II proposal includes implementation of an innovative use of big data algorithms for community profiles and fusion with PHP allowing for targeted and personalized training completing the HazPrep prototype developed and exercised by our beta test team in Phase I. PROJECT NARRATIVE COVID-19 Supplement to HazPrep Phase II. Original Narrative: HazPrep is a new form of a social learning platform which includes crowdsourcing and machine learning AI to formulate personalized learning activities at risk workers with an elevated level of risk such as those who can be engaged in activities related to - or working around - hazardous materials, waste generation, removal, containment, transportation, and emergency response. Actual incidents are ingested from OSHA, NFIRS and other sources as scenarios/case studies.",Phase II - HazPrep Worker Training - Community Risk Profile - COVID-19 Rapid Response,10157843,R44ES028145,"['Academy', 'Achievement', 'Algorithms', 'Assessment tool', 'Awareness', 'Big Data', 'COVID-19', 'COVID-19 pandemic', 'Case Study', 'Communities', 'Community of Practice', 'Consultations', 'Containment', 'Credentialing', 'Data', 'Effectiveness', 'Emergency response', 'Employee', 'Event', 'Excision', 'Exercise', 'Family', 'Feasibility Studies', 'Feedback', 'Feeds', 'Formulation', 'Frequencies', 'Generations', 'Hazardous Substances', 'Health', 'Health Sciences', 'Individual', 'Industry', 'Infection prevention', 'Ingestion', 'Knowledge', 'Libraries', 'Location', 'Machine Learning', 'Maintenance', 'Metadata', 'Modeling', 'Occupations', 'Performance', 'Phase', 'Plants', 'Prevention', 'Privatization', 'Process', 'Production', 'Readiness', 'Recording of previous events', 'Resources', 'Risk', 'S Phase', 'Safety', 'Site', 'Source', 'Structure', 'Surveys', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Testing', 'Texas', 'Time', 'Training', 'Transportation', 'Universities', 'Work', 'application programming interface', 'commercialization', 'crowdsourcing', 'dashboard', 'data archive', 'design', 'e-commerce', 'experience', 'feeding', 'flexibility', 'hazard', 'innovation', 'learning strategy', 'machine learning algorithm', 'pandemic disease', 'personalized learning', 'prototype', 'repaired', 'response', 'skills', 'social learning', 'sound', 'tool', 'virtual', 'wasting', 'web site']",NIEHS,"INXSOL, LLC",R44,2020,86019,-0.021120466301854466
"Graspy: A python package for rigorous statistical analysis of populations of attributed connectomes PROJECT SUMMARY Overview: We will extend and develop implementations of foundational methods for analyzing populations of attributed connectomes. Our toolbox will enable brain scientists to (1) infer latent structure from individual connectomes, (2) identify meaningful clusters among populations of connectomes, and (3) detect relationships between connectomes and multivariate phenotypes. The methods we develop and extend will naturally overcome the challenges inherent in connectomics: high-dimensional non-Euclidean data with multi-level nonlinear interactions. Our implementations will comply with the highest open-source standards by: providing extensive online documentation and extended tutorials, hosting workshops to demonstrate our tools on an annual basis, and merging our implementations into commonly used packages such as scikit-learn [1], scipy [2], and networkx [3]. All of the code we develop is open source. We strive to ensure that our code is shared in accordance with the strictest guiding principles. We chose to implement these algorithms in Python due to its wide adoption in the neuroscience and data science fields. In particular, many other neuroscience tools applicable to connectomics, including NetworkX DiPy, mindboggle, nilearn, and nipy, are also implemented in Python. This will enable researchers to chain our analysis tools onto pre-existing pipelines for data preprocessing and visualization. Nonetheless, we feel that sharing our code in our own public repositories is insufficient for global reach. We have also begun reaching out to developers of the leading data science packages in python, including scipy, sklearn, networkx, scikit-image, and DiPy. For each of those packages, we have informal approval to begin integrating algorithms that we have developed. Those packages are collectively used by >220,000 other packages, so merging our algorithms into those packages will significantly extend our global reach. All researchers investigating connectomics, including all the authors of the 24,000 papers that mention the word “connectome”, will be able to apply state-of-the-art statistical theory and methods to their data. Currently, we have about 150 open source software projects on our NeuroData GitHub organization. Collectively, these projects get about 2,000 downloads and >11,000 views per month. As we incorporate additional functionality as described in this proposal, we expect far more researchers across disciplines and sectors will utilize our software. 20 ​ ​​ ​ ​​ Project Narrative Connectomes are an increasingly important modality for characterizing the structure of the brain, to complement behavior, genetics, and physiology. We and others have developed foundational statistical theory and methods over the last decade for the analysis of networks, networks with edge, vertex, and other attributes, and populations thereof, with preliminary implementations of those tools that we leverage in our laboratory for various application papers. In this project, we will extend our package, called graspy, to be of professional quality, implementing key functionality to include (1) estimating latent structure from attributed connectomes, (2) identifying meaningful clusters among populations of connectomes, and (3) detecting relationships between connectomes and multivariate phenotypes, such as behavior, genetics, and physiology. 18",Graspy: A python package for rigorous statistical analysis of populations of attributed connectomes,10012519,RF1MH123233,"['Adoption', 'Algorithms', 'Behavioral Genetics', 'Brain', 'Code', 'Coin', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Development', 'Discipline', 'Documentation', 'Educational workshop', 'Ensure', 'Foundations', 'Funding', 'Genes', 'Human', 'Image', 'Individual', 'Journals', 'Laboratories', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modality', 'Modernization', 'Motivation', 'Neurosciences', 'Paper', 'Pathway Analysis', 'Phenotype', 'Physiology', 'Population', 'Population Analysis', 'Population Study', 'Property', 'PubMed', 'Publishing', 'Pythons', 'Research Personnel', 'Scientist', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Study', 'Structure', 'Telecommunications', 'Testing', 'Visualization', 'Work', 'brain research', 'connectome', 'data pipeline', 'design', 'high dimensionality', 'high standard', 'open source', 'public repository', 'software development', 'theories', 'tool', 'user-friendly']",NIMH,JOHNS HOPKINS UNIVERSITY,RF1,2020,1246005,-0.017336836352272327
"Gaze-contingent computer screen magnification control for people with low vision ! Project Summary This application describes proposed research with the goal of facilitating use of a computer screen magnifier by people with low vision. Screen magnification is a well-established, popular technology for access of onscreen content. Its main shortcoming is that it requires the user to continuously control, with the mouse or trackpad, the location of the focus of magnification, in order to ensure that the magnified content of interest is within the screen viewport. This tedious process may be time-consuming and ineffective. For example, the simple task of reading the news on a web site requires continuous horizontal scrolling, which affects the experience of using this otherwise very beneficial technology, and may discourage its use, especially by those with poor manual coordination.  We propose to develop a software system that enables hands-free control of a screen magnifier. This system will rely on the user’s eye gaze (measured by a regular IR-based tracker, or from analysis of the images in a camera embedded in the screen) to update the location of the focus of magnification as desired. This research is inspired by preliminary work, which showed promising results with two simple gaze-based control algorithms, tested on three individuals with low vision.  This project will be a collaboration between the Department of Computer Science and Engineering at UC Santa Cruz (PI: Manduchi, Co-I: Prado) and the School of Optometry at UC Berkeley (PI: Chung). Dr. Legge from the Department of Psychology at U. Minnesota will participate as a consultant. Two human subjects studies are planned. In Study 1 with 80 low vision subjects from four different categories of visual impairment, we will investigate the failure rate of a commercial gaze tracker (Aim 1), and will record mouse tracks, gaze tracks, and images from the subjects while performing a number of tasks using two modalities of screen magnification (Aim 2). In Study 2, with the same number of subjects, we will repeat the Study 1 experiment, but using a gaze-based controller trained from the data collected in Study 1, and individually tunable for best performance (Aim 3). In addition, we will experiment with an appearance-based gaze tracker that uses images from the screen camera, thereby removing the need for specialized gaze tracking hardware, as well as with a computer tablet form factor (Aim 4). We expect that reading speed and error rate using our gaze-based controller will be no worse than using mouse-based control. If successful, this study will show that the convenience of hands-free control offered by the proposed system comes at no additional cost in terms of individual performance at the considered tasks. ! ! Project Narrative People with low vision often use screen magnification software to read on a computer screen. Since a magnifier expands the screen content beyond the physical size of the screen (the “viewport”), it is necessary to move the content using the mouse so that the portion of interest falls within the viewport. This project will facilitate use of a screen magnifier by means of a new software system that relies on the user’s own gaze to control scrolling when reading with magnification. !",Gaze-contingent computer screen magnification control for people with low vision,10053172,R01EY030952,"['Affect', 'Age', 'Algorithms', 'Appearance', 'Apple', 'Behavior Control', 'Benchmarking', 'Blindness', 'Categories', 'Collaborations', 'Communication', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Correlation Studies', 'Data', 'Data Set', 'Desktop Video', 'Engineering', 'Ensure', 'Eye', 'Face', 'Failure', 'Funding', 'Glass', 'Goals', 'Hand', 'Image', 'Individual', 'Learning', 'Location', 'Magic', 'Manuals', 'Measures', 'Minnesota', 'Modality', 'Mus', 'Operating System', 'Optometry', 'Performance', 'Peripheral', 'Process', 'Psychological reinforcement', 'Psychology', 'Reader', 'Reading', 'Research', 'Resort', 'Role', 'Schools', 'Science', 'Speech', 'Speed', 'Structure', 'Study Subject', 'System', 'Tablet Computer', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Update', 'Vision', 'Visual', 'Visual impairment', 'Work', 'algorithm development', 'algorithm training', 'base', 'computer science', 'control trial', 'cost', 'data acquisition', 'design', 'experience', 'experimental study', 'falls', 'gaze', 'human subject', 'interest', 'motor control', 'news', 'recurrent neural network', 'sample fixation', 'software systems', 'tool', 'web page', 'web site']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R01,2020,350753,-0.019043930307669
"Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence Abstract Enzyme functionality is a critical component of all life systems. Whereas advances in experimental methodology have enabled a better understanding of factors that control enzyme function, critical components of the reaction space such as highly unstable intermediates and transition states are best accessed for evaluation through computational simulations. Similarly, computational methodology continues to provide a key resource for probing excited-state processes such as bioluminescence. Combined ab initio quantum mechanical molecular mechanical (ai-QM/MM) simulations are, in principle, the preferred choice in the modeling of both processes. But ai-QM/MM modeling of enzymatic reactions is now severely limited by its computational cost, where a direct ai-QM/MM free energy simulation of an enzymatic reaction can take 500,000 or more CPU hours. Meanwhile, ai-QM/MM modeling of firefly bioluminescence is also hindered by the computational accuracy, where it has yet to produce quantitatively correct predictions for the bioluminescence spectral shift with site-directed mutagenesis. The goal of this proposal is to accelerate ai-QM/MM simulations of enzymatic reaction free energy and to improve the quality of ai-QM/MM-simulated bioluminescence spectra, so that ai-QM/MM simulations can be routinely performed by experimental groups. This will be achieved via a) using a lower-level (semi-empirical QM/MM) Hamiltonian for sampling; b) an enhancement to the similarity between the two Hamiltonians by calibrating the low-level Hamiltonian using the reaction pathway force matching approach, in conjunction with several other methods. The expected outcomes of this collaborative effort include: a) advanced methodologies for accelerated reaction free energy simulations and accurate bioluminescence spectra predictions, which will be released through multiple software platforms; b) a fundamental understanding of reactions such as Kemp elimination and polymerase-eta catalyzed DNA replication; c) a deeper insight into the role of macromolecular environment in the modulation of enzyme catalytic activities or bioluminescence wavelengths, which can further enhance our capability of designing new enzymes and bioluminescence probes. Narrative This project aims to develop quantum-mechanics-based computational methods to more quickly model enzymatic reactions and more accurately model bioluminescence spectra. It will lead to reliable and efficient computational tools for use by the general scientific community. It will facilitate the probe of enzymatic reaction mechanisms and the computer-aided design of new bioluminescence probes.",Multiscale Modeling of Enzymatic Reactions and Firefly Bioluminescence,10021018,R01GM135392,"['Adopted', 'Biochemical Reaction', 'Bioluminescence', 'Calibration', 'Communities', 'Computer Simulation', 'Computer software', 'Computer-Aided Design', 'Computing Methodologies', 'DNA biosynthesis', 'DNA-Directed DNA Polymerase', 'Electrostatics', 'Environment', 'Enzymes', 'Evaluation', 'Fireflies', 'Free Energy', 'Freedom', 'Generations', 'Goals', 'Hour', 'Ions', 'Life', 'Machine Learning', 'Mechanics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Multienzyme Complexes', 'Outcome', 'Pathway interactions', 'Polymerase', 'Process', 'Protocols documentation', 'Quantum Mechanics', 'Reaction', 'Resources', 'Role', 'Sampling', 'Site-Directed Mutagenesis', 'System', 'Temperature', 'Thermodynamics', 'Time', 'base', 'computerized tools', 'cost', 'design', 'experimental group', 'improved', 'innovation', 'insight', 'multi-scale modeling', 'mutant', 'quantum', 'simulation', 'theories']",NIGMS,UNIVERSITY OF OKLAHOMA NORMAN,R01,2020,255238,-0.02272406109198158
"New Photo-Acoustic Imaging Process in Fetal Monitoring to Dramatically Reduce Brain Injuries in Newborns PROJECT SUMMARY Summary The Brimrose Technology Corporation and Johns Hopkins University are forming a powerful new team to make a new instrument that has the potential to dramatically reduce a major global health problem–perinatal hypoxic- ischemic encephalopathy (HIE)–by enabling early detection during labor. HIE caused by asphyxia is a leading cause of infant fatalities as well as a source of cerebral palsy and other long-term severe neurologic impairments. The medical community has been limited in early diagnosis of HIE because current fetal heart rate monitoring has poor specificity. If identified early, HIE can be treated effectively with therapeutic hypothermia. We are proposing a fetal photoacoustic monitoring system that measures oxyhemoglobin saturation of the sagittal sinus vein draining the fetal cerebral cortex during labor. Sagittal sinus oxyhemoglobin saturation decreases to very low levels when placental gas exchange is impaired (hypoxia) and/or when fetal cerebral perfusion pressure falls (ischemia). The photoacoustic instrument transmits light through the open fontanelle or bone and into cerebral veins and tissue where ultrasound waves are generated. Using near- infrared incident light at discrete wavelengths that are absorbed preferentially by oxy- and deoxy-hemoglobin, ultrasound detected on the fetal scalp at each wavelength can estimate oxyhemoglobin saturation. Brimrose has constructed a novel ultrasound detection technology with sensitivity orders of magnitude greater than the current best-use piezo-electric sensors. This will permit the use of low-power LED light sources rather than cumbersome laser lights now employed, thereby avoiding safety goggle use and promoting greater deployment. The Hopkins team has already validated the ability of a standard photoacoustic system to accurately estimate sagittal sinus oxyhemoglobin saturation through the skull of newborn piglets. The purpose of Phase I is to demonstrate the feasibility of using safe, low power LED light sources with the new ultrasensitive ultrasound sensor to detect critically low sagittal sinus oxyhemoglobin saturation when oxygenation is manipulated. The platform will be based on in-silico simulation to optimize the acoustic and optical pathways for the skull and brain. Real-time measurements on a time scale of seconds will inform the obstetric caregiver of dynamic fluctuations of brain oxygenation during contractions. The Phase II goal is to make a miniaturized photoacoustic device prototype that can report on fetal brain oxygenation. We believe the resulting instrument will provide early detection brain HI with greater specificity and sensitivity, enabling early intervention and treatment and is potentially transferrable to a commercial model for manufacture. PROJECT NARRATIVE The Brimrose Technology Corporation and the Johns Hopkins University propose making a new instrument to potentially dramatically reduce the incidence of hypoxic-ischemic encephalopathy (HIE), which can result in mortality or lifelong disabilities. Our goal is to develop an intrapartum fetal brain monitor using photoacoustics with inexpensive, safe and clinically convenient light emitting diodes (LEDs) to noninvasively and instantaneously identify the fetus at risk for brain injury. Phase I is intended to provide a proof-of-concept using low power LED light sources and a novel ultrasensitive ultrasound detector rather than standard laser light sources and piezo-electric detectors.",New Photo-Acoustic Imaging Process in Fetal Monitoring to Dramatically Reduce Brain Injuries in Newborns,10010328,R43HD102260,"['Acoustics', 'Adult', 'Aluminum', 'Animals', 'Asphyxia', 'Auscultation', 'Biological', 'Birth', 'Blood', 'Brain', 'Brain Injuries', 'Caregivers', 'Cerebral Palsy', 'Cerebral cortex', 'Cerebral perfusion pressure', 'Cerebrum', 'Cesarean section', 'Clinical', 'Communities', 'Detection', 'Development', 'Devices', 'Discipline of Nursing', 'Discipline of obstetrics', 'Drug or chemical Tissue Distribution', 'Early Diagnosis', 'Early Intervention', 'Early treatment', 'Electricity', 'Elements', 'Engineering', 'Evaluation', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Gases', 'Goals', 'Hemoglobin', 'Hybrids', 'Hypoxia', 'Imaging Device', 'Impairment', 'Incidence', 'Infant', 'Intention', 'Intervention', 'Ischemia', 'Laboratories', 'Lasers', 'Legal patent', 'Light', 'Live Birth', 'Machine Learning', 'Maternal-fetal medicine', 'Measurement', 'Measures', 'Medical', 'Medicine', 'Metabolic acidosis', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Neodymium', 'Neonatal', 'Neurologic', 'Newborn Infant', 'Noise', 'Optics', 'Oxyhemoglobin', 'Pathway interactions', 'Perinatal anoxic ischemic brain injury', 'Phase', 'Physiologic pulse', 'Physiology', 'Preparation', 'Procedures', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Safety', 'Sagittal Sinus', 'Scalp structure', 'Sensitivity and Specificity', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Source', 'Specificity', 'Structure of fontanel of skull', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translations', 'Ultrasonic wave', 'Ultrasonography', 'Universities', 'Validation', 'Veins', 'Venous', 'Yttrium', 'absorption', 'base', 'bone', 'cerebral oxygenation', 'cerebral vein', 'chromophore', 'commercialization', 'contrast imaging', 'cost', 'cranium', 'detector', 'disability', 'energy density', 'falls', 'fetal', 'fetal brain injury', 'fetus at risk', 'global health', 'hazard', 'heart rate monitor', 'imaging system', 'improved', 'in silico', 'in vivo', 'innovation', 'instrument', 'intrapartum', 'light scattering', 'machine learning method', 'microphone', 'miniaturize', 'mortality', 'natural hypothermia', 'neonatal brain', 'neonatal hypoxic-ischemic brain injury', 'novel', 'photoacoustic imaging', 'prevent', 'prototype', 'sensor', 'simulation', 'sound', 'temporal measurement', 'virtual']",NICHD,BRIMROSE TECHNOLOGY CORPORATION,R43,2020,74989,-0.021417679802643017
"The Adherence Promotion with Person-centered Technology (APPT) Project: Promoting Adherence to Enhance the Early Detection and Treatment of Cognitive Decline Many older adults experience declines in cognitive ability that can be substantial, including mild cognitive impairment and Alzheimer’s disease and AD-related dementia. Population aging, coupled with age-related cognitive impairment, including Alzheimer’s disease and other dementias, represents an unprecedented challenge. Early detection of cognitive impairment is a crucial goal. This would allow individuals at risk for mild cognitive impairment and/or AD/ADRD to adopt lifestyle changes to minimize decrements and the risk for acquired cognitive impairment. However, the massive potential of cognitive training and longitudinal assessment to detect and prevent age-related cognitive impairment and dementia are unlikely to be realized unless individuals are willing and able to engage with these protocols for an extended period of time. Adherence to cognitive assessment and training is often poor. Addressing the gap between potential and realized benefits of early detection and prevention of cognitive impairment is an urgent goal as the population ages. The aims of the Adherence Promotion with Person-centered Technology (APPT) project are to promote early detection and treatment of age-related cognitive impairment and dementia by 1) enhancing adherence to cognitive intervention and assessment protocols, 2) improving understanding of barriers to long-term adherence, and 3) assisting in the development of algorithms for predicting and preventing adherence failures. Projects aim to investigate these issues within samples of older adults with and without cognitive impairment. Two randomized controlled trials will test an adaptive, tailored, and integrated technology support system predicted to boost adherence to cognitive protocols, over and above a simpler scheduling and reminder system over 6 months. Studies will provide valuable and generalizable insight into not only the benefits of adherence support, but also the individual difference factors that shape protocol adherence (e.g., attitudes, cognitive ability, dementia status, health status, personality, technology proficiency). Data will inform the process of identifying individuals who would benefit from additional support, and predicting and preventing extended adherence failures before they happen. By increasing adherence, these studies will help improve early detection and treatment of cognitive impairment, which will ultimately extend older adults' functional independence, improving their lives and the lives of their families, and reducing care and support resources needed to address lost independence like that associated with Alzheimer’s disease and AD-related dementia. Further, intervention studies for dementia and Alzheimer’s disease can be made more efficient through tools for identifying individuals likely to experience decline before substantial cognitive impairment has occurred. Results have implications that extend far beyond cognitive impairment; the methods and mechanisms uncovered have broad implications for technology-mediated assessment and protocols to enhance health and well-being in general. The project consists of two large randomized controlled trials and smaller needs assessment and usability studies that will guide their development and deployment. PUBLIC HEALTH RELEVANCE: The aims of the Adherence Promotion with Person-centered Technology (APPT) project are to promote early detection and treatment of age-related cognitive impairment and dementia. This project will develop Artificial Intelligence-based reminder systems to help ensure long-term engagement to home-based cognitive assessment and cognitive training protocols to be able to detect and treat cognitive impairment as soon as possible.",The Adherence Promotion with Person-centered Technology (APPT) Project: Promoting Adherence to Enhance the Early Detection and Treatment of Cognitive Decline,9986599,R01AG064529,"['Address', 'Adherence', 'Adopted', 'Age', 'Age-associated memory impairment', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Artificial Intelligence', 'Attitude', 'Caring', 'Clinical Trials', 'Cognition', 'Cognitive', 'Cognitive aging', 'Computer software', 'Coupled', 'Data', 'Dementia', 'Development', 'Early Diagnosis', 'Early treatment', 'Elderly', 'Ensure', 'Failure', 'Family', 'Goals', 'Health', 'Health Status', 'Health behavior', 'Home environment', 'Human', 'Impaired cognition', 'Individual', 'Individual Differences', 'Intervention', 'Intervention Studies', 'Interview', 'Life Style', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Needs Assessment', 'Participant', 'Personal Satisfaction', 'Personality', 'Population', 'Positioning Attribute', 'Prevention', 'Process', 'Protocols documentation', 'Randomized Controlled Trials', 'Reminder Systems', 'Research', 'Resources', 'Risk', 'Sampling', 'Schedule', 'Shapes', 'Structure', 'Support System', 'Technology', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Weight', 'aging population', 'algorithm development', 'base', 'behavioral adherence', 'cognitive ability', 'cognitive change', 'cognitive performance', 'cognitive testing', 'cognitive training', 'design', 'experience', 'functional independence', 'improved', 'insight', 'intelligent algorithm', 'mild cognitive impairment', 'mobile computing', 'next generation', 'person centered', 'prediction algorithm', 'preference', 'prevent', 'public health relevance', 'success', 'therapy design', 'tool', 'usability']",NIA,FLORIDA STATE UNIVERSITY,R01,2020,692873,-0.06228162174597681
"Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation Project Summary Neonatal endotracheal intubation (ETI) is a time-sensitive resuscitation procedure! essential for ventilation of newborns. It requires an unusually high level of skill due to the narrow airways, relatively large tongue, anterior glottic position, and low respiratory reserve of neonates (Bercic, Pocajt et al. 1978). Given the difficulty of the procedure and the high rate of complications in untrained hands, effective training is crucial. However, intubation success rates for pediatric residents are low under current resuscitation training programs and show little improvement between years 1-3 of residency (23-25%) (O'Donnell, Kamlin et al. 2006; Haubner, Barry et al. 2013). There is a pressing need to understand the factors that lead to poor training results and for innovative training modalities that can bridge the gap left by traditional training and thereby allow rapid skill acquisition. We hypothesize that current training and assessment methods suffer from 4 key weaknesses: (1) Poor realism: manikin and simulator-based training typically provide little variation in anatomy or difficulty level—key requirements for developing expertise (Dreyfus, Athanasiou et al. 1986)—and do not realistically model the look, feel, and motions of real tissue. (2) Subjective, highly variable, and resource-intensive assessment methods: training opportunities are limited by the availability of expert instructors. (3) Poor visualization: learners have poor knowledge about what went wrong and how to improve; they cannot see exactly what is going on inside the manikin or the patient and cannot directly monitor their actions relative to idealized, expert performance. (4) Assessment under artificially ideal conditions: assessments of ETI performance in classroom settings likely overestimate trainees' skill level because they do not mimic the stressors and distractions that are inherent in the real clinical environment. Technology-enhanced ETI simulators can resolve all of these key weaknesses: We have conducted preliminary work (Hahn, Li et al. 2016; Soghier, Li et al. 2014) on an augmented reality (AR (Azuma 1997)) manikin simulator driven by the motions of the trainee and physical manikin in real time that 1) provides a quantitative assessment of ETI technique and 2) allows the trainee to visualize the motion of the laryngoscope inside the manikin. The assessment score can provide feedback during the performance, as well as constitute part of the evaluation of the trainee's skill. Work under this proposal will build on this preliminary work. The specific aims are to: extend the current augmented reality (AR) manikin simulator to a virtual reality (VR) computer simulator and validate, extend and validate automated assessment and visualization algorithm for ETI, study training effectiveness by testing groups of pediatric residents across 3 years to quantify the effect of technology-enhanced methods relative to the current training regimen in terms of both intubation performance on simulators and clinical outcomes in patients, and assess performance under more realistic conditions. Project Narrative The current training and assessment of neonatal endotracheal intubation (ETI) suffers from key weaknesses of 1) poor realism of task simulators, 2) subjective, highly variable, and resource-intensive assessment methods, 3) poor visualization during simulation, and 4) assessment methods under artificially ideal conditions. This high-yield proposal will bridge the gap between training and clinical practice by using quantitative assessment tools and technology-enhanced simulation to improve ETI performance prior to patient care.",Neonatal Endotracheal Intubation: Enhancing Training Through Computer Simulation and Automated Evaluation,9967059,R01HD091179,"['Algorithms', 'Anatomy', 'Anterior', 'Assessment tool', 'Attention', 'Augmented Reality', 'Biomedical Engineering', 'Biometry', 'Childhood', 'Clinical', 'Cognitive Science', 'Computer Simulation', 'Computers', 'Data', 'Effectiveness', 'Enhancement Technology', 'Environment', 'Evaluation', 'Feedback', 'Hand', 'Intratracheal Intubation', 'Intubation', 'Knowledge', 'Laryngoscopes', 'Lead', 'Learning', 'Left', 'Libraries', 'Machine Learning', 'Manikins', 'Measures', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Motion', 'Neonatal', 'Neonatology', 'Newborn Infant', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Positioning Attribute', 'Procedures', 'Regimen', 'Residencies', 'Resources', 'Resuscitation', 'Scanning', 'Standardization', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Tongue', 'Training', 'Training Programs', 'Validation', 'Variant', 'Visualization', 'Work', 'base', 'clinical practice', 'computer science', 'distraction', 'effectiveness testing', 'evidence base', 'haptics', 'improved', 'innovation', 'instructor', 'kinematics', 'multidisciplinary', 'neonate', 'respiratory', 'simulation', 'skill acquisition', 'skills', 'stressor', 'success', 'training opportunity', 'ventilation', 'virtual reality', 'virtual reality simulator']",NICHD,GEORGE WASHINGTON UNIVERSITY,R01,2020,319874,-0.0033003311910998917
"Environmental Localization Mapping and Guidance for Visual Prosthesis Users Project Summary About 1.3 million Americans aged 40 and older are legally blind, a majority because of diseases with onset later in life, such as glaucoma and age-related macular degeneration. Second Sight has developed the world's first FDA approved retinal implant, Argus II, intended to restore some functional vision for people suffering from retinitis pigmentosa (RP). In this era of smart devices, generic navigation technology, such as GPS mapping apps for smartphones, can provide directions to help guide a blind user from point A to point B. However, these navigational aids do little to enable blind users to form an egocentric understanding of the surroundings, are not suited to navigation indoors, and do nothing to assist in avoiding obstacles to mobility. The Argus II, on the other hand, provides blind users with a limited visual representation of their surroundings that improves users' ability to orient themselves and traverse obstacles, yet lacks features for high-level navigation and semantic interpretation of the surroundings. The proposed research aims to address these limitations of the Argus II through a synergy of state-of-the-art stimultaneous localization and mapping (SLAM) and object recognition technologies. For the past three years, JHU/APL has collaborated with Second Sight to develop similar advanced vision-based capabilities for the Argus II, including capabilities for object recognition and obstacle detection by stereo vision. This proposal is driven by the hypothesis that navigation for users of retinal prosthetics can be greatly improved by incorporating SLAM and object recognition technology conveying environmental information via a retinal prosthesis and auditory feedback. SLAM enables the visual prosthesis system to construct a map of the user's environment and locate the user within that map. The system then provides object location and navigational cues via appropriate sensory modalities enabling the user to mentally form an egocentric map of the environment. We propose to develop and test a visual prosthesis system which 1) constructs a map of unfamiliar environments and localizes the user using SLAM technology 2) automatically identifies navigationally-relevant objects and landmarks using object recognition and 3) provides sensory feedback for navigation, obstacle avoidance, and object/landmark identification. Project Narrative The proposed system, when realized, will use advanced simultaneous localization and mapping, and object recognition techniques, to enable visual prosthesis users with unprecedented abilities to autonomously navigate and identify objects/landmarks in unfamiliar environments.",Environmental Localization Mapping and Guidance for Visual Prosthesis Users,10019559,R01EY029741,"['3-Dimensional', 'Address', 'Age related macular degeneration', 'Algorithms', 'American', 'Competence', 'Complex', 'Computer Vision Systems', 'Cues', 'Data', 'Dependence', 'Detection', 'Development', 'Devices', 'Disease', 'Effectiveness', 'Environment', 'Evaluation', 'FDA approved', 'Feedback', 'Glaucoma', 'Goals', 'Image', 'Implant', 'Late-Onset Disorder', 'Lead', 'Learning', 'Life', 'Location', 'Maps', 'Medical Device', 'Modality', 'Motion', 'Ocular Prosthesis', 'Patients', 'Performance', 'Psyche structure', 'Research', 'Retinitis Pigmentosa', 'Running', 'Semantics', 'Sensory', 'Societies', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Vision', 'Visual', 'Volition', 'aged', 'auditory feedback', 'base', 'behavior test', 'blind', 'cognitive load', 'falls', 'human subject', 'improved', 'innovation', 'legally blind', 'navigation aid', 'object recognition', 'portability', 'prosthesis wearer', 'prototype', 'research and development', 'retina implantation', 'retinal prosthesis', 'sensory feedback', 'smartphone Application', 'synergism', 'visual feedback', 'visual information']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2020,662134,-0.012224518482214154
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,9935719,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Asses', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2020,599090,-0.027271134907833613
"Augmented Reality System for the Education of Clinical Caregivers of Older Adults Project Summary/Abstract Proposed is a system to combine and leverage the advantages of both existing physical mannequin-based training and virtual media to support clinical learning using Augmented Reality (AR). Significance: Education in clinical settings is often challenging, infeasible, risky, difficult to organize, time-consuming, and expensive. Due to these barriers, the value of mannequin-based simulation is well recognized and is incorporated extensively into medical education. In general, the purpose of mannequin use in education is to simulate a physical ""patient"" on which to learn, demonstrate, and test skill without fear of harming patients prior to entering clinical environments. Despite their substantial benefits, physical mannequins have several fundamental limitations that do not allow them to demonstrate the many unique phases and expressions of a disease or person-to-person differences in anatomy and physiology. This limits the ability for a learner to view dynamic changes over time and to explore disease progression and consequences of interventions. Hypothesis: This research hypothesizes that existing, current mannequins can be enhanced through an innovative and practical Augmented Reality solution. In the Phase I effort a prototype system and sample educational material covering Pressure Ulcer care was developed and analyzed through pilot studies with Nursing educators, Doctoral Degree in Nursing (DNP) students, and pre-licensure students. The pilot results of the technology demonstrated a high degree of positivity and exceptional enthusiasm and all Phase I metrics of success were met or exceeded. Specific Aims: In Phase II the following aims are proposed: 1) Design a comprehensive suite of course content and design the technology's integration into a College of Nursing course, 2) Develop a production-ready system, and 3) Validate the system utility through human subject testing and expert evaluation of the system. Project Narrative Over the past decade, medical simulation has been experiencing explosive growth and widespread adoption. There are now over 800 medical simulation centers in the US alone, located in medical schools, nursing schools, hospitals, military simulation centers, and schools of allied health professions. The global market for Mannequin-Based Simulation is projected to reach $1 Billion by 2020. It is hypothesized that the combination of existing physical mannequin-based training with virtual media will open new possibilities for exploration and enhanced learning interactions for medical education. 3T",Augmented Reality System for the Education of Clinical Caregivers of Older Adults,9964623,R44AG057257,"['Adoption', 'Adult', 'Algorithmic Software', 'Allied Health Profession', 'Anatomy', 'Area', 'Augmented Reality', 'Caregivers', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Course Content', 'Development', 'Discipline of Nursing', 'Disease', 'Disease Progression', 'Dissection', 'Doctor&apos', 's Degree', 'Education', 'Educational Curriculum', 'Educational Materials', 'Elderly', 'Environment', 'Evaluation', 'Focus Groups', 'Fright', 'Goals', 'Growth', 'Hospitals', 'Hour', 'Human', 'Image', 'Individual', 'Intervention', 'Laboratories', 'Learning', 'Licensure', 'Location', 'Manikins', 'Medical', 'Medical Education', 'Military Personnel', 'Minnesota', 'Modeling', 'Movement', 'Nursing Faculty', 'Nursing Schools', 'Nursing Students', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Production', 'Research', 'Sampling', 'School Nursing', 'Schools', 'Scientist', 'Severity of illness', 'Skin', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'animation', 'base', 'caregiver education', 'college', 'commercialization', 'cost', 'decubitus ulcer', 'design', 'experience', 'flexibility', 'human subject', 'impression', 'innovation', 'medical schools', 'miniaturize', 'person centered', 'professor', 'programs', 'prototype', 'simulation', 'skills', 'success', 'teacher', 'virtual']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2020,688185,-0.020934318102256644
"Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences Abstract A major approach in causal inference literature aimed at mitigating bias due to unmeasured confounding is the so- called instrumental variable (IV) design which relies on identifying a variable which (i) influences the treatment process, (ii) has no direct effect on the outcome other than through the treatment, and (iii) is independent of any unmeasured confounder. IV methods are very well developed and widely used in social and health science, although validity of IV inferences may not be reliable if any of required assumptions (i)-(iii) is violated. This proposal aims to develop (a) new IV methods robust to violation of any of (i)-(iii); (b) New negative control methods that can be used to detect and sometimes to nonparametrically account for unmeasured confounding bias; (c) New bracketing methods for partial inference about causal effects in comparative interrupted time series studies. The proposed methods will be used to address current scientific queries in three major substantive public health areas:(1) to understand the health effects of air pollution; (2) to quantify the causal effects of modifiable risk factors for Alzheimer's disease and related disorders; (3) To uncover the mechanism by which a randomized package of interventions produced a substantial reduction of HIV incidence in a recent major cluster randomized trial of treatment as prevention in Botswana, Africa. Our proposal will provide the best available analytical methods to date to resolve confounding concerns in these high impact public health applications and more broadly in observational studies in the health sciences. Summary This proposal aims to develop new causal inference methods to tame bias due to hidden confounding factors in obser- vational studies as well as in randomized experiments subject to non-adherence. The proposed methods are firmly grounded in modern semiparametric theory which will be used to obtain more robust and efficient inferences about causal effects in a broad range of public health applications including in Epidemiology of Aging, Environmental Health Epidemiology and HIV/AIDS Prevention.",Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences,9859751,R01AG065276,"['AIDS prevention', 'Address', 'Adherence', 'Africa', 'Aging', 'Air Pollution', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Area', 'Blood Pressure', 'Botswana', 'Clinical Treatment', 'Cluster randomized trial', 'Data', 'Diabetes Mellitus', 'Disease', 'Environmental Health', 'Epidemiology', 'Genetic', 'HIV', 'Health', 'Health Sciences', 'Incidence', 'Interruption', 'Intervention', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Masks', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Observational Study', 'Outcome', 'Participant', 'Prevention', 'Process', 'Public Health', 'Public Health Applications Research', 'Randomized', 'Research Design', 'Research Personnel', 'Risk Factors', 'Series', 'Social Sciences', 'Testing', 'Thromboplastin', 'Time', 'ambient air pollution', 'analytical method', 'c new', 'comparative', 'design', 'experimental study', 'genetic variant', 'high dimensionality', 'intervention effect', 'modifiable risk', 'mortality', 'novel', 'pleiotropism', 'semiparametric', 'simulation', 'theories', 'treatment effect', 'uptake', 'user friendly software']",NIA,UNIVERSITY OF PENNSYLVANIA,R01,2020,502013,-0.02741835760393823
"Development of a visual-to-tactile conversion system for automating tactile graphic generation process PROJECT SUMMARY/ABSTRACT There are an estimated 23.7 million people who are blind or visually-impaired (BVI) in the U.S. and 285 million globally. Of this population, 30% do not travel independently outside of their home, only ~11% have a bachelor’s degree, and more than 70% are unemployed. The goal of this SBIR effort is to develop a novel system, which performs principled down-sampling and translation of visual information from digital documents into tactile equivalents. Timely access to information is one of the biggest challenges for BVI people. While access to textual information has largely been solved via screen reading software (e.g., JAWS or VoiceOver), very little progress has been made in making graphical information accessible. Although few assistive technology (AT) devices aim provide non-visual graphical access, they suffer from several shortcomings including high cost, limited portability, lack of multi-purpose, and inability to present information in a real-time context. Importantly, a common underlying problem across all extant approaches is that they require intensive human effort for producing or authoring tactile (and/or multimodal) graphics, which leads to high production costs and significant delays in the time between when the accessible materials are needed, and when they are actually delivered, adversely impacting BVI individuals in K-12 schools, colleges, and workplace settings. To address this long-standing problem, UNAR Labs aims to develop a novel system, which will automatically down-sample and translate visual graphical information into an intuitive tactile equivalent that can be used in tactile embossers. Building upon eight years of empirical research, this Phase I SBIR effort will prove the technical feasibility and functional viability of a prototype system for automating visual-to-tactile graphic conversion process and using the output in embossers. Two specific aims will guide this Phase I project: (1) to develop a prototype of an automated system for performing visual-to-tactile conversion without human intervention, and (2) to assess the technical feasibility and functional utility of the system through a rigorous human study. Success in this effort will provide a robust automated system for tactile graphic generation and promote empowerment of millions of BVI individuals by supporting increased educational attainment, proliferation of vocational opportunities, and enhancing overall quality of life for BVI people. PROJECT NARRATIVE Lack of equitable and timely access to information among persons who are blind or visually impaired (BVI) is key to realizing an inclusive world for all as it alleviates a known impediment that is hugely detrimental to their success in activities affecting quality of life and socio-economic status. The proposed innovation presents a first- of-its kind on-demand visual-to-tactile translation system, which will fully automate the tactile graphic generation process using bio-inspired sensory substitution rules and will instantly deliver the translated information for use in tactile embossers. Successful completion of this project will significantly reduce tactile graphic production costs and preparation time, and will promote empowerment of millions of BVI individuals by supporting increased educational attainment, vocational opportunities, and overall better quality of life.",Development of a visual-to-tactile conversion system for automating tactile graphic generation process,10008494,R43EY031628,"['Access to Information', 'Address', 'Adoption', 'Affect', 'Bachelor&apos', 's Degree', 'Benchmarking', 'Braille Display', 'Characteristics', 'Cognitive', 'Computer software', 'Computers', 'Data', 'Development', 'Devices', 'Elements', 'Empirical Research', 'Evaluation', 'Floor', 'Generations', 'Goals', 'Graph', 'Home environment', 'Human', 'Individual', 'Information Retrieval', 'Intervention', 'Intuition', 'Maine', 'Maps', 'Nature', 'Output', 'Performance', 'Persons', 'Phase', 'Plant Roots', 'Population', 'Preparation', 'Process', 'Production', 'Productivity', 'Psychophysics', 'Quality of life', 'Readability', 'Reading', 'Research', 'Route', 'Sampling', 'Schools', 'Self-Help Devices', 'Sensory', 'Small Business Innovation Research Grant', 'Socioeconomic Status', 'Software Framework', 'Support System', 'System', 'Tactile', 'Text', 'Time', 'Touch sensation', 'Translating', 'Translations', 'Unemployment', 'Universities', 'Visual', 'Visual impairment', 'Visually Impaired Persons', 'Work', 'Workplace', 'base', 'blind', 'braille', 'college', 'cost', 'data modeling', 'deep learning', 'digital', 'empowerment', 'human study', 'innovation', 'multimodality', 'multisensory', 'novel', 'operation', 'portability', 'prototype', 'success', 'touchscreen', 'usability', 'visual information', 'visual learning']",NEI,"UNAR LABS, LLC",R43,2020,300000,-0.0196067523029769
"A Novel Informatics System for Craniosynostosis Surgery Project Summary CranioSynOstosis (CSO) is the premature fusion of one or more of cranial sutures that connect individual skull bones for kids. The estimated prevalence of CSO is one in 2500 live births and even higher. Our ultimate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). CSO is an extremely serious birth defect that involves the premature fusion, of one or more sutures on a baby's skull. CSO, in terms of the fused suture, could be classified mainly into several types of synostosis, such as sagittal, coronal, metopic, and lambdoid. Infants with CSO may have problems with brain and skull growth, resulting in cognitive impairment. This defect may not only ruin the infant's life, but also deeply affect the infant's family. SAS, recognized as a safe, effective, and less invasive treatment method, introduced to treat the CSO. This treatment uses the force of a spring to reshape the skull in a slower manner that harnesses the growth of the skull to assist with shape change. Patient-specific spring selection is the principal barrier to the advancement of SAS for CSO because few surgeons have the experience to select personalized springs for each patient. The selection of the spring force is a crucial step in this surgical treatment, and it is dependent on the experience of the surgeon. Important factors essential in the selection of the spring force include the ages, bone thickness and the subtypes of CSO. One example is that sagittal CSO with an elongated occiput needs a stronger posterior spring, while one with no predominant characteristics typically needs a mid-range anterior and posterior spring. The current problem is that we do not have a complete objective way of classification of CSO and sagittal CSO and estimation of the spring force for the individual. Our hypothesis is that CSO and sagittal CSO can be accurately classified based on the features from sutures and head shape, and behaviors of calvarial bone tissue following virtual optimal spring force can be accurately simulated by integrating a finite element method (FEM) with statistical learning model. To test our hypothesis, we are proposing the following Specific Aim: (1) To define the eSuture Informatic system and build the database, with CT and DTI data; (2) To develop tools for image processing, segmentation, registration, quantification of sutures, and automatically categorize each patient to one catalogue of the CSO types or sagittal CSO subtype; (3) To model and estimate the optimal spring force for SAS; and (4) To validate and evaluate the eSuture system. Our system will produce a paradigm shift in CSO diagnosis and treatment. Narrative Our immediate goal is to develop an open-source imaging-informatics-platform, eSuture, for clinicians to objectively classify the craniosynostosis (CSO) using computed tomography (CT) data, and accurately estimate patient-specific spring force for spring-assisted surgery (SAS). If successful, the system will significantly improve clinical diagnosis, treatment and surgery for children with CSO disease.",A Novel Informatics System for Craniosynostosis Surgery,9970217,R01DE027027,"['3-Dimensional', 'Accounting', 'Affect', 'Anterior', 'Attention', 'Baptist Church', 'Behavior', 'Biomechanics', 'Bone Tissue', 'Brain', 'Calvaria', 'Catalogs', 'Cephalic', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Congenital Abnormality', 'Congenital abnormal Synostosis', 'Craniosynostosis', 'Data', 'Databases', 'Defect', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Family', 'Goals', 'Growth', 'Head', 'Hospitals', 'Imaging Device', 'Impaired cognition', 'Individual', 'Infant', 'Informatics', 'Joint structure of suture of skull', 'Life', 'Live Birth', 'Machine Learning', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Patients', 'Prevalence', 'Property', 'Regression Analysis', 'Scanning', 'Shapes', 'Surface', 'Surgeon', 'Surgical sutures', 'System', 'Testing', 'Thick', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'bone aging', 'clinical Diagnosis', 'cranium', 'experience', 'feature extraction', 'feature selection', 'forest', 'image processing', 'imaging informatics', 'improved', 'indexing', 'innovation', 'novel', 'novel strategies', 'occipital bone', 'open source', 'premature', 'segmentation algorithm', 'statistical learning', 'tool', 'vector', 'virtual']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2020,371369,-0.01246562605029165
"Robust biomimetic models of human legs to solve high-dimensional real-time control problems Project Summary  Anatomically validated musculoskeletal models of human limbs computed faster than real-time are tools that will help advance the control of neuroprosthetics, rehabilitation, and the study of motor control principles. However, the current state-of-the-art models cannot be both accurate and fast. We propose to develop a new generation of validated real-time human leg models with musculoskeletal dynamics that are robust over the full range of multidimensional motion. The first aim is to validate a lower-limb model in the full range of static postures. The second aim is to validate a lower-limb model during dynamic locomotor tasks.  Building on our previous work, we will use OpenSim model repository as a starting point for the iterative process of validating the muscle anatomy and function using published anatomical data. We expect to recreate the full range of leg postures with the validated model. We will then collect data during locomotor tasks performed by healthy humans on the split-belt treadmill with simultaneous re- cordings of ground reaction forces, full-body motion capture, and surface electromyography from rep- resentative leg muscles. The model will be validated over a rich experimental dataset for locomotor pat- terns required in asymmetric stepping on a self-paced treadmill. We expect to validate the dynamic model by estimating in real-time the observed full body kinematics from muscle activity and ground reaction forces. The inverse solutions will allow us to estimate the ongoing spatiotemporal patterns of muscle activity.  At the conclusion of this study we will develop the detailed lower-limb model with high-di- mensional robust muscle path simulations to predict limb motion in real-time. The outcomes of this proposal will inform future work on the use of the real-time musculoskeletal models for the develop- ment of augmentation devices and the clinical assessment of locomotor deficits. Project Narrative The significance of this project is that it will address the major challenges in achieving intuitive human-computer interactions by allowing the simulation of high-dimensional muscle dynamics in real-time. The main innovation of this proposal is the rigorous validation of human leg model across large anthropomorphic variations (due to age and sex) and the robust performance using novel method for musculoskeletal simulations.",Robust biomimetic models of human legs to solve high-dimensional real-time control problems,9979392,R03HD099426,"['Address', 'Age', 'Anatomy', 'Articular Range of Motion', 'Basic Science', 'Behavioral', 'Biological', 'Biomimetics', 'Clinical', 'Clinical assessments', 'Data', 'Data Set', 'Development', 'Devices', 'Electric Stimulation', 'Electromyography', 'Engineering', 'Ensure', 'Evaluation', 'Exercise Physiology', 'Failure', 'Funding Opportunities', 'Future', 'Generations', 'Goals', 'Grant', 'Hand', 'Human', 'Intuition', 'Joints', 'Leg', 'Length', 'Limb Prosthesis', 'Limb structure', 'Lower Extremity', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Morphology', 'Motion', 'Movement', 'Muscle', 'Musculoskeletal', 'Musculoskeletal System', 'Neuromechanics', 'Orthopedics', 'Outcome', 'Participant', 'Pathway interactions', 'Pattern', 'Performance', 'Physical therapy', 'Polynomial Models', 'Posture', 'Process', 'Prosthesis', 'Publishing', 'Reaction', 'Rehabilitation therapy', 'Reproducibility', 'Research', 'Signal Transduction', 'Slide', 'Speed', 'Surface', 'Technology', 'Testing', 'Time', 'Upper Extremity', 'Validation', 'Variant', 'Work', 'arm', 'base', 'computer human interaction', 'high dimensionality', 'human model', 'innovation', 'kinematics', 'locomotor deficit', 'locomotor tasks', 'model development', 'motor control', 'neuroprosthesis', 'novel', 'real time model', 'relating to nervous system', 'repository', 'sex', 'simulation', 'spatiotemporal', 'tool', 'treadmill']",NICHD,WEST VIRGINIA UNIVERSITY,R03,2020,76000,-0.02129076645244467
"MUFA-SIRT1 signaling as a central node regulating healthspan PROJECT SUMMARY Macronutrients serve a multitude of roles beyond provision of energy, with numerous nutrients and/or their downstream metabolites acting as signaling molecules to coordinate cellular metabolism and function. Indeed, numerous nutrient sensing pathways (e.g. mTOR, AMPK and sirtuins) have evolved allowing us to respond to specific nutrients/metabolites, which in turn impacts healthspan. Sirtuins are largely thought to be driven by redox, whereby high levels of NAD, a cofactor in the sirtuin reaction and indicator of low energy charge, drives sirtuin-catalyzed deacylation of target proteins. SIRT1, the most-studied sirtuin, is a key nutrient sensing node that regulates a plethora of cellular functions to promote lifespan extension and healthy aging. As a result, there is immense interest in the use of SIRT1 activating compounds (STACs) to prevent or treat a wide range of aging-related disease. The links between dietary macronutrients, nutrient sensing and healthspan have historically focused upon caloric or protein restriction with limited attention given to dietary lipids. However, a small and growing body of literature has linked monounsaturated fatty acids (MUFAs) to improved healthspan. In addition to positive effects on lifespan and healthy aging in model organisms, dietary MUFAs have been linked to wide-ranging health benefits in epidemiological studies and, since they are a primary constituent of olive oil, thought to contribute to the benefits of the Mediterranean Diet. Despite these studies, little is known about the biological underpinnings through which MUFAs elicit their beneficial health effects. We have previously shown that lipid droplet catabolism (i.e. lipolysis) increases SIRT1 and downstream PGC-1a/PPAR- a signaling as a means to increase mitochondrial biogenesis and function during times of nutrient deprivation. Our preliminary data show for the first time that MUFAs released specifically from lipolysis are trafficked to the nucleus where they allosterically activate SIRT1 towards select acetylated peptide substrates. This discovery makes MUFAs the first-known endogenous allosteric activators of SIRT1. Moreover, we show that MUFAs activate SIRT1 through a similar mechanism to resveratrol suggesting that MUFA signaling may modulate the response to exogenous SIRT1 activators. Based on these preliminary data, the objective of this application is to further characterize the role of MUFAs as endogenous SIRT1 activators. We hypothesize that MUFAs selectively activate SIRT1 to modulate the response to numerous dietary interventions known to impact healthspan. To test our objective, we propose the following aims: Aim 1: To define how MUFAs modulate SIRT1 substrate selectivity. Aim 2: To characterize the SIRT1-dependent effects of MUFAs/olive oil on healthspan. Aim 3: To determine the contribution of MUFAs in mediating the response to STACs or caloric restriction. Upon completion of the proposes studies, we will have further expanded our understanding of SIRT1 biology allowing for refined approaches to activate SIRT1 to promote healthy aging. NARRATIVE The proposed studies will advance our understanding into the underlying biology linking dietary factors to healthspan. The data gleaned from these studies will help refine therapeutic or nutritional avenues to modulate lifespan and aging-related diseases resulting in a direct, positive impact on human health.",MUFA-SIRT1 signaling as a central node regulating healthspan,10092409,R01AG069768,"['Aging', 'Animal Model', 'Animals', 'Attention', 'Biogenesis', 'Biological', 'Biology', 'Caloric Restriction', 'Catabolism', 'Cell Nucleus', 'Cell physiology', 'Charge', 'Clinical Trials', 'Data', 'Deacetylation', 'Development', 'Diet', 'Dietary Factors', 'Dietary Fats', 'Dietary Intervention', 'Disease', 'Dose', 'FRAP1 gene', 'Fasting', 'Glean', 'Gold', 'Health', 'Health Benefit', 'Human', 'Link', 'Lipids', 'Lipolysis', 'Literature', 'Longevity', 'Machine Learning', 'Macronutrients Nutrition', 'Maps', 'Mediating', 'Mediterranean Diet', 'Metabolism', 'Mitochondria', 'Modeling', 'Monounsaturated Fatty Acids', 'Mus', 'Nutrient', 'Nutritional', 'Oils', 'Olive oil preparation', 'Olives - dietary', 'Outcome', 'Oxidation-Reduction', 'PPAR alpha', 'Pathway interactions', 'Peptides', 'Pharmacologic Substance', 'Proteins', 'Proteomics', 'Reaction', 'Research', 'Resveratrol', 'Role', 'SIRT1 gene', 'Signal Transduction', 'Signaling Molecule', 'Sirtuins', 'Source', 'Testing', 'Therapeutic', 'Time', 'Work', 'analog', 'base', 'cofactor', 'deacylation', 'detection of nutrient', 'epidemiology study', 'healthspan', 'healthy aging', 'improved', 'innovation', 'interest', 'middle age', 'mutant mouse model', 'novel', 'nutrient deprivation', 'polyphenol', 'prevent', 'red wine', 'response']",NIA,UNIVERSITY OF MINNESOTA,R01,2020,315700,-0.03718134169694972
"PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site Project Summary Physical activity (PA) prevents or ameliorates a large number of diseases, and inactivity is the 4th leading global mortality risk factor. The molecular mechanisms responsible for the diverse benefits of PA are not well understood. The Molecular Transducers of Physical Activity Consortium (MoTrPAC) is being formed to advance knowledge in this area. We propose to establish PAGES, a Physical Activity Genomics, Epigenomics/transcriptomics Site as an integral component of the MoTrPAC. PAGES will conduct comprehensive analyses of the rat and human PA intervention MoTrPAC samples, contribute these data to public databases, help identify candidate molecular transducers of PA and elucidate new PA response mechanisms, and help develop predictive models of the individual response to PA. PAGES assay sites at Icahn School of Medicine at Mount Sinai, New York Genome Center and Broad Institute provide the infrastructure, expertise and experience to support this large scale, comprehensive analysis of molecular changes associated with PA. PAGES aims are to 1. Work with the MoTrPAC Steering Committee in Year 1 to finalize plans and protocols; 2. Perform assays and analyses to help Identify candidate molecular transducers of the response to PA in rat models and the pathways responsible for model differences, including high-depth RNA-seq and Whole Genome Bisulfite Sequencing (WGBS), supplemented by additional assay types such as ChIP-seq, ATAC-seq based on initial results; 3. Perform comprehensive assays and analyses of the human MoTrPAC clinical study tissue samples, including RNA-seq, WGBS, H3K27ac ChIP-seq, ATAC-seq and whole genome sequencing. 4. Collaborate with the MoTrPAC to analyze data from PAGES and other MoTrPAC analysis sites to identify candidate PA transducers and molecular mechanisms, and to develop predictive models of PA capacity and response to training. The success of PAGES and the MoTrPAC program will transform insight into the molecular networks that transduce PA into health, create an unparalleled comprehensive public PA data resource, and can provide the foundation for profound advances in the prevention and treatment of many major human diseases. Project Narrative While physical activity prevents or improves a large number of diseases, the chemical changes that occur in the body and lead to better health are not well known. As a part of a consortium of physical activity research programs working together, we will use cutting-edge approaches to comprehensively study the changes in genes and gene products caused by physical activity. This study has the potential to lead to advances in the prevention and treatment of many diseases.","PAGES: Physical Activity Genomics, Epigenomics/transcriptomics Site",9840897,U24DK112331,"['ATAC-seq', 'Area', 'Bioinformatics', 'Biological Assay', 'Budgets', 'ChIP-seq', 'Chemicals', 'Chromatin', 'Clinical Research', 'Collaborations', 'Cost efficiency', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Databases', 'Deposition', 'Development', 'Disease', 'Elements', 'Foundations', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Individual', 'Infrastructure', 'Institutes', 'Knowledge', 'Lead', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Analysis', 'New York', 'Ontology', 'Pathway interactions', 'Physical activity', 'Pilot Projects', 'Prevention', 'Production', 'Protocols documentation', 'Rat Strains', 'Rattus', 'Research Activity', 'Risk Factors', 'Sampling', 'Scientist', 'Site', 'Tissue Sample', 'Tissues', 'Training', 'Training Activity', 'Transducers', 'Universities', 'Validation', 'Work', 'analysis pipeline', 'base', 'bisulfite sequencing', 'data exchange', 'data resource', 'epigenomics', 'exercise intervention', 'experience', 'fitness', 'gene product', 'genome sequencing', 'high throughput analysis', 'human data', 'human disease', 'improved', 'individual response', 'insight', 'machine learning algorithm', 'medical schools', 'methylome', 'mortality risk', 'predictive modeling', 'prevent', 'programs', 'response', 'sedentary', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'web page', 'web portal', 'whole genome']",NIDDK,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U24,2020,4401725,-0.016738689914551214
"RNA Sequencing Via Single Reverse Transcript Assessments Project Summary While very substantial progress has been made over the last 10 or so years with regards to next generation sequencing (NGS) and third generation sequencing (TGS) of DNA, the development of novel and enabling tool sets for RNA sequencing has lagged significantly. During this project, we aim to make significant progress with regards to that gap by developing and validating an entirely new solid-state sequencing platform, developed specifically and ideally for direct RNA sequencing, including its structural complexities and nucleotide modifications, all with high accuracy. While there are over 100 known RNA nucleotide modifications, due to the lack of analytical characterization methods available, the exact roles of these modifications remain to be determined. The technology that will be developed during the project will be capable of elucidating the roles of these modifications, and revolutionizing our understanding and use of the transcriptome/epitranscriptome. Project Narrative A method/technology capable of directly (without transcription) sequencing RNA, with extremely high accuracy and the inherent ability to identify nucleotide modifications, has the potential to revolutionize the use of the transcriptome and epitranscriptome, radically change standard R&D practices, as well as enable revolutionary diagnostics and therapeutics. The entirely new direct RNA sequencing methodology/technology that will be developed during this project will overcome known hurdles and limitation with currently available NGS, TGS, and single-molecule sequencing (SMS) approaches, resulting in technology that is cost efficient, highly accurate, easy-to setup and utilize, capable of de novo sequencing and modified base calling, and capable of producing highly simplistic data for easy analysis and post possessing.",RNA Sequencing Via Single Reverse Transcript Assessments,9961426,R43HG011070,"['Biological', 'Biological Sciences', 'Caliber', 'Carbon Nanotubes', 'Chemistry', 'Complex', 'DNA', 'DNA sequencing', 'DNA-Directed RNA Polymerase', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Devices', 'Diagnostic', 'Drops', 'Electrodes', 'Enzymes', 'Evaluation', 'Future', 'Genetic Transcription', 'Genomics', 'Geometry', 'Glass', 'Goals', 'Individual', 'Inosine', 'Ions', 'Label', 'Length', 'Lipid Bilayers', 'Logistics', 'Machine Learning', 'Measurement', 'Mediating', 'Methodology', 'Methods', 'Modification', 'Monitor', 'Motor', 'Movement', 'Noise', 'Nucleotides', 'Phase', 'Polymerase', 'Preparation', 'Process', 'Proteins', 'Pseudouridine', 'RNA', 'RNA primers', 'RNA-Directed DNA Polymerase', 'Reader', 'Reading Frames', 'Reproducibility', 'Risk', 'Role', 'Sampling', 'Series', 'Side', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'Systems Development', 'Technology', 'Therapeutic', 'Third Generation Sequencing', 'Time', 'Transcript', 'Transistors', 'Variant', 'base', 'clinical diagnostics', 'complex data ', 'cost', 'cost efficient', 'electric field', 'epigenomics', 'epitranscriptome', 'epitranscriptomics', 'experimental study', 'improved', 'infancy', 'nanopore', 'neural network', 'new technology', 'next generation sequencing', 'novel', 'programs', 'research and development', 'sequencing platform', 'single molecule', 'solid state', 'tool', 'transcriptome', 'transcriptome sequencing', 'transcriptomics']",NHGRI,"ELECTRONIC BIOSCIENCES, INC.",R43,2020,279999,-0.030439433729889796
"Development and Validation of a Collaborative Web/Cloud-Based Dosimetry System for Radiopharmaceutical Therapy. Project Summary  Radiopharmaceutical therapy (RPT) – the use of targeted radionuclides to deliver radiation specifically to cancer cells and their microenvironment – is a fundamentally different approach to cancer therapy that is growing, with a substantial number of large and small pharmaceuticals companies developing products in this area and radionuclide producers making substantial investments in scaling up production. This is especially true in the area of alpha emitters. The dosimetric evaluation of therapeutic radiopharmaceuticals is a key requirement for regulatory approval and optimal administration of RPTs, especially in combination with external beam radiation therapy. This project will provide a cloud-based dosimetry software service, delivered through a web-browser, that includes the full complement of methods needed for dosimetry in the context of obtaining regulatory approval of RPTs and, ultimately, for optimal clinical delivery. Providing this in a cloud-based system will enable a variety of models for selling the service that do not require a large up-front capital investment for clinics or radiopharmaceutical developers. It also will provide access to expert advice, customization, and dosimetry services, and allow for collaboration between developers, dosimetry experts, and clinical sites. To accomplish the goal of developing this cloud-based web-browser-delivered RPT dosimetry software service, we propose the following specific aims: (1) Design, develop and implement a web/cloud-based integrated software system for treatment planning of RPT therapy; (2) design and implement a full server-side framework for subscription, authentication, and granting collaborative privileges for the various processes and data in the dosimetry pipeline; (3) optimize and adapt the four most computationally intensive processes for a multi-processor cloud-based compute environment; (4) apply and evaluate the toolchain developed in aims 1-3 to phantom, simulated and existing patient data. Successful completion of this project will produce a cloud-based software system delivered to the user via a web browser that provides an integrated, streamlined, robust, state-of-the-art system for RPT treatment planning. This system would enable a collaborative approach to multi-center clinical trials and eventually to clinical delivery of optimally dosed RPT. Projective Narrative  Radiopharmaceutical therapy is an emerging cancer therapy modality involving the targeted delivery of radiation to tumors using tumor-targeting molecules. The dosimetric evaluation of the therapeutic radiopharmaceuticals is a key requirement for regulatory approval and optimal administration of RPTs. This project seeks to develop a cloud-based software system delivered to the user via a web browser that provides an integrated, streamlined, robust, state-of-the-art system for RPT treatment planning; and enables a collaborative approach to multi-center clinical trials and eventually to the clinical delivery of optimally dosed RPT.",Development and Validation of a Collaborative Web/Cloud-Based Dosimetry System for Radiopharmaceutical Therapy.,10019481,R44CA213782,"['3-Dimensional', 'Architecture', 'Area', 'Big Data', 'Biological', 'Businesses', 'Capital', 'Client', 'Clinic', 'Clinical', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Complement', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Collection', 'Development', 'Dose', 'Dose-Rate', 'Environment', 'External Beam Radiation Therapy', 'Generations', 'Goals', 'Grant', 'Growth', 'Health', 'Individual', 'Infrastructure', 'Internet', 'Investments', 'Licensing', 'Methods', 'Modality', 'Modeling', 'Multi-Institutional Clinical Trial', 'Online Systems', 'Pathway interactions', 'Patients', 'Pharmacologic Substance', 'Phase', 'Privacy', 'Process', 'Production', 'Radiation', 'Radioisotopes', 'Radiopharmaceuticals', 'Research Personnel', 'Running', 'Services', 'Side', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'System', 'Systemic disease', 'Translating', 'Treatment Protocols', 'Uncertainty', 'Validation', 'Vendor', 'Work', 'analysis pipeline', 'base', 'cancer cell', 'cancer therapy', 'clinical application', 'clinical research site', 'cloud based', 'collaborative approach', 'computing resources', 'cost effective', 'data de-identification', 'data sharing', 'deep learning', 'design', 'dosimetry', 'encryption', 'experience', 'image reconstruction', 'image registration', 'imaging Segmentation', 'interest', 'medical specialties', 'multicore processor', 'neoplastic cell', 'precision medicine', 'prototype', 'quantitative imaging', 'radiation delivery', 'reconstruction', 'scale up', 'single photon emission computed tomography', 'software systems', 'targeted delivery', 'therapeutic evaluation', 'tool', 'treatment planning', 'treatment strategy', 'tumor', 'web services']",NCI,"RADIOPHARMACEUTICAL IMAGING AND DOSIMETRY, LLC",R44,2020,162019,-0.040805740269873485
"Estimating Mediation Effects in Prevention Studies The purpose of this competing continuation grant proposal is to develop, evaluate and apply  methodological and statistical procedures to investigate how prevention programs change outcome  variables. These mediation analyses assess the link between program effects on the constructs targeted  by a prevention program and effects on the outcome. As noted by many researchers and federal  agencies, mediation analyses identify the most effective program components and increase  understanding of the underlying mechanisms leading to changing outcome variables. Information from  mediation analysis can make interventions more powerful, more efficient, and shorter. The P. I. of this grant received a one-year NIDA small grant and four multi-year grants to develop and evaluate mediation  analysis in prevention research. This work led to many publications and innovations. The proposed  five-year continuation focuses on the further development and refinement of exciting new mediation  analysis statistical developments. Four statistical topics represent next steps in this research and include  analytical and simulation research as well as applications to etiological and prevention data. The work expands on our development of causal mediation and Bayesian mediation methods that hold great promise for mediation analysis. In Study 1, practical causal mediation and Bayesian mediation analyses  for research designs are developed and evaluated. This approach will clarify methods and develop  approaches for dealing with violation of testable and untestable assumptions. Study 2 investigates  important measurement issues for the investigation of mediation. This work will focus on methods to identify critical facets of mediating variables, approaches to understanding whether mediators and  outcomes are redundant, and develop methods for studies with big data. Study 3 continues the development and evaluation of new longitudinal mediation methods for ecological momentary assessment data and other studies with massive data collection. These new methods promise to more accurately model change over time for both individuals and groups of individuals. Study 4 develops methods to  uncover subgroups in mediation analysis including causal mediation methods, multilevel models, and new  approaches based on residuals for identifying individuals for whom mediating processes differ in  effectiveness from other individuals. For each study, we will investigate unique issues with mediation analysis of prevention data including methods for small N and also massive data collection (big data), the RcErLitEicVaANl rCoEle(Soeef imnsetruacstiounrse):ment for mediating mechanisms, and the application of the growing literature on  causal methods and Bayesian methods. Study 5 applies new statistical methods to data from several NIH  The project further develops a method, statistical mediation analysis, that extracts more information from  funded prevention studies providing important feedback about the usefulness of the methods. Study 6  research. Mediation analysis explains how and why prevention and treatments are successful. Mediation  disseminates new information about mediation analysis through our website and other media, by  analysis improves prevention and treatment so that their effects are greater and even cost less. communication with researchers, and publications from the project. n/a",Estimating Mediation Effects in Prevention Studies,9851457,R37DA009757,"['Address', 'Alcohol or Other Drugs use', 'Applications Grants', 'Bayesian Method', 'Behavioral Mechanisms', 'Big Data', 'Biological Models', 'Communication', 'Complex', 'Consultations', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Ecological momentary assessment', 'Educational workshop', 'Effectiveness', 'Etiology', 'Evaluation', 'Feedback', 'Funding', 'Grant', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Outcome', 'Persons', 'Prevention', 'Prevention Research', 'Prevention program', 'Principal Investigator', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Residual state', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Work', 'base', 'computer program', 'cost', 'data space', 'design', 'dynamic system', 'improved', 'innovation', 'interest', 'longitudinal design', 'model design', 'multilevel analysis', 'novel strategies', 'programs', 'simulation', 'successful intervention', 'theories', 'therapy design', 'tool', 'treatment research', 'web site']",NIDA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R37,2020,382893,-0.037173411004077464
"Investigation of arterial changes in the Circle of Willis during intracranial aneurysm growth in humans PROJECT SUMMARY/ABSTRACT Prevalence of saccular intracranial aneurysms (IA) in western populations is estimated at around ~3%. Clinically, IA present a dilemma, in that they are usually asymptomatic; however, IA are extremely dangerous if they rupture, causing subarachnoid hemorrhage (~50% mortality). There is convincing evidence that continued IA growth increases the risk of rupture (12-24 times). To better monitor and predict IA progression, there is a compelling need to better understand clinical IA growth (aneurysmal remodeling). 90% of IA occur within the arteries of the Circle of Willis (CoW). Despite there being overwhelming evidence connecting CoW vascular remodeling and IA disease, the majority of IA research focuses only on the IA site, and does not consider the contribution of connected arteries. Specific vascular remodeling in the CoW arteries may provide an additional indicator for monitoring IA progression. The biochemical processes that occur at the IA site include inflammation and extracellular matrix remodeling leading to cell death and vessel wall degeneration. Analyses in animal models have strongly connected arterial wall shear stress (WSS) as a trigger of these processes, leading to IA initiation and remodeling. Patient-oriented research has further linked areas of low WSS with IA growth. Because CoW vasculature can change during IA growth, the blood flow entering IA changes and may create a new level of WSS to stabilize the remodeling process. Better understanding how human IA may naturally stabilize is highly relevant to predicting IA progression, and the role of changing WSS will be investigated in this grant. In our recent study of 520 clinically monitored IA, we found that while many IA grew consistently, following a projected growth path, others became stable. We also found that IA growth speed is significantly faster in women. Given the association of IA with sex, family history, and disease, different patterns of vascular remodeling may occur within groups with different genetics or medical history. We propose a clinical translational study to study IA growth in different genetic and medical history groups. We hypothesize IA growth may associate with patterns of vascular remodeling within the CoW. We will test our hypothesis with the following specific aims: (1) Is IA growth a local phenomenon or it associated with vascular remodeling within the CoW? (2) Do genetically similar individuals undergo similar patterns of vascular remodeling? (3) Does blood flow within the CoW associate with vascular remodeling? By identifying how IA disease progression may associate with other remodeling within the CoW, this study can identify new imaging biomarkers that enable improved IA treatment decisions. This proposal is significant because there is an unmet need to accurately assess IA disease progression and changes in risk. This proposal is innovative because it will extend existing IA studies to include more, relevant cerebrovascular arteries and longitudinal data, while implementing several technical innovations specific to this problem which can translate to clinical tracking of cerebrovascular changes PROJECT NARRATIVE Intracranial aneurysms are extremely dangerous when they rupture. When one is detected, it may be treated or monitored through imaging, with aneurysm growth a strong indication of increased risk of rupture. This project will study how remodeling in the arteries of the Circle of Willis associates with aneurysm growth, and how blood flow may determine locations of remodeling, in order to identify new biomarkers to improve tracking and assessment of aneurysm progression.",Investigation of arterial changes in the Circle of Willis during intracranial aneurysm growth in humans,9947821,R01HL152270,"['Affect', 'Aneurysm', 'Angiography', 'Animal Model', 'Area', 'Arteries', 'Autosomal Dominant Polycystic Kidney', 'Biochemical Process', 'Biological Markers', 'Blood Vessels', 'Blood flow', 'Caliber', 'Cell Death', 'Characteristics', 'Circle of Willis', 'Clinical', 'Dangerousness', 'Data', 'Data Set', 'Disease', 'Disease Progression', 'Extracellular Matrix', 'Family', 'Gender', 'Genetic', 'Geometry', 'Grant', 'Growth', 'Human', 'Hypertension', 'Image', 'Individual', 'Inflammation', 'Intracranial Aneurysm', 'Investigation', 'Length', 'Lesion', 'Link', 'Liquid substance', 'Location', 'Machine Learning', 'Medical History', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Prevalence', 'Process', 'Prospective cohort', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Role', 'Rupture', 'Site', 'Speed', 'Statistical Models', 'Stroke', 'Subarachnoid Hemorrhage', 'Techniques', 'Testing', 'Time', 'Translating', 'United States', 'Validation', 'Vascular remodeling', 'Woman', 'Work', 'arterial tortuosity', 'cerebrovascular', 'clinical risk', 'data modeling', 'demographics', 'hemodynamics', 'imaging biomarker', 'improved', 'innovation', 'mortality', 'novel', 'patient oriented research', 'sex', 'shape analysis', 'shear stress', 'side effect', 'tool', 'translational study']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,693928,-0.015028887746533397
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9969443,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data standards', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'large datasets', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'public repository', 'repository', 'research and development', 'software development', 'software infrastructure', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2020,158388,-0.017386334266471508
"Promoting Physical Activity in Latinas via lnteractive Web-based Technology Abstract  In the U.S., Latina women report higher rates of inactivity than their non-Hispanic White and male counterparts, and are disproportionately affected by related health conditions (e.g., cancer, hypertension, heart disease, stroke, diabetes). To address this public health crisis, evidence-based interventions that utilize state- of-the-art technology, theory and methods are needed to increase physical activity (PA) among this high-risk population. Recently, our team conducted a randomized controlled trial (N=205) to test the efficacy of a culturally adapted, individually tailored, Spanish-language Internet-based PA intervention among Latinas (Pasos Hacia La Salud, R01CA159954) vs. a Wellness Contact Control Internet Group. Although results were promising, the majority of participants still did not meet national guidelines for PA. In the ongoing renewal of R01CA159954, we will randomize 300 Latina women to either 1) the original Pasos Hacia La Salud tailored Internet-based PA intervention (Original Intervention) or 2) the data driven, enhanced version of the Pasos Hacia La Salud PA intervention (Enhanced Intervention).  The proposed supplement seeks to become the first trial to examine longitudinal patterns of PA adoption and maintenance across a series of longitudinal studies among Latinas. Traditional analytic methods would compare findings across studies and would estimate intervention effects at end of treatment controlling for baseline. We propose to use Integrative Data Analysis to combine data across studies and Latent Class Models to identifies patterns of PA adoption and maintenance. By using Latent Class Modeling (LCM), we will make full use of the longitudinal profile of PA data to identify patterns of change over time. LCMs use objective data (rather than a priori hypotheses) to subdivide the population into distinct groups of participants with similar profiles (of PA changes in this case). LCM can not only capture between- and within-subject heterogeneity, but can aid in the identification of meaningful subgroups within the population. By using this innovative method, we will not only reveal the inter-variability of PA over time but also elucidate the associations between such patterns and key psychosocial, behavioral and demographic predictors. Project Narrative Latinas exhibit high rates of inactivity and related chronic health conditions (including some cancers, diabetes, stroke, and hypertension), and are therefore in need of culturally and linguistically adapted physical activity interventions. The proposed supplement will build on the aims of the parent and renewal studies by using integrative data analysis to identify patterns of change in objectively measured physical activity over time, and test how these patterns relate to participant-level characteristics, including demographics, psychosocial and physiological predictors.",Promoting Physical Activity in Latinas via lnteractive Web-based Technology,9764734,R01CA159954,"['Address', 'Adoption', 'Affect', 'Behavior', 'Behavioral', 'Breast', 'Categories', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Chronic', 'Colon Carcinoma', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Effectiveness', 'Endometrial', 'Evidence based intervention', 'Exhibits', 'Future', 'Goals', 'Guidelines', 'Health', 'Heart Diseases', 'Heterogeneity', 'Hypertension', 'Individual', 'Internet', 'Intervention', 'Language', 'Latina', 'Linguistics', 'Longitudinal Studies', 'Lung', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Not Hispanic or Latino', 'Online Systems', 'Outcome', 'Parents', 'Participant', 'Patient Self-Report', 'Pattern', 'Physical activity', 'Physiological', 'Population', 'Prostate', 'Public Health', 'Publishing', 'Randomized', 'Randomized Controlled Trials', 'Reporting', 'Research', 'Research Personnel', 'Series', 'Stroke', 'Subgroup', 'Techniques', 'Technology', 'Testing', 'Time', 'Woman', 'analytical method', 'arm', 'base', 'behavior change', 'burden of illness', 'cancer risk', 'data reduction', 'demographics', 'design', 'disability', 'efficacy testing', 'exercise intervention', 'group intervention', 'high dimensionality', 'high risk population', 'innovation', 'interest', 'intervention effect', 'longitudinal dataset', 'male', 'moderate-to-vigorous physical activity', 'post intervention', 'protective effect', 'psychosocial', 'randomized trial', 'response', 'social culture', 'success', 'theories', 'vector', 'vigorous intensity']",NCI,BROWN UNIVERSITY,R01,2020,216895,-0.023837703615487486
"Reconstruction of heterogeneous and small macromolecules by cyro-EM PROJECT SUMMARY Single-particle electron cryomicroscopy (cryo-EM) has recently joined X-ray crystallography and NMR spectroscopy as a high-resolution structural method for biological macromolecules. In addition, cryo-EM produces images of individual molecules, and therefore has the potential to resolve conformational changes. The proposal aims to develop new algorithms and software for extending the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing computational tools for cryo-EM. This extension requires solving two of the most challenging computational problems posed by cryo-EM. First, mapping the structural variability of macromolecules is widely recognized as the main computational challenge in cryo-EM. Structural variations are of great significance to biologists, as they provide insight into the functioning of molecular machines. Existing computational tools are limited to a small number of distinct conformations, and therefore are incapable of tackling highly mobile biomolecules with multiple, continuous spectra of conformational changes. The first area of investigation in this project is the development of a computational framework to analyze continuous variability. The proposed approach is based on a new mathematical representation of continuously changing structures and its efficient estimation using Markov chain Monte Carlo (MCMC) algorithms. MCMC algorithms have found great success in many other scientific disciplines, yet they have been mostly overlooked for cryo-EM single particle analysis. Second, a major limiting factor for present cryo-EM studies is the molecule size. Images of small molecules (below ~50kDa) have too little signal to allow existing methods to provide valid 3-D reconstructions. It is commonly believed that cryo-EM cannot be used for molecules that are too small to be reliably detected and picked from micrographs. Challenging that widespread belief, the second area of investigation focuses on developing a groundbreaking approach for reconstructing small molecules directly from micrographs without particle picking. The new approach is based on autocorrelation analysis and completely bypasses particle picking and orientation assignment and requires just one pass over the data. The single-pass approach opens new possibilities for real-time processing during data acquisition. PROJECT NARRATIVE Determining structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, and a first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to significantly increase the power of structure-determination using electron cryomicroscopy (cryo-EM). Importantly, our methods will broaden the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing techniques.",Reconstruction of heterogeneous and small macromolecules by cyro-EM,9943364,R01GM136780,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Area', 'Belief', 'Biological', 'Biological Process', 'Bypass', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Cryoelectron Microscopy', 'Crystallization', 'Data', 'Data Set', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Discipline', 'Drug Design', 'Fostering', 'G-Protein-Coupled Receptors', 'Heterogeneity', 'Human Genome', 'Image', 'Individual', 'Institution', 'Investigation', 'Ion Channel', 'Ion Pumps', 'Machine Learning', 'Maps', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mathematics', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Molecular Motors', 'Molecular Weight', 'Motion', 'NMR Spectroscopy', 'Names', 'Noise', 'Particle Size', 'Phase', 'Polymerase', 'Preparation', 'Proteins', 'Pythons', 'Research', 'Resolution', 'Ribosomes', 'Roentgen Rays', 'Sampling', 'Signal Transduction', 'Spliceosomes', 'Structural Protein', 'Structure', 'Techniques', 'Time', 'Uncertainty', 'Update', 'Variant', 'Work', 'X-Ray Crystallography', 'base', 'computer framework', 'computerized data processing', 'computerized tools', 'data acquisition', 'expectation', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'macromolecule', 'molecular mass', 'novel strategies', 'open source', 'particle', 'programs', 'protein complex', 'protein structure', 'receptor', 'reconstruction', 'small molecule', 'statistics', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2020,328440,-0.042945340583719536
"Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0) OVERALL: ABSTRACT  The scope of regenerative medicine encompasses the repair, regeneration, and replacement of defective, injured, and diseased tissues and organs. The success of regenerative therapies is dependent, at least in part, on a favorable microenvironment in which the regenerative processes occur. Technological innovations and a deepened mechanistic understanding of how these microenvironmental signals influence tissue regeneration has drawn attention to the critical importance of the clinical field with foundations in the application of physical, thermal, and electrical stimuli to promote functional restoration—rehabilitation. We propose that the fields of regenerative medicine and rehabilitative science are inextricably intertwined, an intersection of disciplines that we and others have termed Regenerative Rehabilitation. To realize the full potential of Regenerative Rehabilitation, there is a need for formalized mechanisms that promote the interaction of basic scientists with rehabilitation specialists. During the initial funding cycle, the Alliance for Regenerative Rehabilitation Research & Training (AR3T) built a national network of investigators and programs that has helped to expand scientific knowledge, expertise and methodologies across the domains of regenerative medicine and rehabilitation. This proposal seeks funding for AR3T 2.0, in which we will build on successes achieved and lessons learned over the initial period of support with the goal of being even more responsive to the needs of the greater community. Six specific aims define a framework upon which we will achieve our goals. AR3T will provide education and drive the science underlying Regenerative Rehabilitation by: 1) Providing didactic programs that expose rehabilitation researchers to cutting-edge investigations and state-of-the-art technologies in the field of regenerative medicine (Didactic Aim); 2) Cultivating collaborative opportunities between renowned investigators in the fields of regenerative medicine and rehabilitation (Collaborations Aim); 3) Coordinating a pilot funding program to support novel lines of Regenerative Rehabilitation research (Pilot Funding Aim); 4) Developing and validating technologies to advance the measurement and use of the regenerative rehabilitation programs (Technology Aim); 5) Promoting our center’s expertise to a broad community of trainees, investigators, and clinicians (Promotion Aim); 6) Carefully monitoring and evaluating the effectiveness of our program will ensure that we are successful in achieving our goals (Quality Control Aim). Administrative note: In the preparation of this proposal, we made every effort to present a comprehensive and detailed plan for achieving our goals while minimizing redundancy. Therefore, in multiple places, we refer the reader to specific components of the application, rather than repeating text. We appreciate the time and effort the reviewers devote to the evaluation of the proposals.  Sincerely, Fabrisia, Tom and Mike PROJECT NARRATIVE  Regenerative Rehabilitation is the integration of principles and approaches across the fields of rehabilitation science and regenerative medicine. The integration of these two fields will increase the efficiency of interventions designed to optimize physical functioning to the benefit of a wide range of individuals with disabilities. The Alliance for Regenerative Rehabilitation Research & Training (AR3T) 2.0 will build on the momentum gained over the first cycle of funding with the goal of continuing to illuminate and seize opportunities to expand scientific knowledge, expertise and methodologies in the domain of Regenerative Rehabilitation.",Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0),9967689,P2CHD086843,"['Accountability', 'Activities of Daily Living', 'Age', 'Attention', 'Awareness', 'Basic Science', 'Biocompatible Materials', 'Clinical', 'Collaborations', 'Communities', 'Congenital Abnormality', 'Country', 'Data Analyses', 'Development', 'Disabled Persons', 'Discipline', 'Disease', 'Documentation', 'Education', 'Effectiveness', 'Ensure', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'In Vitro', 'Incubators', 'Individual', 'Injury', 'Intervention', 'Investigation', 'Journals', 'Knowledge', 'Laboratories', 'Machine Learning', 'Marketing', 'Measurement', 'Mechanics', 'Mentors', 'Methodology', 'Methods', 'Mission', 'Monitor', 'Natural regeneration', 'Organ', 'Performance', 'Physical Function', 'Pre-Clinical Model', 'Preparation', 'Process', 'Quality Control', 'Reader', 'Regenerative Medicine', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Science', 'Scientist', 'Series', 'Signal Transduction', 'Specialist', 'Stimulus', 'Structure', 'Systems Analysis', 'Technology', 'Text', 'Time', 'Tissues', 'Training', 'Trauma', 'Treatment Efficacy', 'Update', 'career', 'effectiveness evaluation', 'falls', 'functional restoration', 'gait examination', 'healing', 'injured', 'innovation', 'interest', 'investigator training', 'multidisciplinary', 'new technology', 'novel', 'novel strategies', 'pre-clinical', 'programs', 'regenerative', 'regenerative therapy', 'rehabilitation research', 'rehabilitation science', 'repaired', 'response', 'sabbatical', 'social media', 'success', 'symposium', 'technological innovation', 'therapy design', 'tissue regeneration', 'webinar']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P2C,2020,1059198,-0.03363422507724486
"Socioeconomic status, stress, and smoking cessation PROJECT SUMMARY/ABSTRACT  The prevalence of electronic nicotine delivery systems (ENDS) is rising dramatically among both adults and youth and ENDS use is fast becoming a major public health issue. However, because of their recent emergence, researchers know little about ENDS, their use, their effects on human physiology and health, their risks and benefits, or their impact on tobacco control efforts. A common barrier to studying ENDS is the lack of data on objective, real world use of ENDS. Thus, the proposed project aims to adapt existing innovative mobile assessment tools that can be used to target critical ENDS research gaps by providing mobile sensing technology that can objectively collect precise data regarding ENDS use in real time in real world. Specifically, the proposed revision project will expand the scope of Project On Track (1R01CA190329-01A1, PI: Wetter) by extending the application of puffMarker, an existing tool that automatically detects smoking, for the assessment of ENDS use. The current project has three aims: 1) adapt and validate puffMarker to identify discrete episodes of ENDS use, 2) adapt and validate puffMarker to distinguish between cigarette smoking and ENDS use among dual users of ENDS and cigarettes, and 3) utilize the Project On Track protocol to collect real time, real world data investigating potential determinants of ENDS use among both exclusive ENDS users as well as dual users of cigarettes and ENDS. Altogether, 120 participants (30 for Aim 1, 30 for Aim 2, and 60 for Aim 3) will be enrolled. Participants recruited for Aims 1 and 2 will attend laboratory (three 2-hour sessions) and field (3 days) studies. In the laboratory sessions, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke a cigarette (Aim 2). Participants' ENDS and cigarette puffs will be recorded by an independent observer. In the field studies, participants will wear the AutoSense wireless sensors and be asked to use ENDS (Aim 1) or use ENDS and smoke cigarettes (Aim 2). Participants will be asked to record each instance of ENDS use or cigarette smoking on a SP. The goals of the laboratory studies are to collect data to train puffMarker to identify ENDS use and to distinguish between cigarette smoking and ENDS use. The goal of the field studies is to validate puffMarker in real-life, natural environments. Aim 3 will utilize the Project On Track protocol to collect the first real time, real world data on ENDS and dual use. Participants will be assessed for 6 days using AutoSense, EMA, and GPS to examine potential determinants of ENDS use. A validated puffMarker that detects ENDS use and distinguishes between ENDS use and smoking can enhance many areas of research inquiry on ENDS. Knowledge learned from Aim 3 will be essential for the development of comprehensive conceptual models with respect to ENDS use and smoking cessation. PROJECT NARRATIVE The proposed project aims to develop an innovative tool that targets important ENDS research gaps by offer- ing researchers the latest mobile sensing technology to objectively collect precise data regarding ENDS use and distinguish between ENDS use and smoking in real time and in real world.","Socioeconomic status, stress, and smoking cessation",9985596,R01CA190329,"['Abstinence', 'Acute', 'Address', 'Adult', 'Algorithms', 'Area', 'Assessment tool', 'Behavior', 'Behavioral', 'Benefits and Risks', 'Big Data to Knowledge', 'Breathing', 'Cellular Phone', 'Characteristics', 'Chest', 'Cigarette', 'Data', 'Detection', 'Development', 'Ecological momentary assessment', 'Electronic Nicotine Delivery Systems', 'Enrollment', 'Environment', 'Environmental Risk Factor', 'Geography', 'Gestures', 'Goals', 'Grain', 'Hand', 'Harm Reduction', 'Health', 'High School Student', 'Hour', 'Human', 'Individual', 'Infrastructure', 'Inhalation', 'Knowledge', 'Laboratories', 'Laboratory Study', 'Life', 'Longitudinal cohort study', 'Machine Learning', 'Measures', 'Modeling', 'Movement', 'Oral cavity', 'Participant', 'Patient Recruitments', 'Pattern', 'Physiological', 'Physiology', 'Positioning Attribute', 'Predisposition', 'Prevalence', 'Process', 'Protocols documentation', 'Public Health', 'Questionnaires', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Sensitivity and Specificity', 'Sensory', 'Series', 'Smoke', 'Smoker', 'Smoking', 'Social Environment', 'Socioeconomic Status', 'Stress', 'System', 'Technology', 'Time', 'Training', 'United States National Institutes of Health', 'Wireless Technology', 'Wrist', 'Youth', 'addiction', 'arm movement', 'base', 'biobehavior', 'built environment', 'cigarette smoke', 'cigarette smoking', 'cigarette user', 'data to knowledge', 'experience', 'field study', 'innovation', 'novel', 'parent grant', 'population health', 'primary outcome', 'programs', 'psychosocial', 'real time monitoring', 'recruit', 'respiratory', 'sensor', 'sensor technology', 'smoking cessation', 'social', 'systems research', 'tobacco control', 'tobacco products', 'tool', 'uptake', 'wearable sensor technology', 'young adult']",NCI,UNIVERSITY OF UTAH,R01,2020,582564,-0.010792510623091122
"A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions Abstract. Melanoma is the third most common form of skin cancer with estimated 87,110 new cases diagnosed in the United States in the year 2017. Current routine diagnostic approaches utilize microscopic evaluation of thinly sectioned patient biopsies, but in certain cases diagnosis can be contentious even among experts. The overall goal of this multi-phase SBIR project is to develop, validate, and commercialize MelanoMap™, Frontier Diagnostics' patented assay for the diagnosis of melanoma using a matrix-assisted laser desorption/ionization imaging mass spectrometry (MALDI IMS) platform—and to have this assay available to pathologists in the U.S. as a laboratory developed test. MALDI IMS is a state-of-the-art technology that generates molecular images of tens to thousands of biomolecules from tissue sections in a single analysis. The assay uses formalin-fixed paraffin embedded (FFPE) biopsies used in routine histopathological diagnosis. The proposed assay has pathologists select regions of skin biopsies for analysis via a remote web interface. The acquired IMS data from those regions unambiguously identifies malignant melanoma or benign nevus.  Phase I of this proposal will demonstrate the feasibility of this technology platform to achieve cost-effective diagnosis of melanoma from patient skin biopsies at sample volumes acceptable for a clinical laboratory. Specific Aim 1 focuses on the development of a scalable and robust analytical protocol in both sample preparation and informatics to accurately diagnose melanoma with MALDI IMS. In specific aim 2, we will test the methodology developed in Specific Aim 1 on a cohort of melanocytic lesions with known clinical outcome and subsequently validate the classification accuracy of the proposed test  In Phase II, the protocols developed in Phase I will be integrated into a diagnostic service workflow. This phase will focus on quality control measures, client facing cloud software, clinical diagnostic reporting, and completing the analysis of a 500-patient sample set for final assay validation. Specific Aim 3 of this proposal (initial aim of Phase II) will establish and implement test tissues into standard workflows that will provide performance metrics for standard operation of a test meeting Clinical Laboratory Improvement Amendments (CLIA) standards. Protocols will be developed to monitor reagents, the reproducibility of sample preparation, and mass spectrometer performance on daily basis. Specific Aim 4 will expand software capabilities to include a secure web interface for clients ordering the test and the laboratory performing the test. The software will meet regulatory compliance, perform statistical analysis, and generate and communicate reports of the MALDI IMS analysis. Specific Aim 5 proposes to expand the sample set used in the initial assay from Specific Aim 2 to include a set of 300 patient samples from our clinical collaborators with 5 or more years follow-up data. The test will be independently validated by an additional 200 patient samples with definitive diagnoses. n/a",A Molecular Diagnostic Assay for Accurately Differentiating Melanoma from Benign Lesions,9926849,R44CA228897,"['Antigens', 'Area', 'Benign', 'Biological Assay', 'Biopsy', 'Caliber', 'Cells', 'Classification', 'Client', 'Clinical', 'Clinical Laboratory Improvement Amendments', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Services', 'Digestion', 'Early Diagnosis', 'Ensure', 'Evaluation', 'Formalin', 'Goals', 'Gold', 'Image', 'Incentives', 'Informatics', 'Laboratories', 'Legal patent', 'Lesion', 'Mass Spectrum Analysis', 'Measures', 'Metadata', 'Methodology', 'Microscopic', 'Microtomy', 'Monitor', 'Nevus', 'Outcome', 'Paraffin Embedding', 'Pathologist', 'Pathology Report', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Phase II Clinical Trials', 'Physical shape', 'Physicians', 'Preparation', 'Procedures', 'Proteins', 'Protocols documentation', 'Quality Control', 'Reagent', 'Reporting', 'Reproducibility', 'Research', 'Retrieval', 'Sampling', 'Secure', 'Security', 'Sensitivity and Specificity', 'Side', 'Skin', 'Skin Cancer', 'Small Business Innovation Research Grant', 'Software Tools', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Standardization', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Treatment Cost', 'United States', 'Validation', 'accurate diagnosis', 'analytical method', 'base', 'clinical diagnostics', 'cloud software', 'cohort', 'cost', 'cost effective', 'data acquisition', 'diagnosis standard', 'diagnostic assay', 'disease classification', 'follow-up', 'frontier', 'histopathological examination', 'instrumentation', 'interest', 'large datasets', 'machine learning algorithm', 'mass spectrometer', 'meetings', 'melanoma', 'molecular diagnostics', 'molecular imaging', 'mortality risk', 'operation', 'prototype', 'quality assurance', 'skin lesion', 'tissue preparation', 'web interface']",NCI,"FRONTIER DIAGNOSTICS, LLC",R44,2020,944492,-0.009933714924798201
"RADECT is developing a clinical guidance (CG) software for nurse education and practitioners to evaluate experiential case-files  for the purpose of augmenting health disparity/equity clinical care. Project Summary/Abstract Our NIH SBIR project is to validate a Clinical Guidance System to assist practitioners in underserved and health disparity environments. We will apply our Clinical Guidance System for nurse education. The Clinical Guidance System is being trained across diverse medical disciplines across various healthcare data. This will then guide practitioners in diagnosis and treatment knowledge. The Clinical Guidance System is to improve access to care for the underserved and health disparity without increasing cost. The specific aims are the following, 1) to demonstrate effective software learning algorithms, and 2) to relate the index patient to other patient case-files in accuracy and agility. This project supports the given NIH Mission in seeking better health for everyone. The relevance of our NIH SBIR project is to research and develop a Clinical Guidance System for nurse integrated education and practitioner use in clinical use. The software system will assist nurses and general medical practitioners by offering greater clinical and specialist responsibility in underserved and health disparity environments.",RADECT is developing a clinical guidance (CG) software for nurse education and practitioners to evaluate experiential case-files  for the purpose of augmenting health disparity/equity clinical care.,10038114,R44MD014095,"['Address', 'Adopted', 'Augmented Reality', 'Automobile Driving', 'Back', 'Boston', 'Businesses', 'Cardiovascular system', 'Caregivers', 'Caring', 'Case Study', 'Chronic Disease Hospitals', 'Clinical', 'Clinics and Hospitals', 'Communities', 'Community Hospitals', 'Computer software', 'Computers', 'Data', 'Data Files', 'Data Set', 'Decision Making', 'Devices', 'Diagnosis', 'Dictionary', 'Discipline', 'Discipline of Nursing', 'Disease', 'Education', 'Environment', 'Faculty', 'Future', 'Genomics', 'Guidelines', 'Health', 'Health Care Costs', 'Health Services Accessibility', 'Healthcare', 'Human', 'Improve Access', 'Intervention', 'Knowledge', 'Language', 'Learning', 'Legal patent', 'Machine Learning', 'Massachusetts', 'Maternal Health', 'Medical', 'Methods', 'Mission', 'Modeling', 'Monitor', 'Nurse Practitioners', 'Nurses', 'Nursing Education', 'Paper', 'Pathway interactions', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Play', 'Policies', 'Prevention', 'Primary Health Care', 'Protocols documentation', 'Psychological reinforcement', 'Quality Control', 'Quality of Care', 'Research', 'Site', 'Small Business Innovation Research Grant', 'Specialist', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transcend', 'United States National Institutes of Health', 'Universities', 'Update', 'Validation', 'Vocabulary', 'Writing', 'application programming interface', 'base', 'blockchain', 'cardiovascular risk factor', 'care costs', 'clinical care', 'clinically relevant', 'cost', 'cost effective', 'cost effectiveness', 'crowdsourcing', 'dashboard', 'disadvantaged population', 'distributed ledger', 'health disparity', 'health equity', 'hospital readmission', 'improved', 'indexing', 'innovation', 'learning algorithm', 'learning strategy', 'mortality', 'nutrition', 'programs', 'public health relevance', 'repository', 'respiratory', 'sensor', 'skills', 'socioeconomics', 'software systems', 'visual information']",NIMHD,"RADECT, INC.",R44,2020,730828,-0.025490796877531034
"Immune Basis & Clinical implications of Threshold-Based Phenotypes of Peanut Allergy Summary: Immune Basis and Clinical Implications of Threshold-Based Phenotypes of Peanut Allergy Peanut allergy (PA) is common, affecting 2-5% of school-age children in the US. The characteristics of PA vary widely among individuals, with some reacting to 1/100th of a peanut and others not having symptoms until they have ingested many peanuts. Symptoms can vary from mild rashes to fatal anaphylaxis. There is no FDA- approved treatment, and all patients with PA are managed with strict allergen avoidance. Most research on PA has focused on those with the most exquisite sensitivity to peanut. Immunotherapy trials commonly exclude subjects with a threshold dose over 1/3 of a peanut (100mg). However, most individuals with PA have higher thresholds of reaction and are excluded from current research approaches. We hypothesize that the natural heterogeneity of PA is a valuable opportunity for investigation. We have shown that milk or egg allergic individuals with tolerance to baked forms of these foods not only tolerate their inclusion in the diet, but this exposure increases the rate of resolution 14-16-fold. We hypothesize that dietary exposure to sub-threshold levels of peanut in those with higher threshold levels of reactivity could lead to significant clinical improvement. Furthermore, studying the natural heterogeneity of PA is a valuable opportunity to elucidate mechanisms of disease. To study the clinical implications and mechanism of phenotypic heterogeneity in PA, we will conduct a randomized open feeding trial (CAFETERIA trial) to investigate a prototype approach where children with moderate PA (tolerating at least 100 mg of peanut) ingest a sub-threshold amount daily, with increasing levels tested every 3 months. The impact of dietary intervention will be tested at 1 and 2 years by oral food challenge. The CAFETERIA study will provide a rich biorepository of samples from highly phenotyped subjects. We anticipate screening 200-250 subjects, including low threshold, high threshold, and sensitized but not allergic, in order to enroll 98 subjects that meet the high threshold criteria for the CAFETERIA trial. We will obtain longitudinal samples from subjects randomized to dietary therapy or avoidance. We will comprehensively profile antibody responses by high-throughput epitope assay, peanut-specific T cell responses by flow cytometry, and whole blood activation by CyTOF to construct a detailed clinical-immune network of PA, and analyze the relationship between immune and clinical parameters. We will identify biomarkers and key causal drivers of PA by performing integrated network-based examination of peripheral blood transcriptomes from PA subjects, sampled before and after food challenge, and before and after dietary therapy. Successful completion of these aims will result in (1) a simple low-cost treatment option applicable to the majority of those with PA; (2) an identification of immune and molecular mechanisms of PA and response to dietary therapy; (3) peripheral blood biomarkers that will practically impact clinical care of PA; (4) the potential for personalized approaches to the treatment of PA; and (5) a tremendously rich resource of clinical, immune, and transcriptional data and analytic tools to be made publicly available to the research community. NARRATIVE This AADCR Center will investigate threshold-based phenotypic heterogeneity of peanut allergy. We will focus on an under-studied high-threshold phenotype of peanut allergy, and examine the impact of dietary therapy with sub-threshold amounts of peanut. We will use this clinically diverse cohort to perform high dimensional profiling in order to elucidate immune and molecular mechanisms of allergy and tolerance to peanut.",Immune Basis & Clinical implications of Threshold-Based Phenotypes of Peanut Allergy,9934148,U19AI136053,"['Affect', 'Allergens', 'Allergic', 'Allergy to eggs', 'Allergy to peanuts', 'Anaphylaxis', 'Antibodies', 'Antibody Response', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Biology', 'Characteristics', 'Child', 'Clinical', 'Clinical Data', 'Communities', 'Computational Biology', 'Data', 'Diet', 'Dietary Intervention', 'Disease', 'Dose', 'Economic Burden', 'Enrollment', 'Epitopes', 'Exanthema', 'Exposure to', 'FDA approved', 'Flow Cytometry', 'Food', 'Food Hypersensitivity', 'Funding', 'Genetic Transcription', 'Genomics', 'Goals', 'Heterogeneity', 'Hypersensitivity', 'IgE', 'Immune', 'Immunologics', 'Immunology', 'Individual', 'Ingestion', 'Investigation', 'Lead', 'Life', 'Machine Learning', 'Measures', 'Medical', 'Milk', 'Milk Hypersensitivity', 'Molecular', 'Network-based', 'Nutritional', 'Oral', 'Patients', 'Persons', 'Phase III Clinical Trials', 'Phenotype', 'Predictive Value', 'Proteins', 'Protocols documentation', 'Quality of life', 'Randomized', 'Reaction', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Schedule', 'School-Age Population', 'Severities', 'Speed', 'Symptoms', 'T cell response', 'T-Lymphocyte', 'Testing', 'Treatment Cost', 'Urticaria', 'Visit', 'Whole Blood', 'allergic response', 'analytical tool', 'base', 'biobank', 'biomarker identification', 'clinical care', 'clinical practice', 'cohort', 'cost', 'data tools', 'desensitization', 'egg', 'feeding', 'food allergen', 'food challenge', 'high dimensionality', 'immunotherapy trials', 'individualized medicine', 'intervention cost', 'learning network', 'neglect', 'oral diagnostics', 'oral immunotherapy', 'outcome prediction', 'peripheral blood', 'personalized approach', 'prototype', 'response', 'screening', 'transcriptome']",NIAID,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U19,2020,2195573,-0.0043109000220648026
"Mechanisms of mechano-chemical rupture of blood clots and thrombi Mechanisms of mechano-chemical rupture of blood clots and thrombi Prashant K. Purohit, John L. Bassani, Valeri Barsegov and John W. Weisel The goal of this proposal is to explore and understand the fracture toughness of blood clots and thrombi, thus providing a mechanistic basis for life-threatening thrombotic embolization. A combination of experiments, theoretical modeling and computer simulations will reveal how mechanical stresses (due to blood flow) in synergy with enzymatic lysis induce structural damage from the molecular to continuum scales and affect the propensity of a clot to embolize. The specific aims of this proposal are: (1) Measure and model fracture toughness of fibrin gels in quasi-static conditions, (2) Investigate rate dependent dissipative effects on toughness of fibrin gels, and (3) Study the effects of blood cells, prothrombotic blood composition, and fibrinolysis on rupture of blood clots. In Specific Aim (SA) 1, we will measure toughness of fibrin clots and provide a structural basis for rupture at the micron and nanometer scales. In SA2, we will delve into the thermodynamics and rate-dependence of the fracture of fibrin gels, including fluid flow through pores and fluid drag on fibrin fibers to capture how energy dissipation increases toughness. In the translational SA3, we will investigate toughness of physiologically relevant clots with effects of platelets, red blood cells, and neutrophils in the absence and presence of the physiological fibrinolytic activator (tPA). We will also study the rupture of clots made from the blood of venous thromboembolism patients to explore the effects of (pro)thrombotic alterations of blood composition on clot mechanical stability. Our preliminary studies show that i) the toughness of cross-linked fibrin gels is in the range of those for synthetic hydrogels, ii) the addition of tPA to a crack tip reduces the loads for crack growth, iii) fibers are aligned and broken along the tensile direction at the crack tip, and iv) crack propagation results from the rupture of covalent and non-covalent bonds. We also developed v) dynamic force spectroscopy in silico to mechanically test fibrin fibers and fibrin networks using pulling simulations and vi) atomic stress approach to map the stress-strain fields using the output from simulations. We will use continuum and finite element models of swellable biopolymer hydrogels, and statistical mechanical models for the forced unfolding of fibrin molecules. We will employ multiscale computational modeling based on Molecular Dynamics simulations of atomic structures of fibrin fibers, and Langevin simulations of fibrin networks accelerated on Graphics Processing Units. The proposed experiments cover the whole gamut of macroscopic tensile tests, shear rheometry, electron microscopy and confocal microscopy to visualize and quantitate the structural alterations of ruptured blood clots. Our experiments and modeling will help us to understand the mechanisms of thrombotic embolization and will address the clinically important question: why is there a strong association between clot structure/mechanical properties and cardiovascular diseases? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering. Project Narrative The research objective of this proposal is to measure, model and predict the mechanisms of mechano-chemical rupture of blood clots and thrombi at the molecular and continuum length scales. Our experiments and modeling will help to understand the mechanisms of embolization and will address the clinically important question: why is there a strong correlation between clot structure/mechanical properties and cardiovascular disease? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering.",Mechanisms of mechano-chemical rupture of blood clots and thrombi,9970812,R01HL148227,"['Address', 'Affect', 'Biocompatible Materials', 'Biological', 'Biomedical Engineering', 'Biopolymers', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood coagulation', 'Blood flow', 'Cardiovascular Diseases', 'Cause of Death', 'Chemicals', 'Clinical', 'Clinical Medicine', 'Coagulation Process', 'Complex', 'Computer Models', 'Computer Simulation', 'Confocal Microscopy', 'Cytolysis', 'Dependence', 'Diagnosis', 'Disease', 'Electron Microscopy', 'Elements', 'Enzymes', 'Erythrocytes', 'Evolution', 'Fiber', 'Fibrin', 'Fibrinogen', 'Fibrinolysis', 'Fracture', 'Frustration', 'Gel', 'Glean', 'Goals', 'Growth', 'Hydrogels', 'Knowledge', 'Laws', 'Length', 'Life', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mechanical Stress', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Molecular Structure', 'Output', 'Patients', 'Physicians', 'Physiological', 'Plasma', 'Predisposition', 'Prevention', 'Process', 'Property', 'Prophylactic treatment', 'Proteins', 'Research', 'Research Proposals', 'Resistance', 'Resources', 'Rupture', 'Specimen', 'Spectrum Analysis', 'Stress', 'Structural Models', 'Structural defect', 'Structure', 'Testing', 'Theoretical Studies', 'Theoretical model', 'Therapeutic Embolization', 'Thermodynamics', 'Thick', 'Thrombin', 'Thromboembolism', 'Thrombosis', 'Thrombus', 'Traction', 'Work', 'base', 'crosslink', 'density', 'design', 'disability', 'experimental study', 'fiber cell', 'fluid flow', 'in silico', 'in vivo', 'insight', 'instrumentation', 'interdisciplinary approach', 'materials science', 'mechanical properties', 'models and simulation', 'molecular dynamics', 'molecular scale', 'multi-scale modeling', 'nanoscale', 'neutrophil', 'novel strategies', 'predictive modeling', 'prevent', 'response', 'simulation', 'synergism', 'theories', 'tool', 'venous thromboembolism', 'viscoelasticity']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2020,656886,-0.01982991468954304
"Leveraging Existing Data and Analytic Methods for Health Disparities Research Related to Aging and Alzheimer's Disease and Related Dementias (ADRD) Abstract Two of a series of in-person workshops in 2020-2022 will be hosted at Duke to provide new knowledge on how existing and recently developed analytic methods can be used for detailed population and clinical data analysis in order to make progress in understanding the causes and mechanisms of health-related disparities in Alzheimer’s disease (AD), related dementias (ADRD), and other prominent age-related diseases. The long- term goal of the series is to provide a resource focused on diffusing methodological know-how in terms of demonstrating the capabilities of newly developed methodologies, expanding on the rigor and range of application of well-established and familiar methods, promoting correct use of big health data both from a methodological and ethical prospective as well as providing a forum for experts and newcomers interested in health disparities and age-related diseases to discuss their ideas and promote their research. The pilot Duke- NIA workshop of the series held in February 2019 at Duke University was successful in drawing broad scientific interest to the topic and generated the background for the current proposal. The focus of the first workshop (planned in Winter 2020/2021) will be on demonstrating how studies using established administrative health data resources such as the Medicare claims database combined with innovative analytic approaches such as partitioning analyses, time-series based methods of projection/forecasting, and stochastic process models can be used to uncover previously overlooked and/or understudied aspects in this area of research. Specific topics to be discussed will include: i) disparities in risks and survival of AD/ADRD and other age- related diseases; ii) forecasting approaches for prevalence and mortality of AD/ADRD and other age-related diseases; iii) analysis of Medicare and other administrative claim-based data. The focus of the second workshop (planned in Winter 2021/2022) will extend this to include the health records data routinely collected in hospitals or University medical centers (e.g., the Duke Clinical Data Warehouse) and demonstrate how well- established and new analytic methods can be rigorously applied to such data to contribute to identifying the causes of persistent health disparities between specific groups of the U.S. population and narrowly defined patient strata. Specific topics will be expanded to include: i) analytic approaches to identify and quantify the contribution of treatment-related and medical care access-related factors to disparities in outcomes of AD/ADRD and other age-related diseases; ii) comorbidity, multimorbidity, treatment-related, social and genetic factors as sources of disparities in health outcomes of AD/ADRD and other age-related diseases; iii) forecasting of health outcomes and approaches for analyses of potential health interventions. The proceedings will be streamed live on the workshop website and presentations will be freely available in text and video form after the fact. Narrative Our objective is to host two in-person workshops in 2020-2021, in which research findings and evidence-based information and analytic tools for analyses of health-related disparities in Alzheimer’s disease, related dementias and other prominent age-related diseases are discussed. Specific Aims to be addressed in this project will be focused on increased collaboration and partnership in an interdisciplinary research community focused on analytic methods for large-scale population and clinic-related data, constructing a bridge between independent research subgroups, and the identification of ways to achieve synergistic effects in multidisciplinary research by combining innovative approaches developed across different research groups. Ultimately, our long-term goal is to diffuse the active use of advanced analytic methods for analyses of existing big health population datasets in health disparity research.",Leveraging Existing Data and Analytic Methods for Health Disparities Research Related to Aging and Alzheimer's Disease and Related Dementias (ADRD),10070960,R13AG069381,"['Academic Medical Centers', 'Address', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Area', 'Caring', 'Clinic', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Databases', 'Dependence', 'Development', 'Diffuse', 'Diffusion', 'Discipline', 'Disease', 'Educational workshop', 'Epidemiology', 'Ethics', 'Ethnic Origin', 'Future', 'Generations', 'Genetic', 'Geographic Locations', 'Goals', 'Health', 'Health Services Accessibility', 'Healthcare Systems', 'Hospitals', 'Individual', 'Interdisciplinary Study', 'Intervention', 'Knowledge', 'Machine Learning', 'Measures', 'Medical', 'Medical Care Costs', 'Medical center', 'Medicare', 'Medicare claim', 'Methodology', 'Methods', 'Modeling', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Patients', 'Persons', 'Population', 'Population Analysis', 'Prevalence', 'Process', 'Publications', 'Race', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Series', 'Site', 'Source', 'Statistical Methods', 'Stochastic Processes', 'Stream', 'Subgroup', 'Text', 'Therapeutic', 'Time', 'Time trend', 'Universities', 'advanced analytics', 'age related', 'analytical method', 'analytical tool', 'base', 'burden of illness', 'clinical data warehouse', 'comorbidity', 'data resource', 'data warehouse', 'dementia risk', 'disorder risk', 'evidence base', 'health data', 'health disparity', 'health record', 'innovation', 'interest', 'mortality', 'multiple chronic conditions', 'news', 'population health', 'prospective', 'social', 'web site']",NIA,DUKE UNIVERSITY,R13,2020,50000,-0.05534595038794319
"Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye Age-related macular degeneration (AMD) is the leading cause of blindness in the elderly in the developed world; no cure exists and prevalence is rising rapidly. Because only primates have a macula and since no model of AMD exists in non-human primates, the disease course can only be elucidated through in-depth study of humans. Blindness in AMD is caused by progressive and irreversible death of rod and cone photoreceptors secondary to degeneration of the retinal pigment epithelium (RPE) that is essential for their health and function. Clinical imaging and histology have informed us greatly about the later stages of disease but fundamental knowledge to understand how AMD diverges from normal aging at onset is lacking. With advanced adaptive optics ophthalmoscopy (AOO) imaging methods, combined with clinical imaging and visual function testing, we will characterize healthy human retinal aging in cross-sectional study, by defining the in vivo RPE-photoreceptor cellular organization and microscopic autofluorescence variation with age and wavelength. This will produce the largest quantitative in vivo normative dataset of AOO cell-based metrics to date and we will use this data to generate new quantitative analysis tools needed to evaluate emerging therapies designed to prevent or slow vision loss in AMD (Aim 1). In a case-control study, we will then compare normal photoreceptor topography and RPE cell morphometry to clinically defined early AMD to quantitatively define the earliest cellular changes in AMD that can be detected in vivo. This work will identify the cellular alterations and phenotypes that differentiate normal aging from early AMD to facilitate early onset detection. These results will be contextualized by comparison to tissue-level alterations seen with aging and early AMD in clinical imaging, specifically choriocapillaris decline and drusen (Aim 2). The results of this study will result in a paradigm shift from the use of clinical diagnosis and classification systems for AMD that rely solely on tissue- level biomarkers or traditional funduscopic clinical signs to those that rely on rigorous quantitative in vivo cell- based metrics. Together, this knowledge and these tools will lay the foundation needed to develop and evaluate new preventative therapies that are needed to limit or prevent vision loss in AMD. Project Narrative Age-related macular degeneration is the leading cause of blindness in the elderly in the US and is a significant public health issue that is projected to worsen due to the rapidly aging population. Here we aim to understand how retinal cells change in normal aging and how these normal age-related changes differ from the changes that lead to age-related macular degeneration. This project will allow us to detect age-related macular degeneration earlier and will produce new tools to monitor retinal cells that will facilitate the development and testing of preventative therapies to slow or prevent vision loss in age-related macular degeneration.",Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye,9973645,R01EY030517,"['Age', 'Age related macular degeneration', 'Aging', 'Area', 'Atrophic', 'Biological Markers', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Case-Control Studies', 'Cells', 'Cessation of life', 'Choroid', 'Classification', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Cross-Sectional Studies', 'Cytoplasmic Granules', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic Procedure', 'Disease', 'Drusen', 'Elderly', 'Evaluation', 'Eye', 'Foundations', 'Genetic', 'Goals', 'Health', 'Histology', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Lead', 'Lipofuscin', 'Machine Learning', 'Maps', 'Melanins', 'Methods', 'Microscopic', 'Modeling', 'Monitor', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Perfusion', 'Phenotype', 'Photoreceptors', 'Prevalence', 'Preventive therapy', 'Preventive treatment', 'Primate Diseases', 'Primates', 'Public Health', 'Retina', 'Retinal Cone', 'Retinal Degeneration', 'Retinal Photoreceptors', 'Risk', 'Secondary to', 'Spatial Distribution', 'Structure', 'Structure of retinal pigment epithelium', 'System', 'Techniques', 'Technology', 'Testing', 'Therapy Evaluation', 'Time', 'Tissues', 'Variant', 'Vertebrate Photoreceptors', 'Vision', 'Work', 'adaptive optics', 'age related', 'aging population', 'base', 'clinical Diagnosis', 'clinical decision-making', 'clinical imaging', 'cohort', 'early onset', 'fluorophore', 'healthy aging', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'macula', 'morphometry', 'multimodality', 'neurovascular unit', 'nonhuman primate', 'normal aging', 'prevent', 'restorative treatment', 'retinal imaging', 'retinal rods', 'therapy design', 'tool']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,527040,-0.03763995761384527
"Mechanoresponsive Engrailed-1-negative fibroblasts activate Engrailed-1 to promote fibrosis in wound healing 7. Project Summary/Abstract Adult human skin heals by developing fibrotic scar tissue, which can result in devastating disfigurement, growth restriction, and permanent functional loss. Despite a plethora of clinical options, no current treatment strategies successfully prevent or reverse this fibrotic process, and scars and their sequelae cost the United States over $20 billion every year. Progress towards the development of new therapies has been significantly hindered by a lack of understanding of the specific cell populations responsible for scarring. In 2015, our group reported that Engrailed-1 (En-1) lineage-positive fibroblasts (EPFs) are responsible for the vast majority of dorsal scar production in postnatal mice. In early fetal gestation, mice heal scarlessly via skin regeneration, an ideal outcome mediated by En-1 lineage-negative fibroblasts (ENFs; the predominant fetal fibroblast). However, it has not been established if ENFs contribute to postnatal wound healing. In this proposal, we explore for the first time the postnatal conversion of ENFs to pro-fibrotic EPFs (postnatally-derived EPFs; pEPFs) within the wound environment. First, histology, immunohistochemistry, and wounding in a novel transgenic mouse model will be used to study the conversion of ENFs to pEPFs during wound healing. By examining the behavior of ENF subpopulations (derived from papillary dermis, reticular dermis, and hypodermis) in the wound environment and confirming our findings in a tamoxifen-inducible mouse model of En-1 activation, we will precisely define the ENF population that gives rise to pro-fibrotic pEPFs. Second, we will establish the specific wound environment cues that drive ENF-to-EPF transition. Given that mechanical forces are known to modulate both scar burden and fibroblast activity, we will use in vitro and in vivo models to examine the effects of mechanical environment on En-1 activation. We will further use transcriptomic and epigenomic profiling to explore the role of mechanotransduction signaling in ENF-to-EPF transition and pEPF function. Third, having established a mechanotransduction mechanism underlying En-1 activation in wound ENFs, we will inhibit mechanotransduction signaling with the goal of blocking ENF-to-EPF transition. Specifically, we will assess whether blocking mechanotransduction results in ENF-mediated wound healing with reduced fibrosis. Our ultimate translational goal is to develop therapeutics that target fibrogenic fibroblasts to promote regenerative healing. Collectively, the proposed work will significantly enhance our understanding of the key molecular and cellular determinants of cutaneous scarring, inform the development of novel anti-scarring therapies, and shed light on the cellular origin of dermal scarring fibroblasts. 8. Project Narrative Scarring is the end result of injury in adult human skin and results in an enormous financial and medical burden for our society. There are currently no effective molecular therapies that prevent scarring or its sequelae, and development of therapeutics has been hindered by lack of understanding of the precise cell populations that mediate fibrosis in wound healing. Therefore, we propose to explore the contribution of a specific fibroblast subpopulation (Engrailed-1 lineage-negative fibroblasts; ENFs) in fibrotic wound healing, in order to inform novel directions for targeted treatments that minimize scarring and promote regenerative wound healing.",Mechanoresponsive Engrailed-1-negative fibroblasts activate Engrailed-1 to promote fibrosis in wound healing,9933446,R01GM136659,"['3-Dimensional', 'Adult', 'Algorithms', 'Anatomic Surface', 'Behavior', 'Cells', 'Cellular Assay', 'Characteristics', 'Chemicals', 'Chromatin', 'Cicatrix', 'Clinical', 'Collagen', 'Connective Tissue', 'Cues', 'Cultured Cells', 'Cutaneous', 'Data', 'Dermal', 'Dermis', 'Development', 'Dipeptidyl-Peptidase IV', 'Dorsal', 'Elements', 'Engraftment', 'Environment', 'Extracellular Matrix', 'Fiber', 'Fibroblasts', 'Fibrosis', 'Fluorescence-Activated Cell Sorting', 'Focal Adhesion Kinase 1', 'Genetic Transcription', 'Goals', 'Growth', 'Hair follicle structure', 'High-Throughput Nucleotide Sequencing', 'Histologic', 'Histology', 'Hydrogels', 'Immunohistochemistry', 'In Vitro', 'Individual', 'Injury', 'Light', 'Maps', 'Measures', 'Mechanical Stress', 'Mechanics', 'Mediating', 'Medical', 'Microscopy', 'Molecular', 'Morbidity - disease rate', 'Mus', 'Outcome', 'Papillary', 'Pathway interactions', 'Population', 'Pregnancy', 'Process', 'Production', 'Protein Inhibition', 'Proteins', 'Reporting', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Skin', 'Societies', 'Specimen', 'Subcutaneous Tissue', 'Surface', 'Tamoxifen', 'Time', 'Tissues', 'Transgenic Mice', 'Transposase', 'United States', 'Verteporfin', 'Visual', 'Wild Type Mouse', 'Work', 'analog', 'base', 'cost', 'digital', 'epigenomics', 'experimental study', 'fetal', 'functional loss', 'healing', 'in vivo', 'in vivo Model', 'inhibitor/antagonist', 'machine learning algorithm', 'mechanical force', 'mechanotransduction', 'mortality', 'mouse model', 'novel', 'novel therapeutics', 'postnatal', 'prevent', 'reconstruction', 'regenerative', 'response', 'single-cell RNA sequencing', 'skin regeneration', 'skin wound', 'therapeutic development', 'therapeutic target', 'tissue culture', 'tool', 'transcriptomics', 'treatment strategy', 'wound', 'wound bed', 'wound environment', 'wound healing']",NIGMS,STANFORD UNIVERSITY,R01,2020,317823,-0.03806722505881632
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10082215,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2020,749858,-0.022358224196911563
"HABIT DESIGN: TESTING A NOVEL BEHAVIORAL APPROACH TO CORPORATE WELLNESS IN THE CONTEXT OF METABOLIC SYNDROME Abstract Metabolic syndrome (MetS) is a constellation of risk factors– elevated triglycerides (TG), insufficient high- density lipoprotein cholesterol (HDL-C), elevated blood pressure (BP), elevated fasting blood glucose (FBG), and above-threshold waist circumference (WC)–that is associated with increased cardiovascular disease, type 2 diabetes mellitus, and some forms of cancer. Research suggests that addressing MetS through the workplace could significantly benefit employee health and employer healthcare costs. Habit Design, Inc., has developed an enhanced behavioral health coaching system called Habit Design (HD) that is the first to integrate habit formation, contingency management, and social learning approaches within a smartphone app to support to behavior change in corporate or employee health contexts. In this Fast Track project, we will adapt the HD approach to address MetS. In Phase I, we will 1) refine and extend existing functional prototypes of the HD app to support the latest versions of iOS and Android, 2) conduct usability testing with 8 targeted end users, and 3) prepare standard treatment manuals for the Phase II clinical trial. In Phase II, we will 1) make indicated changes to the HD app based on findings from the Phase I usability test and 2) evaluate the effectiveness of HD coaching compared to standard health coaching in a randomized trial with 424 corporate wellness program participants who have MetS, with follow-up spanning one year. Participants will employees of TriHealth in Cincinnati who have completed a health screening as part of their corporate wellness program and been identified as having at least 3/5 of the following: 1) TG ≥150 mg/dL), 2) HDL-C <40 mg/dL in males and <50 mg/dL in females, 3) BP ≥130/85 mm Hg, 4) FBG ≥100 mg/dl, and 5) WC ≥102 cm in males and ≥80 cm in females.. All participants will be coached to increase physical activity, which will be monitored with a waist-worn FitBit and Fitabase software. Additionally, participants will choose prior to randomization a goal of increasing fruit and vegetable intake or substituting water for sugar-sweetened beverages. Conditions will be stratified by choice of goal and gender. In both conditions coaching will be monitored for fidelity and delivered in 12 weekly in-person 30-minute sessions followed by one 30-minute maintenance session per month for 4 months. The primary outcome will be average daily step count measured over the course of at least one week at baseline, 4 months, 8 months, and 12 months. The secondary outcome will be standard units increase of fruit/vegetable intake or water intake, according to the participant's choice. Tertiary outcomes will consist of FBG, TG, HDL, BP, WC, and body mass index, measured at each time point. Additionally, we will conduct web-based assessment of self-reported physical activity, junk food, and sugar-sweetened beverage consumption; automaticity of exercise and fruit, vegetable, and water consumption; self-efficacy and social support for target behaviors; and health-related quality of life. Ratings of usability and satisfaction and app usage metrics will be examined. Analyses will be intent-to-treat assuming 15% loss to follow-up. Project Narrative/Relevance Metabolic syndrome is a major public health problem that affects over one in three American adults and increases the risk of cardiovascular disease, type 2 diabetes, and some forms of cancer. Habit Design, Inc., has developed an integrated health coaching system that uses a smartphone app to promote healthy behaviors. We will adapt it for metabolic syndrome and evaluate its effectiveness in a corporate health setting.",HABIT DESIGN: TESTING A NOVEL BEHAVIORAL APPROACH TO CORPORATE WELLNESS IN THE CONTEXT OF METABOLIC SYNDROME,10084515,R44HL142328,"['Address', 'Adherence', 'Adult', 'Affect', 'American', 'Android', 'Behavior', 'Behavioral', 'Behavioral Model', 'Blood Glucose', 'Blood Pressure', 'Body mass index', 'Cardiovascular Diseases', 'Central obesity', 'Chronic', 'Companions', 'Computer software', 'Consumption', 'Cues', 'Development', 'Effectiveness', 'Employee', 'Employee Health', 'Environment', 'Exercise', 'Fasting', 'Feedback', 'Female', 'Food', 'Fostering', 'Gender', 'Goals', 'Habits', 'Health', 'Health Care Costs', 'Health behavior', 'High Density Lipoprotein Cholesterol', 'High Density Lipoproteins', 'Hypertension', 'Hypertriglyceridemia', 'Intake', 'Intervention', 'Link', 'Location', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Metabolic syndrome', 'Modeling', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Participant', 'Patient Self-Report', 'Persons', 'Phase', 'Phase II Clinical Trials', 'Physical activity', 'Psychological reinforcement', 'Psychology', 'Public Health', 'Randomized', 'Randomized Controlled Trials', 'Research', 'Rewards', 'Risk Factors', 'Science', 'Self Efficacy', 'Social support', 'System', 'Telephone', 'Test Result', 'Testing', 'Time', 'Translating', 'Triglycerides', 'Water', 'Water consumption', 'Wellness Program', 'Workplace', 'base', 'behavior change', 'behavioral health', 'cardiovascular disorder risk', 'contingency management', 'crowdsourcing', 'design', 'effectiveness evaluation', 'experience', 'financial incentive', 'fitbit', 'follow-up', 'fruits and vegetables', 'health related quality of life', 'improved', 'innovation', 'male', 'mobile computing', 'novel', 'peer coaching', 'peer support', 'primary outcome', 'programs', 'prototype', 'randomized trial', 'satisfaction', 'screening', 'secondary outcome', 'smartphone Application', 'social learning', 'standard care', 'sugar', 'sweetened beverage', 'usability', 'waist circumference', 'web-based assessment']",NHLBI,"HABIT DESIGN, INC.",R44,2020,726708,-0.02715427196471049
"A portable photoacoustic imager for diagnosing vascular diseases Project Summary/Abstract Vascular diseases are the leading cause of death worldwide. Some common vascular diseases include: cardio vascular disease, stroke, and peripheral artery disease (PAD). Many of these vascular diseases need point-of- care (POC) diagnosis and monitoring using non-ionizing, non-invasive and cost-effective approaches. Although Doppler ultrasound meets all these requirements, it only maps blood flow, which is operator dependent and influenced by motion artifacts, resulting in limited sensitivity and specificity to detect the disease in its early stage. A POC technique that provides direct label-free molecular and functional information of vasculature is needed to reliably detect and monitor vascular diseases.  A mobile photoacoustic imager (mPAI) is proposed for diagnosing various vascular diseases in resource poor settings of the world. Leveraging on strong multispectral optical absorption of oxy- and de-oxy hemoglobins, the mPAI is capable of providing multi-parametric information of deep vasculature, such as blood oxygen saturation, plaque lipids, blood flow and blood clot. The mPAI is non-invasive, real time and uses non-ionizing optical and ultrasound radiation. This will be the first and perhaps the only portable technology capable of deriving such multiparametric functional information of deep vasculature without the use of contrast agents. Competing technologies cannot provide such a direct information of vascular health, and certainly not in a compact portable device form. Health care providers can use the mPAI to instantly diagnose several vascular diseases affecting humans of all ages, including infants.  In the R21 phase, Aim1 will design and develop the mPAI, integrating the low-cost optical illumination and piezoelectric micromachined ultrasound transducer (PMUT) arrays. Dr. Rundra Pratap team from the Indian Institute of Science (IISc), Bangalore, will design and fabricate the PMUT arrays. Dr. Kothapalli team will develop the mPAI and validate its performance on tissue mimicking vascular phantoms in Aim 1, and rat models of PAD in Aim 2. The ultimate goal of the two-year R21 phase is to achieve a clinical grade mPAI device with reliable vascular imaging metrics.  In the R33 phase, to test the clinical performance of the mPAI, the following multicenter pilot clinical studies on PAD patients will be conducted in 1) Penn State Hershey medical center, 2) Vikram Hospital in India through collaborations with the IISc team, and 3) in Ghana in Year 5 with the help of Dr. Colette Pameijer of Penn State who conducts medical camps in Ghana every year through Penn State Global Health Program. Clinical studies in R33 phase will be undertaken only if well-defined milestones are achieved in the R21 phase.  The overall goal of these studies is to carefully validate the clinical potential of emerging label-free photoacoustic imaging technology to screen for vascular diseases, in a portable form, in resource poor settings of the world. Project Narrative Vascular diseases are becoming epidemic with increase in aging population, obesity and type II diabetes. They affect humans of all age groups, including neonates. This proposal aims to develop and validate the first ever portable photoacoustic imager for diagnosing and monitoring vascular diseases in resource poor settings.",A portable photoacoustic imager for diagnosing vascular diseases,10058614,R21EB030370,"['3-Dimensional', 'Adipose tissue', 'Affect', 'Age', 'Animals', 'Anticoagulants', 'Arteriovenous malformation', 'Award', 'Blood', 'Blood Vessels', 'Blood Volume', 'Blood coagulation', 'Blood flow', 'Brown Fat', 'Care Technology Points', 'Cause of Death', 'Chronic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computer software', 'Computers', 'Contrast Media', 'Coupled', 'Data', 'Deep Vein Thrombosis', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Doppler Ultrasound', 'Electronics', 'Engineering', 'Epidemic', 'Fiber Optics', 'Functional Imaging', 'Ghana', 'Goals', 'Health', 'Health Personnel', 'Hemangioma', 'Hematoma', 'Hemoglobin', 'Hospitals', 'Human', 'Human Resources', 'Image', 'Imaging Device', 'Imaging technology', 'India', 'Infant', 'Institutes', 'Label', 'Lasers', 'Light', 'Lighting', 'Lipids', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Medical', 'Medical center', 'Modeling', 'Molecular', 'Monitor', 'Morphologic artifacts', 'Motion', 'Multi-site clinical study', 'Noise', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Optics', 'Oxygen', 'Patients', 'Performance', 'Peripheral arterial disease', 'Phase', 'Physicians', 'Population Heterogeneity', 'Radiation', 'Rattus', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Science', 'Screening procedure', 'Sensitivity and Specificity', 'Signal Transduction', 'Source', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Ultrasonic Transducer', 'Ultrasonography', 'Vascular Diseases', 'Venous Insufficiency', 'absorption', 'age group', 'aging population', 'cost', 'cost effective', 'data acquisition', 'deep learning algorithm', 'design', 'falls', 'global health', 'imager', 'imaging capabilities', 'imaging platform', 'imaging system', 'in vivo', 'light scattering', 'miniaturize', 'neonate', 'next generation', 'older patient', 'phantom model', 'photoacoustic imaging', 'point of care', 'portability', 'preclinical study', 'prognostic', 'programs', 'research clinical testing', 'screening', 'time use', 'tissue phantom', 'transmission process']",NIBIB,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R21,2020,1000,-0.010295654202375902
"Microfluidic intact cell platform: A novel tool for oral cancer detection Oral squamous cell carcinoma (OSCC) claims the lives of thousands in the U.S. and hundreds of thousands worldwide annually. A biopsy followed by histopathology, the gold standard for the diagnosis of OSCC, is painful, invasive, costly, not practical if longitudinal assessments of the same lesion are required and oftentimes is not available or imprecise in third world countries. A tool that quickly distinguishes cancerous from non- cancerous lesions and identifies progressive or transforming lesions could allow for early intervention, which would improve outcomes and negate the need for unnecessary biopsies in patients whose lesions remain benign or haven’t begun to degenerate. Therefore, there is an unmet need for a rapid, non-invasive, objective and cost-effective test for OSCC. We and others have reported that an altered expression profile of human beta defensin 3 (hBD-3), an epithelial cell derived antimicrobial peptide (AMP), and hBD-2, another epithelial cell AMP, is an early event in OSCC. Therefore, the ratio of hBD-3 and hBD-2 in the lesion, when compared to the contralateral site, could be exploited in distinguishing OSCC from other lesions of the oral cavity. We refer to this ratio as the beta defensin index (BDI). Our ongoing clinical study of 78 subjects with suspicious oral lesions demonstrated high sensitivity (100%) and specificity (74%) of the ELISA based BDI in distinguishing cancerous from noncancerous oral lesions (P<0.0001). With the high accuracy (98%) of our BDI based molecular assay, we now wish to advance our novel platform from the laborious, time consuming ELISA format into an imaging-based point-of-care (POC) device that utilizes microfluidic technology to quantify the BDI with an expected turnover time of half an hour. Our microfluidic intact cell assay (MICA) approach to developing a POC device for oral cancer detection is unique; it utilizes intact epithelial cells trapped in a microfluidic chip encompassing microfabricated pillar arrays with varying spaces to allow the capture of epithelial cells. Upon capture, the cells are permeabilized and labeled with fluorescent antibodies for hBD ratio analysis. We employ automated fluorescence imaging and computational algorithm to enable automated calculation of the BDI scores. We now hypothesize that the ELISA format that can effectively detect oral cancer, can be configured for point of care MICA, retaining its high accuracy and making it easier to use worldwide. To advance the discovery of this new approach for oral cancer detection, we propose the following aims: 1. Develop a working prototype of a MICA POC device for oral cancer testing equipped with cell imaging and BDI calculation capabilities. 2. Conduct a discovery phase study where MICA POC and ELISA, as independent assays, will be compared with pathology review in their ability to detect oral cancer. The MICA POC, while not intending to replace biopsy, could be deployed, in the future, to objectively and non- invasively determine who actually needs a biopsy, monitor oral premalignant lesions in real world practice and fulfill a major unmet need in low-socio economic countries where pathology review is lacking and/or unreliable. Narrative Oral cancer (OC) kills thousands in the U.S. and hundreds of thousands worldwide, and early detection is key to improved survival. Since biopsy followed by pathology review, the gold standard for OC, is costly, painful, can result in patient complications, is impractical should monitoring be required, and is often not available or imprecise in third world countries, we intend to develop (Aim 1), and test in humans (Aim 2), an innovative device that will accurately detect OC, non-invasively, within ½ hour and thereby will address a major unmet need in early OC detection worldwide. The device will incorporate microfluidic, imaging and computational technologies that will determine the ratios of two key proteins from swabbed cells obtained from suspicious oral lesions; a procedure we have already shown to be accurate using a laboratory based technique.",Microfluidic intact cell platform: A novel tool for oral cancer detection,10043470,R21CA253108,"['Address', 'Aliquot', 'Bedside Testings', 'Benign', 'Biological', 'Biological Assay', 'Biological Markers', 'Biopsy', 'Caliber', 'Cancer Detection', 'Cancerous', 'Carcinoma in Situ', 'Cations', 'Cell membrane', 'Cells', 'Cellular Assay', 'Cellular Phone', 'Clinical Research', 'Coin', 'Collaborations', 'Collecting Cell', 'Computational algorithm', 'Computer Analysis', 'Consumption', 'Contralateral', 'Country', 'Custom', 'Dental Clinics', 'Detection', 'Developing Countries', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early Intervention', 'Engineering', 'Enzyme-Linked Immunosorbent Assay', 'Epithelial Cells', 'Event', 'Expression Profiling', 'Fluorescence', 'Fluorescent Antibody Technique', 'Future', 'Goals', 'Gold', 'Head and Neck Cancer', 'Health care facility', 'Histopathology', 'Hour', 'Human', 'Image', 'Immobilization', 'India', 'Indigenous', 'Individual', 'Label', 'Laboratories', 'Lesion', 'Measures', 'Medicine', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Molecular', 'Monitor', 'Mouth Carcinoma', 'Myelogenous', 'Non-Invasive Lesion', 'Observational Study', 'Oral', 'Oral Stage', 'Oral cavity', 'Oral mucous membrane structure', 'Pain', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Peptides', 'Phase', 'Phenotype', 'Primary Health Care', 'Procedures', 'Proteins', 'Reporting', 'Research Personnel', 'Resources', 'Sampling', 'Screening for Oral Cancer', 'Screening procedure', 'Site', 'Specificity', 'Swab', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'University Hospitals', 'Work', 'antimicrobial', 'antimicrobial peptide', 'base', 'beta pleated sheet', 'beta-Defensins', 'beta-defensin 3', 'biomarker development', 'cellular imaging', 'chemokine', 'clinical care', 'cost', 'cost effective', 'deep learning algorithm', 'diagnosis standard', 'diagnostic accuracy', 'experience', 'fluorescence imaging', 'imaging Segmentation', 'imaging capabilities', 'imaging platform', 'immunoregulation', 'improved', 'improved outcome', 'indexing', 'innovation', 'malignant mouth neoplasm', 'metaplastic cell transformation', 'microfluidic technology', 'monitoring device', 'mouth squamous cell carcinoma', 'mucosal site', 'novel', 'novel strategies', 'oral lesion', 'overexpression', 'patient population', 'point of care', 'portability', 'portable monitoring', 'premalignant', 'primary care setting', 'prospective', 'prototype', 'recruit', 'scalpel', 'screening', 'socioeconomics', 'success', 'tertiary care', 'tool']",NCI,CASE WESTERN RESERVE UNIVERSITY,R21,2020,413972,-0.04400344056186364
